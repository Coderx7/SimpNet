I1210 09:11:39.492043 16412 caffe.cpp:219] Using GPUs 0
I1210 09:11:39.656610 16412 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1210 09:11:39.978469 16412 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 09:11:39.993468 16412 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1210 09:11:39.994468 16412 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 09:11:39.995468 16412 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 09:11:39.995468 16412 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1210 09:11:39.995468 16412 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1210 09:11:39.995468 16412 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_maxdrp_300k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 36
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 44
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 44
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 44
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 62
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 62
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 71
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 09:11:40.007508 16412 layer_factory.cpp:58] Creating layer cifar
I1210 09:11:40.013485 16412 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1210 09:11:40.013485 16412 net.cpp:84] Creating Layer cifar
I1210 09:11:40.013485 16412 net.cpp:380] cifar -> data
I1210 09:11:40.013485 16412 net.cpp:380] cifar -> label
I1210 09:11:40.014487 16412 data_layer.cpp:45] output data size: 100,3,32,32
I1210 09:11:40.022471 16412 net.cpp:122] Setting up cifar
I1210 09:11:40.022471 16412 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 09:11:40.022471 16412 net.cpp:129] Top shape: 100 (100)
I1210 09:11:40.022471 16412 net.cpp:137] Memory required for data: 1229200
I1210 09:11:40.022471 16412 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 09:11:40.022471 16412 net.cpp:84] Creating Layer label_cifar_1_split
I1210 09:11:40.022471 16412 net.cpp:406] label_cifar_1_split <- label
I1210 09:11:40.022471 16412 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 09:11:40.022471 16412 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 09:11:40.023473 16412 net.cpp:122] Setting up label_cifar_1_split
I1210 09:11:40.023473 16412 net.cpp:129] Top shape: 100 (100)
I1210 09:11:40.023473 16412 net.cpp:129] Top shape: 100 (100)
I1210 09:11:40.023473 16412 net.cpp:137] Memory required for data: 1230000
I1210 09:11:40.023473 16412 layer_factory.cpp:58] Creating layer conv1
I1210 09:11:40.023473 16412 net.cpp:84] Creating Layer conv1
I1210 09:11:40.023473 16412 net.cpp:406] conv1 <- data
I1210 09:11:40.023473 16412 net.cpp:380] conv1 -> conv1
I1210 09:11:40.024473  9844 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 09:11:40.272606 16412 net.cpp:122] Setting up conv1
I1210 09:11:40.272606 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.272606 16412 net.cpp:137] Memory required for data: 15975600
I1210 09:11:40.272606 16412 layer_factory.cpp:58] Creating layer bn1
I1210 09:11:40.272606 16412 net.cpp:84] Creating Layer bn1
I1210 09:11:40.272606 16412 net.cpp:406] bn1 <- conv1
I1210 09:11:40.272606 16412 net.cpp:367] bn1 -> conv1 (in-place)
I1210 09:11:40.272606 16412 net.cpp:122] Setting up bn1
I1210 09:11:40.272606 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.272606 16412 net.cpp:137] Memory required for data: 30721200
I1210 09:11:40.272606 16412 layer_factory.cpp:58] Creating layer scale1
I1210 09:11:40.272606 16412 net.cpp:84] Creating Layer scale1
I1210 09:11:40.272606 16412 net.cpp:406] scale1 <- conv1
I1210 09:11:40.272606 16412 net.cpp:367] scale1 -> conv1 (in-place)
I1210 09:11:40.272606 16412 layer_factory.cpp:58] Creating layer scale1
I1210 09:11:40.272606 16412 net.cpp:122] Setting up scale1
I1210 09:11:40.272606 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.272606 16412 net.cpp:137] Memory required for data: 45466800
I1210 09:11:40.272606 16412 layer_factory.cpp:58] Creating layer relu1
I1210 09:11:40.272606 16412 net.cpp:84] Creating Layer relu1
I1210 09:11:40.272606 16412 net.cpp:406] relu1 <- conv1
I1210 09:11:40.272606 16412 net.cpp:367] relu1 -> conv1 (in-place)
I1210 09:11:40.272606 16412 net.cpp:122] Setting up relu1
I1210 09:11:40.272606 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.272606 16412 net.cpp:137] Memory required for data: 60212400
I1210 09:11:40.272606 16412 layer_factory.cpp:58] Creating layer conv1_0
I1210 09:11:40.272606 16412 net.cpp:84] Creating Layer conv1_0
I1210 09:11:40.272606 16412 net.cpp:406] conv1_0 <- conv1
I1210 09:11:40.272606 16412 net.cpp:380] conv1_0 -> conv1_0
I1210 09:11:40.274605 16412 net.cpp:122] Setting up conv1_0
I1210 09:11:40.274605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.274605 16412 net.cpp:137] Memory required for data: 78234800
I1210 09:11:40.275606 16412 layer_factory.cpp:58] Creating layer bn1_0
I1210 09:11:40.275606 16412 net.cpp:84] Creating Layer bn1_0
I1210 09:11:40.275606 16412 net.cpp:406] bn1_0 <- conv1_0
I1210 09:11:40.275606 16412 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 09:11:40.275606 16412 net.cpp:122] Setting up bn1_0
I1210 09:11:40.275606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.275606 16412 net.cpp:137] Memory required for data: 96257200
I1210 09:11:40.275606 16412 layer_factory.cpp:58] Creating layer scale1_0
I1210 09:11:40.275606 16412 net.cpp:84] Creating Layer scale1_0
I1210 09:11:40.275606 16412 net.cpp:406] scale1_0 <- conv1_0
I1210 09:11:40.275606 16412 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 09:11:40.275606 16412 layer_factory.cpp:58] Creating layer scale1_0
I1210 09:11:40.275606 16412 net.cpp:122] Setting up scale1_0
I1210 09:11:40.275606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.275606 16412 net.cpp:137] Memory required for data: 114279600
I1210 09:11:40.275606 16412 layer_factory.cpp:58] Creating layer relu1_0
I1210 09:11:40.275606 16412 net.cpp:84] Creating Layer relu1_0
I1210 09:11:40.275606 16412 net.cpp:406] relu1_0 <- conv1_0
I1210 09:11:40.275606 16412 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 09:11:40.275606 16412 net.cpp:122] Setting up relu1_0
I1210 09:11:40.275606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.275606 16412 net.cpp:137] Memory required for data: 132302000
I1210 09:11:40.275606 16412 layer_factory.cpp:58] Creating layer conv2
I1210 09:11:40.275606 16412 net.cpp:84] Creating Layer conv2
I1210 09:11:40.275606 16412 net.cpp:406] conv2 <- conv1_0
I1210 09:11:40.275606 16412 net.cpp:380] conv2 -> conv2
I1210 09:11:40.278611 16412 net.cpp:122] Setting up conv2
I1210 09:11:40.278611 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.278611 16412 net.cpp:137] Memory required for data: 150324400
I1210 09:11:40.278611 16412 layer_factory.cpp:58] Creating layer bn2
I1210 09:11:40.278611 16412 net.cpp:84] Creating Layer bn2
I1210 09:11:40.278611 16412 net.cpp:406] bn2 <- conv2
I1210 09:11:40.278611 16412 net.cpp:367] bn2 -> conv2 (in-place)
I1210 09:11:40.278611 16412 net.cpp:122] Setting up bn2
I1210 09:11:40.278611 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.278611 16412 net.cpp:137] Memory required for data: 168346800
I1210 09:11:40.278611 16412 layer_factory.cpp:58] Creating layer scale2
I1210 09:11:40.278611 16412 net.cpp:84] Creating Layer scale2
I1210 09:11:40.278611 16412 net.cpp:406] scale2 <- conv2
I1210 09:11:40.278611 16412 net.cpp:367] scale2 -> conv2 (in-place)
I1210 09:11:40.278611 16412 layer_factory.cpp:58] Creating layer scale2
I1210 09:11:40.278611 16412 net.cpp:122] Setting up scale2
I1210 09:11:40.278611 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.278611 16412 net.cpp:137] Memory required for data: 186369200
I1210 09:11:40.278611 16412 layer_factory.cpp:58] Creating layer relu2
I1210 09:11:40.278611 16412 net.cpp:84] Creating Layer relu2
I1210 09:11:40.278611 16412 net.cpp:406] relu2 <- conv2
I1210 09:11:40.278611 16412 net.cpp:367] relu2 -> conv2 (in-place)
I1210 09:11:40.278611 16412 net.cpp:122] Setting up relu2
I1210 09:11:40.278611 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.278611 16412 net.cpp:137] Memory required for data: 204391600
I1210 09:11:40.278611 16412 layer_factory.cpp:58] Creating layer conv2_1
I1210 09:11:40.278611 16412 net.cpp:84] Creating Layer conv2_1
I1210 09:11:40.278611 16412 net.cpp:406] conv2_1 <- conv2
I1210 09:11:40.278611 16412 net.cpp:380] conv2_1 -> conv2_1
I1210 09:11:40.280606 16412 net.cpp:122] Setting up conv2_1
I1210 09:11:40.280606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.280606 16412 net.cpp:137] Memory required for data: 222414000
I1210 09:11:40.280606 16412 layer_factory.cpp:58] Creating layer bn2_1
I1210 09:11:40.280606 16412 net.cpp:84] Creating Layer bn2_1
I1210 09:11:40.280606 16412 net.cpp:406] bn2_1 <- conv2_1
I1210 09:11:40.280606 16412 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 09:11:40.280606 16412 net.cpp:122] Setting up bn2_1
I1210 09:11:40.280606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.280606 16412 net.cpp:137] Memory required for data: 240436400
I1210 09:11:40.280606 16412 layer_factory.cpp:58] Creating layer scale2_1
I1210 09:11:40.280606 16412 net.cpp:84] Creating Layer scale2_1
I1210 09:11:40.280606 16412 net.cpp:406] scale2_1 <- conv2_1
I1210 09:11:40.280606 16412 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 09:11:40.280606 16412 layer_factory.cpp:58] Creating layer scale2_1
I1210 09:11:40.280606 16412 net.cpp:122] Setting up scale2_1
I1210 09:11:40.280606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.280606 16412 net.cpp:137] Memory required for data: 258458800
I1210 09:11:40.280606 16412 layer_factory.cpp:58] Creating layer relu2_1
I1210 09:11:40.280606 16412 net.cpp:84] Creating Layer relu2_1
I1210 09:11:40.280606 16412 net.cpp:406] relu2_1 <- conv2_1
I1210 09:11:40.280606 16412 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 09:11:40.280606 16412 net.cpp:122] Setting up relu2_1
I1210 09:11:40.281605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.281605 16412 net.cpp:137] Memory required for data: 276481200
I1210 09:11:40.281605 16412 layer_factory.cpp:58] Creating layer conv2_2
I1210 09:11:40.281605 16412 net.cpp:84] Creating Layer conv2_2
I1210 09:11:40.281605 16412 net.cpp:406] conv2_2 <- conv2_1
I1210 09:11:40.281605 16412 net.cpp:380] conv2_2 -> conv2_2
I1210 09:11:40.282605 16412 net.cpp:122] Setting up conv2_2
I1210 09:11:40.282605 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.283620 16412 net.cpp:137] Memory required for data: 299009200
I1210 09:11:40.283620 16412 layer_factory.cpp:58] Creating layer bn2_2
I1210 09:11:40.283620 16412 net.cpp:84] Creating Layer bn2_2
I1210 09:11:40.283620 16412 net.cpp:406] bn2_2 <- conv2_2
I1210 09:11:40.283620 16412 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 09:11:40.283620 16412 net.cpp:122] Setting up bn2_2
I1210 09:11:40.283620 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.283620 16412 net.cpp:137] Memory required for data: 321537200
I1210 09:11:40.283620 16412 layer_factory.cpp:58] Creating layer scale2_2
I1210 09:11:40.283620 16412 net.cpp:84] Creating Layer scale2_2
I1210 09:11:40.283620 16412 net.cpp:406] scale2_2 <- conv2_2
I1210 09:11:40.283620 16412 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 09:11:40.283620 16412 layer_factory.cpp:58] Creating layer scale2_2
I1210 09:11:40.283620 16412 net.cpp:122] Setting up scale2_2
I1210 09:11:40.283620 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.283620 16412 net.cpp:137] Memory required for data: 344065200
I1210 09:11:40.283620 16412 layer_factory.cpp:58] Creating layer relu2_2
I1210 09:11:40.283620 16412 net.cpp:84] Creating Layer relu2_2
I1210 09:11:40.283620 16412 net.cpp:406] relu2_2 <- conv2_2
I1210 09:11:40.283620 16412 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 09:11:40.284608 16412 net.cpp:122] Setting up relu2_2
I1210 09:11:40.284608 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.284608 16412 net.cpp:137] Memory required for data: 366593200
I1210 09:11:40.284608 16412 layer_factory.cpp:58] Creating layer pool2_1
I1210 09:11:40.284608 16412 net.cpp:84] Creating Layer pool2_1
I1210 09:11:40.284608 16412 net.cpp:406] pool2_1 <- conv2_2
I1210 09:11:40.284608 16412 net.cpp:380] pool2_1 -> pool2_1
I1210 09:11:40.284608 16412 net.cpp:122] Setting up pool2_1
I1210 09:11:40.284608 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.284608 16412 net.cpp:137] Memory required for data: 372225200
I1210 09:11:40.284608 16412 layer_factory.cpp:58] Creating layer conv3
I1210 09:11:40.284608 16412 net.cpp:84] Creating Layer conv3
I1210 09:11:40.284608 16412 net.cpp:406] conv3 <- pool2_1
I1210 09:11:40.284608 16412 net.cpp:380] conv3 -> conv3
I1210 09:11:40.285619 16412 net.cpp:122] Setting up conv3
I1210 09:11:40.285619 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.285619 16412 net.cpp:137] Memory required for data: 377857200
I1210 09:11:40.285619 16412 layer_factory.cpp:58] Creating layer bn3
I1210 09:11:40.285619 16412 net.cpp:84] Creating Layer bn3
I1210 09:11:40.285619 16412 net.cpp:406] bn3 <- conv3
I1210 09:11:40.285619 16412 net.cpp:367] bn3 -> conv3 (in-place)
I1210 09:11:40.285619 16412 net.cpp:122] Setting up bn3
I1210 09:11:40.285619 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.285619 16412 net.cpp:137] Memory required for data: 383489200
I1210 09:11:40.285619 16412 layer_factory.cpp:58] Creating layer scale3
I1210 09:11:40.286620 16412 net.cpp:84] Creating Layer scale3
I1210 09:11:40.286620 16412 net.cpp:406] scale3 <- conv3
I1210 09:11:40.286620 16412 net.cpp:367] scale3 -> conv3 (in-place)
I1210 09:11:40.286620 16412 layer_factory.cpp:58] Creating layer scale3
I1210 09:11:40.286620 16412 net.cpp:122] Setting up scale3
I1210 09:11:40.286620 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.286620 16412 net.cpp:137] Memory required for data: 389121200
I1210 09:11:40.286620 16412 layer_factory.cpp:58] Creating layer relu3
I1210 09:11:40.286620 16412 net.cpp:84] Creating Layer relu3
I1210 09:11:40.286620 16412 net.cpp:406] relu3 <- conv3
I1210 09:11:40.286620 16412 net.cpp:367] relu3 -> conv3 (in-place)
I1210 09:11:40.286620 16412 net.cpp:122] Setting up relu3
I1210 09:11:40.286620 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.286620 16412 net.cpp:137] Memory required for data: 394753200
I1210 09:11:40.286620 16412 layer_factory.cpp:58] Creating layer conv3_1
I1210 09:11:40.286620 16412 net.cpp:84] Creating Layer conv3_1
I1210 09:11:40.286620 16412 net.cpp:406] conv3_1 <- conv3
I1210 09:11:40.286620 16412 net.cpp:380] conv3_1 -> conv3_1
I1210 09:11:40.287616 16412 net.cpp:122] Setting up conv3_1
I1210 09:11:40.287616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.287616 16412 net.cpp:137] Memory required for data: 400385200
I1210 09:11:40.287616 16412 layer_factory.cpp:58] Creating layer bn3_1
I1210 09:11:40.287616 16412 net.cpp:84] Creating Layer bn3_1
I1210 09:11:40.287616 16412 net.cpp:406] bn3_1 <- conv3_1
I1210 09:11:40.287616 16412 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 09:11:40.288616 16412 net.cpp:122] Setting up bn3_1
I1210 09:11:40.288616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.288616 16412 net.cpp:137] Memory required for data: 406017200
I1210 09:11:40.288616 16412 layer_factory.cpp:58] Creating layer scale3_1
I1210 09:11:40.288616 16412 net.cpp:84] Creating Layer scale3_1
I1210 09:11:40.288616 16412 net.cpp:406] scale3_1 <- conv3_1
I1210 09:11:40.288616 16412 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 09:11:40.288616 16412 layer_factory.cpp:58] Creating layer scale3_1
I1210 09:11:40.288616 16412 net.cpp:122] Setting up scale3_1
I1210 09:11:40.288616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.288616 16412 net.cpp:137] Memory required for data: 411649200
I1210 09:11:40.288616 16412 layer_factory.cpp:58] Creating layer relu3_1
I1210 09:11:40.288616 16412 net.cpp:84] Creating Layer relu3_1
I1210 09:11:40.288616 16412 net.cpp:406] relu3_1 <- conv3_1
I1210 09:11:40.288616 16412 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 09:11:40.288616 16412 net.cpp:122] Setting up relu3_1
I1210 09:11:40.288616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.288616 16412 net.cpp:137] Memory required for data: 417281200
I1210 09:11:40.288616 16412 layer_factory.cpp:58] Creating layer conv4
I1210 09:11:40.288616 16412 net.cpp:84] Creating Layer conv4
I1210 09:11:40.288616 16412 net.cpp:406] conv4 <- conv3_1
I1210 09:11:40.288616 16412 net.cpp:380] conv4 -> conv4
I1210 09:11:40.289616 16412 net.cpp:122] Setting up conv4
I1210 09:11:40.289616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.289616 16412 net.cpp:137] Memory required for data: 422913200
I1210 09:11:40.289616 16412 layer_factory.cpp:58] Creating layer bn4
I1210 09:11:40.289616 16412 net.cpp:84] Creating Layer bn4
I1210 09:11:40.289616 16412 net.cpp:406] bn4 <- conv4
I1210 09:11:40.289616 16412 net.cpp:367] bn4 -> conv4 (in-place)
I1210 09:11:40.289616 16412 net.cpp:122] Setting up bn4
I1210 09:11:40.289616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.289616 16412 net.cpp:137] Memory required for data: 428545200
I1210 09:11:40.289616 16412 layer_factory.cpp:58] Creating layer scale4
I1210 09:11:40.289616 16412 net.cpp:84] Creating Layer scale4
I1210 09:11:40.289616 16412 net.cpp:406] scale4 <- conv4
I1210 09:11:40.289616 16412 net.cpp:367] scale4 -> conv4 (in-place)
I1210 09:11:40.290616 16412 layer_factory.cpp:58] Creating layer scale4
I1210 09:11:40.290616 16412 net.cpp:122] Setting up scale4
I1210 09:11:40.290616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.290616 16412 net.cpp:137] Memory required for data: 434177200
I1210 09:11:40.290616 16412 layer_factory.cpp:58] Creating layer relu4
I1210 09:11:40.290616 16412 net.cpp:84] Creating Layer relu4
I1210 09:11:40.290616 16412 net.cpp:406] relu4 <- conv4
I1210 09:11:40.290616 16412 net.cpp:367] relu4 -> conv4 (in-place)
I1210 09:11:40.290616 16412 net.cpp:122] Setting up relu4
I1210 09:11:40.290616 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.290616 16412 net.cpp:137] Memory required for data: 439809200
I1210 09:11:40.290616 16412 layer_factory.cpp:58] Creating layer conv4_1
I1210 09:11:40.290616 16412 net.cpp:84] Creating Layer conv4_1
I1210 09:11:40.290616 16412 net.cpp:406] conv4_1 <- conv4
I1210 09:11:40.290616 16412 net.cpp:380] conv4_1 -> conv4_1
I1210 09:11:40.292605 16412 net.cpp:122] Setting up conv4_1
I1210 09:11:40.292605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.292605 16412 net.cpp:137] Memory required for data: 445441200
I1210 09:11:40.292605 16412 layer_factory.cpp:58] Creating layer bn4_1
I1210 09:11:40.292605 16412 net.cpp:84] Creating Layer bn4_1
I1210 09:11:40.292605 16412 net.cpp:406] bn4_1 <- conv4_1
I1210 09:11:40.292605 16412 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 09:11:40.292605 16412 net.cpp:122] Setting up bn4_1
I1210 09:11:40.292605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.292605 16412 net.cpp:137] Memory required for data: 451073200
I1210 09:11:40.292605 16412 layer_factory.cpp:58] Creating layer scale4_1
I1210 09:11:40.292605 16412 net.cpp:84] Creating Layer scale4_1
I1210 09:11:40.292605 16412 net.cpp:406] scale4_1 <- conv4_1
I1210 09:11:40.292605 16412 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 09:11:40.292605 16412 layer_factory.cpp:58] Creating layer scale4_1
I1210 09:11:40.292605 16412 net.cpp:122] Setting up scale4_1
I1210 09:11:40.292605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.292605 16412 net.cpp:137] Memory required for data: 456705200
I1210 09:11:40.292605 16412 layer_factory.cpp:58] Creating layer relu4_1
I1210 09:11:40.292605 16412 net.cpp:84] Creating Layer relu4_1
I1210 09:11:40.292605 16412 net.cpp:406] relu4_1 <- conv4_1
I1210 09:11:40.292605 16412 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 09:11:40.292605 16412 net.cpp:122] Setting up relu4_1
I1210 09:11:40.292605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.292605 16412 net.cpp:137] Memory required for data: 462337200
I1210 09:11:40.292605 16412 layer_factory.cpp:58] Creating layer conv4_2
I1210 09:11:40.292605 16412 net.cpp:84] Creating Layer conv4_2
I1210 09:11:40.292605 16412 net.cpp:406] conv4_2 <- conv4_1
I1210 09:11:40.292605 16412 net.cpp:380] conv4_2 -> conv4_2
I1210 09:11:40.294606 16412 net.cpp:122] Setting up conv4_2
I1210 09:11:40.294606 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.294606 16412 net.cpp:137] Memory required for data: 468686000
I1210 09:11:40.294606 16412 layer_factory.cpp:58] Creating layer bn4_2
I1210 09:11:40.294606 16412 net.cpp:84] Creating Layer bn4_2
I1210 09:11:40.294606 16412 net.cpp:406] bn4_2 <- conv4_2
I1210 09:11:40.294606 16412 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 09:11:40.294606 16412 net.cpp:122] Setting up bn4_2
I1210 09:11:40.294606 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.294606 16412 net.cpp:137] Memory required for data: 475034800
I1210 09:11:40.294606 16412 layer_factory.cpp:58] Creating layer scale4_2
I1210 09:11:40.294606 16412 net.cpp:84] Creating Layer scale4_2
I1210 09:11:40.294606 16412 net.cpp:406] scale4_2 <- conv4_2
I1210 09:11:40.294606 16412 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 09:11:40.294606 16412 layer_factory.cpp:58] Creating layer scale4_2
I1210 09:11:40.294606 16412 net.cpp:122] Setting up scale4_2
I1210 09:11:40.294606 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.294606 16412 net.cpp:137] Memory required for data: 481383600
I1210 09:11:40.294606 16412 layer_factory.cpp:58] Creating layer relu4_2
I1210 09:11:40.294606 16412 net.cpp:84] Creating Layer relu4_2
I1210 09:11:40.294606 16412 net.cpp:406] relu4_2 <- conv4_2
I1210 09:11:40.294606 16412 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 09:11:40.294606 16412 net.cpp:122] Setting up relu4_2
I1210 09:11:40.294606 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.294606 16412 net.cpp:137] Memory required for data: 487732400
I1210 09:11:40.294606 16412 layer_factory.cpp:58] Creating layer pool4_2
I1210 09:11:40.294606 16412 net.cpp:84] Creating Layer pool4_2
I1210 09:11:40.294606 16412 net.cpp:406] pool4_2 <- conv4_2
I1210 09:11:40.294606 16412 net.cpp:380] pool4_2 -> pool4_2
I1210 09:11:40.294606 16412 net.cpp:122] Setting up pool4_2
I1210 09:11:40.294606 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.294606 16412 net.cpp:137] Memory required for data: 489319600
I1210 09:11:40.294606 16412 layer_factory.cpp:58] Creating layer conv4_0
I1210 09:11:40.294606 16412 net.cpp:84] Creating Layer conv4_0
I1210 09:11:40.294606 16412 net.cpp:406] conv4_0 <- pool4_2
I1210 09:11:40.294606 16412 net.cpp:380] conv4_0 -> conv4_0
I1210 09:11:40.296607 16412 net.cpp:122] Setting up conv4_0
I1210 09:11:40.296607 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.296607 16412 net.cpp:137] Memory required for data: 490906800
I1210 09:11:40.296607 16412 layer_factory.cpp:58] Creating layer bn4_0
I1210 09:11:40.296607 16412 net.cpp:84] Creating Layer bn4_0
I1210 09:11:40.296607 16412 net.cpp:406] bn4_0 <- conv4_0
I1210 09:11:40.296607 16412 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 09:11:40.296607 16412 net.cpp:122] Setting up bn4_0
I1210 09:11:40.296607 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.296607 16412 net.cpp:137] Memory required for data: 492494000
I1210 09:11:40.296607 16412 layer_factory.cpp:58] Creating layer scale4_0
I1210 09:11:40.296607 16412 net.cpp:84] Creating Layer scale4_0
I1210 09:11:40.296607 16412 net.cpp:406] scale4_0 <- conv4_0
I1210 09:11:40.296607 16412 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 09:11:40.296607 16412 layer_factory.cpp:58] Creating layer scale4_0
I1210 09:11:40.296607 16412 net.cpp:122] Setting up scale4_0
I1210 09:11:40.296607 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.296607 16412 net.cpp:137] Memory required for data: 494081200
I1210 09:11:40.296607 16412 layer_factory.cpp:58] Creating layer relu4_0
I1210 09:11:40.296607 16412 net.cpp:84] Creating Layer relu4_0
I1210 09:11:40.296607 16412 net.cpp:406] relu4_0 <- conv4_0
I1210 09:11:40.296607 16412 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 09:11:40.297605 16412 net.cpp:122] Setting up relu4_0
I1210 09:11:40.297605 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.297605 16412 net.cpp:137] Memory required for data: 495668400
I1210 09:11:40.297605 16412 layer_factory.cpp:58] Creating layer conv11
I1210 09:11:40.297605 16412 net.cpp:84] Creating Layer conv11
I1210 09:11:40.297605 16412 net.cpp:406] conv11 <- conv4_0
I1210 09:11:40.297605 16412 net.cpp:380] conv11 -> conv11
I1210 09:11:40.298604 16412 net.cpp:122] Setting up conv11
I1210 09:11:40.298604 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.298604 16412 net.cpp:137] Memory required for data: 497486000
I1210 09:11:40.298604 16412 layer_factory.cpp:58] Creating layer bn_conv11
I1210 09:11:40.298604 16412 net.cpp:84] Creating Layer bn_conv11
I1210 09:11:40.298604 16412 net.cpp:406] bn_conv11 <- conv11
I1210 09:11:40.298604 16412 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 09:11:40.298604 16412 net.cpp:122] Setting up bn_conv11
I1210 09:11:40.298604 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.298604 16412 net.cpp:137] Memory required for data: 499303600
I1210 09:11:40.298604 16412 layer_factory.cpp:58] Creating layer scale_conv11
I1210 09:11:40.298604 16412 net.cpp:84] Creating Layer scale_conv11
I1210 09:11:40.298604 16412 net.cpp:406] scale_conv11 <- conv11
I1210 09:11:40.298604 16412 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 09:11:40.298604 16412 layer_factory.cpp:58] Creating layer scale_conv11
I1210 09:11:40.298604 16412 net.cpp:122] Setting up scale_conv11
I1210 09:11:40.298604 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.298604 16412 net.cpp:137] Memory required for data: 501121200
I1210 09:11:40.298604 16412 layer_factory.cpp:58] Creating layer relu_conv11
I1210 09:11:40.298604 16412 net.cpp:84] Creating Layer relu_conv11
I1210 09:11:40.298604 16412 net.cpp:406] relu_conv11 <- conv11
I1210 09:11:40.298604 16412 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 09:11:40.299605 16412 net.cpp:122] Setting up relu_conv11
I1210 09:11:40.299605 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.299605 16412 net.cpp:137] Memory required for data: 502938800
I1210 09:11:40.299605 16412 layer_factory.cpp:58] Creating layer conv12
I1210 09:11:40.299605 16412 net.cpp:84] Creating Layer conv12
I1210 09:11:40.299605 16412 net.cpp:406] conv12 <- conv11
I1210 09:11:40.299605 16412 net.cpp:380] conv12 -> conv12
I1210 09:11:40.301605 16412 net.cpp:122] Setting up conv12
I1210 09:11:40.301605 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.301605 16412 net.cpp:137] Memory required for data: 505498800
I1210 09:11:40.301605 16412 layer_factory.cpp:58] Creating layer bn_conv12
I1210 09:11:40.301605 16412 net.cpp:84] Creating Layer bn_conv12
I1210 09:11:40.301605 16412 net.cpp:406] bn_conv12 <- conv12
I1210 09:11:40.301605 16412 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 09:11:40.301605 16412 net.cpp:122] Setting up bn_conv12
I1210 09:11:40.301605 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.301605 16412 net.cpp:137] Memory required for data: 508058800
I1210 09:11:40.301605 16412 layer_factory.cpp:58] Creating layer scale_conv12
I1210 09:11:40.301605 16412 net.cpp:84] Creating Layer scale_conv12
I1210 09:11:40.301605 16412 net.cpp:406] scale_conv12 <- conv12
I1210 09:11:40.301605 16412 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 09:11:40.301605 16412 layer_factory.cpp:58] Creating layer scale_conv12
I1210 09:11:40.301605 16412 net.cpp:122] Setting up scale_conv12
I1210 09:11:40.301605 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.301605 16412 net.cpp:137] Memory required for data: 510618800
I1210 09:11:40.301605 16412 layer_factory.cpp:58] Creating layer relu_conv12
I1210 09:11:40.301605 16412 net.cpp:84] Creating Layer relu_conv12
I1210 09:11:40.301605 16412 net.cpp:406] relu_conv12 <- conv12
I1210 09:11:40.301605 16412 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 09:11:40.302608 16412 net.cpp:122] Setting up relu_conv12
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.302608 16412 net.cpp:137] Memory required for data: 513178800
I1210 09:11:40.302608 16412 layer_factory.cpp:58] Creating layer poolcp6
I1210 09:11:40.302608 16412 net.cpp:84] Creating Layer poolcp6
I1210 09:11:40.302608 16412 net.cpp:406] poolcp6 <- conv12
I1210 09:11:40.302608 16412 net.cpp:380] poolcp6 -> poolcp6
I1210 09:11:40.302608 16412 net.cpp:122] Setting up poolcp6
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1210 09:11:40.302608 16412 net.cpp:137] Memory required for data: 513218800
I1210 09:11:40.302608 16412 layer_factory.cpp:58] Creating layer ip1
I1210 09:11:40.302608 16412 net.cpp:84] Creating Layer ip1
I1210 09:11:40.302608 16412 net.cpp:406] ip1 <- poolcp6
I1210 09:11:40.302608 16412 net.cpp:380] ip1 -> ip1
I1210 09:11:40.302608 16412 net.cpp:122] Setting up ip1
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: 100 100 (10000)
I1210 09:11:40.302608 16412 net.cpp:137] Memory required for data: 513258800
I1210 09:11:40.302608 16412 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 09:11:40.302608 16412 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 09:11:40.302608 16412 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 09:11:40.302608 16412 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 09:11:40.302608 16412 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 09:11:40.302608 16412 net.cpp:122] Setting up ip1_ip1_0_split
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: 100 100 (10000)
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: 100 100 (10000)
I1210 09:11:40.302608 16412 net.cpp:137] Memory required for data: 513338800
I1210 09:11:40.302608 16412 layer_factory.cpp:58] Creating layer accuracy_training
I1210 09:11:40.302608 16412 net.cpp:84] Creating Layer accuracy_training
I1210 09:11:40.302608 16412 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1210 09:11:40.302608 16412 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1210 09:11:40.302608 16412 net.cpp:380] accuracy_training -> accuracy_training
I1210 09:11:40.302608 16412 net.cpp:122] Setting up accuracy_training
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: (1)
I1210 09:11:40.302608 16412 net.cpp:137] Memory required for data: 513338804
I1210 09:11:40.302608 16412 layer_factory.cpp:58] Creating layer loss
I1210 09:11:40.302608 16412 net.cpp:84] Creating Layer loss
I1210 09:11:40.302608 16412 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 09:11:40.302608 16412 net.cpp:406] loss <- label_cifar_1_split_1
I1210 09:11:40.302608 16412 net.cpp:380] loss -> loss
I1210 09:11:40.302608 16412 layer_factory.cpp:58] Creating layer loss
I1210 09:11:40.302608 16412 net.cpp:122] Setting up loss
I1210 09:11:40.302608 16412 net.cpp:129] Top shape: (1)
I1210 09:11:40.302608 16412 net.cpp:132]     with loss weight 1
I1210 09:11:40.302608 16412 net.cpp:137] Memory required for data: 513338808
I1210 09:11:40.302608 16412 net.cpp:198] loss needs backward computation.
I1210 09:11:40.302608 16412 net.cpp:200] accuracy_training does not need backward computation.
I1210 09:11:40.302608 16412 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 09:11:40.302608 16412 net.cpp:198] ip1 needs backward computation.
I1210 09:11:40.302608 16412 net.cpp:198] poolcp6 needs backward computation.
I1210 09:11:40.302608 16412 net.cpp:198] relu_conv12 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale_conv12 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn_conv12 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv12 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu_conv11 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale_conv11 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn_conv11 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv11 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu4_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale4_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn4_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv4_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] pool4_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu4_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale4_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn4_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv4_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu4_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale4_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn4_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv4_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu4 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale4 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn4 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv4 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu3_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale3_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn3_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv3_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu3 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale3 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn3 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv3 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] pool2_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu2_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale2_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn2_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv2_2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu2_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale2_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn2_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv2_1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv2 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu1_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale1_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn1_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv1_0 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] relu1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] scale1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] bn1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:198] conv1 needs backward computation.
I1210 09:11:40.303606 16412 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 09:11:40.303606 16412 net.cpp:200] cifar does not need backward computation.
I1210 09:11:40.303606 16412 net.cpp:242] This network produces output accuracy_training
I1210 09:11:40.303606 16412 net.cpp:242] This network produces output loss
I1210 09:11:40.303606 16412 net.cpp:255] Network initialization done.
I1210 09:11:40.304605 16412 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 09:11:40.304605 16412 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1210 09:11:40.304605 16412 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1210 09:11:40.304605 16412 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1210 09:11:40.304605 16412 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_maxdrp_300k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 36
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 44
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 44
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 44
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 55
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 62
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 62
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 71
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1210 09:11:40.304605 16412 layer_factory.cpp:58] Creating layer cifar
I1210 09:11:40.307613 16412 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1210 09:11:40.307613 16412 net.cpp:84] Creating Layer cifar
I1210 09:11:40.307613 16412 net.cpp:380] cifar -> data
I1210 09:11:40.307613 16412 net.cpp:380] cifar -> label
I1210 09:11:40.307613 16412 data_layer.cpp:45] output data size: 100,3,32,32
I1210 09:11:40.314608 16412 net.cpp:122] Setting up cifar
I1210 09:11:40.314608 16412 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1210 09:11:40.314608 16412 net.cpp:129] Top shape: 100 (100)
I1210 09:11:40.314608 16412 net.cpp:137] Memory required for data: 1229200
I1210 09:11:40.314608 16412 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1210 09:11:40.314608 16412 net.cpp:84] Creating Layer label_cifar_1_split
I1210 09:11:40.314608 16412 net.cpp:406] label_cifar_1_split <- label
I1210 09:11:40.314608 16412 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1210 09:11:40.314608 16412 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1210 09:11:40.314608 16412 net.cpp:122] Setting up label_cifar_1_split
I1210 09:11:40.314608 16412 net.cpp:129] Top shape: 100 (100)
I1210 09:11:40.314608 16412 net.cpp:129] Top shape: 100 (100)
I1210 09:11:40.314608 16412 net.cpp:137] Memory required for data: 1230000
I1210 09:11:40.314608 16412 layer_factory.cpp:58] Creating layer conv1
I1210 09:11:40.314608 16412 net.cpp:84] Creating Layer conv1
I1210 09:11:40.314608 16412 net.cpp:406] conv1 <- data
I1210 09:11:40.314608 16412 net.cpp:380] conv1 -> conv1
I1210 09:11:40.316606 16412 net.cpp:122] Setting up conv1
I1210 09:11:40.316606 15752 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1210 09:11:40.316606 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.316606 16412 net.cpp:137] Memory required for data: 15975600
I1210 09:11:40.316606 16412 layer_factory.cpp:58] Creating layer bn1
I1210 09:11:40.316606 16412 net.cpp:84] Creating Layer bn1
I1210 09:11:40.316606 16412 net.cpp:406] bn1 <- conv1
I1210 09:11:40.316606 16412 net.cpp:367] bn1 -> conv1 (in-place)
I1210 09:11:40.316606 16412 net.cpp:122] Setting up bn1
I1210 09:11:40.316606 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.316606 16412 net.cpp:137] Memory required for data: 30721200
I1210 09:11:40.316606 16412 layer_factory.cpp:58] Creating layer scale1
I1210 09:11:40.316606 16412 net.cpp:84] Creating Layer scale1
I1210 09:11:40.316606 16412 net.cpp:406] scale1 <- conv1
I1210 09:11:40.316606 16412 net.cpp:367] scale1 -> conv1 (in-place)
I1210 09:11:40.317605 16412 layer_factory.cpp:58] Creating layer scale1
I1210 09:11:40.317605 16412 net.cpp:122] Setting up scale1
I1210 09:11:40.317605 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.317605 16412 net.cpp:137] Memory required for data: 45466800
I1210 09:11:40.317605 16412 layer_factory.cpp:58] Creating layer relu1
I1210 09:11:40.317605 16412 net.cpp:84] Creating Layer relu1
I1210 09:11:40.317605 16412 net.cpp:406] relu1 <- conv1
I1210 09:11:40.317605 16412 net.cpp:367] relu1 -> conv1 (in-place)
I1210 09:11:40.317605 16412 net.cpp:122] Setting up relu1
I1210 09:11:40.317605 16412 net.cpp:129] Top shape: 100 36 32 32 (3686400)
I1210 09:11:40.317605 16412 net.cpp:137] Memory required for data: 60212400
I1210 09:11:40.317605 16412 layer_factory.cpp:58] Creating layer conv1_0
I1210 09:11:40.317605 16412 net.cpp:84] Creating Layer conv1_0
I1210 09:11:40.317605 16412 net.cpp:406] conv1_0 <- conv1
I1210 09:11:40.317605 16412 net.cpp:380] conv1_0 -> conv1_0
I1210 09:11:40.318604 16412 net.cpp:122] Setting up conv1_0
I1210 09:11:40.318604 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.318604 16412 net.cpp:137] Memory required for data: 78234800
I1210 09:11:40.318604 16412 layer_factory.cpp:58] Creating layer bn1_0
I1210 09:11:40.318604 16412 net.cpp:84] Creating Layer bn1_0
I1210 09:11:40.318604 16412 net.cpp:406] bn1_0 <- conv1_0
I1210 09:11:40.318604 16412 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1210 09:11:40.319605 16412 net.cpp:122] Setting up bn1_0
I1210 09:11:40.319605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.319605 16412 net.cpp:137] Memory required for data: 96257200
I1210 09:11:40.319605 16412 layer_factory.cpp:58] Creating layer scale1_0
I1210 09:11:40.319605 16412 net.cpp:84] Creating Layer scale1_0
I1210 09:11:40.319605 16412 net.cpp:406] scale1_0 <- conv1_0
I1210 09:11:40.319605 16412 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1210 09:11:40.319605 16412 layer_factory.cpp:58] Creating layer scale1_0
I1210 09:11:40.319605 16412 net.cpp:122] Setting up scale1_0
I1210 09:11:40.319605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.319605 16412 net.cpp:137] Memory required for data: 114279600
I1210 09:11:40.319605 16412 layer_factory.cpp:58] Creating layer relu1_0
I1210 09:11:40.319605 16412 net.cpp:84] Creating Layer relu1_0
I1210 09:11:40.319605 16412 net.cpp:406] relu1_0 <- conv1_0
I1210 09:11:40.319605 16412 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1210 09:11:40.320608 16412 net.cpp:122] Setting up relu1_0
I1210 09:11:40.320608 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.320608 16412 net.cpp:137] Memory required for data: 132302000
I1210 09:11:40.320608 16412 layer_factory.cpp:58] Creating layer conv2
I1210 09:11:40.320608 16412 net.cpp:84] Creating Layer conv2
I1210 09:11:40.320608 16412 net.cpp:406] conv2 <- conv1_0
I1210 09:11:40.320608 16412 net.cpp:380] conv2 -> conv2
I1210 09:11:40.321605 16412 net.cpp:122] Setting up conv2
I1210 09:11:40.321605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.321605 16412 net.cpp:137] Memory required for data: 150324400
I1210 09:11:40.321605 16412 layer_factory.cpp:58] Creating layer bn2
I1210 09:11:40.321605 16412 net.cpp:84] Creating Layer bn2
I1210 09:11:40.321605 16412 net.cpp:406] bn2 <- conv2
I1210 09:11:40.321605 16412 net.cpp:367] bn2 -> conv2 (in-place)
I1210 09:11:40.321605 16412 net.cpp:122] Setting up bn2
I1210 09:11:40.321605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.321605 16412 net.cpp:137] Memory required for data: 168346800
I1210 09:11:40.321605 16412 layer_factory.cpp:58] Creating layer scale2
I1210 09:11:40.321605 16412 net.cpp:84] Creating Layer scale2
I1210 09:11:40.321605 16412 net.cpp:406] scale2 <- conv2
I1210 09:11:40.321605 16412 net.cpp:367] scale2 -> conv2 (in-place)
I1210 09:11:40.321605 16412 layer_factory.cpp:58] Creating layer scale2
I1210 09:11:40.322605 16412 net.cpp:122] Setting up scale2
I1210 09:11:40.322605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.322605 16412 net.cpp:137] Memory required for data: 186369200
I1210 09:11:40.322605 16412 layer_factory.cpp:58] Creating layer relu2
I1210 09:11:40.322605 16412 net.cpp:84] Creating Layer relu2
I1210 09:11:40.322605 16412 net.cpp:406] relu2 <- conv2
I1210 09:11:40.322605 16412 net.cpp:367] relu2 -> conv2 (in-place)
I1210 09:11:40.322605 16412 net.cpp:122] Setting up relu2
I1210 09:11:40.322605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.322605 16412 net.cpp:137] Memory required for data: 204391600
I1210 09:11:40.322605 16412 layer_factory.cpp:58] Creating layer conv2_1
I1210 09:11:40.322605 16412 net.cpp:84] Creating Layer conv2_1
I1210 09:11:40.322605 16412 net.cpp:406] conv2_1 <- conv2
I1210 09:11:40.322605 16412 net.cpp:380] conv2_1 -> conv2_1
I1210 09:11:40.324606 16412 net.cpp:122] Setting up conv2_1
I1210 09:11:40.324606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.324606 16412 net.cpp:137] Memory required for data: 222414000
I1210 09:11:40.324606 16412 layer_factory.cpp:58] Creating layer bn2_1
I1210 09:11:40.324606 16412 net.cpp:84] Creating Layer bn2_1
I1210 09:11:40.324606 16412 net.cpp:406] bn2_1 <- conv2_1
I1210 09:11:40.324606 16412 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1210 09:11:40.324606 16412 net.cpp:122] Setting up bn2_1
I1210 09:11:40.324606 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.325605 16412 net.cpp:137] Memory required for data: 240436400
I1210 09:11:40.325605 16412 layer_factory.cpp:58] Creating layer scale2_1
I1210 09:11:40.325605 16412 net.cpp:84] Creating Layer scale2_1
I1210 09:11:40.325605 16412 net.cpp:406] scale2_1 <- conv2_1
I1210 09:11:40.325605 16412 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1210 09:11:40.325605 16412 layer_factory.cpp:58] Creating layer scale2_1
I1210 09:11:40.325605 16412 net.cpp:122] Setting up scale2_1
I1210 09:11:40.325605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.325605 16412 net.cpp:137] Memory required for data: 258458800
I1210 09:11:40.325605 16412 layer_factory.cpp:58] Creating layer relu2_1
I1210 09:11:40.325605 16412 net.cpp:84] Creating Layer relu2_1
I1210 09:11:40.325605 16412 net.cpp:406] relu2_1 <- conv2_1
I1210 09:11:40.325605 16412 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1210 09:11:40.325605 16412 net.cpp:122] Setting up relu2_1
I1210 09:11:40.325605 16412 net.cpp:129] Top shape: 100 44 32 32 (4505600)
I1210 09:11:40.325605 16412 net.cpp:137] Memory required for data: 276481200
I1210 09:11:40.325605 16412 layer_factory.cpp:58] Creating layer conv2_2
I1210 09:11:40.325605 16412 net.cpp:84] Creating Layer conv2_2
I1210 09:11:40.325605 16412 net.cpp:406] conv2_2 <- conv2_1
I1210 09:11:40.325605 16412 net.cpp:380] conv2_2 -> conv2_2
I1210 09:11:40.326606 16412 net.cpp:122] Setting up conv2_2
I1210 09:11:40.326606 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.326606 16412 net.cpp:137] Memory required for data: 299009200
I1210 09:11:40.327605 16412 layer_factory.cpp:58] Creating layer bn2_2
I1210 09:11:40.327605 16412 net.cpp:84] Creating Layer bn2_2
I1210 09:11:40.327605 16412 net.cpp:406] bn2_2 <- conv2_2
I1210 09:11:40.327605 16412 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1210 09:11:40.327605 16412 net.cpp:122] Setting up bn2_2
I1210 09:11:40.327605 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.327605 16412 net.cpp:137] Memory required for data: 321537200
I1210 09:11:40.327605 16412 layer_factory.cpp:58] Creating layer scale2_2
I1210 09:11:40.327605 16412 net.cpp:84] Creating Layer scale2_2
I1210 09:11:40.327605 16412 net.cpp:406] scale2_2 <- conv2_2
I1210 09:11:40.327605 16412 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1210 09:11:40.327605 16412 layer_factory.cpp:58] Creating layer scale2_2
I1210 09:11:40.327605 16412 net.cpp:122] Setting up scale2_2
I1210 09:11:40.327605 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.327605 16412 net.cpp:137] Memory required for data: 344065200
I1210 09:11:40.327605 16412 layer_factory.cpp:58] Creating layer relu2_2
I1210 09:11:40.327605 16412 net.cpp:84] Creating Layer relu2_2
I1210 09:11:40.327605 16412 net.cpp:406] relu2_2 <- conv2_2
I1210 09:11:40.327605 16412 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1210 09:11:40.327605 16412 net.cpp:122] Setting up relu2_2
I1210 09:11:40.327605 16412 net.cpp:129] Top shape: 100 55 32 32 (5632000)
I1210 09:11:40.327605 16412 net.cpp:137] Memory required for data: 366593200
I1210 09:11:40.327605 16412 layer_factory.cpp:58] Creating layer pool2_1
I1210 09:11:40.327605 16412 net.cpp:84] Creating Layer pool2_1
I1210 09:11:40.327605 16412 net.cpp:406] pool2_1 <- conv2_2
I1210 09:11:40.327605 16412 net.cpp:380] pool2_1 -> pool2_1
I1210 09:11:40.327605 16412 net.cpp:122] Setting up pool2_1
I1210 09:11:40.327605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.327605 16412 net.cpp:137] Memory required for data: 372225200
I1210 09:11:40.327605 16412 layer_factory.cpp:58] Creating layer conv3
I1210 09:11:40.327605 16412 net.cpp:84] Creating Layer conv3
I1210 09:11:40.327605 16412 net.cpp:406] conv3 <- pool2_1
I1210 09:11:40.327605 16412 net.cpp:380] conv3 -> conv3
I1210 09:11:40.329605 16412 net.cpp:122] Setting up conv3
I1210 09:11:40.329605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.329605 16412 net.cpp:137] Memory required for data: 377857200
I1210 09:11:40.329605 16412 layer_factory.cpp:58] Creating layer bn3
I1210 09:11:40.329605 16412 net.cpp:84] Creating Layer bn3
I1210 09:11:40.329605 16412 net.cpp:406] bn3 <- conv3
I1210 09:11:40.329605 16412 net.cpp:367] bn3 -> conv3 (in-place)
I1210 09:11:40.329605 16412 net.cpp:122] Setting up bn3
I1210 09:11:40.329605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.329605 16412 net.cpp:137] Memory required for data: 383489200
I1210 09:11:40.329605 16412 layer_factory.cpp:58] Creating layer scale3
I1210 09:11:40.329605 16412 net.cpp:84] Creating Layer scale3
I1210 09:11:40.329605 16412 net.cpp:406] scale3 <- conv3
I1210 09:11:40.329605 16412 net.cpp:367] scale3 -> conv3 (in-place)
I1210 09:11:40.330605 16412 layer_factory.cpp:58] Creating layer scale3
I1210 09:11:40.330605 16412 net.cpp:122] Setting up scale3
I1210 09:11:40.330605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.330605 16412 net.cpp:137] Memory required for data: 389121200
I1210 09:11:40.330605 16412 layer_factory.cpp:58] Creating layer relu3
I1210 09:11:40.330605 16412 net.cpp:84] Creating Layer relu3
I1210 09:11:40.330605 16412 net.cpp:406] relu3 <- conv3
I1210 09:11:40.330605 16412 net.cpp:367] relu3 -> conv3 (in-place)
I1210 09:11:40.330605 16412 net.cpp:122] Setting up relu3
I1210 09:11:40.330605 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.330605 16412 net.cpp:137] Memory required for data: 394753200
I1210 09:11:40.330605 16412 layer_factory.cpp:58] Creating layer conv3_1
I1210 09:11:40.330605 16412 net.cpp:84] Creating Layer conv3_1
I1210 09:11:40.330605 16412 net.cpp:406] conv3_1 <- conv3
I1210 09:11:40.330605 16412 net.cpp:380] conv3_1 -> conv3_1
I1210 09:11:40.332110 16412 net.cpp:122] Setting up conv3_1
I1210 09:11:40.332110 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.332110 16412 net.cpp:137] Memory required for data: 400385200
I1210 09:11:40.332629 16412 layer_factory.cpp:58] Creating layer bn3_1
I1210 09:11:40.332629 16412 net.cpp:84] Creating Layer bn3_1
I1210 09:11:40.332629 16412 net.cpp:406] bn3_1 <- conv3_1
I1210 09:11:40.332629 16412 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1210 09:11:40.332629 16412 net.cpp:122] Setting up bn3_1
I1210 09:11:40.332629 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.332629 16412 net.cpp:137] Memory required for data: 406017200
I1210 09:11:40.332629 16412 layer_factory.cpp:58] Creating layer scale3_1
I1210 09:11:40.332629 16412 net.cpp:84] Creating Layer scale3_1
I1210 09:11:40.332629 16412 net.cpp:406] scale3_1 <- conv3_1
I1210 09:11:40.332629 16412 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1210 09:11:40.332629 16412 layer_factory.cpp:58] Creating layer scale3_1
I1210 09:11:40.332629 16412 net.cpp:122] Setting up scale3_1
I1210 09:11:40.332629 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.332629 16412 net.cpp:137] Memory required for data: 411649200
I1210 09:11:40.332629 16412 layer_factory.cpp:58] Creating layer relu3_1
I1210 09:11:40.332629 16412 net.cpp:84] Creating Layer relu3_1
I1210 09:11:40.332629 16412 net.cpp:406] relu3_1 <- conv3_1
I1210 09:11:40.332629 16412 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1210 09:11:40.333130 16412 net.cpp:122] Setting up relu3_1
I1210 09:11:40.333130 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.333130 16412 net.cpp:137] Memory required for data: 417281200
I1210 09:11:40.333130 16412 layer_factory.cpp:58] Creating layer conv4
I1210 09:11:40.333130 16412 net.cpp:84] Creating Layer conv4
I1210 09:11:40.333130 16412 net.cpp:406] conv4 <- conv3_1
I1210 09:11:40.333130 16412 net.cpp:380] conv4 -> conv4
I1210 09:11:40.334611 16412 net.cpp:122] Setting up conv4
I1210 09:11:40.334611 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.334611 16412 net.cpp:137] Memory required for data: 422913200
I1210 09:11:40.334611 16412 layer_factory.cpp:58] Creating layer bn4
I1210 09:11:40.334611 16412 net.cpp:84] Creating Layer bn4
I1210 09:11:40.334611 16412 net.cpp:406] bn4 <- conv4
I1210 09:11:40.334611 16412 net.cpp:367] bn4 -> conv4 (in-place)
I1210 09:11:40.334611 16412 net.cpp:122] Setting up bn4
I1210 09:11:40.334611 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.334611 16412 net.cpp:137] Memory required for data: 428545200
I1210 09:11:40.334611 16412 layer_factory.cpp:58] Creating layer scale4
I1210 09:11:40.334611 16412 net.cpp:84] Creating Layer scale4
I1210 09:11:40.334611 16412 net.cpp:406] scale4 <- conv4
I1210 09:11:40.334611 16412 net.cpp:367] scale4 -> conv4 (in-place)
I1210 09:11:40.334611 16412 layer_factory.cpp:58] Creating layer scale4
I1210 09:11:40.335125 16412 net.cpp:122] Setting up scale4
I1210 09:11:40.335125 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.335125 16412 net.cpp:137] Memory required for data: 434177200
I1210 09:11:40.335125 16412 layer_factory.cpp:58] Creating layer relu4
I1210 09:11:40.335125 16412 net.cpp:84] Creating Layer relu4
I1210 09:11:40.335125 16412 net.cpp:406] relu4 <- conv4
I1210 09:11:40.335125 16412 net.cpp:367] relu4 -> conv4 (in-place)
I1210 09:11:40.335610 16412 net.cpp:122] Setting up relu4
I1210 09:11:40.335610 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.335610 16412 net.cpp:137] Memory required for data: 439809200
I1210 09:11:40.335610 16412 layer_factory.cpp:58] Creating layer conv4_1
I1210 09:11:40.335610 16412 net.cpp:84] Creating Layer conv4_1
I1210 09:11:40.335610 16412 net.cpp:406] conv4_1 <- conv4
I1210 09:11:40.335610 16412 net.cpp:380] conv4_1 -> conv4_1
I1210 09:11:40.336611 16412 net.cpp:122] Setting up conv4_1
I1210 09:11:40.336611 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.336611 16412 net.cpp:137] Memory required for data: 445441200
I1210 09:11:40.336611 16412 layer_factory.cpp:58] Creating layer bn4_1
I1210 09:11:40.336611 16412 net.cpp:84] Creating Layer bn4_1
I1210 09:11:40.336611 16412 net.cpp:406] bn4_1 <- conv4_1
I1210 09:11:40.336611 16412 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1210 09:11:40.337126 16412 net.cpp:122] Setting up bn4_1
I1210 09:11:40.337126 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.337126 16412 net.cpp:137] Memory required for data: 451073200
I1210 09:11:40.337126 16412 layer_factory.cpp:58] Creating layer scale4_1
I1210 09:11:40.337126 16412 net.cpp:84] Creating Layer scale4_1
I1210 09:11:40.337126 16412 net.cpp:406] scale4_1 <- conv4_1
I1210 09:11:40.337126 16412 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1210 09:11:40.337126 16412 layer_factory.cpp:58] Creating layer scale4_1
I1210 09:11:40.337126 16412 net.cpp:122] Setting up scale4_1
I1210 09:11:40.337126 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.337126 16412 net.cpp:137] Memory required for data: 456705200
I1210 09:11:40.337126 16412 layer_factory.cpp:58] Creating layer relu4_1
I1210 09:11:40.337126 16412 net.cpp:84] Creating Layer relu4_1
I1210 09:11:40.337126 16412 net.cpp:406] relu4_1 <- conv4_1
I1210 09:11:40.337126 16412 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1210 09:11:40.337625 16412 net.cpp:122] Setting up relu4_1
I1210 09:11:40.337625 16412 net.cpp:129] Top shape: 100 55 16 16 (1408000)
I1210 09:11:40.337625 16412 net.cpp:137] Memory required for data: 462337200
I1210 09:11:40.337625 16412 layer_factory.cpp:58] Creating layer conv4_2
I1210 09:11:40.337625 16412 net.cpp:84] Creating Layer conv4_2
I1210 09:11:40.337625 16412 net.cpp:406] conv4_2 <- conv4_1
I1210 09:11:40.337625 16412 net.cpp:380] conv4_2 -> conv4_2
I1210 09:11:40.339612 16412 net.cpp:122] Setting up conv4_2
I1210 09:11:40.339612 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.339612 16412 net.cpp:137] Memory required for data: 468686000
I1210 09:11:40.339612 16412 layer_factory.cpp:58] Creating layer bn4_2
I1210 09:11:40.339612 16412 net.cpp:84] Creating Layer bn4_2
I1210 09:11:40.339612 16412 net.cpp:406] bn4_2 <- conv4_2
I1210 09:11:40.339612 16412 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1210 09:11:40.340111 16412 net.cpp:122] Setting up bn4_2
I1210 09:11:40.340111 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.340111 16412 net.cpp:137] Memory required for data: 475034800
I1210 09:11:40.340111 16412 layer_factory.cpp:58] Creating layer scale4_2
I1210 09:11:40.340111 16412 net.cpp:84] Creating Layer scale4_2
I1210 09:11:40.340111 16412 net.cpp:406] scale4_2 <- conv4_2
I1210 09:11:40.340111 16412 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1210 09:11:40.340111 16412 layer_factory.cpp:58] Creating layer scale4_2
I1210 09:11:40.340111 16412 net.cpp:122] Setting up scale4_2
I1210 09:11:40.340111 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.340111 16412 net.cpp:137] Memory required for data: 481383600
I1210 09:11:40.340111 16412 layer_factory.cpp:58] Creating layer relu4_2
I1210 09:11:40.340111 16412 net.cpp:84] Creating Layer relu4_2
I1210 09:11:40.340111 16412 net.cpp:406] relu4_2 <- conv4_2
I1210 09:11:40.340111 16412 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1210 09:11:40.340111 16412 net.cpp:122] Setting up relu4_2
I1210 09:11:40.340111 16412 net.cpp:129] Top shape: 100 62 16 16 (1587200)
I1210 09:11:40.340111 16412 net.cpp:137] Memory required for data: 487732400
I1210 09:11:40.340111 16412 layer_factory.cpp:58] Creating layer pool4_2
I1210 09:11:40.340111 16412 net.cpp:84] Creating Layer pool4_2
I1210 09:11:40.340111 16412 net.cpp:406] pool4_2 <- conv4_2
I1210 09:11:40.340111 16412 net.cpp:380] pool4_2 -> pool4_2
I1210 09:11:40.340610 16412 net.cpp:122] Setting up pool4_2
I1210 09:11:40.340610 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.340610 16412 net.cpp:137] Memory required for data: 489319600
I1210 09:11:40.340610 16412 layer_factory.cpp:58] Creating layer conv4_0
I1210 09:11:40.340610 16412 net.cpp:84] Creating Layer conv4_0
I1210 09:11:40.340610 16412 net.cpp:406] conv4_0 <- pool4_2
I1210 09:11:40.340610 16412 net.cpp:380] conv4_0 -> conv4_0
I1210 09:11:40.342111 16412 net.cpp:122] Setting up conv4_0
I1210 09:11:40.342111 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.342111 16412 net.cpp:137] Memory required for data: 490906800
I1210 09:11:40.342111 16412 layer_factory.cpp:58] Creating layer bn4_0
I1210 09:11:40.342111 16412 net.cpp:84] Creating Layer bn4_0
I1210 09:11:40.342111 16412 net.cpp:406] bn4_0 <- conv4_0
I1210 09:11:40.342111 16412 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1210 09:11:40.342111 16412 net.cpp:122] Setting up bn4_0
I1210 09:11:40.342111 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.342111 16412 net.cpp:137] Memory required for data: 492494000
I1210 09:11:40.342111 16412 layer_factory.cpp:58] Creating layer scale4_0
I1210 09:11:40.342111 16412 net.cpp:84] Creating Layer scale4_0
I1210 09:11:40.342111 16412 net.cpp:406] scale4_0 <- conv4_0
I1210 09:11:40.342111 16412 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1210 09:11:40.342111 16412 layer_factory.cpp:58] Creating layer scale4_0
I1210 09:11:40.342610 16412 net.cpp:122] Setting up scale4_0
I1210 09:11:40.342610 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.342610 16412 net.cpp:137] Memory required for data: 494081200
I1210 09:11:40.342610 16412 layer_factory.cpp:58] Creating layer relu4_0
I1210 09:11:40.342610 16412 net.cpp:84] Creating Layer relu4_0
I1210 09:11:40.342610 16412 net.cpp:406] relu4_0 <- conv4_0
I1210 09:11:40.342610 16412 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1210 09:11:40.342610 16412 net.cpp:122] Setting up relu4_0
I1210 09:11:40.342610 16412 net.cpp:129] Top shape: 100 62 8 8 (396800)
I1210 09:11:40.342610 16412 net.cpp:137] Memory required for data: 495668400
I1210 09:11:40.342610 16412 layer_factory.cpp:58] Creating layer conv11
I1210 09:11:40.342610 16412 net.cpp:84] Creating Layer conv11
I1210 09:11:40.342610 16412 net.cpp:406] conv11 <- conv4_0
I1210 09:11:40.342610 16412 net.cpp:380] conv11 -> conv11
I1210 09:11:40.344110 16412 net.cpp:122] Setting up conv11
I1210 09:11:40.344110 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.344110 16412 net.cpp:137] Memory required for data: 497486000
I1210 09:11:40.344110 16412 layer_factory.cpp:58] Creating layer bn_conv11
I1210 09:11:40.344110 16412 net.cpp:84] Creating Layer bn_conv11
I1210 09:11:40.344110 16412 net.cpp:406] bn_conv11 <- conv11
I1210 09:11:40.344110 16412 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1210 09:11:40.344110 16412 net.cpp:122] Setting up bn_conv11
I1210 09:11:40.344110 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.344110 16412 net.cpp:137] Memory required for data: 499303600
I1210 09:11:40.344110 16412 layer_factory.cpp:58] Creating layer scale_conv11
I1210 09:11:40.344110 16412 net.cpp:84] Creating Layer scale_conv11
I1210 09:11:40.344110 16412 net.cpp:406] scale_conv11 <- conv11
I1210 09:11:40.344110 16412 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1210 09:11:40.344610 16412 layer_factory.cpp:58] Creating layer scale_conv11
I1210 09:11:40.344610 16412 net.cpp:122] Setting up scale_conv11
I1210 09:11:40.344610 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.344610 16412 net.cpp:137] Memory required for data: 501121200
I1210 09:11:40.344610 16412 layer_factory.cpp:58] Creating layer relu_conv11
I1210 09:11:40.344610 16412 net.cpp:84] Creating Layer relu_conv11
I1210 09:11:40.344610 16412 net.cpp:406] relu_conv11 <- conv11
I1210 09:11:40.344610 16412 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1210 09:11:40.344610 16412 net.cpp:122] Setting up relu_conv11
I1210 09:11:40.344610 16412 net.cpp:129] Top shape: 100 71 8 8 (454400)
I1210 09:11:40.344610 16412 net.cpp:137] Memory required for data: 502938800
I1210 09:11:40.344610 16412 layer_factory.cpp:58] Creating layer conv12
I1210 09:11:40.344610 16412 net.cpp:84] Creating Layer conv12
I1210 09:11:40.344610 16412 net.cpp:406] conv12 <- conv11
I1210 09:11:40.344610 16412 net.cpp:380] conv12 -> conv12
I1210 09:11:40.345610 16412 net.cpp:122] Setting up conv12
I1210 09:11:40.345610 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.345610 16412 net.cpp:137] Memory required for data: 505498800
I1210 09:11:40.345610 16412 layer_factory.cpp:58] Creating layer bn_conv12
I1210 09:11:40.345610 16412 net.cpp:84] Creating Layer bn_conv12
I1210 09:11:40.345610 16412 net.cpp:406] bn_conv12 <- conv12
I1210 09:11:40.345610 16412 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1210 09:11:40.346781 16412 net.cpp:122] Setting up bn_conv12
I1210 09:11:40.346781 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.346781 16412 net.cpp:137] Memory required for data: 508058800
I1210 09:11:40.346781 16412 layer_factory.cpp:58] Creating layer scale_conv12
I1210 09:11:40.346781 16412 net.cpp:84] Creating Layer scale_conv12
I1210 09:11:40.346781 16412 net.cpp:406] scale_conv12 <- conv12
I1210 09:11:40.346781 16412 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1210 09:11:40.346781 16412 layer_factory.cpp:58] Creating layer scale_conv12
I1210 09:11:40.346781 16412 net.cpp:122] Setting up scale_conv12
I1210 09:11:40.346781 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.346781 16412 net.cpp:137] Memory required for data: 510618800
I1210 09:11:40.346781 16412 layer_factory.cpp:58] Creating layer relu_conv12
I1210 09:11:40.346781 16412 net.cpp:84] Creating Layer relu_conv12
I1210 09:11:40.346781 16412 net.cpp:406] relu_conv12 <- conv12
I1210 09:11:40.346781 16412 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1210 09:11:40.346781 16412 net.cpp:122] Setting up relu_conv12
I1210 09:11:40.346781 16412 net.cpp:129] Top shape: 100 100 8 8 (640000)
I1210 09:11:40.346781 16412 net.cpp:137] Memory required for data: 513178800
I1210 09:11:40.346781 16412 layer_factory.cpp:58] Creating layer poolcp6
I1210 09:11:40.346781 16412 net.cpp:84] Creating Layer poolcp6
I1210 09:11:40.346781 16412 net.cpp:406] poolcp6 <- conv12
I1210 09:11:40.346781 16412 net.cpp:380] poolcp6 -> poolcp6
I1210 09:11:40.346781 16412 net.cpp:122] Setting up poolcp6
I1210 09:11:40.346781 16412 net.cpp:129] Top shape: 100 100 1 1 (10000)
I1210 09:11:40.346781 16412 net.cpp:137] Memory required for data: 513218800
I1210 09:11:40.346781 16412 layer_factory.cpp:58] Creating layer ip1
I1210 09:11:40.346781 16412 net.cpp:84] Creating Layer ip1
I1210 09:11:40.346781 16412 net.cpp:406] ip1 <- poolcp6
I1210 09:11:40.346781 16412 net.cpp:380] ip1 -> ip1
I1210 09:11:40.346781 16412 net.cpp:122] Setting up ip1
I1210 09:11:40.346781 16412 net.cpp:129] Top shape: 100 100 (10000)
I1210 09:11:40.346781 16412 net.cpp:137] Memory required for data: 513258800
I1210 09:11:40.346781 16412 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1210 09:11:40.346781 16412 net.cpp:84] Creating Layer ip1_ip1_0_split
I1210 09:11:40.347781 16412 net.cpp:406] ip1_ip1_0_split <- ip1
I1210 09:11:40.347781 16412 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1210 09:11:40.347781 16412 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1210 09:11:40.347781 16412 net.cpp:122] Setting up ip1_ip1_0_split
I1210 09:11:40.347781 16412 net.cpp:129] Top shape: 100 100 (10000)
I1210 09:11:40.347781 16412 net.cpp:129] Top shape: 100 100 (10000)
I1210 09:11:40.347781 16412 net.cpp:137] Memory required for data: 513338800
I1210 09:11:40.347781 16412 layer_factory.cpp:58] Creating layer accuracy
I1210 09:11:40.347781 16412 net.cpp:84] Creating Layer accuracy
I1210 09:11:40.347781 16412 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1210 09:11:40.347781 16412 net.cpp:406] accuracy <- label_cifar_1_split_0
I1210 09:11:40.347781 16412 net.cpp:380] accuracy -> accuracy
I1210 09:11:40.347781 16412 net.cpp:122] Setting up accuracy
I1210 09:11:40.347781 16412 net.cpp:129] Top shape: (1)
I1210 09:11:40.347781 16412 net.cpp:137] Memory required for data: 513338804
I1210 09:11:40.347781 16412 layer_factory.cpp:58] Creating layer loss
I1210 09:11:40.347781 16412 net.cpp:84] Creating Layer loss
I1210 09:11:40.347781 16412 net.cpp:406] loss <- ip1_ip1_0_split_1
I1210 09:11:40.347781 16412 net.cpp:406] loss <- label_cifar_1_split_1
I1210 09:11:40.347781 16412 net.cpp:380] loss -> loss
I1210 09:11:40.347781 16412 layer_factory.cpp:58] Creating layer loss
I1210 09:11:40.347781 16412 net.cpp:122] Setting up loss
I1210 09:11:40.347781 16412 net.cpp:129] Top shape: (1)
I1210 09:11:40.347781 16412 net.cpp:132]     with loss weight 1
I1210 09:11:40.347781 16412 net.cpp:137] Memory required for data: 513338808
I1210 09:11:40.347781 16412 net.cpp:198] loss needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:200] accuracy does not need backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] ip1 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] poolcp6 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] relu_conv12 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] scale_conv12 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] bn_conv12 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] conv12 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] relu_conv11 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] scale_conv11 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] bn_conv11 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] conv11 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] relu4_0 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] scale4_0 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] bn4_0 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] conv4_0 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] pool4_2 needs backward computation.
I1210 09:11:40.347781 16412 net.cpp:198] relu4_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale4_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn4_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv4_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu4_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale4_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn4_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv4_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu4 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale4 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn4 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv4 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu3_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale3_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn3_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv3_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu3 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale3 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn3 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv3 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] pool2_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu2_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale2_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn2_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv2_2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu2_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale2_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn2_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv2_1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv2 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu1_0 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale1_0 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn1_0 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv1_0 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] relu1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] scale1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] bn1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:198] conv1 needs backward computation.
I1210 09:11:40.348781 16412 net.cpp:200] label_cifar_1_split does not need backward computation.
I1210 09:11:40.348781 16412 net.cpp:200] cifar does not need backward computation.
I1210 09:11:40.348781 16412 net.cpp:242] This network produces output accuracy
I1210 09:11:40.348781 16412 net.cpp:242] This network produces output loss
I1210 09:11:40.348781 16412 net.cpp:255] Network initialization done.
I1210 09:11:40.348781 16412 solver.cpp:56] Solver scaffolding done.
I1210 09:11:40.352795 16412 caffe.cpp:249] Starting Optimization
I1210 09:11:40.352795 16412 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_maxdrp_300k
I1210 09:11:40.352795 16412 solver.cpp:273] Learning Rate Policy: multistep
I1210 09:11:40.354785 16412 solver.cpp:330] Iteration 0, Testing net (#0)
I1210 09:11:40.356791 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:11:41.777686 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:11:41.832190 16412 solver.cpp:397]     Test net output #0: accuracy = 0.01
I1210 09:11:41.832190 16412 solver.cpp:397]     Test net output #1: loss = 86.4632 (* 1 = 86.4632 loss)
I1210 09:11:41.939018 16412 solver.cpp:218] Iteration 0 (0 iter/s, 1.58542s/100 iters), loss = 6.57723
I1210 09:11:41.939018 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0
I1210 09:11:41.939018 16412 solver.cpp:237]     Train net output #1: loss = 6.57723 (* 1 = 6.57723 loss)
I1210 09:11:41.939018 16412 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1210 09:11:47.618808 16412 solver.cpp:218] Iteration 100 (17.6072 iter/s, 5.6795s/100 iters), loss = 4.46771
I1210 09:11:47.618808 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.04
I1210 09:11:47.618808 16412 solver.cpp:237]     Train net output #1: loss = 4.46771 (* 1 = 4.46771 loss)
I1210 09:11:47.618808 16412 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1210 09:11:53.270220 16412 solver.cpp:218] Iteration 200 (17.6954 iter/s, 5.65119s/100 iters), loss = 4.09959
I1210 09:11:53.270220 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1210 09:11:53.270220 16412 solver.cpp:237]     Train net output #1: loss = 4.09959 (* 1 = 4.09959 loss)
I1210 09:11:53.270220 16412 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1210 09:11:58.918368 16412 solver.cpp:218] Iteration 300 (17.7052 iter/s, 5.64807s/100 iters), loss = 4.0125
I1210 09:11:58.919353 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1210 09:11:58.919353 16412 solver.cpp:237]     Train net output #1: loss = 4.0125 (* 1 = 4.0125 loss)
I1210 09:11:58.919353 16412 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1210 09:12:04.567183 16412 solver.cpp:218] Iteration 400 (17.7071 iter/s, 5.64746s/100 iters), loss = 3.95196
I1210 09:12:04.567183 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1210 09:12:04.567183 16412 solver.cpp:237]     Train net output #1: loss = 3.95196 (* 1 = 3.95196 loss)
I1210 09:12:04.567183 16412 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1210 09:12:09.949174  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:12:10.171258 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_500.caffemodel
I1210 09:12:10.191257 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_500.solverstate
I1210 09:12:10.196257 16412 solver.cpp:330] Iteration 500, Testing net (#0)
I1210 09:12:10.196257 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:12:11.562396 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:12:11.615396 16412 solver.cpp:397]     Test net output #0: accuracy = 0.0545
I1210 09:12:11.615396 16412 solver.cpp:397]     Test net output #1: loss = 4.25911 (* 1 = 4.25911 loss)
I1210 09:12:11.669404 16412 solver.cpp:218] Iteration 500 (14.0791 iter/s, 7.10271s/100 iters), loss = 3.74633
I1210 09:12:11.670403 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1210 09:12:11.670403 16412 solver.cpp:237]     Train net output #1: loss = 3.74633 (* 1 = 3.74633 loss)
I1210 09:12:11.670403 16412 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1210 09:12:17.328434 16412 solver.cpp:218] Iteration 600 (17.675 iter/s, 5.6577s/100 iters), loss = 3.55514
I1210 09:12:17.328434 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1210 09:12:17.328434 16412 solver.cpp:237]     Train net output #1: loss = 3.55514 (* 1 = 3.55514 loss)
I1210 09:12:17.328434 16412 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1210 09:12:23.013345 16412 solver.cpp:218] Iteration 700 (17.5907 iter/s, 5.68481s/100 iters), loss = 3.49784
I1210 09:12:23.013345 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1210 09:12:23.013345 16412 solver.cpp:237]     Train net output #1: loss = 3.49784 (* 1 = 3.49784 loss)
I1210 09:12:23.013345 16412 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1210 09:12:28.683764 16412 solver.cpp:218] Iteration 800 (17.6359 iter/s, 5.67024s/100 iters), loss = 3.56382
I1210 09:12:28.683764 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.17
I1210 09:12:28.683764 16412 solver.cpp:237]     Train net output #1: loss = 3.56382 (* 1 = 3.56382 loss)
I1210 09:12:28.683764 16412 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1210 09:12:34.350265 16412 solver.cpp:218] Iteration 900 (17.6498 iter/s, 5.66578s/100 iters), loss = 3.3468
I1210 09:12:34.350265 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.14
I1210 09:12:34.350265 16412 solver.cpp:237]     Train net output #1: loss = 3.3468 (* 1 = 3.3468 loss)
I1210 09:12:34.350265 16412 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1210 09:12:39.749727  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:12:39.973742 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_1000.caffemodel
I1210 09:12:39.987743 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_1000.solverstate
I1210 09:12:39.992745 16412 solver.cpp:330] Iteration 1000, Testing net (#0)
I1210 09:12:39.992745 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:12:41.360877 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:12:41.415390 16412 solver.cpp:397]     Test net output #0: accuracy = 0.1332
I1210 09:12:41.415390 16412 solver.cpp:397]     Test net output #1: loss = 3.70262 (* 1 = 3.70262 loss)
I1210 09:12:41.469882 16412 solver.cpp:218] Iteration 1000 (14.0462 iter/s, 7.11937s/100 iters), loss = 3.11665
I1210 09:12:41.469882 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1210 09:12:41.469882 16412 solver.cpp:237]     Train net output #1: loss = 3.11665 (* 1 = 3.11665 loss)
I1210 09:12:41.469882 16412 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1210 09:12:47.126318 16412 solver.cpp:218] Iteration 1100 (17.6792 iter/s, 5.65638s/100 iters), loss = 3.03536
I1210 09:12:47.126318 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.18
I1210 09:12:47.127319 16412 solver.cpp:237]     Train net output #1: loss = 3.03536 (* 1 = 3.03536 loss)
I1210 09:12:47.127319 16412 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1210 09:12:52.797749 16412 solver.cpp:218] Iteration 1200 (17.6339 iter/s, 5.6709s/100 iters), loss = 2.80705
I1210 09:12:52.797749 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.25
I1210 09:12:52.797749 16412 solver.cpp:237]     Train net output #1: loss = 2.80705 (* 1 = 2.80705 loss)
I1210 09:12:52.797749 16412 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1210 09:12:58.460204 16412 solver.cpp:218] Iteration 1300 (17.6626 iter/s, 5.66168s/100 iters), loss = 2.95612
I1210 09:12:58.460204 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1210 09:12:58.460204 16412 solver.cpp:237]     Train net output #1: loss = 2.95612 (* 1 = 2.95612 loss)
I1210 09:12:58.460204 16412 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1210 09:13:04.143664 16412 solver.cpp:218] Iteration 1400 (17.5974 iter/s, 5.68265s/100 iters), loss = 2.98548
I1210 09:13:04.143664 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.25
I1210 09:13:04.143664 16412 solver.cpp:237]     Train net output #1: loss = 2.98548 (* 1 = 2.98548 loss)
I1210 09:13:04.143664 16412 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1210 09:13:09.524230  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:13:09.746244 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_1500.caffemodel
I1210 09:13:09.760244 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_1500.solverstate
I1210 09:13:09.764245 16412 solver.cpp:330] Iteration 1500, Testing net (#0)
I1210 09:13:09.764245 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:13:11.137320 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:13:11.190323 16412 solver.cpp:397]     Test net output #0: accuracy = 0.0991
I1210 09:13:11.190323 16412 solver.cpp:397]     Test net output #1: loss = 3.98152 (* 1 = 3.98152 loss)
I1210 09:13:11.245323 16412 solver.cpp:218] Iteration 1500 (14.0819 iter/s, 7.10133s/100 iters), loss = 2.68758
I1210 09:13:11.245323 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1210 09:13:11.245323 16412 solver.cpp:237]     Train net output #1: loss = 2.68758 (* 1 = 2.68758 loss)
I1210 09:13:11.245323 16412 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1210 09:13:16.910807 16412 solver.cpp:218] Iteration 1600 (17.6496 iter/s, 5.66586s/100 iters), loss = 2.8263
I1210 09:13:16.911808 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.17
I1210 09:13:16.911808 16412 solver.cpp:237]     Train net output #1: loss = 2.8263 (* 1 = 2.8263 loss)
I1210 09:13:16.911808 16412 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1210 09:13:22.672392 16412 solver.cpp:218] Iteration 1700 (17.3594 iter/s, 5.76057s/100 iters), loss = 2.57118
I1210 09:13:22.672392 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 09:13:22.672392 16412 solver.cpp:237]     Train net output #1: loss = 2.57118 (* 1 = 2.57118 loss)
I1210 09:13:22.672392 16412 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1210 09:13:28.362828 16412 solver.cpp:218] Iteration 1800 (17.5747 iter/s, 5.69s/100 iters), loss = 2.88315
I1210 09:13:28.362828 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1210 09:13:28.362828 16412 solver.cpp:237]     Train net output #1: loss = 2.88315 (* 1 = 2.88315 loss)
I1210 09:13:28.362828 16412 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1210 09:13:34.032254 16412 solver.cpp:218] Iteration 1900 (17.6405 iter/s, 5.66877s/100 iters), loss = 2.82015
I1210 09:13:34.032254 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1210 09:13:34.032254 16412 solver.cpp:237]     Train net output #1: loss = 2.82015 (* 1 = 2.82015 loss)
I1210 09:13:34.032254 16412 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1210 09:13:39.434706  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:13:39.656731 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_2000.caffemodel
I1210 09:13:39.672732 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_2000.solverstate
I1210 09:13:39.676730 16412 solver.cpp:330] Iteration 2000, Testing net (#0)
I1210 09:13:39.676730 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:13:41.053850 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:13:41.107856 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2154
I1210 09:13:41.107856 16412 solver.cpp:397]     Test net output #1: loss = 3.18984 (* 1 = 3.18984 loss)
I1210 09:13:41.160857 16412 solver.cpp:218] Iteration 2000 (14.0278 iter/s, 7.12869s/100 iters), loss = 2.41898
I1210 09:13:41.160857 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 09:13:41.160857 16412 solver.cpp:237]     Train net output #1: loss = 2.41898 (* 1 = 2.41898 loss)
I1210 09:13:41.160857 16412 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1210 09:13:46.849285 16412 solver.cpp:218] Iteration 2100 (17.5826 iter/s, 5.68745s/100 iters), loss = 2.71143
I1210 09:13:46.849285 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1210 09:13:46.849285 16412 solver.cpp:237]     Train net output #1: loss = 2.71143 (* 1 = 2.71143 loss)
I1210 09:13:46.849285 16412 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1210 09:13:52.553797 16412 solver.cpp:218] Iteration 2200 (17.5306 iter/s, 5.70432s/100 iters), loss = 2.42643
I1210 09:13:52.553797 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1210 09:13:52.553797 16412 solver.cpp:237]     Train net output #1: loss = 2.42643 (* 1 = 2.42643 loss)
I1210 09:13:52.553797 16412 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1210 09:13:58.225232 16412 solver.cpp:218] Iteration 2300 (17.6347 iter/s, 5.67064s/100 iters), loss = 2.65737
I1210 09:13:58.225232 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1210 09:13:58.225232 16412 solver.cpp:237]     Train net output #1: loss = 2.65737 (* 1 = 2.65737 loss)
I1210 09:13:58.225232 16412 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1210 09:14:03.930160 16412 solver.cpp:218] Iteration 2400 (17.5295 iter/s, 5.70466s/100 iters), loss = 2.4129
I1210 09:14:03.930660 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1210 09:14:03.930660 16412 solver.cpp:237]     Train net output #1: loss = 2.4129 (* 1 = 2.4129 loss)
I1210 09:14:03.930660 16412 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1210 09:14:09.339139  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:14:09.563176 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_2500.caffemodel
I1210 09:14:09.576176 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_2500.solverstate
I1210 09:14:09.581176 16412 solver.cpp:330] Iteration 2500, Testing net (#0)
I1210 09:14:09.581176 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:14:10.956264 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:14:11.010264 16412 solver.cpp:397]     Test net output #0: accuracy = 0.1616
I1210 09:14:11.010264 16412 solver.cpp:397]     Test net output #1: loss = 3.56274 (* 1 = 3.56274 loss)
I1210 09:14:11.064270 16412 solver.cpp:218] Iteration 2500 (14.0179 iter/s, 7.13371s/100 iters), loss = 2.26371
I1210 09:14:11.064270 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:14:11.064270 16412 solver.cpp:237]     Train net output #1: loss = 2.26371 (* 1 = 2.26371 loss)
I1210 09:14:11.064270 16412 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1210 09:14:16.737010 16412 solver.cpp:218] Iteration 2600 (17.631 iter/s, 5.67184s/100 iters), loss = 2.30537
I1210 09:14:16.737010 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1210 09:14:16.737010 16412 solver.cpp:237]     Train net output #1: loss = 2.30537 (* 1 = 2.30537 loss)
I1210 09:14:16.737010 16412 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1210 09:14:22.433635 16412 solver.cpp:218] Iteration 2700 (17.5547 iter/s, 5.69647s/100 iters), loss = 2.13781
I1210 09:14:22.433635 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:14:22.433635 16412 solver.cpp:237]     Train net output #1: loss = 2.13781 (* 1 = 2.13781 loss)
I1210 09:14:22.433635 16412 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1210 09:14:28.162132 16412 solver.cpp:218] Iteration 2800 (17.4564 iter/s, 5.72857s/100 iters), loss = 2.48632
I1210 09:14:28.163138 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1210 09:14:28.163138 16412 solver.cpp:237]     Train net output #1: loss = 2.48632 (* 1 = 2.48632 loss)
I1210 09:14:28.163138 16412 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1210 09:14:33.969658 16412 solver.cpp:218] Iteration 2900 (17.2231 iter/s, 5.80617s/100 iters), loss = 2.47161
I1210 09:14:33.969658 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1210 09:14:33.969658 16412 solver.cpp:237]     Train net output #1: loss = 2.47161 (* 1 = 2.47161 loss)
I1210 09:14:33.969658 16412 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1210 09:14:39.400940  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:14:39.623955 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_3000.caffemodel
I1210 09:14:39.641954 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_3000.solverstate
I1210 09:14:39.646955 16412 solver.cpp:330] Iteration 3000, Testing net (#0)
I1210 09:14:39.646955 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:14:41.035063 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:14:41.089061 16412 solver.cpp:397]     Test net output #0: accuracy = 0.267
I1210 09:14:41.089061 16412 solver.cpp:397]     Test net output #1: loss = 2.87684 (* 1 = 2.87684 loss)
I1210 09:14:41.145069 16412 solver.cpp:218] Iteration 3000 (13.9364 iter/s, 7.17547s/100 iters), loss = 2.33095
I1210 09:14:41.145069 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1210 09:14:41.145069 16412 solver.cpp:237]     Train net output #1: loss = 2.33095 (* 1 = 2.33095 loss)
I1210 09:14:41.145069 16412 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1210 09:14:46.890545 16412 solver.cpp:218] Iteration 3100 (17.4074 iter/s, 5.74467s/100 iters), loss = 2.22429
I1210 09:14:46.890545 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 09:14:46.890545 16412 solver.cpp:237]     Train net output #1: loss = 2.22429 (* 1 = 2.22429 loss)
I1210 09:14:46.890545 16412 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1210 09:14:52.615034 16412 solver.cpp:218] Iteration 3200 (17.4707 iter/s, 5.72386s/100 iters), loss = 2.0759
I1210 09:14:52.615034 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:14:52.615034 16412 solver.cpp:237]     Train net output #1: loss = 2.0759 (* 1 = 2.0759 loss)
I1210 09:14:52.615034 16412 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1210 09:14:58.321439 16412 solver.cpp:218] Iteration 3300 (17.524 iter/s, 5.70645s/100 iters), loss = 2.23672
I1210 09:14:58.321439 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:14:58.321439 16412 solver.cpp:237]     Train net output #1: loss = 2.23672 (* 1 = 2.23672 loss)
I1210 09:14:58.321439 16412 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1210 09:15:04.009904 16412 solver.cpp:218] Iteration 3400 (17.5818 iter/s, 5.68771s/100 iters), loss = 2.22559
I1210 09:15:04.009904 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 09:15:04.009904 16412 solver.cpp:237]     Train net output #1: loss = 2.22559 (* 1 = 2.22559 loss)
I1210 09:15:04.009904 16412 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1210 09:15:09.424362  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:15:09.649389 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_3500.caffemodel
I1210 09:15:09.664392 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_3500.solverstate
I1210 09:15:09.669394 16412 solver.cpp:330] Iteration 3500, Testing net (#0)
I1210 09:15:09.669394 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:15:11.042527 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:15:11.096561 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2957
I1210 09:15:11.096561 16412 solver.cpp:397]     Test net output #1: loss = 2.75532 (* 1 = 2.75532 loss)
I1210 09:15:11.151562 16412 solver.cpp:218] Iteration 3500 (14.0027 iter/s, 7.14146s/100 iters), loss = 2.14212
I1210 09:15:11.151562 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:15:11.151562 16412 solver.cpp:237]     Train net output #1: loss = 2.14212 (* 1 = 2.14212 loss)
I1210 09:15:11.151562 16412 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1210 09:15:16.846937 16412 solver.cpp:218] Iteration 3600 (17.5602 iter/s, 5.69471s/100 iters), loss = 2.13444
I1210 09:15:16.846937 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1210 09:15:16.846937 16412 solver.cpp:237]     Train net output #1: loss = 2.13444 (* 1 = 2.13444 loss)
I1210 09:15:16.846937 16412 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1210 09:15:22.522357 16412 solver.cpp:218] Iteration 3700 (17.6224 iter/s, 5.6746s/100 iters), loss = 1.82109
I1210 09:15:22.522357 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:15:22.522357 16412 solver.cpp:237]     Train net output #1: loss = 1.82109 (* 1 = 1.82109 loss)
I1210 09:15:22.522357 16412 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1210 09:15:28.204748 16412 solver.cpp:218] Iteration 3800 (17.5979 iter/s, 5.6825s/100 iters), loss = 2.24501
I1210 09:15:28.204748 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 09:15:28.204748 16412 solver.cpp:237]     Train net output #1: loss = 2.24501 (* 1 = 2.24501 loss)
I1210 09:15:28.204748 16412 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1210 09:15:33.888142 16412 solver.cpp:218] Iteration 3900 (17.5974 iter/s, 5.68266s/100 iters), loss = 2.04076
I1210 09:15:33.888142 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 09:15:33.888142 16412 solver.cpp:237]     Train net output #1: loss = 2.04076 (* 1 = 2.04076 loss)
I1210 09:15:33.888142 16412 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1210 09:15:39.302554  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:15:39.525564 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_4000.caffemodel
I1210 09:15:39.539564 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_4000.solverstate
I1210 09:15:39.544564 16412 solver.cpp:330] Iteration 4000, Testing net (#0)
I1210 09:15:39.544564 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:15:40.912564 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:15:40.968559 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2525
I1210 09:15:40.968559 16412 solver.cpp:397]     Test net output #1: loss = 3.01945 (* 1 = 3.01945 loss)
I1210 09:15:41.022578 16412 solver.cpp:218] Iteration 4000 (14.0174 iter/s, 7.13398s/100 iters), loss = 2.23588
I1210 09:15:41.022578 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 09:15:41.022578 16412 solver.cpp:237]     Train net output #1: loss = 2.23588 (* 1 = 2.23588 loss)
I1210 09:15:41.022578 16412 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1210 09:15:46.692368 16412 solver.cpp:218] Iteration 4100 (17.6409 iter/s, 5.66866s/100 iters), loss = 2.01446
I1210 09:15:46.692368 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1210 09:15:46.692368 16412 solver.cpp:237]     Train net output #1: loss = 2.01446 (* 1 = 2.01446 loss)
I1210 09:15:46.692368 16412 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1210 09:15:52.374311 16412 solver.cpp:218] Iteration 4200 (17.6006 iter/s, 5.68162s/100 iters), loss = 1.78076
I1210 09:15:52.374311 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:15:52.374311 16412 solver.cpp:237]     Train net output #1: loss = 1.78076 (* 1 = 1.78076 loss)
I1210 09:15:52.374311 16412 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1210 09:15:58.070158 16412 solver.cpp:218] Iteration 4300 (17.5583 iter/s, 5.69532s/100 iters), loss = 2.11801
I1210 09:15:58.070158 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 09:15:58.070158 16412 solver.cpp:237]     Train net output #1: loss = 2.11801 (* 1 = 2.11801 loss)
I1210 09:15:58.070158 16412 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1210 09:16:03.787123 16412 solver.cpp:218] Iteration 4400 (17.4924 iter/s, 5.71677s/100 iters), loss = 2.1633
I1210 09:16:03.787123 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:16:03.787123 16412 solver.cpp:237]     Train net output #1: loss = 2.1633 (* 1 = 2.1633 loss)
I1210 09:16:03.787123 16412 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1210 09:16:09.243643  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:16:09.471655 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_4500.caffemodel
I1210 09:16:09.486659 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_4500.solverstate
I1210 09:16:09.490660 16412 solver.cpp:330] Iteration 4500, Testing net (#0)
I1210 09:16:09.490660 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:16:10.872719 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:16:10.926733 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3336
I1210 09:16:10.926733 16412 solver.cpp:397]     Test net output #1: loss = 2.61103 (* 1 = 2.61103 loss)
I1210 09:16:10.982724 16412 solver.cpp:218] Iteration 4500 (13.8974 iter/s, 7.19557s/100 iters), loss = 1.9989
I1210 09:16:10.982724 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:16:10.982724 16412 solver.cpp:237]     Train net output #1: loss = 1.9989 (* 1 = 1.9989 loss)
I1210 09:16:10.982724 16412 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1210 09:16:16.699152 16412 solver.cpp:218] Iteration 4600 (17.4974 iter/s, 5.71514s/100 iters), loss = 1.92171
I1210 09:16:16.699152 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 09:16:16.699152 16412 solver.cpp:237]     Train net output #1: loss = 1.92171 (* 1 = 1.92171 loss)
I1210 09:16:16.699152 16412 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1210 09:16:22.391605 16412 solver.cpp:218] Iteration 4700 (17.5685 iter/s, 5.692s/100 iters), loss = 1.73363
I1210 09:16:22.391605 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:16:22.391605 16412 solver.cpp:237]     Train net output #1: loss = 1.73363 (* 1 = 1.73363 loss)
I1210 09:16:22.391605 16412 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1210 09:16:28.059013 16412 solver.cpp:218] Iteration 4800 (17.6449 iter/s, 5.66737s/100 iters), loss = 1.98001
I1210 09:16:28.059013 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:16:28.059013 16412 solver.cpp:237]     Train net output #1: loss = 1.98001 (* 1 = 1.98001 loss)
I1210 09:16:28.059013 16412 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1210 09:16:33.753428 16412 solver.cpp:218] Iteration 4900 (17.5628 iter/s, 5.69386s/100 iters), loss = 2.15754
I1210 09:16:33.753428 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1210 09:16:33.753428 16412 solver.cpp:237]     Train net output #1: loss = 2.15754 (* 1 = 2.15754 loss)
I1210 09:16:33.753428 16412 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1210 09:16:39.175827  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:16:39.400854 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_5000.caffemodel
I1210 09:16:39.414855 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_5000.solverstate
I1210 09:16:39.419857 16412 solver.cpp:330] Iteration 5000, Testing net (#0)
I1210 09:16:39.419857 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:16:40.792029 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:16:40.846027 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2905
I1210 09:16:40.846027 16412 solver.cpp:397]     Test net output #1: loss = 3.00883 (* 1 = 3.00883 loss)
I1210 09:16:40.900033 16412 solver.cpp:218] Iteration 5000 (13.9945 iter/s, 7.14565s/100 iters), loss = 1.98426
I1210 09:16:40.900033 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:16:40.900033 16412 solver.cpp:237]     Train net output #1: loss = 1.98426 (* 1 = 1.98426 loss)
I1210 09:16:40.900033 16412 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1210 09:16:46.580505 16412 solver.cpp:218] Iteration 5100 (17.6048 iter/s, 5.68027s/100 iters), loss = 1.96441
I1210 09:16:46.580505 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:16:46.580505 16412 solver.cpp:237]     Train net output #1: loss = 1.96441 (* 1 = 1.96441 loss)
I1210 09:16:46.580505 16412 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1210 09:16:52.284994 16412 solver.cpp:218] Iteration 5200 (17.5314 iter/s, 5.70405s/100 iters), loss = 1.71001
I1210 09:16:52.284994 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:16:52.284994 16412 solver.cpp:237]     Train net output #1: loss = 1.71001 (* 1 = 1.71001 loss)
I1210 09:16:52.284994 16412 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1210 09:16:57.992807 16412 solver.cpp:218] Iteration 5300 (17.5208 iter/s, 5.70752s/100 iters), loss = 2.31013
I1210 09:16:57.992807 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:16:57.992807 16412 solver.cpp:237]     Train net output #1: loss = 2.31013 (* 1 = 2.31013 loss)
I1210 09:16:57.992807 16412 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1210 09:17:03.775996 16412 solver.cpp:218] Iteration 5400 (17.2937 iter/s, 5.78246s/100 iters), loss = 2.08273
I1210 09:17:03.775996 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:17:03.775996 16412 solver.cpp:237]     Train net output #1: loss = 2.08273 (* 1 = 2.08273 loss)
I1210 09:17:03.775996 16412 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1210 09:17:09.169898  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:17:09.392915 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_5500.caffemodel
I1210 09:17:09.407915 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_5500.solverstate
I1210 09:17:09.411916 16412 solver.cpp:330] Iteration 5500, Testing net (#0)
I1210 09:17:09.411916 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:17:10.794030 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:17:10.847029 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2687
I1210 09:17:10.847029 16412 solver.cpp:397]     Test net output #1: loss = 3.44255 (* 1 = 3.44255 loss)
I1210 09:17:10.902036 16412 solver.cpp:218] Iteration 5500 (14.034 iter/s, 7.12556s/100 iters), loss = 2.04564
I1210 09:17:10.902036 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 09:17:10.902036 16412 solver.cpp:237]     Train net output #1: loss = 2.04564 (* 1 = 2.04564 loss)
I1210 09:17:10.902036 16412 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1210 09:17:16.606457 16412 solver.cpp:218] Iteration 5600 (17.5323 iter/s, 5.70375s/100 iters), loss = 1.77485
I1210 09:17:16.606457 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:17:16.606457 16412 solver.cpp:237]     Train net output #1: loss = 1.77485 (* 1 = 1.77485 loss)
I1210 09:17:16.606457 16412 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1210 09:17:22.309906 16412 solver.cpp:218] Iteration 5700 (17.5336 iter/s, 5.70335s/100 iters), loss = 1.54387
I1210 09:17:22.309906 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:17:22.309906 16412 solver.cpp:237]     Train net output #1: loss = 1.54387 (* 1 = 1.54387 loss)
I1210 09:17:22.309906 16412 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1210 09:17:28.004356 16412 solver.cpp:218] Iteration 5800 (17.5623 iter/s, 5.69402s/100 iters), loss = 2.00779
I1210 09:17:28.004356 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:17:28.004356 16412 solver.cpp:237]     Train net output #1: loss = 2.00779 (* 1 = 2.00779 loss)
I1210 09:17:28.004356 16412 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1210 09:17:33.703749 16412 solver.cpp:218] Iteration 5900 (17.5458 iter/s, 5.69938s/100 iters), loss = 2.04611
I1210 09:17:33.703749 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:17:33.703749 16412 solver.cpp:237]     Train net output #1: loss = 2.04611 (* 1 = 2.04611 loss)
I1210 09:17:33.703749 16412 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1210 09:17:39.096120  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:17:39.320132 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_6000.caffemodel
I1210 09:17:39.335132 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_6000.solverstate
I1210 09:17:39.339133 16412 solver.cpp:330] Iteration 6000, Testing net (#0)
I1210 09:17:39.339133 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:17:40.704255 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:17:40.758255 16412 solver.cpp:397]     Test net output #0: accuracy = 0.251
I1210 09:17:40.758255 16412 solver.cpp:397]     Test net output #1: loss = 3.54798 (* 1 = 3.54798 loss)
I1210 09:17:40.813258 16412 solver.cpp:218] Iteration 6000 (14.0676 iter/s, 7.10851s/100 iters), loss = 1.88609
I1210 09:17:40.813258 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:17:40.813258 16412 solver.cpp:237]     Train net output #1: loss = 1.88609 (* 1 = 1.88609 loss)
I1210 09:17:40.813258 16412 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1210 09:17:46.520823 16412 solver.cpp:218] Iteration 6100 (17.5217 iter/s, 5.70722s/100 iters), loss = 1.71235
I1210 09:17:46.520823 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:17:46.520823 16412 solver.cpp:237]     Train net output #1: loss = 1.71235 (* 1 = 1.71235 loss)
I1210 09:17:46.520823 16412 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1210 09:17:52.226254 16412 solver.cpp:218] Iteration 6200 (17.5282 iter/s, 5.7051s/100 iters), loss = 1.54271
I1210 09:17:52.226254 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:17:52.226254 16412 solver.cpp:237]     Train net output #1: loss = 1.54271 (* 1 = 1.54271 loss)
I1210 09:17:52.226254 16412 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1210 09:17:57.925669 16412 solver.cpp:218] Iteration 6300 (17.5473 iter/s, 5.69887s/100 iters), loss = 2.10023
I1210 09:17:57.925669 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1210 09:17:57.925669 16412 solver.cpp:237]     Train net output #1: loss = 2.10023 (* 1 = 2.10023 loss)
I1210 09:17:57.925669 16412 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1210 09:18:03.600041 16412 solver.cpp:218] Iteration 6400 (17.625 iter/s, 5.67376s/100 iters), loss = 2.14035
I1210 09:18:03.600041 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 09:18:03.600041 16412 solver.cpp:237]     Train net output #1: loss = 2.14035 (* 1 = 2.14035 loss)
I1210 09:18:03.600041 16412 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1210 09:18:09.005702  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:18:09.231739 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_6500.caffemodel
I1210 09:18:09.244737 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_6500.solverstate
I1210 09:18:09.249737 16412 solver.cpp:330] Iteration 6500, Testing net (#0)
I1210 09:18:09.249737 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:18:10.634888 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:18:10.688884 16412 solver.cpp:397]     Test net output #0: accuracy = 0.235
I1210 09:18:10.688884 16412 solver.cpp:397]     Test net output #1: loss = 3.41141 (* 1 = 3.41141 loss)
I1210 09:18:10.742885 16412 solver.cpp:218] Iteration 6500 (14.0007 iter/s, 7.14249s/100 iters), loss = 2.03448
I1210 09:18:10.742885 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:18:10.742885 16412 solver.cpp:237]     Train net output #1: loss = 2.03448 (* 1 = 2.03448 loss)
I1210 09:18:10.742885 16412 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1210 09:18:16.451462 16412 solver.cpp:218] Iteration 6600 (17.5182 iter/s, 5.70833s/100 iters), loss = 1.70879
I1210 09:18:16.451462 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 09:18:16.451462 16412 solver.cpp:237]     Train net output #1: loss = 1.70879 (* 1 = 1.70879 loss)
I1210 09:18:16.451462 16412 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1210 09:18:22.132863 16412 solver.cpp:218] Iteration 6700 (17.6032 iter/s, 5.6808s/100 iters), loss = 1.51169
I1210 09:18:22.132863 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:18:22.132863 16412 solver.cpp:237]     Train net output #1: loss = 1.51169 (* 1 = 1.51169 loss)
I1210 09:18:22.132863 16412 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1210 09:18:27.870518 16412 solver.cpp:218] Iteration 6800 (17.4285 iter/s, 5.73773s/100 iters), loss = 1.93438
I1210 09:18:27.871520 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:18:27.871520 16412 solver.cpp:237]     Train net output #1: loss = 1.93438 (* 1 = 1.93438 loss)
I1210 09:18:27.871520 16412 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1210 09:18:33.630637 16412 solver.cpp:218] Iteration 6900 (17.3639 iter/s, 5.75908s/100 iters), loss = 2.1156
I1210 09:18:33.630637 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1210 09:18:33.630637 16412 solver.cpp:237]     Train net output #1: loss = 2.1156 (* 1 = 2.1156 loss)
I1210 09:18:33.630637 16412 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1210 09:18:39.050581  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:18:39.273593 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_7000.caffemodel
I1210 09:18:39.287591 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_7000.solverstate
I1210 09:18:39.293592 16412 solver.cpp:330] Iteration 7000, Testing net (#0)
I1210 09:18:39.293592 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:18:40.678416 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:18:40.735419 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2805
I1210 09:18:40.735419 16412 solver.cpp:397]     Test net output #1: loss = 2.98796 (* 1 = 2.98796 loss)
I1210 09:18:40.793424 16412 solver.cpp:218] Iteration 7000 (13.9625 iter/s, 7.16202s/100 iters), loss = 1.94481
I1210 09:18:40.793424 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:18:40.793424 16412 solver.cpp:237]     Train net output #1: loss = 1.94481 (* 1 = 1.94481 loss)
I1210 09:18:40.793424 16412 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1210 09:18:46.459214 16412 solver.cpp:218] Iteration 7100 (17.6515 iter/s, 5.66523s/100 iters), loss = 1.78627
I1210 09:18:46.459214 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:18:46.459214 16412 solver.cpp:237]     Train net output #1: loss = 1.78627 (* 1 = 1.78627 loss)
I1210 09:18:46.459214 16412 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1210 09:18:52.164855 16412 solver.cpp:218] Iteration 7200 (17.5267 iter/s, 5.70557s/100 iters), loss = 1.4891
I1210 09:18:52.165345 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:18:52.165345 16412 solver.cpp:237]     Train net output #1: loss = 1.4891 (* 1 = 1.4891 loss)
I1210 09:18:52.165345 16412 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1210 09:18:57.875344 16412 solver.cpp:218] Iteration 7300 (17.5134 iter/s, 5.7099s/100 iters), loss = 1.89514
I1210 09:18:57.875344 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:18:57.875344 16412 solver.cpp:237]     Train net output #1: loss = 1.89514 (* 1 = 1.89514 loss)
I1210 09:18:57.875344 16412 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1210 09:19:03.615779 16412 solver.cpp:218] Iteration 7400 (17.4208 iter/s, 5.74026s/100 iters), loss = 2.05632
I1210 09:19:03.615779 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:19:03.615779 16412 solver.cpp:237]     Train net output #1: loss = 2.05632 (* 1 = 2.05632 loss)
I1210 09:19:03.615779 16412 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1210 09:19:09.120255  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:19:09.346264 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_7500.caffemodel
I1210 09:19:09.362263 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_7500.solverstate
I1210 09:19:09.366770 16412 solver.cpp:330] Iteration 7500, Testing net (#0)
I1210 09:19:09.367270 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:19:10.741367 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:19:10.795383 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2499
I1210 09:19:10.795383 16412 solver.cpp:397]     Test net output #1: loss = 3.21935 (* 1 = 3.21935 loss)
I1210 09:19:10.851385 16412 solver.cpp:218] Iteration 7500 (13.8218 iter/s, 7.23494s/100 iters), loss = 2.06401
I1210 09:19:10.851385 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:19:10.851385 16412 solver.cpp:237]     Train net output #1: loss = 2.06401 (* 1 = 2.06401 loss)
I1210 09:19:10.851385 16412 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1210 09:19:16.565469 16412 solver.cpp:218] Iteration 7600 (17.5028 iter/s, 5.71338s/100 iters), loss = 1.77915
I1210 09:19:16.565469 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:19:16.565469 16412 solver.cpp:237]     Train net output #1: loss = 1.77915 (* 1 = 1.77915 loss)
I1210 09:19:16.565469 16412 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1210 09:19:22.320080 16412 solver.cpp:218] Iteration 7700 (17.3776 iter/s, 5.75454s/100 iters), loss = 1.54718
I1210 09:19:22.320080 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:19:22.320080 16412 solver.cpp:237]     Train net output #1: loss = 1.54718 (* 1 = 1.54718 loss)
I1210 09:19:22.320080 16412 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1210 09:19:28.003828 16412 solver.cpp:218] Iteration 7800 (17.595 iter/s, 5.68342s/100 iters), loss = 1.95886
I1210 09:19:28.003828 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:19:28.003828 16412 solver.cpp:237]     Train net output #1: loss = 1.95886 (* 1 = 1.95886 loss)
I1210 09:19:28.003828 16412 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1210 09:19:33.698683 16412 solver.cpp:218] Iteration 7900 (17.5628 iter/s, 5.69386s/100 iters), loss = 1.94037
I1210 09:19:33.698683 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:19:33.698683 16412 solver.cpp:237]     Train net output #1: loss = 1.94037 (* 1 = 1.94037 loss)
I1210 09:19:33.698683 16412 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1210 09:19:39.119112  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:19:39.342128 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_8000.caffemodel
I1210 09:19:39.356127 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_8000.solverstate
I1210 09:19:39.361127 16412 solver.cpp:330] Iteration 8000, Testing net (#0)
I1210 09:19:39.361127 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:19:40.731359 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:19:40.785864 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2944
I1210 09:19:40.785864 16412 solver.cpp:397]     Test net output #1: loss = 2.88955 (* 1 = 2.88955 loss)
I1210 09:19:40.839365 16412 solver.cpp:218] Iteration 8000 (14.0041 iter/s, 7.14078s/100 iters), loss = 1.91023
I1210 09:19:40.840366 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:19:40.840366 16412 solver.cpp:237]     Train net output #1: loss = 1.91023 (* 1 = 1.91023 loss)
I1210 09:19:40.840366 16412 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1210 09:19:46.540801 16412 solver.cpp:218] Iteration 8100 (17.5441 iter/s, 5.69993s/100 iters), loss = 1.76993
I1210 09:19:46.540801 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:19:46.540801 16412 solver.cpp:237]     Train net output #1: loss = 1.76993 (* 1 = 1.76993 loss)
I1210 09:19:46.540801 16412 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1210 09:19:52.210211 16412 solver.cpp:218] Iteration 8200 (17.638 iter/s, 5.66958s/100 iters), loss = 1.52969
I1210 09:19:52.210211 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:19:52.210211 16412 solver.cpp:237]     Train net output #1: loss = 1.52969 (* 1 = 1.52969 loss)
I1210 09:19:52.210211 16412 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1210 09:19:57.887154 16412 solver.cpp:218] Iteration 8300 (17.6182 iter/s, 5.67594s/100 iters), loss = 1.95038
I1210 09:19:57.887154 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:19:57.887154 16412 solver.cpp:237]     Train net output #1: loss = 1.95038 (* 1 = 1.95038 loss)
I1210 09:19:57.887154 16412 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1210 09:20:03.596194 16412 solver.cpp:218] Iteration 8400 (17.5161 iter/s, 5.70902s/100 iters), loss = 1.91551
I1210 09:20:03.596194 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:20:03.596194 16412 solver.cpp:237]     Train net output #1: loss = 1.91551 (* 1 = 1.91551 loss)
I1210 09:20:03.596194 16412 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1210 09:20:09.017626  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:20:09.248661 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_8500.caffemodel
I1210 09:20:09.264657 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_8500.solverstate
I1210 09:20:09.269665 16412 solver.cpp:330] Iteration 8500, Testing net (#0)
I1210 09:20:09.269665 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:20:10.643784 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:20:10.698791 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3845
I1210 09:20:10.698791 16412 solver.cpp:397]     Test net output #1: loss = 2.35644 (* 1 = 2.35644 loss)
I1210 09:20:10.752800 16412 solver.cpp:218] Iteration 8500 (13.9742 iter/s, 7.15603s/100 iters), loss = 1.92373
I1210 09:20:10.752800 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:20:10.752800 16412 solver.cpp:237]     Train net output #1: loss = 1.92373 (* 1 = 1.92373 loss)
I1210 09:20:10.752800 16412 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1210 09:20:16.442207 16412 solver.cpp:218] Iteration 8600 (17.5788 iter/s, 5.68867s/100 iters), loss = 1.6792
I1210 09:20:16.442207 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:20:16.442207 16412 solver.cpp:237]     Train net output #1: loss = 1.6792 (* 1 = 1.6792 loss)
I1210 09:20:16.442207 16412 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1210 09:20:22.144691 16412 solver.cpp:218] Iteration 8700 (17.5358 iter/s, 5.7026s/100 iters), loss = 1.48902
I1210 09:20:22.144691 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:20:22.144691 16412 solver.cpp:237]     Train net output #1: loss = 1.48902 (* 1 = 1.48902 loss)
I1210 09:20:22.144691 16412 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1210 09:20:27.831145 16412 solver.cpp:218] Iteration 8800 (17.5866 iter/s, 5.68616s/100 iters), loss = 1.9802
I1210 09:20:27.831145 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:20:27.831145 16412 solver.cpp:237]     Train net output #1: loss = 1.9802 (* 1 = 1.9802 loss)
I1210 09:20:27.831145 16412 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1210 09:20:33.613591 16412 solver.cpp:218] Iteration 8900 (17.2958 iter/s, 5.78175s/100 iters), loss = 1.95389
I1210 09:20:33.613591 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:20:33.613591 16412 solver.cpp:237]     Train net output #1: loss = 1.95389 (* 1 = 1.95389 loss)
I1210 09:20:33.613591 16412 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1210 09:20:39.016974  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:20:39.241986 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_9000.caffemodel
I1210 09:20:39.254987 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_9000.solverstate
I1210 09:20:39.259987 16412 solver.cpp:330] Iteration 9000, Testing net (#0)
I1210 09:20:39.259987 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:20:40.634070 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:20:40.688076 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3905
I1210 09:20:40.688076 16412 solver.cpp:397]     Test net output #1: loss = 2.40127 (* 1 = 2.40127 loss)
I1210 09:20:40.742075 16412 solver.cpp:218] Iteration 9000 (14.0295 iter/s, 7.12786s/100 iters), loss = 1.90077
I1210 09:20:40.742075 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:20:40.742075 16412 solver.cpp:237]     Train net output #1: loss = 1.90077 (* 1 = 1.90077 loss)
I1210 09:20:40.742075 16412 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1210 09:20:46.426532 16412 solver.cpp:218] Iteration 9100 (17.5923 iter/s, 5.68431s/100 iters), loss = 1.77365
I1210 09:20:46.426532 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:20:46.426532 16412 solver.cpp:237]     Train net output #1: loss = 1.77365 (* 1 = 1.77365 loss)
I1210 09:20:46.426532 16412 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1210 09:20:52.103924 16412 solver.cpp:218] Iteration 9200 (17.6166 iter/s, 5.67647s/100 iters), loss = 1.43706
I1210 09:20:52.103924 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:20:52.103924 16412 solver.cpp:237]     Train net output #1: loss = 1.43706 (* 1 = 1.43706 loss)
I1210 09:20:52.103924 16412 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1210 09:20:57.887683 16412 solver.cpp:218] Iteration 9300 (17.29 iter/s, 5.78371s/100 iters), loss = 1.86206
I1210 09:20:57.887683 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:20:57.887683 16412 solver.cpp:237]     Train net output #1: loss = 1.86206 (* 1 = 1.86206 loss)
I1210 09:20:57.887683 16412 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1210 09:21:03.659121 16412 solver.cpp:218] Iteration 9400 (17.3293 iter/s, 5.77059s/100 iters), loss = 1.98336
I1210 09:21:03.659121 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:21:03.659121 16412 solver.cpp:237]     Train net output #1: loss = 1.98336 (* 1 = 1.98336 loss)
I1210 09:21:03.659121 16412 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1210 09:21:09.071643  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:21:09.294327 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_9500.caffemodel
I1210 09:21:09.309937 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_9500.solverstate
I1210 09:21:09.313946 16412 solver.cpp:330] Iteration 9500, Testing net (#0)
I1210 09:21:09.313946 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:21:10.687858 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:21:10.741142 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2846
I1210 09:21:10.741142 16412 solver.cpp:397]     Test net output #1: loss = 3.06225 (* 1 = 3.06225 loss)
I1210 09:21:10.797636 16412 solver.cpp:218] Iteration 9500 (14.0092 iter/s, 7.13817s/100 iters), loss = 1.86044
I1210 09:21:10.797636 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:21:10.797636 16412 solver.cpp:237]     Train net output #1: loss = 1.86044 (* 1 = 1.86044 loss)
I1210 09:21:10.797636 16412 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1210 09:21:16.471971 16412 solver.cpp:218] Iteration 9600 (17.6228 iter/s, 5.67446s/100 iters), loss = 1.75407
I1210 09:21:16.471971 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:21:16.471971 16412 solver.cpp:237]     Train net output #1: loss = 1.75407 (* 1 = 1.75407 loss)
I1210 09:21:16.471971 16412 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1210 09:21:22.160363 16412 solver.cpp:218] Iteration 9700 (17.5829 iter/s, 5.68735s/100 iters), loss = 1.57123
I1210 09:21:22.160363 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:21:22.160363 16412 solver.cpp:237]     Train net output #1: loss = 1.57123 (* 1 = 1.57123 loss)
I1210 09:21:22.160363 16412 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1210 09:21:27.841876 16412 solver.cpp:218] Iteration 9800 (17.6026 iter/s, 5.68098s/100 iters), loss = 1.83862
I1210 09:21:27.841876 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:21:27.841876 16412 solver.cpp:237]     Train net output #1: loss = 1.83862 (* 1 = 1.83862 loss)
I1210 09:21:27.841876 16412 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1210 09:21:33.519372 16412 solver.cpp:218] Iteration 9900 (17.6136 iter/s, 5.67744s/100 iters), loss = 2.00537
I1210 09:21:33.519372 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:21:33.519372 16412 solver.cpp:237]     Train net output #1: loss = 2.00537 (* 1 = 2.00537 loss)
I1210 09:21:33.519372 16412 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1210 09:21:38.927798  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:21:39.150809 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_10000.caffemodel
I1210 09:21:39.164808 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_10000.solverstate
I1210 09:21:39.169809 16412 solver.cpp:330] Iteration 10000, Testing net (#0)
I1210 09:21:39.169809 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:21:40.549924 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:21:40.603929 16412 solver.cpp:397]     Test net output #0: accuracy = 0.32
I1210 09:21:40.603929 16412 solver.cpp:397]     Test net output #1: loss = 2.91481 (* 1 = 2.91481 loss)
I1210 09:21:40.657930 16412 solver.cpp:218] Iteration 10000 (14.0099 iter/s, 7.13782s/100 iters), loss = 1.67553
I1210 09:21:40.657930 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:21:40.657930 16412 solver.cpp:237]     Train net output #1: loss = 1.67553 (* 1 = 1.67553 loss)
I1210 09:21:40.657930 16412 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1210 09:21:46.344454 16412 solver.cpp:218] Iteration 10100 (17.5852 iter/s, 5.68661s/100 iters), loss = 1.6462
I1210 09:21:46.344454 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 09:21:46.344454 16412 solver.cpp:237]     Train net output #1: loss = 1.6462 (* 1 = 1.6462 loss)
I1210 09:21:46.344454 16412 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1210 09:21:52.035944 16412 solver.cpp:218] Iteration 10200 (17.5727 iter/s, 5.69063s/100 iters), loss = 1.37954
I1210 09:21:52.035944 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:21:52.035944 16412 solver.cpp:237]     Train net output #1: loss = 1.37954 (* 1 = 1.37954 loss)
I1210 09:21:52.035944 16412 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1210 09:21:57.723498 16412 solver.cpp:218] Iteration 10300 (17.5828 iter/s, 5.68737s/100 iters), loss = 1.94486
I1210 09:21:57.723498 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:21:57.724480 16412 solver.cpp:237]     Train net output #1: loss = 1.94486 (* 1 = 1.94486 loss)
I1210 09:21:57.724480 16412 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1210 09:22:03.479595 16412 solver.cpp:218] Iteration 10400 (17.3764 iter/s, 5.75495s/100 iters), loss = 1.99053
I1210 09:22:03.479595 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:22:03.479595 16412 solver.cpp:237]     Train net output #1: loss = 1.99053 (* 1 = 1.99053 loss)
I1210 09:22:03.479595 16412 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1210 09:22:09.053038  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:22:09.277048 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_10500.caffemodel
I1210 09:22:09.292049 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_10500.solverstate
I1210 09:22:09.296049 16412 solver.cpp:330] Iteration 10500, Testing net (#0)
I1210 09:22:09.297049 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:22:10.672165 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:22:10.726176 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3767
I1210 09:22:10.726176 16412 solver.cpp:397]     Test net output #1: loss = 2.44461 (* 1 = 2.44461 loss)
I1210 09:22:10.780174 16412 solver.cpp:218] Iteration 10500 (13.6977 iter/s, 7.30048s/100 iters), loss = 1.77228
I1210 09:22:10.780174 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:22:10.780174 16412 solver.cpp:237]     Train net output #1: loss = 1.77228 (* 1 = 1.77228 loss)
I1210 09:22:10.780174 16412 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1210 09:22:16.490706 16412 solver.cpp:218] Iteration 10600 (17.514 iter/s, 5.70971s/100 iters), loss = 1.69974
I1210 09:22:16.490706 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:22:16.490706 16412 solver.cpp:237]     Train net output #1: loss = 1.69974 (* 1 = 1.69974 loss)
I1210 09:22:16.490706 16412 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1210 09:22:22.378350 16412 solver.cpp:218] Iteration 10700 (16.9841 iter/s, 5.88788s/100 iters), loss = 1.39926
I1210 09:22:22.379351 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:22:22.379351 16412 solver.cpp:237]     Train net output #1: loss = 1.39926 (* 1 = 1.39926 loss)
I1210 09:22:22.379351 16412 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1210 09:22:28.078824 16412 solver.cpp:218] Iteration 10800 (17.5458 iter/s, 5.69937s/100 iters), loss = 1.84552
I1210 09:22:28.078824 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:22:28.078824 16412 solver.cpp:237]     Train net output #1: loss = 1.84552 (* 1 = 1.84552 loss)
I1210 09:22:28.078824 16412 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1210 09:22:33.759171 16412 solver.cpp:218] Iteration 10900 (17.6058 iter/s, 5.67994s/100 iters), loss = 1.87804
I1210 09:22:33.759171 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:22:33.759171 16412 solver.cpp:237]     Train net output #1: loss = 1.87804 (* 1 = 1.87804 loss)
I1210 09:22:33.759171 16412 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1210 09:22:39.157788  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:22:39.380798 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_11000.caffemodel
I1210 09:22:39.396798 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_11000.solverstate
I1210 09:22:39.401799 16412 solver.cpp:330] Iteration 11000, Testing net (#0)
I1210 09:22:39.401799 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:22:40.776201 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:22:40.830209 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2902
I1210 09:22:40.830209 16412 solver.cpp:397]     Test net output #1: loss = 3.21166 (* 1 = 3.21166 loss)
I1210 09:22:40.884208 16412 solver.cpp:218] Iteration 11000 (14.0356 iter/s, 7.12476s/100 iters), loss = 1.82344
I1210 09:22:40.884208 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:22:40.884208 16412 solver.cpp:237]     Train net output #1: loss = 1.82344 (* 1 = 1.82344 loss)
I1210 09:22:40.884208 16412 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1210 09:22:46.561674 16412 solver.cpp:218] Iteration 11100 (17.6132 iter/s, 5.67755s/100 iters), loss = 1.67777
I1210 09:22:46.562675 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:22:46.562675 16412 solver.cpp:237]     Train net output #1: loss = 1.67777 (* 1 = 1.67777 loss)
I1210 09:22:46.562675 16412 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1210 09:22:52.240078 16412 solver.cpp:218] Iteration 11200 (17.6151 iter/s, 5.67694s/100 iters), loss = 1.4699
I1210 09:22:52.240078 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:22:52.240078 16412 solver.cpp:237]     Train net output #1: loss = 1.4699 (* 1 = 1.4699 loss)
I1210 09:22:52.240078 16412 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1210 09:22:57.940460 16412 solver.cpp:218] Iteration 11300 (17.5441 iter/s, 5.69992s/100 iters), loss = 1.85168
I1210 09:22:57.940460 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:22:57.940460 16412 solver.cpp:237]     Train net output #1: loss = 1.85168 (* 1 = 1.85168 loss)
I1210 09:22:57.940460 16412 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1210 09:23:03.672972 16412 solver.cpp:218] Iteration 11400 (17.4438 iter/s, 5.7327s/100 iters), loss = 1.97432
I1210 09:23:03.672972 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1210 09:23:03.672972 16412 solver.cpp:237]     Train net output #1: loss = 1.97432 (* 1 = 1.97432 loss)
I1210 09:23:03.672972 16412 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1210 09:23:09.094395  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:23:09.316419 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_11500.caffemodel
I1210 09:23:09.330430 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_11500.solverstate
I1210 09:23:09.335430 16412 solver.cpp:330] Iteration 11500, Testing net (#0)
I1210 09:23:09.335430 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:23:10.722015 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:23:10.775019 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3931
I1210 09:23:10.775019 16412 solver.cpp:397]     Test net output #1: loss = 2.34535 (* 1 = 2.34535 loss)
I1210 09:23:10.829025 16412 solver.cpp:218] Iteration 11500 (13.9746 iter/s, 7.15585s/100 iters), loss = 1.87705
I1210 09:23:10.830024 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:23:10.830024 16412 solver.cpp:237]     Train net output #1: loss = 1.87705 (* 1 = 1.87705 loss)
I1210 09:23:10.830024 16412 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1210 09:23:16.526406 16412 solver.cpp:218] Iteration 11600 (17.5533 iter/s, 5.69692s/100 iters), loss = 1.70531
I1210 09:23:16.527405 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:23:16.527405 16412 solver.cpp:237]     Train net output #1: loss = 1.70531 (* 1 = 1.70531 loss)
I1210 09:23:16.527405 16412 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1210 09:23:22.229975 16412 solver.cpp:218] Iteration 11700 (17.5357 iter/s, 5.70264s/100 iters), loss = 1.39983
I1210 09:23:22.229975 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:23:22.229975 16412 solver.cpp:237]     Train net output #1: loss = 1.39983 (* 1 = 1.39983 loss)
I1210 09:23:22.229975 16412 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1210 09:23:28.016007 16412 solver.cpp:218] Iteration 11800 (17.2848 iter/s, 5.78545s/100 iters), loss = 2.01074
I1210 09:23:28.016507 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:23:28.016507 16412 solver.cpp:237]     Train net output #1: loss = 2.01074 (* 1 = 2.01074 loss)
I1210 09:23:28.016507 16412 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1210 09:23:33.869825 16412 solver.cpp:218] Iteration 11900 (17.0858 iter/s, 5.85283s/100 iters), loss = 1.94019
I1210 09:23:33.869825 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1210 09:23:33.869825 16412 solver.cpp:237]     Train net output #1: loss = 1.94019 (* 1 = 1.94019 loss)
I1210 09:23:33.869825 16412 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1210 09:23:39.291508  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:23:39.522630 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_12000.caffemodel
I1210 09:23:39.537709 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_12000.solverstate
I1210 09:23:39.542711 16412 solver.cpp:330] Iteration 12000, Testing net (#0)
I1210 09:23:39.542711 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:23:40.967615 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:23:41.024137 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3937
I1210 09:23:41.024137 16412 solver.cpp:397]     Test net output #1: loss = 2.35309 (* 1 = 2.35309 loss)
I1210 09:23:41.080765 16412 solver.cpp:218] Iteration 12000 (13.8683 iter/s, 7.21068s/100 iters), loss = 1.83681
I1210 09:23:41.080765 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:23:41.080765 16412 solver.cpp:237]     Train net output #1: loss = 1.83681 (* 1 = 1.83681 loss)
I1210 09:23:41.080765 16412 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1210 09:23:46.902473 16412 solver.cpp:218] Iteration 12100 (17.1777 iter/s, 5.82152s/100 iters), loss = 1.49275
I1210 09:23:46.902473 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:23:46.902473 16412 solver.cpp:237]     Train net output #1: loss = 1.49275 (* 1 = 1.49275 loss)
I1210 09:23:46.902473 16412 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1210 09:23:52.603924 16412 solver.cpp:218] Iteration 12200 (17.5402 iter/s, 5.7012s/100 iters), loss = 1.41917
I1210 09:23:52.603924 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:23:52.603924 16412 solver.cpp:237]     Train net output #1: loss = 1.41917 (* 1 = 1.41917 loss)
I1210 09:23:52.603924 16412 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1210 09:23:58.273208 16412 solver.cpp:218] Iteration 12300 (17.6415 iter/s, 5.66845s/100 iters), loss = 1.8596
I1210 09:23:58.273208 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:23:58.273208 16412 solver.cpp:237]     Train net output #1: loss = 1.8596 (* 1 = 1.8596 loss)
I1210 09:23:58.273208 16412 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1210 09:24:03.939157 16412 solver.cpp:218] Iteration 12400 (17.652 iter/s, 5.66509s/100 iters), loss = 1.85102
I1210 09:24:03.939157 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:24:03.939157 16412 solver.cpp:237]     Train net output #1: loss = 1.85102 (* 1 = 1.85102 loss)
I1210 09:24:03.939157 16412 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1210 09:24:09.355783  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:24:09.578330 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_12500.caffemodel
I1210 09:24:09.591331 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_12500.solverstate
I1210 09:24:09.595351 16412 solver.cpp:330] Iteration 12500, Testing net (#0)
I1210 09:24:09.595351 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:24:10.966531 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:24:11.022532 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4036
I1210 09:24:11.022532 16412 solver.cpp:397]     Test net output #1: loss = 2.36183 (* 1 = 2.36183 loss)
I1210 09:24:11.077046 16412 solver.cpp:218] Iteration 12500 (14.0102 iter/s, 7.13766s/100 iters), loss = 1.70508
I1210 09:24:11.077046 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:24:11.077046 16412 solver.cpp:237]     Train net output #1: loss = 1.70508 (* 1 = 1.70508 loss)
I1210 09:24:11.077046 16412 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1210 09:24:16.776808 16412 solver.cpp:218] Iteration 12600 (17.5465 iter/s, 5.69913s/100 iters), loss = 1.67079
I1210 09:24:16.776808 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:24:16.776808 16412 solver.cpp:237]     Train net output #1: loss = 1.67079 (* 1 = 1.67079 loss)
I1210 09:24:16.776808 16412 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1210 09:24:22.550279 16412 solver.cpp:218] Iteration 12700 (17.3219 iter/s, 5.77304s/100 iters), loss = 1.37114
I1210 09:24:22.550279 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:24:22.550279 16412 solver.cpp:237]     Train net output #1: loss = 1.37114 (* 1 = 1.37114 loss)
I1210 09:24:22.550279 16412 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1210 09:24:28.383642 16412 solver.cpp:218] Iteration 12800 (17.1426 iter/s, 5.83342s/100 iters), loss = 1.86758
I1210 09:24:28.383642 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:24:28.383642 16412 solver.cpp:237]     Train net output #1: loss = 1.86758 (* 1 = 1.86758 loss)
I1210 09:24:28.383642 16412 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1210 09:24:34.070150 16412 solver.cpp:218] Iteration 12900 (17.5863 iter/s, 5.68623s/100 iters), loss = 1.97184
I1210 09:24:34.070150 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:24:34.070150 16412 solver.cpp:237]     Train net output #1: loss = 1.97184 (* 1 = 1.97184 loss)
I1210 09:24:34.071151 16412 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1210 09:24:39.707690  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:24:39.934717 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_13000.caffemodel
I1210 09:24:39.948725 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_13000.solverstate
I1210 09:24:39.952724 16412 solver.cpp:330] Iteration 13000, Testing net (#0)
I1210 09:24:39.953725 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:24:41.325870 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:24:41.378876 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3908
I1210 09:24:41.378876 16412 solver.cpp:397]     Test net output #1: loss = 2.38963 (* 1 = 2.38963 loss)
I1210 09:24:41.435379 16412 solver.cpp:218] Iteration 13000 (13.5795 iter/s, 7.36402s/100 iters), loss = 1.67296
I1210 09:24:41.435379 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:24:41.435379 16412 solver.cpp:237]     Train net output #1: loss = 1.67296 (* 1 = 1.67296 loss)
I1210 09:24:41.435379 16412 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1210 09:24:47.130228 16412 solver.cpp:218] Iteration 13100 (17.5604 iter/s, 5.69464s/100 iters), loss = 1.70345
I1210 09:24:47.130228 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:24:47.130228 16412 solver.cpp:237]     Train net output #1: loss = 1.70345 (* 1 = 1.70345 loss)
I1210 09:24:47.130728 16412 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1210 09:24:52.846784 16412 solver.cpp:218] Iteration 13200 (17.4938 iter/s, 5.71631s/100 iters), loss = 1.46396
I1210 09:24:52.846784 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:24:52.846784 16412 solver.cpp:237]     Train net output #1: loss = 1.46396 (* 1 = 1.46396 loss)
I1210 09:24:52.846784 16412 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1210 09:24:58.622320 16412 solver.cpp:218] Iteration 13300 (17.3154 iter/s, 5.77521s/100 iters), loss = 1.88594
I1210 09:24:58.622320 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:24:58.622320 16412 solver.cpp:237]     Train net output #1: loss = 1.88594 (* 1 = 1.88594 loss)
I1210 09:24:58.622320 16412 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1210 09:25:04.428808 16412 solver.cpp:218] Iteration 13400 (17.2235 iter/s, 5.80601s/100 iters), loss = 1.92255
I1210 09:25:04.429810 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:25:04.429810 16412 solver.cpp:237]     Train net output #1: loss = 1.92255 (* 1 = 1.92255 loss)
I1210 09:25:04.429810 16412 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1210 09:25:09.835472  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:25:10.061484 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_13500.caffemodel
I1210 09:25:10.077486 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_13500.solverstate
I1210 09:25:10.081485 16412 solver.cpp:330] Iteration 13500, Testing net (#0)
I1210 09:25:10.081485 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:25:11.451656 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:25:11.504647 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2663
I1210 09:25:11.504647 16412 solver.cpp:397]     Test net output #1: loss = 3.37172 (* 1 = 3.37172 loss)
I1210 09:25:11.560082 16412 solver.cpp:218] Iteration 13500 (14.0254 iter/s, 7.12992s/100 iters), loss = 1.76071
I1210 09:25:11.560082 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:25:11.560082 16412 solver.cpp:237]     Train net output #1: loss = 1.76071 (* 1 = 1.76071 loss)
I1210 09:25:11.560082 16412 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1210 09:25:17.252161 16412 solver.cpp:218] Iteration 13600 (17.5682 iter/s, 5.69211s/100 iters), loss = 1.67707
I1210 09:25:17.252161 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:25:17.252161 16412 solver.cpp:237]     Train net output #1: loss = 1.67707 (* 1 = 1.67707 loss)
I1210 09:25:17.252161 16412 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1210 09:25:22.940621 16412 solver.cpp:218] Iteration 13700 (17.5822 iter/s, 5.68757s/100 iters), loss = 1.26494
I1210 09:25:22.940621 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:25:22.940621 16412 solver.cpp:237]     Train net output #1: loss = 1.26494 (* 1 = 1.26494 loss)
I1210 09:25:22.940621 16412 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1210 09:25:28.676071 16412 solver.cpp:218] Iteration 13800 (17.4367 iter/s, 5.73505s/100 iters), loss = 1.80478
I1210 09:25:28.676071 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:25:28.676071 16412 solver.cpp:237]     Train net output #1: loss = 1.80478 (* 1 = 1.80478 loss)
I1210 09:25:28.676071 16412 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1210 09:25:34.417356 16412 solver.cpp:218] Iteration 13900 (17.4186 iter/s, 5.74098s/100 iters), loss = 2.04251
I1210 09:25:34.417356 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:25:34.417356 16412 solver.cpp:237]     Train net output #1: loss = 2.04251 (* 1 = 2.04251 loss)
I1210 09:25:34.417356 16412 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1210 09:25:39.901846  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:25:40.126855 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_14000.caffemodel
I1210 09:25:40.140856 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_14000.solverstate
I1210 09:25:40.145856 16412 solver.cpp:330] Iteration 14000, Testing net (#0)
I1210 09:25:40.145856 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:25:41.514968 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:25:41.568972 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4294
I1210 09:25:41.568972 16412 solver.cpp:397]     Test net output #1: loss = 2.23698 (* 1 = 2.23698 loss)
I1210 09:25:41.622972 16412 solver.cpp:218] Iteration 14000 (13.8792 iter/s, 7.20501s/100 iters), loss = 1.65368
I1210 09:25:41.622972 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:25:41.622972 16412 solver.cpp:237]     Train net output #1: loss = 1.65368 (* 1 = 1.65368 loss)
I1210 09:25:41.622972 16412 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1210 09:25:47.311365 16412 solver.cpp:218] Iteration 14100 (17.5808 iter/s, 5.68803s/100 iters), loss = 1.55478
I1210 09:25:47.311365 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:25:47.311365 16412 solver.cpp:237]     Train net output #1: loss = 1.55478 (* 1 = 1.55478 loss)
I1210 09:25:47.311365 16412 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1210 09:25:53.010756 16412 solver.cpp:218] Iteration 14200 (17.546 iter/s, 5.69929s/100 iters), loss = 1.44104
I1210 09:25:53.010756 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:25:53.010756 16412 solver.cpp:237]     Train net output #1: loss = 1.44104 (* 1 = 1.44104 loss)
I1210 09:25:53.010756 16412 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1210 09:25:58.765162 16412 solver.cpp:218] Iteration 14300 (17.3783 iter/s, 5.75429s/100 iters), loss = 1.73015
I1210 09:25:58.765162 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:25:58.765162 16412 solver.cpp:237]     Train net output #1: loss = 1.73015 (* 1 = 1.73015 loss)
I1210 09:25:58.765162 16412 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1210 09:26:04.476713 16412 solver.cpp:218] Iteration 14400 (17.5115 iter/s, 5.71052s/100 iters), loss = 1.94774
I1210 09:26:04.476713 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:26:04.476713 16412 solver.cpp:237]     Train net output #1: loss = 1.94774 (* 1 = 1.94774 loss)
I1210 09:26:04.476713 16412 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1210 09:26:09.900401  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:26:10.121417 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_14500.caffemodel
I1210 09:26:10.137429 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_14500.solverstate
I1210 09:26:10.142421 16412 solver.cpp:330] Iteration 14500, Testing net (#0)
I1210 09:26:10.142421 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:26:11.518589 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:26:11.571595 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3774
I1210 09:26:11.571595 16412 solver.cpp:397]     Test net output #1: loss = 2.39585 (* 1 = 2.39585 loss)
I1210 09:26:11.625594 16412 solver.cpp:218] Iteration 14500 (13.9891 iter/s, 7.14843s/100 iters), loss = 1.6204
I1210 09:26:11.625594 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:26:11.625594 16412 solver.cpp:237]     Train net output #1: loss = 1.6204 (* 1 = 1.6204 loss)
I1210 09:26:11.625594 16412 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1210 09:26:17.320344 16412 solver.cpp:218] Iteration 14600 (17.561 iter/s, 5.69444s/100 iters), loss = 1.72013
I1210 09:26:17.320344 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:26:17.320344 16412 solver.cpp:237]     Train net output #1: loss = 1.72013 (* 1 = 1.72013 loss)
I1210 09:26:17.320344 16412 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1210 09:26:23.081203 16412 solver.cpp:218] Iteration 14700 (17.3591 iter/s, 5.76065s/100 iters), loss = 1.3982
I1210 09:26:23.081203 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:26:23.081203 16412 solver.cpp:237]     Train net output #1: loss = 1.3982 (* 1 = 1.3982 loss)
I1210 09:26:23.081203 16412 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1210 09:26:28.854997 16412 solver.cpp:218] Iteration 14800 (17.3232 iter/s, 5.77261s/100 iters), loss = 1.9408
I1210 09:26:28.854997 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:26:28.854997 16412 solver.cpp:237]     Train net output #1: loss = 1.9408 (* 1 = 1.9408 loss)
I1210 09:26:28.854997 16412 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1210 09:26:34.602927 16412 solver.cpp:218] Iteration 14900 (17.3971 iter/s, 5.74809s/100 iters), loss = 2.08957
I1210 09:26:34.602927 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:26:34.602927 16412 solver.cpp:237]     Train net output #1: loss = 2.08957 (* 1 = 2.08957 loss)
I1210 09:26:34.602927 16412 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1210 09:26:40.098568  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:26:40.327548 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_15000.caffemodel
I1210 09:26:40.342548 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_15000.solverstate
I1210 09:26:40.347549 16412 solver.cpp:330] Iteration 15000, Testing net (#0)
I1210 09:26:40.347549 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:26:41.729256 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:26:41.782310 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2847
I1210 09:26:41.782310 16412 solver.cpp:397]     Test net output #1: loss = 3.26327 (* 1 = 3.26327 loss)
I1210 09:26:41.838305 16412 solver.cpp:218] Iteration 15000 (13.8216 iter/s, 7.23506s/100 iters), loss = 1.7899
I1210 09:26:41.838305 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:26:41.838305 16412 solver.cpp:237]     Train net output #1: loss = 1.7899 (* 1 = 1.7899 loss)
I1210 09:26:41.838305 16412 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1210 09:26:47.626273 16412 solver.cpp:218] Iteration 15100 (17.2795 iter/s, 5.78721s/100 iters), loss = 1.50789
I1210 09:26:47.626273 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:26:47.626273 16412 solver.cpp:237]     Train net output #1: loss = 1.50789 (* 1 = 1.50789 loss)
I1210 09:26:47.626273 16412 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1210 09:26:53.403228 16412 solver.cpp:218] Iteration 15200 (17.3113 iter/s, 5.77656s/100 iters), loss = 1.29293
I1210 09:26:53.403228 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:26:53.403228 16412 solver.cpp:237]     Train net output #1: loss = 1.29293 (* 1 = 1.29293 loss)
I1210 09:26:53.403228 16412 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1210 09:26:59.111955 16412 solver.cpp:218] Iteration 15300 (17.5202 iter/s, 5.7077s/100 iters), loss = 1.70753
I1210 09:26:59.111955 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:26:59.111955 16412 solver.cpp:237]     Train net output #1: loss = 1.70753 (* 1 = 1.70753 loss)
I1210 09:26:59.111955 16412 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1210 09:27:04.789216 16412 solver.cpp:218] Iteration 15400 (17.6141 iter/s, 5.67726s/100 iters), loss = 1.90491
I1210 09:27:04.789216 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:27:04.789216 16412 solver.cpp:237]     Train net output #1: loss = 1.90491 (* 1 = 1.90491 loss)
I1210 09:27:04.789216 16412 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1210 09:27:10.243026  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:27:10.469045 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_15500.caffemodel
I1210 09:27:10.484055 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_15500.solverstate
I1210 09:27:10.488555 16412 solver.cpp:330] Iteration 15500, Testing net (#0)
I1210 09:27:10.488555 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:27:11.865545 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:27:11.919551 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4093
I1210 09:27:11.920553 16412 solver.cpp:397]     Test net output #1: loss = 2.25895 (* 1 = 2.25895 loss)
I1210 09:27:11.979063 16412 solver.cpp:218] Iteration 15500 (13.9096 iter/s, 7.18929s/100 iters), loss = 1.64197
I1210 09:27:11.979562 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:27:11.979562 16412 solver.cpp:237]     Train net output #1: loss = 1.64197 (* 1 = 1.64197 loss)
I1210 09:27:11.979562 16412 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1210 09:27:17.686363 16412 solver.cpp:218] Iteration 15600 (17.5244 iter/s, 5.70632s/100 iters), loss = 1.63629
I1210 09:27:17.686363 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:27:17.686363 16412 solver.cpp:237]     Train net output #1: loss = 1.63629 (* 1 = 1.63629 loss)
I1210 09:27:17.686363 16412 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1210 09:27:23.358638 16412 solver.cpp:218] Iteration 15700 (17.6296 iter/s, 5.67228s/100 iters), loss = 1.2454
I1210 09:27:23.358638 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:27:23.358638 16412 solver.cpp:237]     Train net output #1: loss = 1.2454 (* 1 = 1.2454 loss)
I1210 09:27:23.358638 16412 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1210 09:27:29.051808 16412 solver.cpp:218] Iteration 15800 (17.5672 iter/s, 5.69244s/100 iters), loss = 1.69516
I1210 09:27:29.051808 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:27:29.051808 16412 solver.cpp:237]     Train net output #1: loss = 1.69516 (* 1 = 1.69516 loss)
I1210 09:27:29.051808 16412 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1210 09:27:34.831313 16412 solver.cpp:218] Iteration 15900 (17.3042 iter/s, 5.77894s/100 iters), loss = 1.9174
I1210 09:27:34.831313 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:27:34.831313 16412 solver.cpp:237]     Train net output #1: loss = 1.9174 (* 1 = 1.9174 loss)
I1210 09:27:34.831313 16412 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1210 09:27:40.268245  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:27:40.494267 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_16000.caffemodel
I1210 09:27:40.508266 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_16000.solverstate
I1210 09:27:40.512267 16412 solver.cpp:330] Iteration 16000, Testing net (#0)
I1210 09:27:40.512267 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:27:41.915496 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:27:41.970531 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4255
I1210 09:27:41.971524 16412 solver.cpp:397]     Test net output #1: loss = 2.17549 (* 1 = 2.17549 loss)
I1210 09:27:42.026522 16412 solver.cpp:218] Iteration 16000 (13.899 iter/s, 7.19478s/100 iters), loss = 1.71404
I1210 09:27:42.026522 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:27:42.026522 16412 solver.cpp:237]     Train net output #1: loss = 1.71404 (* 1 = 1.71404 loss)
I1210 09:27:42.026522 16412 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1210 09:27:47.885960 16412 solver.cpp:218] Iteration 16100 (17.0665 iter/s, 5.85944s/100 iters), loss = 1.53854
I1210 09:27:47.885960 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:27:47.885960 16412 solver.cpp:237]     Train net output #1: loss = 1.53854 (* 1 = 1.53854 loss)
I1210 09:27:47.885960 16412 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1210 09:27:53.616922 16412 solver.cpp:218] Iteration 16200 (17.4508 iter/s, 5.73038s/100 iters), loss = 1.4178
I1210 09:27:53.616922 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:27:53.616922 16412 solver.cpp:237]     Train net output #1: loss = 1.4178 (* 1 = 1.4178 loss)
I1210 09:27:53.616922 16412 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1210 09:27:59.442761 16412 solver.cpp:218] Iteration 16300 (17.1682 iter/s, 5.82474s/100 iters), loss = 1.81278
I1210 09:27:59.442761 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:27:59.442761 16412 solver.cpp:237]     Train net output #1: loss = 1.81278 (* 1 = 1.81278 loss)
I1210 09:27:59.442761 16412 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1210 09:28:05.131480 16412 solver.cpp:218] Iteration 16400 (17.5774 iter/s, 5.68911s/100 iters), loss = 2.02232
I1210 09:28:05.131480 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1210 09:28:05.131480 16412 solver.cpp:237]     Train net output #1: loss = 2.02232 (* 1 = 2.02232 loss)
I1210 09:28:05.132483 16412 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1210 09:28:10.541988  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:28:10.763523 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_16500.caffemodel
I1210 09:28:10.777523 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_16500.solverstate
I1210 09:28:10.782524 16412 solver.cpp:330] Iteration 16500, Testing net (#0)
I1210 09:28:10.782524 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:28:12.158681 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:28:12.211680 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4123
I1210 09:28:12.211680 16412 solver.cpp:397]     Test net output #1: loss = 2.22822 (* 1 = 2.22822 loss)
I1210 09:28:12.265692 16412 solver.cpp:218] Iteration 16500 (14.0197 iter/s, 7.1328s/100 iters), loss = 1.69485
I1210 09:28:12.265692 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:28:12.265692 16412 solver.cpp:237]     Train net output #1: loss = 1.69485 (* 1 = 1.69485 loss)
I1210 09:28:12.265692 16412 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1210 09:28:17.954510 16412 solver.cpp:218] Iteration 16600 (17.5796 iter/s, 5.68841s/100 iters), loss = 1.60294
I1210 09:28:17.954510 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:28:17.954510 16412 solver.cpp:237]     Train net output #1: loss = 1.60294 (* 1 = 1.60294 loss)
I1210 09:28:17.954510 16412 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1210 09:28:23.633636 16412 solver.cpp:218] Iteration 16700 (17.6088 iter/s, 5.67899s/100 iters), loss = 1.37229
I1210 09:28:23.633636 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:28:23.633636 16412 solver.cpp:237]     Train net output #1: loss = 1.37229 (* 1 = 1.37229 loss)
I1210 09:28:23.633636 16412 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1210 09:28:29.340412 16412 solver.cpp:218] Iteration 16800 (17.525 iter/s, 5.70614s/100 iters), loss = 1.82653
I1210 09:28:29.340412 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:28:29.340412 16412 solver.cpp:237]     Train net output #1: loss = 1.82653 (* 1 = 1.82653 loss)
I1210 09:28:29.340412 16412 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1210 09:28:35.085515 16412 solver.cpp:218] Iteration 16900 (17.4056 iter/s, 5.74527s/100 iters), loss = 1.75205
I1210 09:28:35.085515 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:28:35.085515 16412 solver.cpp:237]     Train net output #1: loss = 1.75205 (* 1 = 1.75205 loss)
I1210 09:28:35.086514 16412 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1210 09:28:40.562484  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:28:40.787505 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_17000.caffemodel
I1210 09:28:40.801506 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_17000.solverstate
I1210 09:28:40.805505 16412 solver.cpp:330] Iteration 17000, Testing net (#0)
I1210 09:28:40.806507 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:28:42.178643 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:28:42.234149 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3798
I1210 09:28:42.234149 16412 solver.cpp:397]     Test net output #1: loss = 2.45013 (* 1 = 2.45013 loss)
I1210 09:28:42.287667 16412 solver.cpp:218] Iteration 17000 (13.8874 iter/s, 7.20078s/100 iters), loss = 1.77639
I1210 09:28:42.287667 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:28:42.287667 16412 solver.cpp:237]     Train net output #1: loss = 1.77639 (* 1 = 1.77639 loss)
I1210 09:28:42.287667 16412 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1210 09:28:47.987052 16412 solver.cpp:218] Iteration 17100 (17.5462 iter/s, 5.69924s/100 iters), loss = 1.62935
I1210 09:28:47.987052 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:28:47.987052 16412 solver.cpp:237]     Train net output #1: loss = 1.62935 (* 1 = 1.62935 loss)
I1210 09:28:47.987052 16412 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1210 09:28:53.718380 16412 solver.cpp:218] Iteration 17200 (17.4485 iter/s, 5.73115s/100 iters), loss = 1.42425
I1210 09:28:53.718380 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:28:53.718380 16412 solver.cpp:237]     Train net output #1: loss = 1.42425 (* 1 = 1.42425 loss)
I1210 09:28:53.718380 16412 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1210 09:28:59.509778 16412 solver.cpp:218] Iteration 17300 (17.2698 iter/s, 5.79045s/100 iters), loss = 1.7588
I1210 09:28:59.509778 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:28:59.509778 16412 solver.cpp:237]     Train net output #1: loss = 1.7588 (* 1 = 1.7588 loss)
I1210 09:28:59.509778 16412 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1210 09:29:05.246192 16412 solver.cpp:218] Iteration 17400 (17.4331 iter/s, 5.73623s/100 iters), loss = 1.8729
I1210 09:29:05.246192 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:29:05.246192 16412 solver.cpp:237]     Train net output #1: loss = 1.8729 (* 1 = 1.8729 loss)
I1210 09:29:05.246192 16412 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1210 09:29:10.674043  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:29:10.897567 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_17500.caffemodel
I1210 09:29:10.912559 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_17500.solverstate
I1210 09:29:10.917559 16412 solver.cpp:330] Iteration 17500, Testing net (#0)
I1210 09:29:10.917559 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:29:12.289705 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:29:12.343710 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4363
I1210 09:29:12.343710 16412 solver.cpp:397]     Test net output #1: loss = 2.16731 (* 1 = 2.16731 loss)
I1210 09:29:12.399708 16412 solver.cpp:218] Iteration 17500 (13.98 iter/s, 7.1531s/100 iters), loss = 1.58823
I1210 09:29:12.399708 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:29:12.399708 16412 solver.cpp:237]     Train net output #1: loss = 1.58823 (* 1 = 1.58823 loss)
I1210 09:29:12.399708 16412 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1210 09:29:18.095190 16412 solver.cpp:218] Iteration 17600 (17.5591 iter/s, 5.69505s/100 iters), loss = 1.54095
I1210 09:29:18.095190 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:29:18.095190 16412 solver.cpp:237]     Train net output #1: loss = 1.54095 (* 1 = 1.54095 loss)
I1210 09:29:18.095190 16412 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1210 09:29:23.788666 16412 solver.cpp:218] Iteration 17700 (17.5661 iter/s, 5.6928s/100 iters), loss = 1.38778
I1210 09:29:23.788666 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:29:23.789167 16412 solver.cpp:237]     Train net output #1: loss = 1.38778 (* 1 = 1.38778 loss)
I1210 09:29:23.789167 16412 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1210 09:29:29.479110 16412 solver.cpp:218] Iteration 17800 (17.5751 iter/s, 5.68988s/100 iters), loss = 1.82023
I1210 09:29:29.479110 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:29:29.479110 16412 solver.cpp:237]     Train net output #1: loss = 1.82023 (* 1 = 1.82023 loss)
I1210 09:29:29.479110 16412 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1210 09:29:35.167486 16412 solver.cpp:218] Iteration 17900 (17.5807 iter/s, 5.68805s/100 iters), loss = 1.95678
I1210 09:29:35.167486 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:29:35.167486 16412 solver.cpp:237]     Train net output #1: loss = 1.95678 (* 1 = 1.95678 loss)
I1210 09:29:35.167486 16412 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1210 09:29:40.571892  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:29:40.793908 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_18000.caffemodel
I1210 09:29:40.810907 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_18000.solverstate
I1210 09:29:40.815907 16412 solver.cpp:330] Iteration 18000, Testing net (#0)
I1210 09:29:40.815907 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:29:42.180994 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:29:42.233996 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4049
I1210 09:29:42.233996 16412 solver.cpp:397]     Test net output #1: loss = 2.32664 (* 1 = 2.32664 loss)
I1210 09:29:42.288498 16412 solver.cpp:218] Iteration 18000 (14.0446 iter/s, 7.12019s/100 iters), loss = 1.71806
I1210 09:29:42.288498 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:29:42.288498 16412 solver.cpp:237]     Train net output #1: loss = 1.71806 (* 1 = 1.71806 loss)
I1210 09:29:42.288498 16412 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1210 09:29:47.985556 16412 solver.cpp:218] Iteration 18100 (17.5537 iter/s, 5.69681s/100 iters), loss = 1.53392
I1210 09:29:47.985556 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:29:47.985556 16412 solver.cpp:237]     Train net output #1: loss = 1.53392 (* 1 = 1.53392 loss)
I1210 09:29:47.985556 16412 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1210 09:29:53.677534 16412 solver.cpp:218] Iteration 18200 (17.57 iter/s, 5.69152s/100 iters), loss = 1.32458
I1210 09:29:53.677534 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:29:53.677534 16412 solver.cpp:237]     Train net output #1: loss = 1.32458 (* 1 = 1.32458 loss)
I1210 09:29:53.677534 16412 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1210 09:29:59.363437 16412 solver.cpp:218] Iteration 18300 (17.5873 iter/s, 5.68593s/100 iters), loss = 1.63148
I1210 09:29:59.363437 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:29:59.363437 16412 solver.cpp:237]     Train net output #1: loss = 1.63148 (* 1 = 1.63148 loss)
I1210 09:29:59.363437 16412 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1210 09:30:05.086827 16412 solver.cpp:218] Iteration 18400 (17.4749 iter/s, 5.72249s/100 iters), loss = 1.81169
I1210 09:30:05.086827 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:30:05.086827 16412 solver.cpp:237]     Train net output #1: loss = 1.81169 (* 1 = 1.81169 loss)
I1210 09:30:05.086827 16412 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1210 09:30:10.489255  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:30:10.710263 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_18500.caffemodel
I1210 09:30:10.728265 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_18500.solverstate
I1210 09:30:10.733265 16412 solver.cpp:330] Iteration 18500, Testing net (#0)
I1210 09:30:10.733265 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:30:12.099395 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:30:12.153395 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3837
I1210 09:30:12.153395 16412 solver.cpp:397]     Test net output #1: loss = 2.45448 (* 1 = 2.45448 loss)
I1210 09:30:12.206401 16412 solver.cpp:218] Iteration 18500 (14.0457 iter/s, 7.11963s/100 iters), loss = 1.63906
I1210 09:30:12.206401 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:30:12.206401 16412 solver.cpp:237]     Train net output #1: loss = 1.63906 (* 1 = 1.63906 loss)
I1210 09:30:12.207401 16412 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1210 09:30:17.883846 16412 solver.cpp:218] Iteration 18600 (17.6153 iter/s, 5.67688s/100 iters), loss = 1.56859
I1210 09:30:17.883846 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:30:17.883846 16412 solver.cpp:237]     Train net output #1: loss = 1.56859 (* 1 = 1.56859 loss)
I1210 09:30:17.883846 16412 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1210 09:30:23.561254 16412 solver.cpp:218] Iteration 18700 (17.6167 iter/s, 5.67642s/100 iters), loss = 1.29273
I1210 09:30:23.561254 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:30:23.561254 16412 solver.cpp:237]     Train net output #1: loss = 1.29273 (* 1 = 1.29273 loss)
I1210 09:30:23.561254 16412 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1210 09:30:29.232625 16412 solver.cpp:218] Iteration 18800 (17.632 iter/s, 5.67149s/100 iters), loss = 1.78733
I1210 09:30:29.232625 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:30:29.232625 16412 solver.cpp:237]     Train net output #1: loss = 1.78733 (* 1 = 1.78733 loss)
I1210 09:30:29.232625 16412 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1210 09:30:34.912010 16412 solver.cpp:218] Iteration 18900 (17.6098 iter/s, 5.67866s/100 iters), loss = 1.80476
I1210 09:30:34.912010 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:30:34.912010 16412 solver.cpp:237]     Train net output #1: loss = 1.80476 (* 1 = 1.80476 loss)
I1210 09:30:34.912010 16412 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1210 09:30:40.314371  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:30:40.538380 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_19000.caffemodel
I1210 09:30:40.551380 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_19000.solverstate
I1210 09:30:40.556380 16412 solver.cpp:330] Iteration 19000, Testing net (#0)
I1210 09:30:40.556380 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:30:41.924496 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:30:41.977500 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4161
I1210 09:30:41.977500 16412 solver.cpp:397]     Test net output #1: loss = 2.24202 (* 1 = 2.24202 loss)
I1210 09:30:42.032500 16412 solver.cpp:218] Iteration 19000 (14.0458 iter/s, 7.11957s/100 iters), loss = 1.67438
I1210 09:30:42.032500 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:30:42.032500 16412 solver.cpp:237]     Train net output #1: loss = 1.67438 (* 1 = 1.67438 loss)
I1210 09:30:42.032500 16412 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1210 09:30:47.706920 16412 solver.cpp:218] Iteration 19100 (17.6218 iter/s, 5.67479s/100 iters), loss = 1.57641
I1210 09:30:47.707921 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:30:47.707921 16412 solver.cpp:237]     Train net output #1: loss = 1.57641 (* 1 = 1.57641 loss)
I1210 09:30:47.707921 16412 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1210 09:30:53.381314 16412 solver.cpp:218] Iteration 19200 (17.6252 iter/s, 5.67371s/100 iters), loss = 1.28006
I1210 09:30:53.381314 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:30:53.381314 16412 solver.cpp:237]     Train net output #1: loss = 1.28006 (* 1 = 1.28006 loss)
I1210 09:30:53.381314 16412 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1210 09:30:59.054734 16412 solver.cpp:218] Iteration 19300 (17.6292 iter/s, 5.67241s/100 iters), loss = 1.85212
I1210 09:30:59.054734 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:30:59.054734 16412 solver.cpp:237]     Train net output #1: loss = 1.85212 (* 1 = 1.85212 loss)
I1210 09:30:59.054734 16412 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1210 09:31:04.736147 16412 solver.cpp:218] Iteration 19400 (17.6026 iter/s, 5.68098s/100 iters), loss = 1.8784
I1210 09:31:04.736147 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:31:04.736147 16412 solver.cpp:237]     Train net output #1: loss = 1.8784 (* 1 = 1.8784 loss)
I1210 09:31:04.736147 16412 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1210 09:31:10.135516  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:31:10.358548 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_19500.caffemodel
I1210 09:31:10.372555 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_19500.solverstate
I1210 09:31:10.377063 16412 solver.cpp:330] Iteration 19500, Testing net (#0)
I1210 09:31:10.377063 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:31:11.743656 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:31:11.796667 16412 solver.cpp:397]     Test net output #0: accuracy = 0.386
I1210 09:31:11.796667 16412 solver.cpp:397]     Test net output #1: loss = 2.44813 (* 1 = 2.44813 loss)
I1210 09:31:11.852660 16412 solver.cpp:218] Iteration 19500 (14.0517 iter/s, 7.11655s/100 iters), loss = 1.61149
I1210 09:31:11.852660 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:31:11.852660 16412 solver.cpp:237]     Train net output #1: loss = 1.61149 (* 1 = 1.61149 loss)
I1210 09:31:11.852660 16412 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1210 09:31:17.522039 16412 solver.cpp:218] Iteration 19600 (17.6397 iter/s, 5.66904s/100 iters), loss = 1.41442
I1210 09:31:17.522039 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:31:17.522039 16412 solver.cpp:237]     Train net output #1: loss = 1.41442 (* 1 = 1.41442 loss)
I1210 09:31:17.522039 16412 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1210 09:31:23.199470 16412 solver.cpp:218] Iteration 19700 (17.6158 iter/s, 5.67671s/100 iters), loss = 1.37627
I1210 09:31:23.199470 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:31:23.199470 16412 solver.cpp:237]     Train net output #1: loss = 1.37627 (* 1 = 1.37627 loss)
I1210 09:31:23.199470 16412 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1210 09:31:28.866905 16412 solver.cpp:218] Iteration 19800 (17.6471 iter/s, 5.66667s/100 iters), loss = 1.81461
I1210 09:31:28.866905 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:31:28.866905 16412 solver.cpp:237]     Train net output #1: loss = 1.81461 (* 1 = 1.81461 loss)
I1210 09:31:28.866905 16412 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1210 09:31:34.539336 16412 solver.cpp:218] Iteration 19900 (17.6303 iter/s, 5.67205s/100 iters), loss = 1.99216
I1210 09:31:34.539336 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:31:34.539336 16412 solver.cpp:237]     Train net output #1: loss = 1.99216 (* 1 = 1.99216 loss)
I1210 09:31:34.539336 16412 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1210 09:31:39.925418  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:31:40.150352 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_20000.caffemodel
I1210 09:31:40.168856 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_20000.solverstate
I1210 09:31:40.173857 16412 solver.cpp:330] Iteration 20000, Testing net (#0)
I1210 09:31:40.173857 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:31:41.540431 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:31:41.594440 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3799
I1210 09:31:41.594440 16412 solver.cpp:397]     Test net output #1: loss = 2.5133 (* 1 = 2.5133 loss)
I1210 09:31:41.648439 16412 solver.cpp:218] Iteration 20000 (14.0671 iter/s, 7.10879s/100 iters), loss = 1.67566
I1210 09:31:41.648439 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:31:41.648439 16412 solver.cpp:237]     Train net output #1: loss = 1.67566 (* 1 = 1.67566 loss)
I1210 09:31:41.648439 16412 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1210 09:31:47.321799 16412 solver.cpp:218] Iteration 20100 (17.6284 iter/s, 5.67265s/100 iters), loss = 1.64952
I1210 09:31:47.321799 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:31:47.321799 16412 solver.cpp:237]     Train net output #1: loss = 1.64952 (* 1 = 1.64952 loss)
I1210 09:31:47.321799 16412 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1210 09:31:53.003422 16412 solver.cpp:218] Iteration 20200 (17.5996 iter/s, 5.68195s/100 iters), loss = 1.37691
I1210 09:31:53.003422 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:31:53.003422 16412 solver.cpp:237]     Train net output #1: loss = 1.37691 (* 1 = 1.37691 loss)
I1210 09:31:53.003422 16412 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1210 09:31:58.681831 16412 solver.cpp:218] Iteration 20300 (17.6144 iter/s, 5.67718s/100 iters), loss = 1.79861
I1210 09:31:58.681831 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:31:58.681831 16412 solver.cpp:237]     Train net output #1: loss = 1.79861 (* 1 = 1.79861 loss)
I1210 09:31:58.681831 16412 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1210 09:32:04.359249 16412 solver.cpp:218] Iteration 20400 (17.615 iter/s, 5.67697s/100 iters), loss = 1.90254
I1210 09:32:04.359249 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:32:04.359249 16412 solver.cpp:237]     Train net output #1: loss = 1.90254 (* 1 = 1.90254 loss)
I1210 09:32:04.359249 16412 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1210 09:32:09.760570  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:32:09.984599 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_20500.caffemodel
I1210 09:32:09.998600 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_20500.solverstate
I1210 09:32:10.002599 16412 solver.cpp:330] Iteration 20500, Testing net (#0)
I1210 09:32:10.002599 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:32:11.368700 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:32:11.423702 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3144
I1210 09:32:11.423702 16412 solver.cpp:397]     Test net output #1: loss = 2.89993 (* 1 = 2.89993 loss)
I1210 09:32:11.477705 16412 solver.cpp:218] Iteration 20500 (14.0488 iter/s, 7.11803s/100 iters), loss = 1.69276
I1210 09:32:11.477705 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:32:11.477705 16412 solver.cpp:237]     Train net output #1: loss = 1.69276 (* 1 = 1.69276 loss)
I1210 09:32:11.477705 16412 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1210 09:32:17.155133 16412 solver.cpp:218] Iteration 20600 (17.6137 iter/s, 5.67741s/100 iters), loss = 1.50994
I1210 09:32:17.155133 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:32:17.155133 16412 solver.cpp:237]     Train net output #1: loss = 1.50994 (* 1 = 1.50994 loss)
I1210 09:32:17.155133 16412 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1210 09:32:22.837604 16412 solver.cpp:218] Iteration 20700 (17.6003 iter/s, 5.68172s/100 iters), loss = 1.39763
I1210 09:32:22.837604 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:32:22.837604 16412 solver.cpp:237]     Train net output #1: loss = 1.39763 (* 1 = 1.39763 loss)
I1210 09:32:22.837604 16412 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1210 09:32:28.506036 16412 solver.cpp:218] Iteration 20800 (17.6421 iter/s, 5.66826s/100 iters), loss = 1.72531
I1210 09:32:28.506036 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:32:28.506036 16412 solver.cpp:237]     Train net output #1: loss = 1.72531 (* 1 = 1.72531 loss)
I1210 09:32:28.506036 16412 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1210 09:32:34.175175 16412 solver.cpp:218] Iteration 20900 (17.6416 iter/s, 5.66841s/100 iters), loss = 1.88541
I1210 09:32:34.175175 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:32:34.175175 16412 solver.cpp:237]     Train net output #1: loss = 1.88541 (* 1 = 1.88541 loss)
I1210 09:32:34.175175 16412 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1210 09:32:39.569118  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:32:39.789659 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_21000.caffemodel
I1210 09:32:39.805716 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_21000.solverstate
I1210 09:32:39.810730 16412 solver.cpp:330] Iteration 21000, Testing net (#0)
I1210 09:32:39.810730 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:32:41.180981 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:32:41.234571 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4195
I1210 09:32:41.234571 16412 solver.cpp:397]     Test net output #1: loss = 2.35043 (* 1 = 2.35043 loss)
I1210 09:32:41.288583 16412 solver.cpp:218] Iteration 21000 (14.0591 iter/s, 7.11283s/100 iters), loss = 1.65028
I1210 09:32:41.288583 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:32:41.288583 16412 solver.cpp:237]     Train net output #1: loss = 1.65028 (* 1 = 1.65028 loss)
I1210 09:32:41.288583 16412 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1210 09:32:46.959795 16412 solver.cpp:218] Iteration 21100 (17.6332 iter/s, 5.67112s/100 iters), loss = 1.49285
I1210 09:32:46.959795 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:32:46.959795 16412 solver.cpp:237]     Train net output #1: loss = 1.49285 (* 1 = 1.49285 loss)
I1210 09:32:46.959795 16412 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1210 09:32:52.633544 16412 solver.cpp:218] Iteration 21200 (17.6264 iter/s, 5.6733s/100 iters), loss = 1.23358
I1210 09:32:52.633544 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:32:52.633544 16412 solver.cpp:237]     Train net output #1: loss = 1.23358 (* 1 = 1.23358 loss)
I1210 09:32:52.633544 16412 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1210 09:32:58.297652 16412 solver.cpp:218] Iteration 21300 (17.6569 iter/s, 5.66351s/100 iters), loss = 1.7937
I1210 09:32:58.297652 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:32:58.297652 16412 solver.cpp:237]     Train net output #1: loss = 1.7937 (* 1 = 1.7937 loss)
I1210 09:32:58.297652 16412 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1210 09:33:03.969137 16412 solver.cpp:218] Iteration 21400 (17.6329 iter/s, 5.67122s/100 iters), loss = 1.86482
I1210 09:33:03.969137 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:33:03.969137 16412 solver.cpp:237]     Train net output #1: loss = 1.86482 (* 1 = 1.86482 loss)
I1210 09:33:03.969137 16412 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1210 09:33:09.356524  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:33:09.580535 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_21500.caffemodel
I1210 09:33:09.595041 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_21500.solverstate
I1210 09:33:09.599041 16412 solver.cpp:330] Iteration 21500, Testing net (#0)
I1210 09:33:09.599041 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:33:10.969651 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:33:11.024662 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3923
I1210 09:33:11.024662 16412 solver.cpp:397]     Test net output #1: loss = 2.51334 (* 1 = 2.51334 loss)
I1210 09:33:11.079655 16412 solver.cpp:218] Iteration 21500 (14.0652 iter/s, 7.10973s/100 iters), loss = 1.76625
I1210 09:33:11.079655 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:33:11.079655 16412 solver.cpp:237]     Train net output #1: loss = 1.76625 (* 1 = 1.76625 loss)
I1210 09:33:11.079655 16412 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1210 09:33:16.748983 16412 solver.cpp:218] Iteration 21600 (17.6405 iter/s, 5.66877s/100 iters), loss = 1.44631
I1210 09:33:16.748983 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:33:16.748983 16412 solver.cpp:237]     Train net output #1: loss = 1.44631 (* 1 = 1.44631 loss)
I1210 09:33:16.748983 16412 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1210 09:33:22.406352 16412 solver.cpp:218] Iteration 21700 (17.6761 iter/s, 5.65736s/100 iters), loss = 1.40399
I1210 09:33:22.406352 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:33:22.406352 16412 solver.cpp:237]     Train net output #1: loss = 1.40399 (* 1 = 1.40399 loss)
I1210 09:33:22.406352 16412 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1210 09:33:28.075845 16412 solver.cpp:218] Iteration 21800 (17.639 iter/s, 5.66925s/100 iters), loss = 1.73546
I1210 09:33:28.075845 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:33:28.075845 16412 solver.cpp:237]     Train net output #1: loss = 1.73546 (* 1 = 1.73546 loss)
I1210 09:33:28.075845 16412 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1210 09:33:33.747349 16412 solver.cpp:218] Iteration 21900 (17.6352 iter/s, 5.67048s/100 iters), loss = 1.63229
I1210 09:33:33.747349 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:33:33.747349 16412 solver.cpp:237]     Train net output #1: loss = 1.63229 (* 1 = 1.63229 loss)
I1210 09:33:33.747349 16412 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1210 09:33:39.139767  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:33:39.362778 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_22000.caffemodel
I1210 09:33:39.377789 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_22000.solverstate
I1210 09:33:39.382782 16412 solver.cpp:330] Iteration 22000, Testing net (#0)
I1210 09:33:39.382782 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:33:40.747890 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:33:40.800889 16412 solver.cpp:397]     Test net output #0: accuracy = 0.377
I1210 09:33:40.800889 16412 solver.cpp:397]     Test net output #1: loss = 2.57848 (* 1 = 2.57848 loss)
I1210 09:33:40.854894 16412 solver.cpp:218] Iteration 22000 (14.0698 iter/s, 7.10741s/100 iters), loss = 1.55148
I1210 09:33:40.854894 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:33:40.854894 16412 solver.cpp:237]     Train net output #1: loss = 1.55148 (* 1 = 1.55148 loss)
I1210 09:33:40.854894 16412 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1210 09:33:46.537355 16412 solver.cpp:218] Iteration 22100 (17.6007 iter/s, 5.6816s/100 iters), loss = 1.40587
I1210 09:33:46.537355 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:33:46.537355 16412 solver.cpp:237]     Train net output #1: loss = 1.40587 (* 1 = 1.40587 loss)
I1210 09:33:46.537355 16412 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1210 09:33:52.212473 16412 solver.cpp:218] Iteration 22200 (17.6226 iter/s, 5.67453s/100 iters), loss = 1.24941
I1210 09:33:52.212473 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 09:33:52.212473 16412 solver.cpp:237]     Train net output #1: loss = 1.24941 (* 1 = 1.24941 loss)
I1210 09:33:52.212473 16412 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1210 09:33:57.884920 16412 solver.cpp:218] Iteration 22300 (17.6306 iter/s, 5.67195s/100 iters), loss = 1.71309
I1210 09:33:57.884920 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:33:57.884920 16412 solver.cpp:237]     Train net output #1: loss = 1.71309 (* 1 = 1.71309 loss)
I1210 09:33:57.884920 16412 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1210 09:34:03.557113 16412 solver.cpp:218] Iteration 22400 (17.6315 iter/s, 5.67166s/100 iters), loss = 1.83863
I1210 09:34:03.557113 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:34:03.557113 16412 solver.cpp:237]     Train net output #1: loss = 1.83863 (* 1 = 1.83863 loss)
I1210 09:34:03.557113 16412 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1210 09:34:08.949914  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:34:09.172924 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_22500.caffemodel
I1210 09:34:09.186923 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_22500.solverstate
I1210 09:34:09.191923 16412 solver.cpp:330] Iteration 22500, Testing net (#0)
I1210 09:34:09.191923 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:34:10.562010 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:34:10.615012 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3935
I1210 09:34:10.615012 16412 solver.cpp:397]     Test net output #1: loss = 2.41463 (* 1 = 2.41463 loss)
I1210 09:34:10.669011 16412 solver.cpp:218] Iteration 22500 (14.0605 iter/s, 7.11211s/100 iters), loss = 1.66752
I1210 09:34:10.669011 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:34:10.669011 16412 solver.cpp:237]     Train net output #1: loss = 1.66752 (* 1 = 1.66752 loss)
I1210 09:34:10.669011 16412 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1210 09:34:16.338413 16412 solver.cpp:218] Iteration 22600 (17.6396 iter/s, 5.66906s/100 iters), loss = 1.54702
I1210 09:34:16.339414 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:34:16.339414 16412 solver.cpp:237]     Train net output #1: loss = 1.54702 (* 1 = 1.54702 loss)
I1210 09:34:16.339414 16412 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1210 09:34:22.011819 16412 solver.cpp:218] Iteration 22700 (17.6291 iter/s, 5.67244s/100 iters), loss = 1.31824
I1210 09:34:22.012320 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:34:22.012320 16412 solver.cpp:237]     Train net output #1: loss = 1.31824 (* 1 = 1.31824 loss)
I1210 09:34:22.012320 16412 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1210 09:34:27.689247 16412 solver.cpp:218] Iteration 22800 (17.6147 iter/s, 5.67709s/100 iters), loss = 1.71806
I1210 09:34:27.689247 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:34:27.689247 16412 solver.cpp:237]     Train net output #1: loss = 1.71806 (* 1 = 1.71806 loss)
I1210 09:34:27.689247 16412 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1210 09:34:33.354697 16412 solver.cpp:218] Iteration 22900 (17.652 iter/s, 5.66507s/100 iters), loss = 1.84586
I1210 09:34:33.354697 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:34:33.354697 16412 solver.cpp:237]     Train net output #1: loss = 1.84586 (* 1 = 1.84586 loss)
I1210 09:34:33.354697 16412 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1210 09:34:38.742090  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:34:38.964102 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_23000.caffemodel
I1210 09:34:38.978101 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_23000.solverstate
I1210 09:34:38.983101 16412 solver.cpp:330] Iteration 23000, Testing net (#0)
I1210 09:34:38.983101 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:34:40.353204 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:34:40.407707 16412 solver.cpp:397]     Test net output #0: accuracy = 0.2912
I1210 09:34:40.407707 16412 solver.cpp:397]     Test net output #1: loss = 3.26107 (* 1 = 3.26107 loss)
I1210 09:34:40.461212 16412 solver.cpp:218] Iteration 23000 (14.072 iter/s, 7.10632s/100 iters), loss = 1.83257
I1210 09:34:40.461212 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:34:40.461212 16412 solver.cpp:237]     Train net output #1: loss = 1.83257 (* 1 = 1.83257 loss)
I1210 09:34:40.461212 16412 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1210 09:34:46.133601 16412 solver.cpp:218] Iteration 23100 (17.6318 iter/s, 5.67157s/100 iters), loss = 1.56815
I1210 09:34:46.133601 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:34:46.133601 16412 solver.cpp:237]     Train net output #1: loss = 1.56815 (* 1 = 1.56815 loss)
I1210 09:34:46.133601 16412 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1210 09:34:51.818034 16412 solver.cpp:218] Iteration 23200 (17.594 iter/s, 5.68376s/100 iters), loss = 1.20472
I1210 09:34:51.818034 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 09:34:51.818034 16412 solver.cpp:237]     Train net output #1: loss = 1.20472 (* 1 = 1.20472 loss)
I1210 09:34:51.818034 16412 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1210 09:34:57.495465 16412 solver.cpp:218] Iteration 23300 (17.6148 iter/s, 5.67706s/100 iters), loss = 1.72507
I1210 09:34:57.495465 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:34:57.495465 16412 solver.cpp:237]     Train net output #1: loss = 1.72507 (* 1 = 1.72507 loss)
I1210 09:34:57.495465 16412 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1210 09:35:03.177649 16412 solver.cpp:218] Iteration 23400 (17.6003 iter/s, 5.68171s/100 iters), loss = 1.76541
I1210 09:35:03.177649 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:35:03.177649 16412 solver.cpp:237]     Train net output #1: loss = 1.76541 (* 1 = 1.76541 loss)
I1210 09:35:03.177649 16412 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1210 09:35:08.580071  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:35:08.803082 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_23500.caffemodel
I1210 09:35:08.817586 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_23500.solverstate
I1210 09:35:08.822087 16412 solver.cpp:330] Iteration 23500, Testing net (#0)
I1210 09:35:08.822087 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:35:10.193244 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:35:10.246250 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3848
I1210 09:35:10.246250 16412 solver.cpp:397]     Test net output #1: loss = 2.50015 (* 1 = 2.50015 loss)
I1210 09:35:10.301251 16412 solver.cpp:218] Iteration 23500 (14.0397 iter/s, 7.12268s/100 iters), loss = 1.62107
I1210 09:35:10.301251 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:35:10.301251 16412 solver.cpp:237]     Train net output #1: loss = 1.62107 (* 1 = 1.62107 loss)
I1210 09:35:10.301251 16412 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1210 09:35:15.976755 16412 solver.cpp:218] Iteration 23600 (17.6182 iter/s, 5.67596s/100 iters), loss = 1.46935
I1210 09:35:15.976755 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:35:15.977756 16412 solver.cpp:237]     Train net output #1: loss = 1.46935 (* 1 = 1.46935 loss)
I1210 09:35:15.977756 16412 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1210 09:35:21.657434 16412 solver.cpp:218] Iteration 23700 (17.6068 iter/s, 5.67963s/100 iters), loss = 1.30152
I1210 09:35:21.657434 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:35:21.657434 16412 solver.cpp:237]     Train net output #1: loss = 1.30152 (* 1 = 1.30152 loss)
I1210 09:35:21.657434 16412 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1210 09:35:27.333896 16412 solver.cpp:218] Iteration 23800 (17.6165 iter/s, 5.6765s/100 iters), loss = 1.71179
I1210 09:35:27.333896 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:35:27.333896 16412 solver.cpp:237]     Train net output #1: loss = 1.71179 (* 1 = 1.71179 loss)
I1210 09:35:27.333896 16412 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1210 09:35:33.012291 16412 solver.cpp:218] Iteration 23900 (17.6143 iter/s, 5.67722s/100 iters), loss = 1.70331
I1210 09:35:33.012291 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:35:33.012291 16412 solver.cpp:237]     Train net output #1: loss = 1.70331 (* 1 = 1.70331 loss)
I1210 09:35:33.012291 16412 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1210 09:35:38.415186  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:35:38.638713 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_24000.caffemodel
I1210 09:35:38.651712 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_24000.solverstate
I1210 09:35:38.656713 16412 solver.cpp:330] Iteration 24000, Testing net (#0)
I1210 09:35:38.656713 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:35:40.024034 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:35:40.077040 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3756
I1210 09:35:40.077040 16412 solver.cpp:397]     Test net output #1: loss = 2.58498 (* 1 = 2.58498 loss)
I1210 09:35:40.132046 16412 solver.cpp:218] Iteration 24000 (14.0463 iter/s, 7.11931s/100 iters), loss = 1.54461
I1210 09:35:40.132046 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:35:40.132046 16412 solver.cpp:237]     Train net output #1: loss = 1.54461 (* 1 = 1.54461 loss)
I1210 09:35:40.132046 16412 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1210 09:35:45.805464 16412 solver.cpp:218] Iteration 24100 (17.6276 iter/s, 5.67293s/100 iters), loss = 1.57757
I1210 09:35:45.805464 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:35:45.805464 16412 solver.cpp:237]     Train net output #1: loss = 1.57757 (* 1 = 1.57757 loss)
I1210 09:35:45.805464 16412 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1210 09:35:51.466941 16412 solver.cpp:218] Iteration 24200 (17.6633 iter/s, 5.66145s/100 iters), loss = 1.34928
I1210 09:35:51.466941 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:35:51.466941 16412 solver.cpp:237]     Train net output #1: loss = 1.34928 (* 1 = 1.34928 loss)
I1210 09:35:51.466941 16412 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1210 09:35:57.137293 16412 solver.cpp:218] Iteration 24300 (17.6367 iter/s, 5.66999s/100 iters), loss = 1.68014
I1210 09:35:57.137293 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:35:57.137293 16412 solver.cpp:237]     Train net output #1: loss = 1.68014 (* 1 = 1.68014 loss)
I1210 09:35:57.137293 16412 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1210 09:36:02.806764 16412 solver.cpp:218] Iteration 24400 (17.6404 iter/s, 5.66879s/100 iters), loss = 1.68678
I1210 09:36:02.806764 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:36:02.806764 16412 solver.cpp:237]     Train net output #1: loss = 1.68678 (* 1 = 1.68678 loss)
I1210 09:36:02.806764 16412 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1210 09:36:08.198165  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:36:08.421686 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_24500.caffemodel
I1210 09:36:08.435192 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_24500.solverstate
I1210 09:36:08.440192 16412 solver.cpp:330] Iteration 24500, Testing net (#0)
I1210 09:36:08.440192 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:36:09.809290 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:36:09.863296 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4308
I1210 09:36:09.863296 16412 solver.cpp:397]     Test net output #1: loss = 2.22065 (* 1 = 2.22065 loss)
I1210 09:36:09.917297 16412 solver.cpp:218] Iteration 24500 (14.0645 iter/s, 7.11009s/100 iters), loss = 1.62879
I1210 09:36:09.917297 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:36:09.917297 16412 solver.cpp:237]     Train net output #1: loss = 1.62879 (* 1 = 1.62879 loss)
I1210 09:36:09.917297 16412 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1210 09:36:15.591673 16412 solver.cpp:218] Iteration 24600 (17.6243 iter/s, 5.67398s/100 iters), loss = 1.52699
I1210 09:36:15.591673 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:36:15.591673 16412 solver.cpp:237]     Train net output #1: loss = 1.52699 (* 1 = 1.52699 loss)
I1210 09:36:15.591673 16412 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1210 09:36:21.258095 16412 solver.cpp:218] Iteration 24700 (17.6468 iter/s, 5.66674s/100 iters), loss = 1.37467
I1210 09:36:21.259096 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:36:21.259096 16412 solver.cpp:237]     Train net output #1: loss = 1.37467 (* 1 = 1.37467 loss)
I1210 09:36:21.259096 16412 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1210 09:36:26.929033 16412 solver.cpp:218] Iteration 24800 (17.6378 iter/s, 5.66963s/100 iters), loss = 1.54125
I1210 09:36:26.929033 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:36:26.929033 16412 solver.cpp:237]     Train net output #1: loss = 1.54125 (* 1 = 1.54125 loss)
I1210 09:36:26.929033 16412 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1210 09:36:32.601961 16412 solver.cpp:218] Iteration 24900 (17.6275 iter/s, 5.67295s/100 iters), loss = 1.91343
I1210 09:36:32.601961 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:36:32.601961 16412 solver.cpp:237]     Train net output #1: loss = 1.91343 (* 1 = 1.91343 loss)
I1210 09:36:32.601961 16412 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1210 09:36:37.992413  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:36:38.216430 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_25000.caffemodel
I1210 09:36:38.232434 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_25000.solverstate
I1210 09:36:38.237434 16412 solver.cpp:330] Iteration 25000, Testing net (#0)
I1210 09:36:38.237434 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:36:39.603523 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:36:39.656538 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3647
I1210 09:36:39.656538 16412 solver.cpp:397]     Test net output #1: loss = 2.52237 (* 1 = 2.52237 loss)
I1210 09:36:39.712538 16412 solver.cpp:218] Iteration 25000 (14.0642 iter/s, 7.11023s/100 iters), loss = 1.57109
I1210 09:36:39.712538 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:36:39.712538 16412 solver.cpp:237]     Train net output #1: loss = 1.57109 (* 1 = 1.57109 loss)
I1210 09:36:39.712538 16412 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1210 09:36:45.381059 16412 solver.cpp:218] Iteration 25100 (17.6416 iter/s, 5.6684s/100 iters), loss = 1.53034
I1210 09:36:45.382061 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:36:45.382061 16412 solver.cpp:237]     Train net output #1: loss = 1.53034 (* 1 = 1.53034 loss)
I1210 09:36:45.382061 16412 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1210 09:36:51.051623 16412 solver.cpp:218] Iteration 25200 (17.6381 iter/s, 5.66954s/100 iters), loss = 1.3259
I1210 09:36:51.051623 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:36:51.051623 16412 solver.cpp:237]     Train net output #1: loss = 1.3259 (* 1 = 1.3259 loss)
I1210 09:36:51.051623 16412 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1210 09:36:56.718163 16412 solver.cpp:218] Iteration 25300 (17.6487 iter/s, 5.66615s/100 iters), loss = 1.67045
I1210 09:36:56.718662 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:36:56.718662 16412 solver.cpp:237]     Train net output #1: loss = 1.67045 (* 1 = 1.67045 loss)
I1210 09:36:56.718662 16412 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1210 09:37:02.396579 16412 solver.cpp:218] Iteration 25400 (17.6108 iter/s, 5.67835s/100 iters), loss = 1.92391
I1210 09:37:02.396579 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:37:02.396579 16412 solver.cpp:237]     Train net output #1: loss = 1.92391 (* 1 = 1.92391 loss)
I1210 09:37:02.396579 16412 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1210 09:37:07.788311  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:37:08.010321 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_25500.caffemodel
I1210 09:37:08.026829 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_25500.solverstate
I1210 09:37:08.033327 16412 solver.cpp:330] Iteration 25500, Testing net (#0)
I1210 09:37:08.033327 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:37:09.403453 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:37:09.456461 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3772
I1210 09:37:09.456461 16412 solver.cpp:397]     Test net output #1: loss = 2.45267 (* 1 = 2.45267 loss)
I1210 09:37:09.510460 16412 solver.cpp:218] Iteration 25500 (14.0586 iter/s, 7.11307s/100 iters), loss = 1.66439
I1210 09:37:09.510460 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:37:09.510460 16412 solver.cpp:237]     Train net output #1: loss = 1.66439 (* 1 = 1.66439 loss)
I1210 09:37:09.510460 16412 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1210 09:37:15.183867 16412 solver.cpp:218] Iteration 25600 (17.6262 iter/s, 5.67337s/100 iters), loss = 1.45192
I1210 09:37:15.183867 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:37:15.183867 16412 solver.cpp:237]     Train net output #1: loss = 1.45192 (* 1 = 1.45192 loss)
I1210 09:37:15.183867 16412 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1210 09:37:20.849318 16412 solver.cpp:218] Iteration 25700 (17.6532 iter/s, 5.66468s/100 iters), loss = 1.39688
I1210 09:37:20.849318 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:37:20.849318 16412 solver.cpp:237]     Train net output #1: loss = 1.39688 (* 1 = 1.39688 loss)
I1210 09:37:20.849318 16412 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1210 09:37:26.517783 16412 solver.cpp:218] Iteration 25800 (17.6422 iter/s, 5.66823s/100 iters), loss = 1.72777
I1210 09:37:26.517783 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:37:26.517783 16412 solver.cpp:237]     Train net output #1: loss = 1.72777 (* 1 = 1.72777 loss)
I1210 09:37:26.517783 16412 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1210 09:37:32.186086 16412 solver.cpp:218] Iteration 25900 (17.642 iter/s, 5.66829s/100 iters), loss = 1.72254
I1210 09:37:32.187086 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:37:32.187086 16412 solver.cpp:237]     Train net output #1: loss = 1.72254 (* 1 = 1.72254 loss)
I1210 09:37:32.187086 16412 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1210 09:37:37.579481  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:37:37.803493 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_26000.caffemodel
I1210 09:37:37.818492 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_26000.solverstate
I1210 09:37:37.822996 16412 solver.cpp:330] Iteration 26000, Testing net (#0)
I1210 09:37:37.823498 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:37:39.191601 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:37:39.245612 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3493
I1210 09:37:39.245612 16412 solver.cpp:397]     Test net output #1: loss = 2.79539 (* 1 = 2.79539 loss)
I1210 09:37:39.301612 16412 solver.cpp:218] Iteration 26000 (14.0553 iter/s, 7.11475s/100 iters), loss = 1.61047
I1210 09:37:39.301612 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:37:39.301612 16412 solver.cpp:237]     Train net output #1: loss = 1.61047 (* 1 = 1.61047 loss)
I1210 09:37:39.301612 16412 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1210 09:37:44.972113 16412 solver.cpp:218] Iteration 26100 (17.6369 iter/s, 5.66992s/100 iters), loss = 1.44918
I1210 09:37:44.972113 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:37:44.972113 16412 solver.cpp:237]     Train net output #1: loss = 1.44918 (* 1 = 1.44918 loss)
I1210 09:37:44.972113 16412 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1210 09:37:50.641288 16412 solver.cpp:218] Iteration 26200 (17.639 iter/s, 5.66926s/100 iters), loss = 1.31655
I1210 09:37:50.642304 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:37:50.642304 16412 solver.cpp:237]     Train net output #1: loss = 1.31655 (* 1 = 1.31655 loss)
I1210 09:37:50.642304 16412 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1210 09:37:56.317270 16412 solver.cpp:218] Iteration 26300 (17.6206 iter/s, 5.67517s/100 iters), loss = 1.73819
I1210 09:37:56.317270 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:37:56.317270 16412 solver.cpp:237]     Train net output #1: loss = 1.73819 (* 1 = 1.73819 loss)
I1210 09:37:56.317270 16412 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1210 09:38:01.986724 16412 solver.cpp:218] Iteration 26400 (17.6414 iter/s, 5.66847s/100 iters), loss = 1.68938
I1210 09:38:01.986724 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:38:01.986724 16412 solver.cpp:237]     Train net output #1: loss = 1.68938 (* 1 = 1.68938 loss)
I1210 09:38:01.986724 16412 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1210 09:38:07.378545  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:38:07.601558 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_26500.caffemodel
I1210 09:38:07.615557 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_26500.solverstate
I1210 09:38:07.620558 16412 solver.cpp:330] Iteration 26500, Testing net (#0)
I1210 09:38:07.620558 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:38:08.990684 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:38:09.044697 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4138
I1210 09:38:09.044697 16412 solver.cpp:397]     Test net output #1: loss = 2.3606 (* 1 = 2.3606 loss)
I1210 09:38:09.098698 16412 solver.cpp:218] Iteration 26500 (14.0608 iter/s, 7.11195s/100 iters), loss = 1.69171
I1210 09:38:09.098698 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:38:09.098698 16412 solver.cpp:237]     Train net output #1: loss = 1.69171 (* 1 = 1.69171 loss)
I1210 09:38:09.098698 16412 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1210 09:38:14.780182 16412 solver.cpp:218] Iteration 26600 (17.6025 iter/s, 5.681s/100 iters), loss = 1.57661
I1210 09:38:14.780182 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:38:14.780182 16412 solver.cpp:237]     Train net output #1: loss = 1.57661 (* 1 = 1.57661 loss)
I1210 09:38:14.780182 16412 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1210 09:38:20.445138 16412 solver.cpp:218] Iteration 26700 (17.6544 iter/s, 5.66432s/100 iters), loss = 1.27928
I1210 09:38:20.445138 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:38:20.445138 16412 solver.cpp:237]     Train net output #1: loss = 1.27928 (* 1 = 1.27928 loss)
I1210 09:38:20.445138 16412 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1210 09:38:26.126083 16412 solver.cpp:218] Iteration 26800 (17.6047 iter/s, 5.6803s/100 iters), loss = 1.82752
I1210 09:38:26.126083 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1210 09:38:26.126083 16412 solver.cpp:237]     Train net output #1: loss = 1.82752 (* 1 = 1.82752 loss)
I1210 09:38:26.126083 16412 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1210 09:38:31.813536 16412 solver.cpp:218] Iteration 26900 (17.5819 iter/s, 5.68766s/100 iters), loss = 1.86845
I1210 09:38:31.813536 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:38:31.813536 16412 solver.cpp:237]     Train net output #1: loss = 1.86845 (* 1 = 1.86845 loss)
I1210 09:38:31.813536 16412 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1210 09:38:37.210947  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:38:37.434957 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_27000.caffemodel
I1210 09:38:37.448957 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_27000.solverstate
I1210 09:38:37.453959 16412 solver.cpp:330] Iteration 27000, Testing net (#0)
I1210 09:38:37.453959 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:38:38.819118 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:38:38.874621 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4159
I1210 09:38:38.874621 16412 solver.cpp:397]     Test net output #1: loss = 2.23847 (* 1 = 2.23847 loss)
I1210 09:38:38.928123 16412 solver.cpp:218] Iteration 27000 (14.0572 iter/s, 7.1138s/100 iters), loss = 1.68103
I1210 09:38:38.928123 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:38:38.928123 16412 solver.cpp:237]     Train net output #1: loss = 1.68103 (* 1 = 1.68103 loss)
I1210 09:38:38.928123 16412 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1210 09:38:44.596770 16412 solver.cpp:218] Iteration 27100 (17.6417 iter/s, 5.66838s/100 iters), loss = 1.52759
I1210 09:38:44.596770 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:38:44.596770 16412 solver.cpp:237]     Train net output #1: loss = 1.52759 (* 1 = 1.52759 loss)
I1210 09:38:44.596770 16412 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1210 09:38:50.277628 16412 solver.cpp:218] Iteration 27200 (17.6055 iter/s, 5.68004s/100 iters), loss = 1.41515
I1210 09:38:50.277628 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:38:50.277628 16412 solver.cpp:237]     Train net output #1: loss = 1.41515 (* 1 = 1.41515 loss)
I1210 09:38:50.277628 16412 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1210 09:38:55.942539 16412 solver.cpp:218] Iteration 27300 (17.6537 iter/s, 5.66454s/100 iters), loss = 1.64414
I1210 09:38:55.942539 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:38:55.942539 16412 solver.cpp:237]     Train net output #1: loss = 1.64414 (* 1 = 1.64414 loss)
I1210 09:38:55.942539 16412 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1210 09:39:01.603924 16412 solver.cpp:218] Iteration 27400 (17.6627 iter/s, 5.66165s/100 iters), loss = 1.68471
I1210 09:39:01.603924 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:39:01.603924 16412 solver.cpp:237]     Train net output #1: loss = 1.68471 (* 1 = 1.68471 loss)
I1210 09:39:01.603924 16412 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1210 09:39:06.995335  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:39:07.219350 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_27500.caffemodel
I1210 09:39:07.233350 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_27500.solverstate
I1210 09:39:07.238350 16412 solver.cpp:330] Iteration 27500, Testing net (#0)
I1210 09:39:07.238350 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:39:08.608430 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:39:08.661429 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3142
I1210 09:39:08.661429 16412 solver.cpp:397]     Test net output #1: loss = 2.93156 (* 1 = 2.93156 loss)
I1210 09:39:08.715435 16412 solver.cpp:218] Iteration 27500 (14.0626 iter/s, 7.11108s/100 iters), loss = 1.68199
I1210 09:39:08.715435 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:39:08.715435 16412 solver.cpp:237]     Train net output #1: loss = 1.68199 (* 1 = 1.68199 loss)
I1210 09:39:08.716434 16412 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1210 09:39:14.390862 16412 solver.cpp:218] Iteration 27600 (17.6227 iter/s, 5.6745s/100 iters), loss = 1.44681
I1210 09:39:14.390862 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:39:14.390862 16412 solver.cpp:237]     Train net output #1: loss = 1.44681 (* 1 = 1.44681 loss)
I1210 09:39:14.390862 16412 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1210 09:39:20.056247 16412 solver.cpp:218] Iteration 27700 (17.6512 iter/s, 5.66533s/100 iters), loss = 1.3231
I1210 09:39:20.056247 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:39:20.056247 16412 solver.cpp:237]     Train net output #1: loss = 1.3231 (* 1 = 1.3231 loss)
I1210 09:39:20.056247 16412 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1210 09:39:25.733675 16412 solver.cpp:218] Iteration 27800 (17.6167 iter/s, 5.67643s/100 iters), loss = 1.72242
I1210 09:39:25.733675 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:39:25.733675 16412 solver.cpp:237]     Train net output #1: loss = 1.72242 (* 1 = 1.72242 loss)
I1210 09:39:25.733675 16412 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1210 09:39:31.396106 16412 solver.cpp:218] Iteration 27900 (17.6613 iter/s, 5.6621s/100 iters), loss = 1.91106
I1210 09:39:31.396106 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:39:31.396106 16412 solver.cpp:237]     Train net output #1: loss = 1.91106 (* 1 = 1.91106 loss)
I1210 09:39:31.396106 16412 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1210 09:39:36.792520  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:39:37.014530 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_28000.caffemodel
I1210 09:39:37.032532 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_28000.solverstate
I1210 09:39:37.037533 16412 solver.cpp:330] Iteration 28000, Testing net (#0)
I1210 09:39:37.037533 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:39:38.403618 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:39:38.457618 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4035
I1210 09:39:38.457618 16412 solver.cpp:397]     Test net output #1: loss = 2.38269 (* 1 = 2.38269 loss)
I1210 09:39:38.512624 16412 solver.cpp:218] Iteration 28000 (14.053 iter/s, 7.11594s/100 iters), loss = 1.62166
I1210 09:39:38.512624 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:39:38.512624 16412 solver.cpp:237]     Train net output #1: loss = 1.62166 (* 1 = 1.62166 loss)
I1210 09:39:38.512624 16412 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1210 09:39:44.184579 16412 solver.cpp:218] Iteration 28100 (17.6317 iter/s, 5.67162s/100 iters), loss = 1.40305
I1210 09:39:44.184579 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:39:44.184579 16412 solver.cpp:237]     Train net output #1: loss = 1.40305 (* 1 = 1.40305 loss)
I1210 09:39:44.184579 16412 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1210 09:39:49.858480 16412 solver.cpp:218] Iteration 28200 (17.6259 iter/s, 5.67347s/100 iters), loss = 1.3359
I1210 09:39:49.858480 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:39:49.858480 16412 solver.cpp:237]     Train net output #1: loss = 1.3359 (* 1 = 1.3359 loss)
I1210 09:39:49.858480 16412 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1210 09:39:55.529155 16412 solver.cpp:218] Iteration 28300 (17.6345 iter/s, 5.67069s/100 iters), loss = 1.76475
I1210 09:39:55.529155 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:39:55.530155 16412 solver.cpp:237]     Train net output #1: loss = 1.76475 (* 1 = 1.76475 loss)
I1210 09:39:55.530155 16412 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1210 09:40:01.228646 16412 solver.cpp:218] Iteration 28400 (17.5495 iter/s, 5.69817s/100 iters), loss = 1.79862
I1210 09:40:01.228646 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:40:01.228646 16412 solver.cpp:237]     Train net output #1: loss = 1.79862 (* 1 = 1.79862 loss)
I1210 09:40:01.228646 16412 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1210 09:40:06.634138  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:40:06.857148 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_28500.caffemodel
I1210 09:40:06.876152 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_28500.solverstate
I1210 09:40:06.881151 16412 solver.cpp:330] Iteration 28500, Testing net (#0)
I1210 09:40:06.881151 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:40:08.249244 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:40:08.302253 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3746
I1210 09:40:08.302253 16412 solver.cpp:397]     Test net output #1: loss = 2.6262 (* 1 = 2.6262 loss)
I1210 09:40:08.359253 16412 solver.cpp:218] Iteration 28500 (14.0252 iter/s, 7.13003s/100 iters), loss = 1.51258
I1210 09:40:08.359253 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:40:08.359253 16412 solver.cpp:237]     Train net output #1: loss = 1.51258 (* 1 = 1.51258 loss)
I1210 09:40:08.359253 16412 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1210 09:40:14.031651 16412 solver.cpp:218] Iteration 28600 (17.6302 iter/s, 5.67207s/100 iters), loss = 1.37526
I1210 09:40:14.031651 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:40:14.031651 16412 solver.cpp:237]     Train net output #1: loss = 1.37526 (* 1 = 1.37526 loss)
I1210 09:40:14.031651 16412 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1210 09:40:19.703070 16412 solver.cpp:218] Iteration 28700 (17.6322 iter/s, 5.67146s/100 iters), loss = 1.23295
I1210 09:40:19.703070 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:40:19.703070 16412 solver.cpp:237]     Train net output #1: loss = 1.23295 (* 1 = 1.23295 loss)
I1210 09:40:19.703070 16412 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1210 09:40:25.377980 16412 solver.cpp:218] Iteration 28800 (17.6243 iter/s, 5.67399s/100 iters), loss = 1.63069
I1210 09:40:25.377980 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:40:25.377980 16412 solver.cpp:237]     Train net output #1: loss = 1.63069 (* 1 = 1.63069 loss)
I1210 09:40:25.377980 16412 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1210 09:40:31.053956 16412 solver.cpp:218] Iteration 28900 (17.6177 iter/s, 5.6761s/100 iters), loss = 1.74687
I1210 09:40:31.053956 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:40:31.053956 16412 solver.cpp:237]     Train net output #1: loss = 1.74687 (* 1 = 1.74687 loss)
I1210 09:40:31.053956 16412 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1210 09:40:36.448335  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:40:36.672356 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_29000.caffemodel
I1210 09:40:36.691359 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_29000.solverstate
I1210 09:40:36.696368 16412 solver.cpp:330] Iteration 29000, Testing net (#0)
I1210 09:40:36.696368 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:40:38.065487 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:40:38.119498 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3822
I1210 09:40:38.119498 16412 solver.cpp:397]     Test net output #1: loss = 2.45113 (* 1 = 2.45113 loss)
I1210 09:40:38.173496 16412 solver.cpp:218] Iteration 29000 (14.0479 iter/s, 7.1185s/100 iters), loss = 1.51577
I1210 09:40:38.173496 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:40:38.173496 16412 solver.cpp:237]     Train net output #1: loss = 1.51577 (* 1 = 1.51577 loss)
I1210 09:40:38.173496 16412 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1210 09:40:43.849882 16412 solver.cpp:218] Iteration 29100 (17.619 iter/s, 5.6757s/100 iters), loss = 1.34872
I1210 09:40:43.849882 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:40:43.849882 16412 solver.cpp:237]     Train net output #1: loss = 1.34872 (* 1 = 1.34872 loss)
I1210 09:40:43.849882 16412 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1210 09:40:49.523310 16412 solver.cpp:218] Iteration 29200 (17.6258 iter/s, 5.6735s/100 iters), loss = 1.18971
I1210 09:40:49.523310 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:40:49.523310 16412 solver.cpp:237]     Train net output #1: loss = 1.18971 (* 1 = 1.18971 loss)
I1210 09:40:49.523310 16412 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1210 09:40:55.194763 16412 solver.cpp:218] Iteration 29300 (17.6342 iter/s, 5.67081s/100 iters), loss = 1.61561
I1210 09:40:55.194763 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:40:55.194763 16412 solver.cpp:237]     Train net output #1: loss = 1.61561 (* 1 = 1.61561 loss)
I1210 09:40:55.194763 16412 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1210 09:41:00.865237 16412 solver.cpp:218] Iteration 29400 (17.6372 iter/s, 5.66984s/100 iters), loss = 1.73096
I1210 09:41:00.865237 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:41:00.865237 16412 solver.cpp:237]     Train net output #1: loss = 1.73096 (* 1 = 1.73096 loss)
I1210 09:41:00.865237 16412 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1210 09:41:06.263629  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:41:06.486150 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_29500.caffemodel
I1210 09:41:06.499652 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_29500.solverstate
I1210 09:41:06.504652 16412 solver.cpp:330] Iteration 29500, Testing net (#0)
I1210 09:41:06.504652 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:41:07.870731 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:41:07.924741 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3991
I1210 09:41:07.924741 16412 solver.cpp:397]     Test net output #1: loss = 2.37068 (* 1 = 2.37068 loss)
I1210 09:41:07.980242 16412 solver.cpp:218] Iteration 29500 (14.0554 iter/s, 7.11472s/100 iters), loss = 1.66669
I1210 09:41:07.980242 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:41:07.980242 16412 solver.cpp:237]     Train net output #1: loss = 1.66669 (* 1 = 1.66669 loss)
I1210 09:41:07.980242 16412 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1210 09:41:13.664145 16412 solver.cpp:218] Iteration 29600 (17.5948 iter/s, 5.68351s/100 iters), loss = 1.39686
I1210 09:41:13.664145 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:41:13.664145 16412 solver.cpp:237]     Train net output #1: loss = 1.39686 (* 1 = 1.39686 loss)
I1210 09:41:13.664145 16412 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1210 09:41:19.336771 16412 solver.cpp:218] Iteration 29700 (17.6296 iter/s, 5.67227s/100 iters), loss = 1.37352
I1210 09:41:19.336771 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:41:19.336771 16412 solver.cpp:237]     Train net output #1: loss = 1.37352 (* 1 = 1.37352 loss)
I1210 09:41:19.336771 16412 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1210 09:41:25.005733 16412 solver.cpp:218] Iteration 29800 (17.6423 iter/s, 5.66819s/100 iters), loss = 1.67632
I1210 09:41:25.005733 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:41:25.005733 16412 solver.cpp:237]     Train net output #1: loss = 1.67632 (* 1 = 1.67632 loss)
I1210 09:41:25.005733 16412 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1210 09:41:30.670997 16412 solver.cpp:218] Iteration 29900 (17.6504 iter/s, 5.66558s/100 iters), loss = 1.88149
I1210 09:41:30.670997 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:41:30.670997 16412 solver.cpp:237]     Train net output #1: loss = 1.88149 (* 1 = 1.88149 loss)
I1210 09:41:30.670997 16412 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1210 09:41:36.054801  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:41:36.277827 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_30000.caffemodel
I1210 09:41:36.291827 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_30000.solverstate
I1210 09:41:36.296828 16412 solver.cpp:330] Iteration 30000, Testing net (#0)
I1210 09:41:36.296828 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:41:37.667781 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:41:37.721276 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3838
I1210 09:41:37.721276 16412 solver.cpp:397]     Test net output #1: loss = 2.51065 (* 1 = 2.51065 loss)
I1210 09:41:37.774780 16412 solver.cpp:218] Iteration 30000 (14.0794 iter/s, 7.10255s/100 iters), loss = 1.72722
I1210 09:41:37.774780 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:41:37.774780 16412 solver.cpp:237]     Train net output #1: loss = 1.72722 (* 1 = 1.72722 loss)
I1210 09:41:37.774780 16412 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1210 09:41:43.442235 16412 solver.cpp:218] Iteration 30100 (17.6451 iter/s, 5.66729s/100 iters), loss = 1.45433
I1210 09:41:43.442235 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:41:43.442235 16412 solver.cpp:237]     Train net output #1: loss = 1.45433 (* 1 = 1.45433 loss)
I1210 09:41:43.442235 16412 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1210 09:41:49.111132 16412 solver.cpp:218] Iteration 30200 (17.6424 iter/s, 5.66815s/100 iters), loss = 1.29987
I1210 09:41:49.111132 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:41:49.111132 16412 solver.cpp:237]     Train net output #1: loss = 1.29987 (* 1 = 1.29987 loss)
I1210 09:41:49.111132 16412 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1210 09:41:54.782048 16412 solver.cpp:218] Iteration 30300 (17.6325 iter/s, 5.67136s/100 iters), loss = 1.69082
I1210 09:41:54.782048 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:41:54.782048 16412 solver.cpp:237]     Train net output #1: loss = 1.69082 (* 1 = 1.69082 loss)
I1210 09:41:54.782048 16412 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1210 09:42:00.454468 16412 solver.cpp:218] Iteration 30400 (17.631 iter/s, 5.67183s/100 iters), loss = 1.77213
I1210 09:42:00.454468 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:42:00.454468 16412 solver.cpp:237]     Train net output #1: loss = 1.77213 (* 1 = 1.77213 loss)
I1210 09:42:00.454468 16412 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1210 09:42:05.844868  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:42:06.068881 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_30500.caffemodel
I1210 09:42:06.082886 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_30500.solverstate
I1210 09:42:06.087887 16412 solver.cpp:330] Iteration 30500, Testing net (#0)
I1210 09:42:06.087887 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:42:07.454994 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:42:07.508999 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3766
I1210 09:42:07.508999 16412 solver.cpp:397]     Test net output #1: loss = 2.50562 (* 1 = 2.50562 loss)
I1210 09:42:07.564501 16412 solver.cpp:218] Iteration 30500 (14.0663 iter/s, 7.10917s/100 iters), loss = 1.54378
I1210 09:42:07.564501 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:42:07.564501 16412 solver.cpp:237]     Train net output #1: loss = 1.54378 (* 1 = 1.54378 loss)
I1210 09:42:07.564501 16412 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1210 09:42:13.236384 16412 solver.cpp:218] Iteration 30600 (17.6317 iter/s, 5.67161s/100 iters), loss = 1.60535
I1210 09:42:13.236384 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:42:13.236384 16412 solver.cpp:237]     Train net output #1: loss = 1.60535 (* 1 = 1.60535 loss)
I1210 09:42:13.236384 16412 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1210 09:42:18.901793 16412 solver.cpp:218] Iteration 30700 (17.651 iter/s, 5.6654s/100 iters), loss = 1.22352
I1210 09:42:18.902793 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 09:42:18.902793 16412 solver.cpp:237]     Train net output #1: loss = 1.22352 (* 1 = 1.22352 loss)
I1210 09:42:18.902793 16412 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1210 09:42:24.572448 16412 solver.cpp:218] Iteration 30800 (17.639 iter/s, 5.66926s/100 iters), loss = 1.61127
I1210 09:42:24.572448 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:42:24.572448 16412 solver.cpp:237]     Train net output #1: loss = 1.61127 (* 1 = 1.61127 loss)
I1210 09:42:24.572448 16412 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1210 09:42:30.249850 16412 solver.cpp:218] Iteration 30900 (17.6145 iter/s, 5.67713s/100 iters), loss = 1.70971
I1210 09:42:30.249850 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:42:30.249850 16412 solver.cpp:237]     Train net output #1: loss = 1.70971 (* 1 = 1.70971 loss)
I1210 09:42:30.249850 16412 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1210 09:42:35.653473  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:42:35.876998 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_31000.caffemodel
I1210 09:42:35.890503 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_31000.solverstate
I1210 09:42:35.896503 16412 solver.cpp:330] Iteration 31000, Testing net (#0)
I1210 09:42:35.896503 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:42:37.269110 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:42:37.322613 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3206
I1210 09:42:37.322613 16412 solver.cpp:397]     Test net output #1: loss = 2.87476 (* 1 = 2.87476 loss)
I1210 09:42:37.377614 16412 solver.cpp:218] Iteration 31000 (14.0306 iter/s, 7.12725s/100 iters), loss = 1.72387
I1210 09:42:37.377614 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:42:37.377614 16412 solver.cpp:237]     Train net output #1: loss = 1.72387 (* 1 = 1.72387 loss)
I1210 09:42:37.377614 16412 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1210 09:42:43.053692 16412 solver.cpp:218] Iteration 31100 (17.6196 iter/s, 5.67551s/100 iters), loss = 1.52942
I1210 09:42:43.053692 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:42:43.053692 16412 solver.cpp:237]     Train net output #1: loss = 1.52942 (* 1 = 1.52942 loss)
I1210 09:42:43.053692 16412 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1210 09:42:48.725603 16412 solver.cpp:218] Iteration 31200 (17.6294 iter/s, 5.67233s/100 iters), loss = 1.27865
I1210 09:42:48.726604 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:42:48.726604 16412 solver.cpp:237]     Train net output #1: loss = 1.27865 (* 1 = 1.27865 loss)
I1210 09:42:48.726604 16412 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1210 09:42:54.397992 16412 solver.cpp:218] Iteration 31300 (17.6326 iter/s, 5.67132s/100 iters), loss = 1.62811
I1210 09:42:54.397992 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:42:54.397992 16412 solver.cpp:237]     Train net output #1: loss = 1.62811 (* 1 = 1.62811 loss)
I1210 09:42:54.397992 16412 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1210 09:43:00.073364 16412 solver.cpp:218] Iteration 31400 (17.6211 iter/s, 5.67501s/100 iters), loss = 1.85835
I1210 09:43:00.073364 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:43:00.073364 16412 solver.cpp:237]     Train net output #1: loss = 1.85835 (* 1 = 1.85835 loss)
I1210 09:43:00.073364 16412 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1210 09:43:05.465736  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:43:05.689745 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_31500.caffemodel
I1210 09:43:05.703747 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_31500.solverstate
I1210 09:43:05.707746 16412 solver.cpp:330] Iteration 31500, Testing net (#0)
I1210 09:43:05.708747 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:43:07.074857 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:43:07.129856 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4112
I1210 09:43:07.129856 16412 solver.cpp:397]     Test net output #1: loss = 2.26932 (* 1 = 2.26932 loss)
I1210 09:43:07.183861 16412 solver.cpp:218] Iteration 31500 (14.0643 iter/s, 7.11018s/100 iters), loss = 1.62014
I1210 09:43:07.183861 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:43:07.183861 16412 solver.cpp:237]     Train net output #1: loss = 1.62014 (* 1 = 1.62014 loss)
I1210 09:43:07.183861 16412 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1210 09:43:12.862224 16412 solver.cpp:218] Iteration 31600 (17.6116 iter/s, 5.67808s/100 iters), loss = 1.35438
I1210 09:43:12.862224 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:43:12.862224 16412 solver.cpp:237]     Train net output #1: loss = 1.35438 (* 1 = 1.35438 loss)
I1210 09:43:12.862224 16412 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1210 09:43:18.540614 16412 solver.cpp:218] Iteration 31700 (17.6132 iter/s, 5.67756s/100 iters), loss = 1.34278
I1210 09:43:18.540614 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:43:18.540614 16412 solver.cpp:237]     Train net output #1: loss = 1.34278 (* 1 = 1.34278 loss)
I1210 09:43:18.540614 16412 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1210 09:43:24.217023 16412 solver.cpp:218] Iteration 31800 (17.6189 iter/s, 5.67572s/100 iters), loss = 1.72146
I1210 09:43:24.217023 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:43:24.217023 16412 solver.cpp:237]     Train net output #1: loss = 1.72146 (* 1 = 1.72146 loss)
I1210 09:43:24.217023 16412 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1210 09:43:29.887420 16412 solver.cpp:218] Iteration 31900 (17.6366 iter/s, 5.67004s/100 iters), loss = 1.69074
I1210 09:43:29.887420 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:43:29.887420 16412 solver.cpp:237]     Train net output #1: loss = 1.69074 (* 1 = 1.69074 loss)
I1210 09:43:29.887420 16412 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1210 09:43:35.281932  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:43:35.503087 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_32000.caffemodel
I1210 09:43:35.519068 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_32000.solverstate
I1210 09:43:35.523573 16412 solver.cpp:330] Iteration 32000, Testing net (#0)
I1210 09:43:35.523573 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:43:36.892760 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:43:36.946300 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3997
I1210 09:43:36.946300 16412 solver.cpp:397]     Test net output #1: loss = 2.50642 (* 1 = 2.50642 loss)
I1210 09:43:37.000298 16412 solver.cpp:218] Iteration 32000 (14.06 iter/s, 7.11237s/100 iters), loss = 1.72592
I1210 09:43:37.000298 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:43:37.000298 16412 solver.cpp:237]     Train net output #1: loss = 1.72592 (* 1 = 1.72592 loss)
I1210 09:43:37.000298 16412 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1210 09:43:42.662360 16412 solver.cpp:218] Iteration 32100 (17.6625 iter/s, 5.6617s/100 iters), loss = 1.4596
I1210 09:43:42.662360 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:43:42.662360 16412 solver.cpp:237]     Train net output #1: loss = 1.4596 (* 1 = 1.4596 loss)
I1210 09:43:42.662360 16412 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1210 09:43:48.324388 16412 solver.cpp:218] Iteration 32200 (17.6624 iter/s, 5.66173s/100 iters), loss = 1.32196
I1210 09:43:48.324388 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:43:48.324388 16412 solver.cpp:237]     Train net output #1: loss = 1.32196 (* 1 = 1.32196 loss)
I1210 09:43:48.324388 16412 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1210 09:43:53.996346 16412 solver.cpp:218] Iteration 32300 (17.6325 iter/s, 5.67136s/100 iters), loss = 1.80319
I1210 09:43:53.996346 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:43:53.996346 16412 solver.cpp:237]     Train net output #1: loss = 1.80319 (* 1 = 1.80319 loss)
I1210 09:43:53.996346 16412 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1210 09:43:59.662760 16412 solver.cpp:218] Iteration 32400 (17.6501 iter/s, 5.6657s/100 iters), loss = 1.82941
I1210 09:43:59.662760 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:43:59.662760 16412 solver.cpp:237]     Train net output #1: loss = 1.82941 (* 1 = 1.82941 loss)
I1210 09:43:59.662760 16412 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1210 09:44:05.058112  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:44:05.281126 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_32500.caffemodel
I1210 09:44:05.296126 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_32500.solverstate
I1210 09:44:05.301126 16412 solver.cpp:330] Iteration 32500, Testing net (#0)
I1210 09:44:05.301126 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:44:06.668244 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:44:06.724243 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3508
I1210 09:44:06.724243 16412 solver.cpp:397]     Test net output #1: loss = 2.63219 (* 1 = 2.63219 loss)
I1210 09:44:06.777252 16412 solver.cpp:218] Iteration 32500 (14.0566 iter/s, 7.11408s/100 iters), loss = 1.82242
I1210 09:44:06.777252 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:44:06.777252 16412 solver.cpp:237]     Train net output #1: loss = 1.82242 (* 1 = 1.82242 loss)
I1210 09:44:06.777252 16412 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1210 09:44:12.446243 16412 solver.cpp:218] Iteration 32600 (17.6409 iter/s, 5.66865s/100 iters), loss = 1.44666
I1210 09:44:12.446243 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:44:12.446243 16412 solver.cpp:237]     Train net output #1: loss = 1.44666 (* 1 = 1.44666 loss)
I1210 09:44:12.446243 16412 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1210 09:44:18.116164 16412 solver.cpp:218] Iteration 32700 (17.6379 iter/s, 5.66961s/100 iters), loss = 1.36123
I1210 09:44:18.116164 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:44:18.116164 16412 solver.cpp:237]     Train net output #1: loss = 1.36123 (* 1 = 1.36123 loss)
I1210 09:44:18.116164 16412 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1210 09:44:23.786589 16412 solver.cpp:218] Iteration 32800 (17.6352 iter/s, 5.67048s/100 iters), loss = 1.71476
I1210 09:44:23.786589 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:44:23.786589 16412 solver.cpp:237]     Train net output #1: loss = 1.71476 (* 1 = 1.71476 loss)
I1210 09:44:23.786589 16412 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1210 09:44:29.465984 16412 solver.cpp:218] Iteration 32900 (17.6092 iter/s, 5.67884s/100 iters), loss = 1.82586
I1210 09:44:29.465984 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:44:29.465984 16412 solver.cpp:237]     Train net output #1: loss = 1.82586 (* 1 = 1.82586 loss)
I1210 09:44:29.465984 16412 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1210 09:44:34.864523  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:44:35.086534 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_33000.caffemodel
I1210 09:44:35.102536 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_33000.solverstate
I1210 09:44:35.107535 16412 solver.cpp:330] Iteration 33000, Testing net (#0)
I1210 09:44:35.107535 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:44:36.477663 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:44:36.530663 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3018
I1210 09:44:36.530663 16412 solver.cpp:397]     Test net output #1: loss = 3.18132 (* 1 = 3.18132 loss)
I1210 09:44:36.584672 16412 solver.cpp:218] Iteration 33000 (14.0484 iter/s, 7.11826s/100 iters), loss = 1.56204
I1210 09:44:36.584672 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:44:36.584672 16412 solver.cpp:237]     Train net output #1: loss = 1.56204 (* 1 = 1.56204 loss)
I1210 09:44:36.584672 16412 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1210 09:44:42.260170 16412 solver.cpp:218] Iteration 33100 (17.6206 iter/s, 5.67516s/100 iters), loss = 1.45712
I1210 09:44:42.261167 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:44:42.261167 16412 solver.cpp:237]     Train net output #1: loss = 1.45712 (* 1 = 1.45712 loss)
I1210 09:44:42.261167 16412 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1210 09:44:47.936060 16412 solver.cpp:218] Iteration 33200 (17.6214 iter/s, 5.67493s/100 iters), loss = 1.25615
I1210 09:44:47.936561 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 09:44:47.936561 16412 solver.cpp:237]     Train net output #1: loss = 1.25615 (* 1 = 1.25615 loss)
I1210 09:44:47.936561 16412 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1210 09:44:53.611086 16412 solver.cpp:218] Iteration 33300 (17.6225 iter/s, 5.67456s/100 iters), loss = 1.72314
I1210 09:44:53.611086 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:44:53.611086 16412 solver.cpp:237]     Train net output #1: loss = 1.72314 (* 1 = 1.72314 loss)
I1210 09:44:53.611086 16412 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1210 09:44:59.287482 16412 solver.cpp:218] Iteration 33400 (17.6182 iter/s, 5.67596s/100 iters), loss = 1.68528
I1210 09:44:59.287482 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:44:59.287482 16412 solver.cpp:237]     Train net output #1: loss = 1.68528 (* 1 = 1.68528 loss)
I1210 09:44:59.287482 16412 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1210 09:45:04.690840  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:45:04.913849 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_33500.caffemodel
I1210 09:45:04.928849 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_33500.solverstate
I1210 09:45:04.933850 16412 solver.cpp:330] Iteration 33500, Testing net (#0)
I1210 09:45:04.933850 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:45:06.302997 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:45:06.356000 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3622
I1210 09:45:06.356000 16412 solver.cpp:397]     Test net output #1: loss = 2.64195 (* 1 = 2.64195 loss)
I1210 09:45:06.411006 16412 solver.cpp:218] Iteration 33500 (14.0397 iter/s, 7.12268s/100 iters), loss = 1.58995
I1210 09:45:06.411006 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:45:06.411006 16412 solver.cpp:237]     Train net output #1: loss = 1.58995 (* 1 = 1.58995 loss)
I1210 09:45:06.411006 16412 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1210 09:45:12.084414 16412 solver.cpp:218] Iteration 33600 (17.6266 iter/s, 5.67324s/100 iters), loss = 1.6042
I1210 09:45:12.084414 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:45:12.084414 16412 solver.cpp:237]     Train net output #1: loss = 1.6042 (* 1 = 1.6042 loss)
I1210 09:45:12.084414 16412 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1210 09:45:17.758249 16412 solver.cpp:218] Iteration 33700 (17.6271 iter/s, 5.67307s/100 iters), loss = 1.22074
I1210 09:45:17.758249 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 09:45:17.758249 16412 solver.cpp:237]     Train net output #1: loss = 1.22074 (* 1 = 1.22074 loss)
I1210 09:45:17.758249 16412 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1210 09:45:23.438241 16412 solver.cpp:218] Iteration 33800 (17.6055 iter/s, 5.68004s/100 iters), loss = 1.64251
I1210 09:45:23.438241 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:45:23.438241 16412 solver.cpp:237]     Train net output #1: loss = 1.64251 (* 1 = 1.64251 loss)
I1210 09:45:23.438241 16412 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1210 09:45:29.111963 16412 solver.cpp:218] Iteration 33900 (17.6284 iter/s, 5.67267s/100 iters), loss = 1.72862
I1210 09:45:29.111963 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:45:29.111963 16412 solver.cpp:237]     Train net output #1: loss = 1.72862 (* 1 = 1.72862 loss)
I1210 09:45:29.111963 16412 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1210 09:45:34.508512  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:45:34.731531 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_34000.caffemodel
I1210 09:45:34.745524 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_34000.solverstate
I1210 09:45:34.750030 16412 solver.cpp:330] Iteration 34000, Testing net (#0)
I1210 09:45:34.750030 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:45:36.117638 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:45:36.171643 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3447
I1210 09:45:36.171643 16412 solver.cpp:397]     Test net output #1: loss = 2.88027 (* 1 = 2.88027 loss)
I1210 09:45:36.227643 16412 solver.cpp:218] Iteration 34000 (14.0529 iter/s, 7.11596s/100 iters), loss = 1.54582
I1210 09:45:36.227643 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:45:36.227643 16412 solver.cpp:237]     Train net output #1: loss = 1.54582 (* 1 = 1.54582 loss)
I1210 09:45:36.227643 16412 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1210 09:45:41.902189 16412 solver.cpp:218] Iteration 34100 (17.6253 iter/s, 5.67368s/100 iters), loss = 1.45181
I1210 09:45:41.902189 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:45:41.902189 16412 solver.cpp:237]     Train net output #1: loss = 1.45181 (* 1 = 1.45181 loss)
I1210 09:45:41.902189 16412 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1210 09:45:47.578537 16412 solver.cpp:218] Iteration 34200 (17.6185 iter/s, 5.67585s/100 iters), loss = 1.31342
I1210 09:45:47.578537 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:45:47.578537 16412 solver.cpp:237]     Train net output #1: loss = 1.31342 (* 1 = 1.31342 loss)
I1210 09:45:47.578537 16412 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1210 09:45:53.251454 16412 solver.cpp:218] Iteration 34300 (17.6299 iter/s, 5.67219s/100 iters), loss = 1.88661
I1210 09:45:53.251454 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:45:53.251454 16412 solver.cpp:237]     Train net output #1: loss = 1.88661 (* 1 = 1.88661 loss)
I1210 09:45:53.251454 16412 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1210 09:45:58.925390 16412 solver.cpp:218] Iteration 34400 (17.6247 iter/s, 5.67387s/100 iters), loss = 1.83546
I1210 09:45:58.925390 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:45:58.925390 16412 solver.cpp:237]     Train net output #1: loss = 1.83546 (* 1 = 1.83546 loss)
I1210 09:45:58.925390 16412 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1210 09:46:04.318775  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:46:04.542785 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_34500.caffemodel
I1210 09:46:04.558290 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_34500.solverstate
I1210 09:46:04.562791 16412 solver.cpp:330] Iteration 34500, Testing net (#0)
I1210 09:46:04.562791 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:46:05.933423 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:46:05.986928 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3805
I1210 09:46:05.986928 16412 solver.cpp:397]     Test net output #1: loss = 2.5596 (* 1 = 2.5596 loss)
I1210 09:46:06.040930 16412 solver.cpp:218] Iteration 34500 (14.0545 iter/s, 7.11517s/100 iters), loss = 1.60196
I1210 09:46:06.040930 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:46:06.040930 16412 solver.cpp:237]     Train net output #1: loss = 1.60196 (* 1 = 1.60196 loss)
I1210 09:46:06.040930 16412 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1210 09:46:11.722422 16412 solver.cpp:218] Iteration 34600 (17.604 iter/s, 5.68052s/100 iters), loss = 1.49861
I1210 09:46:11.722422 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:46:11.722422 16412 solver.cpp:237]     Train net output #1: loss = 1.49861 (* 1 = 1.49861 loss)
I1210 09:46:11.722422 16412 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1210 09:46:17.400928 16412 solver.cpp:218] Iteration 34700 (17.611 iter/s, 5.67826s/100 iters), loss = 1.32056
I1210 09:46:17.400928 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:46:17.400928 16412 solver.cpp:237]     Train net output #1: loss = 1.32056 (* 1 = 1.32056 loss)
I1210 09:46:17.400928 16412 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1210 09:46:23.077344 16412 solver.cpp:218] Iteration 34800 (17.6168 iter/s, 5.67641s/100 iters), loss = 1.71931
I1210 09:46:23.077344 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:46:23.077344 16412 solver.cpp:237]     Train net output #1: loss = 1.71931 (* 1 = 1.71931 loss)
I1210 09:46:23.077344 16412 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1210 09:46:28.750743 16412 solver.cpp:218] Iteration 34900 (17.63 iter/s, 5.67216s/100 iters), loss = 1.83452
I1210 09:46:28.750743 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:46:28.750743 16412 solver.cpp:237]     Train net output #1: loss = 1.83452 (* 1 = 1.83452 loss)
I1210 09:46:28.750743 16412 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1210 09:46:34.149138  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:46:34.373148 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_35000.caffemodel
I1210 09:46:34.386148 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_35000.solverstate
I1210 09:46:34.391149 16412 solver.cpp:330] Iteration 35000, Testing net (#0)
I1210 09:46:34.391149 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:46:35.762316 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:46:35.816315 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3606
I1210 09:46:35.817317 16412 solver.cpp:397]     Test net output #1: loss = 2.59762 (* 1 = 2.59762 loss)
I1210 09:46:35.870321 16412 solver.cpp:218] Iteration 35000 (14.0456 iter/s, 7.11966s/100 iters), loss = 1.72749
I1210 09:46:35.870321 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:46:35.870321 16412 solver.cpp:237]     Train net output #1: loss = 1.72749 (* 1 = 1.72749 loss)
I1210 09:46:35.870321 16412 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1210 09:46:41.537237 16412 solver.cpp:218] Iteration 35100 (17.6486 iter/s, 5.66618s/100 iters), loss = 1.42761
I1210 09:46:41.537237 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:46:41.537237 16412 solver.cpp:237]     Train net output #1: loss = 1.42761 (* 1 = 1.42761 loss)
I1210 09:46:41.537237 16412 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1210 09:46:47.202126 16412 solver.cpp:218] Iteration 35200 (17.6533 iter/s, 5.66465s/100 iters), loss = 1.33402
I1210 09:46:47.202126 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:46:47.202126 16412 solver.cpp:237]     Train net output #1: loss = 1.33402 (* 1 = 1.33402 loss)
I1210 09:46:47.202126 16412 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1210 09:46:52.874564 16412 solver.cpp:218] Iteration 35300 (17.6301 iter/s, 5.67211s/100 iters), loss = 1.69097
I1210 09:46:52.874564 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:46:52.874564 16412 solver.cpp:237]     Train net output #1: loss = 1.69097 (* 1 = 1.69097 loss)
I1210 09:46:52.874564 16412 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1210 09:46:58.551973 16412 solver.cpp:218] Iteration 35400 (17.6157 iter/s, 5.67675s/100 iters), loss = 1.74479
I1210 09:46:58.551973 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:46:58.551973 16412 solver.cpp:237]     Train net output #1: loss = 1.74479 (* 1 = 1.74479 loss)
I1210 09:46:58.551973 16412 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1210 09:47:03.950438  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:47:04.172453 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_35500.caffemodel
I1210 09:47:04.188453 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_35500.solverstate
I1210 09:47:04.193454 16412 solver.cpp:330] Iteration 35500, Testing net (#0)
I1210 09:47:04.193454 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:47:05.564616 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:47:05.618615 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3743
I1210 09:47:05.618615 16412 solver.cpp:397]     Test net output #1: loss = 2.65858 (* 1 = 2.65858 loss)
I1210 09:47:05.672627 16412 solver.cpp:218] Iteration 35500 (14.0448 iter/s, 7.12007s/100 iters), loss = 1.51675
I1210 09:47:05.672627 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:47:05.672627 16412 solver.cpp:237]     Train net output #1: loss = 1.51675 (* 1 = 1.51675 loss)
I1210 09:47:05.672627 16412 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1210 09:47:11.344514 16412 solver.cpp:218] Iteration 35600 (17.6322 iter/s, 5.67143s/100 iters), loss = 1.42996
I1210 09:47:11.344514 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:47:11.344514 16412 solver.cpp:237]     Train net output #1: loss = 1.42996 (* 1 = 1.42996 loss)
I1210 09:47:11.344514 16412 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1210 09:47:17.022393 16412 solver.cpp:218] Iteration 35700 (17.6139 iter/s, 5.67733s/100 iters), loss = 1.27823
I1210 09:47:17.022393 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:47:17.022393 16412 solver.cpp:237]     Train net output #1: loss = 1.27823 (* 1 = 1.27823 loss)
I1210 09:47:17.022393 16412 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1210 09:47:22.699105 16412 solver.cpp:218] Iteration 35800 (17.6172 iter/s, 5.67628s/100 iters), loss = 1.65237
I1210 09:47:22.699105 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:47:22.699105 16412 solver.cpp:237]     Train net output #1: loss = 1.65237 (* 1 = 1.65237 loss)
I1210 09:47:22.699105 16412 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1210 09:47:28.367631 16412 solver.cpp:218] Iteration 35900 (17.6443 iter/s, 5.66754s/100 iters), loss = 1.82745
I1210 09:47:28.367631 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:47:28.367631 16412 solver.cpp:237]     Train net output #1: loss = 1.82745 (* 1 = 1.82745 loss)
I1210 09:47:28.367631 16412 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1210 09:47:33.756458  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:47:33.979579 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_36000.caffemodel
I1210 09:47:33.994576 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_36000.solverstate
I1210 09:47:33.998577 16412 solver.cpp:330] Iteration 36000, Testing net (#0)
I1210 09:47:33.998577 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:47:35.365917 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:47:35.419922 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3766
I1210 09:47:35.419922 16412 solver.cpp:397]     Test net output #1: loss = 2.44332 (* 1 = 2.44332 loss)
I1210 09:47:35.474448 16412 solver.cpp:218] Iteration 36000 (14.0723 iter/s, 7.10617s/100 iters), loss = 1.52275
I1210 09:47:35.474448 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:47:35.474448 16412 solver.cpp:237]     Train net output #1: loss = 1.52275 (* 1 = 1.52275 loss)
I1210 09:47:35.474448 16412 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1210 09:47:41.134599 16412 solver.cpp:218] Iteration 36100 (17.6658 iter/s, 5.66066s/100 iters), loss = 1.51544
I1210 09:47:41.135584 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:47:41.135584 16412 solver.cpp:237]     Train net output #1: loss = 1.51544 (* 1 = 1.51544 loss)
I1210 09:47:41.135584 16412 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1210 09:47:46.806808 16412 solver.cpp:218] Iteration 36200 (17.6346 iter/s, 5.67067s/100 iters), loss = 1.13437
I1210 09:47:46.806808 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:47:46.806808 16412 solver.cpp:237]     Train net output #1: loss = 1.13437 (* 1 = 1.13437 loss)
I1210 09:47:46.806808 16412 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1210 09:47:52.473976 16412 solver.cpp:218] Iteration 36300 (17.644 iter/s, 5.66766s/100 iters), loss = 1.70035
I1210 09:47:52.474977 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:47:52.474977 16412 solver.cpp:237]     Train net output #1: loss = 1.70035 (* 1 = 1.70035 loss)
I1210 09:47:52.474977 16412 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1210 09:47:58.138169 16412 solver.cpp:218] Iteration 36400 (17.6586 iter/s, 5.66296s/100 iters), loss = 1.78181
I1210 09:47:58.138169 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1210 09:47:58.138169 16412 solver.cpp:237]     Train net output #1: loss = 1.78181 (* 1 = 1.78181 loss)
I1210 09:47:58.138169 16412 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1210 09:48:03.520587  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:48:03.743124 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_36500.caffemodel
I1210 09:48:03.758123 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_36500.solverstate
I1210 09:48:03.762125 16412 solver.cpp:330] Iteration 36500, Testing net (#0)
I1210 09:48:03.762125 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:48:05.128841 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:48:05.182432 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3825
I1210 09:48:05.182432 16412 solver.cpp:397]     Test net output #1: loss = 2.48723 (* 1 = 2.48723 loss)
I1210 09:48:05.236441 16412 solver.cpp:218] Iteration 36500 (14.088 iter/s, 7.09824s/100 iters), loss = 1.72164
I1210 09:48:05.236441 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:48:05.236441 16412 solver.cpp:237]     Train net output #1: loss = 1.72164 (* 1 = 1.72164 loss)
I1210 09:48:05.236441 16412 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1210 09:48:10.916661 16412 solver.cpp:218] Iteration 36600 (17.6062 iter/s, 5.67983s/100 iters), loss = 1.25935
I1210 09:48:10.916661 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:48:10.916661 16412 solver.cpp:237]     Train net output #1: loss = 1.25935 (* 1 = 1.25935 loss)
I1210 09:48:10.916661 16412 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1210 09:48:16.592979 16412 solver.cpp:218] Iteration 36700 (17.618 iter/s, 5.67602s/100 iters), loss = 1.26123
I1210 09:48:16.592979 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:48:16.592979 16412 solver.cpp:237]     Train net output #1: loss = 1.26123 (* 1 = 1.26123 loss)
I1210 09:48:16.592979 16412 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1210 09:48:22.268102 16412 solver.cpp:218] Iteration 36800 (17.6229 iter/s, 5.67445s/100 iters), loss = 1.69926
I1210 09:48:22.268102 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:48:22.268102 16412 solver.cpp:237]     Train net output #1: loss = 1.69926 (* 1 = 1.69926 loss)
I1210 09:48:22.268102 16412 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1210 09:48:27.945664 16412 solver.cpp:218] Iteration 36900 (17.6153 iter/s, 5.6769s/100 iters), loss = 1.60108
I1210 09:48:27.945664 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:48:27.945664 16412 solver.cpp:237]     Train net output #1: loss = 1.60108 (* 1 = 1.60108 loss)
I1210 09:48:27.945664 16412 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1210 09:48:33.347491  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:48:33.571815 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_37000.caffemodel
I1210 09:48:33.587334 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_37000.solverstate
I1210 09:48:33.591835 16412 solver.cpp:330] Iteration 37000, Testing net (#0)
I1210 09:48:33.592335 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:48:34.961215 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:48:35.014752 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3503
I1210 09:48:35.014752 16412 solver.cpp:397]     Test net output #1: loss = 2.73277 (* 1 = 2.73277 loss)
I1210 09:48:35.068753 16412 solver.cpp:218] Iteration 37000 (14.0392 iter/s, 7.12293s/100 iters), loss = 1.73381
I1210 09:48:35.068753 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:48:35.068753 16412 solver.cpp:237]     Train net output #1: loss = 1.73381 (* 1 = 1.73381 loss)
I1210 09:48:35.068753 16412 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1210 09:48:40.740654 16412 solver.cpp:218] Iteration 37100 (17.6324 iter/s, 5.67137s/100 iters), loss = 1.33448
I1210 09:48:40.740654 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:48:40.740654 16412 solver.cpp:237]     Train net output #1: loss = 1.33448 (* 1 = 1.33448 loss)
I1210 09:48:40.740654 16412 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1210 09:48:46.420013 16412 solver.cpp:218] Iteration 37200 (17.6082 iter/s, 5.67917s/100 iters), loss = 1.26286
I1210 09:48:46.420013 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:48:46.420013 16412 solver.cpp:237]     Train net output #1: loss = 1.26286 (* 1 = 1.26286 loss)
I1210 09:48:46.420013 16412 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1210 09:48:52.100589 16412 solver.cpp:218] Iteration 37300 (17.6063 iter/s, 5.67978s/100 iters), loss = 1.69376
I1210 09:48:52.100589 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:48:52.101089 16412 solver.cpp:237]     Train net output #1: loss = 1.69376 (* 1 = 1.69376 loss)
I1210 09:48:52.101089 16412 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1210 09:48:57.775687 16412 solver.cpp:218] Iteration 37400 (17.621 iter/s, 5.67505s/100 iters), loss = 1.72875
I1210 09:48:57.775687 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:48:57.775687 16412 solver.cpp:237]     Train net output #1: loss = 1.72875 (* 1 = 1.72875 loss)
I1210 09:48:57.775687 16412 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1210 09:49:03.167965  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:49:03.393105 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_37500.caffemodel
I1210 09:49:03.407102 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_37500.solverstate
I1210 09:49:03.411118 16412 solver.cpp:330] Iteration 37500, Testing net (#0)
I1210 09:49:03.412118 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:49:04.782668 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:49:04.836702 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3716
I1210 09:49:04.836702 16412 solver.cpp:397]     Test net output #1: loss = 2.65154 (* 1 = 2.65154 loss)
I1210 09:49:04.890717 16412 solver.cpp:218] Iteration 37500 (14.0562 iter/s, 7.11431s/100 iters), loss = 1.55154
I1210 09:49:04.890717 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:49:04.890717 16412 solver.cpp:237]     Train net output #1: loss = 1.55154 (* 1 = 1.55154 loss)
I1210 09:49:04.890717 16412 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1210 09:49:10.564409 16412 solver.cpp:218] Iteration 37600 (17.6252 iter/s, 5.67369s/100 iters), loss = 1.44132
I1210 09:49:10.565410 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:49:10.565410 16412 solver.cpp:237]     Train net output #1: loss = 1.44132 (* 1 = 1.44132 loss)
I1210 09:49:10.565410 16412 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1210 09:49:16.236369 16412 solver.cpp:218] Iteration 37700 (17.6329 iter/s, 5.67123s/100 iters), loss = 1.3496
I1210 09:49:16.236369 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:49:16.236369 16412 solver.cpp:237]     Train net output #1: loss = 1.3496 (* 1 = 1.3496 loss)
I1210 09:49:16.236369 16412 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1210 09:49:21.907902 16412 solver.cpp:218] Iteration 37800 (17.6342 iter/s, 5.6708s/100 iters), loss = 1.68494
I1210 09:49:21.908407 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:49:21.908407 16412 solver.cpp:237]     Train net output #1: loss = 1.68494 (* 1 = 1.68494 loss)
I1210 09:49:21.908407 16412 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1210 09:49:27.577250 16412 solver.cpp:218] Iteration 37900 (17.6386 iter/s, 5.66939s/100 iters), loss = 1.56978
I1210 09:49:27.578254 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:49:27.578254 16412 solver.cpp:237]     Train net output #1: loss = 1.56978 (* 1 = 1.56978 loss)
I1210 09:49:27.578254 16412 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1210 09:49:32.968653  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:49:33.192688 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_38000.caffemodel
I1210 09:49:33.211194 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_38000.solverstate
I1210 09:49:33.217195 16412 solver.cpp:330] Iteration 38000, Testing net (#0)
I1210 09:49:33.217195 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:49:34.583801 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:49:34.636804 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3591
I1210 09:49:34.636804 16412 solver.cpp:397]     Test net output #1: loss = 2.75577 (* 1 = 2.75577 loss)
I1210 09:49:34.690806 16412 solver.cpp:218] Iteration 38000 (14.0588 iter/s, 7.113s/100 iters), loss = 1.53774
I1210 09:49:34.690806 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:49:34.690806 16412 solver.cpp:237]     Train net output #1: loss = 1.53774 (* 1 = 1.53774 loss)
I1210 09:49:34.690806 16412 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1210 09:49:40.360296 16412 solver.cpp:218] Iteration 38100 (17.6399 iter/s, 5.66897s/100 iters), loss = 1.36806
I1210 09:49:40.360296 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:49:40.360296 16412 solver.cpp:237]     Train net output #1: loss = 1.36806 (* 1 = 1.36806 loss)
I1210 09:49:40.360296 16412 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1210 09:49:46.034462 16412 solver.cpp:218] Iteration 38200 (17.6271 iter/s, 5.67309s/100 iters), loss = 1.25407
I1210 09:49:46.034462 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:49:46.034462 16412 solver.cpp:237]     Train net output #1: loss = 1.25407 (* 1 = 1.25407 loss)
I1210 09:49:46.034462 16412 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1210 09:49:51.697705 16412 solver.cpp:218] Iteration 38300 (17.6574 iter/s, 5.66336s/100 iters), loss = 1.69909
I1210 09:49:51.697705 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:49:51.697705 16412 solver.cpp:237]     Train net output #1: loss = 1.69909 (* 1 = 1.69909 loss)
I1210 09:49:51.697705 16412 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1210 09:49:57.371068 16412 solver.cpp:218] Iteration 38400 (17.6271 iter/s, 5.67308s/100 iters), loss = 1.79259
I1210 09:49:57.372072 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:49:57.372072 16412 solver.cpp:237]     Train net output #1: loss = 1.79259 (* 1 = 1.79259 loss)
I1210 09:49:57.372072 16412 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1210 09:50:02.792215  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:50:03.014734 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_38500.caffemodel
I1210 09:50:03.035238 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_38500.solverstate
I1210 09:50:03.041239 16412 solver.cpp:330] Iteration 38500, Testing net (#0)
I1210 09:50:03.041239 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:50:04.409389 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:50:04.462427 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3915
I1210 09:50:04.462427 16412 solver.cpp:397]     Test net output #1: loss = 2.43723 (* 1 = 2.43723 loss)
I1210 09:50:04.516446 16412 solver.cpp:218] Iteration 38500 (13.9972 iter/s, 7.1443s/100 iters), loss = 1.69841
I1210 09:50:04.516446 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:50:04.516446 16412 solver.cpp:237]     Train net output #1: loss = 1.69841 (* 1 = 1.69841 loss)
I1210 09:50:04.516446 16412 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1210 09:50:10.194954 16412 solver.cpp:218] Iteration 38600 (17.6099 iter/s, 5.67862s/100 iters), loss = 1.43074
I1210 09:50:10.194954 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:50:10.194954 16412 solver.cpp:237]     Train net output #1: loss = 1.43074 (* 1 = 1.43074 loss)
I1210 09:50:10.194954 16412 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1210 09:50:15.876379 16412 solver.cpp:218] Iteration 38700 (17.6027 iter/s, 5.68094s/100 iters), loss = 1.35221
I1210 09:50:15.876379 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:50:15.876379 16412 solver.cpp:237]     Train net output #1: loss = 1.35221 (* 1 = 1.35221 loss)
I1210 09:50:15.876379 16412 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1210 09:50:21.562811 16412 solver.cpp:218] Iteration 38800 (17.5874 iter/s, 5.6859s/100 iters), loss = 1.66048
I1210 09:50:21.562811 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:50:21.562811 16412 solver.cpp:237]     Train net output #1: loss = 1.66048 (* 1 = 1.66048 loss)
I1210 09:50:21.562811 16412 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1210 09:50:27.243201 16412 solver.cpp:218] Iteration 38900 (17.6061 iter/s, 5.67986s/100 iters), loss = 1.68891
I1210 09:50:27.243201 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:50:27.243201 16412 solver.cpp:237]     Train net output #1: loss = 1.68891 (* 1 = 1.68891 loss)
I1210 09:50:27.243201 16412 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1210 09:50:32.642554  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:50:32.865566 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_39000.caffemodel
I1210 09:50:32.878566 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_39000.solverstate
I1210 09:50:32.882565 16412 solver.cpp:330] Iteration 39000, Testing net (#0)
I1210 09:50:32.882565 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:50:34.249693 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:50:34.304694 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4087
I1210 09:50:34.304694 16412 solver.cpp:397]     Test net output #1: loss = 2.36509 (* 1 = 2.36509 loss)
I1210 09:50:34.358700 16412 solver.cpp:218] Iteration 39000 (14.0557 iter/s, 7.11454s/100 iters), loss = 1.57943
I1210 09:50:34.358700 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:50:34.358700 16412 solver.cpp:237]     Train net output #1: loss = 1.57943 (* 1 = 1.57943 loss)
I1210 09:50:34.358700 16412 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1210 09:50:40.032644 16412 solver.cpp:218] Iteration 39100 (17.6251 iter/s, 5.67373s/100 iters), loss = 1.49163
I1210 09:50:40.032644 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:50:40.032644 16412 solver.cpp:237]     Train net output #1: loss = 1.49163 (* 1 = 1.49163 loss)
I1210 09:50:40.032644 16412 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1210 09:50:45.706570 16412 solver.cpp:218] Iteration 39200 (17.6246 iter/s, 5.67389s/100 iters), loss = 1.25906
I1210 09:50:45.706570 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 09:50:45.706570 16412 solver.cpp:237]     Train net output #1: loss = 1.25906 (* 1 = 1.25906 loss)
I1210 09:50:45.706570 16412 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1210 09:50:51.381059 16412 solver.cpp:218] Iteration 39300 (17.6261 iter/s, 5.6734s/100 iters), loss = 1.67495
I1210 09:50:51.381059 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:50:51.381059 16412 solver.cpp:237]     Train net output #1: loss = 1.67495 (* 1 = 1.67495 loss)
I1210 09:50:51.381059 16412 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1210 09:50:57.048468 16412 solver.cpp:218] Iteration 39400 (17.6448 iter/s, 5.66738s/100 iters), loss = 1.65816
I1210 09:50:57.048468 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:50:57.048468 16412 solver.cpp:237]     Train net output #1: loss = 1.65816 (* 1 = 1.65816 loss)
I1210 09:50:57.048468 16412 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1210 09:51:02.446885  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:51:02.667899 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_39500.caffemodel
I1210 09:51:02.688899 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_39500.solverstate
I1210 09:51:02.693898 16412 solver.cpp:330] Iteration 39500, Testing net (#0)
I1210 09:51:02.693898 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:51:04.060941 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:51:04.114941 16412 solver.cpp:397]     Test net output #0: accuracy = 0.453
I1210 09:51:04.114941 16412 solver.cpp:397]     Test net output #1: loss = 2.14036 (* 1 = 2.14036 loss)
I1210 09:51:04.168949 16412 solver.cpp:218] Iteration 39500 (14.0451 iter/s, 7.11994s/100 iters), loss = 1.57294
I1210 09:51:04.168949 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:51:04.168949 16412 solver.cpp:237]     Train net output #1: loss = 1.57294 (* 1 = 1.57294 loss)
I1210 09:51:04.168949 16412 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1210 09:51:09.847340 16412 solver.cpp:218] Iteration 39600 (17.6104 iter/s, 5.67846s/100 iters), loss = 1.48108
I1210 09:51:09.847340 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:51:09.847340 16412 solver.cpp:237]     Train net output #1: loss = 1.48108 (* 1 = 1.48108 loss)
I1210 09:51:09.848341 16412 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1210 09:51:15.531242 16412 solver.cpp:218] Iteration 39700 (17.5963 iter/s, 5.68301s/100 iters), loss = 1.29219
I1210 09:51:15.531744 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:51:15.531744 16412 solver.cpp:237]     Train net output #1: loss = 1.29219 (* 1 = 1.29219 loss)
I1210 09:51:15.531744 16412 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1210 09:51:21.201411 16412 solver.cpp:218] Iteration 39800 (17.6382 iter/s, 5.66952s/100 iters), loss = 1.66957
I1210 09:51:21.201411 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:51:21.201411 16412 solver.cpp:237]     Train net output #1: loss = 1.66957 (* 1 = 1.66957 loss)
I1210 09:51:21.201411 16412 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1210 09:51:26.872870 16412 solver.cpp:218] Iteration 39900 (17.6339 iter/s, 5.6709s/100 iters), loss = 1.77611
I1210 09:51:26.872870 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:51:26.872870 16412 solver.cpp:237]     Train net output #1: loss = 1.77611 (* 1 = 1.77611 loss)
I1210 09:51:26.872870 16412 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1210 09:51:32.267678  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:51:32.491765 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_40000.caffemodel
I1210 09:51:32.506784 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_40000.solverstate
I1210 09:51:32.511778 16412 solver.cpp:330] Iteration 40000, Testing net (#0)
I1210 09:51:32.511778 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:51:33.881726 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:51:33.935250 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3892
I1210 09:51:33.935748 16412 solver.cpp:397]     Test net output #1: loss = 2.38821 (* 1 = 2.38821 loss)
I1210 09:51:33.989763 16412 solver.cpp:218] Iteration 40000 (14.0516 iter/s, 7.11664s/100 iters), loss = 1.61729
I1210 09:51:33.989763 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:51:33.989763 16412 solver.cpp:237]     Train net output #1: loss = 1.61729 (* 1 = 1.61729 loss)
I1210 09:51:33.989763 16412 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1210 09:51:39.659785 16412 solver.cpp:218] Iteration 40100 (17.6377 iter/s, 5.66968s/100 iters), loss = 1.2955
I1210 09:51:39.659785 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:51:39.659785 16412 solver.cpp:237]     Train net output #1: loss = 1.2955 (* 1 = 1.2955 loss)
I1210 09:51:39.659785 16412 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1210 09:51:45.330579 16412 solver.cpp:218] Iteration 40200 (17.6348 iter/s, 5.67061s/100 iters), loss = 1.2657
I1210 09:51:45.330579 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:51:45.330579 16412 solver.cpp:237]     Train net output #1: loss = 1.2657 (* 1 = 1.2657 loss)
I1210 09:51:45.330579 16412 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1210 09:51:50.998246 16412 solver.cpp:218] Iteration 40300 (17.6466 iter/s, 5.66682s/100 iters), loss = 1.64997
I1210 09:51:50.998246 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:51:50.998246 16412 solver.cpp:237]     Train net output #1: loss = 1.64997 (* 1 = 1.64997 loss)
I1210 09:51:50.998246 16412 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1210 09:51:56.666710 16412 solver.cpp:218] Iteration 40400 (17.6422 iter/s, 5.66823s/100 iters), loss = 1.82106
I1210 09:51:56.666710 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:51:56.666710 16412 solver.cpp:237]     Train net output #1: loss = 1.82106 (* 1 = 1.82106 loss)
I1210 09:51:56.666710 16412 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1210 09:52:02.060443  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:52:02.283509 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_40500.caffemodel
I1210 09:52:02.297509 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_40500.solverstate
I1210 09:52:02.302510 16412 solver.cpp:330] Iteration 40500, Testing net (#0)
I1210 09:52:02.302510 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:52:03.668808 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:52:03.722805 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3944
I1210 09:52:03.722805 16412 solver.cpp:397]     Test net output #1: loss = 2.39076 (* 1 = 2.39076 loss)
I1210 09:52:03.777837 16412 solver.cpp:218] Iteration 40500 (14.064 iter/s, 7.11037s/100 iters), loss = 1.60343
I1210 09:52:03.777837 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:52:03.777837 16412 solver.cpp:237]     Train net output #1: loss = 1.60343 (* 1 = 1.60343 loss)
I1210 09:52:03.777837 16412 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1210 09:52:09.446840 16412 solver.cpp:218] Iteration 40600 (17.6415 iter/s, 5.66844s/100 iters), loss = 1.45247
I1210 09:52:09.446840 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:52:09.446840 16412 solver.cpp:237]     Train net output #1: loss = 1.45247 (* 1 = 1.45247 loss)
I1210 09:52:09.446840 16412 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1210 09:52:15.120010 16412 solver.cpp:218] Iteration 40700 (17.6277 iter/s, 5.67288s/100 iters), loss = 1.38156
I1210 09:52:15.120010 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:52:15.120010 16412 solver.cpp:237]     Train net output #1: loss = 1.38156 (* 1 = 1.38156 loss)
I1210 09:52:15.120010 16412 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1210 09:52:20.789572 16412 solver.cpp:218] Iteration 40800 (17.6392 iter/s, 5.6692s/100 iters), loss = 1.80263
I1210 09:52:20.789572 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:52:20.789572 16412 solver.cpp:237]     Train net output #1: loss = 1.80263 (* 1 = 1.80263 loss)
I1210 09:52:20.789572 16412 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1210 09:52:26.452724 16412 solver.cpp:218] Iteration 40900 (17.6588 iter/s, 5.6629s/100 iters), loss = 1.52049
I1210 09:52:26.452724 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:52:26.452724 16412 solver.cpp:237]     Train net output #1: loss = 1.52049 (* 1 = 1.52049 loss)
I1210 09:52:26.452724 16412 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1210 09:52:31.842083  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:52:32.067253 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_41000.caffemodel
I1210 09:52:32.081794 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_41000.solverstate
I1210 09:52:32.085795 16412 solver.cpp:330] Iteration 41000, Testing net (#0)
I1210 09:52:32.085795 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:52:33.453402 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:52:33.506798 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3109
I1210 09:52:33.506798 16412 solver.cpp:397]     Test net output #1: loss = 3.29316 (* 1 = 3.29316 loss)
I1210 09:52:33.561327 16412 solver.cpp:218] Iteration 41000 (14.0692 iter/s, 7.10773s/100 iters), loss = 1.77578
I1210 09:52:33.561327 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:52:33.561327 16412 solver.cpp:237]     Train net output #1: loss = 1.77578 (* 1 = 1.77578 loss)
I1210 09:52:33.561327 16412 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1210 09:52:39.235566 16412 solver.cpp:218] Iteration 41100 (17.625 iter/s, 5.67374s/100 iters), loss = 1.38159
I1210 09:52:39.235566 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:52:39.235566 16412 solver.cpp:237]     Train net output #1: loss = 1.38159 (* 1 = 1.38159 loss)
I1210 09:52:39.235566 16412 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1210 09:52:44.902015 16412 solver.cpp:218] Iteration 41200 (17.6474 iter/s, 5.66656s/100 iters), loss = 1.42102
I1210 09:52:44.902015 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:52:44.902015 16412 solver.cpp:237]     Train net output #1: loss = 1.42102 (* 1 = 1.42102 loss)
I1210 09:52:44.902015 16412 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1210 09:52:50.579875 16412 solver.cpp:218] Iteration 41300 (17.6162 iter/s, 5.67659s/100 iters), loss = 1.61042
I1210 09:52:50.579875 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:52:50.579875 16412 solver.cpp:237]     Train net output #1: loss = 1.61042 (* 1 = 1.61042 loss)
I1210 09:52:50.579875 16412 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1210 09:52:56.251240 16412 solver.cpp:218] Iteration 41400 (17.632 iter/s, 5.67149s/100 iters), loss = 1.70657
I1210 09:52:56.251240 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:52:56.251240 16412 solver.cpp:237]     Train net output #1: loss = 1.70657 (* 1 = 1.70657 loss)
I1210 09:52:56.251240 16412 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1210 09:53:01.651608  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:53:01.874624 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_41500.caffemodel
I1210 09:53:01.888628 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_41500.solverstate
I1210 09:53:01.893627 16412 solver.cpp:330] Iteration 41500, Testing net (#0)
I1210 09:53:01.893627 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:53:03.259713 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:53:03.314712 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3646
I1210 09:53:03.314712 16412 solver.cpp:397]     Test net output #1: loss = 2.71451 (* 1 = 2.71451 loss)
I1210 09:53:03.368711 16412 solver.cpp:218] Iteration 41500 (14.0513 iter/s, 7.11679s/100 iters), loss = 1.53848
I1210 09:53:03.368711 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:53:03.368711 16412 solver.cpp:237]     Train net output #1: loss = 1.53848 (* 1 = 1.53848 loss)
I1210 09:53:03.368711 16412 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1210 09:53:09.048244 16412 solver.cpp:218] Iteration 41600 (17.6086 iter/s, 5.67904s/100 iters), loss = 1.39893
I1210 09:53:09.048244 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:53:09.048244 16412 solver.cpp:237]     Train net output #1: loss = 1.39893 (* 1 = 1.39893 loss)
I1210 09:53:09.048244 16412 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1210 09:53:14.718430 16412 solver.cpp:218] Iteration 41700 (17.6382 iter/s, 5.6695s/100 iters), loss = 1.34746
I1210 09:53:14.718430 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:53:14.718430 16412 solver.cpp:237]     Train net output #1: loss = 1.34746 (* 1 = 1.34746 loss)
I1210 09:53:14.718430 16412 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1210 09:53:20.392429 16412 solver.cpp:218] Iteration 41800 (17.6257 iter/s, 5.67354s/100 iters), loss = 1.68678
I1210 09:53:20.392429 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:53:20.392429 16412 solver.cpp:237]     Train net output #1: loss = 1.68678 (* 1 = 1.68678 loss)
I1210 09:53:20.392429 16412 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1210 09:53:26.071422 16412 solver.cpp:218] Iteration 41900 (17.6107 iter/s, 5.67836s/100 iters), loss = 1.63981
I1210 09:53:26.071422 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:53:26.071422 16412 solver.cpp:237]     Train net output #1: loss = 1.63981 (* 1 = 1.63981 loss)
I1210 09:53:26.071422 16412 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1210 09:53:31.473021  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:53:31.697950 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_42000.caffemodel
I1210 09:53:31.712494 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_42000.solverstate
I1210 09:53:31.717491 16412 solver.cpp:330] Iteration 42000, Testing net (#0)
I1210 09:53:31.717491 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:53:33.086113 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:53:33.139613 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3786
I1210 09:53:33.139613 16412 solver.cpp:397]     Test net output #1: loss = 2.54111 (* 1 = 2.54111 loss)
I1210 09:53:33.195118 16412 solver.cpp:218] Iteration 42000 (14.0381 iter/s, 7.12345s/100 iters), loss = 1.64194
I1210 09:53:33.195118 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:53:33.195118 16412 solver.cpp:237]     Train net output #1: loss = 1.64194 (* 1 = 1.64194 loss)
I1210 09:53:33.195118 16412 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1210 09:53:38.865443 16412 solver.cpp:218] Iteration 42100 (17.6381 iter/s, 5.66954s/100 iters), loss = 1.419
I1210 09:53:38.865443 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:53:38.865443 16412 solver.cpp:237]     Train net output #1: loss = 1.419 (* 1 = 1.419 loss)
I1210 09:53:38.865443 16412 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1210 09:53:44.546614 16412 solver.cpp:218] Iteration 42200 (17.6027 iter/s, 5.68094s/100 iters), loss = 1.36255
I1210 09:53:44.546614 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:53:44.546614 16412 solver.cpp:237]     Train net output #1: loss = 1.36255 (* 1 = 1.36255 loss)
I1210 09:53:44.546614 16412 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1210 09:53:50.220964 16412 solver.cpp:218] Iteration 42300 (17.6253 iter/s, 5.67365s/100 iters), loss = 1.88403
I1210 09:53:50.220964 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 09:53:50.220964 16412 solver.cpp:237]     Train net output #1: loss = 1.88403 (* 1 = 1.88403 loss)
I1210 09:53:50.220964 16412 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1210 09:53:55.898703 16412 solver.cpp:218] Iteration 42400 (17.6128 iter/s, 5.67769s/100 iters), loss = 1.70338
I1210 09:53:55.898703 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:53:55.899204 16412 solver.cpp:237]     Train net output #1: loss = 1.70338 (* 1 = 1.70338 loss)
I1210 09:53:55.899204 16412 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1210 09:54:01.288808  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:54:01.510331 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_42500.caffemodel
I1210 09:54:01.523835 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_42500.solverstate
I1210 09:54:01.528836 16412 solver.cpp:330] Iteration 42500, Testing net (#0)
I1210 09:54:01.528836 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:54:02.897931 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:54:02.950949 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3662
I1210 09:54:02.950949 16412 solver.cpp:397]     Test net output #1: loss = 2.63287 (* 1 = 2.63287 loss)
I1210 09:54:03.005436 16412 solver.cpp:218] Iteration 42500 (14.0723 iter/s, 7.10617s/100 iters), loss = 1.68548
I1210 09:54:03.005436 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:54:03.005436 16412 solver.cpp:237]     Train net output #1: loss = 1.68548 (* 1 = 1.68548 loss)
I1210 09:54:03.005436 16412 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1210 09:54:08.673331 16412 solver.cpp:218] Iteration 42600 (17.6432 iter/s, 5.6679s/100 iters), loss = 1.43262
I1210 09:54:08.673331 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:54:08.673331 16412 solver.cpp:237]     Train net output #1: loss = 1.43262 (* 1 = 1.43262 loss)
I1210 09:54:08.673331 16412 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1210 09:54:14.341754 16412 solver.cpp:218] Iteration 42700 (17.6449 iter/s, 5.66735s/100 iters), loss = 1.29616
I1210 09:54:14.341754 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:54:14.341754 16412 solver.cpp:237]     Train net output #1: loss = 1.29616 (* 1 = 1.29616 loss)
I1210 09:54:14.341754 16412 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1210 09:54:20.010712 16412 solver.cpp:218] Iteration 42800 (17.6404 iter/s, 5.66881s/100 iters), loss = 1.68757
I1210 09:54:20.010712 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:54:20.010712 16412 solver.cpp:237]     Train net output #1: loss = 1.68757 (* 1 = 1.68757 loss)
I1210 09:54:20.010712 16412 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1210 09:54:25.682613 16412 solver.cpp:218] Iteration 42900 (17.6325 iter/s, 5.67136s/100 iters), loss = 1.84993
I1210 09:54:25.682613 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:54:25.682613 16412 solver.cpp:237]     Train net output #1: loss = 1.84993 (* 1 = 1.84993 loss)
I1210 09:54:25.682613 16412 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1210 09:54:31.076027  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:54:31.298046 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_43000.caffemodel
I1210 09:54:31.312045 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_43000.solverstate
I1210 09:54:31.316051 16412 solver.cpp:330] Iteration 43000, Testing net (#0)
I1210 09:54:31.316051 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:54:32.683159 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:54:32.737166 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3799
I1210 09:54:32.737166 16412 solver.cpp:397]     Test net output #1: loss = 2.79191 (* 1 = 2.79191 loss)
I1210 09:54:32.793166 16412 solver.cpp:218] Iteration 43000 (14.0648 iter/s, 7.10993s/100 iters), loss = 1.61477
I1210 09:54:32.793166 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:54:32.793166 16412 solver.cpp:237]     Train net output #1: loss = 1.61477 (* 1 = 1.61477 loss)
I1210 09:54:32.793166 16412 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1210 09:54:38.466610 16412 solver.cpp:218] Iteration 43100 (17.6269 iter/s, 5.67315s/100 iters), loss = 1.55154
I1210 09:54:38.466610 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:54:38.466610 16412 solver.cpp:237]     Train net output #1: loss = 1.55154 (* 1 = 1.55154 loss)
I1210 09:54:38.466610 16412 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1210 09:54:44.133042 16412 solver.cpp:218] Iteration 43200 (17.6469 iter/s, 5.6667s/100 iters), loss = 1.45939
I1210 09:54:44.133042 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:54:44.133042 16412 solver.cpp:237]     Train net output #1: loss = 1.45939 (* 1 = 1.45939 loss)
I1210 09:54:44.134043 16412 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1210 09:54:49.805469 16412 solver.cpp:218] Iteration 43300 (17.632 iter/s, 5.67152s/100 iters), loss = 1.65451
I1210 09:54:49.805469 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:54:49.805969 16412 solver.cpp:237]     Train net output #1: loss = 1.65451 (* 1 = 1.65451 loss)
I1210 09:54:49.805969 16412 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1210 09:54:55.479913 16412 solver.cpp:218] Iteration 43400 (17.6239 iter/s, 5.67411s/100 iters), loss = 1.71927
I1210 09:54:55.479913 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:54:55.479913 16412 solver.cpp:237]     Train net output #1: loss = 1.71927 (* 1 = 1.71927 loss)
I1210 09:54:55.479913 16412 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1210 09:55:00.879120  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:55:01.102138 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_43500.caffemodel
I1210 09:55:01.118145 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_43500.solverstate
I1210 09:55:01.123147 16412 solver.cpp:330] Iteration 43500, Testing net (#0)
I1210 09:55:01.123147 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:55:02.491232 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:55:02.544237 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4106
I1210 09:55:02.544237 16412 solver.cpp:397]     Test net output #1: loss = 2.37148 (* 1 = 2.37148 loss)
I1210 09:55:02.598238 16412 solver.cpp:218] Iteration 43500 (14.0497 iter/s, 7.11761s/100 iters), loss = 1.62871
I1210 09:55:02.598238 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:55:02.598238 16412 solver.cpp:237]     Train net output #1: loss = 1.62871 (* 1 = 1.62871 loss)
I1210 09:55:02.598238 16412 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1210 09:55:08.269673 16412 solver.cpp:218] Iteration 43600 (17.6322 iter/s, 5.67143s/100 iters), loss = 1.44568
I1210 09:55:08.269673 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:55:08.269673 16412 solver.cpp:237]     Train net output #1: loss = 1.44568 (* 1 = 1.44568 loss)
I1210 09:55:08.269673 16412 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1210 09:55:13.939111 16412 solver.cpp:218] Iteration 43700 (17.6409 iter/s, 5.66863s/100 iters), loss = 1.23528
I1210 09:55:13.939111 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 09:55:13.939111 16412 solver.cpp:237]     Train net output #1: loss = 1.23528 (* 1 = 1.23528 loss)
I1210 09:55:13.939111 16412 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1210 09:55:19.603518 16412 solver.cpp:218] Iteration 43800 (17.6549 iter/s, 5.66415s/100 iters), loss = 1.61777
I1210 09:55:19.604018 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:55:19.604018 16412 solver.cpp:237]     Train net output #1: loss = 1.61777 (* 1 = 1.61777 loss)
I1210 09:55:19.604018 16412 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1210 09:55:25.272954 16412 solver.cpp:218] Iteration 43900 (17.6387 iter/s, 5.66935s/100 iters), loss = 1.75972
I1210 09:55:25.272954 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:55:25.272954 16412 solver.cpp:237]     Train net output #1: loss = 1.75972 (* 1 = 1.75972 loss)
I1210 09:55:25.272954 16412 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1210 09:55:30.666373  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:55:30.888396 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_44000.caffemodel
I1210 09:55:30.903888 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_44000.solverstate
I1210 09:55:30.908390 16412 solver.cpp:330] Iteration 44000, Testing net (#0)
I1210 09:55:30.908390 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:55:32.278522 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:55:32.331526 16412 solver.cpp:397]     Test net output #0: accuracy = 0.442
I1210 09:55:32.331526 16412 solver.cpp:397]     Test net output #1: loss = 2.13837 (* 1 = 2.13837 loss)
I1210 09:55:32.387524 16412 solver.cpp:218] Iteration 44000 (14.057 iter/s, 7.11391s/100 iters), loss = 1.57672
I1210 09:55:32.387524 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:55:32.387524 16412 solver.cpp:237]     Train net output #1: loss = 1.57672 (* 1 = 1.57672 loss)
I1210 09:55:32.387524 16412 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1210 09:55:38.068974 16412 solver.cpp:218] Iteration 44100 (17.6035 iter/s, 5.6807s/100 iters), loss = 1.4482
I1210 09:55:38.068974 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 09:55:38.068974 16412 solver.cpp:237]     Train net output #1: loss = 1.4482 (* 1 = 1.4482 loss)
I1210 09:55:38.068974 16412 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1210 09:55:43.746419 16412 solver.cpp:218] Iteration 44200 (17.6148 iter/s, 5.67704s/100 iters), loss = 1.37325
I1210 09:55:43.746419 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:55:43.746419 16412 solver.cpp:237]     Train net output #1: loss = 1.37325 (* 1 = 1.37325 loss)
I1210 09:55:43.746419 16412 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1210 09:55:49.423914 16412 solver.cpp:218] Iteration 44300 (17.6142 iter/s, 5.67722s/100 iters), loss = 1.88393
I1210 09:55:49.423914 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:55:49.423914 16412 solver.cpp:237]     Train net output #1: loss = 1.88393 (* 1 = 1.88393 loss)
I1210 09:55:49.423914 16412 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1210 09:55:55.100316 16412 solver.cpp:218] Iteration 44400 (17.6168 iter/s, 5.6764s/100 iters), loss = 1.85497
I1210 09:55:55.100316 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1210 09:55:55.100316 16412 solver.cpp:237]     Train net output #1: loss = 1.85497 (* 1 = 1.85497 loss)
I1210 09:55:55.100316 16412 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1210 09:56:00.504772  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:56:00.727795 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_44500.caffemodel
I1210 09:56:00.742795 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_44500.solverstate
I1210 09:56:00.746796 16412 solver.cpp:330] Iteration 44500, Testing net (#0)
I1210 09:56:00.746796 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:56:02.117415 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:56:02.170917 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3176
I1210 09:56:02.170917 16412 solver.cpp:397]     Test net output #1: loss = 2.94811 (* 1 = 2.94811 loss)
I1210 09:56:02.224921 16412 solver.cpp:218] Iteration 44500 (14.0373 iter/s, 7.12386s/100 iters), loss = 1.49953
I1210 09:56:02.224921 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:56:02.224921 16412 solver.cpp:237]     Train net output #1: loss = 1.49953 (* 1 = 1.49953 loss)
I1210 09:56:02.224921 16412 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1210 09:56:07.906878 16412 solver.cpp:218] Iteration 44600 (17.6025 iter/s, 5.68101s/100 iters), loss = 1.44916
I1210 09:56:07.906878 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:56:07.906878 16412 solver.cpp:237]     Train net output #1: loss = 1.44916 (* 1 = 1.44916 loss)
I1210 09:56:07.906878 16412 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1210 09:56:13.578408 16412 solver.cpp:218] Iteration 44700 (17.6313 iter/s, 5.67172s/100 iters), loss = 1.31819
I1210 09:56:13.578408 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:56:13.578408 16412 solver.cpp:237]     Train net output #1: loss = 1.31819 (* 1 = 1.31819 loss)
I1210 09:56:13.578408 16412 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1210 09:56:19.241267 16412 solver.cpp:218] Iteration 44800 (17.66 iter/s, 5.66252s/100 iters), loss = 1.79018
I1210 09:56:19.241267 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1210 09:56:19.241267 16412 solver.cpp:237]     Train net output #1: loss = 1.79018 (* 1 = 1.79018 loss)
I1210 09:56:19.242267 16412 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1210 09:56:24.909198 16412 solver.cpp:218] Iteration 44900 (17.6453 iter/s, 5.66722s/100 iters), loss = 1.66862
I1210 09:56:24.909198 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:56:24.909198 16412 solver.cpp:237]     Train net output #1: loss = 1.66862 (* 1 = 1.66862 loss)
I1210 09:56:24.909198 16412 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1210 09:56:30.301255  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:56:30.523399 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_45000.caffemodel
I1210 09:56:30.536427 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_45000.solverstate
I1210 09:56:30.541429 16412 solver.cpp:330] Iteration 45000, Testing net (#0)
I1210 09:56:30.541429 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:56:31.906927 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:56:31.961459 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3099
I1210 09:56:31.961459 16412 solver.cpp:397]     Test net output #1: loss = 3.07523 (* 1 = 3.07523 loss)
I1210 09:56:32.015462 16412 solver.cpp:218] Iteration 45000 (14.0732 iter/s, 7.10573s/100 iters), loss = 1.45119
I1210 09:56:32.015462 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:56:32.015462 16412 solver.cpp:237]     Train net output #1: loss = 1.45119 (* 1 = 1.45119 loss)
I1210 09:56:32.015462 16412 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1210 09:56:37.683487 16412 solver.cpp:218] Iteration 45100 (17.6438 iter/s, 5.66773s/100 iters), loss = 1.30571
I1210 09:56:37.683487 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 09:56:37.683487 16412 solver.cpp:237]     Train net output #1: loss = 1.30571 (* 1 = 1.30571 loss)
I1210 09:56:37.683487 16412 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1210 09:56:43.358175 16412 solver.cpp:218] Iteration 45200 (17.625 iter/s, 5.67376s/100 iters), loss = 1.25073
I1210 09:56:43.358175 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:56:43.358175 16412 solver.cpp:237]     Train net output #1: loss = 1.25073 (* 1 = 1.25073 loss)
I1210 09:56:43.358175 16412 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1210 09:56:49.028084 16412 solver.cpp:218] Iteration 45300 (17.6384 iter/s, 5.66945s/100 iters), loss = 1.59234
I1210 09:56:49.028084 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:56:49.028084 16412 solver.cpp:237]     Train net output #1: loss = 1.59234 (* 1 = 1.59234 loss)
I1210 09:56:49.028084 16412 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1210 09:56:54.697302 16412 solver.cpp:218] Iteration 45400 (17.6401 iter/s, 5.6689s/100 iters), loss = 1.63681
I1210 09:56:54.697302 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:56:54.697302 16412 solver.cpp:237]     Train net output #1: loss = 1.63681 (* 1 = 1.63681 loss)
I1210 09:56:54.697302 16412 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1210 09:57:00.093601  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:57:00.317669 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_45500.caffemodel
I1210 09:57:00.331681 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_45500.solverstate
I1210 09:57:00.337210 16412 solver.cpp:330] Iteration 45500, Testing net (#0)
I1210 09:57:00.337210 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:57:01.706380 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:57:01.759416 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3126
I1210 09:57:01.759416 16412 solver.cpp:397]     Test net output #1: loss = 3.07501 (* 1 = 3.07501 loss)
I1210 09:57:01.813412 16412 solver.cpp:218] Iteration 45500 (14.0531 iter/s, 7.11588s/100 iters), loss = 1.49929
I1210 09:57:01.813412 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:57:01.813412 16412 solver.cpp:237]     Train net output #1: loss = 1.49929 (* 1 = 1.49929 loss)
I1210 09:57:01.813412 16412 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1210 09:57:07.482764 16412 solver.cpp:218] Iteration 45600 (17.6405 iter/s, 5.66877s/100 iters), loss = 1.50733
I1210 09:57:07.482764 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:57:07.482764 16412 solver.cpp:237]     Train net output #1: loss = 1.50733 (* 1 = 1.50733 loss)
I1210 09:57:07.482764 16412 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1210 09:57:13.155407 16412 solver.cpp:218] Iteration 45700 (17.6317 iter/s, 5.67161s/100 iters), loss = 1.17814
I1210 09:57:13.155407 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1210 09:57:13.155407 16412 solver.cpp:237]     Train net output #1: loss = 1.17814 (* 1 = 1.17814 loss)
I1210 09:57:13.155407 16412 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1210 09:57:18.824357 16412 solver.cpp:218] Iteration 45800 (17.6407 iter/s, 5.66871s/100 iters), loss = 1.60022
I1210 09:57:18.824357 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:57:18.824357 16412 solver.cpp:237]     Train net output #1: loss = 1.60022 (* 1 = 1.60022 loss)
I1210 09:57:18.824357 16412 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1210 09:57:24.496508 16412 solver.cpp:218] Iteration 45900 (17.6309 iter/s, 5.67185s/100 iters), loss = 1.86466
I1210 09:57:24.496508 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:57:24.496508 16412 solver.cpp:237]     Train net output #1: loss = 1.86466 (* 1 = 1.86466 loss)
I1210 09:57:24.496508 16412 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1210 09:57:29.889370  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:57:30.112443 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_46000.caffemodel
I1210 09:57:30.126440 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_46000.solverstate
I1210 09:57:30.131439 16412 solver.cpp:330] Iteration 46000, Testing net (#0)
I1210 09:57:30.131439 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:57:31.498955 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:57:31.553946 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3338
I1210 09:57:31.553946 16412 solver.cpp:397]     Test net output #1: loss = 2.99798 (* 1 = 2.99798 loss)
I1210 09:57:31.606986 16412 solver.cpp:218] Iteration 46000 (14.0638 iter/s, 7.11046s/100 iters), loss = 1.67225
I1210 09:57:31.606986 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:57:31.606986 16412 solver.cpp:237]     Train net output #1: loss = 1.67225 (* 1 = 1.67225 loss)
I1210 09:57:31.606986 16412 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1210 09:57:37.284116 16412 solver.cpp:218] Iteration 46100 (17.617 iter/s, 5.67635s/100 iters), loss = 1.40304
I1210 09:57:37.284116 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:57:37.284116 16412 solver.cpp:237]     Train net output #1: loss = 1.40304 (* 1 = 1.40304 loss)
I1210 09:57:37.284116 16412 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1210 09:57:42.958102 16412 solver.cpp:218] Iteration 46200 (17.6259 iter/s, 5.67345s/100 iters), loss = 1.32237
I1210 09:57:42.958102 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1210 09:57:42.958102 16412 solver.cpp:237]     Train net output #1: loss = 1.32237 (* 1 = 1.32237 loss)
I1210 09:57:42.958102 16412 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1210 09:57:48.633471 16412 solver.cpp:218] Iteration 46300 (17.6199 iter/s, 5.6754s/100 iters), loss = 1.90268
I1210 09:57:48.633471 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1210 09:57:48.633471 16412 solver.cpp:237]     Train net output #1: loss = 1.90268 (* 1 = 1.90268 loss)
I1210 09:57:48.633471 16412 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1210 09:57:54.310184 16412 solver.cpp:218] Iteration 46400 (17.617 iter/s, 5.67632s/100 iters), loss = 1.69821
I1210 09:57:54.310184 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:57:54.310184 16412 solver.cpp:237]     Train net output #1: loss = 1.69821 (* 1 = 1.69821 loss)
I1210 09:57:54.310184 16412 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1210 09:57:59.710290  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:57:59.933544 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_46500.caffemodel
I1210 09:57:59.947543 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_46500.solverstate
I1210 09:57:59.952543 16412 solver.cpp:330] Iteration 46500, Testing net (#0)
I1210 09:57:59.952543 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:58:01.321626 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:58:01.376613 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4136
I1210 09:58:01.377113 16412 solver.cpp:397]     Test net output #1: loss = 2.28905 (* 1 = 2.28905 loss)
I1210 09:58:01.430644 16412 solver.cpp:218] Iteration 46500 (14.0462 iter/s, 7.11937s/100 iters), loss = 1.55049
I1210 09:58:01.430644 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:58:01.430644 16412 solver.cpp:237]     Train net output #1: loss = 1.55049 (* 1 = 1.55049 loss)
I1210 09:58:01.430644 16412 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1210 09:58:07.093511 16412 solver.cpp:218] Iteration 46600 (17.6585 iter/s, 5.66299s/100 iters), loss = 1.48864
I1210 09:58:07.093511 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:58:07.093511 16412 solver.cpp:237]     Train net output #1: loss = 1.48864 (* 1 = 1.48864 loss)
I1210 09:58:07.093511 16412 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1210 09:58:12.765200 16412 solver.cpp:218] Iteration 46700 (17.6337 iter/s, 5.67097s/100 iters), loss = 1.22232
I1210 09:58:12.765200 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 09:58:12.765200 16412 solver.cpp:237]     Train net output #1: loss = 1.22232 (* 1 = 1.22232 loss)
I1210 09:58:12.765200 16412 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1210 09:58:18.430006 16412 solver.cpp:218] Iteration 46800 (17.6552 iter/s, 5.66406s/100 iters), loss = 1.71417
I1210 09:58:18.430006 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:58:18.430006 16412 solver.cpp:237]     Train net output #1: loss = 1.71417 (* 1 = 1.71417 loss)
I1210 09:58:18.430006 16412 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1210 09:58:24.091917 16412 solver.cpp:218] Iteration 46900 (17.6615 iter/s, 5.66202s/100 iters), loss = 1.71542
I1210 09:58:24.091917 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:58:24.091917 16412 solver.cpp:237]     Train net output #1: loss = 1.71542 (* 1 = 1.71542 loss)
I1210 09:58:24.091917 16412 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1210 09:58:29.479091  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:58:29.703227 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_47000.caffemodel
I1210 09:58:29.718211 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_47000.solverstate
I1210 09:58:29.723225 16412 solver.cpp:330] Iteration 47000, Testing net (#0)
I1210 09:58:29.723225 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:58:31.092792 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:58:31.146303 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3827
I1210 09:58:31.146303 16412 solver.cpp:397]     Test net output #1: loss = 2.60905 (* 1 = 2.60905 loss)
I1210 09:58:31.200331 16412 solver.cpp:218] Iteration 47000 (14.0701 iter/s, 7.10726s/100 iters), loss = 1.63041
I1210 09:58:31.200331 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:58:31.200331 16412 solver.cpp:237]     Train net output #1: loss = 1.63041 (* 1 = 1.63041 loss)
I1210 09:58:31.200331 16412 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1210 09:58:36.868674 16412 solver.cpp:218] Iteration 47100 (17.6408 iter/s, 5.66868s/100 iters), loss = 1.35146
I1210 09:58:36.868674 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1210 09:58:36.868674 16412 solver.cpp:237]     Train net output #1: loss = 1.35146 (* 1 = 1.35146 loss)
I1210 09:58:36.868674 16412 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1210 09:58:42.535550 16412 solver.cpp:218] Iteration 47200 (17.6478 iter/s, 5.66641s/100 iters), loss = 1.31229
I1210 09:58:42.535550 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:58:42.535550 16412 solver.cpp:237]     Train net output #1: loss = 1.31229 (* 1 = 1.31229 loss)
I1210 09:58:42.535550 16412 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1210 09:58:48.201020 16412 solver.cpp:218] Iteration 47300 (17.6532 iter/s, 5.66468s/100 iters), loss = 1.54287
I1210 09:58:48.201020 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 09:58:48.201020 16412 solver.cpp:237]     Train net output #1: loss = 1.54287 (* 1 = 1.54287 loss)
I1210 09:58:48.201520 16412 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1210 09:58:53.879900 16412 solver.cpp:218] Iteration 47400 (17.6114 iter/s, 5.67813s/100 iters), loss = 1.90989
I1210 09:58:53.879900 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1210 09:58:53.879900 16412 solver.cpp:237]     Train net output #1: loss = 1.90989 (* 1 = 1.90989 loss)
I1210 09:58:53.879900 16412 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1210 09:58:59.274547  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:58:59.498991 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_47500.caffemodel
I1210 09:58:59.512507 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_47500.solverstate
I1210 09:58:59.517503 16412 solver.cpp:330] Iteration 47500, Testing net (#0)
I1210 09:58:59.517503 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:59:00.882910 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:59:00.938520 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3826
I1210 09:59:00.938520 16412 solver.cpp:397]     Test net output #1: loss = 2.46398 (* 1 = 2.46398 loss)
I1210 09:59:00.991510 16412 solver.cpp:218] Iteration 47500 (14.0612 iter/s, 7.11175s/100 iters), loss = 1.79193
I1210 09:59:00.991510 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 09:59:00.991510 16412 solver.cpp:237]     Train net output #1: loss = 1.79193 (* 1 = 1.79193 loss)
I1210 09:59:00.991510 16412 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1210 09:59:06.663002 16412 solver.cpp:218] Iteration 47600 (17.6328 iter/s, 5.67126s/100 iters), loss = 1.50663
I1210 09:59:06.664006 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:59:06.664006 16412 solver.cpp:237]     Train net output #1: loss = 1.50663 (* 1 = 1.50663 loss)
I1210 09:59:06.664006 16412 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1210 09:59:12.333387 16412 solver.cpp:218] Iteration 47700 (17.638 iter/s, 5.66956s/100 iters), loss = 1.29039
I1210 09:59:12.333387 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 09:59:12.333387 16412 solver.cpp:237]     Train net output #1: loss = 1.29039 (* 1 = 1.29039 loss)
I1210 09:59:12.333387 16412 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1210 09:59:17.993676 16412 solver.cpp:218] Iteration 47800 (17.6684 iter/s, 5.65982s/100 iters), loss = 1.63544
I1210 09:59:17.993676 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 09:59:17.993676 16412 solver.cpp:237]     Train net output #1: loss = 1.63544 (* 1 = 1.63544 loss)
I1210 09:59:17.993676 16412 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1210 09:59:23.665591 16412 solver.cpp:218] Iteration 47900 (17.6341 iter/s, 5.67083s/100 iters), loss = 1.6319
I1210 09:59:23.665591 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1210 09:59:23.665591 16412 solver.cpp:237]     Train net output #1: loss = 1.6319 (* 1 = 1.6319 loss)
I1210 09:59:23.665591 16412 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1210 09:59:29.056277  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:59:29.279343 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_48000.caffemodel
I1210 09:59:29.295362 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_48000.solverstate
I1210 09:59:29.299361 16412 solver.cpp:330] Iteration 48000, Testing net (#0)
I1210 09:59:29.300362 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 09:59:30.666844 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:59:30.720854 16412 solver.cpp:397]     Test net output #0: accuracy = 0.322
I1210 09:59:30.720854 16412 solver.cpp:397]     Test net output #1: loss = 2.86157 (* 1 = 2.86157 loss)
I1210 09:59:30.774847 16412 solver.cpp:218] Iteration 48000 (14.0663 iter/s, 7.10919s/100 iters), loss = 1.50764
I1210 09:59:30.774847 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:59:30.774847 16412 solver.cpp:237]     Train net output #1: loss = 1.50764 (* 1 = 1.50764 loss)
I1210 09:59:30.774847 16412 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1210 09:59:36.449792 16412 solver.cpp:218] Iteration 48100 (17.6221 iter/s, 5.67471s/100 iters), loss = 1.46703
I1210 09:59:36.449792 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1210 09:59:36.449792 16412 solver.cpp:237]     Train net output #1: loss = 1.46703 (* 1 = 1.46703 loss)
I1210 09:59:36.449792 16412 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1210 09:59:42.126473 16412 solver.cpp:218] Iteration 48200 (17.6171 iter/s, 5.67632s/100 iters), loss = 1.19382
I1210 09:59:42.127477 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 09:59:42.127477 16412 solver.cpp:237]     Train net output #1: loss = 1.19382 (* 1 = 1.19382 loss)
I1210 09:59:42.127477 16412 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1210 09:59:47.800887 16412 solver.cpp:218] Iteration 48300 (17.6254 iter/s, 5.67362s/100 iters), loss = 1.67209
I1210 09:59:47.800887 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 09:59:47.800887 16412 solver.cpp:237]     Train net output #1: loss = 1.67209 (* 1 = 1.67209 loss)
I1210 09:59:47.800887 16412 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1210 09:59:53.478415 16412 solver.cpp:218] Iteration 48400 (17.6152 iter/s, 5.67692s/100 iters), loss = 1.5922
I1210 09:59:53.478415 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 09:59:53.478415 16412 solver.cpp:237]     Train net output #1: loss = 1.5922 (* 1 = 1.5922 loss)
I1210 09:59:53.478415 16412 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1210 09:59:58.868806  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 09:59:59.091817 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_48500.caffemodel
I1210 09:59:59.105818 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_48500.solverstate
I1210 09:59:59.109817 16412 solver.cpp:330] Iteration 48500, Testing net (#0)
I1210 09:59:59.109817 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:00:00.487959 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:00:00.541968 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3902
I1210 10:00:00.541968 16412 solver.cpp:397]     Test net output #1: loss = 2.44673 (* 1 = 2.44673 loss)
I1210 10:00:00.597968 16412 solver.cpp:218] Iteration 48500 (14.0473 iter/s, 7.11878s/100 iters), loss = 1.68423
I1210 10:00:00.597968 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 10:00:00.597968 16412 solver.cpp:237]     Train net output #1: loss = 1.68423 (* 1 = 1.68423 loss)
I1210 10:00:00.597968 16412 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1210 10:00:06.300508 16412 solver.cpp:218] Iteration 48600 (17.535 iter/s, 5.70289s/100 iters), loss = 1.45188
I1210 10:00:06.301507 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 10:00:06.301507 16412 solver.cpp:237]     Train net output #1: loss = 1.45188 (* 1 = 1.45188 loss)
I1210 10:00:06.301507 16412 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1210 10:00:11.972908 16412 solver.cpp:218] Iteration 48700 (17.6325 iter/s, 5.67136s/100 iters), loss = 1.26981
I1210 10:00:11.972908 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 10:00:11.972908 16412 solver.cpp:237]     Train net output #1: loss = 1.26981 (* 1 = 1.26981 loss)
I1210 10:00:11.972908 16412 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1210 10:00:17.641330 16412 solver.cpp:218] Iteration 48800 (17.6431 iter/s, 5.66793s/100 iters), loss = 1.57382
I1210 10:00:17.641330 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 10:00:17.641330 16412 solver.cpp:237]     Train net output #1: loss = 1.57382 (* 1 = 1.57382 loss)
I1210 10:00:17.641330 16412 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1210 10:00:23.312780 16412 solver.cpp:218] Iteration 48900 (17.6339 iter/s, 5.67091s/100 iters), loss = 1.72996
I1210 10:00:23.312780 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1210 10:00:23.312780 16412 solver.cpp:237]     Train net output #1: loss = 1.72996 (* 1 = 1.72996 loss)
I1210 10:00:23.312780 16412 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1210 10:00:28.702175  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:00:28.927192 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_49000.caffemodel
I1210 10:00:28.940196 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_49000.solverstate
I1210 10:00:28.945197 16412 solver.cpp:330] Iteration 49000, Testing net (#0)
I1210 10:00:28.945197 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:00:30.312314 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:00:30.367318 16412 solver.cpp:397]     Test net output #0: accuracy = 0.3835
I1210 10:00:30.367318 16412 solver.cpp:397]     Test net output #1: loss = 2.48851 (* 1 = 2.48851 loss)
I1210 10:00:30.421823 16412 solver.cpp:218] Iteration 49000 (14.0673 iter/s, 7.10867s/100 iters), loss = 1.4855
I1210 10:00:30.421823 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1210 10:00:30.421823 16412 solver.cpp:237]     Train net output #1: loss = 1.4855 (* 1 = 1.4855 loss)
I1210 10:00:30.421823 16412 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1210 10:00:36.088735 16412 solver.cpp:218] Iteration 49100 (17.6478 iter/s, 5.66642s/100 iters), loss = 1.42718
I1210 10:00:36.088735 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 10:00:36.088735 16412 solver.cpp:237]     Train net output #1: loss = 1.42718 (* 1 = 1.42718 loss)
I1210 10:00:36.088735 16412 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1210 10:00:41.759146 16412 solver.cpp:218] Iteration 49200 (17.6369 iter/s, 5.66992s/100 iters), loss = 1.27719
I1210 10:00:41.759146 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1210 10:00:41.759146 16412 solver.cpp:237]     Train net output #1: loss = 1.27719 (* 1 = 1.27719 loss)
I1210 10:00:41.759146 16412 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1210 10:00:47.421553 16412 solver.cpp:218] Iteration 49300 (17.6614 iter/s, 5.66207s/100 iters), loss = 1.63339
I1210 10:00:47.421553 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1210 10:00:47.421553 16412 solver.cpp:237]     Train net output #1: loss = 1.63339 (* 1 = 1.63339 loss)
I1210 10:00:47.421553 16412 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1210 10:00:53.090032 16412 solver.cpp:218] Iteration 49400 (17.6421 iter/s, 5.66826s/100 iters), loss = 1.63495
I1210 10:00:53.090032 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 10:00:53.090032 16412 solver.cpp:237]     Train net output #1: loss = 1.63495 (* 1 = 1.63495 loss)
I1210 10:00:53.090032 16412 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1210 10:00:58.487543  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:00:58.712553 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_49500.caffemodel
I1210 10:00:58.727555 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_49500.solverstate
I1210 10:00:58.732554 16412 solver.cpp:330] Iteration 49500, Testing net (#0)
I1210 10:00:58.732554 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:01:00.100661 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:01:00.153671 16412 solver.cpp:397]     Test net output #0: accuracy = 0.4026
I1210 10:01:00.153671 16412 solver.cpp:397]     Test net output #1: loss = 2.45104 (* 1 = 2.45104 loss)
I1210 10:01:00.207670 16412 solver.cpp:218] Iteration 49500 (14.0512 iter/s, 7.11682s/100 iters), loss = 1.59576
I1210 10:01:00.207670 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1210 10:01:00.207670 16412 solver.cpp:237]     Train net output #1: loss = 1.59576 (* 1 = 1.59576 loss)
I1210 10:01:00.207670 16412 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1210 10:01:05.881129 16412 solver.cpp:218] Iteration 49600 (17.6265 iter/s, 5.67328s/100 iters), loss = 1.52887
I1210 10:01:05.881129 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1210 10:01:05.881129 16412 solver.cpp:237]     Train net output #1: loss = 1.52887 (* 1 = 1.52887 loss)
I1210 10:01:05.881129 16412 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1210 10:01:11.551157 16412 solver.cpp:218] Iteration 49700 (17.6388 iter/s, 5.66931s/100 iters), loss = 1.31257
I1210 10:01:11.551157 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 10:01:11.551157 16412 solver.cpp:237]     Train net output #1: loss = 1.31257 (* 1 = 1.31257 loss)
I1210 10:01:11.551157 16412 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1210 10:01:17.222117 16412 solver.cpp:218] Iteration 49800 (17.6344 iter/s, 5.67074s/100 iters), loss = 1.62025
I1210 10:01:17.222117 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 10:01:17.222117 16412 solver.cpp:237]     Train net output #1: loss = 1.62025 (* 1 = 1.62025 loss)
I1210 10:01:17.222117 16412 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1210 10:01:22.898576 16412 solver.cpp:218] Iteration 49900 (17.6169 iter/s, 5.67638s/100 iters), loss = 1.66465
I1210 10:01:22.898576 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1210 10:01:22.898576 16412 solver.cpp:237]     Train net output #1: loss = 1.66465 (* 1 = 1.66465 loss)
I1210 10:01:22.898576 16412 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1210 10:01:28.288022  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:01:28.512043 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_50000.caffemodel
I1210 10:01:28.525043 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_50000.solverstate
I1210 10:01:28.530045 16412 solver.cpp:330] Iteration 50000, Testing net (#0)
I1210 10:01:28.530045 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:01:29.896173 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:01:29.950680 16412 solver.cpp:397]     Test net output #0: accuracy = 0.373
I1210 10:01:29.950680 16412 solver.cpp:397]     Test net output #1: loss = 2.74553 (* 1 = 2.74553 loss)
I1210 10:01:30.006181 16412 solver.cpp:218] Iteration 50000 (14.0716 iter/s, 7.10649s/100 iters), loss = 1.5562
I1210 10:01:30.006181 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1210 10:01:30.006181 16412 solver.cpp:237]     Train net output #1: loss = 1.5562 (* 1 = 1.5562 loss)
I1210 10:01:30.006181 16412 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1210 10:01:30.006181 16412 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1210 10:01:35.677580 16412 solver.cpp:218] Iteration 50100 (17.6325 iter/s, 5.67135s/100 iters), loss = 1.19291
I1210 10:01:35.677580 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 10:01:35.677580 16412 solver.cpp:237]     Train net output #1: loss = 1.19291 (* 1 = 1.19291 loss)
I1210 10:01:35.677580 16412 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1210 10:01:41.349998 16412 solver.cpp:218] Iteration 50200 (17.6306 iter/s, 5.67197s/100 iters), loss = 0.966871
I1210 10:01:41.349998 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:01:41.349998 16412 solver.cpp:237]     Train net output #1: loss = 0.966871 (* 1 = 0.966871 loss)
I1210 10:01:41.350499 16412 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1210 10:01:47.018756 16412 solver.cpp:218] Iteration 50300 (17.6414 iter/s, 5.66848s/100 iters), loss = 1.18962
I1210 10:01:47.018756 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 10:01:47.018756 16412 solver.cpp:237]     Train net output #1: loss = 1.18962 (* 1 = 1.18962 loss)
I1210 10:01:47.018756 16412 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1210 10:01:52.692225 16412 solver.cpp:218] Iteration 50400 (17.6282 iter/s, 5.67272s/100 iters), loss = 1.20015
I1210 10:01:52.692225 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 10:01:52.692225 16412 solver.cpp:237]     Train net output #1: loss = 1.20015 (* 1 = 1.20015 loss)
I1210 10:01:52.692225 16412 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1210 10:01:58.083665  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:01:58.305680 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_50500.caffemodel
I1210 10:01:58.322680 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_50500.solverstate
I1210 10:01:58.327679 16412 solver.cpp:330] Iteration 50500, Testing net (#0)
I1210 10:01:58.327679 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:01:59.696810 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:01:59.750311 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6435
I1210 10:01:59.750811 16412 solver.cpp:397]     Test net output #1: loss = 1.23679 (* 1 = 1.23679 loss)
I1210 10:01:59.803815 16412 solver.cpp:218] Iteration 50500 (14.062 iter/s, 7.11139s/100 iters), loss = 1.03698
I1210 10:01:59.803815 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:01:59.803815 16412 solver.cpp:237]     Train net output #1: loss = 1.03698 (* 1 = 1.03698 loss)
I1210 10:01:59.803815 16412 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1210 10:02:05.475214 16412 solver.cpp:218] Iteration 50600 (17.6327 iter/s, 5.67129s/100 iters), loss = 1.05774
I1210 10:02:05.475214 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:02:05.475214 16412 solver.cpp:237]     Train net output #1: loss = 1.05774 (* 1 = 1.05774 loss)
I1210 10:02:05.475214 16412 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1210 10:02:11.144078 16412 solver.cpp:218] Iteration 50700 (17.6435 iter/s, 5.66782s/100 iters), loss = 0.895557
I1210 10:02:11.144078 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:02:11.144078 16412 solver.cpp:237]     Train net output #1: loss = 0.895557 (* 1 = 0.895557 loss)
I1210 10:02:11.144078 16412 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1210 10:02:16.815006 16412 solver.cpp:218] Iteration 50800 (17.6329 iter/s, 5.67123s/100 iters), loss = 1.12712
I1210 10:02:16.815006 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:02:16.815006 16412 solver.cpp:237]     Train net output #1: loss = 1.12712 (* 1 = 1.12712 loss)
I1210 10:02:16.815006 16412 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1210 10:02:22.491770 16412 solver.cpp:218] Iteration 50900 (17.6166 iter/s, 5.67645s/100 iters), loss = 1.09405
I1210 10:02:22.492770 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1210 10:02:22.492770 16412 solver.cpp:237]     Train net output #1: loss = 1.09405 (* 1 = 1.09405 loss)
I1210 10:02:22.492770 16412 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1210 10:02:27.886185  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:02:28.109203 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_51000.caffemodel
I1210 10:02:28.122208 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_51000.solverstate
I1210 10:02:28.127207 16412 solver.cpp:330] Iteration 51000, Testing net (#0)
I1210 10:02:28.127207 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:02:29.495314 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:02:29.550320 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6506
I1210 10:02:29.550320 16412 solver.cpp:397]     Test net output #1: loss = 1.20908 (* 1 = 1.20908 loss)
I1210 10:02:29.604320 16412 solver.cpp:218] Iteration 51000 (14.0621 iter/s, 7.11129s/100 iters), loss = 0.899501
I1210 10:02:29.604320 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:02:29.604320 16412 solver.cpp:237]     Train net output #1: loss = 0.899501 (* 1 = 0.899501 loss)
I1210 10:02:29.604320 16412 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1210 10:02:35.275741 16412 solver.cpp:218] Iteration 51100 (17.6328 iter/s, 5.67125s/100 iters), loss = 0.948122
I1210 10:02:35.275741 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:02:35.275741 16412 solver.cpp:237]     Train net output #1: loss = 0.948122 (* 1 = 0.948122 loss)
I1210 10:02:35.275741 16412 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1210 10:02:40.952106 16412 solver.cpp:218] Iteration 51200 (17.6203 iter/s, 5.67526s/100 iters), loss = 0.87035
I1210 10:02:40.952106 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:02:40.952106 16412 solver.cpp:237]     Train net output #1: loss = 0.87035 (* 1 = 0.87035 loss)
I1210 10:02:40.952106 16412 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1210 10:02:46.628576 16412 solver.cpp:218] Iteration 51300 (17.6165 iter/s, 5.67648s/100 iters), loss = 1.03867
I1210 10:02:46.628576 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 10:02:46.628576 16412 solver.cpp:237]     Train net output #1: loss = 1.03867 (* 1 = 1.03867 loss)
I1210 10:02:46.628576 16412 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1210 10:02:52.305400 16412 solver.cpp:218] Iteration 51400 (17.6173 iter/s, 5.67624s/100 iters), loss = 1.08933
I1210 10:02:52.305400 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1210 10:02:52.305400 16412 solver.cpp:237]     Train net output #1: loss = 1.08933 (* 1 = 1.08933 loss)
I1210 10:02:52.305400 16412 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1210 10:02:57.698935  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:02:57.921952 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_51500.caffemodel
I1210 10:02:57.935956 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_51500.solverstate
I1210 10:02:57.939956 16412 solver.cpp:330] Iteration 51500, Testing net (#0)
I1210 10:02:57.939956 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:02:59.308092 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:02:59.361097 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6469
I1210 10:02:59.361097 16412 solver.cpp:397]     Test net output #1: loss = 1.22104 (* 1 = 1.22104 loss)
I1210 10:02:59.416102 16412 solver.cpp:218] Iteration 51500 (14.0648 iter/s, 7.10995s/100 iters), loss = 0.821012
I1210 10:02:59.416102 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:02:59.416102 16412 solver.cpp:237]     Train net output #1: loss = 0.821012 (* 1 = 0.821012 loss)
I1210 10:02:59.416102 16412 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1210 10:03:05.081658 16412 solver.cpp:218] Iteration 51600 (17.6512 iter/s, 5.66535s/100 iters), loss = 0.887374
I1210 10:03:05.081658 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:03:05.081658 16412 solver.cpp:237]     Train net output #1: loss = 0.887374 (* 1 = 0.887374 loss)
I1210 10:03:05.081658 16412 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1210 10:03:10.749088 16412 solver.cpp:218] Iteration 51700 (17.6468 iter/s, 5.66674s/100 iters), loss = 0.769426
I1210 10:03:10.749088 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:03:10.749088 16412 solver.cpp:237]     Train net output #1: loss = 0.769426 (* 1 = 0.769426 loss)
I1210 10:03:10.749088 16412 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1210 10:03:16.409018 16412 solver.cpp:218] Iteration 51800 (17.6685 iter/s, 5.6598s/100 iters), loss = 1.0855
I1210 10:03:16.409518 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:03:16.409518 16412 solver.cpp:237]     Train net output #1: loss = 1.0855 (* 1 = 1.0855 loss)
I1210 10:03:16.409518 16412 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1210 10:03:22.071878 16412 solver.cpp:218] Iteration 51900 (17.6593 iter/s, 5.66274s/100 iters), loss = 1.02827
I1210 10:03:22.071878 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:03:22.071878 16412 solver.cpp:237]     Train net output #1: loss = 1.02827 (* 1 = 1.02827 loss)
I1210 10:03:22.071878 16412 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1210 10:03:27.465242  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:03:27.688256 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_52000.caffemodel
I1210 10:03:27.702258 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_52000.solverstate
I1210 10:03:27.707258 16412 solver.cpp:330] Iteration 52000, Testing net (#0)
I1210 10:03:27.707258 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:03:29.074601 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:03:29.128603 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6574
I1210 10:03:29.129103 16412 solver.cpp:397]     Test net output #1: loss = 1.18838 (* 1 = 1.18838 loss)
I1210 10:03:29.183605 16412 solver.cpp:218] Iteration 52000 (14.0634 iter/s, 7.11066s/100 iters), loss = 0.939815
I1210 10:03:29.183605 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:03:29.183605 16412 solver.cpp:237]     Train net output #1: loss = 0.939815 (* 1 = 0.939815 loss)
I1210 10:03:29.183605 16412 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1210 10:03:34.856835 16412 solver.cpp:218] Iteration 52100 (17.6286 iter/s, 5.67259s/100 iters), loss = 0.880176
I1210 10:03:34.856835 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:03:34.856835 16412 solver.cpp:237]     Train net output #1: loss = 0.880176 (* 1 = 0.880176 loss)
I1210 10:03:34.856835 16412 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1210 10:03:40.530635 16412 solver.cpp:218] Iteration 52200 (17.6248 iter/s, 5.67382s/100 iters), loss = 0.756307
I1210 10:03:40.531136 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:03:40.531136 16412 solver.cpp:237]     Train net output #1: loss = 0.756307 (* 1 = 0.756307 loss)
I1210 10:03:40.531136 16412 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1210 10:03:46.200556 16412 solver.cpp:218] Iteration 52300 (17.639 iter/s, 5.66927s/100 iters), loss = 0.989945
I1210 10:03:46.200556 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:03:46.200556 16412 solver.cpp:237]     Train net output #1: loss = 0.989945 (* 1 = 0.989945 loss)
I1210 10:03:46.200556 16412 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1210 10:03:51.870880 16412 solver.cpp:218] Iteration 52400 (17.6348 iter/s, 5.6706s/100 iters), loss = 1.03387
I1210 10:03:51.870880 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:03:51.870880 16412 solver.cpp:237]     Train net output #1: loss = 1.03387 (* 1 = 1.03387 loss)
I1210 10:03:51.870880 16412 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1210 10:03:57.257346  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:03:57.481357 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_52500.caffemodel
I1210 10:03:57.497357 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_52500.solverstate
I1210 10:03:57.501358 16412 solver.cpp:330] Iteration 52500, Testing net (#0)
I1210 10:03:57.502358 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:03:58.870497 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:03:58.924000 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6506
I1210 10:03:58.924000 16412 solver.cpp:397]     Test net output #1: loss = 1.19658 (* 1 = 1.19658 loss)
I1210 10:03:58.978502 16412 solver.cpp:218] Iteration 52500 (14.0713 iter/s, 7.10667s/100 iters), loss = 0.882399
I1210 10:03:58.978502 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:03:58.978502 16412 solver.cpp:237]     Train net output #1: loss = 0.882399 (* 1 = 0.882399 loss)
I1210 10:03:58.978502 16412 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1210 10:04:04.651964 16412 solver.cpp:218] Iteration 52600 (17.627 iter/s, 5.67312s/100 iters), loss = 0.907521
I1210 10:04:04.651964 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:04:04.651964 16412 solver.cpp:237]     Train net output #1: loss = 0.907521 (* 1 = 0.907521 loss)
I1210 10:04:04.651964 16412 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1210 10:04:10.320096 16412 solver.cpp:218] Iteration 52700 (17.644 iter/s, 5.66765s/100 iters), loss = 0.743932
I1210 10:04:10.320096 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:04:10.320096 16412 solver.cpp:237]     Train net output #1: loss = 0.743932 (* 1 = 0.743932 loss)
I1210 10:04:10.320096 16412 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1210 10:04:15.985373 16412 solver.cpp:218] Iteration 52800 (17.6516 iter/s, 5.66522s/100 iters), loss = 0.943508
I1210 10:04:15.986383 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:04:15.986383 16412 solver.cpp:237]     Train net output #1: loss = 0.943508 (* 1 = 0.943508 loss)
I1210 10:04:15.986383 16412 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1210 10:04:21.652869 16412 solver.cpp:218] Iteration 52900 (17.6487 iter/s, 5.66615s/100 iters), loss = 0.98384
I1210 10:04:21.652869 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:04:21.652869 16412 solver.cpp:237]     Train net output #1: loss = 0.98384 (* 1 = 0.98384 loss)
I1210 10:04:21.652869 16412 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1210 10:04:27.038898  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:04:27.263506 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_53000.caffemodel
I1210 10:04:27.277487 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_53000.solverstate
I1210 10:04:27.282501 16412 solver.cpp:330] Iteration 53000, Testing net (#0)
I1210 10:04:27.282501 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:04:28.649749 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:04:28.704740 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6546
I1210 10:04:28.704740 16412 solver.cpp:397]     Test net output #1: loss = 1.20138 (* 1 = 1.20138 loss)
I1210 10:04:28.759243 16412 solver.cpp:218] Iteration 53000 (14.0727 iter/s, 7.10596s/100 iters), loss = 0.838401
I1210 10:04:28.759243 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:04:28.759243 16412 solver.cpp:237]     Train net output #1: loss = 0.838401 (* 1 = 0.838401 loss)
I1210 10:04:28.759243 16412 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1210 10:04:34.436630 16412 solver.cpp:218] Iteration 53100 (17.6153 iter/s, 5.67689s/100 iters), loss = 0.774677
I1210 10:04:34.436630 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:04:34.436630 16412 solver.cpp:237]     Train net output #1: loss = 0.774677 (* 1 = 0.774677 loss)
I1210 10:04:34.436630 16412 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1210 10:04:40.106720 16412 solver.cpp:218] Iteration 53200 (17.6365 iter/s, 5.67005s/100 iters), loss = 0.714028
I1210 10:04:40.106720 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:04:40.106720 16412 solver.cpp:237]     Train net output #1: loss = 0.714028 (* 1 = 0.714028 loss)
I1210 10:04:40.106720 16412 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1210 10:04:45.772605 16412 solver.cpp:218] Iteration 53300 (17.6525 iter/s, 5.66491s/100 iters), loss = 0.89607
I1210 10:04:45.772605 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:04:45.772605 16412 solver.cpp:237]     Train net output #1: loss = 0.89607 (* 1 = 0.89607 loss)
I1210 10:04:45.772605 16412 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1210 10:04:51.446454 16412 solver.cpp:218] Iteration 53400 (17.6263 iter/s, 5.67335s/100 iters), loss = 0.941678
I1210 10:04:51.446454 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:04:51.446454 16412 solver.cpp:237]     Train net output #1: loss = 0.941678 (* 1 = 0.941678 loss)
I1210 10:04:51.446454 16412 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1210 10:04:56.836280  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:04:57.059921 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_53500.caffemodel
I1210 10:04:57.073933 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_53500.solverstate
I1210 10:04:57.078936 16412 solver.cpp:330] Iteration 53500, Testing net (#0)
I1210 10:04:57.078936 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:04:58.445273 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:04:58.497747 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6592
I1210 10:04:58.497747 16412 solver.cpp:397]     Test net output #1: loss = 1.19119 (* 1 = 1.19119 loss)
I1210 10:04:58.552256 16412 solver.cpp:218] Iteration 53500 (14.0739 iter/s, 7.10534s/100 iters), loss = 0.862857
I1210 10:04:58.552256 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:04:58.552256 16412 solver.cpp:237]     Train net output #1: loss = 0.862857 (* 1 = 0.862857 loss)
I1210 10:04:58.552256 16412 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1210 10:05:04.222820 16412 solver.cpp:218] Iteration 53600 (17.6357 iter/s, 5.67033s/100 iters), loss = 0.80069
I1210 10:05:04.222820 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:05:04.222820 16412 solver.cpp:237]     Train net output #1: loss = 0.80069 (* 1 = 0.80069 loss)
I1210 10:05:04.222820 16412 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1210 10:05:09.899529 16412 solver.cpp:218] Iteration 53700 (17.6159 iter/s, 5.67669s/100 iters), loss = 0.691504
I1210 10:05:09.899529 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:05:09.899529 16412 solver.cpp:237]     Train net output #1: loss = 0.691504 (* 1 = 0.691504 loss)
I1210 10:05:09.899529 16412 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1210 10:05:15.565428 16412 solver.cpp:218] Iteration 53800 (17.6516 iter/s, 5.6652s/100 iters), loss = 0.993853
I1210 10:05:15.565428 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:05:15.565428 16412 solver.cpp:237]     Train net output #1: loss = 0.993853 (* 1 = 0.993853 loss)
I1210 10:05:15.565428 16412 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1210 10:05:21.243683 16412 solver.cpp:218] Iteration 53900 (17.6123 iter/s, 5.67785s/100 iters), loss = 0.968613
I1210 10:05:21.243683 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1210 10:05:21.243683 16412 solver.cpp:237]     Train net output #1: loss = 0.968613 (* 1 = 0.968613 loss)
I1210 10:05:21.243683 16412 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1210 10:05:26.637123  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:05:26.860143 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_54000.caffemodel
I1210 10:05:26.873144 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_54000.solverstate
I1210 10:05:26.878144 16412 solver.cpp:330] Iteration 54000, Testing net (#0)
I1210 10:05:26.878144 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:05:28.246251 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:05:28.300256 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6578
I1210 10:05:28.300256 16412 solver.cpp:397]     Test net output #1: loss = 1.21865 (* 1 = 1.21865 loss)
I1210 10:05:28.354759 16412 solver.cpp:218] Iteration 54000 (14.0643 iter/s, 7.1102s/100 iters), loss = 0.83023
I1210 10:05:28.354759 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:05:28.354759 16412 solver.cpp:237]     Train net output #1: loss = 0.83023 (* 1 = 0.83023 loss)
I1210 10:05:28.354759 16412 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1210 10:05:34.020706 16412 solver.cpp:218] Iteration 54100 (17.6491 iter/s, 5.666s/100 iters), loss = 0.847798
I1210 10:05:34.020706 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:05:34.020706 16412 solver.cpp:237]     Train net output #1: loss = 0.847798 (* 1 = 0.847798 loss)
I1210 10:05:34.020706 16412 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1210 10:05:39.691917 16412 solver.cpp:218] Iteration 54200 (17.6341 iter/s, 5.67082s/100 iters), loss = 0.711165
I1210 10:05:39.691917 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:05:39.691917 16412 solver.cpp:237]     Train net output #1: loss = 0.711165 (* 1 = 0.711165 loss)
I1210 10:05:39.692917 16412 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1210 10:05:45.355500 16412 solver.cpp:218] Iteration 54300 (17.6594 iter/s, 5.66271s/100 iters), loss = 0.926115
I1210 10:05:45.355500 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:05:45.355500 16412 solver.cpp:237]     Train net output #1: loss = 0.926115 (* 1 = 0.926115 loss)
I1210 10:05:45.355500 16412 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1210 10:05:51.015311 16412 solver.cpp:218] Iteration 54400 (17.6699 iter/s, 5.65933s/100 iters), loss = 0.901219
I1210 10:05:51.015311 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:05:51.015311 16412 solver.cpp:237]     Train net output #1: loss = 0.901219 (* 1 = 0.901219 loss)
I1210 10:05:51.015311 16412 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1210 10:05:56.393143  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:05:56.614728 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_54500.caffemodel
I1210 10:05:56.633725 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_54500.solverstate
I1210 10:05:56.639725 16412 solver.cpp:330] Iteration 54500, Testing net (#0)
I1210 10:05:56.639725 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:05:58.007921 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:05:58.061928 16412 solver.cpp:397]     Test net output #0: accuracy = 0.659
I1210 10:05:58.061928 16412 solver.cpp:397]     Test net output #1: loss = 1.19879 (* 1 = 1.19879 loss)
I1210 10:05:58.115944 16412 solver.cpp:218] Iteration 54500 (14.0848 iter/s, 7.09985s/100 iters), loss = 0.781963
I1210 10:05:58.115944 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:05:58.115944 16412 solver.cpp:237]     Train net output #1: loss = 0.781963 (* 1 = 0.781963 loss)
I1210 10:05:58.115944 16412 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1210 10:06:03.789028 16412 solver.cpp:218] Iteration 54600 (17.6255 iter/s, 5.67359s/100 iters), loss = 0.820368
I1210 10:06:03.790017 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:06:03.790017 16412 solver.cpp:237]     Train net output #1: loss = 0.820368 (* 1 = 0.820368 loss)
I1210 10:06:03.790017 16412 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1210 10:06:09.461189 16412 solver.cpp:218] Iteration 54700 (17.6316 iter/s, 5.67164s/100 iters), loss = 0.683082
I1210 10:06:09.461189 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:06:09.461189 16412 solver.cpp:237]     Train net output #1: loss = 0.683082 (* 1 = 0.683082 loss)
I1210 10:06:09.461189 16412 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1210 10:06:15.123656 16412 solver.cpp:218] Iteration 54800 (17.6632 iter/s, 5.66148s/100 iters), loss = 0.910032
I1210 10:06:15.123656 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:06:15.123656 16412 solver.cpp:237]     Train net output #1: loss = 0.910032 (* 1 = 0.910032 loss)
I1210 10:06:15.123656 16412 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1210 10:06:20.783427 16412 solver.cpp:218] Iteration 54900 (17.6696 iter/s, 5.65944s/100 iters), loss = 0.964123
I1210 10:06:20.783427 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:06:20.783427 16412 solver.cpp:237]     Train net output #1: loss = 0.964123 (* 1 = 0.964123 loss)
I1210 10:06:20.783926 16412 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1210 10:06:26.171990  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:06:26.394646 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_55000.caffemodel
I1210 10:06:26.409817 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_55000.solverstate
I1210 10:06:26.413820 16412 solver.cpp:330] Iteration 55000, Testing net (#0)
I1210 10:06:26.413820 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:06:27.777562 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:06:27.831828 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6577
I1210 10:06:27.831828 16412 solver.cpp:397]     Test net output #1: loss = 1.19178 (* 1 = 1.19178 loss)
I1210 10:06:27.884832 16412 solver.cpp:218] Iteration 55000 (14.0819 iter/s, 7.10134s/100 iters), loss = 0.801263
I1210 10:06:27.884832 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:06:27.884832 16412 solver.cpp:237]     Train net output #1: loss = 0.801263 (* 1 = 0.801263 loss)
I1210 10:06:27.884832 16412 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1210 10:06:33.551344 16412 solver.cpp:218] Iteration 55100 (17.6514 iter/s, 5.66529s/100 iters), loss = 0.833999
I1210 10:06:33.551344 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:06:33.551344 16412 solver.cpp:237]     Train net output #1: loss = 0.833999 (* 1 = 0.833999 loss)
I1210 10:06:33.551344 16412 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1210 10:06:39.219136 16412 solver.cpp:218] Iteration 55200 (17.6421 iter/s, 5.66824s/100 iters), loss = 0.629792
I1210 10:06:39.220136 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:06:39.220136 16412 solver.cpp:237]     Train net output #1: loss = 0.629792 (* 1 = 0.629792 loss)
I1210 10:06:39.220136 16412 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1210 10:06:44.894048 16412 solver.cpp:218] Iteration 55300 (17.6257 iter/s, 5.67354s/100 iters), loss = 1.0066
I1210 10:06:44.894048 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:06:44.894048 16412 solver.cpp:237]     Train net output #1: loss = 1.0066 (* 1 = 1.0066 loss)
I1210 10:06:44.894048 16412 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1210 10:06:50.559548 16412 solver.cpp:218] Iteration 55400 (17.651 iter/s, 5.66541s/100 iters), loss = 0.887888
I1210 10:06:50.559548 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:06:50.559548 16412 solver.cpp:237]     Train net output #1: loss = 0.887888 (* 1 = 0.887888 loss)
I1210 10:06:50.559548 16412 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1210 10:06:55.946123  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:06:56.168951 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_55500.caffemodel
I1210 10:06:56.184947 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_55500.solverstate
I1210 10:06:56.188958 16412 solver.cpp:330] Iteration 55500, Testing net (#0)
I1210 10:06:56.188958 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:06:57.553216 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:06:57.607740 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6574
I1210 10:06:57.607740 16412 solver.cpp:397]     Test net output #1: loss = 1.21982 (* 1 = 1.21982 loss)
I1210 10:06:57.661985 16412 solver.cpp:218] Iteration 55500 (14.0803 iter/s, 7.10211s/100 iters), loss = 0.797713
I1210 10:06:57.661985 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:06:57.661985 16412 solver.cpp:237]     Train net output #1: loss = 0.797713 (* 1 = 0.797713 loss)
I1210 10:06:57.661985 16412 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1210 10:07:03.325628 16412 solver.cpp:218] Iteration 55600 (17.6585 iter/s, 5.66298s/100 iters), loss = 0.849571
I1210 10:07:03.325628 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:07:03.325628 16412 solver.cpp:237]     Train net output #1: loss = 0.849571 (* 1 = 0.849571 loss)
I1210 10:07:03.325628 16412 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1210 10:07:08.993129 16412 solver.cpp:218] Iteration 55700 (17.6446 iter/s, 5.66744s/100 iters), loss = 0.608673
I1210 10:07:08.993129 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:07:08.993129 16412 solver.cpp:237]     Train net output #1: loss = 0.608673 (* 1 = 0.608673 loss)
I1210 10:07:08.993129 16412 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1210 10:07:14.662838 16412 solver.cpp:218] Iteration 55800 (17.64 iter/s, 5.66893s/100 iters), loss = 0.887426
I1210 10:07:14.662838 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:07:14.662838 16412 solver.cpp:237]     Train net output #1: loss = 0.887426 (* 1 = 0.887426 loss)
I1210 10:07:14.662838 16412 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1210 10:07:20.333346 16412 solver.cpp:218] Iteration 55900 (17.6354 iter/s, 5.67042s/100 iters), loss = 0.915867
I1210 10:07:20.333346 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:07:20.333346 16412 solver.cpp:237]     Train net output #1: loss = 0.915867 (* 1 = 0.915867 loss)
I1210 10:07:20.333346 16412 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1210 10:07:25.731634  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:07:25.955710 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_56000.caffemodel
I1210 10:07:25.970706 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_56000.solverstate
I1210 10:07:25.974710 16412 solver.cpp:330] Iteration 56000, Testing net (#0)
I1210 10:07:25.974710 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:07:27.340229 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:07:27.394227 16412 solver.cpp:397]     Test net output #0: accuracy = 0.64
I1210 10:07:27.394227 16412 solver.cpp:397]     Test net output #1: loss = 1.29867 (* 1 = 1.29867 loss)
I1210 10:07:27.449116 16412 solver.cpp:218] Iteration 56000 (14.0551 iter/s, 7.11485s/100 iters), loss = 0.683031
I1210 10:07:27.449116 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:07:27.449116 16412 solver.cpp:237]     Train net output #1: loss = 0.683031 (* 1 = 0.683031 loss)
I1210 10:07:27.449116 16412 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1210 10:07:33.120455 16412 solver.cpp:218] Iteration 56100 (17.6345 iter/s, 5.6707s/100 iters), loss = 0.760279
I1210 10:07:33.120455 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:07:33.120455 16412 solver.cpp:237]     Train net output #1: loss = 0.760279 (* 1 = 0.760279 loss)
I1210 10:07:33.120455 16412 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1210 10:07:38.792425 16412 solver.cpp:218] Iteration 56200 (17.632 iter/s, 5.67151s/100 iters), loss = 0.596438
I1210 10:07:38.792425 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:07:38.792425 16412 solver.cpp:237]     Train net output #1: loss = 0.596438 (* 1 = 0.596438 loss)
I1210 10:07:38.792425 16412 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1210 10:07:44.474830 16412 solver.cpp:218] Iteration 56300 (17.5975 iter/s, 5.68263s/100 iters), loss = 0.929665
I1210 10:07:44.475831 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:07:44.475831 16412 solver.cpp:237]     Train net output #1: loss = 0.929665 (* 1 = 0.929665 loss)
I1210 10:07:44.475831 16412 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1210 10:07:50.151259 16412 solver.cpp:218] Iteration 56400 (17.6187 iter/s, 5.6758s/100 iters), loss = 0.890769
I1210 10:07:50.151259 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:07:50.151259 16412 solver.cpp:237]     Train net output #1: loss = 0.890769 (* 1 = 0.890769 loss)
I1210 10:07:50.151259 16412 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1210 10:07:55.549906  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:07:55.772128 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_56500.caffemodel
I1210 10:07:55.786124 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_56500.solverstate
I1210 10:07:55.791128 16412 solver.cpp:330] Iteration 56500, Testing net (#0)
I1210 10:07:55.791128 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:07:57.157797 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:07:57.212801 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6504
I1210 10:07:57.212801 16412 solver.cpp:397]     Test net output #1: loss = 1.24961 (* 1 = 1.24961 loss)
I1210 10:07:57.266844 16412 solver.cpp:218] Iteration 56500 (14.0559 iter/s, 7.11447s/100 iters), loss = 0.777475
I1210 10:07:57.266844 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:07:57.266844 16412 solver.cpp:237]     Train net output #1: loss = 0.777475 (* 1 = 0.777475 loss)
I1210 10:07:57.266844 16412 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1210 10:08:02.928598 16412 solver.cpp:218] Iteration 56600 (17.6642 iter/s, 5.66118s/100 iters), loss = 0.752187
I1210 10:08:02.928598 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:08:02.928598 16412 solver.cpp:237]     Train net output #1: loss = 0.752187 (* 1 = 0.752187 loss)
I1210 10:08:02.928598 16412 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1210 10:08:08.588022 16412 solver.cpp:218] Iteration 56700 (17.6703 iter/s, 5.6592s/100 iters), loss = 0.655778
I1210 10:08:08.588022 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:08:08.588022 16412 solver.cpp:237]     Train net output #1: loss = 0.655778 (* 1 = 0.655778 loss)
I1210 10:08:08.588022 16412 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1210 10:08:14.253351 16412 solver.cpp:218] Iteration 56800 (17.6522 iter/s, 5.66502s/100 iters), loss = 1.02756
I1210 10:08:14.253351 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:08:14.253351 16412 solver.cpp:237]     Train net output #1: loss = 1.02756 (* 1 = 1.02756 loss)
I1210 10:08:14.253351 16412 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1210 10:08:19.916445 16412 solver.cpp:218] Iteration 56900 (17.6578 iter/s, 5.66323s/100 iters), loss = 0.868179
I1210 10:08:19.917446 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:08:19.917446 16412 solver.cpp:237]     Train net output #1: loss = 0.868179 (* 1 = 0.868179 loss)
I1210 10:08:19.917446 16412 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1210 10:08:25.302250  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:08:25.524297 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_57000.caffemodel
I1210 10:08:25.538805 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_57000.solverstate
I1210 10:08:25.543305 16412 solver.cpp:330] Iteration 57000, Testing net (#0)
I1210 10:08:25.543805 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:08:26.912809 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:08:26.965329 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6412
I1210 10:08:26.965329 16412 solver.cpp:397]     Test net output #1: loss = 1.3023 (* 1 = 1.3023 loss)
I1210 10:08:27.020339 16412 solver.cpp:218] Iteration 57000 (14.0796 iter/s, 7.10249s/100 iters), loss = 0.813381
I1210 10:08:27.020339 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:08:27.020339 16412 solver.cpp:237]     Train net output #1: loss = 0.813381 (* 1 = 0.813381 loss)
I1210 10:08:27.020339 16412 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1210 10:08:32.690382 16412 solver.cpp:218] Iteration 57100 (17.6363 iter/s, 5.67011s/100 iters), loss = 0.7245
I1210 10:08:32.690382 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:08:32.690382 16412 solver.cpp:237]     Train net output #1: loss = 0.7245 (* 1 = 0.7245 loss)
I1210 10:08:32.690382 16412 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1210 10:08:38.354804 16412 solver.cpp:218] Iteration 57200 (17.6566 iter/s, 5.66361s/100 iters), loss = 0.674417
I1210 10:08:38.355293 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:08:38.355293 16412 solver.cpp:237]     Train net output #1: loss = 0.674417 (* 1 = 0.674417 loss)
I1210 10:08:38.355293 16412 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1210 10:08:44.026216 16412 solver.cpp:218] Iteration 57300 (17.6341 iter/s, 5.67083s/100 iters), loss = 0.966788
I1210 10:08:44.026216 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:08:44.026216 16412 solver.cpp:237]     Train net output #1: loss = 0.966788 (* 1 = 0.966788 loss)
I1210 10:08:44.026216 16412 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1210 10:08:49.700162 16412 solver.cpp:218] Iteration 57400 (17.6259 iter/s, 5.67347s/100 iters), loss = 0.921229
I1210 10:08:49.700162 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:08:49.700162 16412 solver.cpp:237]     Train net output #1: loss = 0.921229 (* 1 = 0.921229 loss)
I1210 10:08:49.700162 16412 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1210 10:08:55.094177  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:08:55.316618 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_57500.caffemodel
I1210 10:08:55.331616 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_57500.solverstate
I1210 10:08:55.335634 16412 solver.cpp:330] Iteration 57500, Testing net (#0)
I1210 10:08:55.335634 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:08:56.700148 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:08:56.754143 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6467
I1210 10:08:56.754143 16412 solver.cpp:397]     Test net output #1: loss = 1.26937 (* 1 = 1.26937 loss)
I1210 10:08:56.808781 16412 solver.cpp:218] Iteration 57500 (14.0689 iter/s, 7.10787s/100 iters), loss = 0.714416
I1210 10:08:56.808781 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:08:56.808781 16412 solver.cpp:237]     Train net output #1: loss = 0.714416 (* 1 = 0.714416 loss)
I1210 10:08:56.808781 16412 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1210 10:09:02.472975 16412 solver.cpp:218] Iteration 57600 (17.6556 iter/s, 5.66392s/100 iters), loss = 0.775309
I1210 10:09:02.472975 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:09:02.472975 16412 solver.cpp:237]     Train net output #1: loss = 0.775309 (* 1 = 0.775309 loss)
I1210 10:09:02.472975 16412 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1210 10:09:08.138543 16412 solver.cpp:218] Iteration 57700 (17.6525 iter/s, 5.66492s/100 iters), loss = 0.757926
I1210 10:09:08.138543 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:09:08.138543 16412 solver.cpp:237]     Train net output #1: loss = 0.757926 (* 1 = 0.757926 loss)
I1210 10:09:08.138543 16412 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1210 10:09:13.811955 16412 solver.cpp:218] Iteration 57800 (17.6268 iter/s, 5.67318s/100 iters), loss = 0.899359
I1210 10:09:13.811955 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:09:13.811955 16412 solver.cpp:237]     Train net output #1: loss = 0.899359 (* 1 = 0.899359 loss)
I1210 10:09:13.811955 16412 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1210 10:09:19.477206 16412 solver.cpp:218] Iteration 57900 (17.6525 iter/s, 5.66493s/100 iters), loss = 0.984304
I1210 10:09:19.477206 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:09:19.477206 16412 solver.cpp:237]     Train net output #1: loss = 0.984304 (* 1 = 0.984304 loss)
I1210 10:09:19.477206 16412 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1210 10:09:24.869451  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:09:25.092759 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_58000.caffemodel
I1210 10:09:25.108757 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_58000.solverstate
I1210 10:09:25.112754 16412 solver.cpp:330] Iteration 58000, Testing net (#0)
I1210 10:09:25.112754 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:09:26.483891 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:09:26.536419 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6268
I1210 10:09:26.536419 16412 solver.cpp:397]     Test net output #1: loss = 1.35009 (* 1 = 1.35009 loss)
I1210 10:09:26.590437 16412 solver.cpp:218] Iteration 58000 (14.0587 iter/s, 7.11304s/100 iters), loss = 0.79634
I1210 10:09:26.590437 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:09:26.590437 16412 solver.cpp:237]     Train net output #1: loss = 0.79634 (* 1 = 0.79634 loss)
I1210 10:09:26.590437 16412 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1210 10:09:32.270313 16412 solver.cpp:218] Iteration 58100 (17.6077 iter/s, 5.67934s/100 iters), loss = 0.701758
I1210 10:09:32.270313 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:09:32.270313 16412 solver.cpp:237]     Train net output #1: loss = 0.701758 (* 1 = 0.701758 loss)
I1210 10:09:32.270313 16412 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1210 10:09:37.950820 16412 solver.cpp:218] Iteration 58200 (17.6057 iter/s, 5.67998s/100 iters), loss = 0.712319
I1210 10:09:37.950820 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:09:37.950820 16412 solver.cpp:237]     Train net output #1: loss = 0.712319 (* 1 = 0.712319 loss)
I1210 10:09:37.950820 16412 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1210 10:09:43.620252 16412 solver.cpp:218] Iteration 58300 (17.6395 iter/s, 5.66909s/100 iters), loss = 0.944035
I1210 10:09:43.620252 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:09:43.620252 16412 solver.cpp:237]     Train net output #1: loss = 0.944035 (* 1 = 0.944035 loss)
I1210 10:09:43.620252 16412 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1210 10:09:49.296764 16412 solver.cpp:218] Iteration 58400 (17.617 iter/s, 5.67634s/100 iters), loss = 0.779454
I1210 10:09:49.296764 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:09:49.296764 16412 solver.cpp:237]     Train net output #1: loss = 0.779454 (* 1 = 0.779454 loss)
I1210 10:09:49.296764 16412 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1210 10:09:54.699090  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:09:54.922375 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_58500.caffemodel
I1210 10:09:54.936377 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_58500.solverstate
I1210 10:09:54.941371 16412 solver.cpp:330] Iteration 58500, Testing net (#0)
I1210 10:09:54.941371 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:09:56.308579 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:09:56.361575 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6373
I1210 10:09:56.361575 16412 solver.cpp:397]     Test net output #1: loss = 1.31071 (* 1 = 1.31071 loss)
I1210 10:09:56.415571 16412 solver.cpp:218] Iteration 58500 (14.0481 iter/s, 7.11842s/100 iters), loss = 0.857484
I1210 10:09:56.416575 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:09:56.416575 16412 solver.cpp:237]     Train net output #1: loss = 0.857484 (* 1 = 0.857484 loss)
I1210 10:09:56.416575 16412 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1210 10:10:02.122594 16412 solver.cpp:218] Iteration 58600 (17.5263 iter/s, 5.70571s/100 iters), loss = 0.692365
I1210 10:10:02.122594 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:10:02.122594 16412 solver.cpp:237]     Train net output #1: loss = 0.692365 (* 1 = 0.692365 loss)
I1210 10:10:02.122594 16412 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1210 10:10:07.788779 16412 solver.cpp:218] Iteration 58700 (17.6501 iter/s, 5.66571s/100 iters), loss = 0.564322
I1210 10:10:07.788779 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:10:07.788779 16412 solver.cpp:237]     Train net output #1: loss = 0.564322 (* 1 = 0.564322 loss)
I1210 10:10:07.788779 16412 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1210 10:10:13.465339 16412 solver.cpp:218] Iteration 58800 (17.6158 iter/s, 5.67672s/100 iters), loss = 0.964313
I1210 10:10:13.465339 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:10:13.465339 16412 solver.cpp:237]     Train net output #1: loss = 0.964313 (* 1 = 0.964313 loss)
I1210 10:10:13.465339 16412 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1210 10:10:19.134495 16412 solver.cpp:218] Iteration 58900 (17.6414 iter/s, 5.66847s/100 iters), loss = 0.920037
I1210 10:10:19.134495 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:10:19.134495 16412 solver.cpp:237]     Train net output #1: loss = 0.920037 (* 1 = 0.920037 loss)
I1210 10:10:19.134495 16412 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1210 10:10:24.525156  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:10:24.750164 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_59000.caffemodel
I1210 10:10:24.764163 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_59000.solverstate
I1210 10:10:24.768164 16412 solver.cpp:330] Iteration 59000, Testing net (#0)
I1210 10:10:24.769165 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:10:26.138305 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:10:26.192304 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6318
I1210 10:10:26.192304 16412 solver.cpp:397]     Test net output #1: loss = 1.34079 (* 1 = 1.34079 loss)
I1210 10:10:26.246311 16412 solver.cpp:218] Iteration 59000 (14.0617 iter/s, 7.1115s/100 iters), loss = 0.703288
I1210 10:10:26.246311 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:10:26.246311 16412 solver.cpp:237]     Train net output #1: loss = 0.703288 (* 1 = 0.703288 loss)
I1210 10:10:26.246311 16412 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1210 10:10:31.916787 16412 solver.cpp:218] Iteration 59100 (17.6371 iter/s, 5.66987s/100 iters), loss = 0.745011
I1210 10:10:31.917285 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:10:31.917285 16412 solver.cpp:237]     Train net output #1: loss = 0.745011 (* 1 = 0.745011 loss)
I1210 10:10:31.917285 16412 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1210 10:10:37.591285 16412 solver.cpp:218] Iteration 59200 (17.6249 iter/s, 5.67381s/100 iters), loss = 0.631466
I1210 10:10:37.591285 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:10:37.591285 16412 solver.cpp:237]     Train net output #1: loss = 0.631466 (* 1 = 0.631466 loss)
I1210 10:10:37.591285 16412 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1210 10:10:43.268761 16412 solver.cpp:218] Iteration 59300 (17.6133 iter/s, 5.67752s/100 iters), loss = 0.891294
I1210 10:10:43.268761 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:10:43.268761 16412 solver.cpp:237]     Train net output #1: loss = 0.891294 (* 1 = 0.891294 loss)
I1210 10:10:43.268761 16412 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1210 10:10:48.948194 16412 solver.cpp:218] Iteration 59400 (17.6099 iter/s, 5.67863s/100 iters), loss = 0.960402
I1210 10:10:48.948194 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:10:48.948194 16412 solver.cpp:237]     Train net output #1: loss = 0.960402 (* 1 = 0.960402 loss)
I1210 10:10:48.948194 16412 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1210 10:10:54.347615  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:10:54.567627 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_59500.caffemodel
I1210 10:10:54.584633 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_59500.solverstate
I1210 10:10:54.590628 16412 solver.cpp:330] Iteration 59500, Testing net (#0)
I1210 10:10:54.590628 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:10:55.960793 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:10:56.014796 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6372
I1210 10:10:56.014796 16412 solver.cpp:397]     Test net output #1: loss = 1.31898 (* 1 = 1.31898 loss)
I1210 10:10:56.067816 16412 solver.cpp:218] Iteration 59500 (14.046 iter/s, 7.11945s/100 iters), loss = 0.71989
I1210 10:10:56.067816 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:10:56.067816 16412 solver.cpp:237]     Train net output #1: loss = 0.71989 (* 1 = 0.71989 loss)
I1210 10:10:56.067816 16412 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1210 10:11:01.740265 16412 solver.cpp:218] Iteration 59600 (17.6314 iter/s, 5.6717s/100 iters), loss = 0.75957
I1210 10:11:01.740265 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:11:01.740265 16412 solver.cpp:237]     Train net output #1: loss = 0.75957 (* 1 = 0.75957 loss)
I1210 10:11:01.740265 16412 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1210 10:11:07.411803 16412 solver.cpp:218] Iteration 59700 (17.6328 iter/s, 5.67126s/100 iters), loss = 0.559994
I1210 10:11:07.412307 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:11:07.412307 16412 solver.cpp:237]     Train net output #1: loss = 0.559994 (* 1 = 0.559994 loss)
I1210 10:11:07.412307 16412 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1210 10:11:13.079282 16412 solver.cpp:218] Iteration 59800 (17.6445 iter/s, 5.66747s/100 iters), loss = 0.918154
I1210 10:11:13.080286 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:11:13.080286 16412 solver.cpp:237]     Train net output #1: loss = 0.918154 (* 1 = 0.918154 loss)
I1210 10:11:13.080286 16412 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1210 10:11:18.754825 16412 solver.cpp:218] Iteration 59900 (17.6213 iter/s, 5.67496s/100 iters), loss = 0.837895
I1210 10:11:18.754825 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:11:18.754825 16412 solver.cpp:237]     Train net output #1: loss = 0.837895 (* 1 = 0.837895 loss)
I1210 10:11:18.754825 16412 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1210 10:11:24.153250  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:11:24.376262 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_60000.caffemodel
I1210 10:11:24.390262 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_60000.solverstate
I1210 10:11:24.394263 16412 solver.cpp:330] Iteration 60000, Testing net (#0)
I1210 10:11:24.395263 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:11:25.761348 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:11:25.816849 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6259
I1210 10:11:25.816849 16412 solver.cpp:397]     Test net output #1: loss = 1.37338 (* 1 = 1.37338 loss)
I1210 10:11:25.870352 16412 solver.cpp:218] Iteration 60000 (14.0555 iter/s, 7.11465s/100 iters), loss = 0.766899
I1210 10:11:25.870352 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:11:25.870352 16412 solver.cpp:237]     Train net output #1: loss = 0.766899 (* 1 = 0.766899 loss)
I1210 10:11:25.870352 16412 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1210 10:11:31.537773 16412 solver.cpp:218] Iteration 60100 (17.6461 iter/s, 5.66696s/100 iters), loss = 0.771794
I1210 10:11:31.537773 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:11:31.537773 16412 solver.cpp:237]     Train net output #1: loss = 0.771794 (* 1 = 0.771794 loss)
I1210 10:11:31.537773 16412 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1210 10:11:37.213182 16412 solver.cpp:218] Iteration 60200 (17.6223 iter/s, 5.67464s/100 iters), loss = 0.670741
I1210 10:11:37.213182 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:11:37.213182 16412 solver.cpp:237]     Train net output #1: loss = 0.670741 (* 1 = 0.670741 loss)
I1210 10:11:37.213182 16412 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1210 10:11:42.889613 16412 solver.cpp:218] Iteration 60300 (17.6181 iter/s, 5.676s/100 iters), loss = 0.841313
I1210 10:11:42.889613 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:11:42.889613 16412 solver.cpp:237]     Train net output #1: loss = 0.841313 (* 1 = 0.841313 loss)
I1210 10:11:42.889613 16412 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1210 10:11:48.563019 16412 solver.cpp:218] Iteration 60400 (17.6249 iter/s, 5.67379s/100 iters), loss = 0.882533
I1210 10:11:48.564018 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:11:48.564018 16412 solver.cpp:237]     Train net output #1: loss = 0.882533 (* 1 = 0.882533 loss)
I1210 10:11:48.564018 16412 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1210 10:11:53.957430  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:11:54.180444 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_60500.caffemodel
I1210 10:11:54.195443 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_60500.solverstate
I1210 10:11:54.200444 16412 solver.cpp:330] Iteration 60500, Testing net (#0)
I1210 10:11:54.200444 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:11:55.568550 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:11:55.622052 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6271
I1210 10:11:55.622052 16412 solver.cpp:397]     Test net output #1: loss = 1.36334 (* 1 = 1.36334 loss)
I1210 10:11:55.675555 16412 solver.cpp:218] Iteration 60500 (14.0607 iter/s, 7.11202s/100 iters), loss = 0.742984
I1210 10:11:55.676555 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:11:55.676555 16412 solver.cpp:237]     Train net output #1: loss = 0.742984 (* 1 = 0.742984 loss)
I1210 10:11:55.676555 16412 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1210 10:12:01.352031 16412 solver.cpp:218] Iteration 60600 (17.6207 iter/s, 5.67514s/100 iters), loss = 0.707938
I1210 10:12:01.352031 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:12:01.352031 16412 solver.cpp:237]     Train net output #1: loss = 0.707938 (* 1 = 0.707938 loss)
I1210 10:12:01.352031 16412 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1210 10:12:07.030031 16412 solver.cpp:218] Iteration 60700 (17.6123 iter/s, 5.67784s/100 iters), loss = 0.686595
I1210 10:12:07.030031 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:12:07.030031 16412 solver.cpp:237]     Train net output #1: loss = 0.686595 (* 1 = 0.686595 loss)
I1210 10:12:07.030031 16412 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1210 10:12:12.706950 16412 solver.cpp:218] Iteration 60800 (17.6161 iter/s, 5.67663s/100 iters), loss = 0.876742
I1210 10:12:12.706950 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:12:12.706950 16412 solver.cpp:237]     Train net output #1: loss = 0.876742 (* 1 = 0.876742 loss)
I1210 10:12:12.706950 16412 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1210 10:12:18.387207 16412 solver.cpp:218] Iteration 60900 (17.606 iter/s, 5.67989s/100 iters), loss = 0.874632
I1210 10:12:18.387207 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:12:18.387207 16412 solver.cpp:237]     Train net output #1: loss = 0.874632 (* 1 = 0.874632 loss)
I1210 10:12:18.387207 16412 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1210 10:12:23.786242  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:12:24.009284 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_61000.caffemodel
I1210 10:12:24.026782 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_61000.solverstate
I1210 10:12:24.033293 16412 solver.cpp:330] Iteration 61000, Testing net (#0)
I1210 10:12:24.033793 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:12:25.401775 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:12:25.455554 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6268
I1210 10:12:25.455554 16412 solver.cpp:397]     Test net output #1: loss = 1.35465 (* 1 = 1.35465 loss)
I1210 10:12:25.508566 16412 solver.cpp:218] Iteration 61000 (14.0429 iter/s, 7.12104s/100 iters), loss = 0.72768
I1210 10:12:25.508566 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:12:25.508566 16412 solver.cpp:237]     Train net output #1: loss = 0.72768 (* 1 = 0.72768 loss)
I1210 10:12:25.508566 16412 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1210 10:12:31.185271 16412 solver.cpp:218] Iteration 61100 (17.6191 iter/s, 5.67566s/100 iters), loss = 0.748002
I1210 10:12:31.185271 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:12:31.185271 16412 solver.cpp:237]     Train net output #1: loss = 0.748002 (* 1 = 0.748002 loss)
I1210 10:12:31.185271 16412 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1210 10:12:36.867323 16412 solver.cpp:218] Iteration 61200 (17.6004 iter/s, 5.68169s/100 iters), loss = 0.640788
I1210 10:12:36.867323 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:12:36.867323 16412 solver.cpp:237]     Train net output #1: loss = 0.640788 (* 1 = 0.640788 loss)
I1210 10:12:36.867323 16412 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1210 10:12:42.538604 16412 solver.cpp:218] Iteration 61300 (17.6339 iter/s, 5.67091s/100 iters), loss = 0.89456
I1210 10:12:42.538604 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:12:42.538604 16412 solver.cpp:237]     Train net output #1: loss = 0.89456 (* 1 = 0.89456 loss)
I1210 10:12:42.538604 16412 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1210 10:12:48.211200 16412 solver.cpp:218] Iteration 61400 (17.6281 iter/s, 5.67275s/100 iters), loss = 0.814367
I1210 10:12:48.211200 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:12:48.211200 16412 solver.cpp:237]     Train net output #1: loss = 0.814367 (* 1 = 0.814367 loss)
I1210 10:12:48.211200 16412 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1210 10:12:53.601866  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:12:53.824918 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_61500.caffemodel
I1210 10:12:53.839923 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_61500.solverstate
I1210 10:12:53.844422 16412 solver.cpp:330] Iteration 61500, Testing net (#0)
I1210 10:12:53.844422 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:12:55.212388 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:12:55.266968 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6262
I1210 10:12:55.266968 16412 solver.cpp:397]     Test net output #1: loss = 1.37001 (* 1 = 1.37001 loss)
I1210 10:12:55.321964 16412 solver.cpp:218] Iteration 61500 (14.0658 iter/s, 7.10943s/100 iters), loss = 0.785177
I1210 10:12:55.321964 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:12:55.321964 16412 solver.cpp:237]     Train net output #1: loss = 0.785177 (* 1 = 0.785177 loss)
I1210 10:12:55.321964 16412 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1210 10:13:00.999487 16412 solver.cpp:218] Iteration 61600 (17.612 iter/s, 5.67795s/100 iters), loss = 0.772547
I1210 10:13:00.999487 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:13:00.999487 16412 solver.cpp:237]     Train net output #1: loss = 0.772547 (* 1 = 0.772547 loss)
I1210 10:13:01.000488 16412 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1210 10:13:06.679888 16412 solver.cpp:218] Iteration 61700 (17.6072 iter/s, 5.67949s/100 iters), loss = 0.715859
I1210 10:13:06.679888 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:13:06.679888 16412 solver.cpp:237]     Train net output #1: loss = 0.715859 (* 1 = 0.715859 loss)
I1210 10:13:06.679888 16412 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1210 10:13:12.356757 16412 solver.cpp:218] Iteration 61800 (17.6153 iter/s, 5.67688s/100 iters), loss = 0.859312
I1210 10:13:12.356757 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:13:12.356757 16412 solver.cpp:237]     Train net output #1: loss = 0.859312 (* 1 = 0.859312 loss)
I1210 10:13:12.356757 16412 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1210 10:13:18.021314 16412 solver.cpp:218] Iteration 61900 (17.6567 iter/s, 5.66358s/100 iters), loss = 0.829591
I1210 10:13:18.021314 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:13:18.021314 16412 solver.cpp:237]     Train net output #1: loss = 0.829591 (* 1 = 0.829591 loss)
I1210 10:13:18.021314 16412 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1210 10:13:23.426678  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:13:23.649194 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_62000.caffemodel
I1210 10:13:23.663193 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_62000.solverstate
I1210 10:13:23.667193 16412 solver.cpp:330] Iteration 62000, Testing net (#0)
I1210 10:13:23.667193 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:13:25.035203 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:13:25.088199 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6313
I1210 10:13:25.088199 16412 solver.cpp:397]     Test net output #1: loss = 1.32638 (* 1 = 1.32638 loss)
I1210 10:13:25.143713 16412 solver.cpp:218] Iteration 62000 (14.0405 iter/s, 7.12225s/100 iters), loss = 0.769587
I1210 10:13:25.143713 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:13:25.143713 16412 solver.cpp:237]     Train net output #1: loss = 0.769587 (* 1 = 0.769587 loss)
I1210 10:13:25.143713 16412 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1210 10:13:30.819938 16412 solver.cpp:218] Iteration 62100 (17.6214 iter/s, 5.67492s/100 iters), loss = 0.711708
I1210 10:13:30.819938 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:13:30.819938 16412 solver.cpp:237]     Train net output #1: loss = 0.711708 (* 1 = 0.711708 loss)
I1210 10:13:30.819938 16412 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1210 10:13:36.491230 16412 solver.cpp:218] Iteration 62200 (17.6315 iter/s, 5.67167s/100 iters), loss = 0.75887
I1210 10:13:36.491230 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:13:36.491230 16412 solver.cpp:237]     Train net output #1: loss = 0.75887 (* 1 = 0.75887 loss)
I1210 10:13:36.491230 16412 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1210 10:13:42.160007 16412 solver.cpp:218] Iteration 62300 (17.6442 iter/s, 5.66759s/100 iters), loss = 0.908334
I1210 10:13:42.160007 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:13:42.160007 16412 solver.cpp:237]     Train net output #1: loss = 0.908334 (* 1 = 0.908334 loss)
I1210 10:13:42.160007 16412 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1210 10:13:47.828821 16412 solver.cpp:218] Iteration 62400 (17.6412 iter/s, 5.66854s/100 iters), loss = 0.873271
I1210 10:13:47.828821 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:13:47.828821 16412 solver.cpp:237]     Train net output #1: loss = 0.873271 (* 1 = 0.873271 loss)
I1210 10:13:47.828821 16412 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1210 10:13:53.213523  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:13:53.436604 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_62500.caffemodel
I1210 10:13:53.449625 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_62500.solverstate
I1210 10:13:53.454625 16412 solver.cpp:330] Iteration 62500, Testing net (#0)
I1210 10:13:53.454625 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:13:54.822226 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:13:54.875262 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6289
I1210 10:13:54.875262 16412 solver.cpp:397]     Test net output #1: loss = 1.34079 (* 1 = 1.34079 loss)
I1210 10:13:54.929257 16412 solver.cpp:218] Iteration 62500 (14.0831 iter/s, 7.10073s/100 iters), loss = 0.661475
I1210 10:13:54.930261 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:13:54.930261 16412 solver.cpp:237]     Train net output #1: loss = 0.661475 (* 1 = 0.661475 loss)
I1210 10:13:54.930261 16412 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1210 10:14:00.601444 16412 solver.cpp:218] Iteration 62600 (17.6328 iter/s, 5.67126s/100 iters), loss = 0.636363
I1210 10:14:00.601444 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:14:00.601444 16412 solver.cpp:237]     Train net output #1: loss = 0.636363 (* 1 = 0.636363 loss)
I1210 10:14:00.601444 16412 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1210 10:14:06.269424 16412 solver.cpp:218] Iteration 62700 (17.6446 iter/s, 5.66746s/100 iters), loss = 0.567757
I1210 10:14:06.269424 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:14:06.269424 16412 solver.cpp:237]     Train net output #1: loss = 0.567757 (* 1 = 0.567757 loss)
I1210 10:14:06.269424 16412 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1210 10:14:11.950845 16412 solver.cpp:218] Iteration 62800 (17.6038 iter/s, 5.68061s/100 iters), loss = 1.00623
I1210 10:14:11.950845 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 10:14:11.950845 16412 solver.cpp:237]     Train net output #1: loss = 1.00623 (* 1 = 1.00623 loss)
I1210 10:14:11.950845 16412 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1210 10:14:17.621265 16412 solver.cpp:218] Iteration 62900 (17.6351 iter/s, 5.67052s/100 iters), loss = 0.803494
I1210 10:14:17.621265 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:14:17.621265 16412 solver.cpp:237]     Train net output #1: loss = 0.803494 (* 1 = 0.803494 loss)
I1210 10:14:17.621265 16412 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1210 10:14:23.016566  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:14:23.240593 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_63000.caffemodel
I1210 10:14:23.256598 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_63000.solverstate
I1210 10:14:23.260598 16412 solver.cpp:330] Iteration 63000, Testing net (#0)
I1210 10:14:23.260598 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:14:24.628692 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:14:24.682696 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6126
I1210 10:14:24.682696 16412 solver.cpp:397]     Test net output #1: loss = 1.47864 (* 1 = 1.47864 loss)
I1210 10:14:24.738199 16412 solver.cpp:218] Iteration 63000 (14.053 iter/s, 7.11591s/100 iters), loss = 0.728204
I1210 10:14:24.738199 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:14:24.738199 16412 solver.cpp:237]     Train net output #1: loss = 0.728204 (* 1 = 0.728204 loss)
I1210 10:14:24.738199 16412 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1210 10:14:30.409085 16412 solver.cpp:218] Iteration 63100 (17.6343 iter/s, 5.67076s/100 iters), loss = 0.788737
I1210 10:14:30.409085 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:14:30.409085 16412 solver.cpp:237]     Train net output #1: loss = 0.788737 (* 1 = 0.788737 loss)
I1210 10:14:30.409085 16412 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1210 10:14:36.080754 16412 solver.cpp:218] Iteration 63200 (17.6338 iter/s, 5.67094s/100 iters), loss = 0.687685
I1210 10:14:36.080754 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:14:36.080754 16412 solver.cpp:237]     Train net output #1: loss = 0.687685 (* 1 = 0.687685 loss)
I1210 10:14:36.080754 16412 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1210 10:14:41.743212 16412 solver.cpp:218] Iteration 63300 (17.6615 iter/s, 5.66202s/100 iters), loss = 0.932985
I1210 10:14:41.743212 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:14:41.743212 16412 solver.cpp:237]     Train net output #1: loss = 0.932985 (* 1 = 0.932985 loss)
I1210 10:14:41.743212 16412 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1210 10:14:47.406194 16412 solver.cpp:218] Iteration 63400 (17.6577 iter/s, 5.66324s/100 iters), loss = 0.813661
I1210 10:14:47.406194 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:14:47.406194 16412 solver.cpp:237]     Train net output #1: loss = 0.813661 (* 1 = 0.813661 loss)
I1210 10:14:47.406194 16412 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1210 10:14:52.791661  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:14:53.014677 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_63500.caffemodel
I1210 10:14:53.034677 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_63500.solverstate
I1210 10:14:53.039675 16412 solver.cpp:330] Iteration 63500, Testing net (#0)
I1210 10:14:53.039675 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:14:54.408797 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:14:54.462301 16412 solver.cpp:397]     Test net output #0: accuracy = 0.626
I1210 10:14:54.462301 16412 solver.cpp:397]     Test net output #1: loss = 1.3899 (* 1 = 1.3899 loss)
I1210 10:14:54.515805 16412 solver.cpp:218] Iteration 63500 (14.0667 iter/s, 7.10901s/100 iters), loss = 0.605011
I1210 10:14:54.515805 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:14:54.515805 16412 solver.cpp:237]     Train net output #1: loss = 0.605011 (* 1 = 0.605011 loss)
I1210 10:14:54.515805 16412 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1210 10:15:00.188304 16412 solver.cpp:218] Iteration 63600 (17.6297 iter/s, 5.67226s/100 iters), loss = 0.637153
I1210 10:15:00.188304 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:15:00.188304 16412 solver.cpp:237]     Train net output #1: loss = 0.637153 (* 1 = 0.637153 loss)
I1210 10:15:00.188304 16412 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1210 10:15:05.855785 16412 solver.cpp:218] Iteration 63700 (17.6488 iter/s, 5.66612s/100 iters), loss = 0.610604
I1210 10:15:05.855785 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:15:05.855785 16412 solver.cpp:237]     Train net output #1: loss = 0.610604 (* 1 = 0.610604 loss)
I1210 10:15:05.855785 16412 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1210 10:15:11.524224 16412 solver.cpp:218] Iteration 63800 (17.6412 iter/s, 5.66855s/100 iters), loss = 1.01402
I1210 10:15:11.524224 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:15:11.524224 16412 solver.cpp:237]     Train net output #1: loss = 1.01402 (* 1 = 1.01402 loss)
I1210 10:15:11.524224 16412 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1210 10:15:17.179642 16412 solver.cpp:218] Iteration 63900 (17.6827 iter/s, 5.65524s/100 iters), loss = 0.784516
I1210 10:15:17.179642 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:15:17.179642 16412 solver.cpp:237]     Train net output #1: loss = 0.784516 (* 1 = 0.784516 loss)
I1210 10:15:17.179642 16412 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1210 10:15:22.563096  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:15:22.784374 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_64000.caffemodel
I1210 10:15:22.797374 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_64000.solverstate
I1210 10:15:22.801374 16412 solver.cpp:330] Iteration 64000, Testing net (#0)
I1210 10:15:22.802372 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:15:24.169955 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:15:24.222961 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6311
I1210 10:15:24.222961 16412 solver.cpp:397]     Test net output #1: loss = 1.39131 (* 1 = 1.39131 loss)
I1210 10:15:24.278992 16412 solver.cpp:218] Iteration 64000 (14.0877 iter/s, 7.09837s/100 iters), loss = 0.658197
I1210 10:15:24.278992 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:15:24.278992 16412 solver.cpp:237]     Train net output #1: loss = 0.658197 (* 1 = 0.658197 loss)
I1210 10:15:24.278992 16412 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1210 10:15:29.948010 16412 solver.cpp:218] Iteration 64100 (17.64 iter/s, 5.66892s/100 iters), loss = 0.755612
I1210 10:15:29.948010 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:15:29.948010 16412 solver.cpp:237]     Train net output #1: loss = 0.755612 (* 1 = 0.755612 loss)
I1210 10:15:29.948010 16412 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1210 10:15:35.612821 16412 solver.cpp:218] Iteration 64200 (17.6554 iter/s, 5.66399s/100 iters), loss = 0.586476
I1210 10:15:35.612821 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:15:35.612821 16412 solver.cpp:237]     Train net output #1: loss = 0.586476 (* 1 = 0.586476 loss)
I1210 10:15:35.612821 16412 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1210 10:15:41.275946 16412 solver.cpp:218] Iteration 64300 (17.6591 iter/s, 5.66282s/100 iters), loss = 0.901011
I1210 10:15:41.276450 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:15:41.276450 16412 solver.cpp:237]     Train net output #1: loss = 0.901011 (* 1 = 0.901011 loss)
I1210 10:15:41.276450 16412 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1210 10:15:46.946887 16412 solver.cpp:218] Iteration 64400 (17.6359 iter/s, 5.67026s/100 iters), loss = 0.749933
I1210 10:15:46.946887 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:15:46.946887 16412 solver.cpp:237]     Train net output #1: loss = 0.749933 (* 1 = 0.749933 loss)
I1210 10:15:46.946887 16412 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1210 10:15:52.337220  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:15:52.560279 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_64500.caffemodel
I1210 10:15:52.576326 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_64500.solverstate
I1210 10:15:52.580826 16412 solver.cpp:330] Iteration 64500, Testing net (#0)
I1210 10:15:52.580826 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:15:53.947139 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:15:54.000650 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6058
I1210 10:15:54.000650 16412 solver.cpp:397]     Test net output #1: loss = 1.44712 (* 1 = 1.44712 loss)
I1210 10:15:54.054664 16412 solver.cpp:218] Iteration 64500 (14.0696 iter/s, 7.10751s/100 iters), loss = 0.640324
I1210 10:15:54.054664 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:15:54.054664 16412 solver.cpp:237]     Train net output #1: loss = 0.640324 (* 1 = 0.640324 loss)
I1210 10:15:54.054664 16412 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1210 10:15:59.733700 16412 solver.cpp:218] Iteration 64600 (17.6106 iter/s, 5.6784s/100 iters), loss = 0.763144
I1210 10:15:59.733700 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:15:59.733700 16412 solver.cpp:237]     Train net output #1: loss = 0.763144 (* 1 = 0.763144 loss)
I1210 10:15:59.733700 16412 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1210 10:16:05.403920 16412 solver.cpp:218] Iteration 64700 (17.6373 iter/s, 5.6698s/100 iters), loss = 0.667464
I1210 10:16:05.403920 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:16:05.403920 16412 solver.cpp:237]     Train net output #1: loss = 0.667464 (* 1 = 0.667464 loss)
I1210 10:16:05.403920 16412 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1210 10:16:11.075350 16412 solver.cpp:218] Iteration 64800 (17.6323 iter/s, 5.67139s/100 iters), loss = 0.996825
I1210 10:16:11.075350 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:16:11.075350 16412 solver.cpp:237]     Train net output #1: loss = 0.996825 (* 1 = 0.996825 loss)
I1210 10:16:11.075350 16412 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1210 10:16:16.748972 16412 solver.cpp:218] Iteration 64900 (17.6265 iter/s, 5.67327s/100 iters), loss = 0.944615
I1210 10:16:16.748972 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:16:16.748972 16412 solver.cpp:237]     Train net output #1: loss = 0.944615 (* 1 = 0.944615 loss)
I1210 10:16:16.748972 16412 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1210 10:16:22.140341  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:16:22.363349 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_65000.caffemodel
I1210 10:16:22.380350 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_65000.solverstate
I1210 10:16:22.385854 16412 solver.cpp:330] Iteration 65000, Testing net (#0)
I1210 10:16:22.385854 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:16:23.751453 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:16:23.806458 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5817
I1210 10:16:23.806458 16412 solver.cpp:397]     Test net output #1: loss = 1.63339 (* 1 = 1.63339 loss)
I1210 10:16:23.861457 16412 solver.cpp:218] Iteration 65000 (14.0621 iter/s, 7.11134s/100 iters), loss = 0.644001
I1210 10:16:23.861457 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:16:23.861457 16412 solver.cpp:237]     Train net output #1: loss = 0.644001 (* 1 = 0.644001 loss)
I1210 10:16:23.861457 16412 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1210 10:16:29.525880 16412 solver.cpp:218] Iteration 65100 (17.6551 iter/s, 5.66407s/100 iters), loss = 0.712242
I1210 10:16:29.525880 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:16:29.525880 16412 solver.cpp:237]     Train net output #1: loss = 0.712242 (* 1 = 0.712242 loss)
I1210 10:16:29.525880 16412 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1210 10:16:35.198827 16412 solver.cpp:218] Iteration 65200 (17.6283 iter/s, 5.67269s/100 iters), loss = 0.625272
I1210 10:16:35.198827 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:16:35.198827 16412 solver.cpp:237]     Train net output #1: loss = 0.625272 (* 1 = 0.625272 loss)
I1210 10:16:35.198827 16412 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1210 10:16:40.869709 16412 solver.cpp:218] Iteration 65300 (17.6334 iter/s, 5.67105s/100 iters), loss = 0.965482
I1210 10:16:40.870708 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:16:40.870708 16412 solver.cpp:237]     Train net output #1: loss = 0.965482 (* 1 = 0.965482 loss)
I1210 10:16:40.870708 16412 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1210 10:16:46.537096 16412 solver.cpp:218] Iteration 65400 (17.6477 iter/s, 5.66647s/100 iters), loss = 0.75121
I1210 10:16:46.537096 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:16:46.537096 16412 solver.cpp:237]     Train net output #1: loss = 0.75121 (* 1 = 0.75121 loss)
I1210 10:16:46.537096 16412 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1210 10:16:51.933475  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:16:52.156484 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_65500.caffemodel
I1210 10:16:52.171484 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_65500.solverstate
I1210 10:16:52.176486 16412 solver.cpp:330] Iteration 65500, Testing net (#0)
I1210 10:16:52.176486 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:16:53.546757 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:16:53.600263 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5798
I1210 10:16:53.600263 16412 solver.cpp:397]     Test net output #1: loss = 1.67339 (* 1 = 1.67339 loss)
I1210 10:16:53.654767 16412 solver.cpp:218] Iteration 65500 (14.051 iter/s, 7.11694s/100 iters), loss = 0.670006
I1210 10:16:53.654767 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:16:53.654767 16412 solver.cpp:237]     Train net output #1: loss = 0.670006 (* 1 = 0.670006 loss)
I1210 10:16:53.654767 16412 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1210 10:16:59.336213 16412 solver.cpp:218] Iteration 65600 (17.6018 iter/s, 5.68125s/100 iters), loss = 0.666267
I1210 10:16:59.336213 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:16:59.336213 16412 solver.cpp:237]     Train net output #1: loss = 0.666267 (* 1 = 0.666267 loss)
I1210 10:16:59.336213 16412 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1210 10:17:05.020584 16412 solver.cpp:218] Iteration 65700 (17.5948 iter/s, 5.68349s/100 iters), loss = 0.589415
I1210 10:17:05.020584 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:17:05.020584 16412 solver.cpp:237]     Train net output #1: loss = 0.589415 (* 1 = 0.589415 loss)
I1210 10:17:05.020584 16412 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1210 10:17:10.691344 16412 solver.cpp:218] Iteration 65800 (17.6353 iter/s, 5.67043s/100 iters), loss = 0.963584
I1210 10:17:10.691344 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:17:10.691344 16412 solver.cpp:237]     Train net output #1: loss = 0.963584 (* 1 = 0.963584 loss)
I1210 10:17:10.691344 16412 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1210 10:17:16.366034 16412 solver.cpp:218] Iteration 65900 (17.6227 iter/s, 5.67451s/100 iters), loss = 0.995536
I1210 10:17:16.366034 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:17:16.366034 16412 solver.cpp:237]     Train net output #1: loss = 0.995536 (* 1 = 0.995536 loss)
I1210 10:17:16.366034 16412 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1210 10:17:21.764397  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:17:21.988409 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_66000.caffemodel
I1210 10:17:22.003412 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_66000.solverstate
I1210 10:17:22.008412 16412 solver.cpp:330] Iteration 66000, Testing net (#0)
I1210 10:17:22.008412 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:17:23.376523 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:17:23.430527 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5984
I1210 10:17:23.430527 16412 solver.cpp:397]     Test net output #1: loss = 1.52544 (* 1 = 1.52544 loss)
I1210 10:17:23.484526 16412 solver.cpp:218] Iteration 66000 (14.0482 iter/s, 7.11835s/100 iters), loss = 0.73402
I1210 10:17:23.484526 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:17:23.484526 16412 solver.cpp:237]     Train net output #1: loss = 0.73402 (* 1 = 0.73402 loss)
I1210 10:17:23.484526 16412 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1210 10:17:29.152989 16412 solver.cpp:218] Iteration 66100 (17.6447 iter/s, 5.66742s/100 iters), loss = 0.788058
I1210 10:17:29.152989 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1210 10:17:29.152989 16412 solver.cpp:237]     Train net output #1: loss = 0.788058 (* 1 = 0.788058 loss)
I1210 10:17:29.152989 16412 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1210 10:17:34.822382 16412 solver.cpp:218] Iteration 66200 (17.6401 iter/s, 5.66889s/100 iters), loss = 0.632836
I1210 10:17:34.822382 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:17:34.822382 16412 solver.cpp:237]     Train net output #1: loss = 0.632836 (* 1 = 0.632836 loss)
I1210 10:17:34.822382 16412 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1210 10:17:40.493942 16412 solver.cpp:218] Iteration 66300 (17.6331 iter/s, 5.67115s/100 iters), loss = 0.835278
I1210 10:17:40.493942 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:17:40.493942 16412 solver.cpp:237]     Train net output #1: loss = 0.835278 (* 1 = 0.835278 loss)
I1210 10:17:40.493942 16412 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1210 10:17:46.164396 16412 solver.cpp:218] Iteration 66400 (17.6362 iter/s, 5.67015s/100 iters), loss = 0.790365
I1210 10:17:46.164396 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:17:46.164396 16412 solver.cpp:237]     Train net output #1: loss = 0.790365 (* 1 = 0.790365 loss)
I1210 10:17:46.164396 16412 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1210 10:17:51.555825  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:17:51.777837 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_66500.caffemodel
I1210 10:17:51.791836 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_66500.solverstate
I1210 10:17:51.796842 16412 solver.cpp:330] Iteration 66500, Testing net (#0)
I1210 10:17:51.796842 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:17:53.166877 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:17:53.219883 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6071
I1210 10:17:53.219883 16412 solver.cpp:397]     Test net output #1: loss = 1.51092 (* 1 = 1.51092 loss)
I1210 10:17:53.272881 16412 solver.cpp:218] Iteration 66500 (14.0678 iter/s, 7.10843s/100 iters), loss = 0.695621
I1210 10:17:53.272881 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:17:53.272881 16412 solver.cpp:237]     Train net output #1: loss = 0.695621 (* 1 = 0.695621 loss)
I1210 10:17:53.272881 16412 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1210 10:17:58.944277 16412 solver.cpp:218] Iteration 66600 (17.6361 iter/s, 5.6702s/100 iters), loss = 0.759224
I1210 10:17:58.944277 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:17:58.944277 16412 solver.cpp:237]     Train net output #1: loss = 0.759224 (* 1 = 0.759224 loss)
I1210 10:17:58.944277 16412 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1210 10:18:04.614665 16412 solver.cpp:218] Iteration 66700 (17.6358 iter/s, 5.67027s/100 iters), loss = 0.607977
I1210 10:18:04.614665 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:18:04.614665 16412 solver.cpp:237]     Train net output #1: loss = 0.607977 (* 1 = 0.607977 loss)
I1210 10:18:04.614665 16412 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1210 10:18:10.282058 16412 solver.cpp:218] Iteration 66800 (17.6462 iter/s, 5.66695s/100 iters), loss = 0.872887
I1210 10:18:10.282058 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:18:10.282058 16412 solver.cpp:237]     Train net output #1: loss = 0.872887 (* 1 = 0.872887 loss)
I1210 10:18:10.282058 16412 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1210 10:18:15.959462 16412 solver.cpp:218] Iteration 66900 (17.6147 iter/s, 5.67707s/100 iters), loss = 0.865585
I1210 10:18:15.959462 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:18:15.959462 16412 solver.cpp:237]     Train net output #1: loss = 0.865585 (* 1 = 0.865585 loss)
I1210 10:18:15.959462 16412 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1210 10:18:21.350782  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:18:21.573791 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_67000.caffemodel
I1210 10:18:21.587791 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_67000.solverstate
I1210 10:18:21.592792 16412 solver.cpp:330] Iteration 67000, Testing net (#0)
I1210 10:18:21.592792 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:18:22.963883 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:18:23.016887 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6137
I1210 10:18:23.016887 16412 solver.cpp:397]     Test net output #1: loss = 1.45229 (* 1 = 1.45229 loss)
I1210 10:18:23.070886 16412 solver.cpp:218] Iteration 67000 (14.0625 iter/s, 7.11113s/100 iters), loss = 0.757093
I1210 10:18:23.070886 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:18:23.070886 16412 solver.cpp:237]     Train net output #1: loss = 0.757093 (* 1 = 0.757093 loss)
I1210 10:18:23.070886 16412 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1210 10:18:28.739292 16412 solver.cpp:218] Iteration 67100 (17.6446 iter/s, 5.66747s/100 iters), loss = 0.665355
I1210 10:18:28.739292 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:18:28.739292 16412 solver.cpp:237]     Train net output #1: loss = 0.665355 (* 1 = 0.665355 loss)
I1210 10:18:28.739292 16412 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1210 10:18:34.405316 16412 solver.cpp:218] Iteration 67200 (17.6504 iter/s, 5.6656s/100 iters), loss = 0.590955
I1210 10:18:34.405316 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:18:34.405316 16412 solver.cpp:237]     Train net output #1: loss = 0.590955 (* 1 = 0.590955 loss)
I1210 10:18:34.405316 16412 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1210 10:18:40.087290 16412 solver.cpp:218] Iteration 67300 (17.6005 iter/s, 5.68164s/100 iters), loss = 0.885859
I1210 10:18:40.087290 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:18:40.087290 16412 solver.cpp:237]     Train net output #1: loss = 0.885859 (* 1 = 0.885859 loss)
I1210 10:18:40.087290 16412 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1210 10:18:45.792803 16412 solver.cpp:218] Iteration 67400 (17.5291 iter/s, 5.70479s/100 iters), loss = 0.935556
I1210 10:18:45.792803 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:18:45.792803 16412 solver.cpp:237]     Train net output #1: loss = 0.935556 (* 1 = 0.935556 loss)
I1210 10:18:45.792803 16412 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1210 10:18:51.270462  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:18:51.497480 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_67500.caffemodel
I1210 10:18:51.511484 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_67500.solverstate
I1210 10:18:51.515486 16412 solver.cpp:330] Iteration 67500, Testing net (#0)
I1210 10:18:51.515486 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:18:52.916824 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:18:52.969822 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5971
I1210 10:18:52.969822 16412 solver.cpp:397]     Test net output #1: loss = 1.55064 (* 1 = 1.55064 loss)
I1210 10:18:53.023835 16412 solver.cpp:218] Iteration 67500 (13.8308 iter/s, 7.23023s/100 iters), loss = 0.713226
I1210 10:18:53.023835 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:18:53.023835 16412 solver.cpp:237]     Train net output #1: loss = 0.713226 (* 1 = 0.713226 loss)
I1210 10:18:53.023835 16412 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1210 10:18:58.752276 16412 solver.cpp:218] Iteration 67600 (17.458 iter/s, 5.72804s/100 iters), loss = 0.632793
I1210 10:18:58.752276 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:18:58.752276 16412 solver.cpp:237]     Train net output #1: loss = 0.632793 (* 1 = 0.632793 loss)
I1210 10:18:58.752276 16412 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1210 10:19:04.480943 16412 solver.cpp:218] Iteration 67700 (17.4584 iter/s, 5.72791s/100 iters), loss = 0.591395
I1210 10:19:04.480943 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:19:04.480943 16412 solver.cpp:237]     Train net output #1: loss = 0.591395 (* 1 = 0.591395 loss)
I1210 10:19:04.480943 16412 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1210 10:19:10.162237 16412 solver.cpp:218] Iteration 67800 (17.602 iter/s, 5.68118s/100 iters), loss = 0.779259
I1210 10:19:10.162237 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:19:10.162237 16412 solver.cpp:237]     Train net output #1: loss = 0.779259 (* 1 = 0.779259 loss)
I1210 10:19:10.162237 16412 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1210 10:19:15.883716 16412 solver.cpp:218] Iteration 67900 (17.4789 iter/s, 5.72118s/100 iters), loss = 0.84715
I1210 10:19:15.883716 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:19:15.883716 16412 solver.cpp:237]     Train net output #1: loss = 0.84715 (* 1 = 0.84715 loss)
I1210 10:19:15.883716 16412 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1210 10:19:21.346199  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:19:21.570220 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_68000.caffemodel
I1210 10:19:21.586220 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_68000.solverstate
I1210 10:19:21.590220 16412 solver.cpp:330] Iteration 68000, Testing net (#0)
I1210 10:19:21.590220 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:19:22.961346 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:19:23.014852 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6073
I1210 10:19:23.014852 16412 solver.cpp:397]     Test net output #1: loss = 1.49148 (* 1 = 1.49148 loss)
I1210 10:19:23.070354 16412 solver.cpp:218] Iteration 68000 (13.915 iter/s, 7.1865s/100 iters), loss = 0.628355
I1210 10:19:23.071354 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:19:23.071354 16412 solver.cpp:237]     Train net output #1: loss = 0.628355 (* 1 = 0.628355 loss)
I1210 10:19:23.071354 16412 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1210 10:19:28.743795 16412 solver.cpp:218] Iteration 68100 (17.6277 iter/s, 5.6729s/100 iters), loss = 0.753276
I1210 10:19:28.743795 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:19:28.743795 16412 solver.cpp:237]     Train net output #1: loss = 0.753276 (* 1 = 0.753276 loss)
I1210 10:19:28.743795 16412 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1210 10:19:34.423254 16412 solver.cpp:218] Iteration 68200 (17.6088 iter/s, 5.67899s/100 iters), loss = 0.695133
I1210 10:19:34.423254 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:19:34.424257 16412 solver.cpp:237]     Train net output #1: loss = 0.695133 (* 1 = 0.695133 loss)
I1210 10:19:34.424257 16412 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1210 10:19:40.104153 16412 solver.cpp:218] Iteration 68300 (17.607 iter/s, 5.67955s/100 iters), loss = 0.957452
I1210 10:19:40.104153 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:19:40.104153 16412 solver.cpp:237]     Train net output #1: loss = 0.957452 (* 1 = 0.957452 loss)
I1210 10:19:40.104153 16412 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1210 10:19:45.824079 16412 solver.cpp:218] Iteration 68400 (17.484 iter/s, 5.7195s/100 iters), loss = 0.795599
I1210 10:19:45.824079 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:19:45.824079 16412 solver.cpp:237]     Train net output #1: loss = 0.795599 (* 1 = 0.795599 loss)
I1210 10:19:45.824079 16412 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1210 10:19:51.234712  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:19:51.455726 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_68500.caffemodel
I1210 10:19:51.472725 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_68500.solverstate
I1210 10:19:51.477733 16412 solver.cpp:330] Iteration 68500, Testing net (#0)
I1210 10:19:51.477733 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:19:52.851896 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:19:52.905896 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5816
I1210 10:19:52.905896 16412 solver.cpp:397]     Test net output #1: loss = 1.66963 (* 1 = 1.66963 loss)
I1210 10:19:52.958899 16412 solver.cpp:218] Iteration 68500 (14.0159 iter/s, 7.13474s/100 iters), loss = 0.631158
I1210 10:19:52.958899 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:19:52.958899 16412 solver.cpp:237]     Train net output #1: loss = 0.631158 (* 1 = 0.631158 loss)
I1210 10:19:52.958899 16412 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1210 10:19:58.653334 16412 solver.cpp:218] Iteration 68600 (17.5625 iter/s, 5.69395s/100 iters), loss = 0.683624
I1210 10:19:58.653334 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:19:58.653334 16412 solver.cpp:237]     Train net output #1: loss = 0.683624 (* 1 = 0.683624 loss)
I1210 10:19:58.653334 16412 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1210 10:20:04.365927 16412 solver.cpp:218] Iteration 68700 (17.5067 iter/s, 5.7121s/100 iters), loss = 0.58056
I1210 10:20:04.365927 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:20:04.365927 16412 solver.cpp:237]     Train net output #1: loss = 0.58056 (* 1 = 0.58056 loss)
I1210 10:20:04.365927 16412 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1210 10:20:10.046334 16412 solver.cpp:218] Iteration 68800 (17.6066 iter/s, 5.67968s/100 iters), loss = 0.796899
I1210 10:20:10.046834 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:20:10.046834 16412 solver.cpp:237]     Train net output #1: loss = 0.796899 (* 1 = 0.796899 loss)
I1210 10:20:10.046834 16412 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1210 10:20:15.729902 16412 solver.cpp:218] Iteration 68900 (17.5956 iter/s, 5.68322s/100 iters), loss = 0.760863
I1210 10:20:15.729902 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:20:15.729902 16412 solver.cpp:237]     Train net output #1: loss = 0.760863 (* 1 = 0.760863 loss)
I1210 10:20:15.729902 16412 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1210 10:20:21.131376  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:20:21.354697 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_69000.caffemodel
I1210 10:20:21.368403 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_69000.solverstate
I1210 10:20:21.373399 16412 solver.cpp:330] Iteration 69000, Testing net (#0)
I1210 10:20:21.373399 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:20:22.743338 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:20:22.796418 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6068
I1210 10:20:22.796418 16412 solver.cpp:397]     Test net output #1: loss = 1.48548 (* 1 = 1.48548 loss)
I1210 10:20:22.851444 16412 solver.cpp:218] Iteration 69000 (14.0439 iter/s, 7.12055s/100 iters), loss = 0.647635
I1210 10:20:22.851444 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:20:22.851444 16412 solver.cpp:237]     Train net output #1: loss = 0.647635 (* 1 = 0.647635 loss)
I1210 10:20:22.851444 16412 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1210 10:20:28.532637 16412 solver.cpp:218] Iteration 69100 (17.6008 iter/s, 5.68155s/100 iters), loss = 0.675066
I1210 10:20:28.532637 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:20:28.532637 16412 solver.cpp:237]     Train net output #1: loss = 0.675066 (* 1 = 0.675066 loss)
I1210 10:20:28.532637 16412 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1210 10:20:34.208652 16412 solver.cpp:218] Iteration 69200 (17.6217 iter/s, 5.67482s/100 iters), loss = 0.633445
I1210 10:20:34.208652 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:20:34.208652 16412 solver.cpp:237]     Train net output #1: loss = 0.633445 (* 1 = 0.633445 loss)
I1210 10:20:34.208652 16412 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1210 10:20:39.880272 16412 solver.cpp:218] Iteration 69300 (17.6309 iter/s, 5.67185s/100 iters), loss = 0.839494
I1210 10:20:39.880272 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:20:39.880272 16412 solver.cpp:237]     Train net output #1: loss = 0.839494 (* 1 = 0.839494 loss)
I1210 10:20:39.880272 16412 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1210 10:20:45.560952 16412 solver.cpp:218] Iteration 69400 (17.6068 iter/s, 5.67962s/100 iters), loss = 0.96271
I1210 10:20:45.560952 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:20:45.560952 16412 solver.cpp:237]     Train net output #1: loss = 0.96271 (* 1 = 0.96271 loss)
I1210 10:20:45.560952 16412 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1210 10:20:50.954267  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:20:51.178663 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_69500.caffemodel
I1210 10:20:51.193670 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_69500.solverstate
I1210 10:20:51.198668 16412 solver.cpp:330] Iteration 69500, Testing net (#0)
I1210 10:20:51.198668 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:20:52.566613 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:20:52.620635 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6002
I1210 10:20:52.620635 16412 solver.cpp:397]     Test net output #1: loss = 1.55708 (* 1 = 1.55708 loss)
I1210 10:20:52.674651 16412 solver.cpp:218] Iteration 69500 (14.0584 iter/s, 7.1132s/100 iters), loss = 0.751738
I1210 10:20:52.674651 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:20:52.674651 16412 solver.cpp:237]     Train net output #1: loss = 0.751738 (* 1 = 0.751738 loss)
I1210 10:20:52.674651 16412 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1210 10:20:58.354759 16412 solver.cpp:218] Iteration 69600 (17.6047 iter/s, 5.68029s/100 iters), loss = 0.767909
I1210 10:20:58.354759 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:20:58.354759 16412 solver.cpp:237]     Train net output #1: loss = 0.767909 (* 1 = 0.767909 loss)
I1210 10:20:58.354759 16412 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1210 10:21:04.025626 16412 solver.cpp:218] Iteration 69700 (17.6358 iter/s, 5.67029s/100 iters), loss = 0.632405
I1210 10:21:04.025626 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:21:04.025626 16412 solver.cpp:237]     Train net output #1: loss = 0.632405 (* 1 = 0.632405 loss)
I1210 10:21:04.025626 16412 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1210 10:21:09.700563 16412 solver.cpp:218] Iteration 69800 (17.6233 iter/s, 5.67431s/100 iters), loss = 0.800475
I1210 10:21:09.700563 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:21:09.700563 16412 solver.cpp:237]     Train net output #1: loss = 0.800475 (* 1 = 0.800475 loss)
I1210 10:21:09.700563 16412 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1210 10:21:15.390394 16412 solver.cpp:218] Iteration 69900 (17.5757 iter/s, 5.68969s/100 iters), loss = 0.843813
I1210 10:21:15.390394 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:21:15.390394 16412 solver.cpp:237]     Train net output #1: loss = 0.843813 (* 1 = 0.843813 loss)
I1210 10:21:15.390394 16412 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1210 10:21:20.792940  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:21:21.015372 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_70000.caffemodel
I1210 10:21:21.034370 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_70000.solverstate
I1210 10:21:21.039371 16412 solver.cpp:330] Iteration 70000, Testing net (#0)
I1210 10:21:21.039371 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:21:22.410854 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:21:22.465854 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6002
I1210 10:21:22.465854 16412 solver.cpp:397]     Test net output #1: loss = 1.54051 (* 1 = 1.54051 loss)
I1210 10:21:22.519387 16412 solver.cpp:218] Iteration 70000 (14.0286 iter/s, 7.12831s/100 iters), loss = 0.698375
I1210 10:21:22.519387 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:21:22.519387 16412 solver.cpp:237]     Train net output #1: loss = 0.698375 (* 1 = 0.698375 loss)
I1210 10:21:22.519387 16412 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1210 10:21:28.197124 16412 solver.cpp:218] Iteration 70100 (17.6148 iter/s, 5.67704s/100 iters), loss = 0.659411
I1210 10:21:28.197124 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:21:28.197124 16412 solver.cpp:237]     Train net output #1: loss = 0.659411 (* 1 = 0.659411 loss)
I1210 10:21:28.197124 16412 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1210 10:21:33.874264 16412 solver.cpp:218] Iteration 70200 (17.6149 iter/s, 5.67702s/100 iters), loss = 0.602197
I1210 10:21:33.874264 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:21:33.874264 16412 solver.cpp:237]     Train net output #1: loss = 0.602197 (* 1 = 0.602197 loss)
I1210 10:21:33.874264 16412 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1210 10:21:39.630023 16412 solver.cpp:218] Iteration 70300 (17.3744 iter/s, 5.7556s/100 iters), loss = 0.794981
I1210 10:21:39.630023 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:21:39.630023 16412 solver.cpp:237]     Train net output #1: loss = 0.794981 (* 1 = 0.794981 loss)
I1210 10:21:39.630023 16412 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1210 10:21:45.330514 16412 solver.cpp:218] Iteration 70400 (17.546 iter/s, 5.69929s/100 iters), loss = 0.842012
I1210 10:21:45.330514 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:21:45.330514 16412 solver.cpp:237]     Train net output #1: loss = 0.842012 (* 1 = 0.842012 loss)
I1210 10:21:45.330514 16412 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1210 10:21:50.747963  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:21:50.971529 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_70500.caffemodel
I1210 10:21:50.986538 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_70500.solverstate
I1210 10:21:50.991039 16412 solver.cpp:330] Iteration 70500, Testing net (#0)
I1210 10:21:50.991539 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:21:52.368149 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:21:52.422157 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6116
I1210 10:21:52.422157 16412 solver.cpp:397]     Test net output #1: loss = 1.48177 (* 1 = 1.48177 loss)
I1210 10:21:52.477155 16412 solver.cpp:218] Iteration 70500 (13.992 iter/s, 7.14694s/100 iters), loss = 0.660998
I1210 10:21:52.478157 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:21:52.478157 16412 solver.cpp:237]     Train net output #1: loss = 0.660998 (* 1 = 0.660998 loss)
I1210 10:21:52.478157 16412 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1210 10:21:58.279986 16412 solver.cpp:218] Iteration 70600 (17.2353 iter/s, 5.80205s/100 iters), loss = 0.643059
I1210 10:21:58.279986 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:21:58.279986 16412 solver.cpp:237]     Train net output #1: loss = 0.643059 (* 1 = 0.643059 loss)
I1210 10:21:58.279986 16412 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1210 10:22:04.146024 16412 solver.cpp:218] Iteration 70700 (17.0506 iter/s, 5.8649s/100 iters), loss = 0.660617
I1210 10:22:04.146024 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:22:04.146024 16412 solver.cpp:237]     Train net output #1: loss = 0.660617 (* 1 = 0.660617 loss)
I1210 10:22:04.146024 16412 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1210 10:22:09.857439 16412 solver.cpp:218] Iteration 70800 (17.5093 iter/s, 5.71127s/100 iters), loss = 1.0131
I1210 10:22:09.857439 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:22:09.857439 16412 solver.cpp:237]     Train net output #1: loss = 1.0131 (* 1 = 1.0131 loss)
I1210 10:22:09.857439 16412 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1210 10:22:15.538319 16412 solver.cpp:218] Iteration 70900 (17.6048 iter/s, 5.68026s/100 iters), loss = 0.845816
I1210 10:22:15.538319 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:22:15.538319 16412 solver.cpp:237]     Train net output #1: loss = 0.845816 (* 1 = 0.845816 loss)
I1210 10:22:15.538319 16412 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1210 10:22:21.153358  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:22:21.377372 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_71000.caffemodel
I1210 10:22:21.392370 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_71000.solverstate
I1210 10:22:21.396370 16412 solver.cpp:330] Iteration 71000, Testing net (#0)
I1210 10:22:21.396370 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:22:22.772526 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:22:22.827541 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5758
I1210 10:22:22.827541 16412 solver.cpp:397]     Test net output #1: loss = 1.64472 (* 1 = 1.64472 loss)
I1210 10:22:22.882532 16412 solver.cpp:218] Iteration 71000 (13.6165 iter/s, 7.34401s/100 iters), loss = 0.645907
I1210 10:22:22.882532 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:22:22.882532 16412 solver.cpp:237]     Train net output #1: loss = 0.645907 (* 1 = 0.645907 loss)
I1210 10:22:22.882532 16412 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1210 10:22:28.632093 16412 solver.cpp:218] Iteration 71100 (17.3929 iter/s, 5.74947s/100 iters), loss = 0.679498
I1210 10:22:28.632093 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:22:28.632093 16412 solver.cpp:237]     Train net output #1: loss = 0.679498 (* 1 = 0.679498 loss)
I1210 10:22:28.632093 16412 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1210 10:22:34.388514 16412 solver.cpp:218] Iteration 71200 (17.374 iter/s, 5.75573s/100 iters), loss = 0.532823
I1210 10:22:34.388514 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:22:34.388514 16412 solver.cpp:237]     Train net output #1: loss = 0.532823 (* 1 = 0.532823 loss)
I1210 10:22:34.388514 16412 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1210 10:22:40.059994 16412 solver.cpp:218] Iteration 71300 (17.6354 iter/s, 5.67042s/100 iters), loss = 0.8336
I1210 10:22:40.059994 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:22:40.059994 16412 solver.cpp:237]     Train net output #1: loss = 0.8336 (* 1 = 0.8336 loss)
I1210 10:22:40.059994 16412 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1210 10:22:45.734467 16412 solver.cpp:218] Iteration 71400 (17.6231 iter/s, 5.67438s/100 iters), loss = 0.899958
I1210 10:22:45.734467 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:22:45.734467 16412 solver.cpp:237]     Train net output #1: loss = 0.899958 (* 1 = 0.899958 loss)
I1210 10:22:45.734467 16412 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1210 10:22:51.184736  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:22:51.407776 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_71500.caffemodel
I1210 10:22:51.421283 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_71500.solverstate
I1210 10:22:51.425783 16412 solver.cpp:330] Iteration 71500, Testing net (#0)
I1210 10:22:51.425783 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:22:52.822235 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:22:52.878260 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6155
I1210 10:22:52.878260 16412 solver.cpp:397]     Test net output #1: loss = 1.46602 (* 1 = 1.46602 loss)
I1210 10:22:52.937286 16412 solver.cpp:218] Iteration 71500 (13.8848 iter/s, 7.20213s/100 iters), loss = 0.511422
I1210 10:22:52.937286 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:22:52.937286 16412 solver.cpp:237]     Train net output #1: loss = 0.511422 (* 1 = 0.511422 loss)
I1210 10:22:52.937286 16412 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1210 10:22:58.714633 16412 solver.cpp:218] Iteration 71600 (17.311 iter/s, 5.77667s/100 iters), loss = 0.678303
I1210 10:22:58.714633 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:22:58.714633 16412 solver.cpp:237]     Train net output #1: loss = 0.678303 (* 1 = 0.678303 loss)
I1210 10:22:58.714633 16412 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1210 10:23:04.568470 16412 solver.cpp:218] Iteration 71700 (17.0845 iter/s, 5.85325s/100 iters), loss = 0.592773
I1210 10:23:04.568470 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:23:04.568470 16412 solver.cpp:237]     Train net output #1: loss = 0.592773 (* 1 = 0.592773 loss)
I1210 10:23:04.568470 16412 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1210 10:23:10.305214 16412 solver.cpp:218] Iteration 71800 (17.4318 iter/s, 5.73664s/100 iters), loss = 0.938915
I1210 10:23:10.305214 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:23:10.305214 16412 solver.cpp:237]     Train net output #1: loss = 0.938915 (* 1 = 0.938915 loss)
I1210 10:23:10.305214 16412 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1210 10:23:15.996637 16412 solver.cpp:218] Iteration 71900 (17.5717 iter/s, 5.69098s/100 iters), loss = 0.982156
I1210 10:23:15.996637 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1210 10:23:15.996637 16412 solver.cpp:237]     Train net output #1: loss = 0.982156 (* 1 = 0.982156 loss)
I1210 10:23:15.996637 16412 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1210 10:23:21.513087  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:23:21.737107 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_72000.caffemodel
I1210 10:23:21.754108 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_72000.solverstate
I1210 10:23:21.759109 16412 solver.cpp:330] Iteration 72000, Testing net (#0)
I1210 10:23:21.759109 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:23:23.132211 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:23:23.185210 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5954
I1210 10:23:23.185210 16412 solver.cpp:397]     Test net output #1: loss = 1.57177 (* 1 = 1.57177 loss)
I1210 10:23:23.240212 16412 solver.cpp:218] Iteration 72000 (13.8067 iter/s, 7.24286s/100 iters), loss = 0.585628
I1210 10:23:23.240212 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:23:23.240212 16412 solver.cpp:237]     Train net output #1: loss = 0.585628 (* 1 = 0.585628 loss)
I1210 10:23:23.240212 16412 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1210 10:23:28.940721 16412 solver.cpp:218] Iteration 72100 (17.5416 iter/s, 5.70073s/100 iters), loss = 0.645079
I1210 10:23:28.941721 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:23:28.941721 16412 solver.cpp:237]     Train net output #1: loss = 0.645079 (* 1 = 0.645079 loss)
I1210 10:23:28.941721 16412 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1210 10:23:34.630142 16412 solver.cpp:218] Iteration 72200 (17.579 iter/s, 5.6886s/100 iters), loss = 0.527545
I1210 10:23:34.630142 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:23:34.630142 16412 solver.cpp:237]     Train net output #1: loss = 0.527545 (* 1 = 0.527545 loss)
I1210 10:23:34.630142 16412 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1210 10:23:40.343542 16412 solver.cpp:218] Iteration 72300 (17.5032 iter/s, 5.71324s/100 iters), loss = 0.886722
I1210 10:23:40.343542 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:23:40.343542 16412 solver.cpp:237]     Train net output #1: loss = 0.886722 (* 1 = 0.886722 loss)
I1210 10:23:40.343542 16412 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1210 10:23:46.023056 16412 solver.cpp:218] Iteration 72400 (17.6113 iter/s, 5.67816s/100 iters), loss = 0.811004
I1210 10:23:46.023056 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:23:46.023056 16412 solver.cpp:237]     Train net output #1: loss = 0.811004 (* 1 = 0.811004 loss)
I1210 10:23:46.023056 16412 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1210 10:23:51.428488  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:23:51.652503 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_72500.caffemodel
I1210 10:23:51.667011 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_72500.solverstate
I1210 10:23:51.671510 16412 solver.cpp:330] Iteration 72500, Testing net (#0)
I1210 10:23:51.671510 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:23:53.053647 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:23:53.107653 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6013
I1210 10:23:53.107653 16412 solver.cpp:397]     Test net output #1: loss = 1.57034 (* 1 = 1.57034 loss)
I1210 10:23:53.162156 16412 solver.cpp:218] Iteration 72500 (14.008 iter/s, 7.13877s/100 iters), loss = 0.706309
I1210 10:23:53.162156 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:23:53.162156 16412 solver.cpp:237]     Train net output #1: loss = 0.706309 (* 1 = 0.706309 loss)
I1210 10:23:53.162156 16412 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1210 10:23:58.848125 16412 solver.cpp:218] Iteration 72600 (17.5886 iter/s, 5.6855s/100 iters), loss = 0.755081
I1210 10:23:58.848125 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:23:58.848125 16412 solver.cpp:237]     Train net output #1: loss = 0.755081 (* 1 = 0.755081 loss)
I1210 10:23:58.848125 16412 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1210 10:24:04.531574 16412 solver.cpp:218] Iteration 72700 (17.5957 iter/s, 5.68321s/100 iters), loss = 0.588646
I1210 10:24:04.531574 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:24:04.531574 16412 solver.cpp:237]     Train net output #1: loss = 0.588646 (* 1 = 0.588646 loss)
I1210 10:24:04.531574 16412 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1210 10:24:10.290122 16412 solver.cpp:218] Iteration 72800 (17.3671 iter/s, 5.75802s/100 iters), loss = 0.930294
I1210 10:24:10.290122 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:24:10.290122 16412 solver.cpp:237]     Train net output #1: loss = 0.930294 (* 1 = 0.930294 loss)
I1210 10:24:10.290122 16412 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1210 10:24:16.039786 16412 solver.cpp:218] Iteration 72900 (17.3959 iter/s, 5.74849s/100 iters), loss = 0.811021
I1210 10:24:16.039786 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:24:16.039786 16412 solver.cpp:237]     Train net output #1: loss = 0.811021 (* 1 = 0.811021 loss)
I1210 10:24:16.039786 16412 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1210 10:24:21.504300  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:24:21.739317 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_73000.caffemodel
I1210 10:24:21.753317 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_73000.solverstate
I1210 10:24:21.758317 16412 solver.cpp:330] Iteration 73000, Testing net (#0)
I1210 10:24:21.758317 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:24:23.146512 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:24:23.202522 16412 solver.cpp:397]     Test net output #0: accuracy = 0.591
I1210 10:24:23.202522 16412 solver.cpp:397]     Test net output #1: loss = 1.60932 (* 1 = 1.60932 loss)
I1210 10:24:23.258536 16412 solver.cpp:218] Iteration 73000 (13.8537 iter/s, 7.21831s/100 iters), loss = 0.627908
I1210 10:24:23.258536 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:24:23.258536 16412 solver.cpp:237]     Train net output #1: loss = 0.627908 (* 1 = 0.627908 loss)
I1210 10:24:23.258536 16412 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1210 10:24:29.017025 16412 solver.cpp:218] Iteration 73100 (17.3673 iter/s, 5.75795s/100 iters), loss = 0.678928
I1210 10:24:29.017025 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:24:29.017025 16412 solver.cpp:237]     Train net output #1: loss = 0.678928 (* 1 = 0.678928 loss)
I1210 10:24:29.017025 16412 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1210 10:24:34.723786 16412 solver.cpp:218] Iteration 73200 (17.5224 iter/s, 5.70697s/100 iters), loss = 0.616435
I1210 10:24:34.723786 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:24:34.723786 16412 solver.cpp:237]     Train net output #1: loss = 0.616435 (* 1 = 0.616435 loss)
I1210 10:24:34.723786 16412 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1210 10:24:40.440443 16412 solver.cpp:218] Iteration 73300 (17.4962 iter/s, 5.71553s/100 iters), loss = 0.778305
I1210 10:24:40.440443 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:24:40.440443 16412 solver.cpp:237]     Train net output #1: loss = 0.778305 (* 1 = 0.778305 loss)
I1210 10:24:40.440443 16412 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1210 10:24:46.133939 16412 solver.cpp:218] Iteration 73400 (17.5637 iter/s, 5.69357s/100 iters), loss = 0.90523
I1210 10:24:46.133939 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:24:46.133939 16412 solver.cpp:237]     Train net output #1: loss = 0.90523 (* 1 = 0.90523 loss)
I1210 10:24:46.133939 16412 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1210 10:24:51.600890  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:24:51.824412 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_73500.caffemodel
I1210 10:24:51.841401 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_73500.solverstate
I1210 10:24:51.845402 16412 solver.cpp:330] Iteration 73500, Testing net (#0)
I1210 10:24:51.846403 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:24:53.244518 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:24:53.300524 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6093
I1210 10:24:53.300524 16412 solver.cpp:397]     Test net output #1: loss = 1.5182 (* 1 = 1.5182 loss)
I1210 10:24:53.357539 16412 solver.cpp:218] Iteration 73500 (13.8443 iter/s, 7.22317s/100 iters), loss = 0.590085
I1210 10:24:53.357539 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:24:53.357539 16412 solver.cpp:237]     Train net output #1: loss = 0.590085 (* 1 = 0.590085 loss)
I1210 10:24:53.357539 16412 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1210 10:24:59.105888 16412 solver.cpp:218] Iteration 73600 (17.3983 iter/s, 5.74768s/100 iters), loss = 0.602667
I1210 10:24:59.105888 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:24:59.105888 16412 solver.cpp:237]     Train net output #1: loss = 0.602667 (* 1 = 0.602667 loss)
I1210 10:24:59.105888 16412 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1210 10:25:04.838312 16412 solver.cpp:218] Iteration 73700 (17.4476 iter/s, 5.73144s/100 iters), loss = 0.653457
I1210 10:25:04.838312 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:25:04.838312 16412 solver.cpp:237]     Train net output #1: loss = 0.653457 (* 1 = 0.653457 loss)
I1210 10:25:04.838312 16412 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1210 10:25:10.576815 16412 solver.cpp:218] Iteration 73800 (17.4278 iter/s, 5.73797s/100 iters), loss = 0.824192
I1210 10:25:10.576815 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:25:10.576815 16412 solver.cpp:237]     Train net output #1: loss = 0.824192 (* 1 = 0.824192 loss)
I1210 10:25:10.576815 16412 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1210 10:25:16.333524 16412 solver.cpp:218] Iteration 73900 (17.3705 iter/s, 5.7569s/100 iters), loss = 0.972641
I1210 10:25:16.333524 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:25:16.333524 16412 solver.cpp:237]     Train net output #1: loss = 0.972641 (* 1 = 0.972641 loss)
I1210 10:25:16.333524 16412 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1210 10:25:21.762946  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:25:21.985956 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_74000.caffemodel
I1210 10:25:22.001960 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_74000.solverstate
I1210 10:25:22.006963 16412 solver.cpp:330] Iteration 74000, Testing net (#0)
I1210 10:25:22.006963 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:25:23.377086 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:25:23.432098 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6023
I1210 10:25:23.432098 16412 solver.cpp:397]     Test net output #1: loss = 1.56154 (* 1 = 1.56154 loss)
I1210 10:25:23.487097 16412 solver.cpp:218] Iteration 74000 (13.9812 iter/s, 7.15246s/100 iters), loss = 0.583243
I1210 10:25:23.487097 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:25:23.487097 16412 solver.cpp:237]     Train net output #1: loss = 0.583243 (* 1 = 0.583243 loss)
I1210 10:25:23.487097 16412 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1210 10:25:29.335700 16412 solver.cpp:218] Iteration 74100 (17.0988 iter/s, 5.84837s/100 iters), loss = 0.743554
I1210 10:25:29.335700 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:25:29.335700 16412 solver.cpp:237]     Train net output #1: loss = 0.743554 (* 1 = 0.743554 loss)
I1210 10:25:29.335700 16412 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1210 10:25:35.084727 16412 solver.cpp:218] Iteration 74200 (17.3946 iter/s, 5.74891s/100 iters), loss = 0.580508
I1210 10:25:35.084727 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:25:35.084727 16412 solver.cpp:237]     Train net output #1: loss = 0.580508 (* 1 = 0.580508 loss)
I1210 10:25:35.084727 16412 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1210 10:25:40.807294 16412 solver.cpp:218] Iteration 74300 (17.4779 iter/s, 5.72152s/100 iters), loss = 0.738886
I1210 10:25:40.807294 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:25:40.807294 16412 solver.cpp:237]     Train net output #1: loss = 0.738886 (* 1 = 0.738886 loss)
I1210 10:25:40.807294 16412 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1210 10:25:46.502346 16412 solver.cpp:218] Iteration 74400 (17.5601 iter/s, 5.69473s/100 iters), loss = 0.808807
I1210 10:25:46.502346 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:25:46.502346 16412 solver.cpp:237]     Train net output #1: loss = 0.808807 (* 1 = 0.808807 loss)
I1210 10:25:46.502346 16412 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1210 10:25:51.912591  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:25:52.134621 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_74500.caffemodel
I1210 10:25:52.152622 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_74500.solverstate
I1210 10:25:52.157621 16412 solver.cpp:330] Iteration 74500, Testing net (#0)
I1210 10:25:52.157621 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:25:53.531886 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:25:53.585886 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6166
I1210 10:25:53.585886 16412 solver.cpp:397]     Test net output #1: loss = 1.46348 (* 1 = 1.46348 loss)
I1210 10:25:53.639890 16412 solver.cpp:218] Iteration 74500 (14.0118 iter/s, 7.13683s/100 iters), loss = 0.58413
I1210 10:25:53.639890 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:25:53.639890 16412 solver.cpp:237]     Train net output #1: loss = 0.58413 (* 1 = 0.58413 loss)
I1210 10:25:53.639890 16412 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1210 10:25:59.402823 16412 solver.cpp:218] Iteration 74600 (17.3532 iter/s, 5.76262s/100 iters), loss = 0.67657
I1210 10:25:59.402823 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:25:59.402823 16412 solver.cpp:237]     Train net output #1: loss = 0.67657 (* 1 = 0.67657 loss)
I1210 10:25:59.402823 16412 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1210 10:26:05.142717 16412 solver.cpp:218] Iteration 74700 (17.4209 iter/s, 5.74023s/100 iters), loss = 0.599616
I1210 10:26:05.142717 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:26:05.142717 16412 solver.cpp:237]     Train net output #1: loss = 0.599616 (* 1 = 0.599616 loss)
I1210 10:26:05.142717 16412 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1210 10:26:10.832151 16412 solver.cpp:218] Iteration 74800 (17.5801 iter/s, 5.68825s/100 iters), loss = 0.765161
I1210 10:26:10.832151 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:26:10.832151 16412 solver.cpp:237]     Train net output #1: loss = 0.765161 (* 1 = 0.765161 loss)
I1210 10:26:10.832151 16412 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1210 10:26:16.554641 16412 solver.cpp:218] Iteration 74900 (17.4748 iter/s, 5.72253s/100 iters), loss = 0.90639
I1210 10:26:16.554641 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:26:16.554641 16412 solver.cpp:237]     Train net output #1: loss = 0.90639 (* 1 = 0.90639 loss)
I1210 10:26:16.554641 16412 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1210 10:26:21.977035  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:26:22.199059 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_75000.caffemodel
I1210 10:26:22.214054 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_75000.solverstate
I1210 10:26:22.220057 16412 solver.cpp:330] Iteration 75000, Testing net (#0)
I1210 10:26:22.220057 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:26:23.596168 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:26:23.650167 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6115
I1210 10:26:23.650167 16412 solver.cpp:397]     Test net output #1: loss = 1.51834 (* 1 = 1.51834 loss)
I1210 10:26:23.704172 16412 solver.cpp:218] Iteration 75000 (13.9889 iter/s, 7.14855s/100 iters), loss = 0.701316
I1210 10:26:23.704172 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:26:23.704172 16412 solver.cpp:237]     Train net output #1: loss = 0.701316 (* 1 = 0.701316 loss)
I1210 10:26:23.704172 16412 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1210 10:26:29.410682 16412 solver.cpp:218] Iteration 75100 (17.5239 iter/s, 5.70649s/100 iters), loss = 0.649331
I1210 10:26:29.410682 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:26:29.410682 16412 solver.cpp:237]     Train net output #1: loss = 0.649331 (* 1 = 0.649331 loss)
I1210 10:26:29.410682 16412 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1210 10:26:35.133139 16412 solver.cpp:218] Iteration 75200 (17.479 iter/s, 5.72115s/100 iters), loss = 0.636384
I1210 10:26:35.133139 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:26:35.133139 16412 solver.cpp:237]     Train net output #1: loss = 0.636384 (* 1 = 0.636384 loss)
I1210 10:26:35.133139 16412 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1210 10:26:40.976052 16412 solver.cpp:218] Iteration 75300 (17.1153 iter/s, 5.84273s/100 iters), loss = 0.830194
I1210 10:26:40.976052 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:26:40.976052 16412 solver.cpp:237]     Train net output #1: loss = 0.830194 (* 1 = 0.830194 loss)
I1210 10:26:40.976052 16412 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1210 10:26:46.765064 16412 solver.cpp:218] Iteration 75400 (17.2759 iter/s, 5.78842s/100 iters), loss = 0.810484
I1210 10:26:46.765064 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:26:46.765064 16412 solver.cpp:237]     Train net output #1: loss = 0.810484 (* 1 = 0.810484 loss)
I1210 10:26:46.765064 16412 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1210 10:26:52.203480  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:26:52.429489 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_75500.caffemodel
I1210 10:26:52.443490 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_75500.solverstate
I1210 10:26:52.447489 16412 solver.cpp:330] Iteration 75500, Testing net (#0)
I1210 10:26:52.447489 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:26:53.821583 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:26:53.875087 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6043
I1210 10:26:53.875087 16412 solver.cpp:397]     Test net output #1: loss = 1.53443 (* 1 = 1.53443 loss)
I1210 10:26:53.928592 16412 solver.cpp:218] Iteration 75500 (13.9606 iter/s, 7.16302s/100 iters), loss = 0.617698
I1210 10:26:53.928592 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:26:53.928592 16412 solver.cpp:237]     Train net output #1: loss = 0.617698 (* 1 = 0.617698 loss)
I1210 10:26:53.928592 16412 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1210 10:26:59.667017 16412 solver.cpp:218] Iteration 75600 (17.4271 iter/s, 5.7382s/100 iters), loss = 0.680617
I1210 10:26:59.667017 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:26:59.667017 16412 solver.cpp:237]     Train net output #1: loss = 0.680617 (* 1 = 0.680617 loss)
I1210 10:26:59.667017 16412 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1210 10:27:05.356410 16412 solver.cpp:218] Iteration 75700 (17.5764 iter/s, 5.68945s/100 iters), loss = 0.586608
I1210 10:27:05.357411 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:27:05.357411 16412 solver.cpp:237]     Train net output #1: loss = 0.586608 (* 1 = 0.586608 loss)
I1210 10:27:05.357411 16412 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1210 10:27:11.074936 16412 solver.cpp:218] Iteration 75800 (17.4902 iter/s, 5.71747s/100 iters), loss = 0.924214
I1210 10:27:11.074936 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:27:11.074936 16412 solver.cpp:237]     Train net output #1: loss = 0.924214 (* 1 = 0.924214 loss)
I1210 10:27:11.074936 16412 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1210 10:27:16.800410 16412 solver.cpp:218] Iteration 75900 (17.4673 iter/s, 5.72499s/100 iters), loss = 0.798453
I1210 10:27:16.800410 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:27:16.800410 16412 solver.cpp:237]     Train net output #1: loss = 0.798453 (* 1 = 0.798453 loss)
I1210 10:27:16.800410 16412 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1210 10:27:22.291862  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:27:22.516872 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_76000.caffemodel
I1210 10:27:22.531873 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_76000.solverstate
I1210 10:27:22.536873 16412 solver.cpp:330] Iteration 76000, Testing net (#0)
I1210 10:27:22.536873 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:27:23.935034 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:27:23.987037 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6029
I1210 10:27:23.987037 16412 solver.cpp:397]     Test net output #1: loss = 1.57729 (* 1 = 1.57729 loss)
I1210 10:27:24.041041 16412 solver.cpp:218] Iteration 76000 (13.8119 iter/s, 7.24011s/100 iters), loss = 0.651622
I1210 10:27:24.041041 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:27:24.041041 16412 solver.cpp:237]     Train net output #1: loss = 0.651622 (* 1 = 0.651622 loss)
I1210 10:27:24.041041 16412 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1210 10:27:29.793530 16412 solver.cpp:218] Iteration 76100 (17.3834 iter/s, 5.75262s/100 iters), loss = 0.673618
I1210 10:27:29.793530 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:27:29.793530 16412 solver.cpp:237]     Train net output #1: loss = 0.673618 (* 1 = 0.673618 loss)
I1210 10:27:29.794531 16412 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1210 10:27:35.479960 16412 solver.cpp:218] Iteration 76200 (17.5889 iter/s, 5.68541s/100 iters), loss = 0.557139
I1210 10:27:35.480469 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:27:35.480469 16412 solver.cpp:237]     Train net output #1: loss = 0.557139 (* 1 = 0.557139 loss)
I1210 10:27:35.480469 16412 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1210 10:27:41.158390 16412 solver.cpp:218] Iteration 76300 (17.6114 iter/s, 5.67813s/100 iters), loss = 0.769642
I1210 10:27:41.158390 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:27:41.158390 16412 solver.cpp:237]     Train net output #1: loss = 0.769642 (* 1 = 0.769642 loss)
I1210 10:27:41.158390 16412 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1210 10:27:46.832768 16412 solver.cpp:218] Iteration 76400 (17.6264 iter/s, 5.6733s/100 iters), loss = 0.837884
I1210 10:27:46.832768 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:27:46.832768 16412 solver.cpp:237]     Train net output #1: loss = 0.837884 (* 1 = 0.837884 loss)
I1210 10:27:46.832768 16412 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1210 10:27:52.226191  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:27:52.450199 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_76500.caffemodel
I1210 10:27:52.464200 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_76500.solverstate
I1210 10:27:52.469199 16412 solver.cpp:330] Iteration 76500, Testing net (#0)
I1210 10:27:52.469199 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:27:53.840342 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:27:53.894346 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6269
I1210 10:27:53.895347 16412 solver.cpp:397]     Test net output #1: loss = 1.43723 (* 1 = 1.43723 loss)
I1210 10:27:53.948345 16412 solver.cpp:218] Iteration 76500 (14.0528 iter/s, 7.11602s/100 iters), loss = 0.624316
I1210 10:27:53.949347 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:27:53.949347 16412 solver.cpp:237]     Train net output #1: loss = 0.624316 (* 1 = 0.624316 loss)
I1210 10:27:53.949347 16412 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1210 10:27:59.669805 16412 solver.cpp:218] Iteration 76600 (17.4798 iter/s, 5.7209s/100 iters), loss = 0.583503
I1210 10:27:59.669805 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:27:59.669805 16412 solver.cpp:237]     Train net output #1: loss = 0.583503 (* 1 = 0.583503 loss)
I1210 10:27:59.669805 16412 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1210 10:28:05.400257 16412 solver.cpp:218] Iteration 76700 (17.4522 iter/s, 5.72994s/100 iters), loss = 0.529371
I1210 10:28:05.400257 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:28:05.400257 16412 solver.cpp:237]     Train net output #1: loss = 0.529371 (* 1 = 0.529371 loss)
I1210 10:28:05.400257 16412 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1210 10:28:11.128757 16412 solver.cpp:218] Iteration 76800 (17.4586 iter/s, 5.72783s/100 iters), loss = 0.735367
I1210 10:28:11.128757 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:28:11.128757 16412 solver.cpp:237]     Train net output #1: loss = 0.735367 (* 1 = 0.735367 loss)
I1210 10:28:11.128757 16412 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1210 10:28:16.834239 16412 solver.cpp:218] Iteration 76900 (17.5293 iter/s, 5.70474s/100 iters), loss = 0.920617
I1210 10:28:16.834239 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1210 10:28:16.834239 16412 solver.cpp:237]     Train net output #1: loss = 0.920617 (* 1 = 0.920617 loss)
I1210 10:28:16.834239 16412 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1210 10:28:22.252697  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:28:22.476728 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_77000.caffemodel
I1210 10:28:22.491729 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_77000.solverstate
I1210 10:28:22.496729 16412 solver.cpp:330] Iteration 77000, Testing net (#0)
I1210 10:28:22.496729 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:28:23.871883 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:28:23.925894 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6037
I1210 10:28:23.925894 16412 solver.cpp:397]     Test net output #1: loss = 1.55578 (* 1 = 1.55578 loss)
I1210 10:28:23.979898 16412 solver.cpp:218] Iteration 77000 (13.9945 iter/s, 7.14564s/100 iters), loss = 0.645499
I1210 10:28:23.979898 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:28:23.979898 16412 solver.cpp:237]     Train net output #1: loss = 0.645499 (* 1 = 0.645499 loss)
I1210 10:28:23.979898 16412 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1210 10:28:29.658541 16412 solver.cpp:218] Iteration 77100 (17.6126 iter/s, 5.67775s/100 iters), loss = 0.663258
I1210 10:28:29.658541 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:28:29.658541 16412 solver.cpp:237]     Train net output #1: loss = 0.663258 (* 1 = 0.663258 loss)
I1210 10:28:29.658541 16412 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1210 10:28:35.369061 16412 solver.cpp:218] Iteration 77200 (17.5112 iter/s, 5.71062s/100 iters), loss = 0.599901
I1210 10:28:35.369061 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:28:35.369061 16412 solver.cpp:237]     Train net output #1: loss = 0.599901 (* 1 = 0.599901 loss)
I1210 10:28:35.369061 16412 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1210 10:28:41.054883 16412 solver.cpp:218] Iteration 77300 (17.5901 iter/s, 5.68501s/100 iters), loss = 0.837733
I1210 10:28:41.054883 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:28:41.054883 16412 solver.cpp:237]     Train net output #1: loss = 0.837733 (* 1 = 0.837733 loss)
I1210 10:28:41.054883 16412 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1210 10:28:46.793558 16412 solver.cpp:218] Iteration 77400 (17.4271 iter/s, 5.7382s/100 iters), loss = 0.909548
I1210 10:28:46.793558 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:28:46.793558 16412 solver.cpp:237]     Train net output #1: loss = 0.909548 (* 1 = 0.909548 loss)
I1210 10:28:46.793558 16412 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1210 10:28:52.241968  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:28:52.467156 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_77500.caffemodel
I1210 10:28:52.481156 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_77500.solverstate
I1210 10:28:52.485170 16412 solver.cpp:330] Iteration 77500, Testing net (#0)
I1210 10:28:52.485170 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:28:53.856457 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:28:53.910962 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6065
I1210 10:28:53.910962 16412 solver.cpp:397]     Test net output #1: loss = 1.52113 (* 1 = 1.52113 loss)
I1210 10:28:53.966658 16412 solver.cpp:218] Iteration 77500 (13.9417 iter/s, 7.17274s/100 iters), loss = 0.535426
I1210 10:28:53.966658 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:28:53.966658 16412 solver.cpp:237]     Train net output #1: loss = 0.535426 (* 1 = 0.535426 loss)
I1210 10:28:53.966658 16412 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1210 10:28:59.752962 16412 solver.cpp:218] Iteration 77600 (17.2842 iter/s, 5.78564s/100 iters), loss = 0.643024
I1210 10:28:59.752962 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:28:59.752962 16412 solver.cpp:237]     Train net output #1: loss = 0.643024 (* 1 = 0.643024 loss)
I1210 10:28:59.752962 16412 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1210 10:29:05.513062 16412 solver.cpp:218] Iteration 77700 (17.3624 iter/s, 5.75958s/100 iters), loss = 0.597942
I1210 10:29:05.513062 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:29:05.513062 16412 solver.cpp:237]     Train net output #1: loss = 0.597942 (* 1 = 0.597942 loss)
I1210 10:29:05.513062 16412 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1210 10:29:11.178680 16412 solver.cpp:218] Iteration 77800 (17.652 iter/s, 5.66508s/100 iters), loss = 0.691282
I1210 10:29:11.178680 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:29:11.178680 16412 solver.cpp:237]     Train net output #1: loss = 0.691282 (* 1 = 0.691282 loss)
I1210 10:29:11.178680 16412 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1210 10:29:16.843214 16412 solver.cpp:218] Iteration 77900 (17.6532 iter/s, 5.66471s/100 iters), loss = 0.905734
I1210 10:29:16.843214 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:29:16.843214 16412 solver.cpp:237]     Train net output #1: loss = 0.905734 (* 1 = 0.905734 loss)
I1210 10:29:16.843214 16412 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1210 10:29:22.263731  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:29:22.487746 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_78000.caffemodel
I1210 10:29:22.502744 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_78000.solverstate
I1210 10:29:22.506744 16412 solver.cpp:330] Iteration 78000, Testing net (#0)
I1210 10:29:22.506744 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:29:23.875882 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:29:23.929885 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5536
I1210 10:29:23.929885 16412 solver.cpp:397]     Test net output #1: loss = 1.93929 (* 1 = 1.93929 loss)
I1210 10:29:23.983886 16412 solver.cpp:218] Iteration 78000 (14.0062 iter/s, 7.13972s/100 iters), loss = 0.57564
I1210 10:29:23.983886 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:29:23.983886 16412 solver.cpp:237]     Train net output #1: loss = 0.57564 (* 1 = 0.57564 loss)
I1210 10:29:23.983886 16412 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1210 10:29:29.701345 16412 solver.cpp:218] Iteration 78100 (17.4911 iter/s, 5.71719s/100 iters), loss = 0.574047
I1210 10:29:29.701345 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:29:29.701345 16412 solver.cpp:237]     Train net output #1: loss = 0.574047 (* 1 = 0.574047 loss)
I1210 10:29:29.701345 16412 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1210 10:29:35.503866 16412 solver.cpp:218] Iteration 78200 (17.2356 iter/s, 5.80195s/100 iters), loss = 0.538695
I1210 10:29:35.503866 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:29:35.503866 16412 solver.cpp:237]     Train net output #1: loss = 0.538695 (* 1 = 0.538695 loss)
I1210 10:29:35.503866 16412 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1210 10:29:41.262382 16412 solver.cpp:218] Iteration 78300 (17.3675 iter/s, 5.75789s/100 iters), loss = 0.843586
I1210 10:29:41.262382 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:29:41.262382 16412 solver.cpp:237]     Train net output #1: loss = 0.843586 (* 1 = 0.843586 loss)
I1210 10:29:41.262382 16412 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1210 10:29:46.988922 16412 solver.cpp:218] Iteration 78400 (17.4618 iter/s, 5.72678s/100 iters), loss = 0.825054
I1210 10:29:46.988922 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:29:46.988922 16412 solver.cpp:237]     Train net output #1: loss = 0.825054 (* 1 = 0.825054 loss)
I1210 10:29:46.988922 16412 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1210 10:29:52.524507  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:29:52.752537 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_78500.caffemodel
I1210 10:29:52.767536 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_78500.solverstate
I1210 10:29:52.771536 16412 solver.cpp:330] Iteration 78500, Testing net (#0)
I1210 10:29:52.771536 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:29:54.143681 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:29:54.196678 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6134
I1210 10:29:54.196678 16412 solver.cpp:397]     Test net output #1: loss = 1.51553 (* 1 = 1.51553 loss)
I1210 10:29:54.252698 16412 solver.cpp:218] Iteration 78500 (13.7683 iter/s, 7.26307s/100 iters), loss = 0.579865
I1210 10:29:54.252698 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:29:54.252698 16412 solver.cpp:237]     Train net output #1: loss = 0.579865 (* 1 = 0.579865 loss)
I1210 10:29:54.252698 16412 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1210 10:29:59.941650 16412 solver.cpp:218] Iteration 78600 (17.5808 iter/s, 5.68803s/100 iters), loss = 0.672589
I1210 10:29:59.941650 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:29:59.941650 16412 solver.cpp:237]     Train net output #1: loss = 0.672589 (* 1 = 0.672589 loss)
I1210 10:29:59.941650 16412 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1210 10:30:05.668730 16412 solver.cpp:218] Iteration 78700 (17.4617 iter/s, 5.72681s/100 iters), loss = 0.55117
I1210 10:30:05.668730 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:30:05.668730 16412 solver.cpp:237]     Train net output #1: loss = 0.55117 (* 1 = 0.55117 loss)
I1210 10:30:05.668730 16412 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1210 10:30:11.343227 16412 solver.cpp:218] Iteration 78800 (17.6233 iter/s, 5.67432s/100 iters), loss = 0.770697
I1210 10:30:11.343227 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:30:11.343227 16412 solver.cpp:237]     Train net output #1: loss = 0.770697 (* 1 = 0.770697 loss)
I1210 10:30:11.343227 16412 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1210 10:30:17.038832 16412 solver.cpp:218] Iteration 78900 (17.5596 iter/s, 5.69489s/100 iters), loss = 0.75559
I1210 10:30:17.038832 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:30:17.038832 16412 solver.cpp:237]     Train net output #1: loss = 0.75559 (* 1 = 0.75559 loss)
I1210 10:30:17.038832 16412 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1210 10:30:22.459270  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:30:22.686282 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_79000.caffemodel
I1210 10:30:22.700785 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_79000.solverstate
I1210 10:30:22.705286 16412 solver.cpp:330] Iteration 79000, Testing net (#0)
I1210 10:30:22.705286 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:30:24.086655 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:30:24.139664 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5858
I1210 10:30:24.139664 16412 solver.cpp:397]     Test net output #1: loss = 1.66381 (* 1 = 1.66381 loss)
I1210 10:30:24.196663 16412 solver.cpp:218] Iteration 79000 (13.9721 iter/s, 7.15712s/100 iters), loss = 0.560723
I1210 10:30:24.196663 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:30:24.196663 16412 solver.cpp:237]     Train net output #1: loss = 0.560723 (* 1 = 0.560723 loss)
I1210 10:30:24.196663 16412 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1210 10:30:29.909636 16412 solver.cpp:218] Iteration 79100 (17.5068 iter/s, 5.71205s/100 iters), loss = 0.697564
I1210 10:30:29.909636 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:30:29.909636 16412 solver.cpp:237]     Train net output #1: loss = 0.697564 (* 1 = 0.697564 loss)
I1210 10:30:29.909636 16412 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1210 10:30:35.580554 16412 solver.cpp:218] Iteration 79200 (17.6332 iter/s, 5.67112s/100 iters), loss = 0.713383
I1210 10:30:35.580554 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:30:35.580554 16412 solver.cpp:237]     Train net output #1: loss = 0.713383 (* 1 = 0.713383 loss)
I1210 10:30:35.580554 16412 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1210 10:30:41.253983 16412 solver.cpp:218] Iteration 79300 (17.629 iter/s, 5.67247s/100 iters), loss = 0.807593
I1210 10:30:41.253983 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:30:41.253983 16412 solver.cpp:237]     Train net output #1: loss = 0.807593 (* 1 = 0.807593 loss)
I1210 10:30:41.253983 16412 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1210 10:30:46.927415 16412 solver.cpp:218] Iteration 79400 (17.6263 iter/s, 5.67334s/100 iters), loss = 0.803851
I1210 10:30:46.927415 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:30:46.927415 16412 solver.cpp:237]     Train net output #1: loss = 0.803851 (* 1 = 0.803851 loss)
I1210 10:30:46.927415 16412 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1210 10:30:52.398924  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:30:52.620945 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_79500.caffemodel
I1210 10:30:52.633945 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_79500.solverstate
I1210 10:30:52.638947 16412 solver.cpp:330] Iteration 79500, Testing net (#0)
I1210 10:30:52.638947 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:30:54.019100 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:30:54.073101 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6041
I1210 10:30:54.073101 16412 solver.cpp:397]     Test net output #1: loss = 1.55383 (* 1 = 1.55383 loss)
I1210 10:30:54.129107 16412 solver.cpp:218] Iteration 79500 (13.8873 iter/s, 7.20082s/100 iters), loss = 0.643854
I1210 10:30:54.129107 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:30:54.129107 16412 solver.cpp:237]     Train net output #1: loss = 0.643854 (* 1 = 0.643854 loss)
I1210 10:30:54.129107 16412 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1210 10:30:59.849671 16412 solver.cpp:218] Iteration 79600 (17.4806 iter/s, 5.72062s/100 iters), loss = 0.722723
I1210 10:30:59.849671 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:30:59.849671 16412 solver.cpp:237]     Train net output #1: loss = 0.722723 (* 1 = 0.722723 loss)
I1210 10:30:59.849671 16412 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1210 10:31:05.578213 16412 solver.cpp:218] Iteration 79700 (17.4593 iter/s, 5.7276s/100 iters), loss = 0.544794
I1210 10:31:05.578213 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:31:05.578213 16412 solver.cpp:237]     Train net output #1: loss = 0.544794 (* 1 = 0.544794 loss)
I1210 10:31:05.578213 16412 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1210 10:31:11.296893 16412 solver.cpp:218] Iteration 79800 (17.4866 iter/s, 5.71867s/100 iters), loss = 0.875809
I1210 10:31:11.296893 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:31:11.296893 16412 solver.cpp:237]     Train net output #1: loss = 0.875809 (* 1 = 0.875809 loss)
I1210 10:31:11.296893 16412 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1210 10:31:17.013350 16412 solver.cpp:218] Iteration 79900 (17.4943 iter/s, 5.71613s/100 iters), loss = 0.843704
I1210 10:31:17.013350 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:31:17.013350 16412 solver.cpp:237]     Train net output #1: loss = 0.843704 (* 1 = 0.843704 loss)
I1210 10:31:17.013350 16412 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1210 10:31:22.554828  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:31:22.779851 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_80000.caffemodel
I1210 10:31:22.794852 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_80000.solverstate
I1210 10:31:22.799852 16412 solver.cpp:330] Iteration 80000, Testing net (#0)
I1210 10:31:22.799852 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:31:24.171972 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:31:24.226475 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6101
I1210 10:31:24.226475 16412 solver.cpp:397]     Test net output #1: loss = 1.50882 (* 1 = 1.50882 loss)
I1210 10:31:24.281976 16412 solver.cpp:218] Iteration 80000 (13.758 iter/s, 7.2685s/100 iters), loss = 0.649074
I1210 10:31:24.281976 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:31:24.281976 16412 solver.cpp:237]     Train net output #1: loss = 0.649074 (* 1 = 0.649074 loss)
I1210 10:31:24.281976 16412 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1210 10:31:29.999440 16412 solver.cpp:218] Iteration 80100 (17.4931 iter/s, 5.71652s/100 iters), loss = 0.654867
I1210 10:31:29.999440 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:31:29.999440 16412 solver.cpp:237]     Train net output #1: loss = 0.654867 (* 1 = 0.654867 loss)
I1210 10:31:29.999440 16412 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1210 10:31:35.760987 16412 solver.cpp:218] Iteration 80200 (17.358 iter/s, 5.76103s/100 iters), loss = 0.599534
I1210 10:31:35.760987 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:31:35.760987 16412 solver.cpp:237]     Train net output #1: loss = 0.599534 (* 1 = 0.599534 loss)
I1210 10:31:35.760987 16412 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1210 10:31:41.518468 16412 solver.cpp:218] Iteration 80300 (17.3692 iter/s, 5.75731s/100 iters), loss = 0.840429
I1210 10:31:41.518468 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:31:41.518468 16412 solver.cpp:237]     Train net output #1: loss = 0.840429 (* 1 = 0.840429 loss)
I1210 10:31:41.518468 16412 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1210 10:31:47.238029 16412 solver.cpp:218] Iteration 80400 (17.4863 iter/s, 5.71875s/100 iters), loss = 0.807729
I1210 10:31:47.238528 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:31:47.238528 16412 solver.cpp:237]     Train net output #1: loss = 0.807729 (* 1 = 0.807729 loss)
I1210 10:31:47.238528 16412 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1210 10:31:52.688590  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:31:52.910600 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_80500.caffemodel
I1210 10:31:52.924600 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_80500.solverstate
I1210 10:31:52.931110 16412 solver.cpp:330] Iteration 80500, Testing net (#0)
I1210 10:31:52.931110 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:31:54.303720 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:31:54.357726 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5978
I1210 10:31:54.357726 16412 solver.cpp:397]     Test net output #1: loss = 1.60162 (* 1 = 1.60162 loss)
I1210 10:31:54.411725 16412 solver.cpp:218] Iteration 80500 (13.9407 iter/s, 7.17325s/100 iters), loss = 0.690485
I1210 10:31:54.411725 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:31:54.411725 16412 solver.cpp:237]     Train net output #1: loss = 0.690485 (* 1 = 0.690485 loss)
I1210 10:31:54.411725 16412 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1210 10:32:00.165184 16412 solver.cpp:218] Iteration 80600 (17.3835 iter/s, 5.75257s/100 iters), loss = 0.692287
I1210 10:32:00.165184 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:32:00.165184 16412 solver.cpp:237]     Train net output #1: loss = 0.692287 (* 1 = 0.692287 loss)
I1210 10:32:00.165184 16412 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1210 10:32:05.897769 16412 solver.cpp:218] Iteration 80700 (17.4436 iter/s, 5.73277s/100 iters), loss = 0.543423
I1210 10:32:05.897769 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:32:05.897769 16412 solver.cpp:237]     Train net output #1: loss = 0.543423 (* 1 = 0.543423 loss)
I1210 10:32:05.897769 16412 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1210 10:32:11.631816 16412 solver.cpp:218] Iteration 80800 (17.4418 iter/s, 5.73336s/100 iters), loss = 0.800692
I1210 10:32:11.632316 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:32:11.632316 16412 solver.cpp:237]     Train net output #1: loss = 0.800692 (* 1 = 0.800692 loss)
I1210 10:32:11.632316 16412 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1210 10:32:17.337252 16412 solver.cpp:218] Iteration 80900 (17.5302 iter/s, 5.70443s/100 iters), loss = 0.826439
I1210 10:32:17.337252 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:32:17.337252 16412 solver.cpp:237]     Train net output #1: loss = 0.826439 (* 1 = 0.826439 loss)
I1210 10:32:17.337252 16412 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1210 10:32:22.756067  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:32:22.981081 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_81000.caffemodel
I1210 10:32:22.995081 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_81000.solverstate
I1210 10:32:23.000082 16412 solver.cpp:330] Iteration 81000, Testing net (#0)
I1210 10:32:23.000082 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:32:24.372222 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:32:24.425220 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5928
I1210 10:32:24.425220 16412 solver.cpp:397]     Test net output #1: loss = 1.59629 (* 1 = 1.59629 loss)
I1210 10:32:24.479228 16412 solver.cpp:218] Iteration 81000 (14.0025 iter/s, 7.14156s/100 iters), loss = 0.783608
I1210 10:32:24.479228 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:32:24.479228 16412 solver.cpp:237]     Train net output #1: loss = 0.783608 (* 1 = 0.783608 loss)
I1210 10:32:24.479228 16412 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1210 10:32:30.172047 16412 solver.cpp:218] Iteration 81100 (17.568 iter/s, 5.69217s/100 iters), loss = 0.664952
I1210 10:32:30.172047 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:32:30.172047 16412 solver.cpp:237]     Train net output #1: loss = 0.664952 (* 1 = 0.664952 loss)
I1210 10:32:30.172047 16412 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1210 10:32:35.905058 16412 solver.cpp:218] Iteration 81200 (17.4448 iter/s, 5.73236s/100 iters), loss = 0.488732
I1210 10:32:35.905058 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:32:35.905058 16412 solver.cpp:237]     Train net output #1: loss = 0.488732 (* 1 = 0.488732 loss)
I1210 10:32:35.905058 16412 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1210 10:32:41.656666 16412 solver.cpp:218] Iteration 81300 (17.3865 iter/s, 5.75157s/100 iters), loss = 0.834239
I1210 10:32:41.656666 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:32:41.656666 16412 solver.cpp:237]     Train net output #1: loss = 0.834239 (* 1 = 0.834239 loss)
I1210 10:32:41.656666 16412 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1210 10:32:47.396086 16412 solver.cpp:218] Iteration 81400 (17.426 iter/s, 5.73856s/100 iters), loss = 0.762754
I1210 10:32:47.396086 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:32:47.396086 16412 solver.cpp:237]     Train net output #1: loss = 0.762754 (* 1 = 0.762754 loss)
I1210 10:32:47.396086 16412 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1210 10:32:52.859380  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:32:53.084969 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_81500.caffemodel
I1210 10:32:53.098963 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_81500.solverstate
I1210 10:32:53.102963 16412 solver.cpp:330] Iteration 81500, Testing net (#0)
I1210 10:32:53.102963 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:32:54.477054 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:32:54.531070 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6197
I1210 10:32:54.531070 16412 solver.cpp:397]     Test net output #1: loss = 1.47679 (* 1 = 1.47679 loss)
I1210 10:32:54.586073 16412 solver.cpp:218] Iteration 81500 (13.9086 iter/s, 7.18977s/100 iters), loss = 0.599837
I1210 10:32:54.586073 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:32:54.586073 16412 solver.cpp:237]     Train net output #1: loss = 0.599837 (* 1 = 0.599837 loss)
I1210 10:32:54.586073 16412 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1210 10:33:00.307757 16412 solver.cpp:218] Iteration 81600 (17.4793 iter/s, 5.72106s/100 iters), loss = 0.745649
I1210 10:33:00.307757 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:33:00.307757 16412 solver.cpp:237]     Train net output #1: loss = 0.745649 (* 1 = 0.745649 loss)
I1210 10:33:00.307757 16412 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1210 10:33:05.992470 16412 solver.cpp:218] Iteration 81700 (17.5914 iter/s, 5.68459s/100 iters), loss = 0.566335
I1210 10:33:05.992470 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:33:05.992470 16412 solver.cpp:237]     Train net output #1: loss = 0.566335 (* 1 = 0.566335 loss)
I1210 10:33:05.992470 16412 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1210 10:33:11.733224 16412 solver.cpp:218] Iteration 81800 (17.4212 iter/s, 5.74014s/100 iters), loss = 0.738938
I1210 10:33:11.733224 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:33:11.733224 16412 solver.cpp:237]     Train net output #1: loss = 0.738938 (* 1 = 0.738938 loss)
I1210 10:33:11.733224 16412 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1210 10:33:17.526830 16412 solver.cpp:218] Iteration 81900 (17.2625 iter/s, 5.79289s/100 iters), loss = 0.629205
I1210 10:33:17.526830 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:33:17.526830 16412 solver.cpp:237]     Train net output #1: loss = 0.629205 (* 1 = 0.629205 loss)
I1210 10:33:17.526830 16412 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1210 10:33:23.005419  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:33:23.230685 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_82000.caffemodel
I1210 10:33:23.245687 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_82000.solverstate
I1210 10:33:23.249686 16412 solver.cpp:330] Iteration 82000, Testing net (#0)
I1210 10:33:23.249686 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:33:24.630380 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:33:24.685387 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6112
I1210 10:33:24.685387 16412 solver.cpp:397]     Test net output #1: loss = 1.49784 (* 1 = 1.49784 loss)
I1210 10:33:24.739385 16412 solver.cpp:218] Iteration 82000 (13.864 iter/s, 7.21294s/100 iters), loss = 0.585218
I1210 10:33:24.739385 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:33:24.739385 16412 solver.cpp:237]     Train net output #1: loss = 0.585218 (* 1 = 0.585218 loss)
I1210 10:33:24.739385 16412 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1210 10:33:30.452747 16412 solver.cpp:218] Iteration 82100 (17.5057 iter/s, 5.71241s/100 iters), loss = 0.655221
I1210 10:33:30.452747 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:33:30.452747 16412 solver.cpp:237]     Train net output #1: loss = 0.655221 (* 1 = 0.655221 loss)
I1210 10:33:30.452747 16412 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1210 10:33:36.146921 16412 solver.cpp:218] Iteration 82200 (17.5634 iter/s, 5.69365s/100 iters), loss = 0.664464
I1210 10:33:36.146921 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:33:36.146921 16412 solver.cpp:237]     Train net output #1: loss = 0.664464 (* 1 = 0.664464 loss)
I1210 10:33:36.146921 16412 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1210 10:33:41.859494 16412 solver.cpp:218] Iteration 82300 (17.5071 iter/s, 5.71196s/100 iters), loss = 0.895361
I1210 10:33:41.859494 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:33:41.859494 16412 solver.cpp:237]     Train net output #1: loss = 0.895361 (* 1 = 0.895361 loss)
I1210 10:33:41.859494 16412 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1210 10:33:47.661900 16412 solver.cpp:218] Iteration 82400 (17.2356 iter/s, 5.80193s/100 iters), loss = 0.644356
I1210 10:33:47.661900 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:33:47.661900 16412 solver.cpp:237]     Train net output #1: loss = 0.644356 (* 1 = 0.644356 loss)
I1210 10:33:47.661900 16412 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1210 10:33:53.085237  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:33:53.310297 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_82500.caffemodel
I1210 10:33:53.324304 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_82500.solverstate
I1210 10:33:53.329819 16412 solver.cpp:330] Iteration 82500, Testing net (#0)
I1210 10:33:53.329819 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:33:54.702033 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:33:54.755070 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5843
I1210 10:33:54.755070 16412 solver.cpp:397]     Test net output #1: loss = 1.63382 (* 1 = 1.63382 loss)
I1210 10:33:54.811067 16412 solver.cpp:218] Iteration 82500 (13.9873 iter/s, 7.14935s/100 iters), loss = 0.622992
I1210 10:33:54.812072 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:33:54.812072 16412 solver.cpp:237]     Train net output #1: loss = 0.622992 (* 1 = 0.622992 loss)
I1210 10:33:54.812072 16412 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1210 10:34:00.516383 16412 solver.cpp:218] Iteration 82600 (17.531 iter/s, 5.70419s/100 iters), loss = 0.716396
I1210 10:34:00.516383 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:34:00.516383 16412 solver.cpp:237]     Train net output #1: loss = 0.716396 (* 1 = 0.716396 loss)
I1210 10:34:00.516383 16412 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1210 10:34:06.233196 16412 solver.cpp:218] Iteration 82700 (17.4947 iter/s, 5.71603s/100 iters), loss = 0.580698
I1210 10:34:06.233196 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:34:06.233196 16412 solver.cpp:237]     Train net output #1: loss = 0.580698 (* 1 = 0.580698 loss)
I1210 10:34:06.233196 16412 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1210 10:34:11.932600 16412 solver.cpp:218] Iteration 82800 (17.546 iter/s, 5.6993s/100 iters), loss = 0.765086
I1210 10:34:11.932600 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:34:11.932600 16412 solver.cpp:237]     Train net output #1: loss = 0.765086 (* 1 = 0.765086 loss)
I1210 10:34:11.932600 16412 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1210 10:34:17.618121 16412 solver.cpp:218] Iteration 82900 (17.5912 iter/s, 5.68466s/100 iters), loss = 0.75595
I1210 10:34:17.618121 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:34:17.618121 16412 solver.cpp:237]     Train net output #1: loss = 0.75595 (* 1 = 0.75595 loss)
I1210 10:34:17.618121 16412 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1210 10:34:23.048141  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:34:23.271764 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_83000.caffemodel
I1210 10:34:23.285871 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_83000.solverstate
I1210 10:34:23.290864 16412 solver.cpp:330] Iteration 83000, Testing net (#0)
I1210 10:34:23.290864 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:34:24.668448 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:34:24.722954 16412 solver.cpp:397]     Test net output #0: accuracy = 0.608
I1210 10:34:24.722954 16412 solver.cpp:397]     Test net output #1: loss = 1.51727 (* 1 = 1.51727 loss)
I1210 10:34:24.777968 16412 solver.cpp:218] Iteration 83000 (13.9676 iter/s, 7.15942s/100 iters), loss = 0.653015
I1210 10:34:24.777968 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:34:24.777968 16412 solver.cpp:237]     Train net output #1: loss = 0.653015 (* 1 = 0.653015 loss)
I1210 10:34:24.777968 16412 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1210 10:34:30.536625 16412 solver.cpp:218] Iteration 83100 (17.3655 iter/s, 5.75856s/100 iters), loss = 0.714517
I1210 10:34:30.536625 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:34:30.536625 16412 solver.cpp:237]     Train net output #1: loss = 0.714517 (* 1 = 0.714517 loss)
I1210 10:34:30.536625 16412 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1210 10:34:36.236706 16412 solver.cpp:218] Iteration 83200 (17.546 iter/s, 5.69931s/100 iters), loss = 0.694124
I1210 10:34:36.236706 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:34:36.236706 16412 solver.cpp:237]     Train net output #1: loss = 0.694124 (* 1 = 0.694124 loss)
I1210 10:34:36.236706 16412 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1210 10:34:42.010062 16412 solver.cpp:218] Iteration 83300 (17.3203 iter/s, 5.77357s/100 iters), loss = 0.872676
I1210 10:34:42.010062 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:34:42.010062 16412 solver.cpp:237]     Train net output #1: loss = 0.872676 (* 1 = 0.872676 loss)
I1210 10:34:42.010062 16412 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1210 10:34:47.685905 16412 solver.cpp:218] Iteration 83400 (17.6213 iter/s, 5.67495s/100 iters), loss = 0.755749
I1210 10:34:47.685905 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:34:47.685905 16412 solver.cpp:237]     Train net output #1: loss = 0.755749 (* 1 = 0.755749 loss)
I1210 10:34:47.685905 16412 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1210 10:34:53.122812  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:34:53.352356 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_83500.caffemodel
I1210 10:34:53.367347 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_83500.solverstate
I1210 10:34:53.372354 16412 solver.cpp:330] Iteration 83500, Testing net (#0)
I1210 10:34:53.372354 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:34:54.747983 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:34:54.801844 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5931
I1210 10:34:54.801844 16412 solver.cpp:397]     Test net output #1: loss = 1.60173 (* 1 = 1.60173 loss)
I1210 10:34:54.857841 16412 solver.cpp:218] Iteration 83500 (13.9434 iter/s, 7.17184s/100 iters), loss = 0.614563
I1210 10:34:54.857841 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:34:54.857841 16412 solver.cpp:237]     Train net output #1: loss = 0.614563 (* 1 = 0.614563 loss)
I1210 10:34:54.857841 16412 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1210 10:35:00.664124 16412 solver.cpp:218] Iteration 83600 (17.2253 iter/s, 5.80542s/100 iters), loss = 0.805939
I1210 10:35:00.664124 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:35:00.664124 16412 solver.cpp:237]     Train net output #1: loss = 0.805939 (* 1 = 0.805939 loss)
I1210 10:35:00.664124 16412 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1210 10:35:06.435751 16412 solver.cpp:218] Iteration 83700 (17.3275 iter/s, 5.77118s/100 iters), loss = 0.513578
I1210 10:35:06.435751 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:35:06.435751 16412 solver.cpp:237]     Train net output #1: loss = 0.513578 (* 1 = 0.513578 loss)
I1210 10:35:06.435751 16412 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1210 10:35:12.251163 16412 solver.cpp:218] Iteration 83800 (17.1973 iter/s, 5.81487s/100 iters), loss = 0.755559
I1210 10:35:12.251163 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:35:12.251163 16412 solver.cpp:237]     Train net output #1: loss = 0.755559 (* 1 = 0.755559 loss)
I1210 10:35:12.251163 16412 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1210 10:35:18.023521 16412 solver.cpp:218] Iteration 83900 (17.3236 iter/s, 5.77246s/100 iters), loss = 0.835105
I1210 10:35:18.023521 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:35:18.024523 16412 solver.cpp:237]     Train net output #1: loss = 0.835105 (* 1 = 0.835105 loss)
I1210 10:35:18.024523 16412 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1210 10:35:23.463264  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:35:23.693765 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_84000.caffemodel
I1210 10:35:23.708262 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_84000.solverstate
I1210 10:35:23.713263 16412 solver.cpp:330] Iteration 84000, Testing net (#0)
I1210 10:35:23.713263 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:35:25.111763 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:35:25.165266 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5628
I1210 10:35:25.165266 16412 solver.cpp:397]     Test net output #1: loss = 1.8526 (* 1 = 1.8526 loss)
I1210 10:35:25.219269 16412 solver.cpp:218] Iteration 84000 (13.9 iter/s, 7.19427s/100 iters), loss = 0.571768
I1210 10:35:25.219269 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:35:25.219269 16412 solver.cpp:237]     Train net output #1: loss = 0.571768 (* 1 = 0.571768 loss)
I1210 10:35:25.219269 16412 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1210 10:35:30.858716 16412 solver.cpp:218] Iteration 84100 (17.7308 iter/s, 5.6399s/100 iters), loss = 0.679187
I1210 10:35:30.859716 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:35:30.859716 16412 solver.cpp:237]     Train net output #1: loss = 0.679187 (* 1 = 0.679187 loss)
I1210 10:35:30.859716 16412 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1210 10:35:36.584833 16412 solver.cpp:218] Iteration 84200 (17.467 iter/s, 5.72508s/100 iters), loss = 0.452666
I1210 10:35:36.584833 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:35:36.584833 16412 solver.cpp:237]     Train net output #1: loss = 0.452666 (* 1 = 0.452666 loss)
I1210 10:35:36.584833 16412 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1210 10:35:42.289250 16412 solver.cpp:218] Iteration 84300 (17.5313 iter/s, 5.70408s/100 iters), loss = 0.741555
I1210 10:35:42.289250 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:35:42.289750 16412 solver.cpp:237]     Train net output #1: loss = 0.741555 (* 1 = 0.741555 loss)
I1210 10:35:42.289750 16412 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1210 10:35:48.039248 16412 solver.cpp:218] Iteration 84400 (17.392 iter/s, 5.74976s/100 iters), loss = 0.683318
I1210 10:35:48.039248 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:35:48.039248 16412 solver.cpp:237]     Train net output #1: loss = 0.683318 (* 1 = 0.683318 loss)
I1210 10:35:48.039248 16412 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1210 10:35:53.526665  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:35:53.750207 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_84500.caffemodel
I1210 10:35:53.764205 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_84500.solverstate
I1210 10:35:53.769201 16412 solver.cpp:330] Iteration 84500, Testing net (#0)
I1210 10:35:53.769201 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:35:55.155803 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:35:55.210847 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5912
I1210 10:35:55.210847 16412 solver.cpp:397]     Test net output #1: loss = 1.64417 (* 1 = 1.64417 loss)
I1210 10:35:55.264848 16412 solver.cpp:218] Iteration 84500 (13.8414 iter/s, 7.22473s/100 iters), loss = 0.566382
I1210 10:35:55.264848 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:35:55.264848 16412 solver.cpp:237]     Train net output #1: loss = 0.566382 (* 1 = 0.566382 loss)
I1210 10:35:55.264848 16412 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1210 10:36:01.016886 16412 solver.cpp:218] Iteration 84600 (17.3862 iter/s, 5.75169s/100 iters), loss = 0.709954
I1210 10:36:01.016886 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:36:01.016886 16412 solver.cpp:237]     Train net output #1: loss = 0.709954 (* 1 = 0.709954 loss)
I1210 10:36:01.016886 16412 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1210 10:36:06.804864 16412 solver.cpp:218] Iteration 84700 (17.2796 iter/s, 5.78717s/100 iters), loss = 0.473717
I1210 10:36:06.804864 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:36:06.804864 16412 solver.cpp:237]     Train net output #1: loss = 0.473717 (* 1 = 0.473717 loss)
I1210 10:36:06.804864 16412 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1210 10:36:12.523598 16412 solver.cpp:218] Iteration 84800 (17.4852 iter/s, 5.71911s/100 iters), loss = 0.755649
I1210 10:36:12.523598 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:36:12.523598 16412 solver.cpp:237]     Train net output #1: loss = 0.755649 (* 1 = 0.755649 loss)
I1210 10:36:12.523598 16412 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1210 10:36:18.217769 16412 solver.cpp:218] Iteration 84900 (17.5631 iter/s, 5.69375s/100 iters), loss = 0.837147
I1210 10:36:18.217769 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:36:18.217769 16412 solver.cpp:237]     Train net output #1: loss = 0.837147 (* 1 = 0.837147 loss)
I1210 10:36:18.217769 16412 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1210 10:36:23.641165  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:36:23.864182 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_85000.caffemodel
I1210 10:36:23.879182 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_85000.solverstate
I1210 10:36:23.883183 16412 solver.cpp:330] Iteration 85000, Testing net (#0)
I1210 10:36:23.883183 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:36:25.259280 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:36:25.313863 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5843
I1210 10:36:25.313863 16412 solver.cpp:397]     Test net output #1: loss = 1.68216 (* 1 = 1.68216 loss)
I1210 10:36:25.367861 16412 solver.cpp:218] Iteration 85000 (13.9868 iter/s, 7.14961s/100 iters), loss = 0.60887
I1210 10:36:25.368860 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:36:25.368860 16412 solver.cpp:237]     Train net output #1: loss = 0.60887 (* 1 = 0.60887 loss)
I1210 10:36:25.368860 16412 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1210 10:36:31.049782 16412 solver.cpp:218] Iteration 85100 (17.602 iter/s, 5.68117s/100 iters), loss = 0.761647
I1210 10:36:31.049782 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1210 10:36:31.049782 16412 solver.cpp:237]     Train net output #1: loss = 0.761647 (* 1 = 0.761647 loss)
I1210 10:36:31.049782 16412 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1210 10:36:36.728186 16412 solver.cpp:218] Iteration 85200 (17.6112 iter/s, 5.67821s/100 iters), loss = 0.558217
I1210 10:36:36.729187 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:36:36.729187 16412 solver.cpp:237]     Train net output #1: loss = 0.558217 (* 1 = 0.558217 loss)
I1210 10:36:36.729187 16412 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1210 10:36:42.424507 16412 solver.cpp:218] Iteration 85300 (17.5593 iter/s, 5.695s/100 iters), loss = 0.809298
I1210 10:36:42.424507 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:36:42.424507 16412 solver.cpp:237]     Train net output #1: loss = 0.809298 (* 1 = 0.809298 loss)
I1210 10:36:42.424507 16412 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1210 10:36:48.097287 16412 solver.cpp:218] Iteration 85400 (17.6273 iter/s, 5.673s/100 iters), loss = 0.685504
I1210 10:36:48.098289 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:36:48.098289 16412 solver.cpp:237]     Train net output #1: loss = 0.685504 (* 1 = 0.685504 loss)
I1210 10:36:48.098289 16412 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1210 10:36:53.497704  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:36:53.721721 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_85500.caffemodel
I1210 10:36:53.735720 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_85500.solverstate
I1210 10:36:53.739720 16412 solver.cpp:330] Iteration 85500, Testing net (#0)
I1210 10:36:53.739720 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:36:55.114331 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:36:55.167836 16412 solver.cpp:397]     Test net output #0: accuracy = 0.612
I1210 10:36:55.167836 16412 solver.cpp:397]     Test net output #1: loss = 1.4785 (* 1 = 1.4785 loss)
I1210 10:36:55.221843 16412 solver.cpp:218] Iteration 85500 (14.0374 iter/s, 7.12385s/100 iters), loss = 0.678023
I1210 10:36:55.221843 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:36:55.221843 16412 solver.cpp:237]     Train net output #1: loss = 0.678023 (* 1 = 0.678023 loss)
I1210 10:36:55.221843 16412 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1210 10:37:00.976284 16412 solver.cpp:218] Iteration 85600 (17.3813 iter/s, 5.7533s/100 iters), loss = 0.704449
I1210 10:37:00.976284 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:37:00.976284 16412 solver.cpp:237]     Train net output #1: loss = 0.704449 (* 1 = 0.704449 loss)
I1210 10:37:00.976284 16412 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1210 10:37:06.727852 16412 solver.cpp:218] Iteration 85700 (17.3861 iter/s, 5.75171s/100 iters), loss = 0.57149
I1210 10:37:06.727852 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:37:06.727852 16412 solver.cpp:237]     Train net output #1: loss = 0.57149 (* 1 = 0.57149 loss)
I1210 10:37:06.727852 16412 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1210 10:37:12.407281 16412 solver.cpp:218] Iteration 85800 (17.6092 iter/s, 5.67884s/100 iters), loss = 0.804738
I1210 10:37:12.407781 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:37:12.407781 16412 solver.cpp:237]     Train net output #1: loss = 0.804738 (* 1 = 0.804738 loss)
I1210 10:37:12.407781 16412 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1210 10:37:18.082672 16412 solver.cpp:218] Iteration 85900 (17.621 iter/s, 5.67505s/100 iters), loss = 0.854826
I1210 10:37:18.082672 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:37:18.082672 16412 solver.cpp:237]     Train net output #1: loss = 0.854826 (* 1 = 0.854826 loss)
I1210 10:37:18.082672 16412 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1210 10:37:23.480056  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:37:23.704078 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_86000.caffemodel
I1210 10:37:23.719082 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_86000.solverstate
I1210 10:37:23.723086 16412 solver.cpp:330] Iteration 86000, Testing net (#0)
I1210 10:37:23.723086 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:37:25.089188 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:37:25.143195 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6
I1210 10:37:25.143195 16412 solver.cpp:397]     Test net output #1: loss = 1.61446 (* 1 = 1.61446 loss)
I1210 10:37:25.198209 16412 solver.cpp:218] Iteration 86000 (14.0549 iter/s, 7.11498s/100 iters), loss = 0.537889
I1210 10:37:25.198209 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:37:25.198209 16412 solver.cpp:237]     Train net output #1: loss = 0.537889 (* 1 = 0.537889 loss)
I1210 10:37:25.198209 16412 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1210 10:37:30.866626 16412 solver.cpp:218] Iteration 86100 (17.6416 iter/s, 5.66843s/100 iters), loss = 0.738722
I1210 10:37:30.866626 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:37:30.866626 16412 solver.cpp:237]     Train net output #1: loss = 0.738722 (* 1 = 0.738722 loss)
I1210 10:37:30.866626 16412 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1210 10:37:36.534186 16412 solver.cpp:218] Iteration 86200 (17.6458 iter/s, 5.66707s/100 iters), loss = 0.688287
I1210 10:37:36.534186 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:37:36.534186 16412 solver.cpp:237]     Train net output #1: loss = 0.688287 (* 1 = 0.688287 loss)
I1210 10:37:36.534186 16412 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1210 10:37:42.206171 16412 solver.cpp:218] Iteration 86300 (17.6335 iter/s, 5.67101s/100 iters), loss = 0.67806
I1210 10:37:42.206171 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:37:42.206171 16412 solver.cpp:237]     Train net output #1: loss = 0.67806 (* 1 = 0.67806 loss)
I1210 10:37:42.206171 16412 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1210 10:37:47.879094 16412 solver.cpp:218] Iteration 86400 (17.629 iter/s, 5.67248s/100 iters), loss = 0.858802
I1210 10:37:47.879094 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:37:47.879094 16412 solver.cpp:237]     Train net output #1: loss = 0.858802 (* 1 = 0.858802 loss)
I1210 10:37:47.879094 16412 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1210 10:37:53.277539  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:37:53.500548 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_86500.caffemodel
I1210 10:37:53.519557 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_86500.solverstate
I1210 10:37:53.524562 16412 solver.cpp:330] Iteration 86500, Testing net (#0)
I1210 10:37:53.524562 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:37:54.890702 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:37:54.944707 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6075
I1210 10:37:54.944707 16412 solver.cpp:397]     Test net output #1: loss = 1.57235 (* 1 = 1.57235 loss)
I1210 10:37:54.997707 16412 solver.cpp:218] Iteration 86500 (14.0477 iter/s, 7.11858s/100 iters), loss = 0.662865
I1210 10:37:54.997707 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:37:54.997707 16412 solver.cpp:237]     Train net output #1: loss = 0.662865 (* 1 = 0.662865 loss)
I1210 10:37:54.997707 16412 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1210 10:38:00.676157 16412 solver.cpp:218] Iteration 86600 (17.6124 iter/s, 5.67781s/100 iters), loss = 0.718581
I1210 10:38:00.676157 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:38:00.676157 16412 solver.cpp:237]     Train net output #1: loss = 0.718581 (* 1 = 0.718581 loss)
I1210 10:38:00.676157 16412 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1210 10:38:06.344597 16412 solver.cpp:218] Iteration 86700 (17.6428 iter/s, 5.66804s/100 iters), loss = 0.568261
I1210 10:38:06.344597 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:38:06.344597 16412 solver.cpp:237]     Train net output #1: loss = 0.568261 (* 1 = 0.568261 loss)
I1210 10:38:06.344597 16412 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1210 10:38:12.015575 16412 solver.cpp:218] Iteration 86800 (17.6365 iter/s, 5.67005s/100 iters), loss = 0.836446
I1210 10:38:12.015575 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:38:12.015575 16412 solver.cpp:237]     Train net output #1: loss = 0.836445 (* 1 = 0.836445 loss)
I1210 10:38:12.015575 16412 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1210 10:38:17.679548 16412 solver.cpp:218] Iteration 86900 (17.6555 iter/s, 5.66397s/100 iters), loss = 0.705518
I1210 10:38:17.679548 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:38:17.679548 16412 solver.cpp:237]     Train net output #1: loss = 0.705518 (* 1 = 0.705518 loss)
I1210 10:38:17.679548 16412 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1210 10:38:23.075014  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:38:23.299026 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_87000.caffemodel
I1210 10:38:23.314033 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_87000.solverstate
I1210 10:38:23.318534 16412 solver.cpp:330] Iteration 87000, Testing net (#0)
I1210 10:38:23.318534 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:38:24.686113 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:38:24.740121 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5831
I1210 10:38:24.740121 16412 solver.cpp:397]     Test net output #1: loss = 1.69094 (* 1 = 1.69094 loss)
I1210 10:38:24.796120 16412 solver.cpp:218] Iteration 87000 (14.0534 iter/s, 7.11572s/100 iters), loss = 0.698303
I1210 10:38:24.796120 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:38:24.796120 16412 solver.cpp:237]     Train net output #1: loss = 0.698303 (* 1 = 0.698303 loss)
I1210 10:38:24.796120 16412 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1210 10:38:30.465579 16412 solver.cpp:218] Iteration 87100 (17.6404 iter/s, 5.66881s/100 iters), loss = 0.620907
I1210 10:38:30.465579 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:38:30.465579 16412 solver.cpp:237]     Train net output #1: loss = 0.620907 (* 1 = 0.620907 loss)
I1210 10:38:30.465579 16412 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1210 10:38:36.140020 16412 solver.cpp:218] Iteration 87200 (17.6218 iter/s, 5.6748s/100 iters), loss = 0.569541
I1210 10:38:36.140020 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:38:36.140020 16412 solver.cpp:237]     Train net output #1: loss = 0.569541 (* 1 = 0.569541 loss)
I1210 10:38:36.140020 16412 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1210 10:38:41.804519 16412 solver.cpp:218] Iteration 87300 (17.6561 iter/s, 5.66375s/100 iters), loss = 0.732214
I1210 10:38:41.804519 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:38:41.804519 16412 solver.cpp:237]     Train net output #1: loss = 0.732214 (* 1 = 0.732214 loss)
I1210 10:38:41.804519 16412 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1210 10:38:47.464943 16412 solver.cpp:218] Iteration 87400 (17.6667 iter/s, 5.66037s/100 iters), loss = 0.768995
I1210 10:38:47.464943 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:38:47.464943 16412 solver.cpp:237]     Train net output #1: loss = 0.768995 (* 1 = 0.768995 loss)
I1210 10:38:47.464943 16412 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1210 10:38:52.854334  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:38:53.076350 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_87500.caffemodel
I1210 10:38:53.090350 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_87500.solverstate
I1210 10:38:53.095351 16412 solver.cpp:330] Iteration 87500, Testing net (#0)
I1210 10:38:53.095351 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:38:54.463459 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:38:54.516963 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5806
I1210 10:38:54.516963 16412 solver.cpp:397]     Test net output #1: loss = 1.74968 (* 1 = 1.74968 loss)
I1210 10:38:54.571463 16412 solver.cpp:218] Iteration 87500 (14.0741 iter/s, 7.10526s/100 iters), loss = 0.782592
I1210 10:38:54.571463 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:38:54.571463 16412 solver.cpp:237]     Train net output #1: loss = 0.782592 (* 1 = 0.782592 loss)
I1210 10:38:54.571463 16412 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1210 10:39:00.241888 16412 solver.cpp:218] Iteration 87600 (17.6363 iter/s, 5.67014s/100 iters), loss = 0.593164
I1210 10:39:00.241888 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:39:00.241888 16412 solver.cpp:237]     Train net output #1: loss = 0.593164 (* 1 = 0.593164 loss)
I1210 10:39:00.241888 16412 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1210 10:39:05.919283 16412 solver.cpp:218] Iteration 87700 (17.6154 iter/s, 5.67686s/100 iters), loss = 0.595483
I1210 10:39:05.919283 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:39:05.919283 16412 solver.cpp:237]     Train net output #1: loss = 0.595482 (* 1 = 0.595482 loss)
I1210 10:39:05.919283 16412 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1210 10:39:11.599709 16412 solver.cpp:218] Iteration 87800 (17.6056 iter/s, 5.68001s/100 iters), loss = 0.775924
I1210 10:39:11.599709 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:39:11.599709 16412 solver.cpp:237]     Train net output #1: loss = 0.775924 (* 1 = 0.775924 loss)
I1210 10:39:11.599709 16412 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1210 10:39:17.283161 16412 solver.cpp:218] Iteration 87900 (17.5958 iter/s, 5.68317s/100 iters), loss = 0.704463
I1210 10:39:17.283161 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:39:17.283161 16412 solver.cpp:237]     Train net output #1: loss = 0.704463 (* 1 = 0.704463 loss)
I1210 10:39:17.283161 16412 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1210 10:39:22.715070  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:39:22.943586 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_88000.caffemodel
I1210 10:39:22.957587 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_88000.solverstate
I1210 10:39:22.961585 16412 solver.cpp:330] Iteration 88000, Testing net (#0)
I1210 10:39:22.961585 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:39:24.354699 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:39:24.408699 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5956
I1210 10:39:24.409701 16412 solver.cpp:397]     Test net output #1: loss = 1.6392 (* 1 = 1.6392 loss)
I1210 10:39:24.464709 16412 solver.cpp:218] Iteration 88000 (13.9247 iter/s, 7.18147s/100 iters), loss = 0.592837
I1210 10:39:24.464709 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:39:24.464709 16412 solver.cpp:237]     Train net output #1: loss = 0.592837 (* 1 = 0.592837 loss)
I1210 10:39:24.464709 16412 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1210 10:39:30.280292 16412 solver.cpp:218] Iteration 88100 (17.1972 iter/s, 5.81492s/100 iters), loss = 0.567238
I1210 10:39:30.280292 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:39:30.280292 16412 solver.cpp:237]     Train net output #1: loss = 0.567238 (* 1 = 0.567238 loss)
I1210 10:39:30.280292 16412 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1210 10:39:36.026521 16412 solver.cpp:218] Iteration 88200 (17.4056 iter/s, 5.74528s/100 iters), loss = 0.52884
I1210 10:39:36.026521 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:39:36.026521 16412 solver.cpp:237]     Train net output #1: loss = 0.52884 (* 1 = 0.52884 loss)
I1210 10:39:36.027019 16412 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1210 10:39:41.784673 16412 solver.cpp:218] Iteration 88300 (17.3681 iter/s, 5.75767s/100 iters), loss = 0.895227
I1210 10:39:41.784673 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:39:41.784673 16412 solver.cpp:237]     Train net output #1: loss = 0.895227 (* 1 = 0.895227 loss)
I1210 10:39:41.784673 16412 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1210 10:39:47.451480 16412 solver.cpp:218] Iteration 88400 (17.6493 iter/s, 5.66596s/100 iters), loss = 0.77175
I1210 10:39:47.451480 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:39:47.451480 16412 solver.cpp:237]     Train net output #1: loss = 0.77175 (* 1 = 0.77175 loss)
I1210 10:39:47.451480 16412 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1210 10:39:52.865128  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:39:53.088307 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_88500.caffemodel
I1210 10:39:53.102324 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_88500.solverstate
I1210 10:39:53.106325 16412 solver.cpp:330] Iteration 88500, Testing net (#0)
I1210 10:39:53.107326 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:39:54.474308 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:39:54.528792 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6217
I1210 10:39:54.529295 16412 solver.cpp:397]     Test net output #1: loss = 1.50379 (* 1 = 1.50379 loss)
I1210 10:39:54.583063 16412 solver.cpp:218] Iteration 88500 (14.023 iter/s, 7.13113s/100 iters), loss = 0.650096
I1210 10:39:54.583063 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:39:54.583063 16412 solver.cpp:237]     Train net output #1: loss = 0.650096 (* 1 = 0.650096 loss)
I1210 10:39:54.583063 16412 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1210 10:40:00.333884 16412 solver.cpp:218] Iteration 88600 (17.3895 iter/s, 5.75059s/100 iters), loss = 0.56458
I1210 10:40:00.333884 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:40:00.333884 16412 solver.cpp:237]     Train net output #1: loss = 0.56458 (* 1 = 0.56458 loss)
I1210 10:40:00.333884 16412 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1210 10:40:06.046763 16412 solver.cpp:218] Iteration 88700 (17.5052 iter/s, 5.71259s/100 iters), loss = 0.516952
I1210 10:40:06.046763 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:40:06.046763 16412 solver.cpp:237]     Train net output #1: loss = 0.516952 (* 1 = 0.516952 loss)
I1210 10:40:06.046763 16412 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1210 10:40:11.717087 16412 solver.cpp:218] Iteration 88800 (17.6374 iter/s, 5.66976s/100 iters), loss = 0.83816
I1210 10:40:11.717087 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:40:11.717087 16412 solver.cpp:237]     Train net output #1: loss = 0.83816 (* 1 = 0.83816 loss)
I1210 10:40:11.717087 16412 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1210 10:40:17.383929 16412 solver.cpp:218] Iteration 88900 (17.6491 iter/s, 5.666s/100 iters), loss = 0.789452
I1210 10:40:17.383929 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:40:17.383929 16412 solver.cpp:237]     Train net output #1: loss = 0.789452 (* 1 = 0.789452 loss)
I1210 10:40:17.383929 16412 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1210 10:40:22.779654  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:40:23.004307 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_89000.caffemodel
I1210 10:40:23.017305 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_89000.solverstate
I1210 10:40:23.024309 16412 solver.cpp:330] Iteration 89000, Testing net (#0)
I1210 10:40:23.024309 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:40:24.388916 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:40:24.444435 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5942
I1210 10:40:24.444435 16412 solver.cpp:397]     Test net output #1: loss = 1.67649 (* 1 = 1.67649 loss)
I1210 10:40:24.498756 16412 solver.cpp:218] Iteration 89000 (14.0559 iter/s, 7.11444s/100 iters), loss = 0.707453
I1210 10:40:24.498756 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:40:24.498756 16412 solver.cpp:237]     Train net output #1: loss = 0.707453 (* 1 = 0.707453 loss)
I1210 10:40:24.498756 16412 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1210 10:40:30.166188 16412 solver.cpp:218] Iteration 89100 (17.6449 iter/s, 5.66737s/100 iters), loss = 0.582193
I1210 10:40:30.166188 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:40:30.166188 16412 solver.cpp:237]     Train net output #1: loss = 0.582193 (* 1 = 0.582193 loss)
I1210 10:40:30.166188 16412 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1210 10:40:35.839095 16412 solver.cpp:218] Iteration 89200 (17.6307 iter/s, 5.67191s/100 iters), loss = 0.480776
I1210 10:40:35.839095 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:40:35.839095 16412 solver.cpp:237]     Train net output #1: loss = 0.480776 (* 1 = 0.480776 loss)
I1210 10:40:35.839095 16412 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1210 10:40:41.511026 16412 solver.cpp:218] Iteration 89300 (17.6309 iter/s, 5.67187s/100 iters), loss = 0.76281
I1210 10:40:41.511026 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:40:41.511026 16412 solver.cpp:237]     Train net output #1: loss = 0.76281 (* 1 = 0.76281 loss)
I1210 10:40:41.511026 16412 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1210 10:40:47.208472 16412 solver.cpp:218] Iteration 89400 (17.5517 iter/s, 5.69745s/100 iters), loss = 0.795683
I1210 10:40:47.209472 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:40:47.209472 16412 solver.cpp:237]     Train net output #1: loss = 0.795683 (* 1 = 0.795683 loss)
I1210 10:40:47.209472 16412 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1210 10:40:52.660917  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:40:52.886929 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_89500.caffemodel
I1210 10:40:52.903928 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_89500.solverstate
I1210 10:40:52.907927 16412 solver.cpp:330] Iteration 89500, Testing net (#0)
I1210 10:40:52.907927 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:40:54.284078 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:40:54.339074 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5854
I1210 10:40:54.339074 16412 solver.cpp:397]     Test net output #1: loss = 1.68683 (* 1 = 1.68683 loss)
I1210 10:40:54.393743 16412 solver.cpp:218] Iteration 89500 (13.9193 iter/s, 7.18426s/100 iters), loss = 0.639248
I1210 10:40:54.393743 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:40:54.393743 16412 solver.cpp:237]     Train net output #1: loss = 0.639248 (* 1 = 0.639248 loss)
I1210 10:40:54.393743 16412 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1210 10:41:00.073997 16412 solver.cpp:218] Iteration 89600 (17.6062 iter/s, 5.67981s/100 iters), loss = 0.680661
I1210 10:41:00.073997 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:41:00.073997 16412 solver.cpp:237]     Train net output #1: loss = 0.680661 (* 1 = 0.680661 loss)
I1210 10:41:00.073997 16412 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1210 10:41:05.744957 16412 solver.cpp:218] Iteration 89700 (17.6349 iter/s, 5.67056s/100 iters), loss = 0.530391
I1210 10:41:05.745458 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:41:05.745458 16412 solver.cpp:237]     Train net output #1: loss = 0.530391 (* 1 = 0.530391 loss)
I1210 10:41:05.745458 16412 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1210 10:41:11.489975 16412 solver.cpp:218] Iteration 89800 (17.4076 iter/s, 5.74461s/100 iters), loss = 0.753725
I1210 10:41:11.489975 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:41:11.489975 16412 solver.cpp:237]     Train net output #1: loss = 0.753725 (* 1 = 0.753725 loss)
I1210 10:41:11.489975 16412 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1210 10:41:17.186476 16412 solver.cpp:218] Iteration 89900 (17.556 iter/s, 5.69605s/100 iters), loss = 0.791415
I1210 10:41:17.186476 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:41:17.186476 16412 solver.cpp:237]     Train net output #1: loss = 0.791415 (* 1 = 0.791415 loss)
I1210 10:41:17.186476 16412 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1210 10:41:22.586870  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:41:22.809885 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_90000.caffemodel
I1210 10:41:22.828883 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_90000.solverstate
I1210 10:41:22.833884 16412 solver.cpp:330] Iteration 90000, Testing net (#0)
I1210 10:41:22.833884 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:41:24.202985 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:41:24.256489 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6051
I1210 10:41:24.256989 16412 solver.cpp:397]     Test net output #1: loss = 1.56211 (* 1 = 1.56211 loss)
I1210 10:41:24.309993 16412 solver.cpp:218] Iteration 90000 (14.0389 iter/s, 7.12307s/100 iters), loss = 0.681412
I1210 10:41:24.309993 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:41:24.309993 16412 solver.cpp:237]     Train net output #1: loss = 0.681412 (* 1 = 0.681412 loss)
I1210 10:41:24.309993 16412 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1210 10:41:29.978423 16412 solver.cpp:218] Iteration 90100 (17.6442 iter/s, 5.66757s/100 iters), loss = 0.56153
I1210 10:41:29.978423 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:41:29.978423 16412 solver.cpp:237]     Train net output #1: loss = 0.56153 (* 1 = 0.56153 loss)
I1210 10:41:29.978423 16412 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1210 10:41:35.647864 16412 solver.cpp:218] Iteration 90200 (17.639 iter/s, 5.66925s/100 iters), loss = 0.586035
I1210 10:41:35.647864 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:41:35.647864 16412 solver.cpp:237]     Train net output #1: loss = 0.586035 (* 1 = 0.586035 loss)
I1210 10:41:35.647864 16412 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1210 10:41:41.317265 16412 solver.cpp:218] Iteration 90300 (17.6388 iter/s, 5.66932s/100 iters), loss = 0.686502
I1210 10:41:41.317265 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:41:41.317265 16412 solver.cpp:237]     Train net output #1: loss = 0.686502 (* 1 = 0.686502 loss)
I1210 10:41:41.317265 16412 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1210 10:41:46.986637 16412 solver.cpp:218] Iteration 90400 (17.6422 iter/s, 5.66822s/100 iters), loss = 0.90929
I1210 10:41:46.986637 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1210 10:41:46.986637 16412 solver.cpp:237]     Train net output #1: loss = 0.90929 (* 1 = 0.90929 loss)
I1210 10:41:46.986637 16412 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1210 10:41:52.382051  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:41:52.607061 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_90500.caffemodel
I1210 10:41:52.621062 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_90500.solverstate
I1210 10:41:52.626062 16412 solver.cpp:330] Iteration 90500, Testing net (#0)
I1210 10:41:52.626062 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:41:53.991144 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:41:54.045143 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6116
I1210 10:41:54.045143 16412 solver.cpp:397]     Test net output #1: loss = 1.5533 (* 1 = 1.5533 loss)
I1210 10:41:54.098152 16412 solver.cpp:218] Iteration 90500 (14.061 iter/s, 7.11185s/100 iters), loss = 0.551797
I1210 10:41:54.098152 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:41:54.098152 16412 solver.cpp:237]     Train net output #1: loss = 0.551797 (* 1 = 0.551797 loss)
I1210 10:41:54.098152 16412 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1210 10:41:59.760049 16412 solver.cpp:218] Iteration 90600 (17.6648 iter/s, 5.66098s/100 iters), loss = 0.744605
I1210 10:41:59.760550 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:41:59.760550 16412 solver.cpp:237]     Train net output #1: loss = 0.744605 (* 1 = 0.744605 loss)
I1210 10:41:59.760550 16412 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1210 10:42:05.427944 16412 solver.cpp:218] Iteration 90700 (17.6435 iter/s, 5.66782s/100 iters), loss = 0.539303
I1210 10:42:05.427944 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:42:05.427944 16412 solver.cpp:237]     Train net output #1: loss = 0.539303 (* 1 = 0.539303 loss)
I1210 10:42:05.427944 16412 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1210 10:42:11.091470 16412 solver.cpp:218] Iteration 90800 (17.6594 iter/s, 5.66269s/100 iters), loss = 0.926299
I1210 10:42:11.091470 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:42:11.091470 16412 solver.cpp:237]     Train net output #1: loss = 0.926299 (* 1 = 0.926299 loss)
I1210 10:42:11.091470 16412 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1210 10:42:16.758882 16412 solver.cpp:218] Iteration 90900 (17.6468 iter/s, 5.66676s/100 iters), loss = 0.768167
I1210 10:42:16.758882 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:42:16.758882 16412 solver.cpp:237]     Train net output #1: loss = 0.768167 (* 1 = 0.768167 loss)
I1210 10:42:16.758882 16412 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1210 10:42:22.155347  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:42:22.378861 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_91000.caffemodel
I1210 10:42:22.394366 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_91000.solverstate
I1210 10:42:22.398365 16412 solver.cpp:330] Iteration 91000, Testing net (#0)
I1210 10:42:22.398365 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:42:23.764463 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:42:23.819474 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6199
I1210 10:42:23.819474 16412 solver.cpp:397]     Test net output #1: loss = 1.53412 (* 1 = 1.53412 loss)
I1210 10:42:23.873474 16412 solver.cpp:218] Iteration 91000 (14.0554 iter/s, 7.1147s/100 iters), loss = 0.768289
I1210 10:42:23.873474 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:42:23.873474 16412 solver.cpp:237]     Train net output #1: loss = 0.768289 (* 1 = 0.768289 loss)
I1210 10:42:23.873474 16412 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1210 10:42:29.540357 16412 solver.cpp:218] Iteration 91100 (17.649 iter/s, 5.66605s/100 iters), loss = 0.608546
I1210 10:42:29.540357 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:42:29.540357 16412 solver.cpp:237]     Train net output #1: loss = 0.608546 (* 1 = 0.608546 loss)
I1210 10:42:29.540357 16412 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1210 10:42:35.217790 16412 solver.cpp:218] Iteration 91200 (17.614 iter/s, 5.6773s/100 iters), loss = 0.52223
I1210 10:42:35.217790 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:42:35.217790 16412 solver.cpp:237]     Train net output #1: loss = 0.52223 (* 1 = 0.52223 loss)
I1210 10:42:35.217790 16412 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1210 10:42:40.887678 16412 solver.cpp:218] Iteration 91300 (17.64 iter/s, 5.66892s/100 iters), loss = 0.829872
I1210 10:42:40.887678 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:42:40.887678 16412 solver.cpp:237]     Train net output #1: loss = 0.829872 (* 1 = 0.829872 loss)
I1210 10:42:40.887678 16412 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1210 10:42:46.561553 16412 solver.cpp:218] Iteration 91400 (17.6253 iter/s, 5.67367s/100 iters), loss = 0.779727
I1210 10:42:46.561553 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:42:46.561553 16412 solver.cpp:237]     Train net output #1: loss = 0.779727 (* 1 = 0.779727 loss)
I1210 10:42:46.561553 16412 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1210 10:42:51.956950  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:42:52.179958 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_91500.caffemodel
I1210 10:42:52.193962 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_91500.solverstate
I1210 10:42:52.198966 16412 solver.cpp:330] Iteration 91500, Testing net (#0)
I1210 10:42:52.198966 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:42:53.567220 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:42:53.620229 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5773
I1210 10:42:53.620229 16412 solver.cpp:397]     Test net output #1: loss = 1.74865 (* 1 = 1.74865 loss)
I1210 10:42:53.675228 16412 solver.cpp:218] Iteration 91500 (14.0596 iter/s, 7.1126s/100 iters), loss = 0.54122
I1210 10:42:53.675228 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:42:53.675228 16412 solver.cpp:237]     Train net output #1: loss = 0.54122 (* 1 = 0.54122 loss)
I1210 10:42:53.675228 16412 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1210 10:42:59.345671 16412 solver.cpp:218] Iteration 91600 (17.6337 iter/s, 5.67096s/100 iters), loss = 0.621251
I1210 10:42:59.345671 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:42:59.345671 16412 solver.cpp:237]     Train net output #1: loss = 0.621251 (* 1 = 0.621251 loss)
I1210 10:42:59.346670 16412 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1210 10:43:05.016067 16412 solver.cpp:218] Iteration 91700 (17.6387 iter/s, 5.66936s/100 iters), loss = 0.485197
I1210 10:43:05.016067 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:43:05.016067 16412 solver.cpp:237]     Train net output #1: loss = 0.485197 (* 1 = 0.485197 loss)
I1210 10:43:05.016067 16412 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1210 10:43:10.687497 16412 solver.cpp:218] Iteration 91800 (17.635 iter/s, 5.67054s/100 iters), loss = 0.730185
I1210 10:43:10.687497 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:43:10.687497 16412 solver.cpp:237]     Train net output #1: loss = 0.730185 (* 1 = 0.730185 loss)
I1210 10:43:10.687497 16412 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1210 10:43:16.363914 16412 solver.cpp:218] Iteration 91900 (17.6162 iter/s, 5.67658s/100 iters), loss = 0.668881
I1210 10:43:16.363914 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:43:16.363914 16412 solver.cpp:237]     Train net output #1: loss = 0.668881 (* 1 = 0.668881 loss)
I1210 10:43:16.363914 16412 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1210 10:43:21.757328  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:43:21.981343 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_92000.caffemodel
I1210 10:43:21.995345 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_92000.solverstate
I1210 10:43:21.999349 16412 solver.cpp:330] Iteration 92000, Testing net (#0)
I1210 10:43:21.999349 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:43:23.364466 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:43:23.419472 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5901
I1210 10:43:23.419472 16412 solver.cpp:397]     Test net output #1: loss = 1.64735 (* 1 = 1.64735 loss)
I1210 10:43:23.473471 16412 solver.cpp:218] Iteration 92000 (14.0662 iter/s, 7.10924s/100 iters), loss = 0.641537
I1210 10:43:23.473471 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:43:23.474472 16412 solver.cpp:237]     Train net output #1: loss = 0.641537 (* 1 = 0.641537 loss)
I1210 10:43:23.474472 16412 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1210 10:43:29.136926 16412 solver.cpp:218] Iteration 92100 (17.6587 iter/s, 5.66294s/100 iters), loss = 0.479463
I1210 10:43:29.136926 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:43:29.136926 16412 solver.cpp:237]     Train net output #1: loss = 0.479463 (* 1 = 0.479463 loss)
I1210 10:43:29.136926 16412 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1210 10:43:34.802343 16412 solver.cpp:218] Iteration 92200 (17.6524 iter/s, 5.66496s/100 iters), loss = 0.571724
I1210 10:43:34.802343 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:43:34.802343 16412 solver.cpp:237]     Train net output #1: loss = 0.571724 (* 1 = 0.571724 loss)
I1210 10:43:34.802343 16412 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1210 10:43:40.466753 16412 solver.cpp:218] Iteration 92300 (17.6564 iter/s, 5.66366s/100 iters), loss = 0.815825
I1210 10:43:40.466753 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:43:40.466753 16412 solver.cpp:237]     Train net output #1: loss = 0.815825 (* 1 = 0.815825 loss)
I1210 10:43:40.466753 16412 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1210 10:43:46.139171 16412 solver.cpp:218] Iteration 92400 (17.6312 iter/s, 5.67176s/100 iters), loss = 0.682428
I1210 10:43:46.139171 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:43:46.139171 16412 solver.cpp:237]     Train net output #1: loss = 0.682428 (* 1 = 0.682428 loss)
I1210 10:43:46.139171 16412 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1210 10:43:51.529587  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:43:51.753106 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_92500.caffemodel
I1210 10:43:51.766610 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_92500.solverstate
I1210 10:43:51.771611 16412 solver.cpp:330] Iteration 92500, Testing net (#0)
I1210 10:43:51.771611 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:43:53.139734 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:43:53.193738 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5849
I1210 10:43:53.193738 16412 solver.cpp:397]     Test net output #1: loss = 1.69579 (* 1 = 1.69579 loss)
I1210 10:43:53.247741 16412 solver.cpp:218] Iteration 92500 (14.0683 iter/s, 7.10819s/100 iters), loss = 0.529433
I1210 10:43:53.247741 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:43:53.247741 16412 solver.cpp:237]     Train net output #1: loss = 0.529433 (* 1 = 0.529433 loss)
I1210 10:43:53.247741 16412 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1210 10:43:58.914252 16412 solver.cpp:218] Iteration 92600 (17.6476 iter/s, 5.66649s/100 iters), loss = 0.668756
I1210 10:43:58.914252 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:43:58.914252 16412 solver.cpp:237]     Train net output #1: loss = 0.668756 (* 1 = 0.668756 loss)
I1210 10:43:58.914252 16412 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1210 10:44:04.587709 16412 solver.cpp:218] Iteration 92700 (17.6284 iter/s, 5.67267s/100 iters), loss = 0.572585
I1210 10:44:04.587709 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:44:04.587709 16412 solver.cpp:237]     Train net output #1: loss = 0.572585 (* 1 = 0.572585 loss)
I1210 10:44:04.587709 16412 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1210 10:44:10.264111 16412 solver.cpp:218] Iteration 92800 (17.6178 iter/s, 5.67609s/100 iters), loss = 0.986037
I1210 10:44:10.264111 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1210 10:44:10.264111 16412 solver.cpp:237]     Train net output #1: loss = 0.986037 (* 1 = 0.986037 loss)
I1210 10:44:10.264111 16412 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1210 10:44:15.935587 16412 solver.cpp:218] Iteration 92900 (17.6341 iter/s, 5.67081s/100 iters), loss = 0.847049
I1210 10:44:15.935587 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1210 10:44:15.935587 16412 solver.cpp:237]     Train net output #1: loss = 0.847049 (* 1 = 0.847049 loss)
I1210 10:44:15.935587 16412 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1210 10:44:21.329941  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:44:21.552954 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_93000.caffemodel
I1210 10:44:21.567960 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_93000.solverstate
I1210 10:44:21.572960 16412 solver.cpp:330] Iteration 93000, Testing net (#0)
I1210 10:44:21.572960 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:44:22.938047 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:44:22.993053 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6066
I1210 10:44:22.993053 16412 solver.cpp:397]     Test net output #1: loss = 1.54379 (* 1 = 1.54379 loss)
I1210 10:44:23.047051 16412 solver.cpp:218] Iteration 93000 (14.0632 iter/s, 7.11073s/100 iters), loss = 0.515106
I1210 10:44:23.047051 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:44:23.047051 16412 solver.cpp:237]     Train net output #1: loss = 0.515106 (* 1 = 0.515106 loss)
I1210 10:44:23.047051 16412 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1210 10:44:28.709429 16412 solver.cpp:218] Iteration 93100 (17.6595 iter/s, 5.66266s/100 iters), loss = 0.707718
I1210 10:44:28.709429 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:44:28.709429 16412 solver.cpp:237]     Train net output #1: loss = 0.707718 (* 1 = 0.707718 loss)
I1210 10:44:28.709429 16412 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1210 10:44:34.373813 16412 solver.cpp:218] Iteration 93200 (17.6554 iter/s, 5.66398s/100 iters), loss = 0.427464
I1210 10:44:34.373813 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:44:34.373813 16412 solver.cpp:237]     Train net output #1: loss = 0.427464 (* 1 = 0.427464 loss)
I1210 10:44:34.373813 16412 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1210 10:44:40.033895 16412 solver.cpp:218] Iteration 93300 (17.6684 iter/s, 5.65982s/100 iters), loss = 0.743505
I1210 10:44:40.033895 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:44:40.034895 16412 solver.cpp:237]     Train net output #1: loss = 0.743505 (* 1 = 0.743505 loss)
I1210 10:44:40.034895 16412 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1210 10:44:45.704660 16412 solver.cpp:218] Iteration 93400 (17.6371 iter/s, 5.66986s/100 iters), loss = 0.732116
I1210 10:44:45.704660 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:44:45.704660 16412 solver.cpp:237]     Train net output #1: loss = 0.732116 (* 1 = 0.732116 loss)
I1210 10:44:45.704660 16412 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1210 10:44:51.093734  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:44:51.316886 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_93500.caffemodel
I1210 10:44:51.331887 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_93500.solverstate
I1210 10:44:51.335887 16412 solver.cpp:330] Iteration 93500, Testing net (#0)
I1210 10:44:51.335887 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:44:52.705152 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:44:52.758162 16412 solver.cpp:397]     Test net output #0: accuracy = 0.609
I1210 10:44:52.758162 16412 solver.cpp:397]     Test net output #1: loss = 1.57951 (* 1 = 1.57951 loss)
I1210 10:44:52.812695 16412 solver.cpp:218] Iteration 93500 (14.0702 iter/s, 7.10724s/100 iters), loss = 0.626545
I1210 10:44:52.812695 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:44:52.812695 16412 solver.cpp:237]     Train net output #1: loss = 0.626545 (* 1 = 0.626545 loss)
I1210 10:44:52.812695 16412 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1210 10:44:58.474310 16412 solver.cpp:218] Iteration 93600 (17.6636 iter/s, 5.66136s/100 iters), loss = 0.645613
I1210 10:44:58.474310 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:44:58.474310 16412 solver.cpp:237]     Train net output #1: loss = 0.645613 (* 1 = 0.645613 loss)
I1210 10:44:58.474310 16412 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1210 10:45:04.136575 16412 solver.cpp:218] Iteration 93700 (17.6623 iter/s, 5.66177s/100 iters), loss = 0.529267
I1210 10:45:04.136575 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:45:04.136575 16412 solver.cpp:237]     Train net output #1: loss = 0.529267 (* 1 = 0.529267 loss)
I1210 10:45:04.136575 16412 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1210 10:45:09.796454 16412 solver.cpp:218] Iteration 93800 (17.6691 iter/s, 5.6596s/100 iters), loss = 0.762076
I1210 10:45:09.796454 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:45:09.796454 16412 solver.cpp:237]     Train net output #1: loss = 0.762076 (* 1 = 0.762076 loss)
I1210 10:45:09.796454 16412 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1210 10:45:15.455292 16412 solver.cpp:218] Iteration 93900 (17.6719 iter/s, 5.65869s/100 iters), loss = 0.774973
I1210 10:45:15.455292 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:45:15.455292 16412 solver.cpp:237]     Train net output #1: loss = 0.774973 (* 1 = 0.774973 loss)
I1210 10:45:15.455292 16412 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1210 10:45:20.838963  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:45:21.063134 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_94000.caffemodel
I1210 10:45:21.076640 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_94000.solverstate
I1210 10:45:21.081138 16412 solver.cpp:330] Iteration 94000, Testing net (#0)
I1210 10:45:21.081138 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:45:22.446398 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:45:22.500427 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6048
I1210 10:45:22.500427 16412 solver.cpp:397]     Test net output #1: loss = 1.59751 (* 1 = 1.59751 loss)
I1210 10:45:22.555439 16412 solver.cpp:218] Iteration 94000 (14.0848 iter/s, 7.09984s/100 iters), loss = 0.69226
I1210 10:45:22.555439 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:45:22.555439 16412 solver.cpp:237]     Train net output #1: loss = 0.69226 (* 1 = 0.69226 loss)
I1210 10:45:22.555439 16412 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1210 10:45:28.222183 16412 solver.cpp:218] Iteration 94100 (17.6496 iter/s, 5.66586s/100 iters), loss = 0.633109
I1210 10:45:28.222183 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:45:28.222183 16412 solver.cpp:237]     Train net output #1: loss = 0.633109 (* 1 = 0.633109 loss)
I1210 10:45:28.222183 16412 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1210 10:45:33.880810 16412 solver.cpp:218] Iteration 94200 (17.6725 iter/s, 5.65851s/100 iters), loss = 0.53634
I1210 10:45:33.880810 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:45:33.880810 16412 solver.cpp:237]     Train net output #1: loss = 0.53634 (* 1 = 0.53634 loss)
I1210 10:45:33.880810 16412 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1210 10:45:39.540586 16412 solver.cpp:218] Iteration 94300 (17.6697 iter/s, 5.65939s/100 iters), loss = 0.747291
I1210 10:45:39.540586 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1210 10:45:39.540586 16412 solver.cpp:237]     Train net output #1: loss = 0.747291 (* 1 = 0.747291 loss)
I1210 10:45:39.540586 16412 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1210 10:45:45.210489 16412 solver.cpp:218] Iteration 94400 (17.6411 iter/s, 5.66857s/100 iters), loss = 0.72162
I1210 10:45:45.210489 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1210 10:45:45.210489 16412 solver.cpp:237]     Train net output #1: loss = 0.72162 (* 1 = 0.72162 loss)
I1210 10:45:45.210489 16412 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1210 10:45:50.596516  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:45:50.820041 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_94500.caffemodel
I1210 10:45:50.834547 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_94500.solverstate
I1210 10:45:50.839066 16412 solver.cpp:330] Iteration 94500, Testing net (#0)
I1210 10:45:50.839066 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:45:52.207552 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:45:52.260574 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5436
I1210 10:45:52.260574 16412 solver.cpp:397]     Test net output #1: loss = 1.99356 (* 1 = 1.99356 loss)
I1210 10:45:52.314579 16412 solver.cpp:218] Iteration 94500 (14.0754 iter/s, 7.10457s/100 iters), loss = 0.662698
I1210 10:45:52.315578 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1210 10:45:52.315578 16412 solver.cpp:237]     Train net output #1: loss = 0.662698 (* 1 = 0.662698 loss)
I1210 10:45:52.315578 16412 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1210 10:45:57.978051 16412 solver.cpp:218] Iteration 94600 (17.6588 iter/s, 5.66289s/100 iters), loss = 0.712866
I1210 10:45:57.978051 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1210 10:45:57.978051 16412 solver.cpp:237]     Train net output #1: loss = 0.712866 (* 1 = 0.712866 loss)
I1210 10:45:57.978051 16412 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1210 10:46:03.643484 16412 solver.cpp:218] Iteration 94700 (17.6541 iter/s, 5.66441s/100 iters), loss = 0.621695
I1210 10:46:03.643484 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:46:03.643484 16412 solver.cpp:237]     Train net output #1: loss = 0.621695 (* 1 = 0.621695 loss)
I1210 10:46:03.643484 16412 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1210 10:46:09.310964 16412 solver.cpp:218] Iteration 94800 (17.6447 iter/s, 5.66742s/100 iters), loss = 0.824681
I1210 10:46:09.310964 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1210 10:46:09.310964 16412 solver.cpp:237]     Train net output #1: loss = 0.824681 (* 1 = 0.824681 loss)
I1210 10:46:09.310964 16412 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1210 10:46:14.980398 16412 solver.cpp:218] Iteration 94900 (17.6398 iter/s, 5.669s/100 iters), loss = 0.783306
I1210 10:46:14.980398 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1210 10:46:14.980398 16412 solver.cpp:237]     Train net output #1: loss = 0.783306 (* 1 = 0.783306 loss)
I1210 10:46:14.980398 16412 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1210 10:46:20.372849  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:46:20.595863 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_95000.caffemodel
I1210 10:46:20.610863 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_95000.solverstate
I1210 10:46:20.614863 16412 solver.cpp:330] Iteration 95000, Testing net (#0)
I1210 10:46:20.614863 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:46:21.982991 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:46:22.038004 16412 solver.cpp:397]     Test net output #0: accuracy = 0.5899
I1210 10:46:22.038004 16412 solver.cpp:397]     Test net output #1: loss = 1.67383 (* 1 = 1.67383 loss)
I1210 10:46:22.092012 16412 solver.cpp:218] Iteration 95000 (14.0621 iter/s, 7.11129s/100 iters), loss = 0.72368
I1210 10:46:22.092012 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1210 10:46:22.092012 16412 solver.cpp:237]     Train net output #1: loss = 0.72368 (* 1 = 0.72368 loss)
I1210 10:46:22.092012 16412 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1210 10:46:22.092012 16412 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1210 10:46:27.761502 16412 solver.cpp:218] Iteration 95100 (17.6397 iter/s, 5.66903s/100 iters), loss = 0.509133
I1210 10:46:27.761502 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:46:27.761502 16412 solver.cpp:237]     Train net output #1: loss = 0.509133 (* 1 = 0.509133 loss)
I1210 10:46:27.761502 16412 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1210 10:46:33.434522 16412 solver.cpp:218] Iteration 95200 (17.6306 iter/s, 5.67197s/100 iters), loss = 0.441564
I1210 10:46:33.434522 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:46:33.434522 16412 solver.cpp:237]     Train net output #1: loss = 0.441564 (* 1 = 0.441564 loss)
I1210 10:46:33.434522 16412 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1210 10:46:39.105533 16412 solver.cpp:218] Iteration 95300 (17.6335 iter/s, 5.67102s/100 iters), loss = 0.557666
I1210 10:46:39.105533 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:46:39.105533 16412 solver.cpp:237]     Train net output #1: loss = 0.557666 (* 1 = 0.557666 loss)
I1210 10:46:39.105533 16412 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1210 10:46:44.776052 16412 solver.cpp:218] Iteration 95400 (17.637 iter/s, 5.6699s/100 iters), loss = 0.407524
I1210 10:46:44.776052 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:46:44.776052 16412 solver.cpp:237]     Train net output #1: loss = 0.407524 (* 1 = 0.407524 loss)
I1210 10:46:44.776052 16412 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1210 10:46:50.164547  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:46:50.387555 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_95500.caffemodel
I1210 10:46:50.401556 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_95500.solverstate
I1210 10:46:50.406556 16412 solver.cpp:330] Iteration 95500, Testing net (#0)
I1210 10:46:50.406556 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:46:51.772672 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:46:51.828174 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6802
I1210 10:46:51.828174 16412 solver.cpp:397]     Test net output #1: loss = 1.17493 (* 1 = 1.17493 loss)
I1210 10:46:51.880677 16412 solver.cpp:218] Iteration 95500 (14.0763 iter/s, 7.10416s/100 iters), loss = 0.473669
I1210 10:46:51.880677 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:46:51.880677 16412 solver.cpp:237]     Train net output #1: loss = 0.473669 (* 1 = 0.473669 loss)
I1210 10:46:51.880677 16412 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1210 10:46:57.561136 16412 solver.cpp:218] Iteration 95600 (17.6061 iter/s, 5.67986s/100 iters), loss = 0.431778
I1210 10:46:57.561136 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:46:57.561136 16412 solver.cpp:237]     Train net output #1: loss = 0.431778 (* 1 = 0.431778 loss)
I1210 10:46:57.561136 16412 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1210 10:47:03.243031 16412 solver.cpp:218] Iteration 95700 (17.6026 iter/s, 5.68097s/100 iters), loss = 0.400541
I1210 10:47:03.243031 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:47:03.243031 16412 solver.cpp:237]     Train net output #1: loss = 0.400541 (* 1 = 0.400541 loss)
I1210 10:47:03.243031 16412 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1210 10:47:08.917546 16412 solver.cpp:218] Iteration 95800 (17.6242 iter/s, 5.67403s/100 iters), loss = 0.67816
I1210 10:47:08.917546 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:47:08.917546 16412 solver.cpp:237]     Train net output #1: loss = 0.67816 (* 1 = 0.67816 loss)
I1210 10:47:08.917546 16412 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1210 10:47:14.596345 16412 solver.cpp:218] Iteration 95900 (17.6112 iter/s, 5.67819s/100 iters), loss = 0.499704
I1210 10:47:14.596345 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:47:14.596345 16412 solver.cpp:237]     Train net output #1: loss = 0.499704 (* 1 = 0.499704 loss)
I1210 10:47:14.596345 16412 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1210 10:47:19.996778  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:47:20.219818 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_96000.caffemodel
I1210 10:47:20.234817 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_96000.solverstate
I1210 10:47:20.238817 16412 solver.cpp:330] Iteration 96000, Testing net (#0)
I1210 10:47:20.238817 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:47:21.606904 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:47:21.660903 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6817
I1210 10:47:21.660903 16412 solver.cpp:397]     Test net output #1: loss = 1.16498 (* 1 = 1.16498 loss)
I1210 10:47:21.715908 16412 solver.cpp:218] Iteration 96000 (14.0468 iter/s, 7.11907s/100 iters), loss = 0.437604
I1210 10:47:21.715908 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:47:21.715908 16412 solver.cpp:237]     Train net output #1: loss = 0.437604 (* 1 = 0.437604 loss)
I1210 10:47:21.715908 16412 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1210 10:47:27.390337 16412 solver.cpp:218] Iteration 96100 (17.6242 iter/s, 5.67401s/100 iters), loss = 0.51092
I1210 10:47:27.390337 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1210 10:47:27.390337 16412 solver.cpp:237]     Train net output #1: loss = 0.51092 (* 1 = 0.51092 loss)
I1210 10:47:27.390337 16412 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1210 10:47:33.048758 16412 solver.cpp:218] Iteration 96200 (17.6717 iter/s, 5.65877s/100 iters), loss = 0.411476
I1210 10:47:33.048758 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:47:33.048758 16412 solver.cpp:237]     Train net output #1: loss = 0.411476 (* 1 = 0.411476 loss)
I1210 10:47:33.048758 16412 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1210 10:47:38.717156 16412 solver.cpp:218] Iteration 96300 (17.6444 iter/s, 5.66751s/100 iters), loss = 0.482258
I1210 10:47:38.717156 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:47:38.717156 16412 solver.cpp:237]     Train net output #1: loss = 0.482258 (* 1 = 0.482258 loss)
I1210 10:47:38.717156 16412 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1210 10:47:44.388598 16412 solver.cpp:218] Iteration 96400 (17.6343 iter/s, 5.67076s/100 iters), loss = 0.430877
I1210 10:47:44.388598 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:47:44.388598 16412 solver.cpp:237]     Train net output #1: loss = 0.430877 (* 1 = 0.430877 loss)
I1210 10:47:44.388598 16412 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1210 10:47:49.774227  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:47:49.997272 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_96500.caffemodel
I1210 10:47:50.014273 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_96500.solverstate
I1210 10:47:50.018273 16412 solver.cpp:330] Iteration 96500, Testing net (#0)
I1210 10:47:50.019273 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:47:51.386868 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:47:51.439369 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6844
I1210 10:47:51.439369 16412 solver.cpp:397]     Test net output #1: loss = 1.16018 (* 1 = 1.16018 loss)
I1210 10:47:51.494390 16412 solver.cpp:218] Iteration 96500 (14.074 iter/s, 7.10528s/100 iters), loss = 0.475023
I1210 10:47:51.494390 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:47:51.494390 16412 solver.cpp:237]     Train net output #1: loss = 0.475023 (* 1 = 0.475023 loss)
I1210 10:47:51.494390 16412 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1210 10:47:57.164803 16412 solver.cpp:218] Iteration 96600 (17.6354 iter/s, 5.67041s/100 iters), loss = 0.38961
I1210 10:47:57.164803 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:47:57.164803 16412 solver.cpp:237]     Train net output #1: loss = 0.38961 (* 1 = 0.38961 loss)
I1210 10:47:57.164803 16412 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1210 10:48:02.833295 16412 solver.cpp:218] Iteration 96700 (17.6424 iter/s, 5.66817s/100 iters), loss = 0.391737
I1210 10:48:02.833295 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:48:02.833295 16412 solver.cpp:237]     Train net output #1: loss = 0.391737 (* 1 = 0.391737 loss)
I1210 10:48:02.834295 16412 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1210 10:48:08.507654 16412 solver.cpp:218] Iteration 96800 (17.626 iter/s, 5.67345s/100 iters), loss = 0.467548
I1210 10:48:08.507654 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:48:08.507654 16412 solver.cpp:237]     Train net output #1: loss = 0.467548 (* 1 = 0.467548 loss)
I1210 10:48:08.507654 16412 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1210 10:48:14.179080 16412 solver.cpp:218] Iteration 96900 (17.6347 iter/s, 5.67064s/100 iters), loss = 0.407432
I1210 10:48:14.179080 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:48:14.179080 16412 solver.cpp:237]     Train net output #1: loss = 0.407432 (* 1 = 0.407432 loss)
I1210 10:48:14.179080 16412 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1210 10:48:19.569562  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:48:19.790575 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_97000.caffemodel
I1210 10:48:19.804580 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_97000.solverstate
I1210 10:48:19.808580 16412 solver.cpp:330] Iteration 97000, Testing net (#0)
I1210 10:48:19.808580 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:48:21.177717 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:48:21.231727 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6855
I1210 10:48:21.231727 16412 solver.cpp:397]     Test net output #1: loss = 1.16556 (* 1 = 1.16556 loss)
I1210 10:48:21.286725 16412 solver.cpp:218] Iteration 97000 (14.0694 iter/s, 7.10761s/100 iters), loss = 0.411081
I1210 10:48:21.287225 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:48:21.287225 16412 solver.cpp:237]     Train net output #1: loss = 0.411081 (* 1 = 0.411081 loss)
I1210 10:48:21.287225 16412 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1210 10:48:26.956156 16412 solver.cpp:218] Iteration 97100 (17.6389 iter/s, 5.66928s/100 iters), loss = 0.458197
I1210 10:48:26.956156 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:48:26.956156 16412 solver.cpp:237]     Train net output #1: loss = 0.458197 (* 1 = 0.458197 loss)
I1210 10:48:26.956156 16412 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1210 10:48:32.614477 16412 solver.cpp:218] Iteration 97200 (17.6762 iter/s, 5.65733s/100 iters), loss = 0.382524
I1210 10:48:32.614477 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:48:32.614477 16412 solver.cpp:237]     Train net output #1: loss = 0.382524 (* 1 = 0.382524 loss)
I1210 10:48:32.614477 16412 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1210 10:48:38.279053 16412 solver.cpp:218] Iteration 97300 (17.6534 iter/s, 5.66464s/100 iters), loss = 0.56376
I1210 10:48:38.279053 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:48:38.279053 16412 solver.cpp:237]     Train net output #1: loss = 0.56376 (* 1 = 0.56376 loss)
I1210 10:48:38.279053 16412 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1210 10:48:43.948540 16412 solver.cpp:218] Iteration 97400 (17.6392 iter/s, 5.66919s/100 iters), loss = 0.402331
I1210 10:48:43.948540 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:48:43.948540 16412 solver.cpp:237]     Train net output #1: loss = 0.402331 (* 1 = 0.402331 loss)
I1210 10:48:43.948540 16412 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1210 10:48:49.337955  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:48:49.560971 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_97500.caffemodel
I1210 10:48:49.573971 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_97500.solverstate
I1210 10:48:49.578971 16412 solver.cpp:330] Iteration 97500, Testing net (#0)
I1210 10:48:49.578971 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:48:50.949126 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:48:51.002619 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6859
I1210 10:48:51.002619 16412 solver.cpp:397]     Test net output #1: loss = 1.17412 (* 1 = 1.17412 loss)
I1210 10:48:51.056120 16412 solver.cpp:218] Iteration 97500 (14.0711 iter/s, 7.10677s/100 iters), loss = 0.375156
I1210 10:48:51.056120 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:48:51.056120 16412 solver.cpp:237]     Train net output #1: loss = 0.375156 (* 1 = 0.375156 loss)
I1210 10:48:51.056120 16412 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1210 10:48:56.726505 16412 solver.cpp:218] Iteration 97600 (17.6365 iter/s, 5.67007s/100 iters), loss = 0.353434
I1210 10:48:56.726505 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:48:56.726505 16412 solver.cpp:237]     Train net output #1: loss = 0.353434 (* 1 = 0.353434 loss)
I1210 10:48:56.726505 16412 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1210 10:49:02.401924 16412 solver.cpp:218] Iteration 97700 (17.6223 iter/s, 5.67462s/100 iters), loss = 0.410988
I1210 10:49:02.401924 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:49:02.401924 16412 solver.cpp:237]     Train net output #1: loss = 0.410988 (* 1 = 0.410988 loss)
I1210 10:49:02.401924 16412 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1210 10:49:08.075371 16412 solver.cpp:218] Iteration 97800 (17.6275 iter/s, 5.67297s/100 iters), loss = 0.516161
I1210 10:49:08.075371 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:49:08.075371 16412 solver.cpp:237]     Train net output #1: loss = 0.516161 (* 1 = 0.516161 loss)
I1210 10:49:08.075371 16412 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1210 10:49:13.797272 16412 solver.cpp:218] Iteration 97900 (17.4776 iter/s, 5.72162s/100 iters), loss = 0.433072
I1210 10:49:13.797272 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:49:13.797773 16412 solver.cpp:237]     Train net output #1: loss = 0.433072 (* 1 = 0.433072 loss)
I1210 10:49:13.797773 16412 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1210 10:49:19.290354  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:49:19.548395 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_98000.caffemodel
I1210 10:49:19.579392 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_98000.solverstate
I1210 10:49:19.586395 16412 solver.cpp:330] Iteration 98000, Testing net (#0)
I1210 10:49:19.586395 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:49:20.979527 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:49:21.032533 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6848
I1210 10:49:21.033535 16412 solver.cpp:397]     Test net output #1: loss = 1.1663 (* 1 = 1.1663 loss)
I1210 10:49:21.087532 16412 solver.cpp:218] Iteration 98000 (13.7182 iter/s, 7.28956s/100 iters), loss = 0.370947
I1210 10:49:21.087532 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:49:21.087532 16412 solver.cpp:237]     Train net output #1: loss = 0.370947 (* 1 = 0.370947 loss)
I1210 10:49:21.087532 16412 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1210 10:49:26.770066 16412 solver.cpp:218] Iteration 98100 (17.5999 iter/s, 5.68186s/100 iters), loss = 0.43839
I1210 10:49:26.770066 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:49:26.770066 16412 solver.cpp:237]     Train net output #1: loss = 0.43839 (* 1 = 0.43839 loss)
I1210 10:49:26.770066 16412 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1210 10:49:32.448494 16412 solver.cpp:218] Iteration 98200 (17.6094 iter/s, 5.67878s/100 iters), loss = 0.359015
I1210 10:49:32.449506 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:49:32.449506 16412 solver.cpp:237]     Train net output #1: loss = 0.359015 (* 1 = 0.359015 loss)
I1210 10:49:32.449506 16412 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1210 10:49:38.237114 16412 solver.cpp:218] Iteration 98300 (17.278 iter/s, 5.78769s/100 iters), loss = 0.49227
I1210 10:49:38.237114 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:49:38.237114 16412 solver.cpp:237]     Train net output #1: loss = 0.49227 (* 1 = 0.49227 loss)
I1210 10:49:38.237114 16412 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1210 10:49:43.942884 16412 solver.cpp:218] Iteration 98400 (17.5287 iter/s, 5.70492s/100 iters), loss = 0.443072
I1210 10:49:43.942884 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:49:43.942884 16412 solver.cpp:237]     Train net output #1: loss = 0.443072 (* 1 = 0.443072 loss)
I1210 10:49:43.942884 16412 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1210 10:49:49.329339  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:49:49.551865 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_98500.caffemodel
I1210 10:49:49.566375 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_98500.solverstate
I1210 10:49:49.570374 16412 solver.cpp:330] Iteration 98500, Testing net (#0)
I1210 10:49:49.571374 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:49:50.938525 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:49:50.992538 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6855
I1210 10:49:50.992538 16412 solver.cpp:397]     Test net output #1: loss = 1.1756 (* 1 = 1.1756 loss)
I1210 10:49:51.046531 16412 solver.cpp:218] Iteration 98500 (14.0772 iter/s, 7.10367s/100 iters), loss = 0.321458
I1210 10:49:51.046531 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:49:51.046531 16412 solver.cpp:237]     Train net output #1: loss = 0.321458 (* 1 = 0.321458 loss)
I1210 10:49:51.046531 16412 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1210 10:49:56.744101 16412 solver.cpp:218] Iteration 98600 (17.5523 iter/s, 5.69727s/100 iters), loss = 0.457309
I1210 10:49:56.744101 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:49:56.744101 16412 solver.cpp:237]     Train net output #1: loss = 0.457309 (* 1 = 0.457309 loss)
I1210 10:49:56.744101 16412 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1210 10:50:02.444519 16412 solver.cpp:218] Iteration 98700 (17.5442 iter/s, 5.6999s/100 iters), loss = 0.265208
I1210 10:50:02.444519 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 10:50:02.444519 16412 solver.cpp:237]     Train net output #1: loss = 0.265208 (* 1 = 0.265208 loss)
I1210 10:50:02.444519 16412 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1210 10:50:08.135030 16412 solver.cpp:218] Iteration 98800 (17.5759 iter/s, 5.6896s/100 iters), loss = 0.513243
I1210 10:50:08.135030 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:50:08.135030 16412 solver.cpp:237]     Train net output #1: loss = 0.513243 (* 1 = 0.513243 loss)
I1210 10:50:08.135030 16412 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1210 10:50:13.825436 16412 solver.cpp:218] Iteration 98900 (17.5739 iter/s, 5.69026s/100 iters), loss = 0.429225
I1210 10:50:13.825436 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:50:13.825436 16412 solver.cpp:237]     Train net output #1: loss = 0.429225 (* 1 = 0.429225 loss)
I1210 10:50:13.825436 16412 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1210 10:50:19.233891  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:50:19.457901 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_99000.caffemodel
I1210 10:50:19.471901 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_99000.solverstate
I1210 10:50:19.476902 16412 solver.cpp:330] Iteration 99000, Testing net (#0)
I1210 10:50:19.476902 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:50:20.844017 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:50:20.898020 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6863
I1210 10:50:20.898020 16412 solver.cpp:397]     Test net output #1: loss = 1.17731 (* 1 = 1.17731 loss)
I1210 10:50:20.951022 16412 solver.cpp:218] Iteration 99000 (14.0343 iter/s, 7.12541s/100 iters), loss = 0.36832
I1210 10:50:20.951022 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:50:20.951022 16412 solver.cpp:237]     Train net output #1: loss = 0.368321 (* 1 = 0.368321 loss)
I1210 10:50:20.951022 16412 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1210 10:50:26.656491 16412 solver.cpp:218] Iteration 99100 (17.5293 iter/s, 5.70475s/100 iters), loss = 0.360899
I1210 10:50:26.656491 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:50:26.656491 16412 solver.cpp:237]     Train net output #1: loss = 0.360899 (* 1 = 0.360899 loss)
I1210 10:50:26.656491 16412 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1210 10:50:32.328380 16412 solver.cpp:218] Iteration 99200 (17.6324 iter/s, 5.67138s/100 iters), loss = 0.364823
I1210 10:50:32.328884 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:50:32.328884 16412 solver.cpp:237]     Train net output #1: loss = 0.364823 (* 1 = 0.364823 loss)
I1210 10:50:32.328884 16412 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1210 10:50:38.019412 16412 solver.cpp:218] Iteration 99300 (17.5719 iter/s, 5.69089s/100 iters), loss = 0.458499
I1210 10:50:38.019412 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:50:38.019412 16412 solver.cpp:237]     Train net output #1: loss = 0.458499 (* 1 = 0.458499 loss)
I1210 10:50:38.019412 16412 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1210 10:50:43.707031 16412 solver.cpp:218] Iteration 99400 (17.5841 iter/s, 5.68696s/100 iters), loss = 0.479605
I1210 10:50:43.707031 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:50:43.707031 16412 solver.cpp:237]     Train net output #1: loss = 0.479605 (* 1 = 0.479605 loss)
I1210 10:50:43.707031 16412 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1210 10:50:49.114526  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:50:49.337530 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_99500.caffemodel
I1210 10:50:49.352535 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_99500.solverstate
I1210 10:50:49.357537 16412 solver.cpp:330] Iteration 99500, Testing net (#0)
I1210 10:50:49.357537 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:50:50.731204 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:50:50.784706 16412 solver.cpp:397]     Test net output #0: accuracy = 0.687
I1210 10:50:50.784706 16412 solver.cpp:397]     Test net output #1: loss = 1.17679 (* 1 = 1.17679 loss)
I1210 10:50:50.839217 16412 solver.cpp:218] Iteration 99500 (14.0229 iter/s, 7.13121s/100 iters), loss = 0.327554
I1210 10:50:50.839217 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:50:50.839217 16412 solver.cpp:237]     Train net output #1: loss = 0.327554 (* 1 = 0.327554 loss)
I1210 10:50:50.839217 16412 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1210 10:50:56.510202 16412 solver.cpp:218] Iteration 99600 (17.6347 iter/s, 5.67063s/100 iters), loss = 0.387253
I1210 10:50:56.510202 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:50:56.510202 16412 solver.cpp:237]     Train net output #1: loss = 0.387253 (* 1 = 0.387253 loss)
I1210 10:50:56.510202 16412 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1210 10:51:02.200701 16412 solver.cpp:218] Iteration 99700 (17.5722 iter/s, 5.69081s/100 iters), loss = 0.259656
I1210 10:51:02.200701 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:51:02.200701 16412 solver.cpp:237]     Train net output #1: loss = 0.259656 (* 1 = 0.259656 loss)
I1210 10:51:02.200701 16412 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1210 10:51:07.907230 16412 solver.cpp:218] Iteration 99800 (17.5252 iter/s, 5.70607s/100 iters), loss = 0.477793
I1210 10:51:07.908231 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:51:07.908231 16412 solver.cpp:237]     Train net output #1: loss = 0.477793 (* 1 = 0.477793 loss)
I1210 10:51:07.908231 16412 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1210 10:51:13.581776 16412 solver.cpp:218] Iteration 99900 (17.6266 iter/s, 5.67325s/100 iters), loss = 0.430045
I1210 10:51:13.581776 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:51:13.581776 16412 solver.cpp:237]     Train net output #1: loss = 0.430045 (* 1 = 0.430045 loss)
I1210 10:51:13.581776 16412 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1210 10:51:19.007270  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:51:19.234289 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_100000.caffemodel
I1210 10:51:19.249263 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_100000.solverstate
I1210 10:51:19.254257 16412 solver.cpp:330] Iteration 100000, Testing net (#0)
I1210 10:51:19.254257 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:51:20.638371 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:51:20.692375 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6854
I1210 10:51:20.692375 16412 solver.cpp:397]     Test net output #1: loss = 1.18955 (* 1 = 1.18955 loss)
I1210 10:51:20.746378 16412 solver.cpp:218] Iteration 100000 (13.9577 iter/s, 7.16448s/100 iters), loss = 0.341153
I1210 10:51:20.746378 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:51:20.746378 16412 solver.cpp:237]     Train net output #1: loss = 0.341153 (* 1 = 0.341153 loss)
I1210 10:51:20.746378 16412 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1210 10:51:26.440701 16412 solver.cpp:218] Iteration 100100 (17.5635 iter/s, 5.69361s/100 iters), loss = 0.288731
I1210 10:51:26.440701 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:51:26.440701 16412 solver.cpp:237]     Train net output #1: loss = 0.288732 (* 1 = 0.288732 loss)
I1210 10:51:26.441201 16412 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1210 10:51:32.129528 16412 solver.cpp:218] Iteration 100200 (17.5808 iter/s, 5.68803s/100 iters), loss = 0.381686
I1210 10:51:32.129528 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:51:32.129528 16412 solver.cpp:237]     Train net output #1: loss = 0.381686 (* 1 = 0.381686 loss)
I1210 10:51:32.129528 16412 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1210 10:51:37.845320 16412 solver.cpp:218] Iteration 100300 (17.4951 iter/s, 5.7159s/100 iters), loss = 0.495566
I1210 10:51:37.845320 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:51:37.845320 16412 solver.cpp:237]     Train net output #1: loss = 0.495566 (* 1 = 0.495566 loss)
I1210 10:51:37.845320 16412 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1210 10:51:43.544008 16412 solver.cpp:218] Iteration 100400 (17.5495 iter/s, 5.69816s/100 iters), loss = 0.459978
I1210 10:51:43.544008 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:51:43.544008 16412 solver.cpp:237]     Train net output #1: loss = 0.459979 (* 1 = 0.459979 loss)
I1210 10:51:43.544008 16412 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1210 10:51:48.966601  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:51:49.193621 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_100500.caffemodel
I1210 10:51:49.207626 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_100500.solverstate
I1210 10:51:49.212627 16412 solver.cpp:330] Iteration 100500, Testing net (#0)
I1210 10:51:49.212627 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:51:50.586241 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:51:50.639749 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6866
I1210 10:51:50.639749 16412 solver.cpp:397]     Test net output #1: loss = 1.18345 (* 1 = 1.18345 loss)
I1210 10:51:50.693749 16412 solver.cpp:218] Iteration 100500 (13.9885 iter/s, 7.14872s/100 iters), loss = 0.383754
I1210 10:51:50.693749 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:51:50.693749 16412 solver.cpp:237]     Train net output #1: loss = 0.383754 (* 1 = 0.383754 loss)
I1210 10:51:50.693749 16412 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1210 10:51:56.379143 16412 solver.cpp:218] Iteration 100600 (17.5893 iter/s, 5.68526s/100 iters), loss = 0.382657
I1210 10:51:56.379143 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:51:56.379143 16412 solver.cpp:237]     Train net output #1: loss = 0.382657 (* 1 = 0.382657 loss)
I1210 10:51:56.379143 16412 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1210 10:52:02.061570 16412 solver.cpp:218] Iteration 100700 (17.5993 iter/s, 5.68204s/100 iters), loss = 0.285493
I1210 10:52:02.061570 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:52:02.061570 16412 solver.cpp:237]     Train net output #1: loss = 0.285493 (* 1 = 0.285493 loss)
I1210 10:52:02.061570 16412 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1210 10:52:07.793084 16412 solver.cpp:218] Iteration 100800 (17.4487 iter/s, 5.7311s/100 iters), loss = 0.486741
I1210 10:52:07.793084 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:52:07.793084 16412 solver.cpp:237]     Train net output #1: loss = 0.486741 (* 1 = 0.486741 loss)
I1210 10:52:07.793084 16412 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1210 10:52:13.636623 16412 solver.cpp:218] Iteration 100900 (17.1158 iter/s, 5.84255s/100 iters), loss = 0.372137
I1210 10:52:13.636623 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:52:13.636623 16412 solver.cpp:237]     Train net output #1: loss = 0.372137 (* 1 = 0.372137 loss)
I1210 10:52:13.636623 16412 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1210 10:52:19.184595  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:52:19.407624 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_101000.caffemodel
I1210 10:52:19.423118 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_101000.solverstate
I1210 10:52:19.427618 16412 solver.cpp:330] Iteration 101000, Testing net (#0)
I1210 10:52:19.428118 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:52:20.824216 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:52:20.879719 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6875
I1210 10:52:20.879719 16412 solver.cpp:397]     Test net output #1: loss = 1.18744 (* 1 = 1.18744 loss)
I1210 10:52:20.937731 16412 solver.cpp:218] Iteration 101000 (13.6973 iter/s, 7.3007s/100 iters), loss = 0.372465
I1210 10:52:20.937731 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:52:20.937731 16412 solver.cpp:237]     Train net output #1: loss = 0.372465 (* 1 = 0.372465 loss)
I1210 10:52:20.937731 16412 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1210 10:52:26.791522 16412 solver.cpp:218] Iteration 101100 (17.0831 iter/s, 5.85373s/100 iters), loss = 0.338541
I1210 10:52:26.791522 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:52:26.792522 16412 solver.cpp:237]     Train net output #1: loss = 0.338541 (* 1 = 0.338541 loss)
I1210 10:52:26.792522 16412 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1210 10:52:32.503985 16412 solver.cpp:218] Iteration 101200 (17.5097 iter/s, 5.71113s/100 iters), loss = 0.355992
I1210 10:52:32.503985 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:52:32.503985 16412 solver.cpp:237]     Train net output #1: loss = 0.355993 (* 1 = 0.355993 loss)
I1210 10:52:32.503985 16412 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1210 10:52:38.336463 16412 solver.cpp:218] Iteration 101300 (17.1473 iter/s, 5.83181s/100 iters), loss = 0.453346
I1210 10:52:38.336463 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:52:38.336463 16412 solver.cpp:237]     Train net output #1: loss = 0.453346 (* 1 = 0.453346 loss)
I1210 10:52:38.336463 16412 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1210 10:52:44.145172 16412 solver.cpp:218] Iteration 101400 (17.2186 iter/s, 5.80769s/100 iters), loss = 0.451598
I1210 10:52:44.145172 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:52:44.145172 16412 solver.cpp:237]     Train net output #1: loss = 0.451598 (* 1 = 0.451598 loss)
I1210 10:52:44.145172 16412 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1210 10:52:49.612181  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:52:49.842211 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_101500.caffemodel
I1210 10:52:49.858209 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_101500.solverstate
I1210 10:52:49.862210 16412 solver.cpp:330] Iteration 101500, Testing net (#0)
I1210 10:52:49.862210 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:52:51.279405 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:52:51.334411 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6851
I1210 10:52:51.334411 16412 solver.cpp:397]     Test net output #1: loss = 1.1982 (* 1 = 1.1982 loss)
I1210 10:52:51.389420 16412 solver.cpp:218] Iteration 101500 (13.804 iter/s, 7.2443s/100 iters), loss = 0.362264
I1210 10:52:51.389420 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:52:51.389420 16412 solver.cpp:237]     Train net output #1: loss = 0.362264 (* 1 = 0.362264 loss)
I1210 10:52:51.389420 16412 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1210 10:52:57.097993 16412 solver.cpp:218] Iteration 101600 (17.5182 iter/s, 5.70836s/100 iters), loss = 0.340025
I1210 10:52:57.097993 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:52:57.097993 16412 solver.cpp:237]     Train net output #1: loss = 0.340025 (* 1 = 0.340025 loss)
I1210 10:52:57.097993 16412 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1210 10:53:02.796892 16412 solver.cpp:218] Iteration 101700 (17.5484 iter/s, 5.69851s/100 iters), loss = 0.298442
I1210 10:53:02.796892 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:53:02.796892 16412 solver.cpp:237]     Train net output #1: loss = 0.298442 (* 1 = 0.298442 loss)
I1210 10:53:02.796892 16412 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1210 10:53:08.513603 16412 solver.cpp:218] Iteration 101800 (17.4942 iter/s, 5.71618s/100 iters), loss = 0.444655
I1210 10:53:08.513603 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:53:08.513603 16412 solver.cpp:237]     Train net output #1: loss = 0.444655 (* 1 = 0.444655 loss)
I1210 10:53:08.513603 16412 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1210 10:53:14.222695 16412 solver.cpp:218] Iteration 101900 (17.5188 iter/s, 5.70815s/100 iters), loss = 0.450577
I1210 10:53:14.222695 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:53:14.222695 16412 solver.cpp:237]     Train net output #1: loss = 0.450577 (* 1 = 0.450577 loss)
I1210 10:53:14.222695 16412 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1210 10:53:19.645546  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:53:19.869560 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_102000.caffemodel
I1210 10:53:19.883561 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_102000.solverstate
I1210 10:53:19.888569 16412 solver.cpp:330] Iteration 102000, Testing net (#0)
I1210 10:53:19.888569 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:53:21.262709 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:53:21.316710 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6842
I1210 10:53:21.316710 16412 solver.cpp:397]     Test net output #1: loss = 1.20181 (* 1 = 1.20181 loss)
I1210 10:53:21.370715 16412 solver.cpp:218] Iteration 102000 (13.9912 iter/s, 7.14736s/100 iters), loss = 0.283612
I1210 10:53:21.370715 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:53:21.370715 16412 solver.cpp:237]     Train net output #1: loss = 0.283612 (* 1 = 0.283612 loss)
I1210 10:53:21.370715 16412 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1210 10:53:27.061095 16412 solver.cpp:218] Iteration 102100 (17.574 iter/s, 5.69022s/100 iters), loss = 0.394103
I1210 10:53:27.061095 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:53:27.061095 16412 solver.cpp:237]     Train net output #1: loss = 0.394103 (* 1 = 0.394103 loss)
I1210 10:53:27.061095 16412 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1210 10:53:32.747587 16412 solver.cpp:218] Iteration 102200 (17.5851 iter/s, 5.68664s/100 iters), loss = 0.346776
I1210 10:53:32.748592 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:53:32.748592 16412 solver.cpp:237]     Train net output #1: loss = 0.346776 (* 1 = 0.346776 loss)
I1210 10:53:32.748592 16412 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1210 10:53:38.421106 16412 solver.cpp:218] Iteration 102300 (17.6283 iter/s, 5.67268s/100 iters), loss = 0.528687
I1210 10:53:38.421106 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:53:38.421106 16412 solver.cpp:237]     Train net output #1: loss = 0.528687 (* 1 = 0.528687 loss)
I1210 10:53:38.421106 16412 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1210 10:53:44.100610 16412 solver.cpp:218] Iteration 102400 (17.611 iter/s, 5.67827s/100 iters), loss = 0.448393
I1210 10:53:44.100610 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:53:44.100610 16412 solver.cpp:237]     Train net output #1: loss = 0.448393 (* 1 = 0.448393 loss)
I1210 10:53:44.100610 16412 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1210 10:53:49.497090  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:53:49.721112 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_102500.caffemodel
I1210 10:53:49.735111 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_102500.solverstate
I1210 10:53:49.740113 16412 solver.cpp:330] Iteration 102500, Testing net (#0)
I1210 10:53:49.740113 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:53:51.105233 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:53:51.160235 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6878
I1210 10:53:51.160235 16412 solver.cpp:397]     Test net output #1: loss = 1.19539 (* 1 = 1.19539 loss)
I1210 10:53:51.214236 16412 solver.cpp:218] Iteration 102500 (14.0584 iter/s, 7.11321s/100 iters), loss = 0.345956
I1210 10:53:51.214236 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:53:51.214236 16412 solver.cpp:237]     Train net output #1: loss = 0.345956 (* 1 = 0.345956 loss)
I1210 10:53:51.214236 16412 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1210 10:53:56.909759 16412 solver.cpp:218] Iteration 102600 (17.5589 iter/s, 5.69512s/100 iters), loss = 0.297955
I1210 10:53:56.909759 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:53:56.909759 16412 solver.cpp:237]     Train net output #1: loss = 0.297956 (* 1 = 0.297956 loss)
I1210 10:53:56.909759 16412 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1210 10:54:02.600203 16412 solver.cpp:218] Iteration 102700 (17.5736 iter/s, 5.69036s/100 iters), loss = 0.352744
I1210 10:54:02.600203 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:54:02.600203 16412 solver.cpp:237]     Train net output #1: loss = 0.352744 (* 1 = 0.352744 loss)
I1210 10:54:02.600203 16412 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1210 10:54:08.304708 16412 solver.cpp:218] Iteration 102800 (17.5331 iter/s, 5.70351s/100 iters), loss = 0.438483
I1210 10:54:08.304708 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:54:08.304708 16412 solver.cpp:237]     Train net output #1: loss = 0.438483 (* 1 = 0.438483 loss)
I1210 10:54:08.304708 16412 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1210 10:54:13.982102 16412 solver.cpp:218] Iteration 102900 (17.6151 iter/s, 5.67696s/100 iters), loss = 0.395633
I1210 10:54:13.982102 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:54:13.982102 16412 solver.cpp:237]     Train net output #1: loss = 0.395633 (* 1 = 0.395633 loss)
I1210 10:54:13.982102 16412 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1210 10:54:19.439575  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:54:19.662590 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_103000.caffemodel
I1210 10:54:19.675592 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_103000.solverstate
I1210 10:54:19.680603 16412 solver.cpp:330] Iteration 103000, Testing net (#0)
I1210 10:54:19.680603 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:54:21.056995 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:54:21.109001 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6872
I1210 10:54:21.109001 16412 solver.cpp:397]     Test net output #1: loss = 1.19932 (* 1 = 1.19932 loss)
I1210 10:54:21.164005 16412 solver.cpp:218] Iteration 103000 (13.9251 iter/s, 7.18126s/100 iters), loss = 0.327783
I1210 10:54:21.164005 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:54:21.164005 16412 solver.cpp:237]     Train net output #1: loss = 0.327783 (* 1 = 0.327783 loss)
I1210 10:54:21.164005 16412 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1210 10:54:26.983719 16412 solver.cpp:218] Iteration 103100 (17.1841 iter/s, 5.81932s/100 iters), loss = 0.318961
I1210 10:54:26.983719 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:54:26.983719 16412 solver.cpp:237]     Train net output #1: loss = 0.318961 (* 1 = 0.318961 loss)
I1210 10:54:26.983719 16412 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1210 10:54:32.695184 16412 solver.cpp:218] Iteration 103200 (17.5097 iter/s, 5.71111s/100 iters), loss = 0.293118
I1210 10:54:32.695184 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:54:32.695184 16412 solver.cpp:237]     Train net output #1: loss = 0.293118 (* 1 = 0.293118 loss)
I1210 10:54:32.695184 16412 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1210 10:54:38.377637 16412 solver.cpp:218] Iteration 103300 (17.5979 iter/s, 5.6825s/100 iters), loss = 0.48524
I1210 10:54:38.377637 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:54:38.377637 16412 solver.cpp:237]     Train net output #1: loss = 0.48524 (* 1 = 0.48524 loss)
I1210 10:54:38.377637 16412 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1210 10:54:44.082322 16412 solver.cpp:218] Iteration 103400 (17.5325 iter/s, 5.70371s/100 iters), loss = 0.434865
I1210 10:54:44.082322 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:54:44.082322 16412 solver.cpp:237]     Train net output #1: loss = 0.434865 (* 1 = 0.434865 loss)
I1210 10:54:44.082322 16412 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1210 10:54:49.495700  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:54:49.720712 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_103500.caffemodel
I1210 10:54:49.735713 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_103500.solverstate
I1210 10:54:49.739712 16412 solver.cpp:330] Iteration 103500, Testing net (#0)
I1210 10:54:49.739712 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:54:51.113800 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:54:51.169303 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6831
I1210 10:54:51.169303 16412 solver.cpp:397]     Test net output #1: loss = 1.20084 (* 1 = 1.20084 loss)
I1210 10:54:51.225813 16412 solver.cpp:218] Iteration 103500 (13.9999 iter/s, 7.14293s/100 iters), loss = 0.278203
I1210 10:54:51.225813 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:54:51.225813 16412 solver.cpp:237]     Train net output #1: loss = 0.278203 (* 1 = 0.278203 loss)
I1210 10:54:51.225813 16412 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1210 10:54:56.944269 16412 solver.cpp:218] Iteration 103600 (17.4886 iter/s, 5.71802s/100 iters), loss = 0.261008
I1210 10:54:56.944269 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 10:54:56.944269 16412 solver.cpp:237]     Train net output #1: loss = 0.261008 (* 1 = 0.261008 loss)
I1210 10:54:56.944269 16412 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1210 10:55:02.647763 16412 solver.cpp:218] Iteration 103700 (17.533 iter/s, 5.70354s/100 iters), loss = 0.291817
I1210 10:55:02.647763 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:55:02.647763 16412 solver.cpp:237]     Train net output #1: loss = 0.291817 (* 1 = 0.291817 loss)
I1210 10:55:02.647763 16412 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1210 10:55:08.338093 16412 solver.cpp:218] Iteration 103800 (17.5761 iter/s, 5.68953s/100 iters), loss = 0.440581
I1210 10:55:08.338093 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1210 10:55:08.338093 16412 solver.cpp:237]     Train net output #1: loss = 0.440581 (* 1 = 0.440581 loss)
I1210 10:55:08.338093 16412 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1210 10:55:14.034142 16412 solver.cpp:218] Iteration 103900 (17.5558 iter/s, 5.69614s/100 iters), loss = 0.42458
I1210 10:55:14.035146 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:55:14.035146 16412 solver.cpp:237]     Train net output #1: loss = 0.42458 (* 1 = 0.42458 loss)
I1210 10:55:14.035146 16412 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1210 10:55:19.461529  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:55:19.687546 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_104000.caffemodel
I1210 10:55:19.702545 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_104000.solverstate
I1210 10:55:19.706545 16412 solver.cpp:330] Iteration 104000, Testing net (#0)
I1210 10:55:19.706545 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:55:21.078142 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:55:21.131645 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6851
I1210 10:55:21.131645 16412 solver.cpp:397]     Test net output #1: loss = 1.2119 (* 1 = 1.2119 loss)
I1210 10:55:21.185649 16412 solver.cpp:218] Iteration 104000 (13.9852 iter/s, 7.15043s/100 iters), loss = 0.231381
I1210 10:55:21.185649 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 10:55:21.185649 16412 solver.cpp:237]     Train net output #1: loss = 0.231381 (* 1 = 0.231381 loss)
I1210 10:55:21.185649 16412 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1210 10:55:26.874089 16412 solver.cpp:218] Iteration 104100 (17.5816 iter/s, 5.68775s/100 iters), loss = 0.321125
I1210 10:55:26.874089 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:55:26.874089 16412 solver.cpp:237]     Train net output #1: loss = 0.321125 (* 1 = 0.321125 loss)
I1210 10:55:26.874089 16412 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1210 10:55:32.565934 16412 solver.cpp:218] Iteration 104200 (17.571 iter/s, 5.6912s/100 iters), loss = 0.269579
I1210 10:55:32.565934 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:55:32.565934 16412 solver.cpp:237]     Train net output #1: loss = 0.269579 (* 1 = 0.269579 loss)
I1210 10:55:32.565934 16412 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1210 10:55:38.262434 16412 solver.cpp:218] Iteration 104300 (17.5549 iter/s, 5.69642s/100 iters), loss = 0.499808
I1210 10:55:38.262434 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:55:38.262434 16412 solver.cpp:237]     Train net output #1: loss = 0.499808 (* 1 = 0.499808 loss)
I1210 10:55:38.262434 16412 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1210 10:55:43.956306 16412 solver.cpp:218] Iteration 104400 (17.5641 iter/s, 5.69342s/100 iters), loss = 0.28497
I1210 10:55:43.956306 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:55:43.956306 16412 solver.cpp:237]     Train net output #1: loss = 0.28497 (* 1 = 0.28497 loss)
I1210 10:55:43.956306 16412 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1210 10:55:49.355691  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:55:49.580225 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_104500.caffemodel
I1210 10:55:49.593730 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_104500.solverstate
I1210 10:55:49.598731 16412 solver.cpp:330] Iteration 104500, Testing net (#0)
I1210 10:55:49.598731 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:55:50.970844 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:55:51.025851 16412 solver.cpp:397]     Test net output #0: accuracy = 0.682
I1210 10:55:51.025851 16412 solver.cpp:397]     Test net output #1: loss = 1.21425 (* 1 = 1.21425 loss)
I1210 10:55:51.079850 16412 solver.cpp:218] Iteration 104500 (14.0392 iter/s, 7.12292s/100 iters), loss = 0.359561
I1210 10:55:51.080351 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:55:51.080351 16412 solver.cpp:237]     Train net output #1: loss = 0.359562 (* 1 = 0.359562 loss)
I1210 10:55:51.080351 16412 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1210 10:55:56.762358 16412 solver.cpp:218] Iteration 104600 (17.5984 iter/s, 5.68234s/100 iters), loss = 0.297573
I1210 10:55:56.762358 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:55:56.762358 16412 solver.cpp:237]     Train net output #1: loss = 0.297573 (* 1 = 0.297573 loss)
I1210 10:55:56.762358 16412 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1210 10:56:02.430780 16412 solver.cpp:218] Iteration 104700 (17.6436 iter/s, 5.66778s/100 iters), loss = 0.324058
I1210 10:56:02.430780 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:56:02.430780 16412 solver.cpp:237]     Train net output #1: loss = 0.324058 (* 1 = 0.324058 loss)
I1210 10:56:02.430780 16412 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1210 10:56:08.106153 16412 solver.cpp:218] Iteration 104800 (17.6216 iter/s, 5.67484s/100 iters), loss = 0.496913
I1210 10:56:08.106153 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:56:08.106153 16412 solver.cpp:237]     Train net output #1: loss = 0.496913 (* 1 = 0.496913 loss)
I1210 10:56:08.106153 16412 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1210 10:56:13.778076 16412 solver.cpp:218] Iteration 104900 (17.6323 iter/s, 5.67141s/100 iters), loss = 0.332272
I1210 10:56:13.778076 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:56:13.778076 16412 solver.cpp:237]     Train net output #1: loss = 0.332272 (* 1 = 0.332272 loss)
I1210 10:56:13.778076 16412 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1210 10:56:19.188951  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:56:19.411967 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_105000.caffemodel
I1210 10:56:19.426966 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_105000.solverstate
I1210 10:56:19.431967 16412 solver.cpp:330] Iteration 105000, Testing net (#0)
I1210 10:56:19.431967 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:56:20.808424 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:56:20.861416 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6849
I1210 10:56:20.861416 16412 solver.cpp:397]     Test net output #1: loss = 1.21014 (* 1 = 1.21014 loss)
I1210 10:56:20.916434 16412 solver.cpp:218] Iteration 105000 (14.0086 iter/s, 7.13845s/100 iters), loss = 0.222207
I1210 10:56:20.917435 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 10:56:20.917435 16412 solver.cpp:237]     Train net output #1: loss = 0.222208 (* 1 = 0.222208 loss)
I1210 10:56:20.917435 16412 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1210 10:56:26.617869 16412 solver.cpp:218] Iteration 105100 (17.5425 iter/s, 5.70044s/100 iters), loss = 0.23214
I1210 10:56:26.617869 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 10:56:26.617869 16412 solver.cpp:237]     Train net output #1: loss = 0.23214 (* 1 = 0.23214 loss)
I1210 10:56:26.617869 16412 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1210 10:56:32.300005 16412 solver.cpp:218] Iteration 105200 (17.6016 iter/s, 5.68129s/100 iters), loss = 0.222353
I1210 10:56:32.300005 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 10:56:32.300005 16412 solver.cpp:237]     Train net output #1: loss = 0.222353 (* 1 = 0.222353 loss)
I1210 10:56:32.300005 16412 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1210 10:56:37.994448 16412 solver.cpp:218] Iteration 105300 (17.5618 iter/s, 5.69419s/100 iters), loss = 0.41444
I1210 10:56:37.994448 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:56:37.994448 16412 solver.cpp:237]     Train net output #1: loss = 0.41444 (* 1 = 0.41444 loss)
I1210 10:56:37.994448 16412 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1210 10:56:43.667423 16412 solver.cpp:218] Iteration 105400 (17.6266 iter/s, 5.67324s/100 iters), loss = 0.411297
I1210 10:56:43.667423 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:56:43.667423 16412 solver.cpp:237]     Train net output #1: loss = 0.411297 (* 1 = 0.411297 loss)
I1210 10:56:43.667423 16412 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1210 10:56:49.071979  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:56:49.295500 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_105500.caffemodel
I1210 10:56:49.309005 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_105500.solverstate
I1210 10:56:49.314005 16412 solver.cpp:330] Iteration 105500, Testing net (#0)
I1210 10:56:49.314005 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:56:50.694103 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:56:50.747105 16412 solver.cpp:397]     Test net output #0: accuracy = 0.685
I1210 10:56:50.747105 16412 solver.cpp:397]     Test net output #1: loss = 1.2119 (* 1 = 1.2119 loss)
I1210 10:56:50.801111 16412 solver.cpp:218] Iteration 105500 (14.0194 iter/s, 7.13297s/100 iters), loss = 0.282051
I1210 10:56:50.801111 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:56:50.801111 16412 solver.cpp:237]     Train net output #1: loss = 0.282051 (* 1 = 0.282051 loss)
I1210 10:56:50.801111 16412 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1210 10:56:56.498579 16412 solver.cpp:218] Iteration 105600 (17.5535 iter/s, 5.69687s/100 iters), loss = 0.341068
I1210 10:56:56.498579 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:56:56.498579 16412 solver.cpp:237]     Train net output #1: loss = 0.341068 (* 1 = 0.341068 loss)
I1210 10:56:56.498579 16412 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1210 10:57:02.195554 16412 solver.cpp:218] Iteration 105700 (17.555 iter/s, 5.69637s/100 iters), loss = 0.247588
I1210 10:57:02.195554 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:57:02.195554 16412 solver.cpp:237]     Train net output #1: loss = 0.247588 (* 1 = 0.247588 loss)
I1210 10:57:02.195554 16412 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1210 10:57:07.890115 16412 solver.cpp:218] Iteration 105800 (17.562 iter/s, 5.69411s/100 iters), loss = 0.395687
I1210 10:57:07.890115 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:57:07.890115 16412 solver.cpp:237]     Train net output #1: loss = 0.395687 (* 1 = 0.395687 loss)
I1210 10:57:07.890115 16412 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1210 10:57:13.591142 16412 solver.cpp:218] Iteration 105900 (17.5422 iter/s, 5.70054s/100 iters), loss = 0.359257
I1210 10:57:13.591142 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:57:13.591142 16412 solver.cpp:237]     Train net output #1: loss = 0.359257 (* 1 = 0.359257 loss)
I1210 10:57:13.591142 16412 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1210 10:57:18.996327  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:57:19.218168 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_106000.caffemodel
I1210 10:57:19.234149 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_106000.solverstate
I1210 10:57:19.241149 16412 solver.cpp:330] Iteration 106000, Testing net (#0)
I1210 10:57:19.241149 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:57:20.611460 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:57:20.665971 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6848
I1210 10:57:20.665971 16412 solver.cpp:397]     Test net output #1: loss = 1.21427 (* 1 = 1.21427 loss)
I1210 10:57:20.719496 16412 solver.cpp:218] Iteration 106000 (14.0288 iter/s, 7.12819s/100 iters), loss = 0.273892
I1210 10:57:20.719496 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:57:20.719496 16412 solver.cpp:237]     Train net output #1: loss = 0.273892 (* 1 = 0.273892 loss)
I1210 10:57:20.719496 16412 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1210 10:57:26.431813 16412 solver.cpp:218] Iteration 106100 (17.5088 iter/s, 5.71141s/100 iters), loss = 0.297769
I1210 10:57:26.431813 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:57:26.431813 16412 solver.cpp:237]     Train net output #1: loss = 0.29777 (* 1 = 0.29777 loss)
I1210 10:57:26.431813 16412 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1210 10:57:32.126353 16412 solver.cpp:218] Iteration 106200 (17.5617 iter/s, 5.69422s/100 iters), loss = 0.294428
I1210 10:57:32.126353 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:57:32.126353 16412 solver.cpp:237]     Train net output #1: loss = 0.294428 (* 1 = 0.294428 loss)
I1210 10:57:32.126353 16412 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1210 10:57:37.923992 16412 solver.cpp:218] Iteration 106300 (17.2484 iter/s, 5.79765s/100 iters), loss = 0.427045
I1210 10:57:37.923992 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:57:37.923992 16412 solver.cpp:237]     Train net output #1: loss = 0.427045 (* 1 = 0.427045 loss)
I1210 10:57:37.923992 16412 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1210 10:57:43.617471 16412 solver.cpp:218] Iteration 106400 (17.5665 iter/s, 5.69264s/100 iters), loss = 0.46983
I1210 10:57:43.617471 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:57:43.617471 16412 solver.cpp:237]     Train net output #1: loss = 0.46983 (* 1 = 0.46983 loss)
I1210 10:57:43.617471 16412 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1210 10:57:49.058763  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:57:49.284798 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_106500.caffemodel
I1210 10:57:49.298810 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_106500.solverstate
I1210 10:57:49.303799 16412 solver.cpp:330] Iteration 106500, Testing net (#0)
I1210 10:57:49.303799 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:57:50.689334 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:57:50.744333 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6838
I1210 10:57:50.744333 16412 solver.cpp:397]     Test net output #1: loss = 1.2203 (* 1 = 1.2203 loss)
I1210 10:57:50.798344 16412 solver.cpp:218] Iteration 106500 (13.9263 iter/s, 7.18066s/100 iters), loss = 0.316253
I1210 10:57:50.798344 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:57:50.798344 16412 solver.cpp:237]     Train net output #1: loss = 0.316253 (* 1 = 0.316253 loss)
I1210 10:57:50.798344 16412 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1210 10:57:56.497038 16412 solver.cpp:218] Iteration 106600 (17.5512 iter/s, 5.69761s/100 iters), loss = 0.352378
I1210 10:57:56.497038 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1210 10:57:56.497038 16412 solver.cpp:237]     Train net output #1: loss = 0.352378 (* 1 = 0.352378 loss)
I1210 10:57:56.497038 16412 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1210 10:58:02.189834 16412 solver.cpp:218] Iteration 106700 (17.5678 iter/s, 5.69222s/100 iters), loss = 0.207107
I1210 10:58:02.189834 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 10:58:02.189834 16412 solver.cpp:237]     Train net output #1: loss = 0.207107 (* 1 = 0.207107 loss)
I1210 10:58:02.189834 16412 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1210 10:58:07.870224 16412 solver.cpp:218] Iteration 106800 (17.6048 iter/s, 5.68028s/100 iters), loss = 0.457251
I1210 10:58:07.870224 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 10:58:07.870224 16412 solver.cpp:237]     Train net output #1: loss = 0.457251 (* 1 = 0.457251 loss)
I1210 10:58:07.870224 16412 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1210 10:58:13.549237 16412 solver.cpp:218] Iteration 106900 (17.6108 iter/s, 5.67835s/100 iters), loss = 0.341772
I1210 10:58:13.549237 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:58:13.549237 16412 solver.cpp:237]     Train net output #1: loss = 0.341772 (* 1 = 0.341772 loss)
I1210 10:58:13.549237 16412 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1210 10:58:18.946537  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:58:19.170567 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_107000.caffemodel
I1210 10:58:19.183568 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_107000.solverstate
I1210 10:58:19.188566 16412 solver.cpp:330] Iteration 107000, Testing net (#0)
I1210 10:58:19.188566 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:58:20.554612 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:58:20.608613 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6844
I1210 10:58:20.608613 16412 solver.cpp:397]     Test net output #1: loss = 1.22529 (* 1 = 1.22529 loss)
I1210 10:58:20.662636 16412 solver.cpp:218] Iteration 107000 (14.0584 iter/s, 7.11316s/100 iters), loss = 0.264524
I1210 10:58:20.662636 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 10:58:20.662636 16412 solver.cpp:237]     Train net output #1: loss = 0.264524 (* 1 = 0.264524 loss)
I1210 10:58:20.662636 16412 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1210 10:58:26.329147 16412 solver.cpp:218] Iteration 107100 (17.6497 iter/s, 5.66583s/100 iters), loss = 0.306946
I1210 10:58:26.329147 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:58:26.329147 16412 solver.cpp:237]     Train net output #1: loss = 0.306946 (* 1 = 0.306946 loss)
I1210 10:58:26.329147 16412 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1210 10:58:31.998654 16412 solver.cpp:218] Iteration 107200 (17.6374 iter/s, 5.66977s/100 iters), loss = 0.227806
I1210 10:58:31.999655 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:58:31.999655 16412 solver.cpp:237]     Train net output #1: loss = 0.227806 (* 1 = 0.227806 loss)
I1210 10:58:31.999655 16412 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1210 10:58:37.668325 16412 solver.cpp:218] Iteration 107300 (17.6391 iter/s, 5.66922s/100 iters), loss = 0.448664
I1210 10:58:37.669325 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1210 10:58:37.669325 16412 solver.cpp:237]     Train net output #1: loss = 0.448665 (* 1 = 0.448665 loss)
I1210 10:58:37.669325 16412 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1210 10:58:43.335006 16412 solver.cpp:218] Iteration 107400 (17.6481 iter/s, 5.66633s/100 iters), loss = 0.365261
I1210 10:58:43.336009 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1210 10:58:43.336009 16412 solver.cpp:237]     Train net output #1: loss = 0.365261 (* 1 = 0.365261 loss)
I1210 10:58:43.336009 16412 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1210 10:58:48.729409  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:58:48.950517 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_107500.caffemodel
I1210 10:58:48.965044 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_107500.solverstate
I1210 10:58:48.969543 16412 solver.cpp:330] Iteration 107500, Testing net (#0)
I1210 10:58:48.969543 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:58:50.336021 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:58:50.390058 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6832
I1210 10:58:50.390058 16412 solver.cpp:397]     Test net output #1: loss = 1.22836 (* 1 = 1.22836 loss)
I1210 10:58:50.444053 16412 solver.cpp:218] Iteration 107500 (14.0694 iter/s, 7.10764s/100 iters), loss = 0.333254
I1210 10:58:50.444053 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 10:58:50.444053 16412 solver.cpp:237]     Train net output #1: loss = 0.333254 (* 1 = 0.333254 loss)
I1210 10:58:50.444053 16412 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1210 10:58:56.113762 16412 solver.cpp:218] Iteration 107600 (17.6387 iter/s, 5.66936s/100 iters), loss = 0.259828
I1210 10:58:56.113762 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1210 10:58:56.113762 16412 solver.cpp:237]     Train net output #1: loss = 0.259829 (* 1 = 0.259829 loss)
I1210 10:58:56.113762 16412 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1210 10:59:01.787519 16412 solver.cpp:218] Iteration 107700 (17.6262 iter/s, 5.67338s/100 iters), loss = 0.33095
I1210 10:59:01.787519 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 10:59:01.787519 16412 solver.cpp:237]     Train net output #1: loss = 0.33095 (* 1 = 0.33095 loss)
I1210 10:59:01.787519 16412 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1210 10:59:07.455516 16412 solver.cpp:218] Iteration 107800 (17.6443 iter/s, 5.66755s/100 iters), loss = 0.526317
I1210 10:59:07.455516 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 10:59:07.455516 16412 solver.cpp:237]     Train net output #1: loss = 0.526317 (* 1 = 0.526317 loss)
I1210 10:59:07.455516 16412 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1210 10:59:13.124141 16412 solver.cpp:218] Iteration 107900 (17.6426 iter/s, 5.66811s/100 iters), loss = 0.311534
I1210 10:59:13.124141 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:59:13.124141 16412 solver.cpp:237]     Train net output #1: loss = 0.311534 (* 1 = 0.311534 loss)
I1210 10:59:13.124141 16412 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1210 10:59:18.515166  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:59:18.738255 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_108000.caffemodel
I1210 10:59:18.752254 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_108000.solverstate
I1210 10:59:18.756254 16412 solver.cpp:330] Iteration 108000, Testing net (#0)
I1210 10:59:18.757256 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:59:20.125109 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:59:20.178623 16412 solver.cpp:397]     Test net output #0: accuracy = 0.682
I1210 10:59:20.178623 16412 solver.cpp:397]     Test net output #1: loss = 1.22514 (* 1 = 1.22514 loss)
I1210 10:59:20.232143 16412 solver.cpp:218] Iteration 108000 (14.0684 iter/s, 7.10815s/100 iters), loss = 0.26221
I1210 10:59:20.232143 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:59:20.232143 16412 solver.cpp:237]     Train net output #1: loss = 0.26221 (* 1 = 0.26221 loss)
I1210 10:59:20.232143 16412 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1210 10:59:25.895201 16412 solver.cpp:218] Iteration 108100 (17.6609 iter/s, 5.66221s/100 iters), loss = 0.25797
I1210 10:59:25.895201 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 10:59:25.895201 16412 solver.cpp:237]     Train net output #1: loss = 0.25797 (* 1 = 0.25797 loss)
I1210 10:59:25.895201 16412 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1210 10:59:31.569743 16412 solver.cpp:218] Iteration 108200 (17.6253 iter/s, 5.67365s/100 iters), loss = 0.238563
I1210 10:59:31.569743 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1210 10:59:31.569743 16412 solver.cpp:237]     Train net output #1: loss = 0.238563 (* 1 = 0.238563 loss)
I1210 10:59:31.569743 16412 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1210 10:59:37.246685 16412 solver.cpp:218] Iteration 108300 (17.6159 iter/s, 5.67669s/100 iters), loss = 0.503972
I1210 10:59:37.246685 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1210 10:59:37.246685 16412 solver.cpp:237]     Train net output #1: loss = 0.503972 (* 1 = 0.503972 loss)
I1210 10:59:37.246685 16412 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1210 10:59:42.910907 16412 solver.cpp:218] Iteration 108400 (17.6559 iter/s, 5.66383s/100 iters), loss = 0.321612
I1210 10:59:42.910907 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 10:59:42.910907 16412 solver.cpp:237]     Train net output #1: loss = 0.321612 (* 1 = 0.321612 loss)
I1210 10:59:42.910907 16412 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1210 10:59:48.309283  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:59:48.533417 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_108500.caffemodel
I1210 10:59:48.552392 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_108500.solverstate
I1210 10:59:48.557401 16412 solver.cpp:330] Iteration 108500, Testing net (#0)
I1210 10:59:48.557401 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 10:59:49.940978 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 10:59:49.993990 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6846
I1210 10:59:49.993990 16412 solver.cpp:397]     Test net output #1: loss = 1.22886 (* 1 = 1.22886 loss)
I1210 10:59:50.050016 16412 solver.cpp:218] Iteration 108500 (14.0086 iter/s, 7.13849s/100 iters), loss = 0.253593
I1210 10:59:50.050016 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 10:59:50.050016 16412 solver.cpp:237]     Train net output #1: loss = 0.253593 (* 1 = 0.253593 loss)
I1210 10:59:50.050016 16412 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1210 10:59:55.753222 16412 solver.cpp:218] Iteration 108600 (17.5333 iter/s, 5.70344s/100 iters), loss = 0.286186
I1210 10:59:55.754222 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1210 10:59:55.754222 16412 solver.cpp:237]     Train net output #1: loss = 0.286186 (* 1 = 0.286186 loss)
I1210 10:59:55.754222 16412 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1210 11:00:01.489190 16412 solver.cpp:218] Iteration 108700 (17.4366 iter/s, 5.73507s/100 iters), loss = 0.251011
I1210 11:00:01.489190 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 11:00:01.489190 16412 solver.cpp:237]     Train net output #1: loss = 0.251011 (* 1 = 0.251011 loss)
I1210 11:00:01.489190 16412 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1210 11:00:07.180836 16412 solver.cpp:218] Iteration 108800 (17.5728 iter/s, 5.6906s/100 iters), loss = 0.362824
I1210 11:00:07.180836 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1210 11:00:07.180836 16412 solver.cpp:237]     Train net output #1: loss = 0.362824 (* 1 = 0.362824 loss)
I1210 11:00:07.180836 16412 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1210 11:00:12.891557 16412 solver.cpp:218] Iteration 108900 (17.511 iter/s, 5.71069s/100 iters), loss = 0.316889
I1210 11:00:12.891557 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1210 11:00:12.891557 16412 solver.cpp:237]     Train net output #1: loss = 0.316889 (* 1 = 0.316889 loss)
I1210 11:00:12.891557 16412 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1210 11:00:18.298270  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 11:00:18.519798 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_109000.caffemodel
I1210 11:00:18.535799 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_109000.solverstate
I1210 11:00:18.539810 16412 solver.cpp:330] Iteration 109000, Testing net (#0)
I1210 11:00:18.539810 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 11:00:19.914386 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 11:00:19.967653 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6816
I1210 11:00:19.967653 16412 solver.cpp:397]     Test net output #1: loss = 1.24025 (* 1 = 1.24025 loss)
I1210 11:00:20.021652 16412 solver.cpp:218] Iteration 109000 (14.0266 iter/s, 7.1293s/100 iters), loss = 0.327962
I1210 11:00:20.021652 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 11:00:20.021652 16412 solver.cpp:237]     Train net output #1: loss = 0.327962 (* 1 = 0.327962 loss)
I1210 11:00:20.021652 16412 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1210 11:00:25.733949 16412 solver.cpp:218] Iteration 109100 (17.5066 iter/s, 5.71212s/100 iters), loss = 0.23031
I1210 11:00:25.733949 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 11:00:25.733949 16412 solver.cpp:237]     Train net output #1: loss = 0.23031 (* 1 = 0.23031 loss)
I1210 11:00:25.733949 16412 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1210 11:00:31.480983 16412 solver.cpp:218] Iteration 109200 (17.4022 iter/s, 5.7464s/100 iters), loss = 0.271994
I1210 11:00:31.480983 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 11:00:31.480983 16412 solver.cpp:237]     Train net output #1: loss = 0.271994 (* 1 = 0.271994 loss)
I1210 11:00:31.480983 16412 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1210 11:00:37.194547 16412 solver.cpp:218] Iteration 109300 (17.5046 iter/s, 5.71279s/100 iters), loss = 0.391721
I1210 11:00:37.194547 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 11:00:37.194547 16412 solver.cpp:237]     Train net output #1: loss = 0.391721 (* 1 = 0.391721 loss)
I1210 11:00:37.194547 16412 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1210 11:00:42.954566 16412 solver.cpp:218] Iteration 109400 (17.362 iter/s, 5.75971s/100 iters), loss = 0.346434
I1210 11:00:42.954566 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1210 11:00:42.954566 16412 solver.cpp:237]     Train net output #1: loss = 0.346434 (* 1 = 0.346434 loss)
I1210 11:00:42.954566 16412 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1210 11:00:48.384555  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 11:00:48.608572 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_109500.caffemodel
I1210 11:00:48.623570 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_109500.solverstate
I1210 11:00:48.627571 16412 solver.cpp:330] Iteration 109500, Testing net (#0)
I1210 11:00:48.627571 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 11:00:49.996749 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 11:00:50.050751 16412 solver.cpp:397]     Test net output #0: accuracy = 0.6821
I1210 11:00:50.050751 16412 solver.cpp:397]     Test net output #1: loss = 1.23359 (* 1 = 1.23359 loss)
I1210 11:00:50.106758 16412 solver.cpp:218] Iteration 109500 (13.9822 iter/s, 7.15197s/100 iters), loss = 0.306269
I1210 11:00:50.106758 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1210 11:00:50.106758 16412 solver.cpp:237]     Train net output #1: loss = 0.306269 (* 1 = 0.306269 loss)
I1210 11:00:50.106758 16412 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1210 11:00:55.810521 16412 solver.cpp:218] Iteration 109600 (17.5349 iter/s, 5.70292s/100 iters), loss = 0.249885
I1210 11:00:55.810521 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 11:00:55.810521 16412 solver.cpp:237]     Train net output #1: loss = 0.249885 (* 1 = 0.249885 loss)
I1210 11:00:55.810521 16412 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1210 11:01:01.498971 16412 solver.cpp:218] Iteration 109700 (17.5791 iter/s, 5.68858s/100 iters), loss = 0.302429
I1210 11:01:01.498971 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1210 11:01:01.498971 16412 solver.cpp:237]     Train net output #1: loss = 0.302429 (* 1 = 0.302429 loss)
I1210 11:01:01.498971 16412 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1210 11:01:07.206550 16412 solver.cpp:218] Iteration 109800 (17.524 iter/s, 5.70647s/100 iters), loss = 0.326612
I1210 11:01:07.206550 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 11:01:07.206550 16412 solver.cpp:237]     Train net output #1: loss = 0.326612 (* 1 = 0.326612 loss)
I1210 11:01:07.206550 16412 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1210 11:01:12.899963 16412 solver.cpp:218] Iteration 109900 (17.5632 iter/s, 5.69374s/100 iters), loss = 0.422184
I1210 11:01:12.899963 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1210 11:01:12.899963 16412 solver.cpp:237]     Train net output #1: loss = 0.422184 (* 1 = 0.422184 loss)
I1210 11:01:12.899963 16412 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1210 11:01:18.337422  9844 data_layer.cpp:73] Restarting data prefetching from start.
I1210 11:01:18.560950 16412 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_110000.caffemodel
I1210 11:01:18.577455 16412 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_13_v2_iter_110000.solverstate
I1210 11:01:18.582455 16412 solver.cpp:330] Iteration 110000, Testing net (#0)
I1210 11:01:18.582455 16412 net.cpp:676] Ignoring source layer accuracy_training
I1210 11:01:19.964131 15752 data_layer.cpp:73] Restarting data prefetching from start.
I1210 11:01:20.018646 16412 solver.cpp:397]     Test net output #0: accuracy = 0.68
I1210 11:01:20.019646 16412 solver.cpp:397]     Test net output #1: loss = 1.22733 (* 1 = 1.22733 loss)
I1210 11:01:20.074654 16412 solver.cpp:218] Iteration 110000 (13.9407 iter/s, 7.17322s/100 iters), loss = 0.261692
I1210 11:01:20.074654 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1210 11:01:20.074654 16412 solver.cpp:237]     Train net output #1: loss = 0.261692 (* 1 = 0.261692 loss)
I1210 11:01:20.074654 16412 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1210 11:01:25.794086 16412 solver.cpp:218] Iteration 110100 (17.4849 iter/s, 5.71921s/100 iters), loss = 0.239617
I1210 11:01:25.794086 16412 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1210 11:01:25.794086 16412 solver.cpp:237]     Train net output #1: l