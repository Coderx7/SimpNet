
G:\Caffe\examples\cifar100>REM go to the caffe root 

G:\Caffe\examples\cifar100>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90000.solverstate 
I1211 17:05:13.085654 17748 caffe.cpp:219] Using GPUs 0
I1211 17:05:13.291656 17748 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1211 17:05:13.620656 17748 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 17:05:13.638170 17748 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1211 17:05:13.639154 17748 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 17:05:13.639657 17748 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 17:05:13.639657 17748 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_pool2_1
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_pool4_2
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1211 17:05:13.640156 17748 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1211 17:05:13.640156 17748 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV2_WnonLin_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_pool2_1"
  type: "BatchNorm"
  bottom: "pool2_1"
  top: "pool2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_pool2_1"
  type: "Scale"
  bottom: "pool2_1"
  top: "pool2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_pool2_1"
  type: "ReLU"
  bottom: "pool2_1"
  top: "pool2_1"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_pool4_2"
  type: "BatchNorm"
  bottom: "pool4_2"
  top: "pool4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_pool4_2"
  type: "Scale"
  bottom: "pool4_2"
  top: "pool4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_pool4_2"
  type: "ReLU"
  bottom: "pool4_2"
  top: "pool4_2"
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 17:05:13.748001 17748 layer_factory.cpp:58] Creating layer cifar
I1211 17:05:13.750500 17748 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1211 17:05:13.750500 17748 net.cpp:84] Creating Layer cifar
I1211 17:05:13.750500 17748 net.cpp:380] cifar -> data
I1211 17:05:13.750500 17748 net.cpp:380] cifar -> label
I1211 17:05:13.751500 17748 data_layer.cpp:45] output data size: 100,3,32,32
I1211 17:05:13.759500 17748 net.cpp:122] Setting up cifar
I1211 17:05:13.759500 17748 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 17:05:13.759500 17748 net.cpp:129] Top shape: 100 (100)
I1211 17:05:13.759500 17748 net.cpp:137] Memory required for data: 1229200
I1211 17:05:13.759500 17748 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 17:05:13.759500 17748 net.cpp:84] Creating Layer label_cifar_1_split
I1211 17:05:13.759500 17748 net.cpp:406] label_cifar_1_split <- label
I1211 17:05:13.759500 17748 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 17:05:13.759500 17748 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 17:05:13.760001 17748 net.cpp:122] Setting up label_cifar_1_split
I1211 17:05:13.760001 17748 net.cpp:129] Top shape: 100 (100)
I1211 17:05:13.760001 17748 net.cpp:129] Top shape: 100 (100)
I1211 17:05:13.760001 17748 net.cpp:137] Memory required for data: 1230000
I1211 17:05:13.760001 17748 layer_factory.cpp:58] Creating layer conv1
I1211 17:05:13.760001 17748 net.cpp:84] Creating Layer conv1
I1211 17:05:13.760001 17748 net.cpp:406] conv1 <- data
I1211 17:05:13.760001 17748 net.cpp:380] conv1 -> conv1
I1211 17:05:13.762001 16060 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 17:05:14.037500 17748 net.cpp:122] Setting up conv1
I1211 17:05:14.037500 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.037500 17748 net.cpp:137] Memory required for data: 13518000
I1211 17:05:14.037500 17748 layer_factory.cpp:58] Creating layer bn1
I1211 17:05:14.037500 17748 net.cpp:84] Creating Layer bn1
I1211 17:05:14.037500 17748 net.cpp:406] bn1 <- conv1
I1211 17:05:14.037500 17748 net.cpp:367] bn1 -> conv1 (in-place)
I1211 17:05:14.037500 17748 net.cpp:122] Setting up bn1
I1211 17:05:14.037500 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.037500 17748 net.cpp:137] Memory required for data: 25806000
I1211 17:05:14.037500 17748 layer_factory.cpp:58] Creating layer scale1
I1211 17:05:14.037500 17748 net.cpp:84] Creating Layer scale1
I1211 17:05:14.037500 17748 net.cpp:406] scale1 <- conv1
I1211 17:05:14.037500 17748 net.cpp:367] scale1 -> conv1 (in-place)
I1211 17:05:14.038000 17748 layer_factory.cpp:58] Creating layer scale1
I1211 17:05:14.038000 17748 net.cpp:122] Setting up scale1
I1211 17:05:14.038000 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.038000 17748 net.cpp:137] Memory required for data: 38094000
I1211 17:05:14.038000 17748 layer_factory.cpp:58] Creating layer relu1
I1211 17:05:14.038000 17748 net.cpp:84] Creating Layer relu1
I1211 17:05:14.038000 17748 net.cpp:406] relu1 <- conv1
I1211 17:05:14.038000 17748 net.cpp:367] relu1 -> conv1 (in-place)
I1211 17:05:14.038000 17748 net.cpp:122] Setting up relu1
I1211 17:05:14.038000 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.038000 17748 net.cpp:137] Memory required for data: 50382000
I1211 17:05:14.038000 17748 layer_factory.cpp:58] Creating layer conv1_0
I1211 17:05:14.038000 17748 net.cpp:84] Creating Layer conv1_0
I1211 17:05:14.038000 17748 net.cpp:406] conv1_0 <- conv1
I1211 17:05:14.038000 17748 net.cpp:380] conv1_0 -> conv1_0
I1211 17:05:14.040500 17748 net.cpp:122] Setting up conv1_0
I1211 17:05:14.040500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.040500 17748 net.cpp:137] Memory required for data: 66766000
I1211 17:05:14.040500 17748 layer_factory.cpp:58] Creating layer bn1_0
I1211 17:05:14.040500 17748 net.cpp:84] Creating Layer bn1_0
I1211 17:05:14.040500 17748 net.cpp:406] bn1_0 <- conv1_0
I1211 17:05:14.040500 17748 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 17:05:14.040999 17748 net.cpp:122] Setting up bn1_0
I1211 17:05:14.040999 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.040999 17748 net.cpp:137] Memory required for data: 83150000
I1211 17:05:14.040999 17748 layer_factory.cpp:58] Creating layer scale1_0
I1211 17:05:14.040999 17748 net.cpp:84] Creating Layer scale1_0
I1211 17:05:14.040999 17748 net.cpp:406] scale1_0 <- conv1_0
I1211 17:05:14.040999 17748 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 17:05:14.040999 17748 layer_factory.cpp:58] Creating layer scale1_0
I1211 17:05:14.040999 17748 net.cpp:122] Setting up scale1_0
I1211 17:05:14.040999 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.040999 17748 net.cpp:137] Memory required for data: 99534000
I1211 17:05:14.040999 17748 layer_factory.cpp:58] Creating layer relu1_0
I1211 17:05:14.040999 17748 net.cpp:84] Creating Layer relu1_0
I1211 17:05:14.040999 17748 net.cpp:406] relu1_0 <- conv1_0
I1211 17:05:14.040999 17748 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 17:05:14.040999 17748 net.cpp:122] Setting up relu1_0
I1211 17:05:14.040999 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.040999 17748 net.cpp:137] Memory required for data: 115918000
I1211 17:05:14.040999 17748 layer_factory.cpp:58] Creating layer conv2
I1211 17:05:14.040999 17748 net.cpp:84] Creating Layer conv2
I1211 17:05:14.040999 17748 net.cpp:406] conv2 <- conv1_0
I1211 17:05:14.040999 17748 net.cpp:380] conv2 -> conv2
I1211 17:05:14.042500 17748 net.cpp:122] Setting up conv2
I1211 17:05:14.042500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.042500 17748 net.cpp:137] Memory required for data: 132302000
I1211 17:05:14.042500 17748 layer_factory.cpp:58] Creating layer bn2
I1211 17:05:14.042500 17748 net.cpp:84] Creating Layer bn2
I1211 17:05:14.042500 17748 net.cpp:406] bn2 <- conv2
I1211 17:05:14.042500 17748 net.cpp:367] bn2 -> conv2 (in-place)
I1211 17:05:14.042500 17748 net.cpp:122] Setting up bn2
I1211 17:05:14.042500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.042500 17748 net.cpp:137] Memory required for data: 148686000
I1211 17:05:14.042500 17748 layer_factory.cpp:58] Creating layer scale2
I1211 17:05:14.042500 17748 net.cpp:84] Creating Layer scale2
I1211 17:05:14.042500 17748 net.cpp:406] scale2 <- conv2
I1211 17:05:14.042500 17748 net.cpp:367] scale2 -> conv2 (in-place)
I1211 17:05:14.042500 17748 layer_factory.cpp:58] Creating layer scale2
I1211 17:05:14.042500 17748 net.cpp:122] Setting up scale2
I1211 17:05:14.042500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.042500 17748 net.cpp:137] Memory required for data: 165070000
I1211 17:05:14.042500 17748 layer_factory.cpp:58] Creating layer relu2
I1211 17:05:14.042999 17748 net.cpp:84] Creating Layer relu2
I1211 17:05:14.042999 17748 net.cpp:406] relu2 <- conv2
I1211 17:05:14.042999 17748 net.cpp:367] relu2 -> conv2 (in-place)
I1211 17:05:14.042999 17748 net.cpp:122] Setting up relu2
I1211 17:05:14.042999 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.042999 17748 net.cpp:137] Memory required for data: 181454000
I1211 17:05:14.042999 17748 layer_factory.cpp:58] Creating layer conv2_1
I1211 17:05:14.042999 17748 net.cpp:84] Creating Layer conv2_1
I1211 17:05:14.042999 17748 net.cpp:406] conv2_1 <- conv2
I1211 17:05:14.042999 17748 net.cpp:380] conv2_1 -> conv2_1
I1211 17:05:14.043999 17748 net.cpp:122] Setting up conv2_1
I1211 17:05:14.043999 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.043999 17748 net.cpp:137] Memory required for data: 197838000
I1211 17:05:14.043999 17748 layer_factory.cpp:58] Creating layer bn2_1
I1211 17:05:14.043999 17748 net.cpp:84] Creating Layer bn2_1
I1211 17:05:14.044499 17748 net.cpp:406] bn2_1 <- conv2_1
I1211 17:05:14.044499 17748 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 17:05:14.044499 17748 net.cpp:122] Setting up bn2_1
I1211 17:05:14.044499 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.044499 17748 net.cpp:137] Memory required for data: 214222000
I1211 17:05:14.044499 17748 layer_factory.cpp:58] Creating layer scale2_1
I1211 17:05:14.044499 17748 net.cpp:84] Creating Layer scale2_1
I1211 17:05:14.044499 17748 net.cpp:406] scale2_1 <- conv2_1
I1211 17:05:14.044499 17748 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 17:05:14.044499 17748 layer_factory.cpp:58] Creating layer scale2_1
I1211 17:05:14.044499 17748 net.cpp:122] Setting up scale2_1
I1211 17:05:14.044499 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.044499 17748 net.cpp:137] Memory required for data: 230606000
I1211 17:05:14.044499 17748 layer_factory.cpp:58] Creating layer relu2_1
I1211 17:05:14.044499 17748 net.cpp:84] Creating Layer relu2_1
I1211 17:05:14.044499 17748 net.cpp:406] relu2_1 <- conv2_1
I1211 17:05:14.044499 17748 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 17:05:14.044999 17748 net.cpp:122] Setting up relu2_1
I1211 17:05:14.044999 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.044999 17748 net.cpp:137] Memory required for data: 246990000
I1211 17:05:14.044999 17748 layer_factory.cpp:58] Creating layer conv2_2
I1211 17:05:14.044999 17748 net.cpp:84] Creating Layer conv2_2
I1211 17:05:14.044999 17748 net.cpp:406] conv2_2 <- conv2_1
I1211 17:05:14.044999 17748 net.cpp:380] conv2_2 -> conv2_2
I1211 17:05:14.047500 17748 net.cpp:122] Setting up conv2_2
I1211 17:05:14.047500 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.047500 17748 net.cpp:137] Memory required for data: 267470000
I1211 17:05:14.047500 17748 layer_factory.cpp:58] Creating layer bn2_2
I1211 17:05:14.047500 17748 net.cpp:84] Creating Layer bn2_2
I1211 17:05:14.047500 17748 net.cpp:406] bn2_2 <- conv2_2
I1211 17:05:14.047500 17748 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 17:05:14.047500 17748 net.cpp:122] Setting up bn2_2
I1211 17:05:14.047500 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.047500 17748 net.cpp:137] Memory required for data: 287950000
I1211 17:05:14.047500 17748 layer_factory.cpp:58] Creating layer scale2_2
I1211 17:05:14.047500 17748 net.cpp:84] Creating Layer scale2_2
I1211 17:05:14.047500 17748 net.cpp:406] scale2_2 <- conv2_2
I1211 17:05:14.047500 17748 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 17:05:14.047500 17748 layer_factory.cpp:58] Creating layer scale2_2
I1211 17:05:14.047500 17748 net.cpp:122] Setting up scale2_2
I1211 17:05:14.047500 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.047999 17748 net.cpp:137] Memory required for data: 308430000
I1211 17:05:14.047999 17748 layer_factory.cpp:58] Creating layer relu2_2
I1211 17:05:14.047999 17748 net.cpp:84] Creating Layer relu2_2
I1211 17:05:14.047999 17748 net.cpp:406] relu2_2 <- conv2_2
I1211 17:05:14.047999 17748 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 17:05:14.048499 17748 net.cpp:122] Setting up relu2_2
I1211 17:05:14.048499 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.048499 17748 net.cpp:137] Memory required for data: 328910000
I1211 17:05:14.048499 17748 layer_factory.cpp:58] Creating layer pool2_1
I1211 17:05:14.048499 17748 net.cpp:84] Creating Layer pool2_1
I1211 17:05:14.048499 17748 net.cpp:406] pool2_1 <- conv2_2
I1211 17:05:14.048499 17748 net.cpp:380] pool2_1 -> pool2_1
I1211 17:05:14.050000 17748 net.cpp:122] Setting up pool2_1
I1211 17:05:14.050000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.050500 17748 net.cpp:137] Memory required for data: 334030000
I1211 17:05:14.050500 17748 layer_factory.cpp:58] Creating layer bn2_pool2_1
I1211 17:05:14.050500 17748 net.cpp:84] Creating Layer bn2_pool2_1
I1211 17:05:14.050500 17748 net.cpp:406] bn2_pool2_1 <- pool2_1
I1211 17:05:14.050500 17748 net.cpp:367] bn2_pool2_1 -> pool2_1 (in-place)
I1211 17:05:14.050500 17748 net.cpp:122] Setting up bn2_pool2_1
I1211 17:05:14.050500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.050500 17748 net.cpp:137] Memory required for data: 339150000
I1211 17:05:14.050500 17748 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 17:05:14.050500 17748 net.cpp:84] Creating Layer scale2_pool2_1
I1211 17:05:14.050500 17748 net.cpp:406] scale2_pool2_1 <- pool2_1
I1211 17:05:14.050500 17748 net.cpp:367] scale2_pool2_1 -> pool2_1 (in-place)
I1211 17:05:14.050500 17748 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 17:05:14.051000 17748 net.cpp:122] Setting up scale2_pool2_1
I1211 17:05:14.051000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.051000 17748 net.cpp:137] Memory required for data: 344270000
I1211 17:05:14.051000 17748 layer_factory.cpp:58] Creating layer relu2_pool2_1
I1211 17:05:14.051000 17748 net.cpp:84] Creating Layer relu2_pool2_1
I1211 17:05:14.051000 17748 net.cpp:406] relu2_pool2_1 <- pool2_1
I1211 17:05:14.051000 17748 net.cpp:367] relu2_pool2_1 -> pool2_1 (in-place)
I1211 17:05:14.051499 17748 net.cpp:122] Setting up relu2_pool2_1
I1211 17:05:14.051499 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.051499 17748 net.cpp:137] Memory required for data: 349390000
I1211 17:05:14.051499 17748 layer_factory.cpp:58] Creating layer conv3
I1211 17:05:14.051499 17748 net.cpp:84] Creating Layer conv3
I1211 17:05:14.051499 17748 net.cpp:406] conv3 <- pool2_1
I1211 17:05:14.051499 17748 net.cpp:380] conv3 -> conv3
I1211 17:05:14.052503 17748 net.cpp:122] Setting up conv3
I1211 17:05:14.052503 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.052503 17748 net.cpp:137] Memory required for data: 354510000
I1211 17:05:14.052503 17748 layer_factory.cpp:58] Creating layer bn3
I1211 17:05:14.052503 17748 net.cpp:84] Creating Layer bn3
I1211 17:05:14.052503 17748 net.cpp:406] bn3 <- conv3
I1211 17:05:14.052503 17748 net.cpp:367] bn3 -> conv3 (in-place)
I1211 17:05:14.052999 17748 net.cpp:122] Setting up bn3
I1211 17:05:14.052999 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.052999 17748 net.cpp:137] Memory required for data: 359630000
I1211 17:05:14.052999 17748 layer_factory.cpp:58] Creating layer scale3
I1211 17:05:14.052999 17748 net.cpp:84] Creating Layer scale3
I1211 17:05:14.052999 17748 net.cpp:406] scale3 <- conv3
I1211 17:05:14.052999 17748 net.cpp:367] scale3 -> conv3 (in-place)
I1211 17:05:14.052999 17748 layer_factory.cpp:58] Creating layer scale3
I1211 17:05:14.052999 17748 net.cpp:122] Setting up scale3
I1211 17:05:14.052999 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.052999 17748 net.cpp:137] Memory required for data: 364750000
I1211 17:05:14.052999 17748 layer_factory.cpp:58] Creating layer relu3
I1211 17:05:14.052999 17748 net.cpp:84] Creating Layer relu3
I1211 17:05:14.052999 17748 net.cpp:406] relu3 <- conv3
I1211 17:05:14.052999 17748 net.cpp:367] relu3 -> conv3 (in-place)
I1211 17:05:14.053499 17748 net.cpp:122] Setting up relu3
I1211 17:05:14.053499 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.053499 17748 net.cpp:137] Memory required for data: 369870000
I1211 17:05:14.053499 17748 layer_factory.cpp:58] Creating layer conv3_1
I1211 17:05:14.053499 17748 net.cpp:84] Creating Layer conv3_1
I1211 17:05:14.053499 17748 net.cpp:406] conv3_1 <- conv3
I1211 17:05:14.053499 17748 net.cpp:380] conv3_1 -> conv3_1
I1211 17:05:14.055001 17748 net.cpp:122] Setting up conv3_1
I1211 17:05:14.055001 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.055001 17748 net.cpp:137] Memory required for data: 374990000
I1211 17:05:14.055001 17748 layer_factory.cpp:58] Creating layer bn3_1
I1211 17:05:14.055500 17748 net.cpp:84] Creating Layer bn3_1
I1211 17:05:14.055500 17748 net.cpp:406] bn3_1 <- conv3_1
I1211 17:05:14.055500 17748 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 17:05:14.055500 17748 net.cpp:122] Setting up bn3_1
I1211 17:05:14.055500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.055500 17748 net.cpp:137] Memory required for data: 380110000
I1211 17:05:14.055500 17748 layer_factory.cpp:58] Creating layer scale3_1
I1211 17:05:14.055500 17748 net.cpp:84] Creating Layer scale3_1
I1211 17:05:14.055500 17748 net.cpp:406] scale3_1 <- conv3_1
I1211 17:05:14.055500 17748 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 17:05:14.056000 17748 layer_factory.cpp:58] Creating layer scale3_1
I1211 17:05:14.056000 17748 net.cpp:122] Setting up scale3_1
I1211 17:05:14.056000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.056000 17748 net.cpp:137] Memory required for data: 385230000
I1211 17:05:14.056000 17748 layer_factory.cpp:58] Creating layer relu3_1
I1211 17:05:14.056000 17748 net.cpp:84] Creating Layer relu3_1
I1211 17:05:14.056000 17748 net.cpp:406] relu3_1 <- conv3_1
I1211 17:05:14.056000 17748 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 17:05:14.056000 17748 net.cpp:122] Setting up relu3_1
I1211 17:05:14.056000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.056000 17748 net.cpp:137] Memory required for data: 390350000
I1211 17:05:14.056500 17748 layer_factory.cpp:58] Creating layer conv4
I1211 17:05:14.056500 17748 net.cpp:84] Creating Layer conv4
I1211 17:05:14.056500 17748 net.cpp:406] conv4 <- conv3_1
I1211 17:05:14.056500 17748 net.cpp:380] conv4 -> conv4
I1211 17:05:14.057500 17748 net.cpp:122] Setting up conv4
I1211 17:05:14.057500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.057500 17748 net.cpp:137] Memory required for data: 395470000
I1211 17:05:14.057500 17748 layer_factory.cpp:58] Creating layer bn4
I1211 17:05:14.058001 17748 net.cpp:84] Creating Layer bn4
I1211 17:05:14.058001 17748 net.cpp:406] bn4 <- conv4
I1211 17:05:14.058001 17748 net.cpp:367] bn4 -> conv4 (in-place)
I1211 17:05:14.058001 17748 net.cpp:122] Setting up bn4
I1211 17:05:14.058001 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.058001 17748 net.cpp:137] Memory required for data: 400590000
I1211 17:05:14.058001 17748 layer_factory.cpp:58] Creating layer scale4
I1211 17:05:14.058001 17748 net.cpp:84] Creating Layer scale4
I1211 17:05:14.058001 17748 net.cpp:406] scale4 <- conv4
I1211 17:05:14.058001 17748 net.cpp:367] scale4 -> conv4 (in-place)
I1211 17:05:14.058001 17748 layer_factory.cpp:58] Creating layer scale4
I1211 17:05:14.058001 17748 net.cpp:122] Setting up scale4
I1211 17:05:14.058001 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.058001 17748 net.cpp:137] Memory required for data: 405710000
I1211 17:05:14.058001 17748 layer_factory.cpp:58] Creating layer relu4
I1211 17:05:14.058001 17748 net.cpp:84] Creating Layer relu4
I1211 17:05:14.058001 17748 net.cpp:406] relu4 <- conv4
I1211 17:05:14.058001 17748 net.cpp:367] relu4 -> conv4 (in-place)
I1211 17:05:14.058501 17748 net.cpp:122] Setting up relu4
I1211 17:05:14.058501 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.058501 17748 net.cpp:137] Memory required for data: 410830000
I1211 17:05:14.058501 17748 layer_factory.cpp:58] Creating layer conv4_1
I1211 17:05:14.058501 17748 net.cpp:84] Creating Layer conv4_1
I1211 17:05:14.058501 17748 net.cpp:406] conv4_1 <- conv4
I1211 17:05:14.058501 17748 net.cpp:380] conv4_1 -> conv4_1
I1211 17:05:14.059499 17748 net.cpp:122] Setting up conv4_1
I1211 17:05:14.060000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.060000 17748 net.cpp:137] Memory required for data: 415950000
I1211 17:05:14.060000 17748 layer_factory.cpp:58] Creating layer bn4_1
I1211 17:05:14.060000 17748 net.cpp:84] Creating Layer bn4_1
I1211 17:05:14.060000 17748 net.cpp:406] bn4_1 <- conv4_1
I1211 17:05:14.060000 17748 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 17:05:14.060000 17748 net.cpp:122] Setting up bn4_1
I1211 17:05:14.060000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.060000 17748 net.cpp:137] Memory required for data: 421070000
I1211 17:05:14.060000 17748 layer_factory.cpp:58] Creating layer scale4_1
I1211 17:05:14.060000 17748 net.cpp:84] Creating Layer scale4_1
I1211 17:05:14.060000 17748 net.cpp:406] scale4_1 <- conv4_1
I1211 17:05:14.060000 17748 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 17:05:14.060000 17748 layer_factory.cpp:58] Creating layer scale4_1
I1211 17:05:14.060000 17748 net.cpp:122] Setting up scale4_1
I1211 17:05:14.060499 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.060499 17748 net.cpp:137] Memory required for data: 426190000
I1211 17:05:14.060499 17748 layer_factory.cpp:58] Creating layer relu4_1
I1211 17:05:14.060499 17748 net.cpp:84] Creating Layer relu4_1
I1211 17:05:14.060499 17748 net.cpp:406] relu4_1 <- conv4_1
I1211 17:05:14.060499 17748 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 17:05:14.060499 17748 net.cpp:122] Setting up relu4_1
I1211 17:05:14.060499 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.060499 17748 net.cpp:137] Memory required for data: 431310000
I1211 17:05:14.060499 17748 layer_factory.cpp:58] Creating layer conv4_2
I1211 17:05:14.060499 17748 net.cpp:84] Creating Layer conv4_2
I1211 17:05:14.060499 17748 net.cpp:406] conv4_2 <- conv4_1
I1211 17:05:14.060499 17748 net.cpp:380] conv4_2 -> conv4_2
I1211 17:05:14.062500 17748 net.cpp:122] Setting up conv4_2
I1211 17:05:14.062500 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.062500 17748 net.cpp:137] Memory required for data: 437249200
I1211 17:05:14.062500 17748 layer_factory.cpp:58] Creating layer bn4_2
I1211 17:05:14.062500 17748 net.cpp:84] Creating Layer bn4_2
I1211 17:05:14.062500 17748 net.cpp:406] bn4_2 <- conv4_2
I1211 17:05:14.062500 17748 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 17:05:14.062500 17748 net.cpp:122] Setting up bn4_2
I1211 17:05:14.063000 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.063000 17748 net.cpp:137] Memory required for data: 443188400
I1211 17:05:14.063000 17748 layer_factory.cpp:58] Creating layer scale4_2
I1211 17:05:14.063000 17748 net.cpp:84] Creating Layer scale4_2
I1211 17:05:14.063000 17748 net.cpp:406] scale4_2 <- conv4_2
I1211 17:05:14.063000 17748 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 17:05:14.063000 17748 layer_factory.cpp:58] Creating layer scale4_2
I1211 17:05:14.063000 17748 net.cpp:122] Setting up scale4_2
I1211 17:05:14.063000 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.063000 17748 net.cpp:137] Memory required for data: 449127600
I1211 17:05:14.063000 17748 layer_factory.cpp:58] Creating layer relu4_2
I1211 17:05:14.063000 17748 net.cpp:84] Creating Layer relu4_2
I1211 17:05:14.063000 17748 net.cpp:406] relu4_2 <- conv4_2
I1211 17:05:14.063000 17748 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 17:05:14.063999 17748 net.cpp:122] Setting up relu4_2
I1211 17:05:14.063999 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.063999 17748 net.cpp:137] Memory required for data: 455066800
I1211 17:05:14.063999 17748 layer_factory.cpp:58] Creating layer pool4_2
I1211 17:05:14.063999 17748 net.cpp:84] Creating Layer pool4_2
I1211 17:05:14.063999 17748 net.cpp:406] pool4_2 <- conv4_2
I1211 17:05:14.063999 17748 net.cpp:380] pool4_2 -> pool4_2
I1211 17:05:14.066001 17748 net.cpp:122] Setting up pool4_2
I1211 17:05:14.066001 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.066001 17748 net.cpp:137] Memory required for data: 456551600
I1211 17:05:14.066001 17748 layer_factory.cpp:58] Creating layer bn4_pool4_2
I1211 17:05:14.066001 17748 net.cpp:84] Creating Layer bn4_pool4_2
I1211 17:05:14.066001 17748 net.cpp:406] bn4_pool4_2 <- pool4_2
I1211 17:05:14.066001 17748 net.cpp:367] bn4_pool4_2 -> pool4_2 (in-place)
I1211 17:05:14.066001 17748 net.cpp:122] Setting up bn4_pool4_2
I1211 17:05:14.066001 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.066001 17748 net.cpp:137] Memory required for data: 458036400
I1211 17:05:14.066001 17748 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 17:05:14.066001 17748 net.cpp:84] Creating Layer scale4_pool4_2
I1211 17:05:14.066001 17748 net.cpp:406] scale4_pool4_2 <- pool4_2
I1211 17:05:14.066001 17748 net.cpp:367] scale4_pool4_2 -> pool4_2 (in-place)
I1211 17:05:14.066001 17748 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 17:05:14.066500 17748 net.cpp:122] Setting up scale4_pool4_2
I1211 17:05:14.066500 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.066500 17748 net.cpp:137] Memory required for data: 459521200
I1211 17:05:14.066500 17748 layer_factory.cpp:58] Creating layer relu4_pool4_2
I1211 17:05:14.066500 17748 net.cpp:84] Creating Layer relu4_pool4_2
I1211 17:05:14.066500 17748 net.cpp:406] relu4_pool4_2 <- pool4_2
I1211 17:05:14.066500 17748 net.cpp:367] relu4_pool4_2 -> pool4_2 (in-place)
I1211 17:05:14.067000 17748 net.cpp:122] Setting up relu4_pool4_2
I1211 17:05:14.067000 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.067000 17748 net.cpp:137] Memory required for data: 461006000
I1211 17:05:14.067000 17748 layer_factory.cpp:58] Creating layer conv4_0
I1211 17:05:14.067000 17748 net.cpp:84] Creating Layer conv4_0
I1211 17:05:14.067000 17748 net.cpp:406] conv4_0 <- pool4_2
I1211 17:05:14.067000 17748 net.cpp:380] conv4_0 -> conv4_0
I1211 17:05:14.068500 17748 net.cpp:122] Setting up conv4_0
I1211 17:05:14.068500 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.068500 17748 net.cpp:137] Memory required for data: 462490800
I1211 17:05:14.068500 17748 layer_factory.cpp:58] Creating layer bn4_0
I1211 17:05:14.068500 17748 net.cpp:84] Creating Layer bn4_0
I1211 17:05:14.068500 17748 net.cpp:406] bn4_0 <- conv4_0
I1211 17:05:14.068500 17748 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 17:05:14.069000 17748 net.cpp:122] Setting up bn4_0
I1211 17:05:14.069000 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.069000 17748 net.cpp:137] Memory required for data: 463975600
I1211 17:05:14.069000 17748 layer_factory.cpp:58] Creating layer scale4_0
I1211 17:05:14.069000 17748 net.cpp:84] Creating Layer scale4_0
I1211 17:05:14.069000 17748 net.cpp:406] scale4_0 <- conv4_0
I1211 17:05:14.069000 17748 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 17:05:14.069000 17748 layer_factory.cpp:58] Creating layer scale4_0
I1211 17:05:14.069000 17748 net.cpp:122] Setting up scale4_0
I1211 17:05:14.069000 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.069000 17748 net.cpp:137] Memory required for data: 465460400
I1211 17:05:14.069000 17748 layer_factory.cpp:58] Creating layer relu4_0
I1211 17:05:14.069000 17748 net.cpp:84] Creating Layer relu4_0
I1211 17:05:14.069000 17748 net.cpp:406] relu4_0 <- conv4_0
I1211 17:05:14.069000 17748 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 17:05:14.069500 17748 net.cpp:122] Setting up relu4_0
I1211 17:05:14.069500 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.069500 17748 net.cpp:137] Memory required for data: 466945200
I1211 17:05:14.069500 17748 layer_factory.cpp:58] Creating layer conv11
I1211 17:05:14.069500 17748 net.cpp:84] Creating Layer conv11
I1211 17:05:14.069500 17748 net.cpp:406] conv11 <- conv4_0
I1211 17:05:14.069500 17748 net.cpp:380] conv11 -> conv11
I1211 17:05:14.070999 17748 net.cpp:122] Setting up conv11
I1211 17:05:14.070999 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.070999 17748 net.cpp:137] Memory required for data: 468737200
I1211 17:05:14.070999 17748 layer_factory.cpp:58] Creating layer bn_conv11
I1211 17:05:14.070999 17748 net.cpp:84] Creating Layer bn_conv11
I1211 17:05:14.070999 17748 net.cpp:406] bn_conv11 <- conv11
I1211 17:05:14.070999 17748 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 17:05:14.071501 17748 net.cpp:122] Setting up bn_conv11
I1211 17:05:14.071501 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.071501 17748 net.cpp:137] Memory required for data: 470529200
I1211 17:05:14.071501 17748 layer_factory.cpp:58] Creating layer scale_conv11
I1211 17:05:14.071501 17748 net.cpp:84] Creating Layer scale_conv11
I1211 17:05:14.071501 17748 net.cpp:406] scale_conv11 <- conv11
I1211 17:05:14.071501 17748 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 17:05:14.071501 17748 layer_factory.cpp:58] Creating layer scale_conv11
I1211 17:05:14.072000 17748 net.cpp:122] Setting up scale_conv11
I1211 17:05:14.072000 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.072000 17748 net.cpp:137] Memory required for data: 472321200
I1211 17:05:14.072000 17748 layer_factory.cpp:58] Creating layer relu_conv11
I1211 17:05:14.072000 17748 net.cpp:84] Creating Layer relu_conv11
I1211 17:05:14.072000 17748 net.cpp:406] relu_conv11 <- conv11
I1211 17:05:14.072000 17748 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 17:05:14.072000 17748 net.cpp:122] Setting up relu_conv11
I1211 17:05:14.072000 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.072000 17748 net.cpp:137] Memory required for data: 474113200
I1211 17:05:14.072000 17748 layer_factory.cpp:58] Creating layer conv12
I1211 17:05:14.072000 17748 net.cpp:84] Creating Layer conv12
I1211 17:05:14.072000 17748 net.cpp:406] conv12 <- conv11
I1211 17:05:14.072000 17748 net.cpp:380] conv12 -> conv12
I1211 17:05:14.075001 17748 net.cpp:122] Setting up conv12
I1211 17:05:14.075001 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.075001 17748 net.cpp:137] Memory required for data: 476417200
I1211 17:05:14.075001 17748 layer_factory.cpp:58] Creating layer bn_conv12
I1211 17:05:14.075001 17748 net.cpp:84] Creating Layer bn_conv12
I1211 17:05:14.075001 17748 net.cpp:406] bn_conv12 <- conv12
I1211 17:05:14.075500 17748 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 17:05:14.075500 17748 net.cpp:122] Setting up bn_conv12
I1211 17:05:14.075500 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.075500 17748 net.cpp:137] Memory required for data: 478721200
I1211 17:05:14.075500 17748 layer_factory.cpp:58] Creating layer scale_conv12
I1211 17:05:14.075500 17748 net.cpp:84] Creating Layer scale_conv12
I1211 17:05:14.075500 17748 net.cpp:406] scale_conv12 <- conv12
I1211 17:05:14.075500 17748 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 17:05:14.075500 17748 layer_factory.cpp:58] Creating layer scale_conv12
I1211 17:05:14.075500 17748 net.cpp:122] Setting up scale_conv12
I1211 17:05:14.075500 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.075500 17748 net.cpp:137] Memory required for data: 481025200
I1211 17:05:14.075500 17748 layer_factory.cpp:58] Creating layer relu_conv12
I1211 17:05:14.075500 17748 net.cpp:84] Creating Layer relu_conv12
I1211 17:05:14.075500 17748 net.cpp:406] relu_conv12 <- conv12
I1211 17:05:14.075500 17748 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 17:05:14.076000 17748 net.cpp:122] Setting up relu_conv12
I1211 17:05:14.076000 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.076000 17748 net.cpp:137] Memory required for data: 483329200
I1211 17:05:14.076000 17748 layer_factory.cpp:58] Creating layer poolcp6
I1211 17:05:14.076000 17748 net.cpp:84] Creating Layer poolcp6
I1211 17:05:14.076000 17748 net.cpp:406] poolcp6 <- conv12
I1211 17:05:14.076000 17748 net.cpp:380] poolcp6 -> poolcp6
I1211 17:05:14.076000 17748 net.cpp:122] Setting up poolcp6
I1211 17:05:14.076000 17748 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 17:05:14.076000 17748 net.cpp:137] Memory required for data: 483365200
I1211 17:05:14.076000 17748 layer_factory.cpp:58] Creating layer ip1
I1211 17:05:14.076000 17748 net.cpp:84] Creating Layer ip1
I1211 17:05:14.076000 17748 net.cpp:406] ip1 <- poolcp6
I1211 17:05:14.076000 17748 net.cpp:380] ip1 -> ip1
I1211 17:05:14.076500 17748 net.cpp:122] Setting up ip1
I1211 17:05:14.076500 17748 net.cpp:129] Top shape: 100 100 (10000)
I1211 17:05:14.076500 17748 net.cpp:137] Memory required for data: 483405200
I1211 17:05:14.076500 17748 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 17:05:14.076500 17748 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 17:05:14.076500 17748 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 17:05:14.076500 17748 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 17:05:14.076500 17748 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 17:05:14.076500 17748 net.cpp:122] Setting up ip1_ip1_0_split
I1211 17:05:14.076500 17748 net.cpp:129] Top shape: 100 100 (10000)
I1211 17:05:14.076500 17748 net.cpp:129] Top shape: 100 100 (10000)
I1211 17:05:14.076500 17748 net.cpp:137] Memory required for data: 483485200
I1211 17:05:14.076500 17748 layer_factory.cpp:58] Creating layer accuracy_training
I1211 17:05:14.076500 17748 net.cpp:84] Creating Layer accuracy_training
I1211 17:05:14.076500 17748 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1211 17:05:14.076500 17748 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1211 17:05:14.076500 17748 net.cpp:380] accuracy_training -> accuracy_training
I1211 17:05:14.076500 17748 net.cpp:122] Setting up accuracy_training
I1211 17:05:14.076500 17748 net.cpp:129] Top shape: (1)
I1211 17:05:14.076500 17748 net.cpp:137] Memory required for data: 483485204
I1211 17:05:14.076500 17748 layer_factory.cpp:58] Creating layer loss
I1211 17:05:14.076500 17748 net.cpp:84] Creating Layer loss
I1211 17:05:14.076500 17748 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 17:05:14.076500 17748 net.cpp:406] loss <- label_cifar_1_split_1
I1211 17:05:14.076500 17748 net.cpp:380] loss -> loss
I1211 17:05:14.076500 17748 layer_factory.cpp:58] Creating layer loss
I1211 17:05:14.077502 17748 net.cpp:122] Setting up loss
I1211 17:05:14.077502 17748 net.cpp:129] Top shape: (1)
I1211 17:05:14.077502 17748 net.cpp:132]     with loss weight 1
I1211 17:05:14.077502 17748 net.cpp:137] Memory required for data: 483485208
I1211 17:05:14.077502 17748 net.cpp:198] loss needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:200] accuracy_training does not need backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] ip1 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] poolcp6 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] relu_conv12 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] scale_conv12 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] bn_conv12 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] conv12 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] relu_conv11 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] scale_conv11 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] bn_conv11 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] conv11 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] relu4_0 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] scale4_0 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] bn4_0 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] conv4_0 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] relu4_pool4_2 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] scale4_pool4_2 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] bn4_pool4_2 needs backward computation.
I1211 17:05:14.077502 17748 net.cpp:198] pool4_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu4_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale4_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn4_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv4_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu4_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale4_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn4_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv4_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu4 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale4 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn4 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv4 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu3_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale3_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn3_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv3_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu3 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale3 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn3 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv3 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu2_pool2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale2_pool2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn2_pool2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] pool2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu2_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale2_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn2_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv2_2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv2_1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv2 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu1_0 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale1_0 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn1_0 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv1_0 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] relu1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] scale1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] bn1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:198] conv1 needs backward computation.
I1211 17:05:14.078001 17748 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 17:05:14.078001 17748 net.cpp:200] cifar does not need backward computation.
I1211 17:05:14.078001 17748 net.cpp:242] This network produces output accuracy_training
I1211 17:05:14.078001 17748 net.cpp:242] This network produces output loss
I1211 17:05:14.078001 17748 net.cpp:255] Network initialization done.
I1211 17:05:14.079501 17748 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 17:05:14.079501 17748 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 17:05:14.079501 17748 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_pool2_1
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_pool4_2
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1211 17:05:14.079501 17748 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1211 17:05:14.080000 17748 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV2_WnonLin_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_pool2_1"
  type: "BatchNorm"
  bottom: "pool2_1"
  top: "pool2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_pool2_1"
  type: "Scale"
  bottom: "pool2_1"
  top: "pool2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_pool2_1"
  type: "ReLU"
  bottom: "pool2_1"
  top: "pool2_1"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_pool4_2"
  type: "BatchNorm"
  bottom: "pool4_2"
  top: "pool4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_pool4_2"
  type: "Scale"
  bottom: "pool4_2"
  top: "pool4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_pool4_2"
  type: "ReLU"
  bottom: "pool4_2"
  top: "pool4_2"
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 17:05:14.080500 17748 layer_factory.cpp:58] Creating layer cifar
I1211 17:05:14.086500 17748 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1211 17:05:14.087004 17748 net.cpp:84] Creating Layer cifar
I1211 17:05:14.087004 17748 net.cpp:380] cifar -> data
I1211 17:05:14.087004 17748 net.cpp:380] cifar -> label
I1211 17:05:14.087004 17748 data_layer.cpp:45] output data size: 100,3,32,32
I1211 17:05:14.097002 17748 net.cpp:122] Setting up cifar
I1211 17:05:14.097002 17748 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 17:05:14.097002 17748 net.cpp:129] Top shape: 100 (100)
I1211 17:05:14.097002 17748 net.cpp:137] Memory required for data: 1229200
I1211 17:05:14.097002 17748 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 17:05:14.097002 17748 net.cpp:84] Creating Layer label_cifar_1_split
I1211 17:05:14.097002 17748 net.cpp:406] label_cifar_1_split <- label
I1211 17:05:14.097002 17748 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 17:05:14.097002 17748 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 17:05:14.097501 17748 net.cpp:122] Setting up label_cifar_1_split
I1211 17:05:14.097501 17748 net.cpp:129] Top shape: 100 (100)
I1211 17:05:14.097501 17748 net.cpp:129] Top shape: 100 (100)
I1211 17:05:14.097501 17748 net.cpp:137] Memory required for data: 1230000
I1211 17:05:14.097501 17748 layer_factory.cpp:58] Creating layer conv1
I1211 17:05:14.097501 17748 net.cpp:84] Creating Layer conv1
I1211 17:05:14.097501 17748 net.cpp:406] conv1 <- data
I1211 17:05:14.097501 17748 net.cpp:380] conv1 -> conv1
I1211 17:05:14.099000 17848 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 17:05:14.099500 17748 net.cpp:122] Setting up conv1
I1211 17:05:14.099500 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.099500 17748 net.cpp:137] Memory required for data: 13518000
I1211 17:05:14.099500 17748 layer_factory.cpp:58] Creating layer bn1
I1211 17:05:14.099500 17748 net.cpp:84] Creating Layer bn1
I1211 17:05:14.099500 17748 net.cpp:406] bn1 <- conv1
I1211 17:05:14.099500 17748 net.cpp:367] bn1 -> conv1 (in-place)
I1211 17:05:14.100000 17748 net.cpp:122] Setting up bn1
I1211 17:05:14.100000 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.100000 17748 net.cpp:137] Memory required for data: 25806000
I1211 17:05:14.100000 17748 layer_factory.cpp:58] Creating layer scale1
I1211 17:05:14.100000 17748 net.cpp:84] Creating Layer scale1
I1211 17:05:14.100000 17748 net.cpp:406] scale1 <- conv1
I1211 17:05:14.100000 17748 net.cpp:367] scale1 -> conv1 (in-place)
I1211 17:05:14.100000 17748 layer_factory.cpp:58] Creating layer scale1
I1211 17:05:14.100000 17748 net.cpp:122] Setting up scale1
I1211 17:05:14.100000 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.100000 17748 net.cpp:137] Memory required for data: 38094000
I1211 17:05:14.100000 17748 layer_factory.cpp:58] Creating layer relu1
I1211 17:05:14.100000 17748 net.cpp:84] Creating Layer relu1
I1211 17:05:14.100000 17748 net.cpp:406] relu1 <- conv1
I1211 17:05:14.100000 17748 net.cpp:367] relu1 -> conv1 (in-place)
I1211 17:05:14.100500 17748 net.cpp:122] Setting up relu1
I1211 17:05:14.100500 17748 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 17:05:14.100500 17748 net.cpp:137] Memory required for data: 50382000
I1211 17:05:14.100500 17748 layer_factory.cpp:58] Creating layer conv1_0
I1211 17:05:14.100500 17748 net.cpp:84] Creating Layer conv1_0
I1211 17:05:14.100500 17748 net.cpp:406] conv1_0 <- conv1
I1211 17:05:14.100500 17748 net.cpp:380] conv1_0 -> conv1_0
I1211 17:05:14.102500 17748 net.cpp:122] Setting up conv1_0
I1211 17:05:14.102500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.102500 17748 net.cpp:137] Memory required for data: 66766000
I1211 17:05:14.102500 17748 layer_factory.cpp:58] Creating layer bn1_0
I1211 17:05:14.102500 17748 net.cpp:84] Creating Layer bn1_0
I1211 17:05:14.102500 17748 net.cpp:406] bn1_0 <- conv1_0
I1211 17:05:14.102500 17748 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 17:05:14.103005 17748 net.cpp:122] Setting up bn1_0
I1211 17:05:14.103005 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.103005 17748 net.cpp:137] Memory required for data: 83150000
I1211 17:05:14.103005 17748 layer_factory.cpp:58] Creating layer scale1_0
I1211 17:05:14.103005 17748 net.cpp:84] Creating Layer scale1_0
I1211 17:05:14.103005 17748 net.cpp:406] scale1_0 <- conv1_0
I1211 17:05:14.103005 17748 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 17:05:14.103005 17748 layer_factory.cpp:58] Creating layer scale1_0
I1211 17:05:14.103005 17748 net.cpp:122] Setting up scale1_0
I1211 17:05:14.103005 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.103005 17748 net.cpp:137] Memory required for data: 99534000
I1211 17:05:14.103005 17748 layer_factory.cpp:58] Creating layer relu1_0
I1211 17:05:14.103005 17748 net.cpp:84] Creating Layer relu1_0
I1211 17:05:14.103005 17748 net.cpp:406] relu1_0 <- conv1_0
I1211 17:05:14.103500 17748 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 17:05:14.103500 17748 net.cpp:122] Setting up relu1_0
I1211 17:05:14.103500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.104001 17748 net.cpp:137] Memory required for data: 115918000
I1211 17:05:14.104001 17748 layer_factory.cpp:58] Creating layer conv2
I1211 17:05:14.104001 17748 net.cpp:84] Creating Layer conv2
I1211 17:05:14.104001 17748 net.cpp:406] conv2 <- conv1_0
I1211 17:05:14.104001 17748 net.cpp:380] conv2 -> conv2
I1211 17:05:14.106000 17748 net.cpp:122] Setting up conv2
I1211 17:05:14.106000 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.106000 17748 net.cpp:137] Memory required for data: 132302000
I1211 17:05:14.106000 17748 layer_factory.cpp:58] Creating layer bn2
I1211 17:05:14.106000 17748 net.cpp:84] Creating Layer bn2
I1211 17:05:14.106000 17748 net.cpp:406] bn2 <- conv2
I1211 17:05:14.106000 17748 net.cpp:367] bn2 -> conv2 (in-place)
I1211 17:05:14.106000 17748 net.cpp:122] Setting up bn2
I1211 17:05:14.106000 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.106000 17748 net.cpp:137] Memory required for data: 148686000
I1211 17:05:14.106000 17748 layer_factory.cpp:58] Creating layer scale2
I1211 17:05:14.106000 17748 net.cpp:84] Creating Layer scale2
I1211 17:05:14.106000 17748 net.cpp:406] scale2 <- conv2
I1211 17:05:14.106000 17748 net.cpp:367] scale2 -> conv2 (in-place)
I1211 17:05:14.106000 17748 layer_factory.cpp:58] Creating layer scale2
I1211 17:05:14.106500 17748 net.cpp:122] Setting up scale2
I1211 17:05:14.106500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.106500 17748 net.cpp:137] Memory required for data: 165070000
I1211 17:05:14.106500 17748 layer_factory.cpp:58] Creating layer relu2
I1211 17:05:14.106500 17748 net.cpp:84] Creating Layer relu2
I1211 17:05:14.106500 17748 net.cpp:406] relu2 <- conv2
I1211 17:05:14.106500 17748 net.cpp:367] relu2 -> conv2 (in-place)
I1211 17:05:14.106500 17748 net.cpp:122] Setting up relu2
I1211 17:05:14.106500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.106500 17748 net.cpp:137] Memory required for data: 181454000
I1211 17:05:14.106500 17748 layer_factory.cpp:58] Creating layer conv2_1
I1211 17:05:14.106500 17748 net.cpp:84] Creating Layer conv2_1
I1211 17:05:14.106500 17748 net.cpp:406] conv2_1 <- conv2
I1211 17:05:14.106500 17748 net.cpp:380] conv2_1 -> conv2_1
I1211 17:05:14.108500 17748 net.cpp:122] Setting up conv2_1
I1211 17:05:14.108500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.108500 17748 net.cpp:137] Memory required for data: 197838000
I1211 17:05:14.108500 17748 layer_factory.cpp:58] Creating layer bn2_1
I1211 17:05:14.108500 17748 net.cpp:84] Creating Layer bn2_1
I1211 17:05:14.108500 17748 net.cpp:406] bn2_1 <- conv2_1
I1211 17:05:14.108500 17748 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 17:05:14.108500 17748 net.cpp:122] Setting up bn2_1
I1211 17:05:14.108500 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.108500 17748 net.cpp:137] Memory required for data: 214222000
I1211 17:05:14.108500 17748 layer_factory.cpp:58] Creating layer scale2_1
I1211 17:05:14.108500 17748 net.cpp:84] Creating Layer scale2_1
I1211 17:05:14.108500 17748 net.cpp:406] scale2_1 <- conv2_1
I1211 17:05:14.108500 17748 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 17:05:14.108500 17748 layer_factory.cpp:58] Creating layer scale2_1
I1211 17:05:14.109000 17748 net.cpp:122] Setting up scale2_1
I1211 17:05:14.109000 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.109000 17748 net.cpp:137] Memory required for data: 230606000
I1211 17:05:14.109000 17748 layer_factory.cpp:58] Creating layer relu2_1
I1211 17:05:14.109000 17748 net.cpp:84] Creating Layer relu2_1
I1211 17:05:14.109000 17748 net.cpp:406] relu2_1 <- conv2_1
I1211 17:05:14.109000 17748 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 17:05:14.109000 17748 net.cpp:122] Setting up relu2_1
I1211 17:05:14.109000 17748 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 17:05:14.109000 17748 net.cpp:137] Memory required for data: 246990000
I1211 17:05:14.109000 17748 layer_factory.cpp:58] Creating layer conv2_2
I1211 17:05:14.109000 17748 net.cpp:84] Creating Layer conv2_2
I1211 17:05:14.109000 17748 net.cpp:406] conv2_2 <- conv2_1
I1211 17:05:14.109500 17748 net.cpp:380] conv2_2 -> conv2_2
I1211 17:05:14.111001 17748 net.cpp:122] Setting up conv2_2
I1211 17:05:14.111001 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.111001 17748 net.cpp:137] Memory required for data: 267470000
I1211 17:05:14.111001 17748 layer_factory.cpp:58] Creating layer bn2_2
I1211 17:05:14.111001 17748 net.cpp:84] Creating Layer bn2_2
I1211 17:05:14.111500 17748 net.cpp:406] bn2_2 <- conv2_2
I1211 17:05:14.111500 17748 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 17:05:14.111500 17748 net.cpp:122] Setting up bn2_2
I1211 17:05:14.111500 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.111500 17748 net.cpp:137] Memory required for data: 287950000
I1211 17:05:14.111500 17748 layer_factory.cpp:58] Creating layer scale2_2
I1211 17:05:14.111500 17748 net.cpp:84] Creating Layer scale2_2
I1211 17:05:14.111500 17748 net.cpp:406] scale2_2 <- conv2_2
I1211 17:05:14.111500 17748 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 17:05:14.111500 17748 layer_factory.cpp:58] Creating layer scale2_2
I1211 17:05:14.112000 17748 net.cpp:122] Setting up scale2_2
I1211 17:05:14.112000 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.112000 17748 net.cpp:137] Memory required for data: 308430000
I1211 17:05:14.112000 17748 layer_factory.cpp:58] Creating layer relu2_2
I1211 17:05:14.112000 17748 net.cpp:84] Creating Layer relu2_2
I1211 17:05:14.112000 17748 net.cpp:406] relu2_2 <- conv2_2
I1211 17:05:14.112000 17748 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 17:05:14.112000 17748 net.cpp:122] Setting up relu2_2
I1211 17:05:14.112000 17748 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 17:05:14.112000 17748 net.cpp:137] Memory required for data: 328910000
I1211 17:05:14.112000 17748 layer_factory.cpp:58] Creating layer pool2_1
I1211 17:05:14.112000 17748 net.cpp:84] Creating Layer pool2_1
I1211 17:05:14.112000 17748 net.cpp:406] pool2_1 <- conv2_2
I1211 17:05:14.112000 17748 net.cpp:380] pool2_1 -> pool2_1
I1211 17:05:14.114500 17748 net.cpp:122] Setting up pool2_1
I1211 17:05:14.114500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.114500 17748 net.cpp:137] Memory required for data: 334030000
I1211 17:05:14.114500 17748 layer_factory.cpp:58] Creating layer bn2_pool2_1
I1211 17:05:14.114500 17748 net.cpp:84] Creating Layer bn2_pool2_1
I1211 17:05:14.114500 17748 net.cpp:406] bn2_pool2_1 <- pool2_1
I1211 17:05:14.114500 17748 net.cpp:367] bn2_pool2_1 -> pool2_1 (in-place)
I1211 17:05:14.114500 17748 net.cpp:122] Setting up bn2_pool2_1
I1211 17:05:14.114500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.114500 17748 net.cpp:137] Memory required for data: 339150000
I1211 17:05:14.114500 17748 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 17:05:14.115000 17748 net.cpp:84] Creating Layer scale2_pool2_1
I1211 17:05:14.115000 17748 net.cpp:406] scale2_pool2_1 <- pool2_1
I1211 17:05:14.115000 17748 net.cpp:367] scale2_pool2_1 -> pool2_1 (in-place)
I1211 17:05:14.115000 17748 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 17:05:14.115000 17748 net.cpp:122] Setting up scale2_pool2_1
I1211 17:05:14.115000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.115000 17748 net.cpp:137] Memory required for data: 344270000
I1211 17:05:14.115000 17748 layer_factory.cpp:58] Creating layer relu2_pool2_1
I1211 17:05:14.115000 17748 net.cpp:84] Creating Layer relu2_pool2_1
I1211 17:05:14.115000 17748 net.cpp:406] relu2_pool2_1 <- pool2_1
I1211 17:05:14.115000 17748 net.cpp:367] relu2_pool2_1 -> pool2_1 (in-place)
I1211 17:05:14.116000 17748 net.cpp:122] Setting up relu2_pool2_1
I1211 17:05:14.116000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.116000 17748 net.cpp:137] Memory required for data: 349390000
I1211 17:05:14.116000 17748 layer_factory.cpp:58] Creating layer conv3
I1211 17:05:14.116000 17748 net.cpp:84] Creating Layer conv3
I1211 17:05:14.116000 17748 net.cpp:406] conv3 <- pool2_1
I1211 17:05:14.116000 17748 net.cpp:380] conv3 -> conv3
I1211 17:05:14.117000 17748 net.cpp:122] Setting up conv3
I1211 17:05:14.117000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.117000 17748 net.cpp:137] Memory required for data: 354510000
I1211 17:05:14.117000 17748 layer_factory.cpp:58] Creating layer bn3
I1211 17:05:14.117000 17748 net.cpp:84] Creating Layer bn3
I1211 17:05:14.117000 17748 net.cpp:406] bn3 <- conv3
I1211 17:05:14.117000 17748 net.cpp:367] bn3 -> conv3 (in-place)
I1211 17:05:14.117000 17748 net.cpp:122] Setting up bn3
I1211 17:05:14.117000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.117000 17748 net.cpp:137] Memory required for data: 359630000
I1211 17:05:14.117000 17748 layer_factory.cpp:58] Creating layer scale3
I1211 17:05:14.117000 17748 net.cpp:84] Creating Layer scale3
I1211 17:05:14.117000 17748 net.cpp:406] scale3 <- conv3
I1211 17:05:14.117000 17748 net.cpp:367] scale3 -> conv3 (in-place)
I1211 17:05:14.117000 17748 layer_factory.cpp:58] Creating layer scale3
I1211 17:05:14.117501 17748 net.cpp:122] Setting up scale3
I1211 17:05:14.117501 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.117501 17748 net.cpp:137] Memory required for data: 364750000
I1211 17:05:14.117501 17748 layer_factory.cpp:58] Creating layer relu3
I1211 17:05:14.117501 17748 net.cpp:84] Creating Layer relu3
I1211 17:05:14.117501 17748 net.cpp:406] relu3 <- conv3
I1211 17:05:14.117501 17748 net.cpp:367] relu3 -> conv3 (in-place)
I1211 17:05:14.118000 17748 net.cpp:122] Setting up relu3
I1211 17:05:14.118000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.118000 17748 net.cpp:137] Memory required for data: 369870000
I1211 17:05:14.118000 17748 layer_factory.cpp:58] Creating layer conv3_1
I1211 17:05:14.118000 17748 net.cpp:84] Creating Layer conv3_1
I1211 17:05:14.118000 17748 net.cpp:406] conv3_1 <- conv3
I1211 17:05:14.118000 17748 net.cpp:380] conv3_1 -> conv3_1
I1211 17:05:14.119501 17748 net.cpp:122] Setting up conv3_1
I1211 17:05:14.119501 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.119501 17748 net.cpp:137] Memory required for data: 374990000
I1211 17:05:14.119501 17748 layer_factory.cpp:58] Creating layer bn3_1
I1211 17:05:14.119501 17748 net.cpp:84] Creating Layer bn3_1
I1211 17:05:14.119501 17748 net.cpp:406] bn3_1 <- conv3_1
I1211 17:05:14.119501 17748 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 17:05:14.119501 17748 net.cpp:122] Setting up bn3_1
I1211 17:05:14.119501 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.120000 17748 net.cpp:137] Memory required for data: 380110000
I1211 17:05:14.120000 17748 layer_factory.cpp:58] Creating layer scale3_1
I1211 17:05:14.120000 17748 net.cpp:84] Creating Layer scale3_1
I1211 17:05:14.120000 17748 net.cpp:406] scale3_1 <- conv3_1
I1211 17:05:14.120000 17748 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 17:05:14.120000 17748 layer_factory.cpp:58] Creating layer scale3_1
I1211 17:05:14.120000 17748 net.cpp:122] Setting up scale3_1
I1211 17:05:14.120000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.120000 17748 net.cpp:137] Memory required for data: 385230000
I1211 17:05:14.120000 17748 layer_factory.cpp:58] Creating layer relu3_1
I1211 17:05:14.120000 17748 net.cpp:84] Creating Layer relu3_1
I1211 17:05:14.120000 17748 net.cpp:406] relu3_1 <- conv3_1
I1211 17:05:14.120000 17748 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 17:05:14.120000 17748 net.cpp:122] Setting up relu3_1
I1211 17:05:14.120000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.120000 17748 net.cpp:137] Memory required for data: 390350000
I1211 17:05:14.120000 17748 layer_factory.cpp:58] Creating layer conv4
I1211 17:05:14.120000 17748 net.cpp:84] Creating Layer conv4
I1211 17:05:14.120000 17748 net.cpp:406] conv4 <- conv3_1
I1211 17:05:14.120000 17748 net.cpp:380] conv4 -> conv4
I1211 17:05:14.122001 17748 net.cpp:122] Setting up conv4
I1211 17:05:14.122001 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.122503 17748 net.cpp:137] Memory required for data: 395470000
I1211 17:05:14.122503 17748 layer_factory.cpp:58] Creating layer bn4
I1211 17:05:14.122503 17748 net.cpp:84] Creating Layer bn4
I1211 17:05:14.122503 17748 net.cpp:406] bn4 <- conv4
I1211 17:05:14.122503 17748 net.cpp:367] bn4 -> conv4 (in-place)
I1211 17:05:14.123008 17748 net.cpp:122] Setting up bn4
I1211 17:05:14.123008 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.123008 17748 net.cpp:137] Memory required for data: 400590000
I1211 17:05:14.123008 17748 layer_factory.cpp:58] Creating layer scale4
I1211 17:05:14.123008 17748 net.cpp:84] Creating Layer scale4
I1211 17:05:14.123008 17748 net.cpp:406] scale4 <- conv4
I1211 17:05:14.123008 17748 net.cpp:367] scale4 -> conv4 (in-place)
I1211 17:05:14.123008 17748 layer_factory.cpp:58] Creating layer scale4
I1211 17:05:14.123500 17748 net.cpp:122] Setting up scale4
I1211 17:05:14.123500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.123500 17748 net.cpp:137] Memory required for data: 405710000
I1211 17:05:14.123500 17748 layer_factory.cpp:58] Creating layer relu4
I1211 17:05:14.123500 17748 net.cpp:84] Creating Layer relu4
I1211 17:05:14.123500 17748 net.cpp:406] relu4 <- conv4
I1211 17:05:14.123500 17748 net.cpp:367] relu4 -> conv4 (in-place)
I1211 17:05:14.123500 17748 net.cpp:122] Setting up relu4
I1211 17:05:14.123500 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.123500 17748 net.cpp:137] Memory required for data: 410830000
I1211 17:05:14.123500 17748 layer_factory.cpp:58] Creating layer conv4_1
I1211 17:05:14.123500 17748 net.cpp:84] Creating Layer conv4_1
I1211 17:05:14.123500 17748 net.cpp:406] conv4_1 <- conv4
I1211 17:05:14.123500 17748 net.cpp:380] conv4_1 -> conv4_1
I1211 17:05:14.125000 17748 net.cpp:122] Setting up conv4_1
I1211 17:05:14.125000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.125000 17748 net.cpp:137] Memory required for data: 415950000
I1211 17:05:14.125000 17748 layer_factory.cpp:58] Creating layer bn4_1
I1211 17:05:14.125000 17748 net.cpp:84] Creating Layer bn4_1
I1211 17:05:14.125000 17748 net.cpp:406] bn4_1 <- conv4_1
I1211 17:05:14.125000 17748 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 17:05:14.125501 17748 net.cpp:122] Setting up bn4_1
I1211 17:05:14.125501 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.125501 17748 net.cpp:137] Memory required for data: 421070000
I1211 17:05:14.125501 17748 layer_factory.cpp:58] Creating layer scale4_1
I1211 17:05:14.125501 17748 net.cpp:84] Creating Layer scale4_1
I1211 17:05:14.125501 17748 net.cpp:406] scale4_1 <- conv4_1
I1211 17:05:14.125501 17748 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 17:05:14.125501 17748 layer_factory.cpp:58] Creating layer scale4_1
I1211 17:05:14.125501 17748 net.cpp:122] Setting up scale4_1
I1211 17:05:14.125501 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.125501 17748 net.cpp:137] Memory required for data: 426190000
I1211 17:05:14.125501 17748 layer_factory.cpp:58] Creating layer relu4_1
I1211 17:05:14.125501 17748 net.cpp:84] Creating Layer relu4_1
I1211 17:05:14.125501 17748 net.cpp:406] relu4_1 <- conv4_1
I1211 17:05:14.125501 17748 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 17:05:14.126000 17748 net.cpp:122] Setting up relu4_1
I1211 17:05:14.126000 17748 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 17:05:14.126000 17748 net.cpp:137] Memory required for data: 431310000
I1211 17:05:14.126000 17748 layer_factory.cpp:58] Creating layer conv4_2
I1211 17:05:14.126000 17748 net.cpp:84] Creating Layer conv4_2
I1211 17:05:14.126000 17748 net.cpp:406] conv4_2 <- conv4_1
I1211 17:05:14.126000 17748 net.cpp:380] conv4_2 -> conv4_2
I1211 17:05:14.127501 17748 net.cpp:122] Setting up conv4_2
I1211 17:05:14.127501 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.127501 17748 net.cpp:137] Memory required for data: 437249200
I1211 17:05:14.127501 17748 layer_factory.cpp:58] Creating layer bn4_2
I1211 17:05:14.127501 17748 net.cpp:84] Creating Layer bn4_2
I1211 17:05:14.127501 17748 net.cpp:406] bn4_2 <- conv4_2
I1211 17:05:14.127501 17748 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 17:05:14.128000 17748 net.cpp:122] Setting up bn4_2
I1211 17:05:14.128000 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.128000 17748 net.cpp:137] Memory required for data: 443188400
I1211 17:05:14.128000 17748 layer_factory.cpp:58] Creating layer scale4_2
I1211 17:05:14.128000 17748 net.cpp:84] Creating Layer scale4_2
I1211 17:05:14.128000 17748 net.cpp:406] scale4_2 <- conv4_2
I1211 17:05:14.128000 17748 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 17:05:14.128000 17748 layer_factory.cpp:58] Creating layer scale4_2
I1211 17:05:14.128000 17748 net.cpp:122] Setting up scale4_2
I1211 17:05:14.128000 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.128000 17748 net.cpp:137] Memory required for data: 449127600
I1211 17:05:14.128000 17748 layer_factory.cpp:58] Creating layer relu4_2
I1211 17:05:14.128000 17748 net.cpp:84] Creating Layer relu4_2
I1211 17:05:14.128000 17748 net.cpp:406] relu4_2 <- conv4_2
I1211 17:05:14.128000 17748 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 17:05:14.128500 17748 net.cpp:122] Setting up relu4_2
I1211 17:05:14.128500 17748 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 17:05:14.128500 17748 net.cpp:137] Memory required for data: 455066800
I1211 17:05:14.128500 17748 layer_factory.cpp:58] Creating layer pool4_2
I1211 17:05:14.128500 17748 net.cpp:84] Creating Layer pool4_2
I1211 17:05:14.128500 17748 net.cpp:406] pool4_2 <- conv4_2
I1211 17:05:14.128500 17748 net.cpp:380] pool4_2 -> pool4_2
I1211 17:05:14.130002 17748 net.cpp:122] Setting up pool4_2
I1211 17:05:14.130002 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.130002 17748 net.cpp:137] Memory required for data: 456551600
I1211 17:05:14.130002 17748 layer_factory.cpp:58] Creating layer bn4_pool4_2
I1211 17:05:14.130002 17748 net.cpp:84] Creating Layer bn4_pool4_2
I1211 17:05:14.130002 17748 net.cpp:406] bn4_pool4_2 <- pool4_2
I1211 17:05:14.130002 17748 net.cpp:367] bn4_pool4_2 -> pool4_2 (in-place)
I1211 17:05:14.130501 17748 net.cpp:122] Setting up bn4_pool4_2
I1211 17:05:14.130501 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.130501 17748 net.cpp:137] Memory required for data: 458036400
I1211 17:05:14.130501 17748 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 17:05:14.130501 17748 net.cpp:84] Creating Layer scale4_pool4_2
I1211 17:05:14.130501 17748 net.cpp:406] scale4_pool4_2 <- pool4_2
I1211 17:05:14.130501 17748 net.cpp:367] scale4_pool4_2 -> pool4_2 (in-place)
I1211 17:05:14.130501 17748 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 17:05:14.130501 17748 net.cpp:122] Setting up scale4_pool4_2
I1211 17:05:14.130501 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.131000 17748 net.cpp:137] Memory required for data: 459521200
I1211 17:05:14.131000 17748 layer_factory.cpp:58] Creating layer relu4_pool4_2
I1211 17:05:14.131000 17748 net.cpp:84] Creating Layer relu4_pool4_2
I1211 17:05:14.131000 17748 net.cpp:406] relu4_pool4_2 <- pool4_2
I1211 17:05:14.131000 17748 net.cpp:367] relu4_pool4_2 -> pool4_2 (in-place)
I1211 17:05:14.131501 17748 net.cpp:122] Setting up relu4_pool4_2
I1211 17:05:14.131501 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.131501 17748 net.cpp:137] Memory required for data: 461006000
I1211 17:05:14.131501 17748 layer_factory.cpp:58] Creating layer conv4_0
I1211 17:05:14.131501 17748 net.cpp:84] Creating Layer conv4_0
I1211 17:05:14.131501 17748 net.cpp:406] conv4_0 <- pool4_2
I1211 17:05:14.131501 17748 net.cpp:380] conv4_0 -> conv4_0
I1211 17:05:14.133000 17748 net.cpp:122] Setting up conv4_0
I1211 17:05:14.133499 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.133499 17748 net.cpp:137] Memory required for data: 462490800
I1211 17:05:14.133499 17748 layer_factory.cpp:58] Creating layer bn4_0
I1211 17:05:14.133499 17748 net.cpp:84] Creating Layer bn4_0
I1211 17:05:14.133499 17748 net.cpp:406] bn4_0 <- conv4_0
I1211 17:05:14.133499 17748 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 17:05:14.133499 17748 net.cpp:122] Setting up bn4_0
I1211 17:05:14.133499 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.133499 17748 net.cpp:137] Memory required for data: 463975600
I1211 17:05:14.133499 17748 layer_factory.cpp:58] Creating layer scale4_0
I1211 17:05:14.133499 17748 net.cpp:84] Creating Layer scale4_0
I1211 17:05:14.133499 17748 net.cpp:406] scale4_0 <- conv4_0
I1211 17:05:14.133499 17748 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 17:05:14.133499 17748 layer_factory.cpp:58] Creating layer scale4_0
I1211 17:05:14.133999 17748 net.cpp:122] Setting up scale4_0
I1211 17:05:14.133999 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.133999 17748 net.cpp:137] Memory required for data: 465460400
I1211 17:05:14.133999 17748 layer_factory.cpp:58] Creating layer relu4_0
I1211 17:05:14.133999 17748 net.cpp:84] Creating Layer relu4_0
I1211 17:05:14.133999 17748 net.cpp:406] relu4_0 <- conv4_0
I1211 17:05:14.133999 17748 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 17:05:14.134500 17748 net.cpp:122] Setting up relu4_0
I1211 17:05:14.134500 17748 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 17:05:14.134500 17748 net.cpp:137] Memory required for data: 466945200
I1211 17:05:14.134500 17748 layer_factory.cpp:58] Creating layer conv11
I1211 17:05:14.134500 17748 net.cpp:84] Creating Layer conv11
I1211 17:05:14.134500 17748 net.cpp:406] conv11 <- conv4_0
I1211 17:05:14.134500 17748 net.cpp:380] conv11 -> conv11
I1211 17:05:14.136500 17748 net.cpp:122] Setting up conv11
I1211 17:05:14.136500 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.136500 17748 net.cpp:137] Memory required for data: 468737200
I1211 17:05:14.136500 17748 layer_factory.cpp:58] Creating layer bn_conv11
I1211 17:05:14.136500 17748 net.cpp:84] Creating Layer bn_conv11
I1211 17:05:14.136500 17748 net.cpp:406] bn_conv11 <- conv11
I1211 17:05:14.136500 17748 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 17:05:14.136500 17748 net.cpp:122] Setting up bn_conv11
I1211 17:05:14.136500 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.136500 17748 net.cpp:137] Memory required for data: 470529200
I1211 17:05:14.136500 17748 layer_factory.cpp:58] Creating layer scale_conv11
I1211 17:05:14.136500 17748 net.cpp:84] Creating Layer scale_conv11
I1211 17:05:14.136500 17748 net.cpp:406] scale_conv11 <- conv11
I1211 17:05:14.137001 17748 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 17:05:14.137001 17748 layer_factory.cpp:58] Creating layer scale_conv11
I1211 17:05:14.137001 17748 net.cpp:122] Setting up scale_conv11
I1211 17:05:14.137001 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.137001 17748 net.cpp:137] Memory required for data: 472321200
I1211 17:05:14.137001 17748 layer_factory.cpp:58] Creating layer relu_conv11
I1211 17:05:14.137001 17748 net.cpp:84] Creating Layer relu_conv11
I1211 17:05:14.137001 17748 net.cpp:406] relu_conv11 <- conv11
I1211 17:05:14.137001 17748 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 17:05:14.137501 17748 net.cpp:122] Setting up relu_conv11
I1211 17:05:14.137501 17748 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 17:05:14.137501 17748 net.cpp:137] Memory required for data: 474113200
I1211 17:05:14.137501 17748 layer_factory.cpp:58] Creating layer conv12
I1211 17:05:14.137501 17748 net.cpp:84] Creating Layer conv12
I1211 17:05:14.137501 17748 net.cpp:406] conv12 <- conv11
I1211 17:05:14.137501 17748 net.cpp:380] conv12 -> conv12
I1211 17:05:14.139500 17748 net.cpp:122] Setting up conv12
I1211 17:05:14.139500 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.139500 17748 net.cpp:137] Memory required for data: 476417200
I1211 17:05:14.139500 17748 layer_factory.cpp:58] Creating layer bn_conv12
I1211 17:05:14.139500 17748 net.cpp:84] Creating Layer bn_conv12
I1211 17:05:14.139500 17748 net.cpp:406] bn_conv12 <- conv12
I1211 17:05:14.139500 17748 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 17:05:14.139500 17748 net.cpp:122] Setting up bn_conv12
I1211 17:05:14.139500 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.139500 17748 net.cpp:137] Memory required for data: 478721200
I1211 17:05:14.140000 17748 layer_factory.cpp:58] Creating layer scale_conv12
I1211 17:05:14.140000 17748 net.cpp:84] Creating Layer scale_conv12
I1211 17:05:14.140000 17748 net.cpp:406] scale_conv12 <- conv12
I1211 17:05:14.140000 17748 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 17:05:14.140000 17748 layer_factory.cpp:58] Creating layer scale_conv12
I1211 17:05:14.140000 17748 net.cpp:122] Setting up scale_conv12
I1211 17:05:14.140000 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.140000 17748 net.cpp:137] Memory required for data: 481025200
I1211 17:05:14.140000 17748 layer_factory.cpp:58] Creating layer relu_conv12
I1211 17:05:14.140000 17748 net.cpp:84] Creating Layer relu_conv12
I1211 17:05:14.140000 17748 net.cpp:406] relu_conv12 <- conv12
I1211 17:05:14.140000 17748 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 17:05:14.140000 17748 net.cpp:122] Setting up relu_conv12
I1211 17:05:14.140000 17748 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 17:05:14.140000 17748 net.cpp:137] Memory required for data: 483329200
I1211 17:05:14.140501 17748 layer_factory.cpp:58] Creating layer poolcp6
I1211 17:05:14.140501 17748 net.cpp:84] Creating Layer poolcp6
I1211 17:05:14.140501 17748 net.cpp:406] poolcp6 <- conv12
I1211 17:05:14.140501 17748 net.cpp:380] poolcp6 -> poolcp6
I1211 17:05:14.140501 17748 net.cpp:122] Setting up poolcp6
I1211 17:05:14.140501 17748 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 17:05:14.140501 17748 net.cpp:137] Memory required for data: 483365200
I1211 17:05:14.140501 17748 layer_factory.cpp:58] Creating layer ip1
I1211 17:05:14.140501 17748 net.cpp:84] Creating Layer ip1
I1211 17:05:14.140501 17748 net.cpp:406] ip1 <- poolcp6
I1211 17:05:14.140501 17748 net.cpp:380] ip1 -> ip1
I1211 17:05:14.140501 17748 net.cpp:122] Setting up ip1
I1211 17:05:14.140501 17748 net.cpp:129] Top shape: 100 100 (10000)
I1211 17:05:14.140501 17748 net.cpp:137] Memory required for data: 483405200
I1211 17:05:14.140501 17748 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 17:05:14.140501 17748 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 17:05:14.140501 17748 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 17:05:14.140501 17748 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 17:05:14.140501 17748 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 17:05:14.140501 17748 net.cpp:122] Setting up ip1_ip1_0_split
I1211 17:05:14.140501 17748 net.cpp:129] Top shape: 100 100 (10000)
I1211 17:05:14.140501 17748 net.cpp:129] Top shape: 100 100 (10000)
I1211 17:05:14.140501 17748 net.cpp:137] Memory required for data: 483485200
I1211 17:05:14.140501 17748 layer_factory.cpp:58] Creating layer accuracy
I1211 17:05:14.140501 17748 net.cpp:84] Creating Layer accuracy
I1211 17:05:14.140501 17748 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1211 17:05:14.140501 17748 net.cpp:406] accuracy <- label_cifar_1_split_0
I1211 17:05:14.140501 17748 net.cpp:380] accuracy -> accuracy
I1211 17:05:14.140501 17748 net.cpp:122] Setting up accuracy
I1211 17:05:14.140501 17748 net.cpp:129] Top shape: (1)
I1211 17:05:14.140501 17748 net.cpp:137] Memory required for data: 483485204
I1211 17:05:14.141000 17748 layer_factory.cpp:58] Creating layer loss
I1211 17:05:14.141000 17748 net.cpp:84] Creating Layer loss
I1211 17:05:14.141000 17748 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 17:05:14.141000 17748 net.cpp:406] loss <- label_cifar_1_split_1
I1211 17:05:14.141000 17748 net.cpp:380] loss -> loss
I1211 17:05:14.141000 17748 layer_factory.cpp:58] Creating layer loss
I1211 17:05:14.141000 17748 net.cpp:122] Setting up loss
I1211 17:05:14.141000 17748 net.cpp:129] Top shape: (1)
I1211 17:05:14.141000 17748 net.cpp:132]     with loss weight 1
I1211 17:05:14.141000 17748 net.cpp:137] Memory required for data: 483485208
I1211 17:05:14.141000 17748 net.cpp:198] loss needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:200] accuracy does not need backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] ip1 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] poolcp6 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] relu_conv12 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] scale_conv12 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] bn_conv12 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] conv12 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] relu_conv11 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] scale_conv11 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] bn_conv11 needs backward computation.
I1211 17:05:14.141000 17748 net.cpp:198] conv11 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu4_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale4_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn4_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv4_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu4_pool4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale4_pool4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn4_pool4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] pool4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv4_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu4_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale4_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn4_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv4_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu4 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale4 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn4 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv4 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu3_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale3_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn3_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv3_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu3 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale3 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn3 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv3 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu2_pool2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale2_pool2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn2_pool2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] pool2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu2_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale2_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn2_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv2_2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv2_1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv2 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu1_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale1_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn1_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv1_0 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] relu1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] scale1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] bn1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:198] conv1 needs backward computation.
I1211 17:05:14.141499 17748 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 17:05:14.141499 17748 net.cpp:200] cifar does not need backward computation.
I1211 17:05:14.141499 17748 net.cpp:242] This network produces output accuracy
I1211 17:05:14.141499 17748 net.cpp:242] This network produces output loss
I1211 17:05:14.141499 17748 net.cpp:255] Network initialization done.
I1211 17:05:14.141999 17748 solver.cpp:56] Solver scaffolding done.
I1211 17:05:14.147001 17748 caffe.cpp:243] Resuming from examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90000.solverstate
I1211 17:05:14.150499 17748 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90000.caffemodel
I1211 17:05:14.150499 17748 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 17:05:14.151000 17748 sgd_solver.cpp:318] SGDSolver: restoring history
I1211 17:05:14.155999 17748 caffe.cpp:249] Starting Optimization
I1211 17:05:14.155999 17748 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV2_WnonLin_360k
I1211 17:05:14.155999 17748 solver.cpp:273] Learning Rate Policy: multistep
I1211 17:05:14.160001 17748 solver.cpp:330] Iteration 90000, Testing net (#0)
I1211 17:05:14.162500 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:05:15.606499 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:05:15.660501 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5639
I1211 17:05:15.661000 17748 solver.cpp:397]     Test net output #1: loss = 1.73094 (* 1 = 1.73094 loss)
I1211 17:05:15.783999 17748 solver.cpp:218] Iteration 90000 (55332.4 iter/s, 1.62653s/100 iters), loss = 0.578607
I1211 17:05:15.783999 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:05:15.783999 17748 solver.cpp:237]     Train net output #1: loss = 0.578607 (* 1 = 0.578607 loss)
I1211 17:05:15.783999 17748 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1211 17:05:22.243355 17748 solver.cpp:218] Iteration 90100 (15.483 iter/s, 6.4587s/100 iters), loss = 0.725594
I1211 17:05:22.243355 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 17:05:22.243355 17748 solver.cpp:237]     Train net output #1: loss = 0.725594 (* 1 = 0.725594 loss)
I1211 17:05:22.243355 17748 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1211 17:05:28.677422 17748 solver.cpp:218] Iteration 90200 (15.5429 iter/s, 6.4338s/100 iters), loss = 0.56582
I1211 17:05:28.677422 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 17:05:28.677422 17748 solver.cpp:237]     Train net output #1: loss = 0.56582 (* 1 = 0.56582 loss)
I1211 17:05:28.677422 17748 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1211 17:05:35.132516 17748 solver.cpp:218] Iteration 90300 (15.4931 iter/s, 6.45449s/100 iters), loss = 0.817089
I1211 17:05:35.132516 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 17:05:35.132516 17748 solver.cpp:237]     Train net output #1: loss = 0.817089 (* 1 = 0.817089 loss)
I1211 17:05:35.132516 17748 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1211 17:05:41.569917 17748 solver.cpp:218] Iteration 90400 (15.5351 iter/s, 6.43703s/100 iters), loss = 0.675589
I1211 17:05:41.570415 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 17:05:41.570415 17748 solver.cpp:237]     Train net output #1: loss = 0.675589 (* 1 = 0.675589 loss)
I1211 17:05:41.570415 17748 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1211 17:05:47.677659 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:05:47.932157 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90500.caffemodel
I1211 17:05:47.950160 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90500.solverstate
I1211 17:05:47.955658 17748 solver.cpp:330] Iteration 90500, Testing net (#0)
I1211 17:05:47.955658 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:05:49.344161 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:05:49.399662 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5776
I1211 17:05:49.399662 17748 solver.cpp:397]     Test net output #1: loss = 1.659 (* 1 = 1.659 loss)
I1211 17:05:49.460157 17748 solver.cpp:218] Iteration 90500 (12.6752 iter/s, 7.88941s/100 iters), loss = 0.538347
I1211 17:05:49.460157 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:05:49.460157 17748 solver.cpp:237]     Train net output #1: loss = 0.538347 (* 1 = 0.538347 loss)
I1211 17:05:49.460157 17748 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1211 17:05:55.892881 17748 solver.cpp:218] Iteration 90600 (15.5467 iter/s, 6.43225s/100 iters), loss = 0.644078
I1211 17:05:55.892881 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:05:55.892881 17748 solver.cpp:237]     Train net output #1: loss = 0.644078 (* 1 = 0.644078 loss)
I1211 17:05:55.892881 17748 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1211 17:06:02.247550 17748 solver.cpp:218] Iteration 90700 (15.7364 iter/s, 6.35471s/100 iters), loss = 0.616798
I1211 17:06:02.247550 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 17:06:02.247550 17748 solver.cpp:237]     Train net output #1: loss = 0.616798 (* 1 = 0.616798 loss)
I1211 17:06:02.247550 17748 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1211 17:06:08.444442 17748 solver.cpp:218] Iteration 90800 (16.1383 iter/s, 6.19642s/100 iters), loss = 0.707861
I1211 17:06:08.444442 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 17:06:08.444442 17748 solver.cpp:237]     Train net output #1: loss = 0.707861 (* 1 = 0.707861 loss)
I1211 17:06:08.444442 17748 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1211 17:06:14.625762 17748 solver.cpp:218] Iteration 90900 (16.1789 iter/s, 6.18088s/100 iters), loss = 0.661573
I1211 17:06:14.625762 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:06:14.625762 17748 solver.cpp:237]     Train net output #1: loss = 0.661573 (* 1 = 0.661573 loss)
I1211 17:06:14.625762 17748 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1211 17:06:20.507540 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:06:20.750563 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91000.caffemodel
I1211 17:06:20.771574 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91000.solverstate
I1211 17:06:20.777096 17748 solver.cpp:330] Iteration 91000, Testing net (#0)
I1211 17:06:20.777096 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:06:22.126986 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:06:22.179991 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5887
I1211 17:06:22.179991 17748 solver.cpp:397]     Test net output #1: loss = 1.57568 (* 1 = 1.57568 loss)
I1211 17:06:22.239022 17748 solver.cpp:218] Iteration 91000 (13.1369 iter/s, 7.61212s/100 iters), loss = 0.549562
I1211 17:06:22.239022 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:06:22.239022 17748 solver.cpp:237]     Train net output #1: loss = 0.549562 (* 1 = 0.549562 loss)
I1211 17:06:22.239022 17748 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1211 17:06:28.428418 17748 solver.cpp:218] Iteration 91100 (16.1574 iter/s, 6.18913s/100 iters), loss = 0.59553
I1211 17:06:28.428418 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 17:06:28.428418 17748 solver.cpp:237]     Train net output #1: loss = 0.59553 (* 1 = 0.59553 loss)
I1211 17:06:28.428418 17748 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1211 17:06:34.667544 17748 solver.cpp:218] Iteration 91200 (16.0298 iter/s, 6.23837s/100 iters), loss = 0.649487
I1211 17:06:34.667544 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:06:34.667544 17748 solver.cpp:237]     Train net output #1: loss = 0.649487 (* 1 = 0.649487 loss)
I1211 17:06:34.667544 17748 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1211 17:06:41.090674 17748 solver.cpp:218] Iteration 91300 (15.5698 iter/s, 6.4227s/100 iters), loss = 0.684916
I1211 17:06:41.090674 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:06:41.090674 17748 solver.cpp:237]     Train net output #1: loss = 0.684916 (* 1 = 0.684916 loss)
I1211 17:06:41.091174 17748 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1211 17:06:47.470356 17748 solver.cpp:218] Iteration 91400 (15.6765 iter/s, 6.37899s/100 iters), loss = 0.777539
I1211 17:06:47.470356 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 17:06:47.470356 17748 solver.cpp:237]     Train net output #1: loss = 0.777539 (* 1 = 0.777539 loss)
I1211 17:06:47.470356 17748 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1211 17:06:53.560452 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:06:53.813473 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91500.caffemodel
I1211 17:06:53.830962 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91500.solverstate
I1211 17:06:53.836463 17748 solver.cpp:330] Iteration 91500, Testing net (#0)
I1211 17:06:53.836463 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:06:55.226968 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:06:55.282963 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5876
I1211 17:06:55.282963 17748 solver.cpp:397]     Test net output #1: loss = 1.60181 (* 1 = 1.60181 loss)
I1211 17:06:55.344477 17748 solver.cpp:218] Iteration 91500 (12.701 iter/s, 7.87341s/100 iters), loss = 0.621842
I1211 17:06:55.344477 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:06:55.344477 17748 solver.cpp:237]     Train net output #1: loss = 0.621842 (* 1 = 0.621842 loss)
I1211 17:06:55.344477 17748 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1211 17:07:01.758795 17748 solver.cpp:218] Iteration 91600 (15.5915 iter/s, 6.41376s/100 iters), loss = 0.672968
I1211 17:07:01.758795 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 17:07:01.758795 17748 solver.cpp:237]     Train net output #1: loss = 0.672968 (* 1 = 0.672968 loss)
I1211 17:07:01.758795 17748 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1211 17:07:08.172137 17748 solver.cpp:218] Iteration 91700 (15.5927 iter/s, 6.41326s/100 iters), loss = 0.663016
I1211 17:07:08.172636 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 17:07:08.172636 17748 solver.cpp:237]     Train net output #1: loss = 0.663016 (* 1 = 0.663016 loss)
I1211 17:07:08.172636 17748 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1211 17:07:14.580266 17748 solver.cpp:218] Iteration 91800 (15.6065 iter/s, 6.40757s/100 iters), loss = 0.631341
I1211 17:07:14.580765 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:07:14.580765 17748 solver.cpp:237]     Train net output #1: loss = 0.631341 (* 1 = 0.631341 loss)
I1211 17:07:14.580765 17748 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1211 17:07:21.000411 17748 solver.cpp:218] Iteration 91900 (15.5772 iter/s, 6.41966s/100 iters), loss = 0.780002
I1211 17:07:21.000411 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 17:07:21.000911 17748 solver.cpp:237]     Train net output #1: loss = 0.780002 (* 1 = 0.780002 loss)
I1211 17:07:21.000911 17748 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1211 17:07:27.119144 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:07:27.373145 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92000.caffemodel
I1211 17:07:27.390146 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92000.solverstate
I1211 17:07:27.395146 17748 solver.cpp:330] Iteration 92000, Testing net (#0)
I1211 17:07:27.395146 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:07:28.788146 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:07:28.843144 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5631
I1211 17:07:28.843144 17748 solver.cpp:397]     Test net output #1: loss = 1.77535 (* 1 = 1.77535 loss)
I1211 17:07:28.904145 17748 solver.cpp:218] Iteration 92000 (12.6536 iter/s, 7.90288s/100 iters), loss = 0.563103
I1211 17:07:28.904145 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:07:28.904145 17748 solver.cpp:237]     Train net output #1: loss = 0.563103 (* 1 = 0.563103 loss)
I1211 17:07:28.904145 17748 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1211 17:07:35.317097 17748 solver.cpp:218] Iteration 92100 (15.5949 iter/s, 6.41236s/100 iters), loss = 0.754161
I1211 17:07:35.317097 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:07:35.317097 17748 solver.cpp:237]     Train net output #1: loss = 0.754161 (* 1 = 0.754161 loss)
I1211 17:07:35.317097 17748 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1211 17:07:41.761418 17748 solver.cpp:218] Iteration 92200 (15.5191 iter/s, 6.44368s/100 iters), loss = 0.679447
I1211 17:07:41.761418 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 17:07:41.761418 17748 solver.cpp:237]     Train net output #1: loss = 0.679447 (* 1 = 0.679447 loss)
I1211 17:07:41.761418 17748 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1211 17:07:48.211971 17748 solver.cpp:218] Iteration 92300 (15.5034 iter/s, 6.4502s/100 iters), loss = 0.626462
I1211 17:07:48.211971 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 17:07:48.211971 17748 solver.cpp:237]     Train net output #1: loss = 0.626462 (* 1 = 0.626462 loss)
I1211 17:07:48.211971 17748 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1211 17:07:54.577126 17748 solver.cpp:218] Iteration 92400 (15.7123 iter/s, 6.36444s/100 iters), loss = 0.730238
I1211 17:07:54.577126 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:07:54.577126 17748 solver.cpp:237]     Train net output #1: loss = 0.730238 (* 1 = 0.730238 loss)
I1211 17:07:54.577126 17748 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1211 17:08:00.462448 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:08:00.705682 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92500.caffemodel
I1211 17:08:00.721683 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92500.solverstate
I1211 17:08:00.726683 17748 solver.cpp:330] Iteration 92500, Testing net (#0)
I1211 17:08:00.726683 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:08:02.073420 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:08:02.125588 17748 solver.cpp:397]     Test net output #0: accuracy = 0.597
I1211 17:08:02.125588 17748 solver.cpp:397]     Test net output #1: loss = 1.56759 (* 1 = 1.56759 loss)
I1211 17:08:02.185642 17748 solver.cpp:218] Iteration 92500 (13.1439 iter/s, 7.60811s/100 iters), loss = 0.571484
I1211 17:08:02.185642 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:08:02.185642 17748 solver.cpp:237]     Train net output #1: loss = 0.571484 (* 1 = 0.571484 loss)
I1211 17:08:02.185642 17748 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1211 17:08:08.364691 17748 solver.cpp:218] Iteration 92600 (16.1827 iter/s, 6.17942s/100 iters), loss = 0.617525
I1211 17:08:08.365690 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 17:08:08.365690 17748 solver.cpp:237]     Train net output #1: loss = 0.617525 (* 1 = 0.617525 loss)
I1211 17:08:08.365690 17748 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1211 17:08:14.547808 17748 solver.cpp:218] Iteration 92700 (16.1747 iter/s, 6.18249s/100 iters), loss = 0.676084
I1211 17:08:14.547808 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 17:08:14.547808 17748 solver.cpp:237]     Train net output #1: loss = 0.676084 (* 1 = 0.676084 loss)
I1211 17:08:14.547808 17748 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1211 17:08:20.738310 17748 solver.cpp:218] Iteration 92800 (16.1558 iter/s, 6.18971s/100 iters), loss = 0.687313
I1211 17:08:20.738310 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 17:08:20.738310 17748 solver.cpp:237]     Train net output #1: loss = 0.687313 (* 1 = 0.687313 loss)
I1211 17:08:20.738310 17748 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1211 17:08:26.953732 17748 solver.cpp:218] Iteration 92900 (16.0904 iter/s, 6.21489s/100 iters), loss = 0.778051
I1211 17:08:26.953732 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 17:08:26.953732 17748 solver.cpp:237]     Train net output #1: loss = 0.778051 (* 1 = 0.778051 loss)
I1211 17:08:26.953732 17748 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1211 17:08:32.976383 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:08:33.222398 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93000.caffemodel
I1211 17:08:33.238397 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93000.solverstate
I1211 17:08:33.243398 17748 solver.cpp:330] Iteration 93000, Testing net (#0)
I1211 17:08:33.243398 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:08:34.630667 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:08:34.684672 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5666
I1211 17:08:34.684672 17748 solver.cpp:397]     Test net output #1: loss = 1.63843 (* 1 = 1.63843 loss)
I1211 17:08:34.745676 17748 solver.cpp:218] Iteration 93000 (12.835 iter/s, 7.79119s/100 iters), loss = 0.5912
I1211 17:08:34.745676 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:08:34.745676 17748 solver.cpp:237]     Train net output #1: loss = 0.5912 (* 1 = 0.5912 loss)
I1211 17:08:34.745676 17748 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1211 17:08:40.991715 17748 solver.cpp:218] Iteration 93100 (16.0121 iter/s, 6.24529s/100 iters), loss = 0.801892
I1211 17:08:40.991715 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 17:08:40.991715 17748 solver.cpp:237]     Train net output #1: loss = 0.801892 (* 1 = 0.801892 loss)
I1211 17:08:40.991715 17748 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1211 17:08:47.215731 17748 solver.cpp:218] Iteration 93200 (16.0674 iter/s, 6.22378s/100 iters), loss = 0.799747
I1211 17:08:47.215731 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 17:08:47.215731 17748 solver.cpp:237]     Train net output #1: loss = 0.799747 (* 1 = 0.799747 loss)
I1211 17:08:47.215731 17748 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1211 17:08:53.503163 17748 solver.cpp:218] Iteration 93300 (15.9048 iter/s, 6.2874s/100 iters), loss = 0.838232
I1211 17:08:53.503163 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 17:08:53.503163 17748 solver.cpp:237]     Train net output #1: loss = 0.838232 (* 1 = 0.838232 loss)
I1211 17:08:53.503163 17748 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1211 17:08:59.718807 17748 solver.cpp:218] Iteration 93400 (16.0901 iter/s, 6.215s/100 iters), loss = 0.652798
I1211 17:08:59.718807 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 17:08:59.718807 17748 solver.cpp:237]     Train net output #1: loss = 0.652798 (* 1 = 0.652798 loss)
I1211 17:08:59.718807 17748 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1211 17:09:05.631254 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:09:05.881772 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93500.caffemodel
I1211 17:09:05.904276 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93500.solverstate
I1211 17:09:05.910277 17748 solver.cpp:330] Iteration 93500, Testing net (#0)
I1211 17:09:05.910277 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:09:07.269379 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:09:07.322383 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5704
I1211 17:09:07.323384 17748 solver.cpp:397]     Test net output #1: loss = 1.718 (* 1 = 1.718 loss)
I1211 17:09:07.382886 17748 solver.cpp:218] Iteration 93500 (13.0499 iter/s, 7.6629s/100 iters), loss = 0.641274
I1211 17:09:07.382886 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 17:09:07.382886 17748 solver.cpp:237]     Train net output #1: loss = 0.641274 (* 1 = 0.641274 loss)
I1211 17:09:07.382886 17748 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1211 17:09:13.578786 17748 solver.cpp:218] Iteration 93600 (16.14 iter/s, 6.19577s/100 iters), loss = 0.625398
I1211 17:09:13.578786 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 17:09:13.578786 17748 solver.cpp:237]     Train net output #1: loss = 0.625398 (* 1 = 0.625398 loss)
I1211 17:09:13.578786 17748 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1211 17:09:19.797734 17748 solver.cpp:218] Iteration 93700 (16.0799 iter/s, 6.21895s/100 iters), loss = 0.459881
I1211 17:09:19.797734 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:09:19.797734 17748 solver.cpp:237]     Train net output #1: loss = 0.459881 (* 1 = 0.459881 loss)
I1211 17:09:19.797734 17748 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1211 17:09:26.006201 17748 solver.cpp:218] Iteration 93800 (16.1104 iter/s, 6.20719s/100 iters), loss = 0.810934
I1211 17:09:26.006201 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 17:09:26.006201 17748 solver.cpp:237]     Train net output #1: loss = 0.810934 (* 1 = 0.810934 loss)
I1211 17:09:26.006201 17748 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1211 17:09:32.306123 17748 solver.cpp:218] Iteration 93900 (15.8735 iter/s, 6.2998s/100 iters), loss = 0.797961
I1211 17:09:32.306123 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 17:09:32.306123 17748 solver.cpp:237]     Train net output #1: loss = 0.797961 (* 1 = 0.797961 loss)
I1211 17:09:32.306123 17748 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1211 17:09:38.266597 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:09:38.518611 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94000.caffemodel
I1211 17:09:38.542114 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94000.solverstate
I1211 17:09:38.547614 17748 solver.cpp:330] Iteration 94000, Testing net (#0)
I1211 17:09:38.548115 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:09:39.937778 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:09:39.992787 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5898
I1211 17:09:39.992787 17748 solver.cpp:397]     Test net output #1: loss = 1.5913 (* 1 = 1.5913 loss)
I1211 17:09:40.054296 17748 solver.cpp:218] Iteration 94000 (12.908 iter/s, 7.74715s/100 iters), loss = 0.519975
I1211 17:09:40.054296 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:09:40.054296 17748 solver.cpp:237]     Train net output #1: loss = 0.519975 (* 1 = 0.519975 loss)
I1211 17:09:40.054296 17748 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1211 17:09:46.472504 17748 solver.cpp:218] Iteration 94100 (15.5812 iter/s, 6.41797s/100 iters), loss = 0.701748
I1211 17:09:46.472504 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 17:09:46.472504 17748 solver.cpp:237]     Train net output #1: loss = 0.701748 (* 1 = 0.701748 loss)
I1211 17:09:46.472504 17748 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1211 17:09:52.876314 17748 solver.cpp:218] Iteration 94200 (15.6163 iter/s, 6.40358s/100 iters), loss = 0.631716
I1211 17:09:52.876314 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:09:52.876314 17748 solver.cpp:237]     Train net output #1: loss = 0.631716 (* 1 = 0.631716 loss)
I1211 17:09:52.876314 17748 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1211 17:09:59.272925 17748 solver.cpp:218] Iteration 94300 (15.636 iter/s, 6.3955s/100 iters), loss = 0.783257
I1211 17:09:59.272925 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 17:09:59.272925 17748 solver.cpp:237]     Train net output #1: loss = 0.783257 (* 1 = 0.783257 loss)
I1211 17:09:59.272925 17748 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1211 17:10:05.664587 17748 solver.cpp:218] Iteration 94400 (15.6455 iter/s, 6.3916s/100 iters), loss = 0.741963
I1211 17:10:05.664587 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 17:10:05.664587 17748 solver.cpp:237]     Train net output #1: loss = 0.741963 (* 1 = 0.741963 loss)
I1211 17:10:05.664587 17748 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1211 17:10:11.743177 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:10:11.990192 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94500.caffemodel
I1211 17:10:12.010192 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94500.solverstate
I1211 17:10:12.016192 17748 solver.cpp:330] Iteration 94500, Testing net (#0)
I1211 17:10:12.016192 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:10:13.406553 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:10:13.461555 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5676
I1211 17:10:13.461555 17748 solver.cpp:397]     Test net output #1: loss = 1.70987 (* 1 = 1.70987 loss)
I1211 17:10:13.522564 17748 solver.cpp:218] Iteration 94500 (12.7264 iter/s, 7.8577s/100 iters), loss = 0.69583
I1211 17:10:13.523560 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 17:10:13.523560 17748 solver.cpp:237]     Train net output #1: loss = 0.69583 (* 1 = 0.69583 loss)
I1211 17:10:13.523560 17748 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1211 17:10:19.930052 17748 solver.cpp:218] Iteration 94600 (15.6083 iter/s, 6.40686s/100 iters), loss = 0.687138
I1211 17:10:19.931054 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 17:10:19.931054 17748 solver.cpp:237]     Train net output #1: loss = 0.687138 (* 1 = 0.687138 loss)
I1211 17:10:19.931054 17748 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1211 17:10:26.340582 17748 solver.cpp:218] Iteration 94700 (15.6016 iter/s, 6.40959s/100 iters), loss = 0.589708
I1211 17:10:26.340582 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 17:10:26.340582 17748 solver.cpp:237]     Train net output #1: loss = 0.589708 (* 1 = 0.589708 loss)
I1211 17:10:26.340582 17748 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1211 17:10:32.729085 17748 solver.cpp:218] Iteration 94800 (15.6536 iter/s, 6.38832s/100 iters), loss = 0.738595
I1211 17:10:32.729085 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 17:10:32.729085 17748 solver.cpp:237]     Train net output #1: loss = 0.738595 (* 1 = 0.738595 loss)
I1211 17:10:32.729085 17748 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1211 17:10:39.110541 17748 solver.cpp:218] Iteration 94900 (15.6719 iter/s, 6.38085s/100 iters), loss = 0.739569
I1211 17:10:39.110541 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 17:10:39.110541 17748 solver.cpp:237]     Train net output #1: loss = 0.739569 (* 1 = 0.739569 loss)
I1211 17:10:39.110541 17748 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1211 17:10:45.193017 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:10:45.448549 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95000.caffemodel
I1211 17:10:45.468055 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95000.solverstate
I1211 17:10:45.474056 17748 solver.cpp:330] Iteration 95000, Testing net (#0)
I1211 17:10:45.474056 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:10:46.871192 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:10:46.926192 17748 solver.cpp:397]     Test net output #0: accuracy = 0.5751
I1211 17:10:46.926192 17748 solver.cpp:397]     Test net output #1: loss = 1.65369 (* 1 = 1.65369 loss)
I1211 17:10:46.987198 17748 solver.cpp:218] Iteration 95000 (12.697 iter/s, 7.87588s/100 iters), loss = 0.647351
I1211 17:10:46.987198 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 17:10:46.987198 17748 solver.cpp:237]     Train net output #1: loss = 0.647351 (* 1 = 0.647351 loss)
I1211 17:10:46.987198 17748 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1211 17:10:46.987198 17748 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1211 17:10:53.397671 17748 solver.cpp:218] Iteration 95100 (15.6002 iter/s, 6.41018s/100 iters), loss = 0.697967
I1211 17:10:53.397671 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 17:10:53.397671 17748 solver.cpp:237]     Train net output #1: loss = 0.697967 (* 1 = 0.697967 loss)
I1211 17:10:53.397671 17748 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1211 17:10:59.776372 17748 solver.cpp:218] Iteration 95200 (15.6795 iter/s, 6.37774s/100 iters), loss = 0.525003
I1211 17:10:59.776372 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:10:59.776372 17748 solver.cpp:237]     Train net output #1: loss = 0.525003 (* 1 = 0.525003 loss)
I1211 17:10:59.776372 17748 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1211 17:11:06.163317 17748 solver.cpp:218] Iteration 95300 (15.6579 iter/s, 6.38657s/100 iters), loss = 0.565122
I1211 17:11:06.163317 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 17:11:06.163317 17748 solver.cpp:237]     Train net output #1: loss = 0.565122 (* 1 = 0.565122 loss)
I1211 17:11:06.163317 17748 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1211 17:11:12.551785 17748 solver.cpp:218] Iteration 95400 (15.6547 iter/s, 6.38786s/100 iters), loss = 0.476849
I1211 17:11:12.551785 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:11:12.551785 17748 solver.cpp:237]     Train net output #1: loss = 0.476849 (* 1 = 0.476849 loss)
I1211 17:11:12.551785 17748 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1211 17:11:18.635776 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:11:18.892793 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95500.caffemodel
I1211 17:11:18.911793 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95500.solverstate
I1211 17:11:18.916792 17748 solver.cpp:330] Iteration 95500, Testing net (#0)
I1211 17:11:18.917793 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:11:20.316128 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:11:20.370133 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6713
I1211 17:11:20.370133 17748 solver.cpp:397]     Test net output #1: loss = 1.19728 (* 1 = 1.19728 loss)
I1211 17:11:20.429132 17748 solver.cpp:218] Iteration 95500 (12.6947 iter/s, 7.87727s/100 iters), loss = 0.505735
I1211 17:11:20.429132 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:11:20.429132 17748 solver.cpp:237]     Train net output #1: loss = 0.505735 (* 1 = 0.505735 loss)
I1211 17:11:20.429132 17748 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1211 17:11:26.819687 17748 solver.cpp:218] Iteration 95600 (15.6487 iter/s, 6.3903s/100 iters), loss = 0.439633
I1211 17:11:26.819687 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:11:26.819687 17748 solver.cpp:237]     Train net output #1: loss = 0.439633 (* 1 = 0.439633 loss)
I1211 17:11:26.819687 17748 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1211 17:11:33.201174 17748 solver.cpp:218] Iteration 95700 (15.6718 iter/s, 6.38089s/100 iters), loss = 0.42029
I1211 17:11:33.201174 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:11:33.201174 17748 solver.cpp:237]     Train net output #1: loss = 0.42029 (* 1 = 0.42029 loss)
I1211 17:11:33.201174 17748 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1211 17:11:39.606688 17748 solver.cpp:218] Iteration 95800 (15.6127 iter/s, 6.40505s/100 iters), loss = 0.461437
I1211 17:11:39.606688 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:11:39.606688 17748 solver.cpp:237]     Train net output #1: loss = 0.461437 (* 1 = 0.461437 loss)
I1211 17:11:39.606688 17748 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1211 17:11:46.012192 17748 solver.cpp:218] Iteration 95900 (15.6145 iter/s, 6.4043s/100 iters), loss = 0.517057
I1211 17:11:46.012192 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:11:46.012192 17748 solver.cpp:237]     Train net output #1: loss = 0.517057 (* 1 = 0.517057 loss)
I1211 17:11:46.012192 17748 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1211 17:11:52.090649 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:11:52.345662 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96000.caffemodel
I1211 17:11:52.363170 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96000.solverstate
I1211 17:11:52.368167 17748 solver.cpp:330] Iteration 96000, Testing net (#0)
I1211 17:11:52.368167 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:11:53.750778 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:11:53.804783 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6748
I1211 17:11:53.804783 17748 solver.cpp:397]     Test net output #1: loss = 1.18563 (* 1 = 1.18563 loss)
I1211 17:11:53.863785 17748 solver.cpp:218] Iteration 96000 (12.737 iter/s, 7.85117s/100 iters), loss = 0.41725
I1211 17:11:53.863785 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:11:53.864289 17748 solver.cpp:237]     Train net output #1: loss = 0.41725 (* 1 = 0.41725 loss)
I1211 17:11:53.864289 17748 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1211 17:12:00.253248 17748 solver.cpp:218] Iteration 96100 (15.6531 iter/s, 6.3885s/100 iters), loss = 0.543735
I1211 17:12:00.253248 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 17:12:00.253248 17748 solver.cpp:237]     Train net output #1: loss = 0.543735 (* 1 = 0.543735 loss)
I1211 17:12:00.253248 17748 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1211 17:12:06.660689 17748 solver.cpp:218] Iteration 96200 (15.6071 iter/s, 6.40732s/100 iters), loss = 0.449341
I1211 17:12:06.661188 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:12:06.661188 17748 solver.cpp:237]     Train net output #1: loss = 0.449341 (* 1 = 0.449341 loss)
I1211 17:12:06.661188 17748 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1211 17:12:13.060953 17748 solver.cpp:218] Iteration 96300 (15.6256 iter/s, 6.39977s/100 iters), loss = 0.449031
I1211 17:12:13.061452 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:12:13.061452 17748 solver.cpp:237]     Train net output #1: loss = 0.449031 (* 1 = 0.449031 loss)
I1211 17:12:13.061452 17748 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1211 17:12:19.455116 17748 solver.cpp:218] Iteration 96400 (15.6394 iter/s, 6.39411s/100 iters), loss = 0.534463
I1211 17:12:19.456117 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:12:19.456117 17748 solver.cpp:237]     Train net output #1: loss = 0.534463 (* 1 = 0.534463 loss)
I1211 17:12:19.456117 17748 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1211 17:12:25.531667 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:12:25.783202 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96500.caffemodel
I1211 17:12:25.800201 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96500.solverstate
I1211 17:12:25.805202 17748 solver.cpp:330] Iteration 96500, Testing net (#0)
I1211 17:12:25.805202 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:12:27.172770 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:12:27.225951 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6779
I1211 17:12:27.225951 17748 solver.cpp:397]     Test net output #1: loss = 1.18725 (* 1 = 1.18725 loss)
I1211 17:12:27.286984 17748 solver.cpp:218] Iteration 96500 (12.7692 iter/s, 7.83132s/100 iters), loss = 0.48291
I1211 17:12:27.287987 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:12:27.287987 17748 solver.cpp:237]     Train net output #1: loss = 0.48291 (* 1 = 0.48291 loss)
I1211 17:12:27.287987 17748 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1211 17:12:33.686334 17748 solver.cpp:218] Iteration 96600 (15.6289 iter/s, 6.3984s/100 iters), loss = 0.498559
I1211 17:12:33.686334 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:12:33.686334 17748 solver.cpp:237]     Train net output #1: loss = 0.498559 (* 1 = 0.498559 loss)
I1211 17:12:33.686334 17748 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1211 17:12:40.092186 17748 solver.cpp:218] Iteration 96700 (15.6122 iter/s, 6.40527s/100 iters), loss = 0.436656
I1211 17:12:40.092186 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:12:40.092186 17748 solver.cpp:237]     Train net output #1: loss = 0.436656 (* 1 = 0.436656 loss)
I1211 17:12:40.092186 17748 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1211 17:12:46.498731 17748 solver.cpp:218] Iteration 96800 (15.6107 iter/s, 6.40588s/100 iters), loss = 0.424991
I1211 17:12:46.498731 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:12:46.498731 17748 solver.cpp:237]     Train net output #1: loss = 0.424991 (* 1 = 0.424991 loss)
I1211 17:12:46.498731 17748 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1211 17:12:52.884610 17748 solver.cpp:218] Iteration 96900 (15.6595 iter/s, 6.38591s/100 iters), loss = 0.489958
I1211 17:12:52.884610 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 17:12:52.884610 17748 solver.cpp:237]     Train net output #1: loss = 0.489958 (* 1 = 0.489958 loss)
I1211 17:12:52.884610 17748 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1211 17:12:58.960861 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:12:59.214890 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97000.caffemodel
I1211 17:12:59.232874 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97000.solverstate
I1211 17:12:59.237874 17748 solver.cpp:330] Iteration 97000, Testing net (#0)
I1211 17:12:59.237874 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:13:00.606325 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:13:00.661311 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1211 17:13:00.661311 17748 solver.cpp:397]     Test net output #1: loss = 1.19282 (* 1 = 1.19282 loss)
I1211 17:13:00.722335 17748 solver.cpp:218] Iteration 97000 (12.7597 iter/s, 7.8372s/100 iters), loss = 0.416381
I1211 17:13:00.723335 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:13:00.723335 17748 solver.cpp:237]     Train net output #1: loss = 0.416381 (* 1 = 0.416381 loss)
I1211 17:13:00.723335 17748 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1211 17:13:07.114050 17748 solver.cpp:218] Iteration 97100 (15.6481 iter/s, 6.39053s/100 iters), loss = 0.490026
I1211 17:13:07.114050 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:13:07.114050 17748 solver.cpp:237]     Train net output #1: loss = 0.490026 (* 1 = 0.490026 loss)
I1211 17:13:07.114050 17748 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1211 17:13:13.521183 17748 solver.cpp:218] Iteration 97200 (15.6094 iter/s, 6.40639s/100 iters), loss = 0.385581
I1211 17:13:13.521183 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:13:13.521183 17748 solver.cpp:237]     Train net output #1: loss = 0.385581 (* 1 = 0.385581 loss)
I1211 17:13:13.521183 17748 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1211 17:13:19.915109 17748 solver.cpp:218] Iteration 97300 (15.6407 iter/s, 6.39358s/100 iters), loss = 0.465818
I1211 17:13:19.915109 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:13:19.915109 17748 solver.cpp:237]     Train net output #1: loss = 0.465818 (* 1 = 0.465818 loss)
I1211 17:13:19.915109 17748 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1211 17:13:26.314855 17748 solver.cpp:218] Iteration 97400 (15.6265 iter/s, 6.39938s/100 iters), loss = 0.450099
I1211 17:13:26.314855 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:13:26.314855 17748 solver.cpp:237]     Train net output #1: loss = 0.450099 (* 1 = 0.450099 loss)
I1211 17:13:26.314855 17748 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1211 17:13:32.397696 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:13:32.640707 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97500.caffemodel
I1211 17:13:32.662708 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97500.solverstate
I1211 17:13:32.668709 17748 solver.cpp:330] Iteration 97500, Testing net (#0)
I1211 17:13:32.668709 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:13:34.050865 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:13:34.105885 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1211 17:13:34.105885 17748 solver.cpp:397]     Test net output #1: loss = 1.19547 (* 1 = 1.19547 loss)
I1211 17:13:34.167886 17748 solver.cpp:218] Iteration 97500 (12.7351 iter/s, 7.85233s/100 iters), loss = 0.381089
I1211 17:13:34.167886 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:13:34.167886 17748 solver.cpp:237]     Train net output #1: loss = 0.381089 (* 1 = 0.381089 loss)
I1211 17:13:34.167886 17748 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1211 17:13:40.569558 17748 solver.cpp:218] Iteration 97600 (15.6217 iter/s, 6.40135s/100 iters), loss = 0.492882
I1211 17:13:40.569558 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:13:40.569558 17748 solver.cpp:237]     Train net output #1: loss = 0.492882 (* 1 = 0.492882 loss)
I1211 17:13:40.569558 17748 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1211 17:13:46.964176 17748 solver.cpp:218] Iteration 97700 (15.6389 iter/s, 6.3943s/100 iters), loss = 0.372428
I1211 17:13:46.964176 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:13:46.964176 17748 solver.cpp:237]     Train net output #1: loss = 0.372428 (* 1 = 0.372428 loss)
I1211 17:13:46.964176 17748 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1211 17:13:53.358716 17748 solver.cpp:218] Iteration 97800 (15.6398 iter/s, 6.39395s/100 iters), loss = 0.479044
I1211 17:13:53.358716 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:13:53.358716 17748 solver.cpp:237]     Train net output #1: loss = 0.479044 (* 1 = 0.479044 loss)
I1211 17:13:53.358716 17748 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1211 17:13:59.739308 17748 solver.cpp:218] Iteration 97900 (15.6745 iter/s, 6.37979s/100 iters), loss = 0.463632
I1211 17:13:59.739308 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:13:59.739308 17748 solver.cpp:237]     Train net output #1: loss = 0.463632 (* 1 = 0.463632 loss)
I1211 17:13:59.739308 17748 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1211 17:14:05.824813 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:14:06.067822 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98000.caffemodel
I1211 17:14:06.089326 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98000.solverstate
I1211 17:14:06.095827 17748 solver.cpp:330] Iteration 98000, Testing net (#0)
I1211 17:14:06.095827 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:14:07.490943 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:14:07.545946 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1211 17:14:07.546947 17748 solver.cpp:397]     Test net output #1: loss = 1.18849 (* 1 = 1.18849 loss)
I1211 17:14:07.607950 17748 solver.cpp:218] Iteration 98000 (12.7102 iter/s, 7.86772s/100 iters), loss = 0.403846
I1211 17:14:07.607950 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:14:07.607950 17748 solver.cpp:237]     Train net output #1: loss = 0.403846 (* 1 = 0.403846 loss)
I1211 17:14:07.607950 17748 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1211 17:14:14.004534 17748 solver.cpp:218] Iteration 98100 (15.6331 iter/s, 6.39669s/100 iters), loss = 0.556798
I1211 17:14:14.004534 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 17:14:14.004534 17748 solver.cpp:237]     Train net output #1: loss = 0.556798 (* 1 = 0.556798 loss)
I1211 17:14:14.004534 17748 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1211 17:14:20.400076 17748 solver.cpp:218] Iteration 98200 (15.6387 iter/s, 6.39438s/100 iters), loss = 0.371312
I1211 17:14:20.400076 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:14:20.400076 17748 solver.cpp:237]     Train net output #1: loss = 0.371312 (* 1 = 0.371312 loss)
I1211 17:14:20.400076 17748 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1211 17:14:26.765563 17748 solver.cpp:218] Iteration 98300 (15.7109 iter/s, 6.365s/100 iters), loss = 0.380131
I1211 17:14:26.765563 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:14:26.765563 17748 solver.cpp:237]     Train net output #1: loss = 0.380131 (* 1 = 0.380131 loss)
I1211 17:14:26.765563 17748 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1211 17:14:33.154930 17748 solver.cpp:218] Iteration 98400 (15.6505 iter/s, 6.38958s/100 iters), loss = 0.495203
I1211 17:14:33.154930 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:14:33.154930 17748 solver.cpp:237]     Train net output #1: loss = 0.495203 (* 1 = 0.495203 loss)
I1211 17:14:33.154930 17748 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1211 17:14:39.230372 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:14:39.485385 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98500.caffemodel
I1211 17:14:39.503391 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98500.solverstate
I1211 17:14:39.508391 17748 solver.cpp:330] Iteration 98500, Testing net (#0)
I1211 17:14:39.508391 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:14:40.906519 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:14:40.961519 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6809
I1211 17:14:40.961519 17748 solver.cpp:397]     Test net output #1: loss = 1.19374 (* 1 = 1.19374 loss)
I1211 17:14:41.023072 17748 solver.cpp:218] Iteration 98500 (12.7115 iter/s, 7.8669s/100 iters), loss = 0.383408
I1211 17:14:41.023072 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:14:41.023072 17748 solver.cpp:237]     Train net output #1: loss = 0.383408 (* 1 = 0.383408 loss)
I1211 17:14:41.023072 17748 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1211 17:14:47.417186 17748 solver.cpp:218] Iteration 98600 (15.6402 iter/s, 6.39377s/100 iters), loss = 0.465469
I1211 17:14:47.417186 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:14:47.417186 17748 solver.cpp:237]     Train net output #1: loss = 0.465469 (* 1 = 0.465469 loss)
I1211 17:14:47.417186 17748 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1211 17:14:53.731699 17748 solver.cpp:218] Iteration 98700 (15.8371 iter/s, 6.31429s/100 iters), loss = 0.451605
I1211 17:14:53.731699 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:14:53.731699 17748 solver.cpp:237]     Train net output #1: loss = 0.451605 (* 1 = 0.451605 loss)
I1211 17:14:53.731699 17748 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1211 17:14:59.990895 17748 solver.cpp:218] Iteration 98800 (15.9776 iter/s, 6.25876s/100 iters), loss = 0.44431
I1211 17:14:59.990895 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:14:59.990895 17748 solver.cpp:237]     Train net output #1: loss = 0.44431 (* 1 = 0.44431 loss)
I1211 17:14:59.990895 17748 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1211 17:15:06.261870 17748 solver.cpp:218] Iteration 98900 (15.9468 iter/s, 6.27085s/100 iters), loss = 0.469534
I1211 17:15:06.261870 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:15:06.261870 17748 solver.cpp:237]     Train net output #1: loss = 0.469534 (* 1 = 0.469534 loss)
I1211 17:15:06.261870 17748 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1211 17:15:12.233268 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:15:12.480281 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99000.caffemodel
I1211 17:15:12.496286 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99000.solverstate
I1211 17:15:12.501785 17748 solver.cpp:330] Iteration 99000, Testing net (#0)
I1211 17:15:12.501785 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:15:13.873416 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:15:13.926422 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6798
I1211 17:15:13.926422 17748 solver.cpp:397]     Test net output #1: loss = 1.20352 (* 1 = 1.20352 loss)
I1211 17:15:13.987422 17748 solver.cpp:218] Iteration 99000 (12.9461 iter/s, 7.72435s/100 iters), loss = 0.367171
I1211 17:15:13.987422 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:15:13.987422 17748 solver.cpp:237]     Train net output #1: loss = 0.367171 (* 1 = 0.367171 loss)
I1211 17:15:13.987422 17748 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1211 17:15:20.267860 17748 solver.cpp:218] Iteration 99100 (15.9213 iter/s, 6.28088s/100 iters), loss = 0.476042
I1211 17:15:20.268860 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:15:20.268860 17748 solver.cpp:237]     Train net output #1: loss = 0.476042 (* 1 = 0.476042 loss)
I1211 17:15:20.268860 17748 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1211 17:15:26.525288 17748 solver.cpp:218] Iteration 99200 (15.9821 iter/s, 6.25698s/100 iters), loss = 0.369546
I1211 17:15:26.526288 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:15:26.526288 17748 solver.cpp:237]     Train net output #1: loss = 0.369546 (* 1 = 0.369546 loss)
I1211 17:15:26.526288 17748 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1211 17:15:32.794771 17748 solver.cpp:218] Iteration 99300 (15.9531 iter/s, 6.26837s/100 iters), loss = 0.378529
I1211 17:15:32.794771 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:15:32.794771 17748 solver.cpp:237]     Train net output #1: loss = 0.378529 (* 1 = 0.378529 loss)
I1211 17:15:32.794771 17748 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1211 17:15:39.063204 17748 solver.cpp:218] Iteration 99400 (15.9527 iter/s, 6.26855s/100 iters), loss = 0.458227
I1211 17:15:39.064203 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:15:39.064203 17748 solver.cpp:237]     Train net output #1: loss = 0.458227 (* 1 = 0.458227 loss)
I1211 17:15:39.064203 17748 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1211 17:15:45.019600 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:15:45.266623 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99500.caffemodel
I1211 17:15:45.283623 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99500.solverstate
I1211 17:15:45.288625 17748 solver.cpp:330] Iteration 99500, Testing net (#0)
I1211 17:15:45.288625 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:15:46.659725 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:15:46.712730 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6787
I1211 17:15:46.712730 17748 solver.cpp:397]     Test net output #1: loss = 1.21474 (* 1 = 1.21474 loss)
I1211 17:15:46.773730 17748 solver.cpp:218] Iteration 99500 (12.9707 iter/s, 7.70966s/100 iters), loss = 0.3483
I1211 17:15:46.773730 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:15:46.773730 17748 solver.cpp:237]     Train net output #1: loss = 0.3483 (* 1 = 0.3483 loss)
I1211 17:15:46.773730 17748 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1211 17:15:53.037752 17748 solver.cpp:218] Iteration 99600 (15.9653 iter/s, 6.2636s/100 iters), loss = 0.460713
I1211 17:15:53.037752 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:15:53.037752 17748 solver.cpp:237]     Train net output #1: loss = 0.460713 (* 1 = 0.460713 loss)
I1211 17:15:53.037752 17748 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1211 17:15:59.306165 17748 solver.cpp:218] Iteration 99700 (15.9546 iter/s, 6.2678s/100 iters), loss = 0.415913
I1211 17:15:59.306665 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:15:59.306665 17748 solver.cpp:237]     Train net output #1: loss = 0.415913 (* 1 = 0.415913 loss)
I1211 17:15:59.306665 17748 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1211 17:16:05.579648 17748 solver.cpp:218] Iteration 99800 (15.9409 iter/s, 6.27317s/100 iters), loss = 0.441064
I1211 17:16:05.579648 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:16:05.579648 17748 solver.cpp:237]     Train net output #1: loss = 0.441064 (* 1 = 0.441064 loss)
I1211 17:16:05.579648 17748 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1211 17:16:11.840121 17748 solver.cpp:218] Iteration 99900 (15.9758 iter/s, 6.25945s/100 iters), loss = 0.490665
I1211 17:16:11.840121 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 17:16:11.840121 17748 solver.cpp:237]     Train net output #1: loss = 0.490665 (* 1 = 0.490665 loss)
I1211 17:16:11.840121 17748 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1211 17:16:17.787545 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:16:18.033578 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100000.caffemodel
I1211 17:16:18.049578 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100000.solverstate
I1211 17:16:18.054579 17748 solver.cpp:330] Iteration 100000, Testing net (#0)
I1211 17:16:18.054579 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:16:19.426734 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:16:19.480741 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6798
I1211 17:16:19.480741 17748 solver.cpp:397]     Test net output #1: loss = 1.19767 (* 1 = 1.19767 loss)
I1211 17:16:19.541739 17748 solver.cpp:218] Iteration 100000 (12.9856 iter/s, 7.70086s/100 iters), loss = 0.301227
I1211 17:16:19.541739 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:16:19.541739 17748 solver.cpp:237]     Train net output #1: loss = 0.301227 (* 1 = 0.301227 loss)
I1211 17:16:19.541739 17748 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1211 17:16:25.838227 17748 solver.cpp:218] Iteration 100100 (15.8809 iter/s, 6.29687s/100 iters), loss = 0.420775
I1211 17:16:25.838227 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:16:25.838227 17748 solver.cpp:237]     Train net output #1: loss = 0.420775 (* 1 = 0.420775 loss)
I1211 17:16:25.838227 17748 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1211 17:16:32.119675 17748 solver.cpp:218] Iteration 100200 (15.9215 iter/s, 6.2808s/100 iters), loss = 0.398116
I1211 17:16:32.119675 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:16:32.119675 17748 solver.cpp:237]     Train net output #1: loss = 0.398116 (* 1 = 0.398116 loss)
I1211 17:16:32.119675 17748 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1211 17:16:38.393520 17748 solver.cpp:218] Iteration 100300 (15.9402 iter/s, 6.27345s/100 iters), loss = 0.421123
I1211 17:16:38.393520 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:16:38.393520 17748 solver.cpp:237]     Train net output #1: loss = 0.421123 (* 1 = 0.421123 loss)
I1211 17:16:38.393520 17748 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1211 17:16:44.655068 17748 solver.cpp:218] Iteration 100400 (15.9713 iter/s, 6.26124s/100 iters), loss = 0.4592
I1211 17:16:44.655068 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:16:44.656069 17748 solver.cpp:237]     Train net output #1: loss = 0.4592 (* 1 = 0.4592 loss)
I1211 17:16:44.656069 17748 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1211 17:16:50.603576 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:16:50.848594 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100500.caffemodel
I1211 17:16:50.869594 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100500.solverstate
I1211 17:16:50.874594 17748 solver.cpp:330] Iteration 100500, Testing net (#0)
I1211 17:16:50.874594 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:16:52.243773 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:16:52.297777 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6801
I1211 17:16:52.297777 17748 solver.cpp:397]     Test net output #1: loss = 1.20593 (* 1 = 1.20593 loss)
I1211 17:16:52.357784 17748 solver.cpp:218] Iteration 100500 (12.9838 iter/s, 7.7019s/100 iters), loss = 0.372749
I1211 17:16:52.357784 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:16:52.357784 17748 solver.cpp:237]     Train net output #1: loss = 0.372749 (* 1 = 0.372749 loss)
I1211 17:16:52.357784 17748 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1211 17:16:58.618433 17748 solver.cpp:218] Iteration 100600 (15.9756 iter/s, 6.25954s/100 iters), loss = 0.442352
I1211 17:16:58.618433 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:16:58.618433 17748 solver.cpp:237]     Train net output #1: loss = 0.442352 (* 1 = 0.442352 loss)
I1211 17:16:58.618433 17748 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1211 17:17:04.883424 17748 solver.cpp:218] Iteration 100700 (15.9633 iter/s, 6.26437s/100 iters), loss = 0.393166
I1211 17:17:04.883424 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:17:04.883424 17748 solver.cpp:237]     Train net output #1: loss = 0.393166 (* 1 = 0.393166 loss)
I1211 17:17:04.883424 17748 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1211 17:17:11.162685 17748 solver.cpp:218] Iteration 100800 (15.9268 iter/s, 6.27871s/100 iters), loss = 0.405566
I1211 17:17:11.162685 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:17:11.162685 17748 solver.cpp:237]     Train net output #1: loss = 0.405566 (* 1 = 0.405566 loss)
I1211 17:17:11.162685 17748 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1211 17:17:17.384495 17748 solver.cpp:218] Iteration 100900 (16.0737 iter/s, 6.22135s/100 iters), loss = 0.439782
I1211 17:17:17.384495 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:17:17.384495 17748 solver.cpp:237]     Train net output #1: loss = 0.439782 (* 1 = 0.439782 loss)
I1211 17:17:17.384495 17748 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1211 17:17:23.290930 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:17:23.536986 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101000.caffemodel
I1211 17:17:23.558001 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101000.solverstate
I1211 17:17:23.563005 17748 solver.cpp:330] Iteration 101000, Testing net (#0)
I1211 17:17:23.563005 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:17:24.914304 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:17:24.967070 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6801
I1211 17:17:24.967070 17748 solver.cpp:397]     Test net output #1: loss = 1.20698 (* 1 = 1.20698 loss)
I1211 17:17:25.026306 17748 solver.cpp:218] Iteration 101000 (13.0867 iter/s, 7.64135s/100 iters), loss = 0.348347
I1211 17:17:25.026306 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:17:25.026306 17748 solver.cpp:237]     Train net output #1: loss = 0.348347 (* 1 = 0.348347 loss)
I1211 17:17:25.026306 17748 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1211 17:17:31.244282 17748 solver.cpp:218] Iteration 101100 (16.0824 iter/s, 6.21798s/100 iters), loss = 0.418671
I1211 17:17:31.244282 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:17:31.244282 17748 solver.cpp:237]     Train net output #1: loss = 0.41867 (* 1 = 0.41867 loss)
I1211 17:17:31.244282 17748 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1211 17:17:37.443188 17748 solver.cpp:218] Iteration 101200 (16.1326 iter/s, 6.19864s/100 iters), loss = 0.364157
I1211 17:17:37.443188 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:17:37.443188 17748 solver.cpp:237]     Train net output #1: loss = 0.364157 (* 1 = 0.364157 loss)
I1211 17:17:37.443188 17748 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1211 17:17:43.651610 17748 solver.cpp:218] Iteration 101300 (16.1087 iter/s, 6.20782s/100 iters), loss = 0.389223
I1211 17:17:43.651610 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:17:43.651610 17748 solver.cpp:237]     Train net output #1: loss = 0.389223 (* 1 = 0.389223 loss)
I1211 17:17:43.651610 17748 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1211 17:17:49.859027 17748 solver.cpp:218] Iteration 101400 (16.1108 iter/s, 6.20702s/100 iters), loss = 0.456391
I1211 17:17:49.859027 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:17:49.859027 17748 solver.cpp:237]     Train net output #1: loss = 0.456391 (* 1 = 0.456391 loss)
I1211 17:17:49.859027 17748 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1211 17:17:55.778491 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:17:56.023003 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101500.caffemodel
I1211 17:17:56.038509 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101500.solverstate
I1211 17:17:56.043509 17748 solver.cpp:330] Iteration 101500, Testing net (#0)
I1211 17:17:56.043509 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:17:57.396605 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:17:57.450616 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6786
I1211 17:17:57.450616 17748 solver.cpp:397]     Test net output #1: loss = 1.20629 (* 1 = 1.20629 loss)
I1211 17:17:57.509610 17748 solver.cpp:218] Iteration 101500 (13.0717 iter/s, 7.65012s/100 iters), loss = 0.299186
I1211 17:17:57.509610 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:17:57.509610 17748 solver.cpp:237]     Train net output #1: loss = 0.299186 (* 1 = 0.299186 loss)
I1211 17:17:57.509610 17748 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1211 17:18:03.768239 17748 solver.cpp:218] Iteration 101600 (15.9791 iter/s, 6.25817s/100 iters), loss = 0.37874
I1211 17:18:03.768239 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:18:03.768239 17748 solver.cpp:237]     Train net output #1: loss = 0.37874 (* 1 = 0.37874 loss)
I1211 17:18:03.768239 17748 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1211 17:18:10.025091 17748 solver.cpp:218] Iteration 101700 (15.9846 iter/s, 6.25603s/100 iters), loss = 0.316048
I1211 17:18:10.025091 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:18:10.025091 17748 solver.cpp:237]     Train net output #1: loss = 0.316048 (* 1 = 0.316048 loss)
I1211 17:18:10.025091 17748 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1211 17:18:16.318233 17748 solver.cpp:218] Iteration 101800 (15.8913 iter/s, 6.29274s/100 iters), loss = 0.368279
I1211 17:18:16.318233 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:18:16.318734 17748 solver.cpp:237]     Train net output #1: loss = 0.368279 (* 1 = 0.368279 loss)
I1211 17:18:16.318734 17748 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1211 17:18:22.534497 17748 solver.cpp:218] Iteration 101900 (16.0883 iter/s, 6.2157s/100 iters), loss = 0.365647
I1211 17:18:22.534497 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:18:22.534497 17748 solver.cpp:237]     Train net output #1: loss = 0.365647 (* 1 = 0.365647 loss)
I1211 17:18:22.534497 17748 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1211 17:18:28.472180 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:18:28.715198 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102000.caffemodel
I1211 17:18:28.730703 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102000.solverstate
I1211 17:18:28.736222 17748 solver.cpp:330] Iteration 102000, Testing net (#0)
I1211 17:18:28.736222 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:18:30.101377 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:18:30.154382 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6786
I1211 17:18:30.154382 17748 solver.cpp:397]     Test net output #1: loss = 1.2085 (* 1 = 1.2085 loss)
I1211 17:18:30.213382 17748 solver.cpp:218] Iteration 102000 (13.0231 iter/s, 7.67867s/100 iters), loss = 0.320676
I1211 17:18:30.213382 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:18:30.213382 17748 solver.cpp:237]     Train net output #1: loss = 0.320676 (* 1 = 0.320676 loss)
I1211 17:18:30.213382 17748 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1211 17:18:36.429411 17748 solver.cpp:218] Iteration 102100 (16.0902 iter/s, 6.21497s/100 iters), loss = 0.395898
I1211 17:18:36.429411 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:18:36.429411 17748 solver.cpp:237]     Train net output #1: loss = 0.395898 (* 1 = 0.395898 loss)
I1211 17:18:36.429411 17748 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1211 17:18:42.638576 17748 solver.cpp:218] Iteration 102200 (16.1067 iter/s, 6.20859s/100 iters), loss = 0.321657
I1211 17:18:42.638576 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:18:42.638576 17748 solver.cpp:237]     Train net output #1: loss = 0.321657 (* 1 = 0.321657 loss)
I1211 17:18:42.638576 17748 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1211 17:18:48.848163 17748 solver.cpp:218] Iteration 102300 (16.104 iter/s, 6.20962s/100 iters), loss = 0.306046
I1211 17:18:48.848163 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:18:48.848163 17748 solver.cpp:237]     Train net output #1: loss = 0.306046 (* 1 = 0.306046 loss)
I1211 17:18:48.848163 17748 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1211 17:18:55.084622 17748 solver.cpp:218] Iteration 102400 (16.035 iter/s, 6.23637s/100 iters), loss = 0.471502
I1211 17:18:55.085618 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:18:55.085618 17748 solver.cpp:237]     Train net output #1: loss = 0.471502 (* 1 = 0.471502 loss)
I1211 17:18:55.085618 17748 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1211 17:19:00.993106 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:19:01.237166 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102500.caffemodel
I1211 17:19:01.258884 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102500.solverstate
I1211 17:19:01.263900 17748 solver.cpp:330] Iteration 102500, Testing net (#0)
I1211 17:19:01.264899 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:19:02.616063 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:19:02.669075 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1211 17:19:02.669075 17748 solver.cpp:397]     Test net output #1: loss = 1.22002 (* 1 = 1.22002 loss)
I1211 17:19:02.728617 17748 solver.cpp:218] Iteration 102500 (13.0838 iter/s, 7.64305s/100 iters), loss = 0.326084
I1211 17:19:02.729116 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:19:02.729116 17748 solver.cpp:237]     Train net output #1: loss = 0.326084 (* 1 = 0.326084 loss)
I1211 17:19:02.729116 17748 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1211 17:19:08.928537 17748 solver.cpp:218] Iteration 102600 (16.1293 iter/s, 6.19989s/100 iters), loss = 0.436379
I1211 17:19:08.929538 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:19:08.929538 17748 solver.cpp:237]     Train net output #1: loss = 0.436379 (* 1 = 0.436379 loss)
I1211 17:19:08.929538 17748 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1211 17:19:15.172205 17748 solver.cpp:218] Iteration 102700 (16.0187 iter/s, 6.2427s/100 iters), loss = 0.352783
I1211 17:19:15.172720 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:19:15.172720 17748 solver.cpp:237]     Train net output #1: loss = 0.352783 (* 1 = 0.352783 loss)
I1211 17:19:15.172720 17748 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1211 17:19:21.558071 17748 solver.cpp:218] Iteration 102800 (15.6606 iter/s, 6.38545s/100 iters), loss = 0.375556
I1211 17:19:21.558071 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:19:21.558071 17748 solver.cpp:237]     Train net output #1: loss = 0.375556 (* 1 = 0.375556 loss)
I1211 17:19:21.558071 17748 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1211 17:19:27.870350 17748 solver.cpp:218] Iteration 102900 (15.8432 iter/s, 6.31184s/100 iters), loss = 0.437185
I1211 17:19:27.870350 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:19:27.870350 17748 solver.cpp:237]     Train net output #1: loss = 0.437184 (* 1 = 0.437184 loss)
I1211 17:19:27.870350 17748 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1211 17:19:33.835814 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:19:34.079828 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103000.caffemodel
I1211 17:19:34.100834 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103000.solverstate
I1211 17:19:34.106834 17748 solver.cpp:330] Iteration 103000, Testing net (#0)
I1211 17:19:34.106834 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:19:35.493435 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:19:35.546938 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6786
I1211 17:19:35.546938 17748 solver.cpp:397]     Test net output #1: loss = 1.2153 (* 1 = 1.2153 loss)
I1211 17:19:35.605943 17748 solver.cpp:218] Iteration 103000 (12.9286 iter/s, 7.73482s/100 iters), loss = 0.301714
I1211 17:19:35.605943 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:19:35.605943 17748 solver.cpp:237]     Train net output #1: loss = 0.301714 (* 1 = 0.301714 loss)
I1211 17:19:35.605943 17748 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1211 17:19:41.825417 17748 solver.cpp:218] Iteration 103100 (16.0784 iter/s, 6.21951s/100 iters), loss = 0.387967
I1211 17:19:41.825417 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:19:41.825417 17748 solver.cpp:237]     Train net output #1: loss = 0.387967 (* 1 = 0.387967 loss)
I1211 17:19:41.825417 17748 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1211 17:19:48.046795 17748 solver.cpp:218] Iteration 103200 (16.0765 iter/s, 6.22024s/100 iters), loss = 0.314892
I1211 17:19:48.046795 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:19:48.046795 17748 solver.cpp:237]     Train net output #1: loss = 0.314892 (* 1 = 0.314892 loss)
I1211 17:19:48.046795 17748 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1211 17:19:54.263265 17748 solver.cpp:218] Iteration 103300 (16.0856 iter/s, 6.21674s/100 iters), loss = 0.373635
I1211 17:19:54.264266 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:19:54.264266 17748 solver.cpp:237]     Train net output #1: loss = 0.373635 (* 1 = 0.373635 loss)
I1211 17:19:54.264266 17748 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1211 17:20:00.520195 17748 solver.cpp:218] Iteration 103400 (15.9853 iter/s, 6.25576s/100 iters), loss = 0.368497
I1211 17:20:00.520195 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:20:00.520195 17748 solver.cpp:237]     Train net output #1: loss = 0.368497 (* 1 = 0.368497 loss)
I1211 17:20:00.520195 17748 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1211 17:20:06.586325 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:20:06.843852 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103500.caffemodel
I1211 17:20:06.865852 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103500.solverstate
I1211 17:20:06.871852 17748 solver.cpp:330] Iteration 103500, Testing net (#0)
I1211 17:20:06.871852 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:20:08.250952 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:20:08.303979 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6769
I1211 17:20:08.303979 17748 solver.cpp:397]     Test net output #1: loss = 1.22398 (* 1 = 1.22398 loss)
I1211 17:20:08.363968 17748 solver.cpp:218] Iteration 103500 (12.7501 iter/s, 7.84309s/100 iters), loss = 0.308693
I1211 17:20:08.363968 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:20:08.363968 17748 solver.cpp:237]     Train net output #1: loss = 0.308693 (* 1 = 0.308693 loss)
I1211 17:20:08.363968 17748 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1211 17:20:14.650101 17748 solver.cpp:218] Iteration 103600 (15.9082 iter/s, 6.28605s/100 iters), loss = 0.407179
I1211 17:20:14.650101 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:20:14.650101 17748 solver.cpp:237]     Train net output #1: loss = 0.407179 (* 1 = 0.407179 loss)
I1211 17:20:14.650101 17748 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1211 17:20:20.976845 17748 solver.cpp:218] Iteration 103700 (15.8084 iter/s, 6.32576s/100 iters), loss = 0.389915
I1211 17:20:20.976845 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:20:20.976845 17748 solver.cpp:237]     Train net output #1: loss = 0.389915 (* 1 = 0.389915 loss)
I1211 17:20:20.976845 17748 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1211 17:20:27.251400 17748 solver.cpp:218] Iteration 103800 (15.9367 iter/s, 6.27484s/100 iters), loss = 0.316073
I1211 17:20:27.251400 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:20:27.252401 17748 solver.cpp:237]     Train net output #1: loss = 0.316072 (* 1 = 0.316072 loss)
I1211 17:20:27.252401 17748 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1211 17:20:33.462976 17748 solver.cpp:218] Iteration 103900 (16.1004 iter/s, 6.21101s/100 iters), loss = 0.404399
I1211 17:20:33.462976 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:20:33.463977 17748 solver.cpp:237]     Train net output #1: loss = 0.404399 (* 1 = 0.404399 loss)
I1211 17:20:33.463977 17748 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1211 17:20:39.373435 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:20:39.617452 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104000.caffemodel
I1211 17:20:39.635452 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104000.solverstate
I1211 17:20:39.641453 17748 solver.cpp:330] Iteration 104000, Testing net (#0)
I1211 17:20:39.641453 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:20:40.992471 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:20:41.045975 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 17:20:41.045975 17748 solver.cpp:397]     Test net output #1: loss = 1.22756 (* 1 = 1.22756 loss)
I1211 17:20:41.104977 17748 solver.cpp:218] Iteration 104000 (13.0872 iter/s, 7.64106s/100 iters), loss = 0.307083
I1211 17:20:41.104977 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:20:41.104977 17748 solver.cpp:237]     Train net output #1: loss = 0.307083 (* 1 = 0.307083 loss)
I1211 17:20:41.104977 17748 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1211 17:20:47.309442 17748 solver.cpp:218] Iteration 104100 (16.1179 iter/s, 6.20427s/100 iters), loss = 0.387318
I1211 17:20:47.309442 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:20:47.309442 17748 solver.cpp:237]     Train net output #1: loss = 0.387318 (* 1 = 0.387318 loss)
I1211 17:20:47.309442 17748 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1211 17:20:53.506883 17748 solver.cpp:218] Iteration 104200 (16.1372 iter/s, 6.19688s/100 iters), loss = 0.332122
I1211 17:20:53.506883 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:20:53.506883 17748 solver.cpp:237]     Train net output #1: loss = 0.332122 (* 1 = 0.332122 loss)
I1211 17:20:53.506883 17748 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1211 17:20:59.765741 17748 solver.cpp:218] Iteration 104300 (15.9776 iter/s, 6.25878s/100 iters), loss = 0.322567
I1211 17:20:59.766742 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:20:59.766742 17748 solver.cpp:237]     Train net output #1: loss = 0.322567 (* 1 = 0.322567 loss)
I1211 17:20:59.766742 17748 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1211 17:21:06.045287 17748 solver.cpp:218] Iteration 104400 (15.9266 iter/s, 6.27879s/100 iters), loss = 0.385549
I1211 17:21:06.045287 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:21:06.045287 17748 solver.cpp:237]     Train net output #1: loss = 0.385549 (* 1 = 0.385549 loss)
I1211 17:21:06.045287 17748 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1211 17:21:11.989781 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:21:12.237797 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104500.caffemodel
I1211 17:21:12.258797 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104500.solverstate
I1211 17:21:12.264797 17748 solver.cpp:330] Iteration 104500, Testing net (#0)
I1211 17:21:12.264797 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:21:13.627893 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:21:13.681892 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6769
I1211 17:21:13.681892 17748 solver.cpp:397]     Test net output #1: loss = 1.22571 (* 1 = 1.22571 loss)
I1211 17:21:13.742832 17748 solver.cpp:218] Iteration 104500 (12.9924 iter/s, 7.69682s/100 iters), loss = 0.297154
I1211 17:21:13.743332 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:21:13.743332 17748 solver.cpp:237]     Train net output #1: loss = 0.297154 (* 1 = 0.297154 loss)
I1211 17:21:13.743332 17748 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1211 17:21:20.007320 17748 solver.cpp:218] Iteration 104600 (15.9642 iter/s, 6.26401s/100 iters), loss = 0.346376
I1211 17:21:20.007822 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:21:20.007822 17748 solver.cpp:237]     Train net output #1: loss = 0.346376 (* 1 = 0.346376 loss)
I1211 17:21:20.007822 17748 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1211 17:21:26.272788 17748 solver.cpp:218] Iteration 104700 (15.9613 iter/s, 6.26516s/100 iters), loss = 0.355667
I1211 17:21:26.272788 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:21:26.272788 17748 solver.cpp:237]     Train net output #1: loss = 0.355667 (* 1 = 0.355667 loss)
I1211 17:21:26.272788 17748 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1211 17:21:32.535600 17748 solver.cpp:218] Iteration 104800 (15.9698 iter/s, 6.26183s/100 iters), loss = 0.41338
I1211 17:21:32.535600 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:21:32.535600 17748 solver.cpp:237]     Train net output #1: loss = 0.41338 (* 1 = 0.41338 loss)
I1211 17:21:32.535600 17748 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1211 17:21:38.785125 17748 solver.cpp:218] Iteration 104900 (16.0004 iter/s, 6.24984s/100 iters), loss = 0.346697
I1211 17:21:38.785125 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:21:38.785125 17748 solver.cpp:237]     Train net output #1: loss = 0.346697 (* 1 = 0.346697 loss)
I1211 17:21:38.785125 17748 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1211 17:21:44.685499 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:21:44.929543 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105000.caffemodel
I1211 17:21:44.950543 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105000.solverstate
I1211 17:21:44.956547 17748 solver.cpp:330] Iteration 105000, Testing net (#0)
I1211 17:21:44.956547 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:21:46.310660 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:21:46.363674 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6767
I1211 17:21:46.363674 17748 solver.cpp:397]     Test net output #1: loss = 1.23498 (* 1 = 1.23498 loss)
I1211 17:21:46.422672 17748 solver.cpp:218] Iteration 105000 (13.094 iter/s, 7.63706s/100 iters), loss = 0.226271
I1211 17:21:46.422672 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:21:46.422672 17748 solver.cpp:237]     Train net output #1: loss = 0.226271 (* 1 = 0.226271 loss)
I1211 17:21:46.422672 17748 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1211 17:21:52.637598 17748 solver.cpp:218] Iteration 105100 (16.0934 iter/s, 6.21372s/100 iters), loss = 0.307568
I1211 17:21:52.637598 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:21:52.637598 17748 solver.cpp:237]     Train net output #1: loss = 0.307568 (* 1 = 0.307568 loss)
I1211 17:21:52.637598 17748 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1211 17:21:58.848553 17748 solver.cpp:218] Iteration 105200 (16.1006 iter/s, 6.21096s/100 iters), loss = 0.295933
I1211 17:21:58.848553 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:21:58.848553 17748 solver.cpp:237]     Train net output #1: loss = 0.295933 (* 1 = 0.295933 loss)
I1211 17:21:58.848553 17748 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1211 17:22:05.062069 17748 solver.cpp:218] Iteration 105300 (16.0949 iter/s, 6.21316s/100 iters), loss = 0.275401
I1211 17:22:05.062069 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:22:05.062069 17748 solver.cpp:237]     Train net output #1: loss = 0.275401 (* 1 = 0.275401 loss)
I1211 17:22:05.062069 17748 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1211 17:22:11.272171 17748 solver.cpp:218] Iteration 105400 (16.1052 iter/s, 6.20916s/100 iters), loss = 0.45389
I1211 17:22:11.272171 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:22:11.272171 17748 solver.cpp:237]     Train net output #1: loss = 0.45389 (* 1 = 0.45389 loss)
I1211 17:22:11.272171 17748 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1211 17:22:17.170593 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:22:17.414608 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105500.caffemodel
I1211 17:22:17.432112 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105500.solverstate
I1211 17:22:17.437120 17748 solver.cpp:330] Iteration 105500, Testing net (#0)
I1211 17:22:17.437613 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:22:18.786717 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:22:18.840719 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 17:22:18.840719 17748 solver.cpp:397]     Test net output #1: loss = 1.22639 (* 1 = 1.22639 loss)
I1211 17:22:18.899720 17748 solver.cpp:218] Iteration 105500 (13.111 iter/s, 7.6272s/100 iters), loss = 0.268021
I1211 17:22:18.899720 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:22:18.899720 17748 solver.cpp:237]     Train net output #1: loss = 0.268021 (* 1 = 0.268021 loss)
I1211 17:22:18.899720 17748 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1211 17:22:25.101164 17748 solver.cpp:218] Iteration 105600 (16.1254 iter/s, 6.20139s/100 iters), loss = 0.356619
I1211 17:22:25.101164 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:22:25.101164 17748 solver.cpp:237]     Train net output #1: loss = 0.356619 (* 1 = 0.356619 loss)
I1211 17:22:25.101164 17748 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1211 17:22:31.314623 17748 solver.cpp:218] Iteration 105700 (16.0963 iter/s, 6.21259s/100 iters), loss = 0.321957
I1211 17:22:31.314623 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:22:31.314623 17748 solver.cpp:237]     Train net output #1: loss = 0.321957 (* 1 = 0.321957 loss)
I1211 17:22:31.314623 17748 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1211 17:22:37.519098 17748 solver.cpp:218] Iteration 105800 (16.1187 iter/s, 6.20396s/100 iters), loss = 0.376019
I1211 17:22:37.519098 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:22:37.519098 17748 solver.cpp:237]     Train net output #1: loss = 0.376019 (* 1 = 0.376019 loss)
I1211 17:22:37.519098 17748 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1211 17:22:43.728591 17748 solver.cpp:218] Iteration 105900 (16.1062 iter/s, 6.20878s/100 iters), loss = 0.399197
I1211 17:22:43.728591 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:22:43.728591 17748 solver.cpp:237]     Train net output #1: loss = 0.399197 (* 1 = 0.399197 loss)
I1211 17:22:43.728591 17748 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1211 17:22:49.630112 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:22:49.876129 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106000.caffemodel
I1211 17:22:49.897130 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106000.solverstate
I1211 17:22:49.903131 17748 solver.cpp:330] Iteration 106000, Testing net (#0)
I1211 17:22:49.903131 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:22:51.253238 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:22:51.306237 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1211 17:22:51.306237 17748 solver.cpp:397]     Test net output #1: loss = 1.23243 (* 1 = 1.23243 loss)
I1211 17:22:51.366250 17748 solver.cpp:218] Iteration 106000 (13.0935 iter/s, 7.63737s/100 iters), loss = 0.285166
I1211 17:22:51.366250 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:22:51.366250 17748 solver.cpp:237]     Train net output #1: loss = 0.285166 (* 1 = 0.285166 loss)
I1211 17:22:51.366250 17748 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1211 17:22:57.566730 17748 solver.cpp:218] Iteration 106100 (16.1278 iter/s, 6.20049s/100 iters), loss = 0.375692
I1211 17:22:57.566730 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:22:57.566730 17748 solver.cpp:237]     Train net output #1: loss = 0.375692 (* 1 = 0.375692 loss)
I1211 17:22:57.566730 17748 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1211 17:23:03.776219 17748 solver.cpp:218] Iteration 106200 (16.1061 iter/s, 6.20882s/100 iters), loss = 0.307208
I1211 17:23:03.776219 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:23:03.776219 17748 solver.cpp:237]     Train net output #1: loss = 0.307208 (* 1 = 0.307208 loss)
I1211 17:23:03.776219 17748 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1211 17:23:09.980669 17748 solver.cpp:218] Iteration 106300 (16.1176 iter/s, 6.20438s/100 iters), loss = 0.320763
I1211 17:23:09.980669 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:23:09.980669 17748 solver.cpp:237]     Train net output #1: loss = 0.320763 (* 1 = 0.320763 loss)
I1211 17:23:09.980669 17748 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1211 17:23:16.191107 17748 solver.cpp:218] Iteration 106400 (16.1042 iter/s, 6.20957s/100 iters), loss = 0.368804
I1211 17:23:16.191107 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:23:16.191107 17748 solver.cpp:237]     Train net output #1: loss = 0.368804 (* 1 = 0.368804 loss)
I1211 17:23:16.191107 17748 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1211 17:23:22.094565 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:23:22.339582 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106500.caffemodel
I1211 17:23:22.358590 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106500.solverstate
I1211 17:23:22.364585 17748 solver.cpp:330] Iteration 106500, Testing net (#0)
I1211 17:23:22.364585 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:23:23.715683 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:23:23.769690 17748 solver.cpp:397]     Test net output #0: accuracy = 0.681
I1211 17:23:23.769690 17748 solver.cpp:397]     Test net output #1: loss = 1.23751 (* 1 = 1.23751 loss)
I1211 17:23:23.828688 17748 solver.cpp:218] Iteration 106500 (13.0942 iter/s, 7.63695s/100 iters), loss = 0.286656
I1211 17:23:23.828688 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:23:23.828688 17748 solver.cpp:237]     Train net output #1: loss = 0.286656 (* 1 = 0.286656 loss)
I1211 17:23:23.828688 17748 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1211 17:23:30.030120 17748 solver.cpp:218] Iteration 106600 (16.1273 iter/s, 6.20067s/100 iters), loss = 0.405384
I1211 17:23:30.030120 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:23:30.030120 17748 solver.cpp:237]     Train net output #1: loss = 0.405384 (* 1 = 0.405384 loss)
I1211 17:23:30.030120 17748 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1211 17:23:36.239075 17748 solver.cpp:218] Iteration 106700 (16.1065 iter/s, 6.20867s/100 iters), loss = 0.33439
I1211 17:23:36.239075 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:23:36.239075 17748 solver.cpp:237]     Train net output #1: loss = 0.33439 (* 1 = 0.33439 loss)
I1211 17:23:36.239075 17748 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1211 17:23:42.453487 17748 solver.cpp:218] Iteration 106800 (16.093 iter/s, 6.21387s/100 iters), loss = 0.356179
I1211 17:23:42.453487 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:23:42.453487 17748 solver.cpp:237]     Train net output #1: loss = 0.356179 (* 1 = 0.356179 loss)
I1211 17:23:42.453487 17748 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1211 17:23:48.652937 17748 solver.cpp:218] Iteration 106900 (16.1308 iter/s, 6.19931s/100 iters), loss = 0.393731
I1211 17:23:48.653439 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:23:48.653439 17748 solver.cpp:237]     Train net output #1: loss = 0.39373 (* 1 = 0.39373 loss)
I1211 17:23:48.653439 17748 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1211 17:23:54.558825 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:23:54.801836 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107000.caffemodel
I1211 17:23:54.818835 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107000.solverstate
I1211 17:23:54.823835 17748 solver.cpp:330] Iteration 107000, Testing net (#0)
I1211 17:23:54.823835 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:23:56.174932 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:23:56.227931 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6774
I1211 17:23:56.228931 17748 solver.cpp:397]     Test net output #1: loss = 1.23877 (* 1 = 1.23877 loss)
I1211 17:23:56.286939 17748 solver.cpp:218] Iteration 107000 (13.0994 iter/s, 7.63394s/100 iters), loss = 0.298905
I1211 17:23:56.286939 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:23:56.286939 17748 solver.cpp:237]     Train net output #1: loss = 0.298904 (* 1 = 0.298904 loss)
I1211 17:23:56.286939 17748 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1211 17:24:02.504320 17748 solver.cpp:218] Iteration 107100 (16.0868 iter/s, 6.21628s/100 iters), loss = 0.435643
I1211 17:24:02.504320 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 17:24:02.504320 17748 solver.cpp:237]     Train net output #1: loss = 0.435643 (* 1 = 0.435643 loss)
I1211 17:24:02.504320 17748 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1211 17:24:08.710804 17748 solver.cpp:218] Iteration 107200 (16.1137 iter/s, 6.2059s/100 iters), loss = 0.358101
I1211 17:24:08.710804 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:24:08.710804 17748 solver.cpp:237]     Train net output #1: loss = 0.358101 (* 1 = 0.358101 loss)
I1211 17:24:08.710804 17748 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1211 17:24:14.912310 17748 solver.cpp:218] Iteration 107300 (16.1259 iter/s, 6.2012s/100 iters), loss = 0.365756
I1211 17:24:14.912310 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:24:14.912310 17748 solver.cpp:237]     Train net output #1: loss = 0.365756 (* 1 = 0.365756 loss)
I1211 17:24:14.912310 17748 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1211 17:24:21.117753 17748 solver.cpp:218] Iteration 107400 (16.116 iter/s, 6.20502s/100 iters), loss = 0.382936
I1211 17:24:21.117753 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:24:21.117753 17748 solver.cpp:237]     Train net output #1: loss = 0.382935 (* 1 = 0.382935 loss)
I1211 17:24:21.117753 17748 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1211 17:24:27.016171 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:24:27.260195 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107500.caffemodel
I1211 17:24:27.280194 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107500.solverstate
I1211 17:24:27.285194 17748 solver.cpp:330] Iteration 107500, Testing net (#0)
I1211 17:24:27.285194 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:24:28.638540 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:24:28.690551 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6768
I1211 17:24:28.690551 17748 solver.cpp:397]     Test net output #1: loss = 1.23919 (* 1 = 1.23919 loss)
I1211 17:24:28.750555 17748 solver.cpp:218] Iteration 107500 (13.1022 iter/s, 7.6323s/100 iters), loss = 0.254403
I1211 17:24:28.750555 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:24:28.750555 17748 solver.cpp:237]     Train net output #1: loss = 0.254403 (* 1 = 0.254403 loss)
I1211 17:24:28.750555 17748 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1211 17:24:34.955166 17748 solver.cpp:218] Iteration 107600 (16.118 iter/s, 6.20425s/100 iters), loss = 0.325078
I1211 17:24:34.955166 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:24:34.955166 17748 solver.cpp:237]     Train net output #1: loss = 0.325078 (* 1 = 0.325078 loss)
I1211 17:24:34.955166 17748 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1211 17:24:41.157068 17748 solver.cpp:218] Iteration 107700 (16.1249 iter/s, 6.20158s/100 iters), loss = 0.302626
I1211 17:24:41.157569 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:24:41.157569 17748 solver.cpp:237]     Train net output #1: loss = 0.302626 (* 1 = 0.302626 loss)
I1211 17:24:41.157569 17748 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1211 17:24:47.360981 17748 solver.cpp:218] Iteration 107800 (16.1204 iter/s, 6.20333s/100 iters), loss = 0.330077
I1211 17:24:47.360981 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:24:47.360981 17748 solver.cpp:237]     Train net output #1: loss = 0.330077 (* 1 = 0.330077 loss)
I1211 17:24:47.360981 17748 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1211 17:24:53.561440 17748 solver.cpp:218] Iteration 107900 (16.1292 iter/s, 6.19994s/100 iters), loss = 0.368833
I1211 17:24:53.561440 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:24:53.561440 17748 solver.cpp:237]     Train net output #1: loss = 0.368833 (* 1 = 0.368833 loss)
I1211 17:24:53.561440 17748 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1211 17:24:59.461918 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:24:59.705935 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108000.caffemodel
I1211 17:24:59.721936 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108000.solverstate
I1211 17:24:59.726935 17748 solver.cpp:330] Iteration 108000, Testing net (#0)
I1211 17:24:59.726935 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:25:01.082051 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:25:01.136051 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 17:25:01.136051 17748 solver.cpp:397]     Test net output #1: loss = 1.2592 (* 1 = 1.2592 loss)
I1211 17:25:01.194068 17748 solver.cpp:218] Iteration 108000 (13.1017 iter/s, 7.6326s/100 iters), loss = 0.314382
I1211 17:25:01.194068 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:25:01.194068 17748 solver.cpp:237]     Train net output #1: loss = 0.314382 (* 1 = 0.314382 loss)
I1211 17:25:01.195060 17748 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1211 17:25:07.394572 17748 solver.cpp:218] Iteration 108100 (16.1299 iter/s, 6.19968s/100 iters), loss = 0.295359
I1211 17:25:07.394572 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:25:07.394572 17748 solver.cpp:237]     Train net output #1: loss = 0.295358 (* 1 = 0.295358 loss)
I1211 17:25:07.394572 17748 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1211 17:25:13.593133 17748 solver.cpp:218] Iteration 108200 (16.1338 iter/s, 6.19815s/100 iters), loss = 0.307363
I1211 17:25:13.593133 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:25:13.593133 17748 solver.cpp:237]     Train net output #1: loss = 0.307363 (* 1 = 0.307363 loss)
I1211 17:25:13.593133 17748 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1211 17:25:19.796694 17748 solver.cpp:218] Iteration 108300 (16.1205 iter/s, 6.20329s/100 iters), loss = 0.394878
I1211 17:25:19.796694 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:25:19.796694 17748 solver.cpp:237]     Train net output #1: loss = 0.394878 (* 1 = 0.394878 loss)
I1211 17:25:19.796694 17748 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1211 17:25:26.008177 17748 solver.cpp:218] Iteration 108400 (16.1008 iter/s, 6.21086s/100 iters), loss = 0.352947
I1211 17:25:26.008177 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:25:26.008177 17748 solver.cpp:237]     Train net output #1: loss = 0.352947 (* 1 = 0.352947 loss)
I1211 17:25:26.008177 17748 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1211 17:25:31.906970 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:25:32.151970 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108500.caffemodel
I1211 17:25:32.169972 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108500.solverstate
I1211 17:25:32.174970 17748 solver.cpp:330] Iteration 108500, Testing net (#0)
I1211 17:25:32.174970 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:25:33.527552 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:25:33.580554 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6787
I1211 17:25:33.580554 17748 solver.cpp:397]     Test net output #1: loss = 1.23429 (* 1 = 1.23429 loss)
I1211 17:25:33.639559 17748 solver.cpp:218] Iteration 108500 (13.1052 iter/s, 7.63057s/100 iters), loss = 0.223428
I1211 17:25:33.639559 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:25:33.639559 17748 solver.cpp:237]     Train net output #1: loss = 0.223428 (* 1 = 0.223428 loss)
I1211 17:25:33.639559 17748 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1211 17:25:39.840955 17748 solver.cpp:218] Iteration 108600 (16.1264 iter/s, 6.201s/100 iters), loss = 0.338214
I1211 17:25:39.840955 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:25:39.840955 17748 solver.cpp:237]     Train net output #1: loss = 0.338214 (* 1 = 0.338214 loss)
I1211 17:25:39.840955 17748 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1211 17:25:46.051260 17748 solver.cpp:218] Iteration 108700 (16.1028 iter/s, 6.2101s/100 iters), loss = 0.344836
I1211 17:25:46.051260 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:25:46.051260 17748 solver.cpp:237]     Train net output #1: loss = 0.344836 (* 1 = 0.344836 loss)
I1211 17:25:46.051260 17748 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1211 17:25:52.246978 17748 solver.cpp:218] Iteration 108800 (16.1426 iter/s, 6.19481s/100 iters), loss = 0.372397
I1211 17:25:52.246978 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:25:52.246978 17748 solver.cpp:237]     Train net output #1: loss = 0.372397 (* 1 = 0.372397 loss)
I1211 17:25:52.246978 17748 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1211 17:25:58.449841 17748 solver.cpp:218] Iteration 108900 (16.1205 iter/s, 6.20329s/100 iters), loss = 0.358727
I1211 17:25:58.449841 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:25:58.449841 17748 solver.cpp:237]     Train net output #1: loss = 0.358727 (* 1 = 0.358727 loss)
I1211 17:25:58.449841 17748 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1211 17:26:04.338276 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:26:04.584290 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109000.caffemodel
I1211 17:26:04.605288 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109000.solverstate
I1211 17:26:04.611299 17748 solver.cpp:330] Iteration 109000, Testing net (#0)
I1211 17:26:04.611299 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:26:05.964393 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:26:06.017393 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6798
I1211 17:26:06.017393 17748 solver.cpp:397]     Test net output #1: loss = 1.24327 (* 1 = 1.24327 loss)
I1211 17:26:06.076411 17748 solver.cpp:218] Iteration 109000 (13.1132 iter/s, 7.62589s/100 iters), loss = 0.303399
I1211 17:26:06.076411 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:26:06.076411 17748 solver.cpp:237]     Train net output #1: loss = 0.303398 (* 1 = 0.303398 loss)
I1211 17:26:06.076411 17748 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1211 17:26:12.283852 17748 solver.cpp:218] Iteration 109100 (16.1107 iter/s, 6.20707s/100 iters), loss = 0.354464
I1211 17:26:12.283852 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:26:12.283852 17748 solver.cpp:237]     Train net output #1: loss = 0.354464 (* 1 = 0.354464 loss)
I1211 17:26:12.283852 17748 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1211 17:26:18.484340 17748 solver.cpp:218] Iteration 109200 (16.1293 iter/s, 6.19989s/100 iters), loss = 0.278045
I1211 17:26:18.484340 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:26:18.484340 17748 solver.cpp:237]     Train net output #1: loss = 0.278045 (* 1 = 0.278045 loss)
I1211 17:26:18.484340 17748 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1211 17:26:24.690800 17748 solver.cpp:218] Iteration 109300 (16.113 iter/s, 6.20617s/100 iters), loss = 0.34274
I1211 17:26:24.690800 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:26:24.690800 17748 solver.cpp:237]     Train net output #1: loss = 0.34274 (* 1 = 0.34274 loss)
I1211 17:26:24.690800 17748 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1211 17:26:30.895530 17748 solver.cpp:218] Iteration 109400 (16.1191 iter/s, 6.20382s/100 iters), loss = 0.401614
I1211 17:26:30.895530 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:26:30.895530 17748 solver.cpp:237]     Train net output #1: loss = 0.401614 (* 1 = 0.401614 loss)
I1211 17:26:30.895530 17748 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1211 17:26:36.795946 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:26:37.039963 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109500.caffemodel
I1211 17:26:37.060962 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109500.solverstate
I1211 17:26:37.065969 17748 solver.cpp:330] Iteration 109500, Testing net (#0)
I1211 17:26:37.065969 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:26:38.418066 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:26:38.472072 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1211 17:26:38.472072 17748 solver.cpp:397]     Test net output #1: loss = 1.24607 (* 1 = 1.24607 loss)
I1211 17:26:38.531075 17748 solver.cpp:218] Iteration 109500 (13.0975 iter/s, 7.63503s/100 iters), loss = 0.285992
I1211 17:26:38.531574 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:26:38.531574 17748 solver.cpp:237]     Train net output #1: loss = 0.285992 (* 1 = 0.285992 loss)
I1211 17:26:38.531574 17748 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1211 17:26:44.737500 17748 solver.cpp:218] Iteration 109600 (16.1137 iter/s, 6.20591s/100 iters), loss = 0.320055
I1211 17:26:44.737500 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:26:44.737500 17748 solver.cpp:237]     Train net output #1: loss = 0.320055 (* 1 = 0.320055 loss)
I1211 17:26:44.737500 17748 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1211 17:26:50.956933 17748 solver.cpp:218] Iteration 109700 (16.0789 iter/s, 6.21931s/100 iters), loss = 0.267826
I1211 17:26:50.956933 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:26:50.956933 17748 solver.cpp:237]     Train net output #1: loss = 0.267826 (* 1 = 0.267826 loss)
I1211 17:26:50.956933 17748 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1211 17:26:57.153223 17748 solver.cpp:218] Iteration 109800 (16.1403 iter/s, 6.19568s/100 iters), loss = 0.285737
I1211 17:26:57.153223 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:26:57.153223 17748 solver.cpp:237]     Train net output #1: loss = 0.285737 (* 1 = 0.285737 loss)
I1211 17:26:57.153223 17748 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1211 17:27:03.356036 17748 solver.cpp:218] Iteration 109900 (16.1224 iter/s, 6.20257s/100 iters), loss = 0.373887
I1211 17:27:03.356036 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:27:03.356036 17748 solver.cpp:237]     Train net output #1: loss = 0.373886 (* 1 = 0.373886 loss)
I1211 17:27:03.356036 17748 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1211 17:27:09.258595 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:27:09.503607 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110000.caffemodel
I1211 17:27:09.525607 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110000.solverstate
I1211 17:27:09.532116 17748 solver.cpp:330] Iteration 110000, Testing net (#0)
I1211 17:27:09.532116 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:27:10.882709 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:27:10.936213 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6761
I1211 17:27:10.936213 17748 solver.cpp:397]     Test net output #1: loss = 1.24801 (* 1 = 1.24801 loss)
I1211 17:27:10.994715 17748 solver.cpp:218] Iteration 110000 (13.0933 iter/s, 7.63751s/100 iters), loss = 0.228572
I1211 17:27:10.994715 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 17:27:10.994715 17748 solver.cpp:237]     Train net output #1: loss = 0.228572 (* 1 = 0.228572 loss)
I1211 17:27:10.994715 17748 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1211 17:27:17.200134 17748 solver.cpp:218] Iteration 110100 (16.1154 iter/s, 6.20526s/100 iters), loss = 0.475257
I1211 17:27:17.200134 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:27:17.200134 17748 solver.cpp:237]     Train net output #1: loss = 0.475257 (* 1 = 0.475257 loss)
I1211 17:27:17.200134 17748 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1211 17:27:23.405643 17748 solver.cpp:218] Iteration 110200 (16.1156 iter/s, 6.20519s/100 iters), loss = 0.288169
I1211 17:27:23.405643 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:27:23.405643 17748 solver.cpp:237]     Train net output #1: loss = 0.288169 (* 1 = 0.288169 loss)
I1211 17:27:23.405643 17748 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1211 17:27:29.603061 17748 solver.cpp:218] Iteration 110300 (16.1364 iter/s, 6.19717s/100 iters), loss = 0.328342
I1211 17:27:29.603061 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:27:29.603061 17748 solver.cpp:237]     Train net output #1: loss = 0.328342 (* 1 = 0.328342 loss)
I1211 17:27:29.603061 17748 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1211 17:27:35.813468 17748 solver.cpp:218] Iteration 110400 (16.103 iter/s, 6.21004s/100 iters), loss = 0.371066
I1211 17:27:35.813468 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:27:35.813468 17748 solver.cpp:237]     Train net output #1: loss = 0.371066 (* 1 = 0.371066 loss)
I1211 17:27:35.813468 17748 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1211 17:27:41.708935 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:27:41.953949 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110500.caffemodel
I1211 17:27:41.974949 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110500.solverstate
I1211 17:27:41.979950 17748 solver.cpp:330] Iteration 110500, Testing net (#0)
I1211 17:27:41.979950 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:27:43.332047 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:27:43.385052 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1211 17:27:43.385052 17748 solver.cpp:397]     Test net output #1: loss = 1.2557 (* 1 = 1.2557 loss)
I1211 17:27:43.445057 17748 solver.cpp:218] Iteration 110500 (13.1055 iter/s, 7.63038s/100 iters), loss = 0.230977
I1211 17:27:43.445057 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:27:43.445057 17748 solver.cpp:237]     Train net output #1: loss = 0.230977 (* 1 = 0.230977 loss)
I1211 17:27:43.445057 17748 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1211 17:27:49.637462 17748 solver.cpp:218] Iteration 110600 (16.1498 iter/s, 6.19202s/100 iters), loss = 0.278458
I1211 17:27:49.637462 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:27:49.637462 17748 solver.cpp:237]     Train net output #1: loss = 0.278457 (* 1 = 0.278457 loss)
I1211 17:27:49.637462 17748 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1211 17:27:55.838419 17748 solver.cpp:218] Iteration 110700 (16.128 iter/s, 6.20039s/100 iters), loss = 0.319293
I1211 17:27:55.838419 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:27:55.838419 17748 solver.cpp:237]     Train net output #1: loss = 0.319293 (* 1 = 0.319293 loss)
I1211 17:27:55.838419 17748 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1211 17:28:02.027721 17748 solver.cpp:218] Iteration 110800 (16.1579 iter/s, 6.18893s/100 iters), loss = 0.388757
I1211 17:28:02.027721 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 17:28:02.027721 17748 solver.cpp:237]     Train net output #1: loss = 0.388757 (* 1 = 0.388757 loss)
I1211 17:28:02.027721 17748 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1211 17:28:08.224627 17748 solver.cpp:218] Iteration 110900 (16.1361 iter/s, 6.19728s/100 iters), loss = 0.353619
I1211 17:28:08.225628 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:28:08.225628 17748 solver.cpp:237]     Train net output #1: loss = 0.353619 (* 1 = 0.353619 loss)
I1211 17:28:08.225628 17748 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1211 17:28:14.122829 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:28:14.366600 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111000.caffemodel
I1211 17:28:14.382593 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111000.solverstate
I1211 17:28:14.387607 17748 solver.cpp:330] Iteration 111000, Testing net (#0)
I1211 17:28:14.388588 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:28:15.738497 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:28:15.791501 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6796
I1211 17:28:15.791501 17748 solver.cpp:397]     Test net output #1: loss = 1.24688 (* 1 = 1.24688 loss)
I1211 17:28:15.850028 17748 solver.cpp:218] Iteration 111000 (13.1161 iter/s, 7.62424s/100 iters), loss = 0.337007
I1211 17:28:15.850028 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:28:15.850028 17748 solver.cpp:237]     Train net output #1: loss = 0.337006 (* 1 = 0.337006 loss)
I1211 17:28:15.850028 17748 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1211 17:28:22.051456 17748 solver.cpp:218] Iteration 111100 (16.1273 iter/s, 6.20067s/100 iters), loss = 0.351847
I1211 17:28:22.051456 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:28:22.051456 17748 solver.cpp:237]     Train net output #1: loss = 0.351847 (* 1 = 0.351847 loss)
I1211 17:28:22.051456 17748 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1211 17:28:28.246955 17748 solver.cpp:218] Iteration 111200 (16.1411 iter/s, 6.19535s/100 iters), loss = 0.315112
I1211 17:28:28.246955 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:28:28.246955 17748 solver.cpp:237]     Train net output #1: loss = 0.315111 (* 1 = 0.315111 loss)
I1211 17:28:28.246955 17748 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1211 17:28:34.448050 17748 solver.cpp:218] Iteration 111300 (16.1272 iter/s, 6.20069s/100 iters), loss = 0.379304
I1211 17:28:34.448050 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:28:34.448050 17748 solver.cpp:237]     Train net output #1: loss = 0.379304 (* 1 = 0.379304 loss)
I1211 17:28:34.448050 17748 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1211 17:28:40.652500 17748 solver.cpp:218] Iteration 111400 (16.1191 iter/s, 6.20382s/100 iters), loss = 0.291596
I1211 17:28:40.652500 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:28:40.652500 17748 solver.cpp:237]     Train net output #1: loss = 0.291596 (* 1 = 0.291596 loss)
I1211 17:28:40.652500 17748 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1211 17:28:46.559981 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:28:46.802994 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111500.caffemodel
I1211 17:28:46.824998 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111500.solverstate
I1211 17:28:46.829999 17748 solver.cpp:330] Iteration 111500, Testing net (#0)
I1211 17:28:46.829999 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:28:48.183092 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:28:48.236099 17748 solver.cpp:397]     Test net output #0: accuracy = 0.679
I1211 17:28:48.236099 17748 solver.cpp:397]     Test net output #1: loss = 1.26763 (* 1 = 1.26763 loss)
I1211 17:28:48.296602 17748 solver.cpp:218] Iteration 111500 (13.083 iter/s, 7.6435s/100 iters), loss = 0.228431
I1211 17:28:48.296602 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:28:48.296602 17748 solver.cpp:237]     Train net output #1: loss = 0.22843 (* 1 = 0.22843 loss)
I1211 17:28:48.296602 17748 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1211 17:28:54.502516 17748 solver.cpp:218] Iteration 111600 (16.1146 iter/s, 6.20557s/100 iters), loss = 0.352074
I1211 17:28:54.502516 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:28:54.502516 17748 solver.cpp:237]     Train net output #1: loss = 0.352074 (* 1 = 0.352074 loss)
I1211 17:28:54.502516 17748 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1211 17:29:00.705615 17748 solver.cpp:218] Iteration 111700 (16.1214 iter/s, 6.20292s/100 iters), loss = 0.276
I1211 17:29:00.706115 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:29:00.706115 17748 solver.cpp:237]     Train net output #1: loss = 0.276 (* 1 = 0.276 loss)
I1211 17:29:00.706115 17748 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1211 17:29:06.897555 17748 solver.cpp:218] Iteration 111800 (16.1517 iter/s, 6.19131s/100 iters), loss = 0.303391
I1211 17:29:06.898058 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:29:06.898058 17748 solver.cpp:237]     Train net output #1: loss = 0.303391 (* 1 = 0.303391 loss)
I1211 17:29:06.898058 17748 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1211 17:29:13.103032 17748 solver.cpp:218] Iteration 111900 (16.1165 iter/s, 6.20483s/100 iters), loss = 0.419157
I1211 17:29:13.103032 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:29:13.103032 17748 solver.cpp:237]     Train net output #1: loss = 0.419157 (* 1 = 0.419157 loss)
I1211 17:29:13.103032 17748 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1211 17:29:18.995456 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:29:19.238471 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112000.caffemodel
I1211 17:29:19.261471 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112000.solverstate
I1211 17:29:19.266472 17748 solver.cpp:330] Iteration 112000, Testing net (#0)
I1211 17:29:19.266472 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:29:20.616569 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:29:20.670567 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1211 17:29:20.670567 17748 solver.cpp:397]     Test net output #1: loss = 1.25417 (* 1 = 1.25417 loss)
I1211 17:29:20.728572 17748 solver.cpp:218] Iteration 112000 (13.1138 iter/s, 7.62557s/100 iters), loss = 0.208118
I1211 17:29:20.728572 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:29:20.728572 17748 solver.cpp:237]     Train net output #1: loss = 0.208118 (* 1 = 0.208118 loss)
I1211 17:29:20.728572 17748 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1211 17:29:26.939214 17748 solver.cpp:218] Iteration 112100 (16.1025 iter/s, 6.21023s/100 iters), loss = 0.325941
I1211 17:29:26.940214 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:29:26.940214 17748 solver.cpp:237]     Train net output #1: loss = 0.325941 (* 1 = 0.325941 loss)
I1211 17:29:26.940214 17748 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1211 17:29:33.142293 17748 solver.cpp:218] Iteration 112200 (16.1225 iter/s, 6.2025s/100 iters), loss = 0.323822
I1211 17:29:33.142293 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:29:33.142293 17748 solver.cpp:237]     Train net output #1: loss = 0.323821 (* 1 = 0.323821 loss)
I1211 17:29:33.142293 17748 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1211 17:29:39.349097 17748 solver.cpp:218] Iteration 112300 (16.1139 iter/s, 6.20584s/100 iters), loss = 0.279482
I1211 17:29:39.349097 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:29:39.349097 17748 solver.cpp:237]     Train net output #1: loss = 0.279482 (* 1 = 0.279482 loss)
I1211 17:29:39.349097 17748 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1211 17:29:45.540866 17748 solver.cpp:218] Iteration 112400 (16.1515 iter/s, 6.19136s/100 iters), loss = 0.3866
I1211 17:29:45.540866 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:29:45.540866 17748 solver.cpp:237]     Train net output #1: loss = 0.3866 (* 1 = 0.3866 loss)
I1211 17:29:45.540866 17748 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1211 17:29:51.448814 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:29:51.690825 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112500.caffemodel
I1211 17:29:51.711832 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112500.solverstate
I1211 17:29:51.716831 17748 solver.cpp:330] Iteration 112500, Testing net (#0)
I1211 17:29:51.717833 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:29:53.069948 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:29:53.122967 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 17:29:53.122967 17748 solver.cpp:397]     Test net output #1: loss = 1.26267 (* 1 = 1.26267 loss)
I1211 17:29:53.180966 17748 solver.cpp:218] Iteration 112500 (13.0894 iter/s, 7.63976s/100 iters), loss = 0.270564
I1211 17:29:53.180966 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:29:53.180966 17748 solver.cpp:237]     Train net output #1: loss = 0.270564 (* 1 = 0.270564 loss)
I1211 17:29:53.180966 17748 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1211 17:29:59.382349 17748 solver.cpp:218] Iteration 112600 (16.1258 iter/s, 6.20124s/100 iters), loss = 0.339977
I1211 17:29:59.382349 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:29:59.382349 17748 solver.cpp:237]     Train net output #1: loss = 0.339976 (* 1 = 0.339976 loss)
I1211 17:29:59.382349 17748 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1211 17:30:05.614245 17748 solver.cpp:218] Iteration 112700 (16.0487 iter/s, 6.23103s/100 iters), loss = 0.304219
I1211 17:30:05.614245 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:30:05.614245 17748 solver.cpp:237]     Train net output #1: loss = 0.304219 (* 1 = 0.304219 loss)
I1211 17:30:05.614245 17748 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1211 17:30:11.811755 17748 solver.cpp:218] Iteration 112800 (16.1372 iter/s, 6.19684s/100 iters), loss = 0.36942
I1211 17:30:11.811755 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:30:11.811755 17748 solver.cpp:237]     Train net output #1: loss = 0.369419 (* 1 = 0.369419 loss)
I1211 17:30:11.811755 17748 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1211 17:30:18.008756 17748 solver.cpp:218] Iteration 112900 (16.1378 iter/s, 6.19664s/100 iters), loss = 0.393137
I1211 17:30:18.008756 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:30:18.008756 17748 solver.cpp:237]     Train net output #1: loss = 0.393136 (* 1 = 0.393136 loss)
I1211 17:30:18.008756 17748 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1211 17:30:23.908771 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:30:24.153801 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113000.caffemodel
I1211 17:30:24.177801 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113000.solverstate
I1211 17:30:24.182802 17748 solver.cpp:330] Iteration 113000, Testing net (#0)
I1211 17:30:24.182802 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:30:25.533931 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:30:25.586923 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6736
I1211 17:30:25.586923 17748 solver.cpp:397]     Test net output #1: loss = 1.27078 (* 1 = 1.27078 loss)
I1211 17:30:25.645928 17748 solver.cpp:218] Iteration 113000 (13.0945 iter/s, 7.63681s/100 iters), loss = 0.25028
I1211 17:30:25.645928 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:30:25.645928 17748 solver.cpp:237]     Train net output #1: loss = 0.25028 (* 1 = 0.25028 loss)
I1211 17:30:25.645928 17748 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1211 17:30:31.844339 17748 solver.cpp:218] Iteration 113100 (16.135 iter/s, 6.19772s/100 iters), loss = 0.31885
I1211 17:30:31.844339 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:30:31.844339 17748 solver.cpp:237]     Train net output #1: loss = 0.31885 (* 1 = 0.31885 loss)
I1211 17:30:31.844339 17748 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1211 17:30:38.058753 17748 solver.cpp:218] Iteration 113200 (16.0918 iter/s, 6.21433s/100 iters), loss = 0.261428
I1211 17:30:38.058753 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:30:38.058753 17748 solver.cpp:237]     Train net output #1: loss = 0.261428 (* 1 = 0.261428 loss)
I1211 17:30:38.058753 17748 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1211 17:30:44.260246 17748 solver.cpp:218] Iteration 113300 (16.1278 iter/s, 6.20048s/100 iters), loss = 0.305209
I1211 17:30:44.260246 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:30:44.260246 17748 solver.cpp:237]     Train net output #1: loss = 0.305209 (* 1 = 0.305209 loss)
I1211 17:30:44.260246 17748 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1211 17:30:50.467741 17748 solver.cpp:218] Iteration 113400 (16.1098 iter/s, 6.20739s/100 iters), loss = 0.368684
I1211 17:30:50.467741 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:30:50.467741 17748 solver.cpp:237]     Train net output #1: loss = 0.368684 (* 1 = 0.368684 loss)
I1211 17:30:50.467741 17748 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1211 17:30:56.356294 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:30:56.602313 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113500.caffemodel
I1211 17:30:56.618317 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113500.solverstate
I1211 17:30:56.623317 17748 solver.cpp:330] Iteration 113500, Testing net (#0)
I1211 17:30:56.623317 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:30:57.975420 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:30:58.028429 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1211 17:30:58.028429 17748 solver.cpp:397]     Test net output #1: loss = 1.25928 (* 1 = 1.25928 loss)
I1211 17:30:58.087429 17748 solver.cpp:218] Iteration 113500 (13.1245 iter/s, 7.61932s/100 iters), loss = 0.218148
I1211 17:30:58.087429 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:30:58.087429 17748 solver.cpp:237]     Train net output #1: loss = 0.218147 (* 1 = 0.218147 loss)
I1211 17:30:58.087429 17748 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1211 17:31:04.293898 17748 solver.cpp:218] Iteration 113600 (16.1146 iter/s, 6.20554s/100 iters), loss = 0.3071
I1211 17:31:04.293898 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:31:04.293898 17748 solver.cpp:237]     Train net output #1: loss = 0.3071 (* 1 = 0.3071 loss)
I1211 17:31:04.293898 17748 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1211 17:31:10.492352 17748 solver.cpp:218] Iteration 113700 (16.1341 iter/s, 6.19807s/100 iters), loss = 0.330294
I1211 17:31:10.492352 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:31:10.492352 17748 solver.cpp:237]     Train net output #1: loss = 0.330293 (* 1 = 0.330293 loss)
I1211 17:31:10.492352 17748 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1211 17:31:16.693794 17748 solver.cpp:218] Iteration 113800 (16.1262 iter/s, 6.20108s/100 iters), loss = 0.334023
I1211 17:31:16.693794 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:31:16.693794 17748 solver.cpp:237]     Train net output #1: loss = 0.334023 (* 1 = 0.334023 loss)
I1211 17:31:16.693794 17748 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1211 17:31:22.897164 17748 solver.cpp:218] Iteration 113900 (16.121 iter/s, 6.20309s/100 iters), loss = 0.326668
I1211 17:31:22.897164 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:31:22.897164 17748 solver.cpp:237]     Train net output #1: loss = 0.326668 (* 1 = 0.326668 loss)
I1211 17:31:22.897164 17748 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1211 17:31:28.786571 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:31:29.031586 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114000.caffemodel
I1211 17:31:29.047586 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114000.solverstate
I1211 17:31:29.052587 17748 solver.cpp:330] Iteration 114000, Testing net (#0)
I1211 17:31:29.052587 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:31:30.404196 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:31:30.456707 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6746
I1211 17:31:30.456707 17748 solver.cpp:397]     Test net output #1: loss = 1.27049 (* 1 = 1.27049 loss)
I1211 17:31:30.515203 17748 solver.cpp:218] Iteration 114000 (13.1277 iter/s, 7.61748s/100 iters), loss = 0.325602
I1211 17:31:30.515703 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:31:30.515703 17748 solver.cpp:237]     Train net output #1: loss = 0.325601 (* 1 = 0.325601 loss)
I1211 17:31:30.515703 17748 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1211 17:31:36.718255 17748 solver.cpp:218] Iteration 114100 (16.1229 iter/s, 6.20235s/100 iters), loss = 0.276776
I1211 17:31:36.718255 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:31:36.718255 17748 solver.cpp:237]     Train net output #1: loss = 0.276776 (* 1 = 0.276776 loss)
I1211 17:31:36.718255 17748 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1211 17:31:42.908161 17748 solver.cpp:218] Iteration 114200 (16.1564 iter/s, 6.1895s/100 iters), loss = 0.336402
I1211 17:31:42.908161 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:31:42.908161 17748 solver.cpp:237]     Train net output #1: loss = 0.336401 (* 1 = 0.336401 loss)
I1211 17:31:42.908161 17748 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1211 17:31:49.103027 17748 solver.cpp:218] Iteration 114300 (16.1438 iter/s, 6.19431s/100 iters), loss = 0.329833
I1211 17:31:49.103027 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:31:49.103027 17748 solver.cpp:237]     Train net output #1: loss = 0.329833 (* 1 = 0.329833 loss)
I1211 17:31:49.103027 17748 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1211 17:31:55.299255 17748 solver.cpp:218] Iteration 114400 (16.1388 iter/s, 6.19626s/100 iters), loss = 0.277486
I1211 17:31:55.299255 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:31:55.299255 17748 solver.cpp:237]     Train net output #1: loss = 0.277486 (* 1 = 0.277486 loss)
I1211 17:31:55.299255 17748 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1211 17:32:01.204347 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:32:01.449499 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114500.caffemodel
I1211 17:32:01.470484 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114500.solverstate
I1211 17:32:01.475483 17748 solver.cpp:330] Iteration 114500, Testing net (#0)
I1211 17:32:01.475483 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:32:02.827214 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:32:02.880219 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6746
I1211 17:32:02.880219 17748 solver.cpp:397]     Test net output #1: loss = 1.27313 (* 1 = 1.27313 loss)
I1211 17:32:02.939239 17748 solver.cpp:218] Iteration 114500 (13.0897 iter/s, 7.63957s/100 iters), loss = 0.233577
I1211 17:32:02.939239 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:32:02.939239 17748 solver.cpp:237]     Train net output #1: loss = 0.233577 (* 1 = 0.233577 loss)
I1211 17:32:02.939239 17748 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1211 17:32:09.140079 17748 solver.cpp:218] Iteration 114600 (16.1297 iter/s, 6.19976s/100 iters), loss = 0.33925
I1211 17:32:09.140079 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:32:09.140079 17748 solver.cpp:237]     Train net output #1: loss = 0.339249 (* 1 = 0.339249 loss)
I1211 17:32:09.140079 17748 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1211 17:32:15.340553 17748 solver.cpp:218] Iteration 114700 (16.1273 iter/s, 6.20068s/100 iters), loss = 0.316873
I1211 17:32:15.340553 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:32:15.340553 17748 solver.cpp:237]     Train net output #1: loss = 0.316873 (* 1 = 0.316873 loss)
I1211 17:32:15.340553 17748 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1211 17:32:21.542785 17748 solver.cpp:218] Iteration 114800 (16.1251 iter/s, 6.2015s/100 iters), loss = 0.356501
I1211 17:32:21.542785 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:32:21.542785 17748 solver.cpp:237]     Train net output #1: loss = 0.356501 (* 1 = 0.356501 loss)
I1211 17:32:21.542785 17748 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1211 17:32:27.734728 17748 solver.cpp:218] Iteration 114900 (16.1519 iter/s, 6.19121s/100 iters), loss = 0.421368
I1211 17:32:27.734728 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:32:27.734728 17748 solver.cpp:237]     Train net output #1: loss = 0.421367 (* 1 = 0.421367 loss)
I1211 17:32:27.734728 17748 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1211 17:32:33.640154 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:32:33.884685 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115000.caffemodel
I1211 17:32:33.904685 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115000.solverstate
I1211 17:32:33.909684 17748 solver.cpp:330] Iteration 115000, Testing net (#0)
I1211 17:32:33.909684 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:32:35.259793 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:32:35.312793 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1211 17:32:35.312793 17748 solver.cpp:397]     Test net output #1: loss = 1.27555 (* 1 = 1.27555 loss)
I1211 17:32:35.370805 17748 solver.cpp:218] Iteration 115000 (13.0951 iter/s, 7.63644s/100 iters), loss = 0.264623
I1211 17:32:35.370805 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:32:35.370805 17748 solver.cpp:237]     Train net output #1: loss = 0.264623 (* 1 = 0.264623 loss)
I1211 17:32:35.370805 17748 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1211 17:32:41.562875 17748 solver.cpp:218] Iteration 115100 (16.1516 iter/s, 6.19134s/100 iters), loss = 0.319946
I1211 17:32:41.562875 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:32:41.562875 17748 solver.cpp:237]     Train net output #1: loss = 0.319946 (* 1 = 0.319946 loss)
I1211 17:32:41.562875 17748 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1211 17:32:47.759124 17748 solver.cpp:218] Iteration 115200 (16.1415 iter/s, 6.19519s/100 iters), loss = 0.263367
I1211 17:32:47.759124 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:32:47.759124 17748 solver.cpp:237]     Train net output #1: loss = 0.263366 (* 1 = 0.263366 loss)
I1211 17:32:47.759124 17748 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1211 17:32:53.961184 17748 solver.cpp:218] Iteration 115300 (16.1246 iter/s, 6.20172s/100 iters), loss = 0.34245
I1211 17:32:53.961184 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:32:53.961184 17748 solver.cpp:237]     Train net output #1: loss = 0.34245 (* 1 = 0.34245 loss)
I1211 17:32:53.961184 17748 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1211 17:33:00.167685 17748 solver.cpp:218] Iteration 115400 (16.1136 iter/s, 6.20595s/100 iters), loss = 0.3247
I1211 17:33:00.167685 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:33:00.167685 17748 solver.cpp:237]     Train net output #1: loss = 0.324699 (* 1 = 0.324699 loss)
I1211 17:33:00.167685 17748 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1211 17:33:06.075079 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:33:06.319093 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115500.caffemodel
I1211 17:33:06.339596 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115500.solverstate
I1211 17:33:06.345096 17748 solver.cpp:330] Iteration 115500, Testing net (#0)
I1211 17:33:06.345096 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:33:07.694229 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:33:07.747733 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6742
I1211 17:33:07.747733 17748 solver.cpp:397]     Test net output #1: loss = 1.26674 (* 1 = 1.26674 loss)
I1211 17:33:07.806237 17748 solver.cpp:218] Iteration 115500 (13.0918 iter/s, 7.63836s/100 iters), loss = 0.297267
I1211 17:33:07.806237 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:33:07.806237 17748 solver.cpp:237]     Train net output #1: loss = 0.297267 (* 1 = 0.297267 loss)
I1211 17:33:07.806237 17748 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1211 17:33:14.011651 17748 solver.cpp:218] Iteration 115600 (16.1152 iter/s, 6.2053s/100 iters), loss = 0.424453
I1211 17:33:14.011651 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:33:14.011651 17748 solver.cpp:237]     Train net output #1: loss = 0.424453 (* 1 = 0.424453 loss)
I1211 17:33:14.011651 17748 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1211 17:33:20.209089 17748 solver.cpp:218] Iteration 115700 (16.1363 iter/s, 6.19722s/100 iters), loss = 0.317426
I1211 17:33:20.209089 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:33:20.209089 17748 solver.cpp:237]     Train net output #1: loss = 0.317425 (* 1 = 0.317425 loss)
I1211 17:33:20.209089 17748 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1211 17:33:26.414571 17748 solver.cpp:218] Iteration 115800 (16.1178 iter/s, 6.20433s/100 iters), loss = 0.258479
I1211 17:33:26.414571 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:33:26.414571 17748 solver.cpp:237]     Train net output #1: loss = 0.258479 (* 1 = 0.258479 loss)
I1211 17:33:26.414571 17748 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1211 17:33:32.618108 17748 solver.cpp:218] Iteration 115900 (16.1204 iter/s, 6.20331s/100 iters), loss = 0.243166
I1211 17:33:32.618108 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:33:32.618108 17748 solver.cpp:237]     Train net output #1: loss = 0.243166 (* 1 = 0.243166 loss)
I1211 17:33:32.618108 17748 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1211 17:33:38.519564 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:33:38.762584 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116000.caffemodel
I1211 17:33:38.784585 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116000.solverstate
I1211 17:33:38.789585 17748 solver.cpp:330] Iteration 116000, Testing net (#0)
I1211 17:33:38.789585 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:33:40.141181 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:33:40.193688 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1211 17:33:40.193688 17748 solver.cpp:397]     Test net output #1: loss = 1.27541 (* 1 = 1.27541 loss)
I1211 17:33:40.252694 17748 solver.cpp:218] Iteration 116000 (13.0991 iter/s, 7.63412s/100 iters), loss = 0.25069
I1211 17:33:40.252694 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:33:40.252694 17748 solver.cpp:237]     Train net output #1: loss = 0.250689 (* 1 = 0.250689 loss)
I1211 17:33:40.252694 17748 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1211 17:33:46.456125 17748 solver.cpp:218] Iteration 116100 (16.1218 iter/s, 6.20279s/100 iters), loss = 0.313107
I1211 17:33:46.456125 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:33:46.456125 17748 solver.cpp:237]     Train net output #1: loss = 0.313106 (* 1 = 0.313106 loss)
I1211 17:33:46.456125 17748 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1211 17:33:52.664566 17748 solver.cpp:218] Iteration 116200 (16.1085 iter/s, 6.20792s/100 iters), loss = 0.304617
I1211 17:33:52.664566 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:33:52.664566 17748 solver.cpp:237]     Train net output #1: loss = 0.304616 (* 1 = 0.304616 loss)
I1211 17:33:52.664566 17748 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1211 17:33:58.883013 17748 solver.cpp:218] Iteration 116300 (16.0825 iter/s, 6.21795s/100 iters), loss = 0.314457
I1211 17:33:58.883013 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:33:58.883013 17748 solver.cpp:237]     Train net output #1: loss = 0.314457 (* 1 = 0.314457 loss)
I1211 17:33:58.883013 17748 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1211 17:34:05.091502 17748 solver.cpp:218] Iteration 116400 (16.1069 iter/s, 6.20851s/100 iters), loss = 0.340463
I1211 17:34:05.091502 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:34:05.091502 17748 solver.cpp:237]     Train net output #1: loss = 0.340463 (* 1 = 0.340463 loss)
I1211 17:34:05.091502 17748 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1211 17:34:10.989889 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:34:11.234902 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116500.caffemodel
I1211 17:34:11.249905 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116500.solverstate
I1211 17:34:11.255913 17748 solver.cpp:330] Iteration 116500, Testing net (#0)
I1211 17:34:11.255913 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:34:12.604038 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:34:12.657042 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6736
I1211 17:34:12.657042 17748 solver.cpp:397]     Test net output #1: loss = 1.2812 (* 1 = 1.2812 loss)
I1211 17:34:12.716042 17748 solver.cpp:218] Iteration 116500 (13.1159 iter/s, 7.62432s/100 iters), loss = 0.199687
I1211 17:34:12.716042 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:34:12.716042 17748 solver.cpp:237]     Train net output #1: loss = 0.199686 (* 1 = 0.199686 loss)
I1211 17:34:12.716042 17748 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1211 17:34:18.937458 17748 solver.cpp:218] Iteration 116600 (16.0752 iter/s, 6.22076s/100 iters), loss = 0.347962
I1211 17:34:18.937458 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 17:34:18.937458 17748 solver.cpp:237]     Train net output #1: loss = 0.347962 (* 1 = 0.347962 loss)
I1211 17:34:18.937458 17748 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1211 17:34:25.143052 17748 solver.cpp:218] Iteration 116700 (16.117 iter/s, 6.20462s/100 iters), loss = 0.254088
I1211 17:34:25.143052 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:34:25.143052 17748 solver.cpp:237]     Train net output #1: loss = 0.254088 (* 1 = 0.254088 loss)
I1211 17:34:25.143052 17748 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1211 17:34:31.341994 17748 solver.cpp:218] Iteration 116800 (16.1331 iter/s, 6.19843s/100 iters), loss = 0.366344
I1211 17:34:31.341994 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:34:31.341994 17748 solver.cpp:237]     Train net output #1: loss = 0.366344 (* 1 = 0.366344 loss)
I1211 17:34:31.341994 17748 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1211 17:34:37.546983 17748 solver.cpp:218] Iteration 116900 (16.1174 iter/s, 6.20449s/100 iters), loss = 0.336157
I1211 17:34:37.546983 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:34:37.546983 17748 solver.cpp:237]     Train net output #1: loss = 0.336156 (* 1 = 0.336156 loss)
I1211 17:34:37.546983 17748 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1211 17:34:43.451949 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:34:43.696462 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117000.caffemodel
I1211 17:34:43.717461 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117000.solverstate
I1211 17:34:43.722462 17748 solver.cpp:330] Iteration 117000, Testing net (#0)
I1211 17:34:43.722462 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:34:45.072583 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:34:45.124584 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6713
I1211 17:34:45.125583 17748 solver.cpp:397]     Test net output #1: loss = 1.28696 (* 1 = 1.28696 loss)
I1211 17:34:45.185596 17748 solver.cpp:218] Iteration 117000 (13.0926 iter/s, 7.63793s/100 iters), loss = 0.227162
I1211 17:34:45.185596 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:34:45.185596 17748 solver.cpp:237]     Train net output #1: loss = 0.227162 (* 1 = 0.227162 loss)
I1211 17:34:45.185596 17748 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1211 17:34:51.371075 17748 solver.cpp:218] Iteration 117100 (16.1677 iter/s, 6.18516s/100 iters), loss = 0.310759
I1211 17:34:51.371075 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 17:34:51.371075 17748 solver.cpp:237]     Train net output #1: loss = 0.310758 (* 1 = 0.310758 loss)
I1211 17:34:51.371075 17748 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1211 17:34:57.572504 17748 solver.cpp:218] Iteration 117200 (16.1259 iter/s, 6.2012s/100 iters), loss = 0.33993
I1211 17:34:57.572504 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:34:57.572504 17748 solver.cpp:237]     Train net output #1: loss = 0.33993 (* 1 = 0.33993 loss)
I1211 17:34:57.572504 17748 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1211 17:35:03.766937 17748 solver.cpp:218] Iteration 117300 (16.1451 iter/s, 6.19384s/100 iters), loss = 0.346173
I1211 17:35:03.766937 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:35:03.766937 17748 solver.cpp:237]     Train net output #1: loss = 0.346173 (* 1 = 0.346173 loss)
I1211 17:35:03.766937 17748 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1211 17:35:09.964380 17748 solver.cpp:218] Iteration 117400 (16.1353 iter/s, 6.19759s/100 iters), loss = 0.35083
I1211 17:35:09.964380 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:35:09.964380 17748 solver.cpp:237]     Train net output #1: loss = 0.35083 (* 1 = 0.35083 loss)
I1211 17:35:09.964380 17748 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1211 17:35:15.864079 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:35:16.109091 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117500.caffemodel
I1211 17:35:16.125089 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117500.solverstate
I1211 17:35:16.130093 17748 solver.cpp:330] Iteration 117500, Testing net (#0)
I1211 17:35:16.130093 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:35:17.481305 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:35:17.535305 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1211 17:35:17.535305 17748 solver.cpp:397]     Test net output #1: loss = 1.2806 (* 1 = 1.2806 loss)
I1211 17:35:17.594326 17748 solver.cpp:218] Iteration 117500 (13.1083 iter/s, 7.62875s/100 iters), loss = 0.200192
I1211 17:35:17.594326 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:35:17.594326 17748 solver.cpp:237]     Train net output #1: loss = 0.200192 (* 1 = 0.200192 loss)
I1211 17:35:17.594326 17748 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1211 17:35:23.795861 17748 solver.cpp:218] Iteration 117600 (16.1254 iter/s, 6.20139s/100 iters), loss = 0.30822
I1211 17:35:23.795861 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:35:23.795861 17748 solver.cpp:237]     Train net output #1: loss = 0.30822 (* 1 = 0.30822 loss)
I1211 17:35:23.795861 17748 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1211 17:35:29.992543 17748 solver.cpp:218] Iteration 117700 (16.1406 iter/s, 6.19556s/100 iters), loss = 0.237036
I1211 17:35:29.992543 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:35:29.992543 17748 solver.cpp:237]     Train net output #1: loss = 0.237036 (* 1 = 0.237036 loss)
I1211 17:35:29.992543 17748 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1211 17:35:36.193120 17748 solver.cpp:218] Iteration 117800 (16.1286 iter/s, 6.20018s/100 iters), loss = 0.300738
I1211 17:35:36.193120 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:35:36.193120 17748 solver.cpp:237]     Train net output #1: loss = 0.300738 (* 1 = 0.300738 loss)
I1211 17:35:36.193120 17748 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1211 17:35:42.401489 17748 solver.cpp:218] Iteration 117900 (16.1072 iter/s, 6.20842s/100 iters), loss = 0.383236
I1211 17:35:42.401489 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 17:35:42.401489 17748 solver.cpp:237]     Train net output #1: loss = 0.383236 (* 1 = 0.383236 loss)
I1211 17:35:42.401489 17748 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1211 17:35:48.301928 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:35:48.545940 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118000.caffemodel
I1211 17:35:48.565948 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118000.solverstate
I1211 17:35:48.570947 17748 solver.cpp:330] Iteration 118000, Testing net (#0)
I1211 17:35:48.570947 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:35:49.924041 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:35:49.976049 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6753
I1211 17:35:49.976049 17748 solver.cpp:397]     Test net output #1: loss = 1.27132 (* 1 = 1.27132 loss)
I1211 17:35:50.035048 17748 solver.cpp:218] Iteration 118000 (13.1017 iter/s, 7.63258s/100 iters), loss = 0.260671
I1211 17:35:50.035048 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:35:50.035048 17748 solver.cpp:237]     Train net output #1: loss = 0.26067 (* 1 = 0.26067 loss)
I1211 17:35:50.035048 17748 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1211 17:35:56.242481 17748 solver.cpp:218] Iteration 118100 (16.1086 iter/s, 6.20787s/100 iters), loss = 0.247791
I1211 17:35:56.243482 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:35:56.243482 17748 solver.cpp:237]     Train net output #1: loss = 0.247791 (* 1 = 0.247791 loss)
I1211 17:35:56.243482 17748 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1211 17:36:02.438906 17748 solver.cpp:218] Iteration 118200 (16.1398 iter/s, 6.19586s/100 iters), loss = 0.303248
I1211 17:36:02.438906 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:36:02.438906 17748 solver.cpp:237]     Train net output #1: loss = 0.303248 (* 1 = 0.303248 loss)
I1211 17:36:02.438906 17748 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1211 17:36:08.685443 17748 solver.cpp:218] Iteration 118300 (16.0116 iter/s, 6.24549s/100 iters), loss = 0.296172
I1211 17:36:08.685443 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:36:08.685443 17748 solver.cpp:237]     Train net output #1: loss = 0.296172 (* 1 = 0.296172 loss)
I1211 17:36:08.685443 17748 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1211 17:36:14.857105 17748 solver.cpp:218] Iteration 118400 (16.2048 iter/s, 6.17101s/100 iters), loss = 0.383799
I1211 17:36:14.857105 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:36:14.857105 17748 solver.cpp:237]     Train net output #1: loss = 0.383799 (* 1 = 0.383799 loss)
I1211 17:36:14.857105 17748 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1211 17:36:20.738448 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:36:20.983465 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118500.caffemodel
I1211 17:36:20.999465 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118500.solverstate
I1211 17:36:21.004464 17748 solver.cpp:330] Iteration 118500, Testing net (#0)
I1211 17:36:21.004464 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:36:22.353073 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:36:22.406579 17748 solver.cpp:397]     Test net output #0: accuracy = 0.675
I1211 17:36:22.406579 17748 solver.cpp:397]     Test net output #1: loss = 1.28581 (* 1 = 1.28581 loss)
I1211 17:36:22.464581 17748 solver.cpp:218] Iteration 118500 (13.1443 iter/s, 7.60783s/100 iters), loss = 0.290228
I1211 17:36:22.464581 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:36:22.464581 17748 solver.cpp:237]     Train net output #1: loss = 0.290228 (* 1 = 0.290228 loss)
I1211 17:36:22.465584 17748 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1211 17:36:28.641013 17748 solver.cpp:218] Iteration 118600 (16.1938 iter/s, 6.17521s/100 iters), loss = 0.26199
I1211 17:36:28.641013 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:36:28.641013 17748 solver.cpp:237]     Train net output #1: loss = 0.26199 (* 1 = 0.26199 loss)
I1211 17:36:28.641013 17748 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1211 17:36:34.818480 17748 solver.cpp:218] Iteration 118700 (16.187 iter/s, 6.17778s/100 iters), loss = 0.256931
I1211 17:36:34.818480 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:36:34.818480 17748 solver.cpp:237]     Train net output #1: loss = 0.256931 (* 1 = 0.256931 loss)
I1211 17:36:34.818480 17748 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1211 17:36:41.005934 17748 solver.cpp:218] Iteration 118800 (16.1635 iter/s, 6.1868s/100 iters), loss = 0.309895
I1211 17:36:41.005934 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:36:41.005934 17748 solver.cpp:237]     Train net output #1: loss = 0.309895 (* 1 = 0.309895 loss)
I1211 17:36:41.005934 17748 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1211 17:36:47.196403 17748 solver.cpp:218] Iteration 118900 (16.1555 iter/s, 6.18985s/100 iters), loss = 0.322913
I1211 17:36:47.196403 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:36:47.196403 17748 solver.cpp:237]     Train net output #1: loss = 0.322913 (* 1 = 0.322913 loss)
I1211 17:36:47.196403 17748 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1211 17:36:53.076831 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:36:53.320844 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119000.caffemodel
I1211 17:36:53.341845 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119000.solverstate
I1211 17:36:53.347844 17748 solver.cpp:330] Iteration 119000, Testing net (#0)
I1211 17:36:53.347844 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:36:54.694933 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:36:54.747932 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1211 17:36:54.747932 17748 solver.cpp:397]     Test net output #1: loss = 1.28241 (* 1 = 1.28241 loss)
I1211 17:36:54.807941 17748 solver.cpp:218] Iteration 119000 (13.1396 iter/s, 7.61056s/100 iters), loss = 0.232171
I1211 17:36:54.807941 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:36:54.807941 17748 solver.cpp:237]     Train net output #1: loss = 0.23217 (* 1 = 0.23217 loss)
I1211 17:36:54.807941 17748 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1211 17:37:00.988400 17748 solver.cpp:218] Iteration 119100 (16.1799 iter/s, 6.18051s/100 iters), loss = 0.23851
I1211 17:37:00.988400 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:37:00.988400 17748 solver.cpp:237]     Train net output #1: loss = 0.23851 (* 1 = 0.23851 loss)
I1211 17:37:00.988400 17748 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1211 17:37:07.185868 17748 solver.cpp:218] Iteration 119200 (16.138 iter/s, 6.19655s/100 iters), loss = 0.234674
I1211 17:37:07.185868 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:37:07.185868 17748 solver.cpp:237]     Train net output #1: loss = 0.234674 (* 1 = 0.234674 loss)
I1211 17:37:07.185868 17748 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1211 17:37:13.372331 17748 solver.cpp:218] Iteration 119300 (16.1635 iter/s, 6.18677s/100 iters), loss = 0.23518
I1211 17:37:13.372331 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:37:13.372331 17748 solver.cpp:237]     Train net output #1: loss = 0.235179 (* 1 = 0.235179 loss)
I1211 17:37:13.372331 17748 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1211 17:37:19.552314 17748 solver.cpp:218] Iteration 119400 (16.1839 iter/s, 6.17899s/100 iters), loss = 0.318567
I1211 17:37:19.552314 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:37:19.552314 17748 solver.cpp:237]     Train net output #1: loss = 0.318567 (* 1 = 0.318567 loss)
I1211 17:37:19.552314 17748 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1211 17:37:25.439602 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:37:25.684617 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119500.caffemodel
I1211 17:37:25.705616 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119500.solverstate
I1211 17:37:25.710618 17748 solver.cpp:330] Iteration 119500, Testing net (#0)
I1211 17:37:25.710618 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:37:27.057232 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:37:27.109736 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1211 17:37:27.109736 17748 solver.cpp:397]     Test net output #1: loss = 1.28699 (* 1 = 1.28699 loss)
I1211 17:37:27.168740 17748 solver.cpp:218] Iteration 119500 (13.1306 iter/s, 7.61579s/100 iters), loss = 0.265519
I1211 17:37:27.168740 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:37:27.168740 17748 solver.cpp:237]     Train net output #1: loss = 0.265518 (* 1 = 0.265518 loss)
I1211 17:37:27.168740 17748 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1211 17:37:33.363145 17748 solver.cpp:218] Iteration 119600 (16.143 iter/s, 6.19464s/100 iters), loss = 0.293549
I1211 17:37:33.363145 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:37:33.364146 17748 solver.cpp:237]     Train net output #1: loss = 0.293549 (* 1 = 0.293549 loss)
I1211 17:37:33.364146 17748 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1211 17:37:39.553614 17748 solver.cpp:218] Iteration 119700 (16.1575 iter/s, 6.18908s/100 iters), loss = 0.301132
I1211 17:37:39.553614 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:37:39.553614 17748 solver.cpp:237]     Train net output #1: loss = 0.301132 (* 1 = 0.301132 loss)
I1211 17:37:39.553614 17748 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1211 17:37:45.737038 17748 solver.cpp:218] Iteration 119800 (16.173 iter/s, 6.18316s/100 iters), loss = 0.309099
I1211 17:37:45.737038 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:37:45.737038 17748 solver.cpp:237]     Train net output #1: loss = 0.309098 (* 1 = 0.309098 loss)
I1211 17:37:45.737038 17748 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1211 17:37:51.918992 17748 solver.cpp:218] Iteration 119900 (16.1775 iter/s, 6.18144s/100 iters), loss = 0.317111
I1211 17:37:51.918992 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:37:51.918992 17748 solver.cpp:237]     Train net output #1: loss = 0.317111 (* 1 = 0.317111 loss)
I1211 17:37:51.918992 17748 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1211 17:37:57.806924 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:37:58.049953 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120000.caffemodel
I1211 17:37:58.066948 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120000.solverstate
I1211 17:37:58.071947 17748 solver.cpp:330] Iteration 120000, Testing net (#0)
I1211 17:37:58.071947 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:37:59.420562 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:37:59.473076 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6742
I1211 17:37:59.473076 17748 solver.cpp:397]     Test net output #1: loss = 1.29942 (* 1 = 1.29942 loss)
I1211 17:37:59.533071 17748 solver.cpp:218] Iteration 120000 (13.1346 iter/s, 7.61348s/100 iters), loss = 0.210487
I1211 17:37:59.533071 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 17:37:59.533071 17748 solver.cpp:237]     Train net output #1: loss = 0.210487 (* 1 = 0.210487 loss)
I1211 17:37:59.533071 17748 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1211 17:38:05.723505 17748 solver.cpp:218] Iteration 120100 (16.1551 iter/s, 6.19s/100 iters), loss = 0.313869
I1211 17:38:05.723505 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:38:05.723505 17748 solver.cpp:237]     Train net output #1: loss = 0.313869 (* 1 = 0.313869 loss)
I1211 17:38:05.723505 17748 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1211 17:38:11.908931 17748 solver.cpp:218] Iteration 120200 (16.1687 iter/s, 6.18478s/100 iters), loss = 0.281342
I1211 17:38:11.908931 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:38:11.908931 17748 solver.cpp:237]     Train net output #1: loss = 0.281342 (* 1 = 0.281342 loss)
I1211 17:38:11.908931 17748 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1211 17:38:18.092314 17748 solver.cpp:218] Iteration 120300 (16.1739 iter/s, 6.18281s/100 iters), loss = 0.287829
I1211 17:38:18.092314 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:38:18.092314 17748 solver.cpp:237]     Train net output #1: loss = 0.287828 (* 1 = 0.287828 loss)
I1211 17:38:18.092314 17748 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1211 17:38:24.274770 17748 solver.cpp:218] Iteration 120400 (16.1741 iter/s, 6.18271s/100 iters), loss = 0.341824
I1211 17:38:24.274770 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:38:24.274770 17748 solver.cpp:237]     Train net output #1: loss = 0.341824 (* 1 = 0.341824 loss)
I1211 17:38:24.274770 17748 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1211 17:38:30.157135 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:38:30.400147 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120500.caffemodel
I1211 17:38:30.420650 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120500.solverstate
I1211 17:38:30.425652 17748 solver.cpp:330] Iteration 120500, Testing net (#0)
I1211 17:38:30.425652 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:38:31.774237 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:38:31.827739 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6717
I1211 17:38:31.827739 17748 solver.cpp:397]     Test net output #1: loss = 1.28997 (* 1 = 1.28997 loss)
I1211 17:38:31.886240 17748 solver.cpp:218] Iteration 120500 (13.1386 iter/s, 7.61115s/100 iters), loss = 0.186856
I1211 17:38:31.886240 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:38:31.886240 17748 solver.cpp:237]     Train net output #1: loss = 0.186856 (* 1 = 0.186856 loss)
I1211 17:38:31.886240 17748 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1211 17:38:38.059675 17748 solver.cpp:218] Iteration 120600 (16.2013 iter/s, 6.17236s/100 iters), loss = 0.317793
I1211 17:38:38.059675 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:38:38.059675 17748 solver.cpp:237]     Train net output #1: loss = 0.317792 (* 1 = 0.317792 loss)
I1211 17:38:38.059675 17748 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1211 17:38:44.251067 17748 solver.cpp:218] Iteration 120700 (16.1517 iter/s, 6.19132s/100 iters), loss = 0.220257
I1211 17:38:44.251067 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:38:44.251067 17748 solver.cpp:237]     Train net output #1: loss = 0.220256 (* 1 = 0.220256 loss)
I1211 17:38:44.251067 17748 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1211 17:38:50.437515 17748 solver.cpp:218] Iteration 120800 (16.167 iter/s, 6.18543s/100 iters), loss = 0.363936
I1211 17:38:50.437515 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:38:50.437515 17748 solver.cpp:237]     Train net output #1: loss = 0.363935 (* 1 = 0.363935 loss)
I1211 17:38:50.437515 17748 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1211 17:38:56.628428 17748 solver.cpp:218] Iteration 120900 (16.1532 iter/s, 6.19074s/100 iters), loss = 0.307335
I1211 17:38:56.628428 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:38:56.628428 17748 solver.cpp:237]     Train net output #1: loss = 0.307334 (* 1 = 0.307334 loss)
I1211 17:38:56.628428 17748 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1211 17:39:02.508330 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:39:02.752344 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121000.caffemodel
I1211 17:39:02.770344 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121000.solverstate
I1211 17:39:02.775344 17748 solver.cpp:330] Iteration 121000, Testing net (#0)
I1211 17:39:02.775344 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:39:04.122431 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:39:04.175433 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1211 17:39:04.175433 17748 solver.cpp:397]     Test net output #1: loss = 1.30039 (* 1 = 1.30039 loss)
I1211 17:39:04.234941 17748 solver.cpp:218] Iteration 121000 (13.1478 iter/s, 7.60582s/100 iters), loss = 0.198883
I1211 17:39:04.234941 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:39:04.234941 17748 solver.cpp:237]     Train net output #1: loss = 0.198882 (* 1 = 0.198882 loss)
I1211 17:39:04.234941 17748 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1211 17:39:10.432904 17748 solver.cpp:218] Iteration 121100 (16.1363 iter/s, 6.19721s/100 iters), loss = 0.295856
I1211 17:39:10.432904 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 17:39:10.432904 17748 solver.cpp:237]     Train net output #1: loss = 0.295856 (* 1 = 0.295856 loss)
I1211 17:39:10.432904 17748 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1211 17:39:16.620343 17748 solver.cpp:218] Iteration 121200 (16.1627 iter/s, 6.18707s/100 iters), loss = 0.218516
I1211 17:39:16.620343 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:39:16.620343 17748 solver.cpp:237]     Train net output #1: loss = 0.218515 (* 1 = 0.218515 loss)
I1211 17:39:16.620343 17748 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1211 17:39:22.807811 17748 solver.cpp:218] Iteration 121300 (16.1612 iter/s, 6.18766s/100 iters), loss = 0.250317
I1211 17:39:22.807811 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:39:22.807811 17748 solver.cpp:237]     Train net output #1: loss = 0.250317 (* 1 = 0.250317 loss)
I1211 17:39:22.807811 17748 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1211 17:39:28.988322 17748 solver.cpp:218] Iteration 121400 (16.1805 iter/s, 6.18028s/100 iters), loss = 0.339293
I1211 17:39:28.988322 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:39:28.988322 17748 solver.cpp:237]     Train net output #1: loss = 0.339293 (* 1 = 0.339293 loss)
I1211 17:39:28.988322 17748 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1211 17:39:34.879727 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:39:35.124243 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121500.caffemodel
I1211 17:39:35.144748 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121500.solverstate
I1211 17:39:35.150748 17748 solver.cpp:330] Iteration 121500, Testing net (#0)
I1211 17:39:35.150748 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:39:36.496865 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:39:36.549873 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6731
I1211 17:39:36.549873 17748 solver.cpp:397]     Test net output #1: loss = 1.29651 (* 1 = 1.29651 loss)
I1211 17:39:36.608872 17748 solver.cpp:218] Iteration 121500 (13.1239 iter/s, 7.61971s/100 iters), loss = 0.301676
I1211 17:39:36.608872 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:39:36.608872 17748 solver.cpp:237]     Train net output #1: loss = 0.301675 (* 1 = 0.301675 loss)
I1211 17:39:36.608872 17748 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1211 17:39:42.798351 17748 solver.cpp:218] Iteration 121600 (16.1587 iter/s, 6.18863s/100 iters), loss = 0.287742
I1211 17:39:42.798351 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:39:42.798351 17748 solver.cpp:237]     Train net output #1: loss = 0.287742 (* 1 = 0.287742 loss)
I1211 17:39:42.798351 17748 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1211 17:39:48.988742 17748 solver.cpp:218] Iteration 121700 (16.1553 iter/s, 6.18991s/100 iters), loss = 0.281349
I1211 17:39:48.988742 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:39:48.988742 17748 solver.cpp:237]     Train net output #1: loss = 0.281348 (* 1 = 0.281348 loss)
I1211 17:39:48.988742 17748 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1211 17:39:55.174162 17748 solver.cpp:218] Iteration 121800 (16.1661 iter/s, 6.18579s/100 iters), loss = 0.272391
I1211 17:39:55.174162 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:39:55.174162 17748 solver.cpp:237]     Train net output #1: loss = 0.272391 (* 1 = 0.272391 loss)
I1211 17:39:55.174162 17748 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1211 17:40:01.359601 17748 solver.cpp:218] Iteration 121900 (16.1683 iter/s, 6.18493s/100 iters), loss = 0.348837
I1211 17:40:01.359601 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 17:40:01.359601 17748 solver.cpp:237]     Train net output #1: loss = 0.348837 (* 1 = 0.348837 loss)
I1211 17:40:01.359601 17748 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1211 17:40:07.237031 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:40:07.481043 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122000.caffemodel
I1211 17:40:07.499043 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122000.solverstate
I1211 17:40:07.504042 17748 solver.cpp:330] Iteration 122000, Testing net (#0)
I1211 17:40:07.504042 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:40:08.851171 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:40:08.904170 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6749
I1211 17:40:08.904170 17748 solver.cpp:397]     Test net output #1: loss = 1.29469 (* 1 = 1.29469 loss)
I1211 17:40:08.964177 17748 solver.cpp:218] Iteration 122000 (13.1519 iter/s, 7.60345s/100 iters), loss = 0.228696
I1211 17:40:08.964177 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:40:08.964177 17748 solver.cpp:237]     Train net output #1: loss = 0.228696 (* 1 = 0.228696 loss)
I1211 17:40:08.964177 17748 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1211 17:40:15.149616 17748 solver.cpp:218] Iteration 122100 (16.1679 iter/s, 6.18509s/100 iters), loss = 0.328501
I1211 17:40:15.149616 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:40:15.149616 17748 solver.cpp:237]     Train net output #1: loss = 0.328501 (* 1 = 0.328501 loss)
I1211 17:40:15.149616 17748 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1211 17:40:21.334563 17748 solver.cpp:218] Iteration 122200 (16.169 iter/s, 6.18466s/100 iters), loss = 0.27835
I1211 17:40:21.335063 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:40:21.335063 17748 solver.cpp:237]     Train net output #1: loss = 0.278349 (* 1 = 0.278349 loss)
I1211 17:40:21.335063 17748 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1211 17:40:27.521507 17748 solver.cpp:218] Iteration 122300 (16.1637 iter/s, 6.18668s/100 iters), loss = 0.288186
I1211 17:40:27.521507 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:40:27.521507 17748 solver.cpp:237]     Train net output #1: loss = 0.288186 (* 1 = 0.288186 loss)
I1211 17:40:27.521507 17748 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1211 17:40:33.708000 17748 solver.cpp:218] Iteration 122400 (16.1671 iter/s, 6.18542s/100 iters), loss = 0.298794
I1211 17:40:33.708000 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:40:33.708000 17748 solver.cpp:237]     Train net output #1: loss = 0.298794 (* 1 = 0.298794 loss)
I1211 17:40:33.708000 17748 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1211 17:40:39.595198 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:40:39.839217 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122500.caffemodel
I1211 17:40:39.855216 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122500.solverstate
I1211 17:40:39.860216 17748 solver.cpp:330] Iteration 122500, Testing net (#0)
I1211 17:40:39.860216 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:40:41.207309 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:40:41.260311 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1211 17:40:41.260311 17748 solver.cpp:397]     Test net output #1: loss = 1.29385 (* 1 = 1.29385 loss)
I1211 17:40:41.320317 17748 solver.cpp:218] Iteration 122500 (13.1364 iter/s, 7.61241s/100 iters), loss = 0.19315
I1211 17:40:41.320317 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:40:41.320317 17748 solver.cpp:237]     Train net output #1: loss = 0.19315 (* 1 = 0.19315 loss)
I1211 17:40:41.320317 17748 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1211 17:40:47.510279 17748 solver.cpp:218] Iteration 122600 (16.1575 iter/s, 6.18909s/100 iters), loss = 0.24337
I1211 17:40:47.510279 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 17:40:47.510279 17748 solver.cpp:237]     Train net output #1: loss = 0.24337 (* 1 = 0.24337 loss)
I1211 17:40:47.510279 17748 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1211 17:40:53.692284 17748 solver.cpp:218] Iteration 122700 (16.1773 iter/s, 6.18152s/100 iters), loss = 0.297195
I1211 17:40:53.692284 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:40:53.692284 17748 solver.cpp:237]     Train net output #1: loss = 0.297195 (* 1 = 0.297195 loss)
I1211 17:40:53.692284 17748 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1211 17:40:59.877570 17748 solver.cpp:218] Iteration 122800 (16.1687 iter/s, 6.18479s/100 iters), loss = 0.215978
I1211 17:40:59.877570 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:40:59.877570 17748 solver.cpp:237]     Train net output #1: loss = 0.215978 (* 1 = 0.215978 loss)
I1211 17:40:59.877570 17748 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1211 17:41:06.061125 17748 solver.cpp:218] Iteration 122900 (16.172 iter/s, 6.18355s/100 iters), loss = 0.316933
I1211 17:41:06.061125 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:41:06.061125 17748 solver.cpp:237]     Train net output #1: loss = 0.316933 (* 1 = 0.316933 loss)
I1211 17:41:06.061125 17748 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1211 17:41:11.932514 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:41:12.174527 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123000.caffemodel
I1211 17:41:12.194527 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123000.solverstate
I1211 17:41:12.199527 17748 solver.cpp:330] Iteration 123000, Testing net (#0)
I1211 17:41:12.200528 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:41:13.549641 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:41:13.603145 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6707
I1211 17:41:13.603145 17748 solver.cpp:397]     Test net output #1: loss = 1.31368 (* 1 = 1.31368 loss)
I1211 17:41:13.661646 17748 solver.cpp:218] Iteration 123000 (13.1578 iter/s, 7.60005s/100 iters), loss = 0.210102
I1211 17:41:13.661646 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:41:13.661646 17748 solver.cpp:237]     Train net output #1: loss = 0.210102 (* 1 = 0.210102 loss)
I1211 17:41:13.661646 17748 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1211 17:41:19.840046 17748 solver.cpp:218] Iteration 123100 (16.1867 iter/s, 6.17793s/100 iters), loss = 0.188556
I1211 17:41:19.840046 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 17:41:19.840046 17748 solver.cpp:237]     Train net output #1: loss = 0.188556 (* 1 = 0.188556 loss)
I1211 17:41:19.840046 17748 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1211 17:41:26.035459 17748 solver.cpp:218] Iteration 123200 (16.1428 iter/s, 6.1947s/100 iters), loss = 0.218751
I1211 17:41:26.035459 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:41:26.035459 17748 solver.cpp:237]     Train net output #1: loss = 0.21875 (* 1 = 0.21875 loss)
I1211 17:41:26.035459 17748 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1211 17:41:32.224915 17748 solver.cpp:218] Iteration 123300 (16.1566 iter/s, 6.18943s/100 iters), loss = 0.329724
I1211 17:41:32.224915 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:41:32.224915 17748 solver.cpp:237]     Train net output #1: loss = 0.329723 (* 1 = 0.329723 loss)
I1211 17:41:32.224915 17748 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1211 17:41:38.416895 17748 solver.cpp:218] Iteration 123400 (16.1527 iter/s, 6.19092s/100 iters), loss = 0.293533
I1211 17:41:38.416895 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:41:38.416895 17748 solver.cpp:237]     Train net output #1: loss = 0.293533 (* 1 = 0.293533 loss)
I1211 17:41:38.416895 17748 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1211 17:41:44.296789 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:41:44.540837 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123500.caffemodel
I1211 17:41:44.557837 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123500.solverstate
I1211 17:41:44.562839 17748 solver.cpp:330] Iteration 123500, Testing net (#0)
I1211 17:41:44.562839 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:41:45.909440 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:41:45.961951 17748 solver.cpp:397]     Test net output #0: accuracy = 0.671
I1211 17:41:45.961951 17748 solver.cpp:397]     Test net output #1: loss = 1.30396 (* 1 = 1.30396 loss)
I1211 17:41:46.019949 17748 solver.cpp:218] Iteration 123500 (13.1521 iter/s, 7.60335s/100 iters), loss = 0.226922
I1211 17:41:46.019949 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:41:46.020951 17748 solver.cpp:237]     Train net output #1: loss = 0.226921 (* 1 = 0.226921 loss)
I1211 17:41:46.020951 17748 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1211 17:41:52.208422 17748 solver.cpp:218] Iteration 123600 (16.1627 iter/s, 6.18709s/100 iters), loss = 0.281051
I1211 17:41:52.208422 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:41:52.208422 17748 solver.cpp:237]     Train net output #1: loss = 0.281051 (* 1 = 0.281051 loss)
I1211 17:41:52.208422 17748 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1211 17:41:58.393908 17748 solver.cpp:218] Iteration 123700 (16.1667 iter/s, 6.18557s/100 iters), loss = 0.20594
I1211 17:41:58.393908 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:41:58.393908 17748 solver.cpp:237]     Train net output #1: loss = 0.205939 (* 1 = 0.205939 loss)
I1211 17:41:58.393908 17748 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1211 17:42:04.577911 17748 solver.cpp:218] Iteration 123800 (16.1716 iter/s, 6.18367s/100 iters), loss = 0.262125
I1211 17:42:04.577911 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:42:04.577911 17748 solver.cpp:237]     Train net output #1: loss = 0.262125 (* 1 = 0.262125 loss)
I1211 17:42:04.577911 17748 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1211 17:42:10.761663 17748 solver.cpp:218] Iteration 123900 (16.1737 iter/s, 6.18289s/100 iters), loss = 0.305699
I1211 17:42:10.761663 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:42:10.761663 17748 solver.cpp:237]     Train net output #1: loss = 0.305699 (* 1 = 0.305699 loss)
I1211 17:42:10.761663 17748 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1211 17:42:16.640166 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:42:16.882179 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124000.caffemodel
I1211 17:42:16.903177 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124000.solverstate
I1211 17:42:16.908180 17748 solver.cpp:330] Iteration 124000, Testing net (#0)
I1211 17:42:16.908180 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:42:18.255286 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:42:18.308287 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6707
I1211 17:42:18.308287 17748 solver.cpp:397]     Test net output #1: loss = 1.30105 (* 1 = 1.30105 loss)
I1211 17:42:18.367296 17748 solver.cpp:218] Iteration 124000 (13.1483 iter/s, 7.60557s/100 iters), loss = 0.189437
I1211 17:42:18.367296 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 17:42:18.367296 17748 solver.cpp:237]     Train net output #1: loss = 0.189437 (* 1 = 0.189437 loss)
I1211 17:42:18.367296 17748 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1211 17:42:24.561779 17748 solver.cpp:218] Iteration 124100 (16.1462 iter/s, 6.19342s/100 iters), loss = 0.262674
I1211 17:42:24.561779 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 17:42:24.561779 17748 solver.cpp:237]     Train net output #1: loss = 0.262674 (* 1 = 0.262674 loss)
I1211 17:42:24.561779 17748 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1211 17:42:30.749186 17748 solver.cpp:218] Iteration 124200 (16.1624 iter/s, 6.18719s/100 iters), loss = 0.248459
I1211 17:42:30.749186 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:42:30.749186 17748 solver.cpp:237]     Train net output #1: loss = 0.248458 (* 1 = 0.248458 loss)
I1211 17:42:30.749186 17748 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1211 17:42:36.935624 17748 solver.cpp:218] Iteration 124300 (16.1651 iter/s, 6.18618s/100 iters), loss = 0.319648
I1211 17:42:36.935624 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:42:36.935624 17748 solver.cpp:237]     Train net output #1: loss = 0.319648 (* 1 = 0.319648 loss)
I1211 17:42:36.935624 17748 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1211 17:42:43.126135 17748 solver.cpp:218] Iteration 124400 (16.1562 iter/s, 6.18956s/100 iters), loss = 0.327781
I1211 17:42:43.126135 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 17:42:43.126135 17748 solver.cpp:237]     Train net output #1: loss = 0.327781 (* 1 = 0.327781 loss)
I1211 17:42:43.126135 17748 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1211 17:42:48.998523 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:42:49.240542 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124500.caffemodel
I1211 17:42:49.260541 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124500.solverstate
I1211 17:42:49.265542 17748 solver.cpp:330] Iteration 124500, Testing net (#0)
I1211 17:42:49.265542 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:42:50.615140 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:42:50.666645 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6717
I1211 17:42:50.666645 17748 solver.cpp:397]     Test net output #1: loss = 1.32194 (* 1 = 1.32194 loss)
I1211 17:42:50.725147 17748 solver.cpp:218] Iteration 124500 (13.1602 iter/s, 7.59869s/100 iters), loss = 0.257648
I1211 17:42:50.725147 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:42:50.725147 17748 solver.cpp:237]     Train net output #1: loss = 0.257647 (* 1 = 0.257647 loss)
I1211 17:42:50.725147 17748 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1211 17:42:56.912607 17748 solver.cpp:218] Iteration 124600 (16.1627 iter/s, 6.18707s/100 iters), loss = 0.261524
I1211 17:42:56.912607 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:42:56.912607 17748 solver.cpp:237]     Train net output #1: loss = 0.261524 (* 1 = 0.261524 loss)
I1211 17:42:56.912607 17748 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1211 17:43:03.126544 17748 solver.cpp:218] Iteration 124700 (16.0938 iter/s, 6.21356s/100 iters), loss = 0.216651
I1211 17:43:03.126544 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 17:43:03.126544 17748 solver.cpp:237]     Train net output #1: loss = 0.216651 (* 1 = 0.216651 loss)
I1211 17:43:03.127048 17748 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1211 17:43:09.329005 17748 solver.cpp:218] Iteration 124800 (16.1246 iter/s, 6.2017s/100 iters), loss = 0.298184
I1211 17:43:09.329005 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 17:43:09.329005 17748 solver.cpp:237]     Train net output #1: loss = 0.298184 (* 1 = 0.298184 loss)
I1211 17:43:09.329005 17748 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1211 17:43:15.506577 17748 solver.cpp:218] Iteration 124900 (16.1886 iter/s, 6.17718s/100 iters), loss = 0.246103
I1211 17:43:15.506577 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:43:15.506577 17748 solver.cpp:237]     Train net output #1: loss = 0.246103 (* 1 = 0.246103 loss)
I1211 17:43:15.506577 17748 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1211 17:43:21.397102 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:43:21.640120 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125000.caffemodel
I1211 17:43:21.657120 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125000.solverstate
I1211 17:43:21.661120 17748 solver.cpp:330] Iteration 125000, Testing net (#0)
I1211 17:43:21.661120 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:43:23.013247 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:43:23.066252 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6706
I1211 17:43:23.066252 17748 solver.cpp:397]     Test net output #1: loss = 1.31653 (* 1 = 1.31653 loss)
I1211 17:43:23.125253 17748 solver.cpp:218] Iteration 125000 (13.1266 iter/s, 7.61813s/100 iters), loss = 0.208173
I1211 17:43:23.125253 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 17:43:23.125253 17748 solver.cpp:237]     Train net output #1: loss = 0.208173 (* 1 = 0.208173 loss)
I1211 17:43:23.125253 17748 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1211 17:43:29.316776 17748 solver.cpp:218] Iteration 125100 (16.1526 iter/s, 6.19095s/100 iters), loss = 0.304177
I1211 17:43:29.316776 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:43:29.316776 17748 solver.cpp:237]     Train net output #1: loss = 0.304177 (* 1 = 0.304177 loss)
I1211 17:43:29.316776 17748 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1211 17:43:35.500263 17748 solver.cpp:218] Iteration 125200 (16.1714 iter/s, 6.18377s/100 iters), loss = 0.269958
I1211 17:43:35.500263 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:43:35.500263 17748 solver.cpp:237]     Train net output #1: loss = 0.269958 (* 1 = 0.269958 loss)
I1211 17:43:35.500263 17748 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1211 17:43:41.685696 17748 solver.cpp:218] Iteration 125300 (16.1702 iter/s, 6.18421s/100 iters), loss = 0.302554
I1211 17:43:41.685696 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 17:43:41.685696 17748 solver.cpp:237]     Train net output #1: loss = 0.302554 (* 1 = 0.302554 loss)
I1211 17:43:41.685696 17748 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1211 17:43:47.863287 17748 solver.cpp:218] Iteration 125400 (16.1865 iter/s, 6.17797s/100 iters), loss = 0.275398
I1211 17:43:47.863287 17748 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 17:43:47.863287 17748 solver.cpp:237]     Train net output #1: loss = 0.275398 (* 1 = 0.275398 loss)
I1211 17:43:47.863287 17748 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1211 17:43:53.744520 16060 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:43:53.991533 17748 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125500.caffemodel
I1211 17:43:54.011533 17748 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125500.solverstate
I1211 17:43:54.018036 17748 solver.cpp:330] Iteration 125500, Testing net (#0)
I1211 17:43:54.018036 17748 net.cpp:676] Ignoring source layer accuracy_training
I1211 17:43:55.366587 17848 data_layer.cpp:73] Restarting data prefetching from start.
I1211 17:43:55.419591 17748 solver.cpp:397]     Test net output #0: accuracy = 0.6714
I1211 17:43:55.419591 17748 solver.cpp:397]     Test net output #1: loss = 1.31584 (* 1