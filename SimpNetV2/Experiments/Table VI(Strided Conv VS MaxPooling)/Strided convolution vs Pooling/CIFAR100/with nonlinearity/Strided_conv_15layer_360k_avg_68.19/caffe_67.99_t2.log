I1211 14:11:14.662463 16720 caffe.cpp:219] Using GPUs 0
I1211 14:11:14.849601 16720 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1211 14:11:15.152823 16720 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 14:11:15.170825 16720 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1211 14:11:15.171823 16720 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 14:11:15.171823 16720 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 14:11:15.171823 16720 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 14:11:15.171823 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1211 14:11:15.171823 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_pool2_1
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_pool4_2
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1211 14:11:15.172842 16720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1211 14:11:15.172842 16720 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV2_WnonLin_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_pool2_1"
  type: "BatchNorm"
  bottom: "pool2_1"
  top: "pool2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_pool2_1"
  type: "Scale"
  bottom: "pool2_1"
  top: "pool2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_pool2_1"
  type: "ReLU"
  bottom: "pool2_1"
  top: "pool2_1"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_pool4_2"
  type: "BatchNorm"
  bottom: "pool4_2"
  top: "pool4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_pool4_2"
  type: "Scale"
  bottom: "pool4_2"
  top: "pool4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_pool4_2"
  type: "ReLU"
  bottom: "pool4_2"
  top: "pool4_2"
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 14:11:15.182822 16720 layer_factory.cpp:58] Creating layer cifar
I1211 14:11:15.185834 16720 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1211 14:11:15.186823 16720 net.cpp:84] Creating Layer cifar
I1211 14:11:15.186823 16720 net.cpp:380] cifar -> data
I1211 14:11:15.186823 16720 net.cpp:380] cifar -> label
I1211 14:11:15.187822 16720 data_layer.cpp:45] output data size: 100,3,32,32
I1211 14:11:15.193821 16720 net.cpp:122] Setting up cifar
I1211 14:11:15.193821 16720 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 14:11:15.193821 16720 net.cpp:129] Top shape: 100 (100)
I1211 14:11:15.193821 16720 net.cpp:137] Memory required for data: 1229200
I1211 14:11:15.193821 16720 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 14:11:15.193821 16720 net.cpp:84] Creating Layer label_cifar_1_split
I1211 14:11:15.193821 16720 net.cpp:406] label_cifar_1_split <- label
I1211 14:11:15.193821 16720 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 14:11:15.193821 16720 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 14:11:15.193821 16720 net.cpp:122] Setting up label_cifar_1_split
I1211 14:11:15.193821 16720 net.cpp:129] Top shape: 100 (100)
I1211 14:11:15.193821 16720 net.cpp:129] Top shape: 100 (100)
I1211 14:11:15.193821 16720 net.cpp:137] Memory required for data: 1230000
I1211 14:11:15.193821 16720 layer_factory.cpp:58] Creating layer conv1
I1211 14:11:15.193821 16720 net.cpp:84] Creating Layer conv1
I1211 14:11:15.193821 16720 net.cpp:406] conv1 <- data
I1211 14:11:15.193821 16720 net.cpp:380] conv1 -> conv1
I1211 14:11:15.194825  8040 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 14:11:15.448374 16720 net.cpp:122] Setting up conv1
I1211 14:11:15.448374 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.448374 16720 net.cpp:137] Memory required for data: 13518000
I1211 14:11:15.448374 16720 layer_factory.cpp:58] Creating layer bn1
I1211 14:11:15.448374 16720 net.cpp:84] Creating Layer bn1
I1211 14:11:15.448374 16720 net.cpp:406] bn1 <- conv1
I1211 14:11:15.448374 16720 net.cpp:367] bn1 -> conv1 (in-place)
I1211 14:11:15.448374 16720 net.cpp:122] Setting up bn1
I1211 14:11:15.448374 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.448374 16720 net.cpp:137] Memory required for data: 25806000
I1211 14:11:15.448374 16720 layer_factory.cpp:58] Creating layer scale1
I1211 14:11:15.448374 16720 net.cpp:84] Creating Layer scale1
I1211 14:11:15.448374 16720 net.cpp:406] scale1 <- conv1
I1211 14:11:15.448374 16720 net.cpp:367] scale1 -> conv1 (in-place)
I1211 14:11:15.448374 16720 layer_factory.cpp:58] Creating layer scale1
I1211 14:11:15.448374 16720 net.cpp:122] Setting up scale1
I1211 14:11:15.448374 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.448374 16720 net.cpp:137] Memory required for data: 38094000
I1211 14:11:15.448374 16720 layer_factory.cpp:58] Creating layer relu1
I1211 14:11:15.448374 16720 net.cpp:84] Creating Layer relu1
I1211 14:11:15.448374 16720 net.cpp:406] relu1 <- conv1
I1211 14:11:15.448374 16720 net.cpp:367] relu1 -> conv1 (in-place)
I1211 14:11:15.449374 16720 net.cpp:122] Setting up relu1
I1211 14:11:15.449374 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.449374 16720 net.cpp:137] Memory required for data: 50382000
I1211 14:11:15.449374 16720 layer_factory.cpp:58] Creating layer conv1_0
I1211 14:11:15.449374 16720 net.cpp:84] Creating Layer conv1_0
I1211 14:11:15.449374 16720 net.cpp:406] conv1_0 <- conv1
I1211 14:11:15.449374 16720 net.cpp:380] conv1_0 -> conv1_0
I1211 14:11:15.451375 16720 net.cpp:122] Setting up conv1_0
I1211 14:11:15.451375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.451375 16720 net.cpp:137] Memory required for data: 66766000
I1211 14:11:15.451375 16720 layer_factory.cpp:58] Creating layer bn1_0
I1211 14:11:15.451375 16720 net.cpp:84] Creating Layer bn1_0
I1211 14:11:15.451375 16720 net.cpp:406] bn1_0 <- conv1_0
I1211 14:11:15.451375 16720 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 14:11:15.451375 16720 net.cpp:122] Setting up bn1_0
I1211 14:11:15.451375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.451375 16720 net.cpp:137] Memory required for data: 83150000
I1211 14:11:15.451375 16720 layer_factory.cpp:58] Creating layer scale1_0
I1211 14:11:15.451375 16720 net.cpp:84] Creating Layer scale1_0
I1211 14:11:15.451375 16720 net.cpp:406] scale1_0 <- conv1_0
I1211 14:11:15.451375 16720 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 14:11:15.451375 16720 layer_factory.cpp:58] Creating layer scale1_0
I1211 14:11:15.451375 16720 net.cpp:122] Setting up scale1_0
I1211 14:11:15.451375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.451375 16720 net.cpp:137] Memory required for data: 99534000
I1211 14:11:15.451375 16720 layer_factory.cpp:58] Creating layer relu1_0
I1211 14:11:15.451375 16720 net.cpp:84] Creating Layer relu1_0
I1211 14:11:15.451375 16720 net.cpp:406] relu1_0 <- conv1_0
I1211 14:11:15.451375 16720 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 14:11:15.451375 16720 net.cpp:122] Setting up relu1_0
I1211 14:11:15.451375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.451375 16720 net.cpp:137] Memory required for data: 115918000
I1211 14:11:15.451375 16720 layer_factory.cpp:58] Creating layer conv2
I1211 14:11:15.451375 16720 net.cpp:84] Creating Layer conv2
I1211 14:11:15.451375 16720 net.cpp:406] conv2 <- conv1_0
I1211 14:11:15.451375 16720 net.cpp:380] conv2 -> conv2
I1211 14:11:15.452375 16720 net.cpp:122] Setting up conv2
I1211 14:11:15.452375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.452375 16720 net.cpp:137] Memory required for data: 132302000
I1211 14:11:15.452375 16720 layer_factory.cpp:58] Creating layer bn2
I1211 14:11:15.452375 16720 net.cpp:84] Creating Layer bn2
I1211 14:11:15.452375 16720 net.cpp:406] bn2 <- conv2
I1211 14:11:15.452375 16720 net.cpp:367] bn2 -> conv2 (in-place)
I1211 14:11:15.452375 16720 net.cpp:122] Setting up bn2
I1211 14:11:15.452375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.452375 16720 net.cpp:137] Memory required for data: 148686000
I1211 14:11:15.452375 16720 layer_factory.cpp:58] Creating layer scale2
I1211 14:11:15.452375 16720 net.cpp:84] Creating Layer scale2
I1211 14:11:15.452375 16720 net.cpp:406] scale2 <- conv2
I1211 14:11:15.452375 16720 net.cpp:367] scale2 -> conv2 (in-place)
I1211 14:11:15.453375 16720 layer_factory.cpp:58] Creating layer scale2
I1211 14:11:15.453375 16720 net.cpp:122] Setting up scale2
I1211 14:11:15.453375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.453375 16720 net.cpp:137] Memory required for data: 165070000
I1211 14:11:15.453375 16720 layer_factory.cpp:58] Creating layer relu2
I1211 14:11:15.453375 16720 net.cpp:84] Creating Layer relu2
I1211 14:11:15.453375 16720 net.cpp:406] relu2 <- conv2
I1211 14:11:15.453375 16720 net.cpp:367] relu2 -> conv2 (in-place)
I1211 14:11:15.453375 16720 net.cpp:122] Setting up relu2
I1211 14:11:15.453375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.453375 16720 net.cpp:137] Memory required for data: 181454000
I1211 14:11:15.453375 16720 layer_factory.cpp:58] Creating layer conv2_1
I1211 14:11:15.453375 16720 net.cpp:84] Creating Layer conv2_1
I1211 14:11:15.453375 16720 net.cpp:406] conv2_1 <- conv2
I1211 14:11:15.453375 16720 net.cpp:380] conv2_1 -> conv2_1
I1211 14:11:15.454376 16720 net.cpp:122] Setting up conv2_1
I1211 14:11:15.454376 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.454376 16720 net.cpp:137] Memory required for data: 197838000
I1211 14:11:15.454376 16720 layer_factory.cpp:58] Creating layer bn2_1
I1211 14:11:15.454376 16720 net.cpp:84] Creating Layer bn2_1
I1211 14:11:15.454376 16720 net.cpp:406] bn2_1 <- conv2_1
I1211 14:11:15.454376 16720 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 14:11:15.454376 16720 net.cpp:122] Setting up bn2_1
I1211 14:11:15.454376 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.454376 16720 net.cpp:137] Memory required for data: 214222000
I1211 14:11:15.454376 16720 layer_factory.cpp:58] Creating layer scale2_1
I1211 14:11:15.454376 16720 net.cpp:84] Creating Layer scale2_1
I1211 14:11:15.454376 16720 net.cpp:406] scale2_1 <- conv2_1
I1211 14:11:15.454376 16720 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 14:11:15.454376 16720 layer_factory.cpp:58] Creating layer scale2_1
I1211 14:11:15.454376 16720 net.cpp:122] Setting up scale2_1
I1211 14:11:15.454376 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.454376 16720 net.cpp:137] Memory required for data: 230606000
I1211 14:11:15.454376 16720 layer_factory.cpp:58] Creating layer relu2_1
I1211 14:11:15.454376 16720 net.cpp:84] Creating Layer relu2_1
I1211 14:11:15.454376 16720 net.cpp:406] relu2_1 <- conv2_1
I1211 14:11:15.454376 16720 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 14:11:15.455375 16720 net.cpp:122] Setting up relu2_1
I1211 14:11:15.455375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.455375 16720 net.cpp:137] Memory required for data: 246990000
I1211 14:11:15.455375 16720 layer_factory.cpp:58] Creating layer conv2_2
I1211 14:11:15.455375 16720 net.cpp:84] Creating Layer conv2_2
I1211 14:11:15.455375 16720 net.cpp:406] conv2_2 <- conv2_1
I1211 14:11:15.455375 16720 net.cpp:380] conv2_2 -> conv2_2
I1211 14:11:15.457376 16720 net.cpp:122] Setting up conv2_2
I1211 14:11:15.457376 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.457376 16720 net.cpp:137] Memory required for data: 267470000
I1211 14:11:15.457376 16720 layer_factory.cpp:58] Creating layer bn2_2
I1211 14:11:15.457376 16720 net.cpp:84] Creating Layer bn2_2
I1211 14:11:15.457376 16720 net.cpp:406] bn2_2 <- conv2_2
I1211 14:11:15.457376 16720 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 14:11:15.457376 16720 net.cpp:122] Setting up bn2_2
I1211 14:11:15.457376 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.457376 16720 net.cpp:137] Memory required for data: 287950000
I1211 14:11:15.457376 16720 layer_factory.cpp:58] Creating layer scale2_2
I1211 14:11:15.457376 16720 net.cpp:84] Creating Layer scale2_2
I1211 14:11:15.457376 16720 net.cpp:406] scale2_2 <- conv2_2
I1211 14:11:15.457376 16720 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 14:11:15.457376 16720 layer_factory.cpp:58] Creating layer scale2_2
I1211 14:11:15.457376 16720 net.cpp:122] Setting up scale2_2
I1211 14:11:15.457376 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.457376 16720 net.cpp:137] Memory required for data: 308430000
I1211 14:11:15.457376 16720 layer_factory.cpp:58] Creating layer relu2_2
I1211 14:11:15.457376 16720 net.cpp:84] Creating Layer relu2_2
I1211 14:11:15.457376 16720 net.cpp:406] relu2_2 <- conv2_2
I1211 14:11:15.457376 16720 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 14:11:15.458376 16720 net.cpp:122] Setting up relu2_2
I1211 14:11:15.458376 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.458376 16720 net.cpp:137] Memory required for data: 328910000
I1211 14:11:15.458376 16720 layer_factory.cpp:58] Creating layer pool2_1
I1211 14:11:15.458376 16720 net.cpp:84] Creating Layer pool2_1
I1211 14:11:15.458376 16720 net.cpp:406] pool2_1 <- conv2_2
I1211 14:11:15.458376 16720 net.cpp:380] pool2_1 -> pool2_1
I1211 14:11:15.459377 16720 net.cpp:122] Setting up pool2_1
I1211 14:11:15.459377 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.459377 16720 net.cpp:137] Memory required for data: 334030000
I1211 14:11:15.459377 16720 layer_factory.cpp:58] Creating layer bn2_pool2_1
I1211 14:11:15.459377 16720 net.cpp:84] Creating Layer bn2_pool2_1
I1211 14:11:15.459377 16720 net.cpp:406] bn2_pool2_1 <- pool2_1
I1211 14:11:15.459377 16720 net.cpp:367] bn2_pool2_1 -> pool2_1 (in-place)
I1211 14:11:15.459377 16720 net.cpp:122] Setting up bn2_pool2_1
I1211 14:11:15.459377 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.459377 16720 net.cpp:137] Memory required for data: 339150000
I1211 14:11:15.459377 16720 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 14:11:15.459377 16720 net.cpp:84] Creating Layer scale2_pool2_1
I1211 14:11:15.459377 16720 net.cpp:406] scale2_pool2_1 <- pool2_1
I1211 14:11:15.459377 16720 net.cpp:367] scale2_pool2_1 -> pool2_1 (in-place)
I1211 14:11:15.460376 16720 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 14:11:15.460376 16720 net.cpp:122] Setting up scale2_pool2_1
I1211 14:11:15.460376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.460376 16720 net.cpp:137] Memory required for data: 344270000
I1211 14:11:15.460376 16720 layer_factory.cpp:58] Creating layer relu2_pool2_1
I1211 14:11:15.460376 16720 net.cpp:84] Creating Layer relu2_pool2_1
I1211 14:11:15.460376 16720 net.cpp:406] relu2_pool2_1 <- pool2_1
I1211 14:11:15.460376 16720 net.cpp:367] relu2_pool2_1 -> pool2_1 (in-place)
I1211 14:11:15.460376 16720 net.cpp:122] Setting up relu2_pool2_1
I1211 14:11:15.460376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.460376 16720 net.cpp:137] Memory required for data: 349390000
I1211 14:11:15.460376 16720 layer_factory.cpp:58] Creating layer conv3
I1211 14:11:15.460376 16720 net.cpp:84] Creating Layer conv3
I1211 14:11:15.460376 16720 net.cpp:406] conv3 <- pool2_1
I1211 14:11:15.460376 16720 net.cpp:380] conv3 -> conv3
I1211 14:11:15.461375 16720 net.cpp:122] Setting up conv3
I1211 14:11:15.461375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.461375 16720 net.cpp:137] Memory required for data: 354510000
I1211 14:11:15.461375 16720 layer_factory.cpp:58] Creating layer bn3
I1211 14:11:15.461375 16720 net.cpp:84] Creating Layer bn3
I1211 14:11:15.461375 16720 net.cpp:406] bn3 <- conv3
I1211 14:11:15.461375 16720 net.cpp:367] bn3 -> conv3 (in-place)
I1211 14:11:15.462375 16720 net.cpp:122] Setting up bn3
I1211 14:11:15.462375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.462375 16720 net.cpp:137] Memory required for data: 359630000
I1211 14:11:15.462375 16720 layer_factory.cpp:58] Creating layer scale3
I1211 14:11:15.462375 16720 net.cpp:84] Creating Layer scale3
I1211 14:11:15.462375 16720 net.cpp:406] scale3 <- conv3
I1211 14:11:15.462375 16720 net.cpp:367] scale3 -> conv3 (in-place)
I1211 14:11:15.462375 16720 layer_factory.cpp:58] Creating layer scale3
I1211 14:11:15.462375 16720 net.cpp:122] Setting up scale3
I1211 14:11:15.462375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.462375 16720 net.cpp:137] Memory required for data: 364750000
I1211 14:11:15.462375 16720 layer_factory.cpp:58] Creating layer relu3
I1211 14:11:15.462375 16720 net.cpp:84] Creating Layer relu3
I1211 14:11:15.462375 16720 net.cpp:406] relu3 <- conv3
I1211 14:11:15.462375 16720 net.cpp:367] relu3 -> conv3 (in-place)
I1211 14:11:15.462375 16720 net.cpp:122] Setting up relu3
I1211 14:11:15.462375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.462375 16720 net.cpp:137] Memory required for data: 369870000
I1211 14:11:15.462375 16720 layer_factory.cpp:58] Creating layer conv3_1
I1211 14:11:15.462375 16720 net.cpp:84] Creating Layer conv3_1
I1211 14:11:15.462375 16720 net.cpp:406] conv3_1 <- conv3
I1211 14:11:15.462375 16720 net.cpp:380] conv3_1 -> conv3_1
I1211 14:11:15.463376 16720 net.cpp:122] Setting up conv3_1
I1211 14:11:15.463376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.463376 16720 net.cpp:137] Memory required for data: 374990000
I1211 14:11:15.463376 16720 layer_factory.cpp:58] Creating layer bn3_1
I1211 14:11:15.463376 16720 net.cpp:84] Creating Layer bn3_1
I1211 14:11:15.463376 16720 net.cpp:406] bn3_1 <- conv3_1
I1211 14:11:15.463376 16720 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 14:11:15.464375 16720 net.cpp:122] Setting up bn3_1
I1211 14:11:15.464375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.464375 16720 net.cpp:137] Memory required for data: 380110000
I1211 14:11:15.464375 16720 layer_factory.cpp:58] Creating layer scale3_1
I1211 14:11:15.464375 16720 net.cpp:84] Creating Layer scale3_1
I1211 14:11:15.464375 16720 net.cpp:406] scale3_1 <- conv3_1
I1211 14:11:15.464375 16720 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 14:11:15.464375 16720 layer_factory.cpp:58] Creating layer scale3_1
I1211 14:11:15.464375 16720 net.cpp:122] Setting up scale3_1
I1211 14:11:15.464375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.464375 16720 net.cpp:137] Memory required for data: 385230000
I1211 14:11:15.464375 16720 layer_factory.cpp:58] Creating layer relu3_1
I1211 14:11:15.464375 16720 net.cpp:84] Creating Layer relu3_1
I1211 14:11:15.464375 16720 net.cpp:406] relu3_1 <- conv3_1
I1211 14:11:15.464375 16720 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 14:11:15.464375 16720 net.cpp:122] Setting up relu3_1
I1211 14:11:15.464375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.464375 16720 net.cpp:137] Memory required for data: 390350000
I1211 14:11:15.464375 16720 layer_factory.cpp:58] Creating layer conv4
I1211 14:11:15.464375 16720 net.cpp:84] Creating Layer conv4
I1211 14:11:15.464375 16720 net.cpp:406] conv4 <- conv3_1
I1211 14:11:15.464375 16720 net.cpp:380] conv4 -> conv4
I1211 14:11:15.465375 16720 net.cpp:122] Setting up conv4
I1211 14:11:15.465375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.465375 16720 net.cpp:137] Memory required for data: 395470000
I1211 14:11:15.465375 16720 layer_factory.cpp:58] Creating layer bn4
I1211 14:11:15.465375 16720 net.cpp:84] Creating Layer bn4
I1211 14:11:15.465375 16720 net.cpp:406] bn4 <- conv4
I1211 14:11:15.465375 16720 net.cpp:367] bn4 -> conv4 (in-place)
I1211 14:11:15.466374 16720 net.cpp:122] Setting up bn4
I1211 14:11:15.466374 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.466374 16720 net.cpp:137] Memory required for data: 400590000
I1211 14:11:15.466374 16720 layer_factory.cpp:58] Creating layer scale4
I1211 14:11:15.466374 16720 net.cpp:84] Creating Layer scale4
I1211 14:11:15.466374 16720 net.cpp:406] scale4 <- conv4
I1211 14:11:15.466374 16720 net.cpp:367] scale4 -> conv4 (in-place)
I1211 14:11:15.466374 16720 layer_factory.cpp:58] Creating layer scale4
I1211 14:11:15.466374 16720 net.cpp:122] Setting up scale4
I1211 14:11:15.466374 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.466374 16720 net.cpp:137] Memory required for data: 405710000
I1211 14:11:15.466374 16720 layer_factory.cpp:58] Creating layer relu4
I1211 14:11:15.466374 16720 net.cpp:84] Creating Layer relu4
I1211 14:11:15.466374 16720 net.cpp:406] relu4 <- conv4
I1211 14:11:15.466374 16720 net.cpp:367] relu4 -> conv4 (in-place)
I1211 14:11:15.466374 16720 net.cpp:122] Setting up relu4
I1211 14:11:15.466374 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.466374 16720 net.cpp:137] Memory required for data: 410830000
I1211 14:11:15.466374 16720 layer_factory.cpp:58] Creating layer conv4_1
I1211 14:11:15.466374 16720 net.cpp:84] Creating Layer conv4_1
I1211 14:11:15.466374 16720 net.cpp:406] conv4_1 <- conv4
I1211 14:11:15.466374 16720 net.cpp:380] conv4_1 -> conv4_1
I1211 14:11:15.467375 16720 net.cpp:122] Setting up conv4_1
I1211 14:11:15.467375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.467375 16720 net.cpp:137] Memory required for data: 415950000
I1211 14:11:15.467375 16720 layer_factory.cpp:58] Creating layer bn4_1
I1211 14:11:15.467375 16720 net.cpp:84] Creating Layer bn4_1
I1211 14:11:15.467375 16720 net.cpp:406] bn4_1 <- conv4_1
I1211 14:11:15.467375 16720 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 14:11:15.467375 16720 net.cpp:122] Setting up bn4_1
I1211 14:11:15.467375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.467375 16720 net.cpp:137] Memory required for data: 421070000
I1211 14:11:15.468375 16720 layer_factory.cpp:58] Creating layer scale4_1
I1211 14:11:15.468375 16720 net.cpp:84] Creating Layer scale4_1
I1211 14:11:15.468375 16720 net.cpp:406] scale4_1 <- conv4_1
I1211 14:11:15.468375 16720 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 14:11:15.468375 16720 layer_factory.cpp:58] Creating layer scale4_1
I1211 14:11:15.468375 16720 net.cpp:122] Setting up scale4_1
I1211 14:11:15.468375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.468375 16720 net.cpp:137] Memory required for data: 426190000
I1211 14:11:15.468375 16720 layer_factory.cpp:58] Creating layer relu4_1
I1211 14:11:15.468375 16720 net.cpp:84] Creating Layer relu4_1
I1211 14:11:15.468375 16720 net.cpp:406] relu4_1 <- conv4_1
I1211 14:11:15.468375 16720 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 14:11:15.468375 16720 net.cpp:122] Setting up relu4_1
I1211 14:11:15.468375 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.468375 16720 net.cpp:137] Memory required for data: 431310000
I1211 14:11:15.468375 16720 layer_factory.cpp:58] Creating layer conv4_2
I1211 14:11:15.468375 16720 net.cpp:84] Creating Layer conv4_2
I1211 14:11:15.468375 16720 net.cpp:406] conv4_2 <- conv4_1
I1211 14:11:15.468375 16720 net.cpp:380] conv4_2 -> conv4_2
I1211 14:11:15.469377 16720 net.cpp:122] Setting up conv4_2
I1211 14:11:15.469377 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.469377 16720 net.cpp:137] Memory required for data: 437249200
I1211 14:11:15.469377 16720 layer_factory.cpp:58] Creating layer bn4_2
I1211 14:11:15.469377 16720 net.cpp:84] Creating Layer bn4_2
I1211 14:11:15.469377 16720 net.cpp:406] bn4_2 <- conv4_2
I1211 14:11:15.469377 16720 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 14:11:15.470376 16720 net.cpp:122] Setting up bn4_2
I1211 14:11:15.470376 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.470376 16720 net.cpp:137] Memory required for data: 443188400
I1211 14:11:15.470376 16720 layer_factory.cpp:58] Creating layer scale4_2
I1211 14:11:15.470376 16720 net.cpp:84] Creating Layer scale4_2
I1211 14:11:15.470376 16720 net.cpp:406] scale4_2 <- conv4_2
I1211 14:11:15.470376 16720 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 14:11:15.470376 16720 layer_factory.cpp:58] Creating layer scale4_2
I1211 14:11:15.470376 16720 net.cpp:122] Setting up scale4_2
I1211 14:11:15.470376 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.470376 16720 net.cpp:137] Memory required for data: 449127600
I1211 14:11:15.470376 16720 layer_factory.cpp:58] Creating layer relu4_2
I1211 14:11:15.470376 16720 net.cpp:84] Creating Layer relu4_2
I1211 14:11:15.470376 16720 net.cpp:406] relu4_2 <- conv4_2
I1211 14:11:15.470376 16720 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 14:11:15.470376 16720 net.cpp:122] Setting up relu4_2
I1211 14:11:15.470376 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.470376 16720 net.cpp:137] Memory required for data: 455066800
I1211 14:11:15.470376 16720 layer_factory.cpp:58] Creating layer pool4_2
I1211 14:11:15.470376 16720 net.cpp:84] Creating Layer pool4_2
I1211 14:11:15.470376 16720 net.cpp:406] pool4_2 <- conv4_2
I1211 14:11:15.470376 16720 net.cpp:380] pool4_2 -> pool4_2
I1211 14:11:15.471375 16720 net.cpp:122] Setting up pool4_2
I1211 14:11:15.472376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.472376 16720 net.cpp:137] Memory required for data: 456551600
I1211 14:11:15.472376 16720 layer_factory.cpp:58] Creating layer bn4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:84] Creating Layer bn4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:406] bn4_pool4_2 <- pool4_2
I1211 14:11:15.472376 16720 net.cpp:367] bn4_pool4_2 -> pool4_2 (in-place)
I1211 14:11:15.472376 16720 net.cpp:122] Setting up bn4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.472376 16720 net.cpp:137] Memory required for data: 458036400
I1211 14:11:15.472376 16720 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:84] Creating Layer scale4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:406] scale4_pool4_2 <- pool4_2
I1211 14:11:15.472376 16720 net.cpp:367] scale4_pool4_2 -> pool4_2 (in-place)
I1211 14:11:15.472376 16720 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:122] Setting up scale4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.472376 16720 net.cpp:137] Memory required for data: 459521200
I1211 14:11:15.472376 16720 layer_factory.cpp:58] Creating layer relu4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:84] Creating Layer relu4_pool4_2
I1211 14:11:15.472376 16720 net.cpp:406] relu4_pool4_2 <- pool4_2
I1211 14:11:15.472376 16720 net.cpp:367] relu4_pool4_2 -> pool4_2 (in-place)
I1211 14:11:15.473376 16720 net.cpp:122] Setting up relu4_pool4_2
I1211 14:11:15.473376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.473376 16720 net.cpp:137] Memory required for data: 461006000
I1211 14:11:15.473376 16720 layer_factory.cpp:58] Creating layer conv4_0
I1211 14:11:15.473376 16720 net.cpp:84] Creating Layer conv4_0
I1211 14:11:15.473376 16720 net.cpp:406] conv4_0 <- pool4_2
I1211 14:11:15.473376 16720 net.cpp:380] conv4_0 -> conv4_0
I1211 14:11:15.474375 16720 net.cpp:122] Setting up conv4_0
I1211 14:11:15.474375 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.474375 16720 net.cpp:137] Memory required for data: 462490800
I1211 14:11:15.474375 16720 layer_factory.cpp:58] Creating layer bn4_0
I1211 14:11:15.474375 16720 net.cpp:84] Creating Layer bn4_0
I1211 14:11:15.474375 16720 net.cpp:406] bn4_0 <- conv4_0
I1211 14:11:15.474375 16720 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 14:11:15.475376 16720 net.cpp:122] Setting up bn4_0
I1211 14:11:15.475376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.475376 16720 net.cpp:137] Memory required for data: 463975600
I1211 14:11:15.475376 16720 layer_factory.cpp:58] Creating layer scale4_0
I1211 14:11:15.475376 16720 net.cpp:84] Creating Layer scale4_0
I1211 14:11:15.475376 16720 net.cpp:406] scale4_0 <- conv4_0
I1211 14:11:15.475376 16720 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 14:11:15.475376 16720 layer_factory.cpp:58] Creating layer scale4_0
I1211 14:11:15.475376 16720 net.cpp:122] Setting up scale4_0
I1211 14:11:15.475376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.475376 16720 net.cpp:137] Memory required for data: 465460400
I1211 14:11:15.475376 16720 layer_factory.cpp:58] Creating layer relu4_0
I1211 14:11:15.475376 16720 net.cpp:84] Creating Layer relu4_0
I1211 14:11:15.475376 16720 net.cpp:406] relu4_0 <- conv4_0
I1211 14:11:15.475376 16720 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 14:11:15.475376 16720 net.cpp:122] Setting up relu4_0
I1211 14:11:15.475376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.475376 16720 net.cpp:137] Memory required for data: 466945200
I1211 14:11:15.475376 16720 layer_factory.cpp:58] Creating layer conv11
I1211 14:11:15.475376 16720 net.cpp:84] Creating Layer conv11
I1211 14:11:15.475376 16720 net.cpp:406] conv11 <- conv4_0
I1211 14:11:15.475376 16720 net.cpp:380] conv11 -> conv11
I1211 14:11:15.477377 16720 net.cpp:122] Setting up conv11
I1211 14:11:15.477377 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.477377 16720 net.cpp:137] Memory required for data: 468737200
I1211 14:11:15.477377 16720 layer_factory.cpp:58] Creating layer bn_conv11
I1211 14:11:15.477377 16720 net.cpp:84] Creating Layer bn_conv11
I1211 14:11:15.477377 16720 net.cpp:406] bn_conv11 <- conv11
I1211 14:11:15.477377 16720 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 14:11:15.477377 16720 net.cpp:122] Setting up bn_conv11
I1211 14:11:15.477377 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.477377 16720 net.cpp:137] Memory required for data: 470529200
I1211 14:11:15.477377 16720 layer_factory.cpp:58] Creating layer scale_conv11
I1211 14:11:15.477377 16720 net.cpp:84] Creating Layer scale_conv11
I1211 14:11:15.477377 16720 net.cpp:406] scale_conv11 <- conv11
I1211 14:11:15.477377 16720 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 14:11:15.477377 16720 layer_factory.cpp:58] Creating layer scale_conv11
I1211 14:11:15.477377 16720 net.cpp:122] Setting up scale_conv11
I1211 14:11:15.477377 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.477377 16720 net.cpp:137] Memory required for data: 472321200
I1211 14:11:15.477377 16720 layer_factory.cpp:58] Creating layer relu_conv11
I1211 14:11:15.477377 16720 net.cpp:84] Creating Layer relu_conv11
I1211 14:11:15.477377 16720 net.cpp:406] relu_conv11 <- conv11
I1211 14:11:15.477377 16720 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 14:11:15.477377 16720 net.cpp:122] Setting up relu_conv11
I1211 14:11:15.477377 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.477377 16720 net.cpp:137] Memory required for data: 474113200
I1211 14:11:15.477377 16720 layer_factory.cpp:58] Creating layer conv12
I1211 14:11:15.477377 16720 net.cpp:84] Creating Layer conv12
I1211 14:11:15.477377 16720 net.cpp:406] conv12 <- conv11
I1211 14:11:15.477377 16720 net.cpp:380] conv12 -> conv12
I1211 14:11:15.479375 16720 net.cpp:122] Setting up conv12
I1211 14:11:15.479375 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.479375 16720 net.cpp:137] Memory required for data: 476417200
I1211 14:11:15.479375 16720 layer_factory.cpp:58] Creating layer bn_conv12
I1211 14:11:15.479375 16720 net.cpp:84] Creating Layer bn_conv12
I1211 14:11:15.479375 16720 net.cpp:406] bn_conv12 <- conv12
I1211 14:11:15.479375 16720 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 14:11:15.479375 16720 net.cpp:122] Setting up bn_conv12
I1211 14:11:15.479375 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.479375 16720 net.cpp:137] Memory required for data: 478721200
I1211 14:11:15.479375 16720 layer_factory.cpp:58] Creating layer scale_conv12
I1211 14:11:15.479375 16720 net.cpp:84] Creating Layer scale_conv12
I1211 14:11:15.479375 16720 net.cpp:406] scale_conv12 <- conv12
I1211 14:11:15.479375 16720 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 14:11:15.479375 16720 layer_factory.cpp:58] Creating layer scale_conv12
I1211 14:11:15.479375 16720 net.cpp:122] Setting up scale_conv12
I1211 14:11:15.479375 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.479375 16720 net.cpp:137] Memory required for data: 481025200
I1211 14:11:15.479375 16720 layer_factory.cpp:58] Creating layer relu_conv12
I1211 14:11:15.479375 16720 net.cpp:84] Creating Layer relu_conv12
I1211 14:11:15.479375 16720 net.cpp:406] relu_conv12 <- conv12
I1211 14:11:15.479375 16720 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 14:11:15.480376 16720 net.cpp:122] Setting up relu_conv12
I1211 14:11:15.480376 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.480376 16720 net.cpp:137] Memory required for data: 483329200
I1211 14:11:15.480376 16720 layer_factory.cpp:58] Creating layer poolcp6
I1211 14:11:15.480376 16720 net.cpp:84] Creating Layer poolcp6
I1211 14:11:15.480376 16720 net.cpp:406] poolcp6 <- conv12
I1211 14:11:15.480376 16720 net.cpp:380] poolcp6 -> poolcp6
I1211 14:11:15.480376 16720 net.cpp:122] Setting up poolcp6
I1211 14:11:15.480376 16720 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 14:11:15.480376 16720 net.cpp:137] Memory required for data: 483365200
I1211 14:11:15.480376 16720 layer_factory.cpp:58] Creating layer ip1
I1211 14:11:15.480376 16720 net.cpp:84] Creating Layer ip1
I1211 14:11:15.480376 16720 net.cpp:406] ip1 <- poolcp6
I1211 14:11:15.480376 16720 net.cpp:380] ip1 -> ip1
I1211 14:11:15.480376 16720 net.cpp:122] Setting up ip1
I1211 14:11:15.480376 16720 net.cpp:129] Top shape: 100 100 (10000)
I1211 14:11:15.480376 16720 net.cpp:137] Memory required for data: 483405200
I1211 14:11:15.480376 16720 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 14:11:15.480376 16720 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 14:11:15.480376 16720 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 14:11:15.480376 16720 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 14:11:15.480376 16720 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 14:11:15.480376 16720 net.cpp:122] Setting up ip1_ip1_0_split
I1211 14:11:15.480376 16720 net.cpp:129] Top shape: 100 100 (10000)
I1211 14:11:15.480376 16720 net.cpp:129] Top shape: 100 100 (10000)
I1211 14:11:15.480376 16720 net.cpp:137] Memory required for data: 483485200
I1211 14:11:15.480376 16720 layer_factory.cpp:58] Creating layer accuracy_training
I1211 14:11:15.480376 16720 net.cpp:84] Creating Layer accuracy_training
I1211 14:11:15.480376 16720 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1211 14:11:15.480376 16720 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1211 14:11:15.480376 16720 net.cpp:380] accuracy_training -> accuracy_training
I1211 14:11:15.480376 16720 net.cpp:122] Setting up accuracy_training
I1211 14:11:15.480376 16720 net.cpp:129] Top shape: (1)
I1211 14:11:15.480376 16720 net.cpp:137] Memory required for data: 483485204
I1211 14:11:15.480376 16720 layer_factory.cpp:58] Creating layer loss
I1211 14:11:15.480376 16720 net.cpp:84] Creating Layer loss
I1211 14:11:15.480376 16720 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 14:11:15.480376 16720 net.cpp:406] loss <- label_cifar_1_split_1
I1211 14:11:15.480376 16720 net.cpp:380] loss -> loss
I1211 14:11:15.480376 16720 layer_factory.cpp:58] Creating layer loss
I1211 14:11:15.481376 16720 net.cpp:122] Setting up loss
I1211 14:11:15.481376 16720 net.cpp:129] Top shape: (1)
I1211 14:11:15.481376 16720 net.cpp:132]     with loss weight 1
I1211 14:11:15.481376 16720 net.cpp:137] Memory required for data: 483485208
I1211 14:11:15.481376 16720 net.cpp:198] loss needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:200] accuracy_training does not need backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] ip1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] poolcp6 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu_conv12 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale_conv12 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn_conv12 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv12 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu_conv11 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale_conv11 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn_conv11 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv11 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu4_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale4_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn4_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv4_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu4_pool4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale4_pool4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn4_pool4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] pool4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv4_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu4_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale4_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn4_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv4_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu4 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale4 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn4 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv4 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu3_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale3_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn3_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv3_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu3 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale3 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn3 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv3 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu2_pool2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale2_pool2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn2_pool2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] pool2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu2_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale2_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn2_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv2_2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv2_1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv2 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu1_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale1_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn1_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv1_0 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] relu1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] scale1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] bn1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:198] conv1 needs backward computation.
I1211 14:11:15.481376 16720 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 14:11:15.481376 16720 net.cpp:200] cifar does not need backward computation.
I1211 14:11:15.481376 16720 net.cpp:242] This network produces output accuracy_training
I1211 14:11:15.481376 16720 net.cpp:242] This network produces output loss
I1211 14:11:15.481376 16720 net.cpp:255] Network initialization done.
I1211 14:11:15.482375 16720 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 14:11:15.482375 16720 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 14:11:15.482375 16720 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_pool2_1
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_pool4_2
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1211 14:11:15.482375 16720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1211 14:11:15.483376 16720 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV2_WnonLin_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "pool2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_pool2_1"
  type: "BatchNorm"
  bottom: "pool2_1"
  top: "pool2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_pool2_1"
  type: "Scale"
  bottom: "pool2_1"
  top: "pool2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_pool2_1"
  type: "ReLU"
  bottom: "pool2_1"
  top: "pool2_1"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "pool4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_pool4_2"
  type: "BatchNorm"
  bottom: "pool4_2"
  top: "pool4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_pool4_2"
  type: "Scale"
  bottom: "pool4_2"
  top: "pool4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_pool4_2"
  type: "ReLU"
  bottom: "pool4_2"
  top: "pool4_2"
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 14:11:15.483376 16720 layer_factory.cpp:58] Creating layer cifar
I1211 14:11:15.488379 16720 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1211 14:11:15.489377 16720 net.cpp:84] Creating Layer cifar
I1211 14:11:15.489377 16720 net.cpp:380] cifar -> data
I1211 14:11:15.489377 16720 net.cpp:380] cifar -> label
I1211 14:11:15.489377 16720 data_layer.cpp:45] output data size: 100,3,32,32
I1211 14:11:15.495386 16720 net.cpp:122] Setting up cifar
I1211 14:11:15.495386 16720 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 14:11:15.495386 16720 net.cpp:129] Top shape: 100 (100)
I1211 14:11:15.495386 16720 net.cpp:137] Memory required for data: 1229200
I1211 14:11:15.495386 16720 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 14:11:15.495386 16720 net.cpp:84] Creating Layer label_cifar_1_split
I1211 14:11:15.495386 16720 net.cpp:406] label_cifar_1_split <- label
I1211 14:11:15.495386 16720 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 14:11:15.495386 16720 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 14:11:15.495386 16720 net.cpp:122] Setting up label_cifar_1_split
I1211 14:11:15.495386 16720 net.cpp:129] Top shape: 100 (100)
I1211 14:11:15.495386 16720 net.cpp:129] Top shape: 100 (100)
I1211 14:11:15.495386 16720 net.cpp:137] Memory required for data: 1230000
I1211 14:11:15.495386 16720 layer_factory.cpp:58] Creating layer conv1
I1211 14:11:15.495386 16720 net.cpp:84] Creating Layer conv1
I1211 14:11:15.495386 16720 net.cpp:406] conv1 <- data
I1211 14:11:15.495386 16720 net.cpp:380] conv1 -> conv1
I1211 14:11:15.497377 16720 net.cpp:122] Setting up conv1
I1211 14:11:15.497377 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.497377 16720 net.cpp:137] Memory required for data: 13518000
I1211 14:11:15.497377 16720 layer_factory.cpp:58] Creating layer bn1
I1211 14:11:15.497377 16720 net.cpp:84] Creating Layer bn1
I1211 14:11:15.497377 16720 net.cpp:406] bn1 <- conv1
I1211 14:11:15.497377 16720 net.cpp:367] bn1 -> conv1 (in-place)
I1211 14:11:15.497377 11892 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 14:11:15.497377 16720 net.cpp:122] Setting up bn1
I1211 14:11:15.497377 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.497377 16720 net.cpp:137] Memory required for data: 25806000
I1211 14:11:15.497377 16720 layer_factory.cpp:58] Creating layer scale1
I1211 14:11:15.497377 16720 net.cpp:84] Creating Layer scale1
I1211 14:11:15.497377 16720 net.cpp:406] scale1 <- conv1
I1211 14:11:15.497377 16720 net.cpp:367] scale1 -> conv1 (in-place)
I1211 14:11:15.497377 16720 layer_factory.cpp:58] Creating layer scale1
I1211 14:11:15.497377 16720 net.cpp:122] Setting up scale1
I1211 14:11:15.497377 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.497377 16720 net.cpp:137] Memory required for data: 38094000
I1211 14:11:15.497377 16720 layer_factory.cpp:58] Creating layer relu1
I1211 14:11:15.497377 16720 net.cpp:84] Creating Layer relu1
I1211 14:11:15.497377 16720 net.cpp:406] relu1 <- conv1
I1211 14:11:15.497377 16720 net.cpp:367] relu1 -> conv1 (in-place)
I1211 14:11:15.498391 16720 net.cpp:122] Setting up relu1
I1211 14:11:15.498391 16720 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 14:11:15.498391 16720 net.cpp:137] Memory required for data: 50382000
I1211 14:11:15.498391 16720 layer_factory.cpp:58] Creating layer conv1_0
I1211 14:11:15.498391 16720 net.cpp:84] Creating Layer conv1_0
I1211 14:11:15.498391 16720 net.cpp:406] conv1_0 <- conv1
I1211 14:11:15.498391 16720 net.cpp:380] conv1_0 -> conv1_0
I1211 14:11:15.499390 16720 net.cpp:122] Setting up conv1_0
I1211 14:11:15.499390 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.499390 16720 net.cpp:137] Memory required for data: 66766000
I1211 14:11:15.499390 16720 layer_factory.cpp:58] Creating layer bn1_0
I1211 14:11:15.499390 16720 net.cpp:84] Creating Layer bn1_0
I1211 14:11:15.499390 16720 net.cpp:406] bn1_0 <- conv1_0
I1211 14:11:15.499390 16720 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 14:11:15.500375 16720 net.cpp:122] Setting up bn1_0
I1211 14:11:15.500375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.500375 16720 net.cpp:137] Memory required for data: 83150000
I1211 14:11:15.500375 16720 layer_factory.cpp:58] Creating layer scale1_0
I1211 14:11:15.500375 16720 net.cpp:84] Creating Layer scale1_0
I1211 14:11:15.500375 16720 net.cpp:406] scale1_0 <- conv1_0
I1211 14:11:15.500375 16720 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 14:11:15.500375 16720 layer_factory.cpp:58] Creating layer scale1_0
I1211 14:11:15.500375 16720 net.cpp:122] Setting up scale1_0
I1211 14:11:15.500375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.500375 16720 net.cpp:137] Memory required for data: 99534000
I1211 14:11:15.500375 16720 layer_factory.cpp:58] Creating layer relu1_0
I1211 14:11:15.500375 16720 net.cpp:84] Creating Layer relu1_0
I1211 14:11:15.500375 16720 net.cpp:406] relu1_0 <- conv1_0
I1211 14:11:15.500375 16720 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 14:11:15.500375 16720 net.cpp:122] Setting up relu1_0
I1211 14:11:15.500375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.500375 16720 net.cpp:137] Memory required for data: 115918000
I1211 14:11:15.500375 16720 layer_factory.cpp:58] Creating layer conv2
I1211 14:11:15.500375 16720 net.cpp:84] Creating Layer conv2
I1211 14:11:15.500375 16720 net.cpp:406] conv2 <- conv1_0
I1211 14:11:15.500375 16720 net.cpp:380] conv2 -> conv2
I1211 14:11:15.502375 16720 net.cpp:122] Setting up conv2
I1211 14:11:15.502375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.502375 16720 net.cpp:137] Memory required for data: 132302000
I1211 14:11:15.502375 16720 layer_factory.cpp:58] Creating layer bn2
I1211 14:11:15.502375 16720 net.cpp:84] Creating Layer bn2
I1211 14:11:15.502375 16720 net.cpp:406] bn2 <- conv2
I1211 14:11:15.502375 16720 net.cpp:367] bn2 -> conv2 (in-place)
I1211 14:11:15.502375 16720 net.cpp:122] Setting up bn2
I1211 14:11:15.502375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.502375 16720 net.cpp:137] Memory required for data: 148686000
I1211 14:11:15.502375 16720 layer_factory.cpp:58] Creating layer scale2
I1211 14:11:15.502375 16720 net.cpp:84] Creating Layer scale2
I1211 14:11:15.502375 16720 net.cpp:406] scale2 <- conv2
I1211 14:11:15.502375 16720 net.cpp:367] scale2 -> conv2 (in-place)
I1211 14:11:15.502375 16720 layer_factory.cpp:58] Creating layer scale2
I1211 14:11:15.502375 16720 net.cpp:122] Setting up scale2
I1211 14:11:15.502375 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.502375 16720 net.cpp:137] Memory required for data: 165070000
I1211 14:11:15.502375 16720 layer_factory.cpp:58] Creating layer relu2
I1211 14:11:15.502375 16720 net.cpp:84] Creating Layer relu2
I1211 14:11:15.502375 16720 net.cpp:406] relu2 <- conv2
I1211 14:11:15.502375 16720 net.cpp:367] relu2 -> conv2 (in-place)
I1211 14:11:15.503376 16720 net.cpp:122] Setting up relu2
I1211 14:11:15.503376 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.503376 16720 net.cpp:137] Memory required for data: 181454000
I1211 14:11:15.503376 16720 layer_factory.cpp:58] Creating layer conv2_1
I1211 14:11:15.503376 16720 net.cpp:84] Creating Layer conv2_1
I1211 14:11:15.503376 16720 net.cpp:406] conv2_1 <- conv2
I1211 14:11:15.503376 16720 net.cpp:380] conv2_1 -> conv2_1
I1211 14:11:15.504379 16720 net.cpp:122] Setting up conv2_1
I1211 14:11:15.504379 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.504379 16720 net.cpp:137] Memory required for data: 197838000
I1211 14:11:15.504379 16720 layer_factory.cpp:58] Creating layer bn2_1
I1211 14:11:15.504379 16720 net.cpp:84] Creating Layer bn2_1
I1211 14:11:15.504379 16720 net.cpp:406] bn2_1 <- conv2_1
I1211 14:11:15.504379 16720 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 14:11:15.505374 16720 net.cpp:122] Setting up bn2_1
I1211 14:11:15.505374 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.505374 16720 net.cpp:137] Memory required for data: 214222000
I1211 14:11:15.505374 16720 layer_factory.cpp:58] Creating layer scale2_1
I1211 14:11:15.505374 16720 net.cpp:84] Creating Layer scale2_1
I1211 14:11:15.505374 16720 net.cpp:406] scale2_1 <- conv2_1
I1211 14:11:15.505374 16720 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 14:11:15.505374 16720 layer_factory.cpp:58] Creating layer scale2_1
I1211 14:11:15.505374 16720 net.cpp:122] Setting up scale2_1
I1211 14:11:15.505374 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.505374 16720 net.cpp:137] Memory required for data: 230606000
I1211 14:11:15.505374 16720 layer_factory.cpp:58] Creating layer relu2_1
I1211 14:11:15.505374 16720 net.cpp:84] Creating Layer relu2_1
I1211 14:11:15.505374 16720 net.cpp:406] relu2_1 <- conv2_1
I1211 14:11:15.505374 16720 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 14:11:15.505374 16720 net.cpp:122] Setting up relu2_1
I1211 14:11:15.505374 16720 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 14:11:15.505374 16720 net.cpp:137] Memory required for data: 246990000
I1211 14:11:15.505374 16720 layer_factory.cpp:58] Creating layer conv2_2
I1211 14:11:15.505374 16720 net.cpp:84] Creating Layer conv2_2
I1211 14:11:15.505374 16720 net.cpp:406] conv2_2 <- conv2_1
I1211 14:11:15.505374 16720 net.cpp:380] conv2_2 -> conv2_2
I1211 14:11:15.507375 16720 net.cpp:122] Setting up conv2_2
I1211 14:11:15.507375 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.507375 16720 net.cpp:137] Memory required for data: 267470000
I1211 14:11:15.507375 16720 layer_factory.cpp:58] Creating layer bn2_2
I1211 14:11:15.507375 16720 net.cpp:84] Creating Layer bn2_2
I1211 14:11:15.507375 16720 net.cpp:406] bn2_2 <- conv2_2
I1211 14:11:15.507375 16720 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 14:11:15.507375 16720 net.cpp:122] Setting up bn2_2
I1211 14:11:15.507375 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.507375 16720 net.cpp:137] Memory required for data: 287950000
I1211 14:11:15.507375 16720 layer_factory.cpp:58] Creating layer scale2_2
I1211 14:11:15.507375 16720 net.cpp:84] Creating Layer scale2_2
I1211 14:11:15.507375 16720 net.cpp:406] scale2_2 <- conv2_2
I1211 14:11:15.507375 16720 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 14:11:15.507375 16720 layer_factory.cpp:58] Creating layer scale2_2
I1211 14:11:15.507375 16720 net.cpp:122] Setting up scale2_2
I1211 14:11:15.507375 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.507375 16720 net.cpp:137] Memory required for data: 308430000
I1211 14:11:15.507375 16720 layer_factory.cpp:58] Creating layer relu2_2
I1211 14:11:15.507375 16720 net.cpp:84] Creating Layer relu2_2
I1211 14:11:15.507375 16720 net.cpp:406] relu2_2 <- conv2_2
I1211 14:11:15.507375 16720 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 14:11:15.507375 16720 net.cpp:122] Setting up relu2_2
I1211 14:11:15.507375 16720 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 14:11:15.507375 16720 net.cpp:137] Memory required for data: 328910000
I1211 14:11:15.507375 16720 layer_factory.cpp:58] Creating layer pool2_1
I1211 14:11:15.507375 16720 net.cpp:84] Creating Layer pool2_1
I1211 14:11:15.507375 16720 net.cpp:406] pool2_1 <- conv2_2
I1211 14:11:15.507375 16720 net.cpp:380] pool2_1 -> pool2_1
I1211 14:11:15.509398 16720 net.cpp:122] Setting up pool2_1
I1211 14:11:15.509398 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.509398 16720 net.cpp:137] Memory required for data: 334030000
I1211 14:11:15.509398 16720 layer_factory.cpp:58] Creating layer bn2_pool2_1
I1211 14:11:15.509398 16720 net.cpp:84] Creating Layer bn2_pool2_1
I1211 14:11:15.509398 16720 net.cpp:406] bn2_pool2_1 <- pool2_1
I1211 14:11:15.509398 16720 net.cpp:367] bn2_pool2_1 -> pool2_1 (in-place)
I1211 14:11:15.509398 16720 net.cpp:122] Setting up bn2_pool2_1
I1211 14:11:15.509398 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.509398 16720 net.cpp:137] Memory required for data: 339150000
I1211 14:11:15.509398 16720 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 14:11:15.509398 16720 net.cpp:84] Creating Layer scale2_pool2_1
I1211 14:11:15.509398 16720 net.cpp:406] scale2_pool2_1 <- pool2_1
I1211 14:11:15.509398 16720 net.cpp:367] scale2_pool2_1 -> pool2_1 (in-place)
I1211 14:11:15.509398 16720 layer_factory.cpp:58] Creating layer scale2_pool2_1
I1211 14:11:15.510393 16720 net.cpp:122] Setting up scale2_pool2_1
I1211 14:11:15.510393 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.510393 16720 net.cpp:137] Memory required for data: 344270000
I1211 14:11:15.510393 16720 layer_factory.cpp:58] Creating layer relu2_pool2_1
I1211 14:11:15.510393 16720 net.cpp:84] Creating Layer relu2_pool2_1
I1211 14:11:15.510393 16720 net.cpp:406] relu2_pool2_1 <- pool2_1
I1211 14:11:15.510393 16720 net.cpp:367] relu2_pool2_1 -> pool2_1 (in-place)
I1211 14:11:15.510393 16720 net.cpp:122] Setting up relu2_pool2_1
I1211 14:11:15.510393 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.510393 16720 net.cpp:137] Memory required for data: 349390000
I1211 14:11:15.510393 16720 layer_factory.cpp:58] Creating layer conv3
I1211 14:11:15.510393 16720 net.cpp:84] Creating Layer conv3
I1211 14:11:15.510393 16720 net.cpp:406] conv3 <- pool2_1
I1211 14:11:15.510393 16720 net.cpp:380] conv3 -> conv3
I1211 14:11:15.511389 16720 net.cpp:122] Setting up conv3
I1211 14:11:15.511389 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.511389 16720 net.cpp:137] Memory required for data: 354510000
I1211 14:11:15.511389 16720 layer_factory.cpp:58] Creating layer bn3
I1211 14:11:15.511389 16720 net.cpp:84] Creating Layer bn3
I1211 14:11:15.511389 16720 net.cpp:406] bn3 <- conv3
I1211 14:11:15.511389 16720 net.cpp:367] bn3 -> conv3 (in-place)
I1211 14:11:15.512387 16720 net.cpp:122] Setting up bn3
I1211 14:11:15.512387 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.512387 16720 net.cpp:137] Memory required for data: 359630000
I1211 14:11:15.512387 16720 layer_factory.cpp:58] Creating layer scale3
I1211 14:11:15.512387 16720 net.cpp:84] Creating Layer scale3
I1211 14:11:15.512387 16720 net.cpp:406] scale3 <- conv3
I1211 14:11:15.512387 16720 net.cpp:367] scale3 -> conv3 (in-place)
I1211 14:11:15.512387 16720 layer_factory.cpp:58] Creating layer scale3
I1211 14:11:15.512387 16720 net.cpp:122] Setting up scale3
I1211 14:11:15.512387 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.512387 16720 net.cpp:137] Memory required for data: 364750000
I1211 14:11:15.512387 16720 layer_factory.cpp:58] Creating layer relu3
I1211 14:11:15.512387 16720 net.cpp:84] Creating Layer relu3
I1211 14:11:15.512387 16720 net.cpp:406] relu3 <- conv3
I1211 14:11:15.512387 16720 net.cpp:367] relu3 -> conv3 (in-place)
I1211 14:11:15.512387 16720 net.cpp:122] Setting up relu3
I1211 14:11:15.512387 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.512387 16720 net.cpp:137] Memory required for data: 369870000
I1211 14:11:15.512387 16720 layer_factory.cpp:58] Creating layer conv3_1
I1211 14:11:15.512387 16720 net.cpp:84] Creating Layer conv3_1
I1211 14:11:15.512387 16720 net.cpp:406] conv3_1 <- conv3
I1211 14:11:15.512387 16720 net.cpp:380] conv3_1 -> conv3_1
I1211 14:11:15.514385 16720 net.cpp:122] Setting up conv3_1
I1211 14:11:15.514385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.514385 16720 net.cpp:137] Memory required for data: 374990000
I1211 14:11:15.514385 16720 layer_factory.cpp:58] Creating layer bn3_1
I1211 14:11:15.514385 16720 net.cpp:84] Creating Layer bn3_1
I1211 14:11:15.514385 16720 net.cpp:406] bn3_1 <- conv3_1
I1211 14:11:15.514385 16720 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 14:11:15.514385 16720 net.cpp:122] Setting up bn3_1
I1211 14:11:15.514385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.514385 16720 net.cpp:137] Memory required for data: 380110000
I1211 14:11:15.514385 16720 layer_factory.cpp:58] Creating layer scale3_1
I1211 14:11:15.514385 16720 net.cpp:84] Creating Layer scale3_1
I1211 14:11:15.514385 16720 net.cpp:406] scale3_1 <- conv3_1
I1211 14:11:15.514385 16720 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 14:11:15.514385 16720 layer_factory.cpp:58] Creating layer scale3_1
I1211 14:11:15.514385 16720 net.cpp:122] Setting up scale3_1
I1211 14:11:15.514385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.514385 16720 net.cpp:137] Memory required for data: 385230000
I1211 14:11:15.514385 16720 layer_factory.cpp:58] Creating layer relu3_1
I1211 14:11:15.514385 16720 net.cpp:84] Creating Layer relu3_1
I1211 14:11:15.514385 16720 net.cpp:406] relu3_1 <- conv3_1
I1211 14:11:15.514385 16720 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 14:11:15.514385 16720 net.cpp:122] Setting up relu3_1
I1211 14:11:15.514385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.514385 16720 net.cpp:137] Memory required for data: 390350000
I1211 14:11:15.514385 16720 layer_factory.cpp:58] Creating layer conv4
I1211 14:11:15.514385 16720 net.cpp:84] Creating Layer conv4
I1211 14:11:15.514385 16720 net.cpp:406] conv4 <- conv3_1
I1211 14:11:15.514385 16720 net.cpp:380] conv4 -> conv4
I1211 14:11:15.516376 16720 net.cpp:122] Setting up conv4
I1211 14:11:15.516376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.516376 16720 net.cpp:137] Memory required for data: 395470000
I1211 14:11:15.516376 16720 layer_factory.cpp:58] Creating layer bn4
I1211 14:11:15.516376 16720 net.cpp:84] Creating Layer bn4
I1211 14:11:15.516376 16720 net.cpp:406] bn4 <- conv4
I1211 14:11:15.516376 16720 net.cpp:367] bn4 -> conv4 (in-place)
I1211 14:11:15.516376 16720 net.cpp:122] Setting up bn4
I1211 14:11:15.516376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.516376 16720 net.cpp:137] Memory required for data: 400590000
I1211 14:11:15.516376 16720 layer_factory.cpp:58] Creating layer scale4
I1211 14:11:15.516376 16720 net.cpp:84] Creating Layer scale4
I1211 14:11:15.516376 16720 net.cpp:406] scale4 <- conv4
I1211 14:11:15.516376 16720 net.cpp:367] scale4 -> conv4 (in-place)
I1211 14:11:15.516376 16720 layer_factory.cpp:58] Creating layer scale4
I1211 14:11:15.516376 16720 net.cpp:122] Setting up scale4
I1211 14:11:15.516376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.516376 16720 net.cpp:137] Memory required for data: 405710000
I1211 14:11:15.516376 16720 layer_factory.cpp:58] Creating layer relu4
I1211 14:11:15.516376 16720 net.cpp:84] Creating Layer relu4
I1211 14:11:15.516376 16720 net.cpp:406] relu4 <- conv4
I1211 14:11:15.516376 16720 net.cpp:367] relu4 -> conv4 (in-place)
I1211 14:11:15.517380 16720 net.cpp:122] Setting up relu4
I1211 14:11:15.517380 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.517380 16720 net.cpp:137] Memory required for data: 410830000
I1211 14:11:15.517380 16720 layer_factory.cpp:58] Creating layer conv4_1
I1211 14:11:15.517380 16720 net.cpp:84] Creating Layer conv4_1
I1211 14:11:15.517380 16720 net.cpp:406] conv4_1 <- conv4
I1211 14:11:15.517380 16720 net.cpp:380] conv4_1 -> conv4_1
I1211 14:11:15.518385 16720 net.cpp:122] Setting up conv4_1
I1211 14:11:15.518385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.518385 16720 net.cpp:137] Memory required for data: 415950000
I1211 14:11:15.518385 16720 layer_factory.cpp:58] Creating layer bn4_1
I1211 14:11:15.518385 16720 net.cpp:84] Creating Layer bn4_1
I1211 14:11:15.518385 16720 net.cpp:406] bn4_1 <- conv4_1
I1211 14:11:15.518385 16720 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 14:11:15.518385 16720 net.cpp:122] Setting up bn4_1
I1211 14:11:15.518385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.518385 16720 net.cpp:137] Memory required for data: 421070000
I1211 14:11:15.518385 16720 layer_factory.cpp:58] Creating layer scale4_1
I1211 14:11:15.518385 16720 net.cpp:84] Creating Layer scale4_1
I1211 14:11:15.518385 16720 net.cpp:406] scale4_1 <- conv4_1
I1211 14:11:15.518385 16720 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 14:11:15.518385 16720 layer_factory.cpp:58] Creating layer scale4_1
I1211 14:11:15.518385 16720 net.cpp:122] Setting up scale4_1
I1211 14:11:15.518385 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.518385 16720 net.cpp:137] Memory required for data: 426190000
I1211 14:11:15.518385 16720 layer_factory.cpp:58] Creating layer relu4_1
I1211 14:11:15.518385 16720 net.cpp:84] Creating Layer relu4_1
I1211 14:11:15.518385 16720 net.cpp:406] relu4_1 <- conv4_1
I1211 14:11:15.518385 16720 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 14:11:15.519376 16720 net.cpp:122] Setting up relu4_1
I1211 14:11:15.519376 16720 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 14:11:15.519376 16720 net.cpp:137] Memory required for data: 431310000
I1211 14:11:15.519376 16720 layer_factory.cpp:58] Creating layer conv4_2
I1211 14:11:15.519376 16720 net.cpp:84] Creating Layer conv4_2
I1211 14:11:15.519376 16720 net.cpp:406] conv4_2 <- conv4_1
I1211 14:11:15.519376 16720 net.cpp:380] conv4_2 -> conv4_2
I1211 14:11:15.520376 16720 net.cpp:122] Setting up conv4_2
I1211 14:11:15.520376 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.520376 16720 net.cpp:137] Memory required for data: 437249200
I1211 14:11:15.520376 16720 layer_factory.cpp:58] Creating layer bn4_2
I1211 14:11:15.520376 16720 net.cpp:84] Creating Layer bn4_2
I1211 14:11:15.520376 16720 net.cpp:406] bn4_2 <- conv4_2
I1211 14:11:15.520376 16720 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 14:11:15.520376 16720 net.cpp:122] Setting up bn4_2
I1211 14:11:15.520376 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.520376 16720 net.cpp:137] Memory required for data: 443188400
I1211 14:11:15.520376 16720 layer_factory.cpp:58] Creating layer scale4_2
I1211 14:11:15.520376 16720 net.cpp:84] Creating Layer scale4_2
I1211 14:11:15.520376 16720 net.cpp:406] scale4_2 <- conv4_2
I1211 14:11:15.520376 16720 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 14:11:15.521375 16720 layer_factory.cpp:58] Creating layer scale4_2
I1211 14:11:15.521375 16720 net.cpp:122] Setting up scale4_2
I1211 14:11:15.521375 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.521375 16720 net.cpp:137] Memory required for data: 449127600
I1211 14:11:15.521375 16720 layer_factory.cpp:58] Creating layer relu4_2
I1211 14:11:15.521375 16720 net.cpp:84] Creating Layer relu4_2
I1211 14:11:15.521375 16720 net.cpp:406] relu4_2 <- conv4_2
I1211 14:11:15.521375 16720 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 14:11:15.521375 16720 net.cpp:122] Setting up relu4_2
I1211 14:11:15.521375 16720 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 14:11:15.521375 16720 net.cpp:137] Memory required for data: 455066800
I1211 14:11:15.521375 16720 layer_factory.cpp:58] Creating layer pool4_2
I1211 14:11:15.521375 16720 net.cpp:84] Creating Layer pool4_2
I1211 14:11:15.521375 16720 net.cpp:406] pool4_2 <- conv4_2
I1211 14:11:15.521375 16720 net.cpp:380] pool4_2 -> pool4_2
I1211 14:11:15.522377 16720 net.cpp:122] Setting up pool4_2
I1211 14:11:15.522377 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.522377 16720 net.cpp:137] Memory required for data: 456551600
I1211 14:11:15.522377 16720 layer_factory.cpp:58] Creating layer bn4_pool4_2
I1211 14:11:15.522377 16720 net.cpp:84] Creating Layer bn4_pool4_2
I1211 14:11:15.522377 16720 net.cpp:406] bn4_pool4_2 <- pool4_2
I1211 14:11:15.522377 16720 net.cpp:367] bn4_pool4_2 -> pool4_2 (in-place)
I1211 14:11:15.522377 16720 net.cpp:122] Setting up bn4_pool4_2
I1211 14:11:15.522377 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.522377 16720 net.cpp:137] Memory required for data: 458036400
I1211 14:11:15.522377 16720 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 14:11:15.523375 16720 net.cpp:84] Creating Layer scale4_pool4_2
I1211 14:11:15.523375 16720 net.cpp:406] scale4_pool4_2 <- pool4_2
I1211 14:11:15.523375 16720 net.cpp:367] scale4_pool4_2 -> pool4_2 (in-place)
I1211 14:11:15.523375 16720 layer_factory.cpp:58] Creating layer scale4_pool4_2
I1211 14:11:15.523375 16720 net.cpp:122] Setting up scale4_pool4_2
I1211 14:11:15.523375 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.523375 16720 net.cpp:137] Memory required for data: 459521200
I1211 14:11:15.523375 16720 layer_factory.cpp:58] Creating layer relu4_pool4_2
I1211 14:11:15.523375 16720 net.cpp:84] Creating Layer relu4_pool4_2
I1211 14:11:15.523375 16720 net.cpp:406] relu4_pool4_2 <- pool4_2
I1211 14:11:15.523375 16720 net.cpp:367] relu4_pool4_2 -> pool4_2 (in-place)
I1211 14:11:15.523375 16720 net.cpp:122] Setting up relu4_pool4_2
I1211 14:11:15.524375 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.524375 16720 net.cpp:137] Memory required for data: 461006000
I1211 14:11:15.524375 16720 layer_factory.cpp:58] Creating layer conv4_0
I1211 14:11:15.524375 16720 net.cpp:84] Creating Layer conv4_0
I1211 14:11:15.524375 16720 net.cpp:406] conv4_0 <- pool4_2
I1211 14:11:15.524375 16720 net.cpp:380] conv4_0 -> conv4_0
I1211 14:11:15.525377 16720 net.cpp:122] Setting up conv4_0
I1211 14:11:15.525377 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.525377 16720 net.cpp:137] Memory required for data: 462490800
I1211 14:11:15.525377 16720 layer_factory.cpp:58] Creating layer bn4_0
I1211 14:11:15.525377 16720 net.cpp:84] Creating Layer bn4_0
I1211 14:11:15.525377 16720 net.cpp:406] bn4_0 <- conv4_0
I1211 14:11:15.525377 16720 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 14:11:15.526376 16720 net.cpp:122] Setting up bn4_0
I1211 14:11:15.526376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.526376 16720 net.cpp:137] Memory required for data: 463975600
I1211 14:11:15.526376 16720 layer_factory.cpp:58] Creating layer scale4_0
I1211 14:11:15.526376 16720 net.cpp:84] Creating Layer scale4_0
I1211 14:11:15.526376 16720 net.cpp:406] scale4_0 <- conv4_0
I1211 14:11:15.526376 16720 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 14:11:15.526376 16720 layer_factory.cpp:58] Creating layer scale4_0
I1211 14:11:15.526376 16720 net.cpp:122] Setting up scale4_0
I1211 14:11:15.526376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.526376 16720 net.cpp:137] Memory required for data: 465460400
I1211 14:11:15.526376 16720 layer_factory.cpp:58] Creating layer relu4_0
I1211 14:11:15.526376 16720 net.cpp:84] Creating Layer relu4_0
I1211 14:11:15.526376 16720 net.cpp:406] relu4_0 <- conv4_0
I1211 14:11:15.526376 16720 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 14:11:15.526376 16720 net.cpp:122] Setting up relu4_0
I1211 14:11:15.526376 16720 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 14:11:15.526376 16720 net.cpp:137] Memory required for data: 466945200
I1211 14:11:15.526376 16720 layer_factory.cpp:58] Creating layer conv11
I1211 14:11:15.526376 16720 net.cpp:84] Creating Layer conv11
I1211 14:11:15.526376 16720 net.cpp:406] conv11 <- conv4_0
I1211 14:11:15.527375 16720 net.cpp:380] conv11 -> conv11
I1211 14:11:15.528887 16720 net.cpp:122] Setting up conv11
I1211 14:11:15.528887 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.528887 16720 net.cpp:137] Memory required for data: 468737200
I1211 14:11:15.528887 16720 layer_factory.cpp:58] Creating layer bn_conv11
I1211 14:11:15.528887 16720 net.cpp:84] Creating Layer bn_conv11
I1211 14:11:15.528887 16720 net.cpp:406] bn_conv11 <- conv11
I1211 14:11:15.528887 16720 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 14:11:15.528887 16720 net.cpp:122] Setting up bn_conv11
I1211 14:11:15.528887 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.528887 16720 net.cpp:137] Memory required for data: 470529200
I1211 14:11:15.528887 16720 layer_factory.cpp:58] Creating layer scale_conv11
I1211 14:11:15.528887 16720 net.cpp:84] Creating Layer scale_conv11
I1211 14:11:15.528887 16720 net.cpp:406] scale_conv11 <- conv11
I1211 14:11:15.528887 16720 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 14:11:15.528887 16720 layer_factory.cpp:58] Creating layer scale_conv11
I1211 14:11:15.528887 16720 net.cpp:122] Setting up scale_conv11
I1211 14:11:15.528887 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.528887 16720 net.cpp:137] Memory required for data: 472321200
I1211 14:11:15.528887 16720 layer_factory.cpp:58] Creating layer relu_conv11
I1211 14:11:15.529381 16720 net.cpp:84] Creating Layer relu_conv11
I1211 14:11:15.529381 16720 net.cpp:406] relu_conv11 <- conv11
I1211 14:11:15.529381 16720 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 14:11:15.529381 16720 net.cpp:122] Setting up relu_conv11
I1211 14:11:15.529381 16720 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 14:11:15.529381 16720 net.cpp:137] Memory required for data: 474113200
I1211 14:11:15.529381 16720 layer_factory.cpp:58] Creating layer conv12
I1211 14:11:15.529381 16720 net.cpp:84] Creating Layer conv12
I1211 14:11:15.529381 16720 net.cpp:406] conv12 <- conv11
I1211 14:11:15.529381 16720 net.cpp:380] conv12 -> conv12
I1211 14:11:15.531380 16720 net.cpp:122] Setting up conv12
I1211 14:11:15.531380 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.531380 16720 net.cpp:137] Memory required for data: 476417200
I1211 14:11:15.531380 16720 layer_factory.cpp:58] Creating layer bn_conv12
I1211 14:11:15.531380 16720 net.cpp:84] Creating Layer bn_conv12
I1211 14:11:15.531380 16720 net.cpp:406] bn_conv12 <- conv12
I1211 14:11:15.531380 16720 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 14:11:15.531380 16720 net.cpp:122] Setting up bn_conv12
I1211 14:11:15.531380 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.531380 16720 net.cpp:137] Memory required for data: 478721200
I1211 14:11:15.531380 16720 layer_factory.cpp:58] Creating layer scale_conv12
I1211 14:11:15.531380 16720 net.cpp:84] Creating Layer scale_conv12
I1211 14:11:15.531380 16720 net.cpp:406] scale_conv12 <- conv12
I1211 14:11:15.531380 16720 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 14:11:15.531380 16720 layer_factory.cpp:58] Creating layer scale_conv12
I1211 14:11:15.531880 16720 net.cpp:122] Setting up scale_conv12
I1211 14:11:15.531880 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.531880 16720 net.cpp:137] Memory required for data: 481025200
I1211 14:11:15.531880 16720 layer_factory.cpp:58] Creating layer relu_conv12
I1211 14:11:15.531880 16720 net.cpp:84] Creating Layer relu_conv12
I1211 14:11:15.531880 16720 net.cpp:406] relu_conv12 <- conv12
I1211 14:11:15.531880 16720 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 14:11:15.531880 16720 net.cpp:122] Setting up relu_conv12
I1211 14:11:15.531880 16720 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 14:11:15.531880 16720 net.cpp:137] Memory required for data: 483329200
I1211 14:11:15.531880 16720 layer_factory.cpp:58] Creating layer poolcp6
I1211 14:11:15.531880 16720 net.cpp:84] Creating Layer poolcp6
I1211 14:11:15.531880 16720 net.cpp:406] poolcp6 <- conv12
I1211 14:11:15.531880 16720 net.cpp:380] poolcp6 -> poolcp6
I1211 14:11:15.531880 16720 net.cpp:122] Setting up poolcp6
I1211 14:11:15.531880 16720 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 14:11:15.531880 16720 net.cpp:137] Memory required for data: 483365200
I1211 14:11:15.531880 16720 layer_factory.cpp:58] Creating layer ip1
I1211 14:11:15.531880 16720 net.cpp:84] Creating Layer ip1
I1211 14:11:15.531880 16720 net.cpp:406] ip1 <- poolcp6
I1211 14:11:15.531880 16720 net.cpp:380] ip1 -> ip1
I1211 14:11:15.532380 16720 net.cpp:122] Setting up ip1
I1211 14:11:15.532380 16720 net.cpp:129] Top shape: 100 100 (10000)
I1211 14:11:15.532380 16720 net.cpp:137] Memory required for data: 483405200
I1211 14:11:15.532380 16720 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 14:11:15.532380 16720 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 14:11:15.532380 16720 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 14:11:15.532380 16720 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 14:11:15.532380 16720 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 14:11:15.532380 16720 net.cpp:122] Setting up ip1_ip1_0_split
I1211 14:11:15.532380 16720 net.cpp:129] Top shape: 100 100 (10000)
I1211 14:11:15.532380 16720 net.cpp:129] Top shape: 100 100 (10000)
I1211 14:11:15.532380 16720 net.cpp:137] Memory required for data: 483485200
I1211 14:11:15.532380 16720 layer_factory.cpp:58] Creating layer accuracy
I1211 14:11:15.532380 16720 net.cpp:84] Creating Layer accuracy
I1211 14:11:15.532380 16720 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1211 14:11:15.532380 16720 net.cpp:406] accuracy <- label_cifar_1_split_0
I1211 14:11:15.532380 16720 net.cpp:380] accuracy -> accuracy
I1211 14:11:15.532380 16720 net.cpp:122] Setting up accuracy
I1211 14:11:15.532380 16720 net.cpp:129] Top shape: (1)
I1211 14:11:15.532380 16720 net.cpp:137] Memory required for data: 483485204
I1211 14:11:15.532380 16720 layer_factory.cpp:58] Creating layer loss
I1211 14:11:15.532380 16720 net.cpp:84] Creating Layer loss
I1211 14:11:15.532380 16720 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 14:11:15.532380 16720 net.cpp:406] loss <- label_cifar_1_split_1
I1211 14:11:15.532380 16720 net.cpp:380] loss -> loss
I1211 14:11:15.532380 16720 layer_factory.cpp:58] Creating layer loss
I1211 14:11:15.532881 16720 net.cpp:122] Setting up loss
I1211 14:11:15.532881 16720 net.cpp:129] Top shape: (1)
I1211 14:11:15.532881 16720 net.cpp:132]     with loss weight 1
I1211 14:11:15.532881 16720 net.cpp:137] Memory required for data: 483485208
I1211 14:11:15.532881 16720 net.cpp:198] loss needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:200] accuracy does not need backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] ip1 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] poolcp6 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu_conv12 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale_conv12 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] bn_conv12 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] conv12 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu_conv11 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale_conv11 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] bn_conv11 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] conv11 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu4_0 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale4_0 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] bn4_0 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] conv4_0 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu4_pool4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale4_pool4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] bn4_pool4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] pool4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] bn4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] conv4_2 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu4_1 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale4_1 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] bn4_1 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] conv4_1 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] relu4 needs backward computation.
I1211 14:11:15.532881 16720 net.cpp:198] scale4 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn4 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv4 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu3_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale3_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn3_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv3_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu3 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale3 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn3 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv3 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu2_pool2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale2_pool2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn2_pool2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] pool2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu2_2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale2_2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn2_2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv2_2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv2_1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv2 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu1_0 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale1_0 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn1_0 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv1_0 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] relu1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] scale1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] bn1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:198] conv1 needs backward computation.
I1211 14:11:15.533380 16720 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 14:11:15.533380 16720 net.cpp:200] cifar does not need backward computation.
I1211 14:11:15.533380 16720 net.cpp:242] This network produces output accuracy
I1211 14:11:15.533380 16720 net.cpp:242] This network produces output loss
I1211 14:11:15.533380 16720 net.cpp:255] Network initialization done.
I1211 14:11:15.533380 16720 solver.cpp:56] Solver scaffolding done.
I1211 14:11:15.538380 16720 caffe.cpp:249] Starting Optimization
I1211 14:11:15.538380 16720 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_stridedConvV2_WnonLin_360k
I1211 14:11:15.538380 16720 solver.cpp:273] Learning Rate Policy: multistep
I1211 14:11:15.542379 16720 solver.cpp:330] Iteration 0, Testing net (#0)
I1211 14:11:15.544384 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:11:16.938985 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:11:16.991488 16720 solver.cpp:397]     Test net output #0: accuracy = 0.0108
I1211 14:11:16.991488 16720 solver.cpp:397]     Test net output #1: loss = 86.3933 (* 1 = 86.3933 loss)
I1211 14:11:17.103190 16720 solver.cpp:218] Iteration 0 (0 iter/s, 1.56362s/100 iters), loss = 6.72688
I1211 14:11:17.103190 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.01
I1211 14:11:17.103190 16720 solver.cpp:237]     Train net output #1: loss = 6.72688 (* 1 = 6.72688 loss)
I1211 14:11:17.103190 16720 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1211 14:11:23.256767 16720 solver.cpp:218] Iteration 100 (16.2509 iter/s, 6.15352s/100 iters), loss = 4.59078
I1211 14:11:23.256767 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.01
I1211 14:11:23.256767 16720 solver.cpp:237]     Train net output #1: loss = 4.59078 (* 1 = 4.59078 loss)
I1211 14:11:23.256767 16720 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1211 14:11:29.423898 16720 solver.cpp:218] Iteration 200 (16.2175 iter/s, 6.1662s/100 iters), loss = 4.49598
I1211 14:11:29.423898 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.02
I1211 14:11:29.423898 16720 solver.cpp:237]     Train net output #1: loss = 4.49598 (* 1 = 4.49598 loss)
I1211 14:11:29.423898 16720 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1211 14:11:35.558140 16720 solver.cpp:218] Iteration 300 (16.3018 iter/s, 6.1343s/100 iters), loss = 4.1771
I1211 14:11:35.558140 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1211 14:11:35.558140 16720 solver.cpp:237]     Train net output #1: loss = 4.1771 (* 1 = 4.1771 loss)
I1211 14:11:35.558140 16720 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1211 14:11:41.685930 16720 solver.cpp:218] Iteration 400 (16.3206 iter/s, 6.12722s/100 iters), loss = 4.10751
I1211 14:11:41.685930 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1211 14:11:41.685930 16720 solver.cpp:237]     Train net output #1: loss = 4.10751 (* 1 = 4.10751 loss)
I1211 14:11:41.685930 16720 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1211 14:11:47.524073  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:11:47.766217 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_500.caffemodel
I1211 14:11:47.791216 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_500.solverstate
I1211 14:11:47.796221 16720 solver.cpp:330] Iteration 500, Testing net (#0)
I1211 14:11:47.796221 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:11:49.133906 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:11:49.186498 16720 solver.cpp:397]     Test net output #0: accuracy = 0.0347
I1211 14:11:49.186498 16720 solver.cpp:397]     Test net output #1: loss = 4.43089 (* 1 = 4.43089 loss)
I1211 14:11:49.246495 16720 solver.cpp:218] Iteration 500 (13.2284 iter/s, 7.55948s/100 iters), loss = 3.92935
I1211 14:11:49.246495 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1211 14:11:49.246495 16720 solver.cpp:237]     Train net output #1: loss = 3.92935 (* 1 = 3.92935 loss)
I1211 14:11:49.246495 16720 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1211 14:11:55.465678 16720 solver.cpp:218] Iteration 600 (16.0798 iter/s, 6.21898s/100 iters), loss = 3.9074
I1211 14:11:55.465678 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.07
I1211 14:11:55.465678 16720 solver.cpp:237]     Train net output #1: loss = 3.9074 (* 1 = 3.9074 loss)
I1211 14:11:55.465678 16720 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1211 14:12:01.641664 16720 solver.cpp:218] Iteration 700 (16.1917 iter/s, 6.17602s/100 iters), loss = 3.75982
I1211 14:12:01.641664 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1211 14:12:01.641664 16720 solver.cpp:237]     Train net output #1: loss = 3.75982 (* 1 = 3.75982 loss)
I1211 14:12:01.641664 16720 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1211 14:12:07.859704 16720 solver.cpp:218] Iteration 800 (16.0851 iter/s, 6.21694s/100 iters), loss = 3.79299
I1211 14:12:07.859704 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1211 14:12:07.859704 16720 solver.cpp:237]     Train net output #1: loss = 3.79299 (* 1 = 3.79299 loss)
I1211 14:12:07.859704 16720 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1211 14:12:14.051560 16720 solver.cpp:218] Iteration 900 (16.1519 iter/s, 6.1912s/100 iters), loss = 3.7028
I1211 14:12:14.051560 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I1211 14:12:14.051560 16720 solver.cpp:237]     Train net output #1: loss = 3.7028 (* 1 = 3.7028 loss)
I1211 14:12:14.051560 16720 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1211 14:12:19.918759  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:12:20.161350 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_1000.caffemodel
I1211 14:12:20.175578 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_1000.solverstate
I1211 14:12:20.180574 16720 solver.cpp:330] Iteration 1000, Testing net (#0)
I1211 14:12:20.181574 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:12:21.513815 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:12:21.566843 16720 solver.cpp:397]     Test net output #0: accuracy = 0.0947
I1211 14:12:21.566843 16720 solver.cpp:397]     Test net output #1: loss = 4.00433 (* 1 = 4.00433 loss)
I1211 14:12:21.625780 16720 solver.cpp:218] Iteration 1000 (13.2027 iter/s, 7.57419s/100 iters), loss = 3.59272
I1211 14:12:21.625780 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.15
I1211 14:12:21.625780 16720 solver.cpp:237]     Train net output #1: loss = 3.59272 (* 1 = 3.59272 loss)
I1211 14:12:21.625780 16720 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1211 14:12:27.766846 16720 solver.cpp:218] Iteration 1100 (16.2856 iter/s, 6.14038s/100 iters), loss = 3.61136
I1211 14:12:27.766846 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1211 14:12:27.766846 16720 solver.cpp:237]     Train net output #1: loss = 3.61136 (* 1 = 3.61136 loss)
I1211 14:12:27.766846 16720 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1211 14:12:33.920236 16720 solver.cpp:218] Iteration 1200 (16.2519 iter/s, 6.15311s/100 iters), loss = 3.29785
I1211 14:12:33.920236 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 14:12:33.920236 16720 solver.cpp:237]     Train net output #1: loss = 3.29785 (* 1 = 3.29785 loss)
I1211 14:12:33.920236 16720 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1211 14:12:40.076154 16720 solver.cpp:218] Iteration 1300 (16.2467 iter/s, 6.15511s/100 iters), loss = 3.39599
I1211 14:12:40.076154 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.21
I1211 14:12:40.076154 16720 solver.cpp:237]     Train net output #1: loss = 3.39599 (* 1 = 3.39599 loss)
I1211 14:12:40.076154 16720 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1211 14:12:46.228093 16720 solver.cpp:218] Iteration 1400 (16.2546 iter/s, 6.15211s/100 iters), loss = 3.65125
I1211 14:12:46.228093 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1211 14:12:46.228093 16720 solver.cpp:237]     Train net output #1: loss = 3.65125 (* 1 = 3.65125 loss)
I1211 14:12:46.228093 16720 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1211 14:12:52.077462  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:12:52.319483 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_1500.caffemodel
I1211 14:12:52.334482 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_1500.solverstate
I1211 14:12:52.338482 16720 solver.cpp:330] Iteration 1500, Testing net (#0)
I1211 14:12:52.339483 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:12:53.673758 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:12:53.725761 16720 solver.cpp:397]     Test net output #0: accuracy = 0.1205
I1211 14:12:53.725761 16720 solver.cpp:397]     Test net output #1: loss = 3.82043 (* 1 = 3.82043 loss)
I1211 14:12:53.784767 16720 solver.cpp:218] Iteration 1500 (13.2342 iter/s, 7.55617s/100 iters), loss = 3.23677
I1211 14:12:53.784767 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1211 14:12:53.784767 16720 solver.cpp:237]     Train net output #1: loss = 3.23677 (* 1 = 3.23677 loss)
I1211 14:12:53.784767 16720 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1211 14:12:59.939236 16720 solver.cpp:218] Iteration 1600 (16.2501 iter/s, 6.1538s/100 iters), loss = 3.29896
I1211 14:12:59.939236 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I1211 14:12:59.939236 16720 solver.cpp:237]     Train net output #1: loss = 3.29896 (* 1 = 3.29896 loss)
I1211 14:12:59.939236 16720 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1211 14:13:06.100687 16720 solver.cpp:218] Iteration 1700 (16.2314 iter/s, 6.1609s/100 iters), loss = 2.93783
I1211 14:13:06.100687 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1211 14:13:06.100687 16720 solver.cpp:237]     Train net output #1: loss = 2.93783 (* 1 = 2.93783 loss)
I1211 14:13:06.100687 16720 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1211 14:13:12.251176 16720 solver.cpp:218] Iteration 1800 (16.2588 iter/s, 6.15052s/100 iters), loss = 3.1744
I1211 14:13:12.251176 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.21
I1211 14:13:12.251176 16720 solver.cpp:237]     Train net output #1: loss = 3.1744 (* 1 = 3.1744 loss)
I1211 14:13:12.251176 16720 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1211 14:13:18.431167 16720 solver.cpp:218] Iteration 1900 (16.182 iter/s, 6.17969s/100 iters), loss = 3.24461
I1211 14:13:18.431167 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.14
I1211 14:13:18.431167 16720 solver.cpp:237]     Train net output #1: loss = 3.24461 (* 1 = 3.24461 loss)
I1211 14:13:18.432173 16720 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1211 14:13:24.326848  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:13:24.569903 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_2000.caffemodel
I1211 14:13:24.584910 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_2000.solverstate
I1211 14:13:24.588908 16720 solver.cpp:330] Iteration 2000, Testing net (#0)
I1211 14:13:24.589912 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:13:25.938848 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:13:25.991849 16720 solver.cpp:397]     Test net output #0: accuracy = 0.128
I1211 14:13:25.991849 16720 solver.cpp:397]     Test net output #1: loss = 3.75164 (* 1 = 3.75164 loss)
I1211 14:13:26.050865 16720 solver.cpp:218] Iteration 2000 (13.1259 iter/s, 7.61853s/100 iters), loss = 3.02385
I1211 14:13:26.050865 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1211 14:13:26.050865 16720 solver.cpp:237]     Train net output #1: loss = 3.02385 (* 1 = 3.02385 loss)
I1211 14:13:26.050865 16720 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1211 14:13:32.344959 16720 solver.cpp:218] Iteration 2100 (15.8878 iter/s, 6.29414s/100 iters), loss = 3.05835
I1211 14:13:32.344959 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 14:13:32.344959 16720 solver.cpp:237]     Train net output #1: loss = 3.05835 (* 1 = 3.05835 loss)
I1211 14:13:32.344959 16720 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1211 14:13:38.577563 16720 solver.cpp:218] Iteration 2200 (16.047 iter/s, 6.23171s/100 iters), loss = 2.74839
I1211 14:13:38.578068 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 14:13:38.578068 16720 solver.cpp:237]     Train net output #1: loss = 2.74839 (* 1 = 2.74839 loss)
I1211 14:13:38.578068 16720 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1211 14:13:44.867257 16720 solver.cpp:218] Iteration 2300 (15.9005 iter/s, 6.28912s/100 iters), loss = 2.92242
I1211 14:13:44.867257 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1211 14:13:44.867257 16720 solver.cpp:237]     Train net output #1: loss = 2.92242 (* 1 = 2.92242 loss)
I1211 14:13:44.867257 16720 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1211 14:13:51.187449 16720 solver.cpp:218] Iteration 2400 (15.8236 iter/s, 6.31967s/100 iters), loss = 2.814
I1211 14:13:51.187449 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1211 14:13:51.187449 16720 solver.cpp:237]     Train net output #1: loss = 2.814 (* 1 = 2.814 loss)
I1211 14:13:51.187449 16720 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1211 14:13:57.118088  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:13:57.366477 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_2500.caffemodel
I1211 14:13:57.382987 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_2500.solverstate
I1211 14:13:57.388483 16720 solver.cpp:330] Iteration 2500, Testing net (#0)
I1211 14:13:57.388983 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:13:58.776168 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:13:58.831209 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2294
I1211 14:13:58.831209 16720 solver.cpp:397]     Test net output #1: loss = 3.13224 (* 1 = 3.13224 loss)
I1211 14:13:58.892709 16720 solver.cpp:218] Iteration 2500 (12.9792 iter/s, 7.70464s/100 iters), loss = 2.62707
I1211 14:13:58.892709 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 14:13:58.892709 16720 solver.cpp:237]     Train net output #1: loss = 2.62707 (* 1 = 2.62707 loss)
I1211 14:13:58.892709 16720 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1211 14:14:05.088711 16720 solver.cpp:218] Iteration 2600 (16.1411 iter/s, 6.19535s/100 iters), loss = 2.76252
I1211 14:14:05.088711 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1211 14:14:05.088711 16720 solver.cpp:237]     Train net output #1: loss = 2.76252 (* 1 = 2.76252 loss)
I1211 14:14:05.088711 16720 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1211 14:14:11.244148 16720 solver.cpp:218] Iteration 2700 (16.2471 iter/s, 6.15493s/100 iters), loss = 2.44196
I1211 14:14:11.244148 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 14:14:11.244148 16720 solver.cpp:237]     Train net output #1: loss = 2.44196 (* 1 = 2.44196 loss)
I1211 14:14:11.244148 16720 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1211 14:14:17.406597 16720 solver.cpp:218] Iteration 2800 (16.226 iter/s, 6.16296s/100 iters), loss = 2.84029
I1211 14:14:17.406597 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1211 14:14:17.407598 16720 solver.cpp:237]     Train net output #1: loss = 2.84029 (* 1 = 2.84029 loss)
I1211 14:14:17.407598 16720 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1211 14:14:23.807207 16720 solver.cpp:218] Iteration 2900 (15.6259 iter/s, 6.39964s/100 iters), loss = 2.68844
I1211 14:14:23.807207 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1211 14:14:23.807207 16720 solver.cpp:237]     Train net output #1: loss = 2.68844 (* 1 = 2.68844 loss)
I1211 14:14:23.807207 16720 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1211 14:14:29.898610  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:14:30.150707 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_3000.caffemodel
I1211 14:14:30.167707 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_3000.solverstate
I1211 14:14:30.172706 16720 solver.cpp:330] Iteration 3000, Testing net (#0)
I1211 14:14:30.172706 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:14:31.556139 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:14:31.609737 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2377
I1211 14:14:31.609737 16720 solver.cpp:397]     Test net output #1: loss = 3.07581 (* 1 = 3.07581 loss)
I1211 14:14:31.670732 16720 solver.cpp:218] Iteration 3000 (12.7171 iter/s, 7.86345s/100 iters), loss = 2.63285
I1211 14:14:31.670732 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1211 14:14:31.670732 16720 solver.cpp:237]     Train net output #1: loss = 2.63285 (* 1 = 2.63285 loss)
I1211 14:14:31.670732 16720 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1211 14:14:38.092130 16720 solver.cpp:218] Iteration 3100 (15.5759 iter/s, 6.42018s/100 iters), loss = 2.55431
I1211 14:14:38.092130 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1211 14:14:38.092130 16720 solver.cpp:237]     Train net output #1: loss = 2.55431 (* 1 = 2.55431 loss)
I1211 14:14:38.092130 16720 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1211 14:14:44.612135 16720 solver.cpp:218] Iteration 3200 (15.3378 iter/s, 6.51985s/100 iters), loss = 2.29635
I1211 14:14:44.612135 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 14:14:44.612135 16720 solver.cpp:237]     Train net output #1: loss = 2.29635 (* 1 = 2.29635 loss)
I1211 14:14:44.612135 16720 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1211 14:14:51.127132 16720 solver.cpp:218] Iteration 3300 (15.3503 iter/s, 6.51452s/100 iters), loss = 2.56228
I1211 14:14:51.128132 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 14:14:51.128132 16720 solver.cpp:237]     Train net output #1: loss = 2.56228 (* 1 = 2.56228 loss)
I1211 14:14:51.128132 16720 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1211 14:14:57.651655 16720 solver.cpp:218] Iteration 3400 (15.3302 iter/s, 6.52307s/100 iters), loss = 2.66858
I1211 14:14:57.651655 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.26
I1211 14:14:57.651655 16720 solver.cpp:237]     Train net output #1: loss = 2.66858 (* 1 = 2.66858 loss)
I1211 14:14:57.651655 16720 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1211 14:15:03.843477  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:15:04.101991 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_3500.caffemodel
I1211 14:15:04.118500 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_3500.solverstate
I1211 14:15:04.123495 16720 solver.cpp:330] Iteration 3500, Testing net (#0)
I1211 14:15:04.123495 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:15:05.541777 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:15:05.586776 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2621
I1211 14:15:05.586776 16720 solver.cpp:397]     Test net output #1: loss = 2.93483 (* 1 = 2.93483 loss)
I1211 14:15:05.648793 16720 solver.cpp:218] Iteration 3500 (12.5049 iter/s, 7.99688s/100 iters), loss = 2.45182
I1211 14:15:05.648793 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 14:15:05.648793 16720 solver.cpp:237]     Train net output #1: loss = 2.45182 (* 1 = 2.45182 loss)
I1211 14:15:05.648793 16720 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1211 14:15:12.028627 16720 solver.cpp:218] Iteration 3600 (15.6755 iter/s, 6.37937s/100 iters), loss = 2.3291
I1211 14:15:12.028627 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 14:15:12.028627 16720 solver.cpp:237]     Train net output #1: loss = 2.3291 (* 1 = 2.3291 loss)
I1211 14:15:12.028627 16720 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1211 14:15:18.472568 16720 solver.cpp:218] Iteration 3700 (15.521 iter/s, 6.44288s/100 iters), loss = 2.14525
I1211 14:15:18.472568 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 14:15:18.472568 16720 solver.cpp:237]     Train net output #1: loss = 2.14525 (* 1 = 2.14525 loss)
I1211 14:15:18.472568 16720 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1211 14:15:24.948360 16720 solver.cpp:218] Iteration 3800 (15.442 iter/s, 6.47585s/100 iters), loss = 2.44714
I1211 14:15:24.948360 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1211 14:15:24.948360 16720 solver.cpp:237]     Train net output #1: loss = 2.44714 (* 1 = 2.44714 loss)
I1211 14:15:24.948360 16720 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1211 14:15:31.416677 16720 solver.cpp:218] Iteration 3900 (15.4623 iter/s, 6.46736s/100 iters), loss = 2.41937
I1211 14:15:31.416677 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 14:15:31.416677 16720 solver.cpp:237]     Train net output #1: loss = 2.41937 (* 1 = 2.41937 loss)
I1211 14:15:31.416677 16720 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1211 14:15:37.449075  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:15:37.698084 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_4000.caffemodel
I1211 14:15:37.715090 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_4000.solverstate
I1211 14:15:37.720088 16720 solver.cpp:330] Iteration 4000, Testing net (#0)
I1211 14:15:37.720088 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:15:39.096344 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:15:39.150360 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2526
I1211 14:15:39.150360 16720 solver.cpp:397]     Test net output #1: loss = 3.06125 (* 1 = 3.06125 loss)
I1211 14:15:39.210372 16720 solver.cpp:218] Iteration 4000 (12.8315 iter/s, 7.79331s/100 iters), loss = 2.37595
I1211 14:15:39.210372 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 14:15:39.210372 16720 solver.cpp:237]     Train net output #1: loss = 2.37595 (* 1 = 2.37595 loss)
I1211 14:15:39.210372 16720 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1211 14:15:45.502946 16720 solver.cpp:218] Iteration 4100 (15.8939 iter/s, 6.29171s/100 iters), loss = 2.23653
I1211 14:15:45.502946 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:15:45.502946 16720 solver.cpp:237]     Train net output #1: loss = 2.23653 (* 1 = 2.23653 loss)
I1211 14:15:45.502946 16720 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1211 14:15:51.669811 16720 solver.cpp:218] Iteration 4200 (16.2156 iter/s, 6.16692s/100 iters), loss = 2.18817
I1211 14:15:51.669811 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:15:51.669811 16720 solver.cpp:237]     Train net output #1: loss = 2.18817 (* 1 = 2.18817 loss)
I1211 14:15:51.669811 16720 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1211 14:15:57.928797 16720 solver.cpp:218] Iteration 4300 (15.978 iter/s, 6.25861s/100 iters), loss = 2.5896
I1211 14:15:57.928797 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 14:15:57.928797 16720 solver.cpp:237]     Train net output #1: loss = 2.5896 (* 1 = 2.5896 loss)
I1211 14:15:57.928797 16720 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1211 14:16:04.081040 16720 solver.cpp:218] Iteration 4400 (16.256 iter/s, 6.15158s/100 iters), loss = 2.41911
I1211 14:16:04.081040 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 14:16:04.081040 16720 solver.cpp:237]     Train net output #1: loss = 2.41911 (* 1 = 2.41911 loss)
I1211 14:16:04.081040 16720 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1211 14:16:09.928133  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:16:10.170142 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_4500.caffemodel
I1211 14:16:10.186143 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_4500.solverstate
I1211 14:16:10.190143 16720 solver.cpp:330] Iteration 4500, Testing net (#0)
I1211 14:16:10.190143 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:16:11.525053 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:16:11.577369 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3333
I1211 14:16:11.577369 16720 solver.cpp:397]     Test net output #1: loss = 2.59801 (* 1 = 2.59801 loss)
I1211 14:16:11.637025 16720 solver.cpp:218] Iteration 4500 (13.2358 iter/s, 7.55526s/100 iters), loss = 2.29394
I1211 14:16:11.637025 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:16:11.637025 16720 solver.cpp:237]     Train net output #1: loss = 2.29394 (* 1 = 2.29394 loss)
I1211 14:16:11.637025 16720 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1211 14:16:17.790922 16720 solver.cpp:218] Iteration 4600 (16.2493 iter/s, 6.1541s/100 iters), loss = 2.0799
I1211 14:16:17.790922 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:16:17.790922 16720 solver.cpp:237]     Train net output #1: loss = 2.0799 (* 1 = 2.0799 loss)
I1211 14:16:17.790922 16720 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1211 14:16:23.939617 16720 solver.cpp:218] Iteration 4700 (16.2666 iter/s, 6.14758s/100 iters), loss = 1.8904
I1211 14:16:23.939617 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:16:23.939617 16720 solver.cpp:237]     Train net output #1: loss = 1.8904 (* 1 = 1.8904 loss)
I1211 14:16:23.939617 16720 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1211 14:16:30.118970 16720 solver.cpp:218] Iteration 4800 (16.1851 iter/s, 6.17853s/100 iters), loss = 2.2447
I1211 14:16:30.118970 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:16:30.118970 16720 solver.cpp:237]     Train net output #1: loss = 2.2447 (* 1 = 2.2447 loss)
I1211 14:16:30.118970 16720 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1211 14:16:36.313935 16720 solver.cpp:218] Iteration 4900 (16.1435 iter/s, 6.19445s/100 iters), loss = 2.42846
I1211 14:16:36.313935 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 14:16:36.313935 16720 solver.cpp:237]     Train net output #1: loss = 2.42846 (* 1 = 2.42846 loss)
I1211 14:16:36.313935 16720 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1211 14:16:42.187026  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:16:42.431555 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_5000.caffemodel
I1211 14:16:42.449584 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_5000.solverstate
I1211 14:16:42.454583 16720 solver.cpp:330] Iteration 5000, Testing net (#0)
I1211 14:16:42.454583 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:16:43.793272 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:16:43.846279 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2617
I1211 14:16:43.846279 16720 solver.cpp:397]     Test net output #1: loss = 3.24553 (* 1 = 3.24553 loss)
I1211 14:16:43.905277 16720 solver.cpp:218] Iteration 5000 (13.173 iter/s, 7.59127s/100 iters), loss = 2.27539
I1211 14:16:43.905277 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 14:16:43.905277 16720 solver.cpp:237]     Train net output #1: loss = 2.27539 (* 1 = 2.27539 loss)
I1211 14:16:43.905277 16720 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1211 14:16:50.088073 16720 solver.cpp:218] Iteration 5100 (16.1746 iter/s, 6.18253s/100 iters), loss = 2.03316
I1211 14:16:50.088073 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 14:16:50.088073 16720 solver.cpp:237]     Train net output #1: loss = 2.03316 (* 1 = 2.03316 loss)
I1211 14:16:50.088073 16720 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1211 14:16:56.238919 16720 solver.cpp:218] Iteration 5200 (16.2603 iter/s, 6.14996s/100 iters), loss = 1.77407
I1211 14:16:56.238919 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:16:56.238919 16720 solver.cpp:237]     Train net output #1: loss = 1.77407 (* 1 = 1.77407 loss)
I1211 14:16:56.238919 16720 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1211 14:17:02.391206 16720 solver.cpp:218] Iteration 5300 (16.2538 iter/s, 6.1524s/100 iters), loss = 2.36843
I1211 14:17:02.391206 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 14:17:02.391206 16720 solver.cpp:237]     Train net output #1: loss = 2.36843 (* 1 = 2.36843 loss)
I1211 14:17:02.391206 16720 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1211 14:17:08.547606 16720 solver.cpp:218] Iteration 5400 (16.2452 iter/s, 6.15566s/100 iters), loss = 2.33534
I1211 14:17:08.547606 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:17:08.547606 16720 solver.cpp:237]     Train net output #1: loss = 2.33534 (* 1 = 2.33534 loss)
I1211 14:17:08.547606 16720 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1211 14:17:14.414698  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:17:14.657713 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_5500.caffemodel
I1211 14:17:14.672714 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_5500.solverstate
I1211 14:17:14.677714 16720 solver.cpp:330] Iteration 5500, Testing net (#0)
I1211 14:17:14.677714 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:17:16.015846 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:17:16.068848 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3208
I1211 14:17:16.068848 16720 solver.cpp:397]     Test net output #1: loss = 2.69305 (* 1 = 2.69305 loss)
I1211 14:17:16.127848 16720 solver.cpp:218] Iteration 5500 (13.1929 iter/s, 7.57981s/100 iters), loss = 2.21009
I1211 14:17:16.127848 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 14:17:16.127848 16720 solver.cpp:237]     Train net output #1: loss = 2.21009 (* 1 = 2.21009 loss)
I1211 14:17:16.127848 16720 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1211 14:17:22.288141 16720 solver.cpp:218] Iteration 5600 (16.2332 iter/s, 6.16021s/100 iters), loss = 2.04689
I1211 14:17:22.288141 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 14:17:22.288141 16720 solver.cpp:237]     Train net output #1: loss = 2.04689 (* 1 = 2.04689 loss)
I1211 14:17:22.288141 16720 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1211 14:17:28.456692 16720 solver.cpp:218] Iteration 5700 (16.2122 iter/s, 6.16819s/100 iters), loss = 1.77383
I1211 14:17:28.456692 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:17:28.456692 16720 solver.cpp:237]     Train net output #1: loss = 1.77383 (* 1 = 1.77383 loss)
I1211 14:17:28.456692 16720 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1211 14:17:34.661449 16720 solver.cpp:218] Iteration 5800 (16.1188 iter/s, 6.20394s/100 iters), loss = 2.04612
I1211 14:17:34.661449 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:17:34.661449 16720 solver.cpp:237]     Train net output #1: loss = 2.04612 (* 1 = 2.04612 loss)
I1211 14:17:34.661449 16720 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1211 14:17:40.882679 16720 solver.cpp:218] Iteration 5900 (16.0759 iter/s, 6.2205s/100 iters), loss = 2.203
I1211 14:17:40.882679 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:17:40.882679 16720 solver.cpp:237]     Train net output #1: loss = 2.203 (* 1 = 2.203 loss)
I1211 14:17:40.882679 16720 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1211 14:17:46.905643  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:17:47.153683 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_6000.caffemodel
I1211 14:17:47.172685 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_6000.solverstate
I1211 14:17:47.180682 16720 solver.cpp:330] Iteration 6000, Testing net (#0)
I1211 14:17:47.180682 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:17:48.529916 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:17:48.581914 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3268
I1211 14:17:48.581914 16720 solver.cpp:397]     Test net output #1: loss = 2.76198 (* 1 = 2.76198 loss)
I1211 14:17:48.639924 16720 solver.cpp:218] Iteration 6000 (12.8912 iter/s, 7.75722s/100 iters), loss = 2.11367
I1211 14:17:48.639924 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 14:17:48.639924 16720 solver.cpp:237]     Train net output #1: loss = 2.11367 (* 1 = 2.11367 loss)
I1211 14:17:48.639924 16720 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1211 14:17:54.796064 16720 solver.cpp:218] Iteration 6100 (16.2469 iter/s, 6.15501s/100 iters), loss = 1.98432
I1211 14:17:54.796064 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 14:17:54.796064 16720 solver.cpp:237]     Train net output #1: loss = 1.98432 (* 1 = 1.98432 loss)
I1211 14:17:54.796064 16720 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1211 14:18:00.981163 16720 solver.cpp:218] Iteration 6200 (16.1673 iter/s, 6.18532s/100 iters), loss = 1.664
I1211 14:18:00.981163 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:18:00.981163 16720 solver.cpp:237]     Train net output #1: loss = 1.664 (* 1 = 1.664 loss)
I1211 14:18:00.981163 16720 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1211 14:18:07.169955 16720 solver.cpp:218] Iteration 6300 (16.1602 iter/s, 6.18803s/100 iters), loss = 2.14056
I1211 14:18:07.169955 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:18:07.169955 16720 solver.cpp:237]     Train net output #1: loss = 2.14056 (* 1 = 2.14056 loss)
I1211 14:18:07.169955 16720 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1211 14:18:13.370507 16720 solver.cpp:218] Iteration 6400 (16.1283 iter/s, 6.20026s/100 iters), loss = 2.31849
I1211 14:18:13.370507 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:18:13.370507 16720 solver.cpp:237]     Train net output #1: loss = 2.31849 (* 1 = 2.31849 loss)
I1211 14:18:13.370507 16720 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1211 14:18:19.224994  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:18:19.469013 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_6500.caffemodel
I1211 14:18:19.485016 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_6500.solverstate
I1211 14:18:19.489518 16720 solver.cpp:330] Iteration 6500, Testing net (#0)
I1211 14:18:19.489518 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:18:20.833127 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:18:20.886127 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2908
I1211 14:18:20.886127 16720 solver.cpp:397]     Test net output #1: loss = 3.03974 (* 1 = 3.03974 loss)
I1211 14:18:20.945135 16720 solver.cpp:218] Iteration 6500 (13.2043 iter/s, 7.57328s/100 iters), loss = 2.05319
I1211 14:18:20.945135 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:18:20.945135 16720 solver.cpp:237]     Train net output #1: loss = 2.05319 (* 1 = 2.05319 loss)
I1211 14:18:20.945135 16720 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1211 14:18:27.113598 16720 solver.cpp:218] Iteration 6600 (16.2125 iter/s, 6.1681s/100 iters), loss = 1.92444
I1211 14:18:27.113598 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 14:18:27.113598 16720 solver.cpp:237]     Train net output #1: loss = 1.92444 (* 1 = 1.92444 loss)
I1211 14:18:27.113598 16720 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1211 14:18:33.312304 16720 solver.cpp:218] Iteration 6700 (16.1334 iter/s, 6.1983s/100 iters), loss = 1.62462
I1211 14:18:33.312304 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:18:33.312304 16720 solver.cpp:237]     Train net output #1: loss = 1.62462 (* 1 = 1.62462 loss)
I1211 14:18:33.312304 16720 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1211 14:18:39.487864 16720 solver.cpp:218] Iteration 6800 (16.194 iter/s, 6.17513s/100 iters), loss = 2.14177
I1211 14:18:39.487864 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 14:18:39.487864 16720 solver.cpp:237]     Train net output #1: loss = 2.14177 (* 1 = 2.14177 loss)
I1211 14:18:39.487864 16720 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1211 14:18:45.742444 16720 solver.cpp:218] Iteration 6900 (15.9896 iter/s, 6.25405s/100 iters), loss = 2.1804
I1211 14:18:45.742444 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:18:45.742444 16720 solver.cpp:237]     Train net output #1: loss = 2.1804 (* 1 = 2.1804 loss)
I1211 14:18:45.742444 16720 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1211 14:18:51.597857  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:18:51.839900 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_7000.caffemodel
I1211 14:18:51.854899 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_7000.solverstate
I1211 14:18:51.859899 16720 solver.cpp:330] Iteration 7000, Testing net (#0)
I1211 14:18:51.859899 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:18:53.193296 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:18:53.245303 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3213
I1211 14:18:53.245303 16720 solver.cpp:397]     Test net output #1: loss = 2.73028 (* 1 = 2.73028 loss)
I1211 14:18:53.304464 16720 solver.cpp:218] Iteration 7000 (13.2245 iter/s, 7.56174s/100 iters), loss = 2.09324
I1211 14:18:53.304464 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 14:18:53.304464 16720 solver.cpp:237]     Train net output #1: loss = 2.09324 (* 1 = 2.09324 loss)
I1211 14:18:53.304464 16720 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1211 14:18:59.452342 16720 solver.cpp:218] Iteration 7100 (16.2683 iter/s, 6.14693s/100 iters), loss = 1.8959
I1211 14:18:59.452342 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:18:59.452342 16720 solver.cpp:237]     Train net output #1: loss = 1.8959 (* 1 = 1.8959 loss)
I1211 14:18:59.452342 16720 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1211 14:19:05.628813 16720 solver.cpp:218] Iteration 7200 (16.1917 iter/s, 6.176s/100 iters), loss = 1.75899
I1211 14:19:05.628813 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:19:05.628813 16720 solver.cpp:237]     Train net output #1: loss = 1.75899 (* 1 = 1.75899 loss)
I1211 14:19:05.628813 16720 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1211 14:19:11.888437 16720 solver.cpp:218] Iteration 7300 (15.9757 iter/s, 6.25949s/100 iters), loss = 1.95903
I1211 14:19:11.888437 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:19:11.888437 16720 solver.cpp:237]     Train net output #1: loss = 1.95903 (* 1 = 1.95903 loss)
I1211 14:19:11.888437 16720 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1211 14:19:18.138880 16720 solver.cpp:218] Iteration 7400 (15.9985 iter/s, 6.25057s/100 iters), loss = 2.16405
I1211 14:19:18.138880 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:19:18.139869 16720 solver.cpp:237]     Train net output #1: loss = 2.16405 (* 1 = 2.16405 loss)
I1211 14:19:18.139869 16720 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1211 14:19:24.099414  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:19:24.341655 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_7500.caffemodel
I1211 14:19:24.357656 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_7500.solverstate
I1211 14:19:24.362656 16720 solver.cpp:330] Iteration 7500, Testing net (#0)
I1211 14:19:24.362656 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:19:25.723572 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:19:25.776571 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3316
I1211 14:19:25.776571 16720 solver.cpp:397]     Test net output #1: loss = 2.66365 (* 1 = 2.66365 loss)
I1211 14:19:25.836678 16720 solver.cpp:218] Iteration 7500 (12.9921 iter/s, 7.69697s/100 iters), loss = 2.02829
I1211 14:19:25.836678 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:19:25.836678 16720 solver.cpp:237]     Train net output #1: loss = 2.02829 (* 1 = 2.02829 loss)
I1211 14:19:25.836678 16720 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1211 14:19:32.089610 16720 solver.cpp:218] Iteration 7600 (15.9943 iter/s, 6.25224s/100 iters), loss = 1.81907
I1211 14:19:32.089610 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:19:32.089610 16720 solver.cpp:237]     Train net output #1: loss = 1.81907 (* 1 = 1.81907 loss)
I1211 14:19:32.089610 16720 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1211 14:19:38.328239 16720 solver.cpp:218] Iteration 7700 (16.0302 iter/s, 6.23823s/100 iters), loss = 1.65978
I1211 14:19:38.328239 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:19:38.328239 16720 solver.cpp:237]     Train net output #1: loss = 1.65978 (* 1 = 1.65978 loss)
I1211 14:19:38.328239 16720 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1211 14:19:44.544793 16720 solver.cpp:218] Iteration 7800 (16.0886 iter/s, 6.21558s/100 iters), loss = 1.88193
I1211 14:19:44.544793 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:19:44.544793 16720 solver.cpp:237]     Train net output #1: loss = 1.88193 (* 1 = 1.88193 loss)
I1211 14:19:44.544793 16720 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1211 14:19:50.796576 16720 solver.cpp:218] Iteration 7900 (15.9962 iter/s, 6.25148s/100 iters), loss = 2.13703
I1211 14:19:50.796576 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:19:50.796576 16720 solver.cpp:237]     Train net output #1: loss = 2.13703 (* 1 = 2.13703 loss)
I1211 14:19:50.796576 16720 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1211 14:19:56.662055  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:19:56.906066 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_8000.caffemodel
I1211 14:19:56.921074 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_8000.solverstate
I1211 14:19:56.927070 16720 solver.cpp:330] Iteration 8000, Testing net (#0)
I1211 14:19:56.927070 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:19:58.264161 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:19:58.317164 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3116
I1211 14:19:58.318166 16720 solver.cpp:397]     Test net output #1: loss = 2.82424 (* 1 = 2.82424 loss)
I1211 14:19:58.376165 16720 solver.cpp:218] Iteration 8000 (13.1932 iter/s, 7.57967s/100 iters), loss = 2.05637
I1211 14:19:58.377166 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:19:58.377166 16720 solver.cpp:237]     Train net output #1: loss = 2.05637 (* 1 = 2.05637 loss)
I1211 14:19:58.377166 16720 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1211 14:20:04.614248 16720 solver.cpp:218] Iteration 8100 (16.0334 iter/s, 6.23698s/100 iters), loss = 1.81102
I1211 14:20:04.614248 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 14:20:04.614248 16720 solver.cpp:237]     Train net output #1: loss = 1.81102 (* 1 = 1.81102 loss)
I1211 14:20:04.614248 16720 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1211 14:20:10.846318 16720 solver.cpp:218] Iteration 8200 (16.0455 iter/s, 6.23227s/100 iters), loss = 1.82181
I1211 14:20:10.847319 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:20:10.847319 16720 solver.cpp:237]     Train net output #1: loss = 1.82181 (* 1 = 1.82181 loss)
I1211 14:20:10.847319 16720 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1211 14:20:17.012567 16720 solver.cpp:218] Iteration 8300 (16.2198 iter/s, 6.1653s/100 iters), loss = 2.04506
I1211 14:20:17.012567 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:20:17.012567 16720 solver.cpp:237]     Train net output #1: loss = 2.04506 (* 1 = 2.04506 loss)
I1211 14:20:17.012567 16720 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1211 14:20:23.169390 16720 solver.cpp:218] Iteration 8400 (16.2439 iter/s, 6.15618s/100 iters), loss = 2.02406
I1211 14:20:23.169390 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:20:23.169390 16720 solver.cpp:237]     Train net output #1: loss = 2.02406 (* 1 = 2.02406 loss)
I1211 14:20:23.169390 16720 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1211 14:20:29.016613  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:20:29.259140 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_8500.caffemodel
I1211 14:20:29.274139 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_8500.solverstate
I1211 14:20:29.279139 16720 solver.cpp:330] Iteration 8500, Testing net (#0)
I1211 14:20:29.279139 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:20:30.615599 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:20:30.667600 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3919
I1211 14:20:30.667600 16720 solver.cpp:397]     Test net output #1: loss = 2.38223 (* 1 = 2.38223 loss)
I1211 14:20:30.726610 16720 solver.cpp:218] Iteration 8500 (13.233 iter/s, 7.55688s/100 iters), loss = 2.01055
I1211 14:20:30.726610 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:20:30.726610 16720 solver.cpp:237]     Train net output #1: loss = 2.01055 (* 1 = 2.01055 loss)
I1211 14:20:30.726610 16720 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1211 14:20:36.916326 16720 solver.cpp:218] Iteration 8600 (16.1567 iter/s, 6.18937s/100 iters), loss = 1.79
I1211 14:20:36.916326 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:20:36.916326 16720 solver.cpp:237]     Train net output #1: loss = 1.79 (* 1 = 1.79 loss)
I1211 14:20:36.916826 16720 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1211 14:20:43.154083 16720 solver.cpp:218] Iteration 8700 (16.033 iter/s, 6.23714s/100 iters), loss = 1.6939
I1211 14:20:43.154083 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:20:43.154083 16720 solver.cpp:237]     Train net output #1: loss = 1.6939 (* 1 = 1.6939 loss)
I1211 14:20:43.154083 16720 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1211 14:20:49.358613 16720 solver.cpp:218] Iteration 8800 (16.1189 iter/s, 6.20388s/100 iters), loss = 2.01164
I1211 14:20:49.358613 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:20:49.358613 16720 solver.cpp:237]     Train net output #1: loss = 2.01164 (* 1 = 2.01164 loss)
I1211 14:20:49.358613 16720 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1211 14:20:55.577699 16720 solver.cpp:218] Iteration 8900 (16.079 iter/s, 6.2193s/100 iters), loss = 2.06521
I1211 14:20:55.577699 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:20:55.577699 16720 solver.cpp:237]     Train net output #1: loss = 2.06521 (* 1 = 2.06521 loss)
I1211 14:20:55.577699 16720 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1211 14:21:01.577616  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:21:01.827689 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_9000.caffemodel
I1211 14:21:01.842694 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_9000.solverstate
I1211 14:21:01.847693 16720 solver.cpp:330] Iteration 9000, Testing net (#0)
I1211 14:21:01.847693 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:21:03.213346 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:21:03.266852 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3206
I1211 14:21:03.266852 16720 solver.cpp:397]     Test net output #1: loss = 2.78256 (* 1 = 2.78256 loss)
I1211 14:21:03.327373 16720 solver.cpp:218] Iteration 9000 (12.9052 iter/s, 7.74883s/100 iters), loss = 1.93741
I1211 14:21:03.327373 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:21:03.327373 16720 solver.cpp:237]     Train net output #1: loss = 1.93741 (* 1 = 1.93741 loss)
I1211 14:21:03.327373 16720 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1211 14:21:09.601467 16720 solver.cpp:218] Iteration 9100 (15.9392 iter/s, 6.27384s/100 iters), loss = 1.76596
I1211 14:21:09.601467 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:21:09.601467 16720 solver.cpp:237]     Train net output #1: loss = 1.76596 (* 1 = 1.76596 loss)
I1211 14:21:09.601467 16720 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1211 14:21:15.911046 16720 solver.cpp:218] Iteration 9200 (15.8497 iter/s, 6.30928s/100 iters), loss = 1.60627
I1211 14:21:15.912046 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:21:15.912046 16720 solver.cpp:237]     Train net output #1: loss = 1.60627 (* 1 = 1.60627 loss)
I1211 14:21:15.912046 16720 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1211 14:21:22.124686 16720 solver.cpp:218] Iteration 9300 (16.0959 iter/s, 6.21276s/100 iters), loss = 1.98151
I1211 14:21:22.124686 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:21:22.124686 16720 solver.cpp:237]     Train net output #1: loss = 1.98151 (* 1 = 1.98151 loss)
I1211 14:21:22.124686 16720 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1211 14:21:28.455561 16720 solver.cpp:218] Iteration 9400 (15.797 iter/s, 6.33031s/100 iters), loss = 1.95218
I1211 14:21:28.455561 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:21:28.455561 16720 solver.cpp:237]     Train net output #1: loss = 1.95218 (* 1 = 1.95218 loss)
I1211 14:21:28.455561 16720 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1211 14:21:34.561532  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:21:34.814594 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_9500.caffemodel
I1211 14:21:34.830595 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_9500.solverstate
I1211 14:21:34.835593 16720 solver.cpp:330] Iteration 9500, Testing net (#0)
I1211 14:21:34.835593 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:21:36.233721 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:21:36.288223 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3382
I1211 14:21:36.288223 16720 solver.cpp:397]     Test net output #1: loss = 2.71116 (* 1 = 2.71116 loss)
I1211 14:21:36.349725 16720 solver.cpp:218] Iteration 9500 (12.6691 iter/s, 7.8932s/100 iters), loss = 1.89753
I1211 14:21:36.349725 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:21:36.349725 16720 solver.cpp:237]     Train net output #1: loss = 1.89753 (* 1 = 1.89753 loss)
I1211 14:21:36.349725 16720 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1211 14:21:42.729346 16720 solver.cpp:218] Iteration 9600 (15.6746 iter/s, 6.37977s/100 iters), loss = 1.95196
I1211 14:21:42.729346 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 14:21:42.729346 16720 solver.cpp:237]     Train net output #1: loss = 1.95196 (* 1 = 1.95196 loss)
I1211 14:21:42.729346 16720 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1211 14:21:48.941818 16720 solver.cpp:218] Iteration 9700 (16.0974 iter/s, 6.21219s/100 iters), loss = 1.58951
I1211 14:21:48.942819 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:21:48.942819 16720 solver.cpp:237]     Train net output #1: loss = 1.58951 (* 1 = 1.58951 loss)
I1211 14:21:48.942819 16720 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1211 14:21:55.100119 16720 solver.cpp:218] Iteration 9800 (16.2408 iter/s, 6.15732s/100 iters), loss = 1.95754
I1211 14:21:55.100119 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:21:55.100620 16720 solver.cpp:237]     Train net output #1: loss = 1.95754 (* 1 = 1.95754 loss)
I1211 14:21:55.100620 16720 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1211 14:22:01.264142 16720 solver.cpp:218] Iteration 9900 (16.2228 iter/s, 6.16415s/100 iters), loss = 2.01815
I1211 14:22:01.265143 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:22:01.265143 16720 solver.cpp:237]     Train net output #1: loss = 2.01815 (* 1 = 2.01815 loss)
I1211 14:22:01.265143 16720 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1211 14:22:07.118680  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:22:07.360692 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_10000.caffemodel
I1211 14:22:07.376693 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_10000.solverstate
I1211 14:22:07.380692 16720 solver.cpp:330] Iteration 10000, Testing net (#0)
I1211 14:22:07.380692 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:22:08.717834 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:22:08.770833 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3276
I1211 14:22:08.770833 16720 solver.cpp:397]     Test net output #1: loss = 2.71262 (* 1 = 2.71262 loss)
I1211 14:22:08.829840 16720 solver.cpp:218] Iteration 10000 (13.22 iter/s, 7.56429s/100 iters), loss = 1.91613
I1211 14:22:08.829840 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:22:08.829840 16720 solver.cpp:237]     Train net output #1: loss = 1.91613 (* 1 = 1.91613 loss)
I1211 14:22:08.829840 16720 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1211 14:22:14.978018 16720 solver.cpp:218] Iteration 10100 (16.2651 iter/s, 6.14813s/100 iters), loss = 1.78085
I1211 14:22:14.978018 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 14:22:14.978018 16720 solver.cpp:237]     Train net output #1: loss = 1.78085 (* 1 = 1.78085 loss)
I1211 14:22:14.978018 16720 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1211 14:22:21.126883 16720 solver.cpp:218] Iteration 10200 (16.2643 iter/s, 6.14842s/100 iters), loss = 1.67875
I1211 14:22:21.126883 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:22:21.126883 16720 solver.cpp:237]     Train net output #1: loss = 1.67875 (* 1 = 1.67875 loss)
I1211 14:22:21.126883 16720 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1211 14:22:27.291833 16720 solver.cpp:218] Iteration 10300 (16.2213 iter/s, 6.16474s/100 iters), loss = 1.94601
I1211 14:22:27.291833 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:22:27.291833 16720 solver.cpp:237]     Train net output #1: loss = 1.94601 (* 1 = 1.94601 loss)
I1211 14:22:27.291833 16720 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1211 14:22:33.444584 16720 solver.cpp:218] Iteration 10400 (16.2535 iter/s, 6.15251s/100 iters), loss = 2.06559
I1211 14:22:33.444584 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:22:33.444584 16720 solver.cpp:237]     Train net output #1: loss = 2.06559 (* 1 = 2.06559 loss)
I1211 14:22:33.444584 16720 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1211 14:22:39.297842  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:22:39.538367 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_10500.caffemodel
I1211 14:22:39.555367 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_10500.solverstate
I1211 14:22:39.559367 16720 solver.cpp:330] Iteration 10500, Testing net (#0)
I1211 14:22:39.559367 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:22:40.900482 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:22:40.953486 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3205
I1211 14:22:40.953486 16720 solver.cpp:397]     Test net output #1: loss = 2.87301 (* 1 = 2.87301 loss)
I1211 14:22:41.012495 16720 solver.cpp:218] Iteration 10500 (13.2151 iter/s, 7.56712s/100 iters), loss = 1.90667
I1211 14:22:41.012495 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:22:41.012495 16720 solver.cpp:237]     Train net output #1: loss = 1.90667 (* 1 = 1.90667 loss)
I1211 14:22:41.012495 16720 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1211 14:22:47.176417 16720 solver.cpp:218] Iteration 10600 (16.2253 iter/s, 6.16322s/100 iters), loss = 1.62615
I1211 14:22:47.176417 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:22:47.176417 16720 solver.cpp:237]     Train net output #1: loss = 1.62615 (* 1 = 1.62615 loss)
I1211 14:22:47.176417 16720 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1211 14:22:53.340409 16720 solver.cpp:218] Iteration 10700 (16.2229 iter/s, 6.16411s/100 iters), loss = 1.64443
I1211 14:22:53.341398 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:22:53.341398 16720 solver.cpp:237]     Train net output #1: loss = 1.64443 (* 1 = 1.64443 loss)
I1211 14:22:53.341398 16720 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1211 14:22:59.497867 16720 solver.cpp:218] Iteration 10800 (16.2436 iter/s, 6.15627s/100 iters), loss = 1.88284
I1211 14:22:59.497867 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:22:59.497867 16720 solver.cpp:237]     Train net output #1: loss = 1.88284 (* 1 = 1.88284 loss)
I1211 14:22:59.497867 16720 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1211 14:23:05.650497 16720 solver.cpp:218] Iteration 10900 (16.255 iter/s, 6.15194s/100 iters), loss = 1.93257
I1211 14:23:05.650497 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:23:05.650497 16720 solver.cpp:237]     Train net output #1: loss = 1.93257 (* 1 = 1.93257 loss)
I1211 14:23:05.650497 16720 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1211 14:23:11.532136  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:23:11.774147 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_11000.caffemodel
I1211 14:23:11.793150 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_11000.solverstate
I1211 14:23:11.798146 16720 solver.cpp:330] Iteration 11000, Testing net (#0)
I1211 14:23:11.798146 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:23:13.142261 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:23:13.196259 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3633
I1211 14:23:13.196259 16720 solver.cpp:397]     Test net output #1: loss = 2.49441 (* 1 = 2.49441 loss)
I1211 14:23:13.254264 16720 solver.cpp:218] Iteration 11000 (13.152 iter/s, 7.6034s/100 iters), loss = 1.83274
I1211 14:23:13.254264 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:23:13.254264 16720 solver.cpp:237]     Train net output #1: loss = 1.83274 (* 1 = 1.83274 loss)
I1211 14:23:13.254264 16720 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1211 14:23:19.450717 16720 solver.cpp:218] Iteration 11100 (16.139 iter/s, 6.19615s/100 iters), loss = 1.6883
I1211 14:23:19.450717 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:23:19.450717 16720 solver.cpp:237]     Train net output #1: loss = 1.6883 (* 1 = 1.6883 loss)
I1211 14:23:19.450717 16720 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1211 14:23:25.651266 16720 solver.cpp:218] Iteration 11200 (16.1281 iter/s, 6.20037s/100 iters), loss = 1.50361
I1211 14:23:25.651266 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:23:25.651266 16720 solver.cpp:237]     Train net output #1: loss = 1.50361 (* 1 = 1.50361 loss)
I1211 14:23:25.651266 16720 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1211 14:23:31.833050 16720 solver.cpp:218] Iteration 11300 (16.1768 iter/s, 6.1817s/100 iters), loss = 2.0381
I1211 14:23:31.833050 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 14:23:31.834051 16720 solver.cpp:237]     Train net output #1: loss = 2.0381 (* 1 = 2.0381 loss)
I1211 14:23:31.834051 16720 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1211 14:23:37.983459 16720 solver.cpp:218] Iteration 11400 (16.2622 iter/s, 6.14921s/100 iters), loss = 2.04852
I1211 14:23:37.983459 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:23:37.983459 16720 solver.cpp:237]     Train net output #1: loss = 2.04852 (* 1 = 2.04852 loss)
I1211 14:23:37.983459 16720 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1211 14:23:43.832445  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:23:44.074461 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_11500.caffemodel
I1211 14:23:44.089462 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_11500.solverstate
I1211 14:23:44.094462 16720 solver.cpp:330] Iteration 11500, Testing net (#0)
I1211 14:23:44.094462 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:23:45.433547 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:23:45.486555 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3036
I1211 14:23:45.486555 16720 solver.cpp:397]     Test net output #1: loss = 3.01843 (* 1 = 3.01843 loss)
I1211 14:23:45.545553 16720 solver.cpp:218] Iteration 11500 (13.2246 iter/s, 7.56165s/100 iters), loss = 1.89746
I1211 14:23:45.545553 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:23:45.545553 16720 solver.cpp:237]     Train net output #1: loss = 1.89746 (* 1 = 1.89746 loss)
I1211 14:23:45.545553 16720 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1211 14:23:51.703999 16720 solver.cpp:218] Iteration 11600 (16.2393 iter/s, 6.15792s/100 iters), loss = 1.69087
I1211 14:23:51.703999 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:23:51.703999 16720 solver.cpp:237]     Train net output #1: loss = 1.69087 (* 1 = 1.69087 loss)
I1211 14:23:51.703999 16720 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1211 14:23:57.860213 16720 solver.cpp:218] Iteration 11700 (16.2451 iter/s, 6.15571s/100 iters), loss = 1.59945
I1211 14:23:57.860213 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:23:57.860213 16720 solver.cpp:237]     Train net output #1: loss = 1.59945 (* 1 = 1.59945 loss)
I1211 14:23:57.860213 16720 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1211 14:24:04.018448 16720 solver.cpp:218] Iteration 11800 (16.2397 iter/s, 6.15774s/100 iters), loss = 1.87601
I1211 14:24:04.018448 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:24:04.018448 16720 solver.cpp:237]     Train net output #1: loss = 1.87601 (* 1 = 1.87601 loss)
I1211 14:24:04.018448 16720 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1211 14:24:10.170802 16720 solver.cpp:218] Iteration 11900 (16.255 iter/s, 6.15194s/100 iters), loss = 1.96464
I1211 14:24:10.170802 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:24:10.170802 16720 solver.cpp:237]     Train net output #1: loss = 1.96464 (* 1 = 1.96464 loss)
I1211 14:24:10.170802 16720 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1211 14:24:16.028856  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:24:16.271402 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_12000.caffemodel
I1211 14:24:16.286427 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_12000.solverstate
I1211 14:24:16.291440 16720 solver.cpp:330] Iteration 12000, Testing net (#0)
I1211 14:24:16.291440 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:24:17.628592 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:24:17.681111 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3303
I1211 14:24:17.681111 16720 solver.cpp:397]     Test net output #1: loss = 2.77513 (* 1 = 2.77513 loss)
I1211 14:24:17.739629 16720 solver.cpp:218] Iteration 12000 (13.2125 iter/s, 7.56857s/100 iters), loss = 1.93752
I1211 14:24:17.739629 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:24:17.739629 16720 solver.cpp:237]     Train net output #1: loss = 1.93752 (* 1 = 1.93752 loss)
I1211 14:24:17.739629 16720 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1211 14:24:23.891412 16720 solver.cpp:218] Iteration 12100 (16.2571 iter/s, 6.15117s/100 iters), loss = 1.79248
I1211 14:24:23.891412 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:24:23.891412 16720 solver.cpp:237]     Train net output #1: loss = 1.79248 (* 1 = 1.79248 loss)
I1211 14:24:23.891412 16720 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1211 14:24:30.051067 16720 solver.cpp:218] Iteration 12200 (16.236 iter/s, 6.15916s/100 iters), loss = 1.53278
I1211 14:24:30.051067 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:24:30.051067 16720 solver.cpp:237]     Train net output #1: loss = 1.53278 (* 1 = 1.53278 loss)
I1211 14:24:30.051067 16720 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1211 14:24:36.201514 16720 solver.cpp:218] Iteration 12300 (16.259 iter/s, 6.15046s/100 iters), loss = 1.90808
I1211 14:24:36.201514 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:24:36.201514 16720 solver.cpp:237]     Train net output #1: loss = 1.90808 (* 1 = 1.90808 loss)
I1211 14:24:36.201514 16720 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1211 14:24:42.341980 16720 solver.cpp:218] Iteration 12400 (16.2874 iter/s, 6.13973s/100 iters), loss = 2.07739
I1211 14:24:42.341980 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:24:42.341980 16720 solver.cpp:237]     Train net output #1: loss = 2.07739 (* 1 = 2.07739 loss)
I1211 14:24:42.341980 16720 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1211 14:24:48.191925  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:24:48.434540 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_12500.caffemodel
I1211 14:24:48.449540 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_12500.solverstate
I1211 14:24:48.454546 16720 solver.cpp:330] Iteration 12500, Testing net (#0)
I1211 14:24:48.454546 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:24:49.792636 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:24:49.845141 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2789
I1211 14:24:49.845141 16720 solver.cpp:397]     Test net output #1: loss = 3.16869 (* 1 = 3.16869 loss)
I1211 14:24:49.904144 16720 solver.cpp:218] Iteration 12500 (13.2246 iter/s, 7.56166s/100 iters), loss = 1.83532
I1211 14:24:49.904144 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:24:49.904144 16720 solver.cpp:237]     Train net output #1: loss = 1.83532 (* 1 = 1.83532 loss)
I1211 14:24:49.904144 16720 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1211 14:24:56.057620 16720 solver.cpp:218] Iteration 12600 (16.2508 iter/s, 6.15356s/100 iters), loss = 1.66729
I1211 14:24:56.058619 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:24:56.058619 16720 solver.cpp:237]     Train net output #1: loss = 1.66729 (* 1 = 1.66729 loss)
I1211 14:24:56.058619 16720 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1211 14:25:02.217401 16720 solver.cpp:218] Iteration 12700 (16.2379 iter/s, 6.15843s/100 iters), loss = 1.48665
I1211 14:25:02.217401 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:25:02.217401 16720 solver.cpp:237]     Train net output #1: loss = 1.48665 (* 1 = 1.48665 loss)
I1211 14:25:02.217401 16720 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1211 14:25:08.373842 16720 solver.cpp:218] Iteration 12800 (16.2444 iter/s, 6.15598s/100 iters), loss = 1.88406
I1211 14:25:08.373842 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:25:08.373842 16720 solver.cpp:237]     Train net output #1: loss = 1.88406 (* 1 = 1.88406 loss)
I1211 14:25:08.373842 16720 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1211 14:25:14.523332 16720 solver.cpp:218] Iteration 12900 (16.2626 iter/s, 6.14909s/100 iters), loss = 1.99117
I1211 14:25:14.523332 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:25:14.523332 16720 solver.cpp:237]     Train net output #1: loss = 1.99117 (* 1 = 1.99117 loss)
I1211 14:25:14.523332 16720 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1211 14:25:20.373863  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:25:20.615877 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_13000.caffemodel
I1211 14:25:20.630877 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_13000.solverstate
I1211 14:25:20.635877 16720 solver.cpp:330] Iteration 13000, Testing net (#0)
I1211 14:25:20.635877 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:25:21.973013 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:25:22.026022 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3446
I1211 14:25:22.026022 16720 solver.cpp:397]     Test net output #1: loss = 2.67097 (* 1 = 2.67097 loss)
I1211 14:25:22.085016 16720 solver.cpp:218] Iteration 13000 (13.2253 iter/s, 7.56128s/100 iters), loss = 1.80425
I1211 14:25:22.085016 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:25:22.085016 16720 solver.cpp:237]     Train net output #1: loss = 1.80425 (* 1 = 1.80425 loss)
I1211 14:25:22.085016 16720 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1211 14:25:28.236088 16720 solver.cpp:218] Iteration 13100 (16.2565 iter/s, 6.15138s/100 iters), loss = 1.8606
I1211 14:25:28.236088 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:25:28.236088 16720 solver.cpp:237]     Train net output #1: loss = 1.8606 (* 1 = 1.8606 loss)
I1211 14:25:28.236088 16720 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1211 14:25:34.379938 16720 solver.cpp:218] Iteration 13200 (16.2783 iter/s, 6.14314s/100 iters), loss = 1.66678
I1211 14:25:34.379938 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:25:34.379938 16720 solver.cpp:237]     Train net output #1: loss = 1.66678 (* 1 = 1.66678 loss)
I1211 14:25:34.379938 16720 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1211 14:25:40.541854 16720 solver.cpp:218] Iteration 13300 (16.2293 iter/s, 6.16169s/100 iters), loss = 1.88806
I1211 14:25:40.541854 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:25:40.541854 16720 solver.cpp:237]     Train net output #1: loss = 1.88806 (* 1 = 1.88806 loss)
I1211 14:25:40.541854 16720 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1211 14:25:46.690485 16720 solver.cpp:218] Iteration 13400 (16.2664 iter/s, 6.14763s/100 iters), loss = 1.99038
I1211 14:25:46.690485 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:25:46.690485 16720 solver.cpp:237]     Train net output #1: loss = 1.99038 (* 1 = 1.99038 loss)
I1211 14:25:46.690485 16720 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1211 14:25:52.535276  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:25:52.778321 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_13500.caffemodel
I1211 14:25:52.794325 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_13500.solverstate
I1211 14:25:52.799326 16720 solver.cpp:330] Iteration 13500, Testing net (#0)
I1211 14:25:52.799326 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:25:54.133455 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:25:54.186444 16720 solver.cpp:397]     Test net output #0: accuracy = 0.4001
I1211 14:25:54.186444 16720 solver.cpp:397]     Test net output #1: loss = 2.31162 (* 1 = 2.31162 loss)
I1211 14:25:54.244452 16720 solver.cpp:218] Iteration 13500 (13.238 iter/s, 7.55404s/100 iters), loss = 1.93201
I1211 14:25:54.244452 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:25:54.244452 16720 solver.cpp:237]     Train net output #1: loss = 1.93201 (* 1 = 1.93201 loss)
I1211 14:25:54.244452 16720 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1211 14:26:00.392901 16720 solver.cpp:218] Iteration 13600 (16.2652 iter/s, 6.14811s/100 iters), loss = 1.79102
I1211 14:26:00.392901 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:26:00.393903 16720 solver.cpp:237]     Train net output #1: loss = 1.79102 (* 1 = 1.79102 loss)
I1211 14:26:00.393903 16720 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1211 14:26:06.555430 16720 solver.cpp:218] Iteration 13700 (16.2288 iter/s, 6.16187s/100 iters), loss = 1.54278
I1211 14:26:06.555430 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:26:06.555430 16720 solver.cpp:237]     Train net output #1: loss = 1.54278 (* 1 = 1.54278 loss)
I1211 14:26:06.555430 16720 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1211 14:26:12.714866 16720 solver.cpp:218] Iteration 13800 (16.2373 iter/s, 6.15866s/100 iters), loss = 1.75482
I1211 14:26:12.714866 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:26:12.715366 16720 solver.cpp:237]     Train net output #1: loss = 1.75482 (* 1 = 1.75482 loss)
I1211 14:26:12.715366 16720 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1211 14:26:18.871353 16720 solver.cpp:218] Iteration 13900 (16.2429 iter/s, 6.15653s/100 iters), loss = 1.87852
I1211 14:26:18.871353 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:26:18.872354 16720 solver.cpp:237]     Train net output #1: loss = 1.87852 (* 1 = 1.87852 loss)
I1211 14:26:18.872354 16720 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1211 14:26:24.720255  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:26:24.961782 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_14000.caffemodel
I1211 14:26:24.976784 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_14000.solverstate
I1211 14:26:24.981784 16720 solver.cpp:330] Iteration 14000, Testing net (#0)
I1211 14:26:24.981784 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:26:26.317102 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:26:26.369103 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2946
I1211 14:26:26.370105 16720 solver.cpp:397]     Test net output #1: loss = 3.16998 (* 1 = 3.16998 loss)
I1211 14:26:26.428112 16720 solver.cpp:218] Iteration 14000 (13.2351 iter/s, 7.55564s/100 iters), loss = 1.88979
I1211 14:26:26.428112 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:26:26.428112 16720 solver.cpp:237]     Train net output #1: loss = 1.88979 (* 1 = 1.88979 loss)
I1211 14:26:26.428112 16720 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1211 14:26:32.582656 16720 solver.cpp:218] Iteration 14100 (16.2496 iter/s, 6.15399s/100 iters), loss = 1.57758
I1211 14:26:32.582656 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:26:32.582656 16720 solver.cpp:237]     Train net output #1: loss = 1.57758 (* 1 = 1.57758 loss)
I1211 14:26:32.582656 16720 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1211 14:26:38.735134 16720 solver.cpp:218] Iteration 14200 (16.2541 iter/s, 6.1523s/100 iters), loss = 1.46625
I1211 14:26:38.735134 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:26:38.735134 16720 solver.cpp:237]     Train net output #1: loss = 1.46625 (* 1 = 1.46625 loss)
I1211 14:26:38.735134 16720 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1211 14:26:44.894558 16720 solver.cpp:218] Iteration 14300 (16.2358 iter/s, 6.15924s/100 iters), loss = 2.00536
I1211 14:26:44.894558 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:26:44.894558 16720 solver.cpp:237]     Train net output #1: loss = 2.00536 (* 1 = 2.00536 loss)
I1211 14:26:44.894558 16720 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1211 14:26:51.043984 16720 solver.cpp:218] Iteration 14400 (16.263 iter/s, 6.14891s/100 iters), loss = 1.96546
I1211 14:26:51.043984 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:26:51.043984 16720 solver.cpp:237]     Train net output #1: loss = 1.96546 (* 1 = 1.96546 loss)
I1211 14:26:51.043984 16720 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1211 14:26:56.905388  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:26:57.148417 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_14500.caffemodel
I1211 14:26:57.164409 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_14500.solverstate
I1211 14:26:57.169407 16720 solver.cpp:330] Iteration 14500, Testing net (#0)
I1211 14:26:57.169407 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:26:58.507519 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:26:58.560523 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3082
I1211 14:26:58.560523 16720 solver.cpp:397]     Test net output #1: loss = 2.90671 (* 1 = 2.90671 loss)
I1211 14:26:58.619025 16720 solver.cpp:218] Iteration 14500 (13.2028 iter/s, 7.57415s/100 iters), loss = 1.87957
I1211 14:26:58.619525 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:26:58.619525 16720 solver.cpp:237]     Train net output #1: loss = 1.87957 (* 1 = 1.87957 loss)
I1211 14:26:58.619525 16720 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1211 14:27:04.784026 16720 solver.cpp:218] Iteration 14600 (16.223 iter/s, 6.16408s/100 iters), loss = 1.66384
I1211 14:27:04.784026 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:27:04.784026 16720 solver.cpp:237]     Train net output #1: loss = 1.66384 (* 1 = 1.66384 loss)
I1211 14:27:04.784026 16720 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1211 14:27:10.944478 16720 solver.cpp:218] Iteration 14700 (16.2325 iter/s, 6.16049s/100 iters), loss = 1.53619
I1211 14:27:10.944478 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:27:10.944478 16720 solver.cpp:237]     Train net output #1: loss = 1.53619 (* 1 = 1.53619 loss)
I1211 14:27:10.944478 16720 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1211 14:27:17.097898 16720 solver.cpp:218] Iteration 14800 (16.2517 iter/s, 6.1532s/100 iters), loss = 1.93631
I1211 14:27:17.097898 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:27:17.097898 16720 solver.cpp:237]     Train net output #1: loss = 1.93631 (* 1 = 1.93631 loss)
I1211 14:27:17.097898 16720 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1211 14:27:23.252387 16720 solver.cpp:218] Iteration 14900 (16.2506 iter/s, 6.15361s/100 iters), loss = 1.89126
I1211 14:27:23.252387 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:27:23.252387 16720 solver.cpp:237]     Train net output #1: loss = 1.89126 (* 1 = 1.89126 loss)
I1211 14:27:23.252387 16720 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1211 14:27:29.095408  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:27:29.335921 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_15000.caffemodel
I1211 14:27:29.352921 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_15000.solverstate
I1211 14:27:29.357920 16720 solver.cpp:330] Iteration 15000, Testing net (#0)
I1211 14:27:29.357920 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:27:30.695544 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:27:30.748047 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3531
I1211 14:27:30.748047 16720 solver.cpp:397]     Test net output #1: loss = 2.58508 (* 1 = 2.58508 loss)
I1211 14:27:30.806089 16720 solver.cpp:218] Iteration 15000 (13.2386 iter/s, 7.55366s/100 iters), loss = 1.80474
I1211 14:27:30.806089 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:27:30.806089 16720 solver.cpp:237]     Train net output #1: loss = 1.80474 (* 1 = 1.80474 loss)
I1211 14:27:30.806089 16720 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1211 14:27:36.944113 16720 solver.cpp:218] Iteration 15100 (16.2947 iter/s, 6.13696s/100 iters), loss = 1.62666
I1211 14:27:36.944113 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:27:36.944113 16720 solver.cpp:237]     Train net output #1: loss = 1.62666 (* 1 = 1.62666 loss)
I1211 14:27:36.944113 16720 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1211 14:27:43.090591 16720 solver.cpp:218] Iteration 15200 (16.2691 iter/s, 6.14661s/100 iters), loss = 1.54644
I1211 14:27:43.090591 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:27:43.090591 16720 solver.cpp:237]     Train net output #1: loss = 1.54644 (* 1 = 1.54644 loss)
I1211 14:27:43.090591 16720 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1211 14:27:49.235155 16720 solver.cpp:218] Iteration 15300 (16.2757 iter/s, 6.14412s/100 iters), loss = 1.68634
I1211 14:27:49.235155 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:27:49.235155 16720 solver.cpp:237]     Train net output #1: loss = 1.68634 (* 1 = 1.68634 loss)
I1211 14:27:49.235155 16720 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1211 14:27:55.385646 16720 solver.cpp:218] Iteration 15400 (16.2612 iter/s, 6.14962s/100 iters), loss = 1.92252
I1211 14:27:55.385646 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:27:55.385646 16720 solver.cpp:237]     Train net output #1: loss = 1.92252 (* 1 = 1.92252 loss)
I1211 14:27:55.385646 16720 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1211 14:28:01.242132  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:28:01.485142 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_15500.caffemodel
I1211 14:28:01.502143 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_15500.solverstate
I1211 14:28:01.506142 16720 solver.cpp:330] Iteration 15500, Testing net (#0)
I1211 14:28:01.506142 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:28:02.843233 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:28:02.895232 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3475
I1211 14:28:02.895232 16720 solver.cpp:397]     Test net output #1: loss = 2.65095 (* 1 = 2.65095 loss)
I1211 14:28:02.954252 16720 solver.cpp:218] Iteration 15500 (13.2134 iter/s, 7.56807s/100 iters), loss = 1.92127
I1211 14:28:02.954252 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:28:02.954252 16720 solver.cpp:237]     Train net output #1: loss = 1.92127 (* 1 = 1.92127 loss)
I1211 14:28:02.954252 16720 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1211 14:28:09.093675 16720 solver.cpp:218] Iteration 15600 (16.2882 iter/s, 6.13942s/100 iters), loss = 1.5303
I1211 14:28:09.093675 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:28:09.093675 16720 solver.cpp:237]     Train net output #1: loss = 1.5303 (* 1 = 1.5303 loss)
I1211 14:28:09.093675 16720 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1211 14:28:15.232888 16720 solver.cpp:218] Iteration 15700 (16.2907 iter/s, 6.13848s/100 iters), loss = 1.49754
I1211 14:28:15.232888 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:28:15.232888 16720 solver.cpp:237]     Train net output #1: loss = 1.49754 (* 1 = 1.49754 loss)
I1211 14:28:15.232888 16720 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1211 14:28:21.372376 16720 solver.cpp:218] Iteration 15800 (16.289 iter/s, 6.1391s/100 iters), loss = 1.80584
I1211 14:28:21.372376 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:28:21.372376 16720 solver.cpp:237]     Train net output #1: loss = 1.80584 (* 1 = 1.80584 loss)
I1211 14:28:21.372376 16720 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1211 14:28:27.513538 16720 solver.cpp:218] Iteration 15900 (16.284 iter/s, 6.141s/100 iters), loss = 1.8954
I1211 14:28:27.514528 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:28:27.514528 16720 solver.cpp:237]     Train net output #1: loss = 1.8954 (* 1 = 1.8954 loss)
I1211 14:28:27.514528 16720 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1211 14:28:33.361397  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:28:33.604408 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_16000.caffemodel
I1211 14:28:33.619413 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_16000.solverstate
I1211 14:28:33.624415 16720 solver.cpp:330] Iteration 16000, Testing net (#0)
I1211 14:28:33.624415 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:28:34.961529 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:28:35.013545 16720 solver.cpp:397]     Test net output #0: accuracy = 0.4045
I1211 14:28:35.013545 16720 solver.cpp:397]     Test net output #1: loss = 2.28605 (* 1 = 2.28605 loss)
I1211 14:28:35.073540 16720 solver.cpp:218] Iteration 16000 (13.2299 iter/s, 7.55863s/100 iters), loss = 1.67655
I1211 14:28:35.073540 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:28:35.073540 16720 solver.cpp:237]     Train net output #1: loss = 1.67655 (* 1 = 1.67655 loss)
I1211 14:28:35.073540 16720 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1211 14:28:41.230049 16720 solver.cpp:218] Iteration 16100 (16.244 iter/s, 6.15613s/100 iters), loss = 1.717
I1211 14:28:41.230049 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:28:41.230049 16720 solver.cpp:237]     Train net output #1: loss = 1.717 (* 1 = 1.717 loss)
I1211 14:28:41.230049 16720 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1211 14:28:47.381611 16720 solver.cpp:218] Iteration 16200 (16.257 iter/s, 6.1512s/100 iters), loss = 1.45869
I1211 14:28:47.381611 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:28:47.381611 16720 solver.cpp:237]     Train net output #1: loss = 1.45869 (* 1 = 1.45869 loss)
I1211 14:28:47.381611 16720 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1211 14:28:53.541101 16720 solver.cpp:218] Iteration 16300 (16.2353 iter/s, 6.15942s/100 iters), loss = 1.80812
I1211 14:28:53.541101 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:28:53.541101 16720 solver.cpp:237]     Train net output #1: loss = 1.80812 (* 1 = 1.80812 loss)
I1211 14:28:53.541101 16720 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1211 14:28:59.705024 16720 solver.cpp:218] Iteration 16400 (16.2258 iter/s, 6.16303s/100 iters), loss = 1.8736
I1211 14:28:59.705024 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:28:59.705024 16720 solver.cpp:237]     Train net output #1: loss = 1.8736 (* 1 = 1.8736 loss)
I1211 14:28:59.705024 16720 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1211 14:29:05.554929  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:29:05.796958 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_16500.caffemodel
I1211 14:29:05.814961 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_16500.solverstate
I1211 14:29:05.819968 16720 solver.cpp:330] Iteration 16500, Testing net (#0)
I1211 14:29:05.819968 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:29:07.154045 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:29:07.207548 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3565
I1211 14:29:07.207548 16720 solver.cpp:397]     Test net output #1: loss = 2.63825 (* 1 = 2.63825 loss)
I1211 14:29:07.266049 16720 solver.cpp:218] Iteration 16500 (13.2259 iter/s, 7.56094s/100 iters), loss = 1.81876
I1211 14:29:07.266049 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:29:07.266049 16720 solver.cpp:237]     Train net output #1: loss = 1.81876 (* 1 = 1.81876 loss)
I1211 14:29:07.266049 16720 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1211 14:29:13.423563 16720 solver.cpp:218] Iteration 16600 (16.2409 iter/s, 6.15729s/100 iters), loss = 1.64367
I1211 14:29:13.423563 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:29:13.423563 16720 solver.cpp:237]     Train net output #1: loss = 1.64367 (* 1 = 1.64367 loss)
I1211 14:29:13.423563 16720 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1211 14:29:19.589692 16720 solver.cpp:218] Iteration 16700 (16.2189 iter/s, 6.16564s/100 iters), loss = 1.41996
I1211 14:29:19.589692 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:29:19.589692 16720 solver.cpp:237]     Train net output #1: loss = 1.41996 (* 1 = 1.41996 loss)
I1211 14:29:19.589692 16720 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1211 14:29:25.745803 16720 solver.cpp:218] Iteration 16800 (16.2468 iter/s, 6.15507s/100 iters), loss = 1.7798
I1211 14:29:25.745803 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:29:25.745803 16720 solver.cpp:237]     Train net output #1: loss = 1.7798 (* 1 = 1.7798 loss)
I1211 14:29:25.745803 16720 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1211 14:29:31.902647 16720 solver.cpp:218] Iteration 16900 (16.2412 iter/s, 6.15717s/100 iters), loss = 1.91506
I1211 14:29:31.902647 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:29:31.902647 16720 solver.cpp:237]     Train net output #1: loss = 1.91506 (* 1 = 1.91506 loss)
I1211 14:29:31.902647 16720 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1211 14:29:37.755693  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:29:37.998702 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_17000.caffemodel
I1211 14:29:38.015205 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_17000.solverstate
I1211 14:29:38.020207 16720 solver.cpp:330] Iteration 17000, Testing net (#0)
I1211 14:29:38.020207 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:29:39.360821 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:29:39.414338 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2847
I1211 14:29:39.414338 16720 solver.cpp:397]     Test net output #1: loss = 3.27994 (* 1 = 3.27994 loss)
I1211 14:29:39.472826 16720 solver.cpp:218] Iteration 17000 (13.2103 iter/s, 7.56983s/100 iters), loss = 1.73266
I1211 14:29:39.472826 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:29:39.472826 16720 solver.cpp:237]     Train net output #1: loss = 1.73266 (* 1 = 1.73266 loss)
I1211 14:29:39.473826 16720 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1211 14:29:45.629415 16720 solver.cpp:218] Iteration 17100 (16.2452 iter/s, 6.15568s/100 iters), loss = 1.70439
I1211 14:29:45.629415 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:29:45.629415 16720 solver.cpp:237]     Train net output #1: loss = 1.70439 (* 1 = 1.70439 loss)
I1211 14:29:45.629415 16720 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1211 14:29:51.789840 16720 solver.cpp:218] Iteration 17200 (16.2341 iter/s, 6.15986s/100 iters), loss = 1.40614
I1211 14:29:51.789840 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:29:51.789840 16720 solver.cpp:237]     Train net output #1: loss = 1.40614 (* 1 = 1.40614 loss)
I1211 14:29:51.789840 16720 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1211 14:29:57.946254 16720 solver.cpp:218] Iteration 17300 (16.2447 iter/s, 6.15584s/100 iters), loss = 1.85106
I1211 14:29:57.946254 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:29:57.946254 16720 solver.cpp:237]     Train net output #1: loss = 1.85106 (* 1 = 1.85106 loss)
I1211 14:29:57.946254 16720 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1211 14:30:04.120853 16720 solver.cpp:218] Iteration 17400 (16.1958 iter/s, 6.17444s/100 iters), loss = 1.9828
I1211 14:30:04.120853 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:30:04.120853 16720 solver.cpp:237]     Train net output #1: loss = 1.9828 (* 1 = 1.9828 loss)
I1211 14:30:04.120853 16720 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1211 14:30:09.968231  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:30:10.210242 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_17500.caffemodel
I1211 14:30:10.225248 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_17500.solverstate
I1211 14:30:10.230248 16720 solver.cpp:330] Iteration 17500, Testing net (#0)
I1211 14:30:10.230248 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:30:11.565870 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:30:11.618381 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3277
I1211 14:30:11.618381 16720 solver.cpp:397]     Test net output #1: loss = 2.88224 (* 1 = 2.88224 loss)
I1211 14:30:11.677381 16720 solver.cpp:218] Iteration 17500 (13.2355 iter/s, 7.55545s/100 iters), loss = 1.83048
I1211 14:30:11.677381 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:30:11.677381 16720 solver.cpp:237]     Train net output #1: loss = 1.83048 (* 1 = 1.83048 loss)
I1211 14:30:11.677381 16720 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1211 14:30:17.832900 16720 solver.cpp:218] Iteration 17600 (16.2455 iter/s, 6.15556s/100 iters), loss = 1.60833
I1211 14:30:17.832900 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:30:17.832900 16720 solver.cpp:237]     Train net output #1: loss = 1.60833 (* 1 = 1.60833 loss)
I1211 14:30:17.832900 16720 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1211 14:30:23.986346 16720 solver.cpp:218] Iteration 17700 (16.2518 iter/s, 6.15317s/100 iters), loss = 1.59996
I1211 14:30:23.986346 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:30:23.986346 16720 solver.cpp:237]     Train net output #1: loss = 1.59996 (* 1 = 1.59996 loss)
I1211 14:30:23.986346 16720 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1211 14:30:30.144831 16720 solver.cpp:218] Iteration 17800 (16.2389 iter/s, 6.15806s/100 iters), loss = 1.71456
I1211 14:30:30.145833 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:30:30.145833 16720 solver.cpp:237]     Train net output #1: loss = 1.71456 (* 1 = 1.71456 loss)
I1211 14:30:30.145833 16720 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1211 14:30:36.311751 16720 solver.cpp:218] Iteration 17900 (16.2181 iter/s, 6.16595s/100 iters), loss = 1.85727
I1211 14:30:36.312252 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:30:36.312252 16720 solver.cpp:237]     Train net output #1: loss = 1.85727 (* 1 = 1.85727 loss)
I1211 14:30:36.312252 16720 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1211 14:30:42.163698  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:30:42.407210 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_18000.caffemodel
I1211 14:30:42.421715 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_18000.solverstate
I1211 14:30:42.426715 16720 solver.cpp:330] Iteration 18000, Testing net (#0)
I1211 14:30:42.426715 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:30:43.763808 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:30:43.816321 16720 solver.cpp:397]     Test net output #0: accuracy = 0.341
I1211 14:30:43.816321 16720 solver.cpp:397]     Test net output #1: loss = 2.75588 (* 1 = 2.75588 loss)
I1211 14:30:43.874825 16720 solver.cpp:218] Iteration 18000 (13.223 iter/s, 7.56257s/100 iters), loss = 1.84519
I1211 14:30:43.874825 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:30:43.874825 16720 solver.cpp:237]     Train net output #1: loss = 1.84519 (* 1 = 1.84519 loss)
I1211 14:30:43.874825 16720 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1211 14:30:50.027336 16720 solver.cpp:218] Iteration 18100 (16.2541 iter/s, 6.15228s/100 iters), loss = 1.62022
I1211 14:30:50.027336 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:30:50.027336 16720 solver.cpp:237]     Train net output #1: loss = 1.62022 (* 1 = 1.62022 loss)
I1211 14:30:50.027336 16720 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1211 14:30:56.171875 16720 solver.cpp:218] Iteration 18200 (16.2751 iter/s, 6.14437s/100 iters), loss = 1.46653
I1211 14:30:56.172868 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:30:56.172868 16720 solver.cpp:237]     Train net output #1: loss = 1.46653 (* 1 = 1.46653 loss)
I1211 14:30:56.172868 16720 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1211 14:31:02.329599 16720 solver.cpp:218] Iteration 18300 (16.2418 iter/s, 6.15696s/100 iters), loss = 1.85312
I1211 14:31:02.329599 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:31:02.329599 16720 solver.cpp:237]     Train net output #1: loss = 1.85312 (* 1 = 1.85312 loss)
I1211 14:31:02.329599 16720 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1211 14:31:08.480180 16720 solver.cpp:218] Iteration 18400 (16.2596 iter/s, 6.15023s/100 iters), loss = 2.02741
I1211 14:31:08.480180 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:31:08.480180 16720 solver.cpp:237]     Train net output #1: loss = 2.02741 (* 1 = 2.02741 loss)
I1211 14:31:08.480180 16720 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1211 14:31:14.342681  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:31:14.585700 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_18500.caffemodel
I1211 14:31:14.600700 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_18500.solverstate
I1211 14:31:14.605705 16720 solver.cpp:330] Iteration 18500, Testing net (#0)
I1211 14:31:14.605705 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:31:15.942028 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:31:15.994027 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3389
I1211 14:31:15.994027 16720 solver.cpp:397]     Test net output #1: loss = 2.79815 (* 1 = 2.79815 loss)
I1211 14:31:16.053032 16720 solver.cpp:218] Iteration 18500 (13.2063 iter/s, 7.57215s/100 iters), loss = 1.85782
I1211 14:31:16.053032 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:31:16.053032 16720 solver.cpp:237]     Train net output #1: loss = 1.85782 (* 1 = 1.85782 loss)
I1211 14:31:16.053032 16720 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1211 14:31:22.210008 16720 solver.cpp:218] Iteration 18600 (16.244 iter/s, 6.15611s/100 iters), loss = 1.6221
I1211 14:31:22.210008 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:31:22.210008 16720 solver.cpp:237]     Train net output #1: loss = 1.6221 (* 1 = 1.6221 loss)
I1211 14:31:22.210008 16720 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1211 14:31:28.357002 16720 solver.cpp:218] Iteration 18700 (16.2679 iter/s, 6.14708s/100 iters), loss = 1.42954
I1211 14:31:28.357002 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:31:28.357002 16720 solver.cpp:237]     Train net output #1: loss = 1.42954 (* 1 = 1.42954 loss)
I1211 14:31:28.357002 16720 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1211 14:31:34.501487 16720 solver.cpp:218] Iteration 18800 (16.277 iter/s, 6.14363s/100 iters), loss = 1.95545
I1211 14:31:34.501487 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:31:34.501487 16720 solver.cpp:237]     Train net output #1: loss = 1.95545 (* 1 = 1.95545 loss)
I1211 14:31:34.501487 16720 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1211 14:31:40.649950 16720 solver.cpp:218] Iteration 18900 (16.265 iter/s, 6.14816s/100 iters), loss = 1.95404
I1211 14:31:40.649950 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:31:40.649950 16720 solver.cpp:237]     Train net output #1: loss = 1.95404 (* 1 = 1.95404 loss)
I1211 14:31:40.649950 16720 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1211 14:31:46.497364  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:31:46.739379 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_19000.caffemodel
I1211 14:31:46.755380 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_19000.solverstate
I1211 14:31:46.760380 16720 solver.cpp:330] Iteration 19000, Testing net (#0)
I1211 14:31:46.760380 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:31:48.098476 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:31:48.150485 16720 solver.cpp:397]     Test net output #0: accuracy = 0.288
I1211 14:31:48.150485 16720 solver.cpp:397]     Test net output #1: loss = 3.0984 (* 1 = 3.0984 loss)
I1211 14:31:48.210487 16720 solver.cpp:218] Iteration 19000 (13.2278 iter/s, 7.55986s/100 iters), loss = 1.88797
I1211 14:31:48.210487 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:31:48.210487 16720 solver.cpp:237]     Train net output #1: loss = 1.88797 (* 1 = 1.88797 loss)
I1211 14:31:48.210487 16720 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1211 14:31:54.358903 16720 solver.cpp:218] Iteration 19100 (16.2636 iter/s, 6.14869s/100 iters), loss = 1.44006
I1211 14:31:54.358903 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:31:54.358903 16720 solver.cpp:237]     Train net output #1: loss = 1.44006 (* 1 = 1.44006 loss)
I1211 14:31:54.358903 16720 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1211 14:32:00.509341 16720 solver.cpp:218] Iteration 19200 (16.261 iter/s, 6.1497s/100 iters), loss = 1.41099
I1211 14:32:00.509341 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:32:00.509341 16720 solver.cpp:237]     Train net output #1: loss = 1.41099 (* 1 = 1.41099 loss)
I1211 14:32:00.509341 16720 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1211 14:32:06.659763 16720 solver.cpp:218] Iteration 19300 (16.2611 iter/s, 6.14966s/100 iters), loss = 1.82556
I1211 14:32:06.659763 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:32:06.659763 16720 solver.cpp:237]     Train net output #1: loss = 1.82556 (* 1 = 1.82556 loss)
I1211 14:32:06.659763 16720 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1211 14:32:12.823228 16720 solver.cpp:218] Iteration 19400 (16.2264 iter/s, 6.1628s/100 iters), loss = 1.87776
I1211 14:32:12.823228 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 14:32:12.823228 16720 solver.cpp:237]     Train net output #1: loss = 1.87776 (* 1 = 1.87776 loss)
I1211 14:32:12.823228 16720 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1211 14:32:18.674713  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:32:18.917727 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_19500.caffemodel
I1211 14:32:18.931731 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_19500.solverstate
I1211 14:32:18.935731 16720 solver.cpp:330] Iteration 19500, Testing net (#0)
I1211 14:32:18.936731 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:32:20.270813 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:32:20.323818 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3355
I1211 14:32:20.323818 16720 solver.cpp:397]     Test net output #1: loss = 2.74081 (* 1 = 2.74081 loss)
I1211 14:32:20.381821 16720 solver.cpp:218] Iteration 19500 (13.2298 iter/s, 7.5587s/100 iters), loss = 1.90003
I1211 14:32:20.381821 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 14:32:20.381821 16720 solver.cpp:237]     Train net output #1: loss = 1.90003 (* 1 = 1.90003 loss)
I1211 14:32:20.381821 16720 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1211 14:32:26.538332 16720 solver.cpp:218] Iteration 19600 (16.2436 iter/s, 6.15626s/100 iters), loss = 1.58966
I1211 14:32:26.538332 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:32:26.538332 16720 solver.cpp:237]     Train net output #1: loss = 1.58966 (* 1 = 1.58966 loss)
I1211 14:32:26.539332 16720 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1211 14:32:32.689824 16720 solver.cpp:218] Iteration 19700 (16.2595 iter/s, 6.15026s/100 iters), loss = 1.34886
I1211 14:32:32.689824 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:32:32.689824 16720 solver.cpp:237]     Train net output #1: loss = 1.34886 (* 1 = 1.34886 loss)
I1211 14:32:32.689824 16720 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1211 14:32:38.846297 16720 solver.cpp:218] Iteration 19800 (16.2437 iter/s, 6.15623s/100 iters), loss = 1.85912
I1211 14:32:38.846297 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:32:38.846297 16720 solver.cpp:237]     Train net output #1: loss = 1.85912 (* 1 = 1.85912 loss)
I1211 14:32:38.846297 16720 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1211 14:32:44.994884 16720 solver.cpp:218] Iteration 19900 (16.2665 iter/s, 6.1476s/100 iters), loss = 1.88034
I1211 14:32:44.994884 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:32:44.994884 16720 solver.cpp:237]     Train net output #1: loss = 1.88034 (* 1 = 1.88034 loss)
I1211 14:32:44.994884 16720 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1211 14:32:50.846722  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:32:51.089337 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_20000.caffemodel
I1211 14:32:51.105339 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_20000.solverstate
I1211 14:32:51.109338 16720 solver.cpp:330] Iteration 20000, Testing net (#0)
I1211 14:32:51.110338 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:32:52.444229 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:32:52.497243 16720 solver.cpp:397]     Test net output #0: accuracy = 0.306
I1211 14:32:52.497243 16720 solver.cpp:397]     Test net output #1: loss = 3.10686 (* 1 = 3.10686 loss)
I1211 14:32:52.556255 16720 solver.cpp:218] Iteration 20000 (13.2246 iter/s, 7.56168s/100 iters), loss = 1.672
I1211 14:32:52.556255 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:32:52.556255 16720 solver.cpp:237]     Train net output #1: loss = 1.672 (* 1 = 1.672 loss)
I1211 14:32:52.556255 16720 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1211 14:32:58.719588 16720 solver.cpp:218] Iteration 20100 (16.2284 iter/s, 6.16205s/100 iters), loss = 1.68146
I1211 14:32:58.719588 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:32:58.719588 16720 solver.cpp:237]     Train net output #1: loss = 1.68146 (* 1 = 1.68146 loss)
I1211 14:32:58.719588 16720 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1211 14:33:04.873617 16720 solver.cpp:218] Iteration 20200 (16.2498 iter/s, 6.15394s/100 iters), loss = 1.30771
I1211 14:33:04.873617 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 14:33:04.873617 16720 solver.cpp:237]     Train net output #1: loss = 1.30771 (* 1 = 1.30771 loss)
I1211 14:33:04.873617 16720 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1211 14:33:11.033107 16720 solver.cpp:218] Iteration 20300 (16.2367 iter/s, 6.15888s/100 iters), loss = 1.73195
I1211 14:33:11.033107 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:33:11.033107 16720 solver.cpp:237]     Train net output #1: loss = 1.73195 (* 1 = 1.73195 loss)
I1211 14:33:11.033107 16720 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1211 14:33:17.194852 16720 solver.cpp:218] Iteration 20400 (16.2309 iter/s, 6.16109s/100 iters), loss = 1.92223
I1211 14:33:17.194852 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 14:33:17.194852 16720 solver.cpp:237]     Train net output #1: loss = 1.92223 (* 1 = 1.92223 loss)
I1211 14:33:17.194852 16720 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1211 14:33:23.039971  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:33:23.283984 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_20500.caffemodel
I1211 14:33:23.298987 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_20500.solverstate
I1211 14:33:23.303988 16720 solver.cpp:330] Iteration 20500, Testing net (#0)
I1211 14:33:23.303988 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:33:24.640089 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:33:24.693094 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3284
I1211 14:33:24.693094 16720 solver.cpp:397]     Test net output #1: loss = 2.77861 (* 1 = 2.77861 loss)
I1211 14:33:24.752091 16720 solver.cpp:218] Iteration 20500 (13.2319 iter/s, 7.55748s/100 iters), loss = 1.74556
I1211 14:33:24.752091 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:33:24.752091 16720 solver.cpp:237]     Train net output #1: loss = 1.74556 (* 1 = 1.74556 loss)
I1211 14:33:24.752091 16720 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1211 14:33:30.904880 16720 solver.cpp:218] Iteration 20600 (16.2538 iter/s, 6.1524s/100 iters), loss = 1.59169
I1211 14:33:30.904880 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:33:30.904880 16720 solver.cpp:237]     Train net output #1: loss = 1.59169 (* 1 = 1.59169 loss)
I1211 14:33:30.904880 16720 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1211 14:33:37.051654 16720 solver.cpp:218] Iteration 20700 (16.2696 iter/s, 6.14644s/100 iters), loss = 1.43038
I1211 14:33:37.051654 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:33:37.051654 16720 solver.cpp:237]     Train net output #1: loss = 1.43038 (* 1 = 1.43038 loss)
I1211 14:33:37.051654 16720 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1211 14:33:43.252216 16720 solver.cpp:218] Iteration 20800 (16.13 iter/s, 6.19964s/100 iters), loss = 1.72644
I1211 14:33:43.252216 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:33:43.252216 16720 solver.cpp:237]     Train net output #1: loss = 1.72644 (* 1 = 1.72644 loss)
I1211 14:33:43.252216 16720 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1211 14:33:49.462983 16720 solver.cpp:218] Iteration 20900 (16.1012 iter/s, 6.21073s/100 iters), loss = 1.89765
I1211 14:33:49.462983 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:33:49.462983 16720 solver.cpp:237]     Train net output #1: loss = 1.89765 (* 1 = 1.89765 loss)
I1211 14:33:49.462983 16720 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1211 14:33:55.350044  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:33:55.595080 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_21000.caffemodel
I1211 14:33:55.612087 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_21000.solverstate
I1211 14:33:55.616086 16720 solver.cpp:330] Iteration 21000, Testing net (#0)
I1211 14:33:55.616086 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:33:56.962229 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:33:57.016242 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3481
I1211 14:33:57.016242 16720 solver.cpp:397]     Test net output #1: loss = 2.6435 (* 1 = 2.6435 loss)
I1211 14:33:57.075237 16720 solver.cpp:218] Iteration 21000 (13.1375 iter/s, 7.61177s/100 iters), loss = 1.7302
I1211 14:33:57.075237 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:33:57.076248 16720 solver.cpp:237]     Train net output #1: loss = 1.7302 (* 1 = 1.7302 loss)
I1211 14:33:57.076248 16720 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1211 14:34:03.261662 16720 solver.cpp:218] Iteration 21100 (16.1683 iter/s, 6.18494s/100 iters), loss = 1.53999
I1211 14:34:03.261662 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:34:03.261662 16720 solver.cpp:237]     Train net output #1: loss = 1.53999 (* 1 = 1.53999 loss)
I1211 14:34:03.261662 16720 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1211 14:34:09.517478 16720 solver.cpp:218] Iteration 21200 (15.9855 iter/s, 6.25568s/100 iters), loss = 1.49162
I1211 14:34:09.517478 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:34:09.517478 16720 solver.cpp:237]     Train net output #1: loss = 1.49162 (* 1 = 1.49162 loss)
I1211 14:34:09.517478 16720 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1211 14:34:15.728657 16720 solver.cpp:218] Iteration 21300 (16.1003 iter/s, 6.21108s/100 iters), loss = 1.66873
I1211 14:34:15.728657 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:34:15.728657 16720 solver.cpp:237]     Train net output #1: loss = 1.66873 (* 1 = 1.66873 loss)
I1211 14:34:15.728657 16720 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1211 14:34:21.967185 16720 solver.cpp:218] Iteration 21400 (16.0302 iter/s, 6.23821s/100 iters), loss = 1.91021
I1211 14:34:21.967185 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:34:21.968185 16720 solver.cpp:237]     Train net output #1: loss = 1.91021 (* 1 = 1.91021 loss)
I1211 14:34:21.968185 16720 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1211 14:34:27.841339  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:34:28.089370 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_21500.caffemodel
I1211 14:34:28.104876 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_21500.solverstate
I1211 14:34:28.109377 16720 solver.cpp:330] Iteration 21500, Testing net (#0)
I1211 14:34:28.109377 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:34:29.455524 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:34:29.508028 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3073
I1211 14:34:29.508028 16720 solver.cpp:397]     Test net output #1: loss = 2.92505 (* 1 = 2.92505 loss)
I1211 14:34:29.567529 16720 solver.cpp:218] Iteration 21500 (13.1598 iter/s, 7.59892s/100 iters), loss = 1.74465
I1211 14:34:29.567529 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:34:29.567529 16720 solver.cpp:237]     Train net output #1: loss = 1.74465 (* 1 = 1.74465 loss)
I1211 14:34:29.567529 16720 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1211 14:34:35.732671 16720 solver.cpp:218] Iteration 21600 (16.2192 iter/s, 6.16552s/100 iters), loss = 1.59382
I1211 14:34:35.732671 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:34:35.732671 16720 solver.cpp:237]     Train net output #1: loss = 1.59382 (* 1 = 1.59382 loss)
I1211 14:34:35.732671 16720 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1211 14:34:42.050302 16720 solver.cpp:218] Iteration 21700 (15.8315 iter/s, 6.31652s/100 iters), loss = 1.43942
I1211 14:34:42.050302 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:34:42.050302 16720 solver.cpp:237]     Train net output #1: loss = 1.43942 (* 1 = 1.43942 loss)
I1211 14:34:42.050302 16720 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1211 14:34:48.394811 16720 solver.cpp:218] Iteration 21800 (15.7627 iter/s, 6.3441s/100 iters), loss = 1.68373
I1211 14:34:48.394811 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:34:48.394811 16720 solver.cpp:237]     Train net output #1: loss = 1.68373 (* 1 = 1.68373 loss)
I1211 14:34:48.394811 16720 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1211 14:34:54.739382 16720 solver.cpp:218] Iteration 21900 (15.7629 iter/s, 6.344s/100 iters), loss = 1.7752
I1211 14:34:54.739382 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:34:54.739382 16720 solver.cpp:237]     Train net output #1: loss = 1.7752 (* 1 = 1.7752 loss)
I1211 14:34:54.739382 16720 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1211 14:35:00.834347  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:35:01.080369 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_22000.caffemodel
I1211 14:35:01.097367 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_22000.solverstate
I1211 14:35:01.102367 16720 solver.cpp:330] Iteration 22000, Testing net (#0)
I1211 14:35:01.102367 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:35:02.465716 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:35:02.518723 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3702
I1211 14:35:02.518723 16720 solver.cpp:397]     Test net output #1: loss = 2.51561 (* 1 = 2.51561 loss)
I1211 14:35:02.578724 16720 solver.cpp:218] Iteration 22000 (12.7576 iter/s, 7.83849s/100 iters), loss = 1.76607
I1211 14:35:02.578724 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:35:02.578724 16720 solver.cpp:237]     Train net output #1: loss = 1.76607 (* 1 = 1.76607 loss)
I1211 14:35:02.578724 16720 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1211 14:35:08.983629 16720 solver.cpp:218] Iteration 22100 (15.6144 iter/s, 6.40436s/100 iters), loss = 1.617
I1211 14:35:08.983629 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:35:08.983629 16720 solver.cpp:237]     Train net output #1: loss = 1.617 (* 1 = 1.617 loss)
I1211 14:35:08.983629 16720 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1211 14:35:15.393759 16720 solver.cpp:218] Iteration 22200 (15.5998 iter/s, 6.41033s/100 iters), loss = 1.22322
I1211 14:35:15.393759 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 14:35:15.393759 16720 solver.cpp:237]     Train net output #1: loss = 1.22322 (* 1 = 1.22322 loss)
I1211 14:35:15.393759 16720 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1211 14:35:21.802464 16720 solver.cpp:218] Iteration 22300 (15.6055 iter/s, 6.40801s/100 iters), loss = 1.81934
I1211 14:35:21.802464 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:35:21.802464 16720 solver.cpp:237]     Train net output #1: loss = 1.81934 (* 1 = 1.81934 loss)
I1211 14:35:21.802464 16720 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1211 14:35:28.216511 16720 solver.cpp:218] Iteration 22400 (15.5931 iter/s, 6.41308s/100 iters), loss = 1.82064
I1211 14:35:28.216511 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:35:28.216511 16720 solver.cpp:237]     Train net output #1: loss = 1.82064 (* 1 = 1.82064 loss)
I1211 14:35:28.216511 16720 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1211 14:35:34.318325  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:35:34.571368 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_22500.caffemodel
I1211 14:35:34.587369 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_22500.solverstate
I1211 14:35:34.592371 16720 solver.cpp:330] Iteration 22500, Testing net (#0)
I1211 14:35:34.592371 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:35:35.971354 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:35:36.024859 16720 solver.cpp:397]     Test net output #0: accuracy = 0.361
I1211 14:35:36.024859 16720 solver.cpp:397]     Test net output #1: loss = 2.56912 (* 1 = 2.56912 loss)
I1211 14:35:36.086361 16720 solver.cpp:218] Iteration 22500 (12.7071 iter/s, 7.86964s/100 iters), loss = 1.86642
I1211 14:35:36.086361 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 14:35:36.086361 16720 solver.cpp:237]     Train net output #1: loss = 1.86642 (* 1 = 1.86642 loss)
I1211 14:35:36.086361 16720 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1211 14:35:42.464964 16720 solver.cpp:218] Iteration 22600 (15.6782 iter/s, 6.37828s/100 iters), loss = 1.65628
I1211 14:35:42.464964 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:35:42.465966 16720 solver.cpp:237]     Train net output #1: loss = 1.65628 (* 1 = 1.65628 loss)
I1211 14:35:42.465966 16720 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1211 14:35:48.870559 16720 solver.cpp:218] Iteration 22700 (15.6143 iter/s, 6.40439s/100 iters), loss = 1.49992
I1211 14:35:48.870559 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:35:48.870559 16720 solver.cpp:237]     Train net output #1: loss = 1.49992 (* 1 = 1.49992 loss)
I1211 14:35:48.870559 16720 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1211 14:35:55.335979 16720 solver.cpp:218] Iteration 22800 (15.4682 iter/s, 6.46487s/100 iters), loss = 1.83272
I1211 14:35:55.335979 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:35:55.335979 16720 solver.cpp:237]     Train net output #1: loss = 1.83272 (* 1 = 1.83272 loss)
I1211 14:35:55.335979 16720 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1211 14:36:01.791231 16720 solver.cpp:218] Iteration 22900 (15.4908 iter/s, 6.45544s/100 iters), loss = 2.06447
I1211 14:36:01.792232 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:36:01.792232 16720 solver.cpp:237]     Train net output #1: loss = 2.06447 (* 1 = 2.06447 loss)
I1211 14:36:01.792232 16720 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1211 14:36:07.945529  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:36:08.203317 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_23000.caffemodel
I1211 14:36:08.221318 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_23000.solverstate
I1211 14:36:08.225318 16720 solver.cpp:330] Iteration 23000, Testing net (#0)
I1211 14:36:08.226317 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:36:09.609527 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:36:09.664036 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3341
I1211 14:36:09.664036 16720 solver.cpp:397]     Test net output #1: loss = 2.88807 (* 1 = 2.88807 loss)
I1211 14:36:09.724036 16720 solver.cpp:218] Iteration 23000 (12.6069 iter/s, 7.93216s/100 iters), loss = 1.6779
I1211 14:36:09.725034 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:36:09.725034 16720 solver.cpp:237]     Train net output #1: loss = 1.6779 (* 1 = 1.6779 loss)
I1211 14:36:09.725034 16720 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1211 14:36:16.261693 16720 solver.cpp:218] Iteration 23100 (15.2985 iter/s, 6.5366s/100 iters), loss = 1.63983
I1211 14:36:16.261693 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:36:16.261693 16720 solver.cpp:237]     Train net output #1: loss = 1.63983 (* 1 = 1.63983 loss)
I1211 14:36:16.261693 16720 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1211 14:36:22.812304 16720 solver.cpp:218] Iteration 23200 (15.2664 iter/s, 6.55034s/100 iters), loss = 1.5101
I1211 14:36:22.812304 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:36:22.812304 16720 solver.cpp:237]     Train net output #1: loss = 1.5101 (* 1 = 1.5101 loss)
I1211 14:36:22.812304 16720 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1211 14:36:29.144028 16720 solver.cpp:218] Iteration 23300 (15.7958 iter/s, 6.33079s/100 iters), loss = 1.70136
I1211 14:36:29.144028 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:36:29.144028 16720 solver.cpp:237]     Train net output #1: loss = 1.70136 (* 1 = 1.70136 loss)
I1211 14:36:29.144028 16720 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1211 14:36:35.369581 16720 solver.cpp:218] Iteration 23400 (16.0626 iter/s, 6.22566s/100 iters), loss = 1.80795
I1211 14:36:35.369581 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:36:35.369581 16720 solver.cpp:237]     Train net output #1: loss = 1.80795 (* 1 = 1.80795 loss)
I1211 14:36:35.369581 16720 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1211 14:36:41.274842  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:36:41.516867 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_23500.caffemodel
I1211 14:36:41.532867 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_23500.solverstate
I1211 14:36:41.537868 16720 solver.cpp:330] Iteration 23500, Testing net (#0)
I1211 14:36:41.537868 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:36:42.878149 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:36:42.934149 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3129
I1211 14:36:42.934149 16720 solver.cpp:397]     Test net output #1: loss = 3.03506 (* 1 = 3.03506 loss)
I1211 14:36:42.994773 16720 solver.cpp:218] Iteration 23500 (13.1165 iter/s, 7.62397s/100 iters), loss = 1.89726
I1211 14:36:42.994773 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:36:42.994773 16720 solver.cpp:237]     Train net output #1: loss = 1.89726 (* 1 = 1.89726 loss)
I1211 14:36:42.994773 16720 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1211 14:36:49.293459 16720 solver.cpp:218] Iteration 23600 (15.8778 iter/s, 6.29809s/100 iters), loss = 1.63383
I1211 14:36:49.293459 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:36:49.293459 16720 solver.cpp:237]     Train net output #1: loss = 1.63383 (* 1 = 1.63383 loss)
I1211 14:36:49.293459 16720 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1211 14:36:55.595976 16720 solver.cpp:218] Iteration 23700 (15.8677 iter/s, 6.30212s/100 iters), loss = 1.32978
I1211 14:36:55.595976 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:36:55.595976 16720 solver.cpp:237]     Train net output #1: loss = 1.32978 (* 1 = 1.32978 loss)
I1211 14:36:55.595976 16720 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1211 14:37:01.903791 16720 solver.cpp:218] Iteration 23800 (15.8541 iter/s, 6.30752s/100 iters), loss = 1.86463
I1211 14:37:01.903791 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:37:01.903791 16720 solver.cpp:237]     Train net output #1: loss = 1.86463 (* 1 = 1.86463 loss)
I1211 14:37:01.903791 16720 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1211 14:37:08.210217 16720 solver.cpp:218] Iteration 23900 (15.8585 iter/s, 6.30579s/100 iters), loss = 1.91287
I1211 14:37:08.210217 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:37:08.210217 16720 solver.cpp:237]     Train net output #1: loss = 1.91287 (* 1 = 1.91287 loss)
I1211 14:37:08.210217 16720 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1211 14:37:14.216217  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:37:14.465718 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_24000.caffemodel
I1211 14:37:14.481217 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_24000.solverstate
I1211 14:37:14.486218 16720 solver.cpp:330] Iteration 24000, Testing net (#0)
I1211 14:37:14.486218 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:37:15.850217 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:37:15.904217 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2884
I1211 14:37:15.904217 16720 solver.cpp:397]     Test net output #1: loss = 3.02173 (* 1 = 3.02173 loss)
I1211 14:37:15.963717 16720 solver.cpp:218] Iteration 24000 (12.8983 iter/s, 7.75298s/100 iters), loss = 1.78151
I1211 14:37:15.963717 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:37:15.963717 16720 solver.cpp:237]     Train net output #1: loss = 1.78151 (* 1 = 1.78151 loss)
I1211 14:37:15.963717 16720 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1211 14:37:22.284744 16720 solver.cpp:218] Iteration 24100 (15.8219 iter/s, 6.32036s/100 iters), loss = 1.54427
I1211 14:37:22.284744 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:37:22.284744 16720 solver.cpp:237]     Train net output #1: loss = 1.54427 (* 1 = 1.54427 loss)
I1211 14:37:22.284744 16720 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1211 14:37:28.599745 16720 solver.cpp:218] Iteration 24200 (15.8369 iter/s, 6.31438s/100 iters), loss = 1.36587
I1211 14:37:28.599745 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:37:28.599745 16720 solver.cpp:237]     Train net output #1: loss = 1.36587 (* 1 = 1.36587 loss)
I1211 14:37:28.599745 16720 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1211 14:37:34.912786 16720 solver.cpp:218] Iteration 24300 (15.8411 iter/s, 6.31271s/100 iters), loss = 1.5729
I1211 14:37:34.912786 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:37:34.912786 16720 solver.cpp:237]     Train net output #1: loss = 1.5729 (* 1 = 1.5729 loss)
I1211 14:37:34.912786 16720 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1211 14:37:41.243904 16720 solver.cpp:218] Iteration 24400 (15.7963 iter/s, 6.3306s/100 iters), loss = 1.874
I1211 14:37:41.243904 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:37:41.243904 16720 solver.cpp:237]     Train net output #1: loss = 1.874 (* 1 = 1.874 loss)
I1211 14:37:41.243904 16720 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1211 14:37:47.254695  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:37:47.503196 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_24500.caffemodel
I1211 14:37:47.519695 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_24500.solverstate
I1211 14:37:47.524194 16720 solver.cpp:330] Iteration 24500, Testing net (#0)
I1211 14:37:47.524194 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:37:48.889696 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:37:48.943195 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3672
I1211 14:37:48.943195 16720 solver.cpp:397]     Test net output #1: loss = 2.55769 (* 1 = 2.55769 loss)
I1211 14:37:49.003695 16720 solver.cpp:218] Iteration 24500 (12.8876 iter/s, 7.75943s/100 iters), loss = 1.55199
I1211 14:37:49.003695 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:37:49.003695 16720 solver.cpp:237]     Train net output #1: loss = 1.55199 (* 1 = 1.55199 loss)
I1211 14:37:49.003695 16720 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1211 14:37:55.331329 16720 solver.cpp:218] Iteration 24600 (15.805 iter/s, 6.3271s/100 iters), loss = 1.48509
I1211 14:37:55.331329 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:37:55.331329 16720 solver.cpp:237]     Train net output #1: loss = 1.48509 (* 1 = 1.48509 loss)
I1211 14:37:55.331329 16720 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1211 14:38:01.652635 16720 solver.cpp:218] Iteration 24700 (15.8206 iter/s, 6.32086s/100 iters), loss = 1.41239
I1211 14:38:01.652635 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:38:01.652635 16720 solver.cpp:237]     Train net output #1: loss = 1.41239 (* 1 = 1.41239 loss)
I1211 14:38:01.652635 16720 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1211 14:38:07.989753 16720 solver.cpp:218] Iteration 24800 (15.7808 iter/s, 6.33681s/100 iters), loss = 1.78975
I1211 14:38:07.990253 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:38:07.990253 16720 solver.cpp:237]     Train net output #1: loss = 1.78975 (* 1 = 1.78975 loss)
I1211 14:38:07.990253 16720 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1211 14:38:14.315402 16720 solver.cpp:218] Iteration 24900 (15.8106 iter/s, 6.32487s/100 iters), loss = 1.86341
I1211 14:38:14.315402 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:38:14.315402 16720 solver.cpp:237]     Train net output #1: loss = 1.86341 (* 1 = 1.86341 loss)
I1211 14:38:14.315402 16720 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1211 14:38:20.340142  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:38:20.590140 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_25000.caffemodel
I1211 14:38:20.606140 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_25000.solverstate
I1211 14:38:20.610641 16720 solver.cpp:330] Iteration 25000, Testing net (#0)
I1211 14:38:20.610641 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:38:21.976141 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:38:22.030140 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3118
I1211 14:38:22.030140 16720 solver.cpp:397]     Test net output #1: loss = 2.966 (* 1 = 2.966 loss)
I1211 14:38:22.091152 16720 solver.cpp:218] Iteration 25000 (12.8608 iter/s, 7.77556s/100 iters), loss = 1.77484
I1211 14:38:22.091656 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:38:22.091656 16720 solver.cpp:237]     Train net output #1: loss = 1.77484 (* 1 = 1.77484 loss)
I1211 14:38:22.091656 16720 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1211 14:38:28.387914 16720 solver.cpp:218] Iteration 25100 (15.8824 iter/s, 6.29629s/100 iters), loss = 1.47645
I1211 14:38:28.388415 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:38:28.388415 16720 solver.cpp:237]     Train net output #1: loss = 1.47645 (* 1 = 1.47645 loss)
I1211 14:38:28.388415 16720 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1211 14:38:34.538851 16720 solver.cpp:218] Iteration 25200 (16.2593 iter/s, 6.15033s/100 iters), loss = 1.48012
I1211 14:38:34.538851 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:38:34.538851 16720 solver.cpp:237]     Train net output #1: loss = 1.48012 (* 1 = 1.48012 loss)
I1211 14:38:34.538851 16720 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1211 14:38:40.697068 16720 solver.cpp:218] Iteration 25300 (16.2402 iter/s, 6.15755s/100 iters), loss = 1.66472
I1211 14:38:40.697068 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:38:40.697068 16720 solver.cpp:237]     Train net output #1: loss = 1.66472 (* 1 = 1.66472 loss)
I1211 14:38:40.697068 16720 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1211 14:38:46.851011 16720 solver.cpp:218] Iteration 25400 (16.2511 iter/s, 6.15342s/100 iters), loss = 1.73169
I1211 14:38:46.851011 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:38:46.851011 16720 solver.cpp:237]     Train net output #1: loss = 1.73169 (* 1 = 1.73169 loss)
I1211 14:38:46.851011 16720 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1211 14:38:52.700912  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:38:52.944424 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_25500.caffemodel
I1211 14:38:52.959929 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_25500.solverstate
I1211 14:38:52.963928 16720 solver.cpp:330] Iteration 25500, Testing net (#0)
I1211 14:38:52.963928 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:38:54.302031 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:38:54.354032 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3771
I1211 14:38:54.355036 16720 solver.cpp:397]     Test net output #1: loss = 2.54835 (* 1 = 2.54835 loss)
I1211 14:38:54.414036 16720 solver.cpp:218] Iteration 25500 (13.2231 iter/s, 7.56253s/100 iters), loss = 1.8916
I1211 14:38:54.414036 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:38:54.414036 16720 solver.cpp:237]     Train net output #1: loss = 1.8916 (* 1 = 1.8916 loss)
I1211 14:38:54.414036 16720 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1211 14:39:00.570482 16720 solver.cpp:218] Iteration 25600 (16.2443 iter/s, 6.15602s/100 iters), loss = 1.71946
I1211 14:39:00.570482 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:39:00.570482 16720 solver.cpp:237]     Train net output #1: loss = 1.71946 (* 1 = 1.71946 loss)
I1211 14:39:00.570482 16720 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1211 14:39:06.725910 16720 solver.cpp:218] Iteration 25700 (16.2456 iter/s, 6.15552s/100 iters), loss = 1.47072
I1211 14:39:06.725910 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:39:06.725910 16720 solver.cpp:237]     Train net output #1: loss = 1.47072 (* 1 = 1.47072 loss)
I1211 14:39:06.725910 16720 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1211 14:39:12.889334 16720 solver.cpp:218] Iteration 25800 (16.2255 iter/s, 6.16315s/100 iters), loss = 1.70983
I1211 14:39:12.889334 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:39:12.889334 16720 solver.cpp:237]     Train net output #1: loss = 1.70983 (* 1 = 1.70983 loss)
I1211 14:39:12.889334 16720 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1211 14:39:19.036762 16720 solver.cpp:218] Iteration 25900 (16.2683 iter/s, 6.14691s/100 iters), loss = 1.88657
I1211 14:39:19.036762 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 14:39:19.036762 16720 solver.cpp:237]     Train net output #1: loss = 1.88657 (* 1 = 1.88657 loss)
I1211 14:39:19.036762 16720 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1211 14:39:24.895246  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:39:25.139256 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_26000.caffemodel
I1211 14:39:25.157759 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_26000.solverstate
I1211 14:39:25.162278 16720 solver.cpp:330] Iteration 26000, Testing net (#0)
I1211 14:39:25.163276 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:39:26.499359 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:39:26.551862 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3329
I1211 14:39:26.552374 16720 solver.cpp:397]     Test net output #1: loss = 2.7977 (* 1 = 2.7977 loss)
I1211 14:39:26.611363 16720 solver.cpp:218] Iteration 26000 (13.2036 iter/s, 7.57369s/100 iters), loss = 1.66598
I1211 14:39:26.611363 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:39:26.611363 16720 solver.cpp:237]     Train net output #1: loss = 1.66598 (* 1 = 1.66598 loss)
I1211 14:39:26.611363 16720 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1211 14:39:32.778810 16720 solver.cpp:218] Iteration 26100 (16.2139 iter/s, 6.16755s/100 iters), loss = 1.5246
I1211 14:39:32.778810 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:39:32.778810 16720 solver.cpp:237]     Train net output #1: loss = 1.5246 (* 1 = 1.5246 loss)
I1211 14:39:32.778810 16720 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1211 14:39:38.942340 16720 solver.cpp:218] Iteration 26200 (16.2276 iter/s, 6.16234s/100 iters), loss = 1.37923
I1211 14:39:38.942340 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:39:38.942340 16720 solver.cpp:237]     Train net output #1: loss = 1.37923 (* 1 = 1.37923 loss)
I1211 14:39:38.942340 16720 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1211 14:39:45.102790 16720 solver.cpp:218] Iteration 26300 (16.2328 iter/s, 6.16035s/100 iters), loss = 1.71933
I1211 14:39:45.102790 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:39:45.102790 16720 solver.cpp:237]     Train net output #1: loss = 1.71933 (* 1 = 1.71933 loss)
I1211 14:39:45.102790 16720 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1211 14:39:51.262212 16720 solver.cpp:218] Iteration 26400 (16.2366 iter/s, 6.15893s/100 iters), loss = 1.92476
I1211 14:39:51.262212 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:39:51.262212 16720 solver.cpp:237]     Train net output #1: loss = 1.92476 (* 1 = 1.92476 loss)
I1211 14:39:51.262212 16720 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1211 14:39:57.119398  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:39:57.361609 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_26500.caffemodel
I1211 14:39:57.377133 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_26500.solverstate
I1211 14:39:57.382134 16720 solver.cpp:330] Iteration 26500, Testing net (#0)
I1211 14:39:57.382134 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:39:58.716655 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:39:58.769163 16720 solver.cpp:397]     Test net output #0: accuracy = 0.345
I1211 14:39:58.769163 16720 solver.cpp:397]     Test net output #1: loss = 2.63651 (* 1 = 2.63651 loss)
I1211 14:39:58.828177 16720 solver.cpp:218] Iteration 26500 (13.2171 iter/s, 7.56594s/100 iters), loss = 1.66931
I1211 14:39:58.828177 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:39:58.828177 16720 solver.cpp:237]     Train net output #1: loss = 1.66931 (* 1 = 1.66931 loss)
I1211 14:39:58.828177 16720 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1211 14:40:05.043350 16720 solver.cpp:218] Iteration 26600 (16.0918 iter/s, 6.21434s/100 iters), loss = 1.56368
I1211 14:40:05.043350 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:40:05.043350 16720 solver.cpp:237]     Train net output #1: loss = 1.56368 (* 1 = 1.56368 loss)
I1211 14:40:05.043350 16720 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1211 14:40:11.196826 16720 solver.cpp:218] Iteration 26700 (16.2532 iter/s, 6.15264s/100 iters), loss = 1.46412
I1211 14:40:11.196826 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:40:11.196826 16720 solver.cpp:237]     Train net output #1: loss = 1.46412 (* 1 = 1.46412 loss)
I1211 14:40:11.196826 16720 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1211 14:40:17.344311 16720 solver.cpp:218] Iteration 26800 (16.2661 iter/s, 6.14777s/100 iters), loss = 1.73986
I1211 14:40:17.344311 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:40:17.344311 16720 solver.cpp:237]     Train net output #1: loss = 1.73986 (* 1 = 1.73986 loss)
I1211 14:40:17.344311 16720 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1211 14:40:23.499745 16720 solver.cpp:218] Iteration 26900 (16.2475 iter/s, 6.15479s/100 iters), loss = 1.93183
I1211 14:40:23.499745 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:40:23.499745 16720 solver.cpp:237]     Train net output #1: loss = 1.93183 (* 1 = 1.93183 loss)
I1211 14:40:23.499745 16720 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1211 14:40:29.355185  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:40:29.597213 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_27000.caffemodel
I1211 14:40:29.613214 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_27000.solverstate
I1211 14:40:29.617213 16720 solver.cpp:330] Iteration 27000, Testing net (#0)
I1211 14:40:29.618214 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:40:30.955314 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:40:31.007318 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3534
I1211 14:40:31.007318 16720 solver.cpp:397]     Test net output #1: loss = 2.5789 (* 1 = 2.5789 loss)
I1211 14:40:31.067319 16720 solver.cpp:218] Iteration 27000 (13.2157 iter/s, 7.56678s/100 iters), loss = 1.73371
I1211 14:40:31.067319 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:40:31.067319 16720 solver.cpp:237]     Train net output #1: loss = 1.73371 (* 1 = 1.73371 loss)
I1211 14:40:31.067319 16720 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1211 14:40:37.232803 16720 solver.cpp:218] Iteration 27100 (16.2188 iter/s, 6.16568s/100 iters), loss = 1.58296
I1211 14:40:37.233804 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:40:37.233804 16720 solver.cpp:237]     Train net output #1: loss = 1.58296 (* 1 = 1.58296 loss)
I1211 14:40:37.233804 16720 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1211 14:40:43.395902 16720 solver.cpp:218] Iteration 27200 (16.2292 iter/s, 6.16172s/100 iters), loss = 1.26813
I1211 14:40:43.395902 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:40:43.395902 16720 solver.cpp:237]     Train net output #1: loss = 1.26813 (* 1 = 1.26813 loss)
I1211 14:40:43.395902 16720 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1211 14:40:49.554848 16720 solver.cpp:218] Iteration 27300 (16.2375 iter/s, 6.1586s/100 iters), loss = 1.76973
I1211 14:40:49.554848 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:40:49.554848 16720 solver.cpp:237]     Train net output #1: loss = 1.76973 (* 1 = 1.76973 loss)
I1211 14:40:49.554848 16720 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1211 14:40:55.713353 16720 solver.cpp:218] Iteration 27400 (16.2382 iter/s, 6.15832s/100 iters), loss = 1.8946
I1211 14:40:55.713353 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:40:55.713353 16720 solver.cpp:237]     Train net output #1: loss = 1.8946 (* 1 = 1.8946 loss)
I1211 14:40:55.713353 16720 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1211 14:41:01.563431  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:41:01.806345 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_27500.caffemodel
I1211 14:41:01.821348 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_27500.solverstate
I1211 14:41:01.826344 16720 solver.cpp:330] Iteration 27500, Testing net (#0)
I1211 14:41:01.826344 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:41:03.157552 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:41:03.210449 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2758
I1211 14:41:03.210449 16720 solver.cpp:397]     Test net output #1: loss = 3.28127 (* 1 = 3.28127 loss)
I1211 14:41:03.269460 16720 solver.cpp:218] Iteration 27500 (13.2348 iter/s, 7.55582s/100 iters), loss = 1.71054
I1211 14:41:03.269460 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:41:03.269460 16720 solver.cpp:237]     Train net output #1: loss = 1.71054 (* 1 = 1.71054 loss)
I1211 14:41:03.269460 16720 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1211 14:41:09.409181 16720 solver.cpp:218] Iteration 27600 (16.2884 iter/s, 6.13935s/100 iters), loss = 1.68558
I1211 14:41:09.409181 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:41:09.409181 16720 solver.cpp:237]     Train net output #1: loss = 1.68558 (* 1 = 1.68558 loss)
I1211 14:41:09.409181 16720 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1211 14:41:15.652178 16720 solver.cpp:218] Iteration 27700 (16.0201 iter/s, 6.24214s/100 iters), loss = 1.41396
I1211 14:41:15.652178 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:41:15.652178 16720 solver.cpp:237]     Train net output #1: loss = 1.41396 (* 1 = 1.41396 loss)
I1211 14:41:15.652178 16720 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1211 14:41:21.987046 16720 solver.cpp:218] Iteration 27800 (15.7868 iter/s, 6.33439s/100 iters), loss = 1.68723
I1211 14:41:21.987046 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:41:21.987046 16720 solver.cpp:237]     Train net output #1: loss = 1.68723 (* 1 = 1.68723 loss)
I1211 14:41:21.987046 16720 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1211 14:41:28.326582 16720 solver.cpp:218] Iteration 27900 (15.7745 iter/s, 6.33936s/100 iters), loss = 1.97422
I1211 14:41:28.327073 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:41:28.327073 16720 solver.cpp:237]     Train net output #1: loss = 1.97422 (* 1 = 1.97422 loss)
I1211 14:41:28.327073 16720 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1211 14:41:34.367283  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:41:34.616781 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_28000.caffemodel
I1211 14:41:34.632781 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_28000.solverstate
I1211 14:41:34.637783 16720 solver.cpp:330] Iteration 28000, Testing net (#0)
I1211 14:41:34.638283 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:41:36.008396 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:41:36.062397 16720 solver.cpp:397]     Test net output #0: accuracy = 0.4142
I1211 14:41:36.062397 16720 solver.cpp:397]     Test net output #1: loss = 2.26971 (* 1 = 2.26971 loss)
I1211 14:41:36.123395 16720 solver.cpp:218] Iteration 28000 (12.8267 iter/s, 7.79627s/100 iters), loss = 1.84214
I1211 14:41:36.123896 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:41:36.123896 16720 solver.cpp:237]     Train net output #1: loss = 1.84214 (* 1 = 1.84214 loss)
I1211 14:41:36.123896 16720 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1211 14:41:42.468128 16720 solver.cpp:218] Iteration 28100 (15.7637 iter/s, 6.34371s/100 iters), loss = 1.63495
I1211 14:41:42.468128 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:41:42.468128 16720 solver.cpp:237]     Train net output #1: loss = 1.63495 (* 1 = 1.63495 loss)
I1211 14:41:42.468128 16720 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1211 14:41:48.789100 16720 solver.cpp:218] Iteration 28200 (15.8211 iter/s, 6.32066s/100 iters), loss = 1.55968
I1211 14:41:48.789597 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:41:48.789597 16720 solver.cpp:237]     Train net output #1: loss = 1.55968 (* 1 = 1.55968 loss)
I1211 14:41:48.789597 16720 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1211 14:41:55.121738 16720 solver.cpp:218] Iteration 28300 (15.7931 iter/s, 6.33189s/100 iters), loss = 1.63341
I1211 14:41:55.121738 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:41:55.121738 16720 solver.cpp:237]     Train net output #1: loss = 1.63341 (* 1 = 1.63341 loss)
I1211 14:41:55.121738 16720 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1211 14:42:01.449738 16720 solver.cpp:218] Iteration 28400 (15.8048 iter/s, 6.32717s/100 iters), loss = 1.77314
I1211 14:42:01.449738 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:42:01.449738 16720 solver.cpp:237]     Train net output #1: loss = 1.77314 (* 1 = 1.77314 loss)
I1211 14:42:01.449738 16720 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1211 14:42:07.469538  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:42:07.720036 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_28500.caffemodel
I1211 14:42:07.736037 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_28500.solverstate
I1211 14:42:07.740537 16720 solver.cpp:330] Iteration 28500, Testing net (#0)
I1211 14:42:07.740537 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:42:09.106037 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:42:09.159538 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3188
I1211 14:42:09.159538 16720 solver.cpp:397]     Test net output #1: loss = 3.05512 (* 1 = 3.05512 loss)
I1211 14:42:09.219537 16720 solver.cpp:218] Iteration 28500 (12.8713 iter/s, 7.7692s/100 iters), loss = 1.84499
I1211 14:42:09.219537 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:42:09.219537 16720 solver.cpp:237]     Train net output #1: loss = 1.84499 (* 1 = 1.84499 loss)
I1211 14:42:09.219537 16720 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1211 14:42:15.545536 16720 solver.cpp:218] Iteration 28600 (15.8086 iter/s, 6.32566s/100 iters), loss = 1.5135
I1211 14:42:15.545536 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:42:15.545536 16720 solver.cpp:237]     Train net output #1: loss = 1.5135 (* 1 = 1.5135 loss)
I1211 14:42:15.545536 16720 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1211 14:42:21.866145 16720 solver.cpp:218] Iteration 28700 (15.8223 iter/s, 6.3202s/100 iters), loss = 1.40606
I1211 14:42:21.866145 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:42:21.866145 16720 solver.cpp:237]     Train net output #1: loss = 1.40606 (* 1 = 1.40606 loss)
I1211 14:42:21.866145 16720 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1211 14:42:28.176275 16720 solver.cpp:218] Iteration 28800 (15.8484 iter/s, 6.30977s/100 iters), loss = 1.64947
I1211 14:42:28.176275 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:42:28.176275 16720 solver.cpp:237]     Train net output #1: loss = 1.64947 (* 1 = 1.64947 loss)
I1211 14:42:28.176275 16720 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1211 14:42:34.485888 16720 solver.cpp:218] Iteration 28900 (15.8506 iter/s, 6.3089s/100 iters), loss = 1.75381
I1211 14:42:34.485888 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:42:34.485888 16720 solver.cpp:237]     Train net output #1: loss = 1.75381 (* 1 = 1.75381 loss)
I1211 14:42:34.485888 16720 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1211 14:42:40.498158  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:42:40.749158 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_29000.caffemodel
I1211 14:42:40.764657 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_29000.solverstate
I1211 14:42:40.769156 16720 solver.cpp:330] Iteration 29000, Testing net (#0)
I1211 14:42:40.769156 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:42:42.133158 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:42:42.187156 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3421
I1211 14:42:42.187156 16720 solver.cpp:397]     Test net output #1: loss = 2.71132 (* 1 = 2.71132 loss)
I1211 14:42:42.249157 16720 solver.cpp:218] Iteration 29000 (12.8824 iter/s, 7.76256s/100 iters), loss = 1.75666
I1211 14:42:42.249157 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:42:42.249157 16720 solver.cpp:237]     Train net output #1: loss = 1.75666 (* 1 = 1.75666 loss)
I1211 14:42:42.249157 16720 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1211 14:42:48.584225 16720 solver.cpp:218] Iteration 29100 (15.7863 iter/s, 6.33462s/100 iters), loss = 1.49204
I1211 14:42:48.584225 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:42:48.584225 16720 solver.cpp:237]     Train net output #1: loss = 1.49204 (* 1 = 1.49204 loss)
I1211 14:42:48.584225 16720 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1211 14:42:54.766238 16720 solver.cpp:218] Iteration 29200 (16.1777 iter/s, 6.18136s/100 iters), loss = 1.44532
I1211 14:42:54.766238 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:42:54.766238 16720 solver.cpp:237]     Train net output #1: loss = 1.44532 (* 1 = 1.44532 loss)
I1211 14:42:54.766238 16720 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1211 14:43:00.917767 16720 solver.cpp:218] Iteration 29300 (16.2565 iter/s, 6.1514s/100 iters), loss = 1.7745
I1211 14:43:00.917767 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:43:00.917767 16720 solver.cpp:237]     Train net output #1: loss = 1.7745 (* 1 = 1.7745 loss)
I1211 14:43:00.917767 16720 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1211 14:43:07.081275 16720 solver.cpp:218] Iteration 29400 (16.2265 iter/s, 6.16274s/100 iters), loss = 1.89949
I1211 14:43:07.081275 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:43:07.081275 16720 solver.cpp:237]     Train net output #1: loss = 1.89949 (* 1 = 1.89949 loss)
I1211 14:43:07.081275 16720 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1211 14:43:12.997925  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:43:13.247424 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_29500.caffemodel
I1211 14:43:13.262423 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_29500.solverstate
I1211 14:43:13.267424 16720 solver.cpp:330] Iteration 29500, Testing net (#0)
I1211 14:43:13.267925 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:43:14.631424 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:43:14.685926 16720 solver.cpp:397]     Test net output #0: accuracy = 0.323
I1211 14:43:14.685926 16720 solver.cpp:397]     Test net output #1: loss = 2.8776 (* 1 = 2.8776 loss)
I1211 14:43:14.745923 16720 solver.cpp:218] Iteration 29500 (13.0471 iter/s, 7.66456s/100 iters), loss = 1.63863
I1211 14:43:14.746424 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:43:14.746424 16720 solver.cpp:237]     Train net output #1: loss = 1.63863 (* 1 = 1.63863 loss)
I1211 14:43:14.746424 16720 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1211 14:43:21.070924 16720 solver.cpp:218] Iteration 29600 (15.8118 iter/s, 6.32439s/100 iters), loss = 1.56788
I1211 14:43:21.070924 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:43:21.071424 16720 solver.cpp:237]     Train net output #1: loss = 1.56788 (* 1 = 1.56788 loss)
I1211 14:43:21.071424 16720 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1211 14:43:27.399924 16720 solver.cpp:218] Iteration 29700 (15.8019 iter/s, 6.32835s/100 iters), loss = 1.42697
I1211 14:43:27.399924 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:43:27.399924 16720 solver.cpp:237]     Train net output #1: loss = 1.42697 (* 1 = 1.42697 loss)
I1211 14:43:27.399924 16720 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1211 14:43:33.726914 16720 solver.cpp:218] Iteration 29800 (15.8065 iter/s, 6.32653s/100 iters), loss = 1.7014
I1211 14:43:33.726914 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:43:33.726914 16720 solver.cpp:237]     Train net output #1: loss = 1.7014 (* 1 = 1.7014 loss)
I1211 14:43:33.726914 16720 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1211 14:43:40.046133 16720 solver.cpp:218] Iteration 29900 (15.8263 iter/s, 6.31861s/100 iters), loss = 1.76162
I1211 14:43:40.046133 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:43:40.046133 16720 solver.cpp:237]     Train net output #1: loss = 1.76162 (* 1 = 1.76162 loss)
I1211 14:43:40.046133 16720 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1211 14:43:46.054469  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:43:46.305088 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_30000.caffemodel
I1211 14:43:46.320587 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_30000.solverstate
I1211 14:43:46.325088 16720 solver.cpp:330] Iteration 30000, Testing net (#0)
I1211 14:43:46.325088 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:43:47.688102 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:43:47.741098 16720 solver.cpp:397]     Test net output #0: accuracy = 0.285
I1211 14:43:47.741098 16720 solver.cpp:397]     Test net output #1: loss = 3.37448 (* 1 = 3.37448 loss)
I1211 14:43:47.801090 16720 solver.cpp:218] Iteration 30000 (12.8959 iter/s, 7.75439s/100 iters), loss = 1.59699
I1211 14:43:47.801090 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:43:47.801090 16720 solver.cpp:237]     Train net output #1: loss = 1.59699 (* 1 = 1.59699 loss)
I1211 14:43:47.801090 16720 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1211 14:43:54.094712 16720 solver.cpp:218] Iteration 30100 (15.8895 iter/s, 6.29346s/100 iters), loss = 1.54493
I1211 14:43:54.094712 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:43:54.094712 16720 solver.cpp:237]     Train net output #1: loss = 1.54493 (* 1 = 1.54493 loss)
I1211 14:43:54.094712 16720 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1211 14:44:00.416126 16720 solver.cpp:218] Iteration 30200 (15.8207 iter/s, 6.32084s/100 iters), loss = 1.34126
I1211 14:44:00.416126 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 14:44:00.416126 16720 solver.cpp:237]     Train net output #1: loss = 1.34126 (* 1 = 1.34126 loss)
I1211 14:44:00.416126 16720 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1211 14:44:06.740679 16720 solver.cpp:218] Iteration 30300 (15.8131 iter/s, 6.32389s/100 iters), loss = 1.80078
I1211 14:44:06.740679 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:44:06.740679 16720 solver.cpp:237]     Train net output #1: loss = 1.80078 (* 1 = 1.80078 loss)
I1211 14:44:06.740679 16720 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1211 14:44:13.065505 16720 solver.cpp:218] Iteration 30400 (15.8112 iter/s, 6.32462s/100 iters), loss = 1.82619
I1211 14:44:13.065505 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:44:13.065505 16720 solver.cpp:237]     Train net output #1: loss = 1.82619 (* 1 = 1.82619 loss)
I1211 14:44:13.065505 16720 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1211 14:44:19.082419  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:44:19.330937 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_30500.caffemodel
I1211 14:44:19.347434 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_30500.solverstate
I1211 14:44:19.351934 16720 solver.cpp:330] Iteration 30500, Testing net (#0)
I1211 14:44:19.351934 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:44:20.713418 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:44:20.766419 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3646
I1211 14:44:20.766419 16720 solver.cpp:397]     Test net output #1: loss = 2.54478 (* 1 = 2.54478 loss)
I1211 14:44:20.826918 16720 solver.cpp:218] Iteration 30500 (12.8853 iter/s, 7.76078s/100 iters), loss = 1.66988
I1211 14:44:20.826918 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:44:20.826918 16720 solver.cpp:237]     Train net output #1: loss = 1.66988 (* 1 = 1.66988 loss)
I1211 14:44:20.826918 16720 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1211 14:44:27.156731 16720 solver.cpp:218] Iteration 30600 (15.7997 iter/s, 6.32923s/100 iters), loss = 1.51018
I1211 14:44:27.156731 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:44:27.156731 16720 solver.cpp:237]     Train net output #1: loss = 1.51018 (* 1 = 1.51018 loss)
I1211 14:44:27.156731 16720 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1211 14:44:33.478082 16720 solver.cpp:218] Iteration 30700 (15.8204 iter/s, 6.32095s/100 iters), loss = 1.36381
I1211 14:44:33.478082 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 14:44:33.478082 16720 solver.cpp:237]     Train net output #1: loss = 1.36381 (* 1 = 1.36381 loss)
I1211 14:44:33.478082 16720 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1211 14:44:39.796972 16720 solver.cpp:218] Iteration 30800 (15.8277 iter/s, 6.31805s/100 iters), loss = 1.54984
I1211 14:44:39.796972 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:44:39.796972 16720 solver.cpp:237]     Train net output #1: loss = 1.54984 (* 1 = 1.54984 loss)
I1211 14:44:39.796972 16720 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1211 14:44:46.118134 16720 solver.cpp:218] Iteration 30900 (15.821 iter/s, 6.32069s/100 iters), loss = 1.82427
I1211 14:44:46.118134 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:44:46.118134 16720 solver.cpp:237]     Train net output #1: loss = 1.82427 (* 1 = 1.82427 loss)
I1211 14:44:46.118134 16720 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1211 14:44:52.159103  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:44:52.409606 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_31000.caffemodel
I1211 14:44:52.426106 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_31000.solverstate
I1211 14:44:52.430608 16720 solver.cpp:330] Iteration 31000, Testing net (#0)
I1211 14:44:52.430608 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:44:53.797606 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:44:53.851605 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3731
I1211 14:44:53.851605 16720 solver.cpp:397]     Test net output #1: loss = 2.55461 (* 1 = 2.55461 loss)
I1211 14:44:53.911105 16720 solver.cpp:218] Iteration 31000 (12.8326 iter/s, 7.79266s/100 iters), loss = 1.73058
I1211 14:44:53.911105 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:44:53.911105 16720 solver.cpp:237]     Train net output #1: loss = 1.73058 (* 1 = 1.73058 loss)
I1211 14:44:53.911105 16720 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1211 14:45:00.226186 16720 solver.cpp:218] Iteration 31100 (15.8366 iter/s, 6.31447s/100 iters), loss = 1.5297
I1211 14:45:00.226186 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:45:00.226186 16720 solver.cpp:237]     Train net output #1: loss = 1.5297 (* 1 = 1.5297 loss)
I1211 14:45:00.226186 16720 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1211 14:45:06.552243 16720 solver.cpp:218] Iteration 31200 (15.8091 iter/s, 6.32548s/100 iters), loss = 1.3183
I1211 14:45:06.552243 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:45:06.552243 16720 solver.cpp:237]     Train net output #1: loss = 1.3183 (* 1 = 1.3183 loss)
I1211 14:45:06.552243 16720 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1211 14:45:12.875243 16720 solver.cpp:218] Iteration 31300 (15.8166 iter/s, 6.32248s/100 iters), loss = 1.67982
I1211 14:45:12.875243 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:45:12.875243 16720 solver.cpp:237]     Train net output #1: loss = 1.67982 (* 1 = 1.67982 loss)
I1211 14:45:12.875243 16720 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1211 14:45:19.198782 16720 solver.cpp:218] Iteration 31400 (15.8153 iter/s, 6.323s/100 iters), loss = 1.91217
I1211 14:45:19.198782 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:45:19.198782 16720 solver.cpp:237]     Train net output #1: loss = 1.91217 (* 1 = 1.91217 loss)
I1211 14:45:19.198782 16720 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1211 14:45:25.111135  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:45:25.354329 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_31500.caffemodel
I1211 14:45:25.369844 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_31500.solverstate
I1211 14:45:25.374840 16720 solver.cpp:330] Iteration 31500, Testing net (#0)
I1211 14:45:25.374840 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:45:26.708844 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:45:26.761842 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3738
I1211 14:45:26.761842 16720 solver.cpp:397]     Test net output #1: loss = 2.51674 (* 1 = 2.51674 loss)
I1211 14:45:26.821331 16720 solver.cpp:218] Iteration 31500 (13.119 iter/s, 7.6225s/100 iters), loss = 1.86972
I1211 14:45:26.821830 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:45:26.821830 16720 solver.cpp:237]     Train net output #1: loss = 1.86972 (* 1 = 1.86972 loss)
I1211 14:45:26.821830 16720 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1211 14:45:32.997586 16720 solver.cpp:218] Iteration 31600 (16.1927 iter/s, 6.17561s/100 iters), loss = 1.4204
I1211 14:45:32.997586 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:45:32.997586 16720 solver.cpp:237]     Train net output #1: loss = 1.4204 (* 1 = 1.4204 loss)
I1211 14:45:32.997586 16720 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1211 14:45:39.146925 16720 solver.cpp:218] Iteration 31700 (16.2629 iter/s, 6.14897s/100 iters), loss = 1.44611
I1211 14:45:39.146925 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:45:39.146925 16720 solver.cpp:237]     Train net output #1: loss = 1.44611 (* 1 = 1.44611 loss)
I1211 14:45:39.146925 16720 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1211 14:45:45.304394 16720 solver.cpp:218] Iteration 31800 (16.2412 iter/s, 6.15718s/100 iters), loss = 1.68452
I1211 14:45:45.304394 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:45:45.304394 16720 solver.cpp:237]     Train net output #1: loss = 1.68452 (* 1 = 1.68452 loss)
I1211 14:45:45.304394 16720 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1211 14:45:51.470162 16720 solver.cpp:218] Iteration 31900 (16.2186 iter/s, 6.16575s/100 iters), loss = 1.78746
I1211 14:45:51.471161 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:45:51.471161 16720 solver.cpp:237]     Train net output #1: loss = 1.78746 (* 1 = 1.78746 loss)
I1211 14:45:51.471161 16720 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1211 14:45:57.326889  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:45:57.569403 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_32000.caffemodel
I1211 14:45:57.585402 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_32000.solverstate
I1211 14:45:57.589402 16720 solver.cpp:330] Iteration 32000, Testing net (#0)
I1211 14:45:57.589402 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:45:58.937007 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:45:58.989511 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3323
I1211 14:45:58.989511 16720 solver.cpp:397]     Test net output #1: loss = 2.82715 (* 1 = 2.82715 loss)
I1211 14:45:59.047519 16720 solver.cpp:218] Iteration 32000 (13.1984 iter/s, 7.5767s/100 iters), loss = 1.68699
I1211 14:45:59.047519 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:45:59.047519 16720 solver.cpp:237]     Train net output #1: loss = 1.68699 (* 1 = 1.68699 loss)
I1211 14:45:59.047519 16720 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1211 14:46:05.265990 16720 solver.cpp:218] Iteration 32100 (16.0828 iter/s, 6.21783s/100 iters), loss = 1.62979
I1211 14:46:05.265990 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:46:05.265990 16720 solver.cpp:237]     Train net output #1: loss = 1.62979 (* 1 = 1.62979 loss)
I1211 14:46:05.265990 16720 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1211 14:46:11.500907 16720 solver.cpp:218] Iteration 32200 (16.0405 iter/s, 6.23421s/100 iters), loss = 1.48147
I1211 14:46:11.500907 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:46:11.500907 16720 solver.cpp:237]     Train net output #1: loss = 1.48147 (* 1 = 1.48147 loss)
I1211 14:46:11.500907 16720 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1211 14:46:17.858779 16720 solver.cpp:218] Iteration 32300 (15.7294 iter/s, 6.35752s/100 iters), loss = 1.68509
I1211 14:46:17.858779 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:46:17.858779 16720 solver.cpp:237]     Train net output #1: loss = 1.68509 (* 1 = 1.68509 loss)
I1211 14:46:17.858779 16720 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1211 14:46:24.238787 16720 solver.cpp:218] Iteration 32400 (15.6758 iter/s, 6.37928s/100 iters), loss = 1.82658
I1211 14:46:24.238787 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:46:24.238787 16720 solver.cpp:237]     Train net output #1: loss = 1.82658 (* 1 = 1.82658 loss)
I1211 14:46:24.238787 16720 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1211 14:46:30.306403  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:46:30.555438 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_32500.caffemodel
I1211 14:46:30.577440 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_32500.solverstate
I1211 14:46:30.582439 16720 solver.cpp:330] Iteration 32500, Testing net (#0)
I1211 14:46:30.582439 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:46:31.956626 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:46:32.011622 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2834
I1211 14:46:32.011622 16720 solver.cpp:397]     Test net output #1: loss = 3.21287 (* 1 = 3.21287 loss)
I1211 14:46:32.071645 16720 solver.cpp:218] Iteration 32500 (12.7672 iter/s, 7.83255s/100 iters), loss = 1.68079
I1211 14:46:32.071645 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:46:32.071645 16720 solver.cpp:237]     Train net output #1: loss = 1.68079 (* 1 = 1.68079 loss)
I1211 14:46:32.071645 16720 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1211 14:46:38.316246 16720 solver.cpp:218] Iteration 32600 (16.0163 iter/s, 6.24362s/100 iters), loss = 1.59562
I1211 14:46:38.316246 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:46:38.316246 16720 solver.cpp:237]     Train net output #1: loss = 1.59562 (* 1 = 1.59562 loss)
I1211 14:46:38.316246 16720 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1211 14:46:44.505033 16720 solver.cpp:218] Iteration 32700 (16.1572 iter/s, 6.18921s/100 iters), loss = 1.49094
I1211 14:46:44.506036 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:46:44.506036 16720 solver.cpp:237]     Train net output #1: loss = 1.49094 (* 1 = 1.49094 loss)
I1211 14:46:44.506036 16720 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1211 14:46:50.662601 16720 solver.cpp:218] Iteration 32800 (16.2438 iter/s, 6.1562s/100 iters), loss = 1.84644
I1211 14:46:50.662601 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:46:50.662601 16720 solver.cpp:237]     Train net output #1: loss = 1.84644 (* 1 = 1.84644 loss)
I1211 14:46:50.662601 16720 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1211 14:46:56.819561 16720 solver.cpp:218] Iteration 32900 (16.2428 iter/s, 6.15657s/100 iters), loss = 1.7542
I1211 14:46:56.819561 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:46:56.819561 16720 solver.cpp:237]     Train net output #1: loss = 1.7542 (* 1 = 1.7542 loss)
I1211 14:46:56.819561 16720 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1211 14:47:02.676002  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:47:02.921018 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_33000.caffemodel
I1211 14:47:02.936019 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_33000.solverstate
I1211 14:47:02.940522 16720 solver.cpp:330] Iteration 33000, Testing net (#0)
I1211 14:47:02.940522 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:47:04.274144 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:47:04.327145 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3509
I1211 14:47:04.327145 16720 solver.cpp:397]     Test net output #1: loss = 2.6362 (* 1 = 2.6362 loss)
I1211 14:47:04.386148 16720 solver.cpp:218] Iteration 33000 (13.2156 iter/s, 7.5668s/100 iters), loss = 1.56832
I1211 14:47:04.386148 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:47:04.386148 16720 solver.cpp:237]     Train net output #1: loss = 1.56832 (* 1 = 1.56832 loss)
I1211 14:47:04.386148 16720 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1211 14:47:10.548599 16720 solver.cpp:218] Iteration 33100 (16.2295 iter/s, 6.16161s/100 iters), loss = 1.53835
I1211 14:47:10.549099 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:47:10.549099 16720 solver.cpp:237]     Train net output #1: loss = 1.53835 (* 1 = 1.53835 loss)
I1211 14:47:10.549099 16720 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1211 14:47:16.702051 16720 solver.cpp:218] Iteration 33200 (16.2517 iter/s, 6.1532s/100 iters), loss = 1.51741
I1211 14:47:16.702051 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:47:16.702051 16720 solver.cpp:237]     Train net output #1: loss = 1.51741 (* 1 = 1.51741 loss)
I1211 14:47:16.702051 16720 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1211 14:47:22.845341 16720 solver.cpp:218] Iteration 33300 (16.2803 iter/s, 6.1424s/100 iters), loss = 1.73171
I1211 14:47:22.845341 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:47:22.845341 16720 solver.cpp:237]     Train net output #1: loss = 1.73171 (* 1 = 1.73171 loss)
I1211 14:47:22.845341 16720 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1211 14:47:28.992822 16720 solver.cpp:218] Iteration 33400 (16.2676 iter/s, 6.14719s/100 iters), loss = 1.80056
I1211 14:47:28.992822 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:47:28.992822 16720 solver.cpp:237]     Train net output #1: loss = 1.80056 (* 1 = 1.80056 loss)
I1211 14:47:28.992822 16720 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1211 14:47:34.845238  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:47:35.088763 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_33500.caffemodel
I1211 14:47:35.104267 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_33500.solverstate
I1211 14:47:35.108268 16720 solver.cpp:330] Iteration 33500, Testing net (#0)
I1211 14:47:35.108268 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:47:36.445377 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:47:36.498383 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3661
I1211 14:47:36.498383 16720 solver.cpp:397]     Test net output #1: loss = 2.57514 (* 1 = 2.57514 loss)
I1211 14:47:36.557380 16720 solver.cpp:218] Iteration 33500 (13.2207 iter/s, 7.56389s/100 iters), loss = 1.71428
I1211 14:47:36.557380 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:47:36.557380 16720 solver.cpp:237]     Train net output #1: loss = 1.71428 (* 1 = 1.71428 loss)
I1211 14:47:36.557380 16720 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1211 14:47:42.711518 16720 solver.cpp:218] Iteration 33600 (16.2486 iter/s, 6.15436s/100 iters), loss = 1.58405
I1211 14:47:42.711518 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:47:42.711518 16720 solver.cpp:237]     Train net output #1: loss = 1.58405 (* 1 = 1.58405 loss)
I1211 14:47:42.711518 16720 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1211 14:47:48.865479 16720 solver.cpp:218] Iteration 33700 (16.2512 iter/s, 6.15339s/100 iters), loss = 1.37933
I1211 14:47:48.865479 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:47:48.865479 16720 solver.cpp:237]     Train net output #1: loss = 1.37933 (* 1 = 1.37933 loss)
I1211 14:47:48.865479 16720 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1211 14:47:55.021344 16720 solver.cpp:218] Iteration 33800 (16.2455 iter/s, 6.15557s/100 iters), loss = 1.83595
I1211 14:47:55.021344 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:47:55.021344 16720 solver.cpp:237]     Train net output #1: loss = 1.83595 (* 1 = 1.83595 loss)
I1211 14:47:55.021344 16720 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1211 14:48:01.177014 16720 solver.cpp:218] Iteration 33900 (16.2471 iter/s, 6.15493s/100 iters), loss = 1.82592
I1211 14:48:01.177014 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:48:01.177014 16720 solver.cpp:237]     Train net output #1: loss = 1.82592 (* 1 = 1.82592 loss)
I1211 14:48:01.177014 16720 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1211 14:48:07.030237  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:48:07.271317 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_34000.caffemodel
I1211 14:48:07.286319 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_34000.solverstate
I1211 14:48:07.291322 16720 solver.cpp:330] Iteration 34000, Testing net (#0)
I1211 14:48:07.291822 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:48:08.626348 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:48:08.679364 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3399
I1211 14:48:08.679364 16720 solver.cpp:397]     Test net output #1: loss = 2.79446 (* 1 = 2.79446 loss)
I1211 14:48:08.737864 16720 solver.cpp:218] Iteration 34000 (13.2266 iter/s, 7.56053s/100 iters), loss = 1.7782
I1211 14:48:08.737864 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:48:08.737864 16720 solver.cpp:237]     Train net output #1: loss = 1.7782 (* 1 = 1.7782 loss)
I1211 14:48:08.737864 16720 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1211 14:48:14.895539 16720 solver.cpp:218] Iteration 34100 (16.2418 iter/s, 6.15697s/100 iters), loss = 1.50461
I1211 14:48:14.895539 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:48:14.895539 16720 solver.cpp:237]     Train net output #1: loss = 1.50461 (* 1 = 1.50461 loss)
I1211 14:48:14.895539 16720 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1211 14:48:21.071377 16720 solver.cpp:218] Iteration 34200 (16.1913 iter/s, 6.17614s/100 iters), loss = 1.37492
I1211 14:48:21.072378 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:48:21.072378 16720 solver.cpp:237]     Train net output #1: loss = 1.37492 (* 1 = 1.37492 loss)
I1211 14:48:21.072378 16720 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1211 14:48:27.231070 16720 solver.cpp:218] Iteration 34300 (16.2383 iter/s, 6.15828s/100 iters), loss = 1.57578
I1211 14:48:27.231070 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:48:27.231070 16720 solver.cpp:237]     Train net output #1: loss = 1.57578 (* 1 = 1.57578 loss)
I1211 14:48:27.231070 16720 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1211 14:48:33.392300 16720 solver.cpp:218] Iteration 34400 (16.2314 iter/s, 6.16089s/100 iters), loss = 1.84375
I1211 14:48:33.392300 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:48:33.392300 16720 solver.cpp:237]     Train net output #1: loss = 1.84375 (* 1 = 1.84375 loss)
I1211 14:48:33.392300 16720 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1211 14:48:39.250331  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:48:39.498919 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_34500.caffemodel
I1211 14:48:39.514425 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_34500.solverstate
I1211 14:48:39.519425 16720 solver.cpp:330] Iteration 34500, Testing net (#0)
I1211 14:48:39.519425 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:48:40.856402 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:48:40.909412 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3536
I1211 14:48:40.909412 16720 solver.cpp:397]     Test net output #1: loss = 2.7792 (* 1 = 2.7792 loss)
I1211 14:48:40.967914 16720 solver.cpp:218] Iteration 34500 (13.201 iter/s, 7.57519s/100 iters), loss = 1.70467
I1211 14:48:40.967914 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:48:40.967914 16720 solver.cpp:237]     Train net output #1: loss = 1.70467 (* 1 = 1.70467 loss)
I1211 14:48:40.967914 16720 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1211 14:48:47.122686 16720 solver.cpp:218] Iteration 34600 (16.2489 iter/s, 6.15425s/100 iters), loss = 1.37471
I1211 14:48:47.122686 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:48:47.122686 16720 solver.cpp:237]     Train net output #1: loss = 1.37471 (* 1 = 1.37471 loss)
I1211 14:48:47.122686 16720 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1211 14:48:53.285745 16720 solver.cpp:218] Iteration 34700 (16.2249 iter/s, 6.16338s/100 iters), loss = 1.40742
I1211 14:48:53.285745 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:48:53.285745 16720 solver.cpp:237]     Train net output #1: loss = 1.40742 (* 1 = 1.40742 loss)
I1211 14:48:53.286747 16720 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1211 14:48:59.463451 16720 solver.cpp:218] Iteration 34800 (16.1892 iter/s, 6.17696s/100 iters), loss = 1.96749
I1211 14:48:59.463451 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:48:59.463451 16720 solver.cpp:237]     Train net output #1: loss = 1.96749 (* 1 = 1.96749 loss)
I1211 14:48:59.463451 16720 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1211 14:49:05.625026 16720 solver.cpp:218] Iteration 34900 (16.2317 iter/s, 6.16079s/100 iters), loss = 1.89488
I1211 14:49:05.625026 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:49:05.625026 16720 solver.cpp:237]     Train net output #1: loss = 1.89488 (* 1 = 1.89488 loss)
I1211 14:49:05.625026 16720 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1211 14:49:11.469396  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:49:11.711434 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_35000.caffemodel
I1211 14:49:11.726439 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_35000.solverstate
I1211 14:49:11.731441 16720 solver.cpp:330] Iteration 35000, Testing net (#0)
I1211 14:49:11.731441 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:49:13.065573 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:49:13.117584 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3354
I1211 14:49:13.117584 16720 solver.cpp:397]     Test net output #1: loss = 2.78054 (* 1 = 2.78054 loss)
I1211 14:49:13.176584 16720 solver.cpp:218] Iteration 35000 (13.2423 iter/s, 7.55158s/100 iters), loss = 1.58803
I1211 14:49:13.176584 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:49:13.176584 16720 solver.cpp:237]     Train net output #1: loss = 1.58803 (* 1 = 1.58803 loss)
I1211 14:49:13.176584 16720 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1211 14:49:19.338587 16720 solver.cpp:218] Iteration 35100 (16.23 iter/s, 6.16143s/100 iters), loss = 1.41268
I1211 14:49:19.338587 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:49:19.338587 16720 solver.cpp:237]     Train net output #1: loss = 1.41268 (* 1 = 1.41268 loss)
I1211 14:49:19.338587 16720 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1211 14:49:25.509632 16720 solver.cpp:218] Iteration 35200 (16.206 iter/s, 6.17057s/100 iters), loss = 1.48785
I1211 14:49:25.509632 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 14:49:25.509632 16720 solver.cpp:237]     Train net output #1: loss = 1.48785 (* 1 = 1.48785 loss)
I1211 14:49:25.509632 16720 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1211 14:49:31.664863 16720 solver.cpp:218] Iteration 35300 (16.2485 iter/s, 6.15442s/100 iters), loss = 1.72212
I1211 14:49:31.664863 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:49:31.664863 16720 solver.cpp:237]     Train net output #1: loss = 1.72212 (* 1 = 1.72212 loss)
I1211 14:49:31.664863 16720 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1211 14:49:37.836241 16720 solver.cpp:218] Iteration 35400 (16.2036 iter/s, 6.17148s/100 iters), loss = 1.76241
I1211 14:49:37.836241 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:49:37.836241 16720 solver.cpp:237]     Train net output #1: loss = 1.76241 (* 1 = 1.76241 loss)
I1211 14:49:37.836241 16720 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1211 14:49:43.714399  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:49:43.957526 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_35500.caffemodel
I1211 14:49:43.975034 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_35500.solverstate
I1211 14:49:43.980034 16720 solver.cpp:330] Iteration 35500, Testing net (#0)
I1211 14:49:43.980034 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:49:45.313544 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:49:45.366525 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3638
I1211 14:49:45.366525 16720 solver.cpp:397]     Test net output #1: loss = 2.54057 (* 1 = 2.54057 loss)
I1211 14:49:45.424583 16720 solver.cpp:218] Iteration 35500 (13.1786 iter/s, 7.58807s/100 iters), loss = 1.76099
I1211 14:49:45.424583 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:49:45.424583 16720 solver.cpp:237]     Train net output #1: loss = 1.76099 (* 1 = 1.76099 loss)
I1211 14:49:45.424583 16720 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1211 14:49:51.582967 16720 solver.cpp:218] Iteration 35600 (16.2408 iter/s, 6.15732s/100 iters), loss = 1.43686
I1211 14:49:51.582967 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:49:51.582967 16720 solver.cpp:237]     Train net output #1: loss = 1.43686 (* 1 = 1.43686 loss)
I1211 14:49:51.582967 16720 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1211 14:49:57.735477 16720 solver.cpp:218] Iteration 35700 (16.2554 iter/s, 6.15182s/100 iters), loss = 1.42129
I1211 14:49:57.735477 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:49:57.735477 16720 solver.cpp:237]     Train net output #1: loss = 1.42129 (* 1 = 1.42129 loss)
I1211 14:49:57.735477 16720 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1211 14:50:03.918704 16720 solver.cpp:218] Iteration 35800 (16.1726 iter/s, 6.1833s/100 iters), loss = 1.88668
I1211 14:50:03.918704 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:50:03.918704 16720 solver.cpp:237]     Train net output #1: loss = 1.88668 (* 1 = 1.88668 loss)
I1211 14:50:03.918704 16720 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1211 14:50:10.076117 16720 solver.cpp:218] Iteration 35900 (16.2417 iter/s, 6.15697s/100 iters), loss = 1.73925
I1211 14:50:10.076117 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:50:10.076117 16720 solver.cpp:237]     Train net output #1: loss = 1.73925 (* 1 = 1.73925 loss)
I1211 14:50:10.076117 16720 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1211 14:50:15.934509  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:50:16.176523 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_36000.caffemodel
I1211 14:50:16.192526 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_36000.solverstate
I1211 14:50:16.196530 16720 solver.cpp:330] Iteration 36000, Testing net (#0)
I1211 14:50:16.196530 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:50:17.529633 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:50:17.582136 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2888
I1211 14:50:17.582136 16720 solver.cpp:397]     Test net output #1: loss = 3.21007 (* 1 = 3.21007 loss)
I1211 14:50:17.640637 16720 solver.cpp:218] Iteration 36000 (13.2216 iter/s, 7.56339s/100 iters), loss = 1.66407
I1211 14:50:17.640637 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:50:17.640637 16720 solver.cpp:237]     Train net output #1: loss = 1.66407 (* 1 = 1.66407 loss)
I1211 14:50:17.640637 16720 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1211 14:50:23.792621 16720 solver.cpp:218] Iteration 36100 (16.2553 iter/s, 6.15184s/100 iters), loss = 1.57266
I1211 14:50:23.792621 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:50:23.792621 16720 solver.cpp:237]     Train net output #1: loss = 1.57266 (* 1 = 1.57266 loss)
I1211 14:50:23.793121 16720 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1211 14:50:29.947598 16720 solver.cpp:218] Iteration 36200 (16.248 iter/s, 6.15462s/100 iters), loss = 1.35356
I1211 14:50:29.947598 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:50:29.947598 16720 solver.cpp:237]     Train net output #1: loss = 1.35356 (* 1 = 1.35356 loss)
I1211 14:50:29.947598 16720 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1211 14:50:36.123116 16720 solver.cpp:218] Iteration 36300 (16.1948 iter/s, 6.17484s/100 iters), loss = 1.75506
I1211 14:50:36.123116 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:50:36.123116 16720 solver.cpp:237]     Train net output #1: loss = 1.75506 (* 1 = 1.75506 loss)
I1211 14:50:36.123116 16720 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1211 14:50:42.288619 16720 solver.cpp:218] Iteration 36400 (16.2204 iter/s, 6.16506s/100 iters), loss = 1.67532
I1211 14:50:42.288619 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:50:42.288619 16720 solver.cpp:237]     Train net output #1: loss = 1.67532 (* 1 = 1.67532 loss)
I1211 14:50:42.288619 16720 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1211 14:50:48.140573  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:50:48.384572 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_36500.caffemodel
I1211 14:50:48.412075 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_36500.solverstate
I1211 14:50:48.416575 16720 solver.cpp:330] Iteration 36500, Testing net (#0)
I1211 14:50:48.416575 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:50:49.766697 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:50:49.818707 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3289
I1211 14:50:49.818707 16720 solver.cpp:397]     Test net output #1: loss = 2.99324 (* 1 = 2.99324 loss)
I1211 14:50:49.877707 16720 solver.cpp:218] Iteration 36500 (13.1778 iter/s, 7.58853s/100 iters), loss = 1.53695
I1211 14:50:49.877707 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:50:49.877707 16720 solver.cpp:237]     Train net output #1: loss = 1.53695 (* 1 = 1.53695 loss)
I1211 14:50:49.877707 16720 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1211 14:50:56.057992 16720 solver.cpp:218] Iteration 36600 (16.1806 iter/s, 6.18023s/100 iters), loss = 1.46142
I1211 14:50:56.057992 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:50:56.057992 16720 solver.cpp:237]     Train net output #1: loss = 1.46142 (* 1 = 1.46142 loss)
I1211 14:50:56.057992 16720 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1211 14:51:02.209434 16720 solver.cpp:218] Iteration 36700 (16.257 iter/s, 6.15121s/100 iters), loss = 1.3938
I1211 14:51:02.209434 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:51:02.209434 16720 solver.cpp:237]     Train net output #1: loss = 1.3938 (* 1 = 1.3938 loss)
I1211 14:51:02.209434 16720 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1211 14:51:08.366860 16720 solver.cpp:218] Iteration 36800 (16.2429 iter/s, 6.15654s/100 iters), loss = 1.8734
I1211 14:51:08.366860 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:51:08.366860 16720 solver.cpp:237]     Train net output #1: loss = 1.8734 (* 1 = 1.8734 loss)
I1211 14:51:08.366860 16720 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1211 14:51:14.561381 16720 solver.cpp:218] Iteration 36900 (16.1447 iter/s, 6.19397s/100 iters), loss = 1.76502
I1211 14:51:14.561381 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:51:14.561381 16720 solver.cpp:237]     Train net output #1: loss = 1.76502 (* 1 = 1.76502 loss)
I1211 14:51:14.561381 16720 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1211 14:51:20.501833  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:51:20.742668 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_37000.caffemodel
I1211 14:51:20.757675 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_37000.solverstate
I1211 14:51:20.762657 16720 solver.cpp:330] Iteration 37000, Testing net (#0)
I1211 14:51:20.762657 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:51:22.096520 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:51:22.149554 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2583
I1211 14:51:22.149554 16720 solver.cpp:397]     Test net output #1: loss = 3.53265 (* 1 = 3.53265 loss)
I1211 14:51:22.208068 16720 solver.cpp:218] Iteration 37000 (13.0781 iter/s, 7.64637s/100 iters), loss = 1.68693
I1211 14:51:22.208068 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:51:22.208068 16720 solver.cpp:237]     Train net output #1: loss = 1.68693 (* 1 = 1.68693 loss)
I1211 14:51:22.208068 16720 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1211 14:51:28.377012 16720 solver.cpp:218] Iteration 37100 (16.212 iter/s, 6.16829s/100 iters), loss = 1.584
I1211 14:51:28.377012 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:51:28.377012 16720 solver.cpp:237]     Train net output #1: loss = 1.584 (* 1 = 1.584 loss)
I1211 14:51:28.377012 16720 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1211 14:51:34.533572 16720 solver.cpp:218] Iteration 37200 (16.2432 iter/s, 6.15644s/100 iters), loss = 1.35383
I1211 14:51:34.533572 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:51:34.533572 16720 solver.cpp:237]     Train net output #1: loss = 1.35383 (* 1 = 1.35383 loss)
I1211 14:51:34.533572 16720 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1211 14:51:40.698062 16720 solver.cpp:218] Iteration 37300 (16.2225 iter/s, 6.16429s/100 iters), loss = 1.73612
I1211 14:51:40.698062 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:51:40.698062 16720 solver.cpp:237]     Train net output #1: loss = 1.73612 (* 1 = 1.73612 loss)
I1211 14:51:40.698062 16720 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1211 14:51:46.859467 16720 solver.cpp:218] Iteration 37400 (16.231 iter/s, 6.16105s/100 iters), loss = 1.76938
I1211 14:51:46.859467 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:51:46.859467 16720 solver.cpp:237]     Train net output #1: loss = 1.76938 (* 1 = 1.76938 loss)
I1211 14:51:46.859467 16720 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1211 14:51:52.734884  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:51:52.977908 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_37500.caffemodel
I1211 14:51:52.992908 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_37500.solverstate
I1211 14:51:52.996908 16720 solver.cpp:330] Iteration 37500, Testing net (#0)
I1211 14:51:52.996908 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:51:54.332994 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:51:54.385993 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2284
I1211 14:51:54.385993 16720 solver.cpp:397]     Test net output #1: loss = 4.18405 (* 1 = 4.18405 loss)
I1211 14:51:54.445008 16720 solver.cpp:218] Iteration 37500 (13.1842 iter/s, 7.58483s/100 iters), loss = 1.75393
I1211 14:51:54.445008 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:51:54.445008 16720 solver.cpp:237]     Train net output #1: loss = 1.75393 (* 1 = 1.75393 loss)
I1211 14:51:54.445008 16720 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1211 14:52:00.603487 16720 solver.cpp:218] Iteration 37600 (16.2402 iter/s, 6.15757s/100 iters), loss = 1.68511
I1211 14:52:00.603487 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:52:00.603487 16720 solver.cpp:237]     Train net output #1: loss = 1.68511 (* 1 = 1.68511 loss)
I1211 14:52:00.603487 16720 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1211 14:52:06.756927 16720 solver.cpp:218] Iteration 37700 (16.2514 iter/s, 6.15331s/100 iters), loss = 1.45154
I1211 14:52:06.756927 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 14:52:06.756927 16720 solver.cpp:237]     Train net output #1: loss = 1.45154 (* 1 = 1.45154 loss)
I1211 14:52:06.756927 16720 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1211 14:52:12.913908 16720 solver.cpp:218] Iteration 37800 (16.2425 iter/s, 6.15669s/100 iters), loss = 1.81478
I1211 14:52:12.914408 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:52:12.914408 16720 solver.cpp:237]     Train net output #1: loss = 1.81478 (* 1 = 1.81478 loss)
I1211 14:52:12.914408 16720 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1211 14:52:19.068820 16720 solver.cpp:218] Iteration 37900 (16.2487 iter/s, 6.15433s/100 iters), loss = 1.84618
I1211 14:52:19.068820 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:52:19.068820 16720 solver.cpp:237]     Train net output #1: loss = 1.84618 (* 1 = 1.84618 loss)
I1211 14:52:19.068820 16720 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1211 14:52:24.924190  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:52:25.168200 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_38000.caffemodel
I1211 14:52:25.183202 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_38000.solverstate
I1211 14:52:25.187201 16720 solver.cpp:330] Iteration 38000, Testing net (#0)
I1211 14:52:25.188202 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:52:26.525275 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:52:26.578277 16720 solver.cpp:397]     Test net output #0: accuracy = 0.377
I1211 14:52:26.578277 16720 solver.cpp:397]     Test net output #1: loss = 2.47009 (* 1 = 2.47009 loss)
I1211 14:52:26.636292 16720 solver.cpp:218] Iteration 38000 (13.2147 iter/s, 7.56735s/100 iters), loss = 1.62692
I1211 14:52:26.636292 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:52:26.636292 16720 solver.cpp:237]     Train net output #1: loss = 1.62692 (* 1 = 1.62692 loss)
I1211 14:52:26.636292 16720 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1211 14:52:32.789739 16720 solver.cpp:218] Iteration 38100 (16.2519 iter/s, 6.15312s/100 iters), loss = 1.63957
I1211 14:52:32.789739 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:52:32.789739 16720 solver.cpp:237]     Train net output #1: loss = 1.63957 (* 1 = 1.63957 loss)
I1211 14:52:32.789739 16720 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1211 14:52:38.945231 16720 solver.cpp:218] Iteration 38200 (16.247 iter/s, 6.15498s/100 iters), loss = 1.24773
I1211 14:52:38.945231 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 14:52:38.945231 16720 solver.cpp:237]     Train net output #1: loss = 1.24773 (* 1 = 1.24773 loss)
I1211 14:52:38.945231 16720 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1211 14:52:45.094609 16720 solver.cpp:218] Iteration 38300 (16.2647 iter/s, 6.14828s/100 iters), loss = 1.62675
I1211 14:52:45.094609 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:52:45.094609 16720 solver.cpp:237]     Train net output #1: loss = 1.62675 (* 1 = 1.62675 loss)
I1211 14:52:45.094609 16720 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1211 14:52:51.258345 16720 solver.cpp:218] Iteration 38400 (16.2236 iter/s, 6.16386s/100 iters), loss = 1.80396
I1211 14:52:51.258345 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:52:51.258345 16720 solver.cpp:237]     Train net output #1: loss = 1.80396 (* 1 = 1.80396 loss)
I1211 14:52:51.258345 16720 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1211 14:52:57.116276  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:52:57.360787 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_38500.caffemodel
I1211 14:52:57.376787 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_38500.solverstate
I1211 14:52:57.380787 16720 solver.cpp:330] Iteration 38500, Testing net (#0)
I1211 14:52:57.380787 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:52:58.717718 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:52:58.770222 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3631
I1211 14:52:58.770222 16720 solver.cpp:397]     Test net output #1: loss = 2.64651 (* 1 = 2.64651 loss)
I1211 14:52:58.829228 16720 solver.cpp:218] Iteration 38500 (13.2102 iter/s, 7.56989s/100 iters), loss = 1.6812
I1211 14:52:58.829228 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:52:58.829228 16720 solver.cpp:237]     Train net output #1: loss = 1.6812 (* 1 = 1.6812 loss)
I1211 14:52:58.829228 16720 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1211 14:53:04.997186 16720 solver.cpp:218] Iteration 38600 (16.2123 iter/s, 6.16816s/100 iters), loss = 1.63452
I1211 14:53:04.997186 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:53:04.997186 16720 solver.cpp:237]     Train net output #1: loss = 1.63452 (* 1 = 1.63452 loss)
I1211 14:53:04.997186 16720 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1211 14:53:11.166713 16720 solver.cpp:218] Iteration 38700 (16.2103 iter/s, 6.16892s/100 iters), loss = 1.27552
I1211 14:53:11.166713 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 14:53:11.166713 16720 solver.cpp:237]     Train net output #1: loss = 1.27552 (* 1 = 1.27552 loss)
I1211 14:53:11.166713 16720 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1211 14:53:17.331040 16720 solver.cpp:218] Iteration 38800 (16.2246 iter/s, 6.16349s/100 iters), loss = 1.71107
I1211 14:53:17.331040 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:53:17.331040 16720 solver.cpp:237]     Train net output #1: loss = 1.71107 (* 1 = 1.71107 loss)
I1211 14:53:17.331040 16720 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1211 14:53:23.493696 16720 solver.cpp:218] Iteration 38900 (16.2281 iter/s, 6.16216s/100 iters), loss = 1.72921
I1211 14:53:23.493696 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 14:53:23.493696 16720 solver.cpp:237]     Train net output #1: loss = 1.72921 (* 1 = 1.72921 loss)
I1211 14:53:23.493696 16720 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1211 14:53:29.349541  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:53:29.591894 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_39000.caffemodel
I1211 14:53:29.605893 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_39000.solverstate
I1211 14:53:29.610893 16720 solver.cpp:330] Iteration 39000, Testing net (#0)
I1211 14:53:29.610893 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:53:30.942219 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:53:30.995213 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3554
I1211 14:53:30.995213 16720 solver.cpp:397]     Test net output #1: loss = 2.73454 (* 1 = 2.73454 loss)
I1211 14:53:31.054071 16720 solver.cpp:218] Iteration 39000 (13.2274 iter/s, 7.56005s/100 iters), loss = 1.6147
I1211 14:53:31.054071 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:53:31.054071 16720 solver.cpp:237]     Train net output #1: loss = 1.6147 (* 1 = 1.6147 loss)
I1211 14:53:31.054071 16720 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1211 14:53:37.203899 16720 solver.cpp:218] Iteration 39100 (16.2608 iter/s, 6.14977s/100 iters), loss = 1.58139
I1211 14:53:37.203899 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:53:37.203899 16720 solver.cpp:237]     Train net output #1: loss = 1.58139 (* 1 = 1.58139 loss)
I1211 14:53:37.203899 16720 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1211 14:53:43.365386 16720 solver.cpp:218] Iteration 39200 (16.2324 iter/s, 6.1605s/100 iters), loss = 1.42841
I1211 14:53:43.365386 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:53:43.365386 16720 solver.cpp:237]     Train net output #1: loss = 1.42841 (* 1 = 1.42841 loss)
I1211 14:53:43.365386 16720 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1211 14:53:49.536905 16720 solver.cpp:218] Iteration 39300 (16.2042 iter/s, 6.17124s/100 iters), loss = 1.86995
I1211 14:53:49.536905 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:53:49.536905 16720 solver.cpp:237]     Train net output #1: loss = 1.86995 (* 1 = 1.86995 loss)
I1211 14:53:49.536905 16720 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1211 14:53:55.700417 16720 solver.cpp:218] Iteration 39400 (16.2252 iter/s, 6.16324s/100 iters), loss = 1.76025
I1211 14:53:55.700417 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:53:55.700417 16720 solver.cpp:237]     Train net output #1: loss = 1.76025 (* 1 = 1.76025 loss)
I1211 14:53:55.700417 16720 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1211 14:54:01.563830  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:54:01.804841 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_39500.caffemodel
I1211 14:54:01.820842 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_39500.solverstate
I1211 14:54:01.824843 16720 solver.cpp:330] Iteration 39500, Testing net (#0)
I1211 14:54:01.824843 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:54:03.161972 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:54:03.213970 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3531
I1211 14:54:03.214972 16720 solver.cpp:397]     Test net output #1: loss = 2.69376 (* 1 = 2.69376 loss)
I1211 14:54:03.273455 16720 solver.cpp:218] Iteration 39500 (13.2048 iter/s, 7.57302s/100 iters), loss = 1.69214
I1211 14:54:03.273455 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:54:03.273455 16720 solver.cpp:237]     Train net output #1: loss = 1.69214 (* 1 = 1.69214 loss)
I1211 14:54:03.273455 16720 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1211 14:54:09.430044 16720 solver.cpp:218] Iteration 39600 (16.2456 iter/s, 6.15551s/100 iters), loss = 1.44344
I1211 14:54:09.430044 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:54:09.430044 16720 solver.cpp:237]     Train net output #1: loss = 1.44344 (* 1 = 1.44344 loss)
I1211 14:54:09.430044 16720 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1211 14:54:15.570698 16720 solver.cpp:218] Iteration 39700 (16.2839 iter/s, 6.14104s/100 iters), loss = 1.2586
I1211 14:54:15.570698 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 14:54:15.570698 16720 solver.cpp:237]     Train net output #1: loss = 1.2586 (* 1 = 1.2586 loss)
I1211 14:54:15.570698 16720 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1211 14:54:21.732810 16720 solver.cpp:218] Iteration 39800 (16.2311 iter/s, 6.16101s/100 iters), loss = 1.64485
I1211 14:54:21.732810 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:54:21.732810 16720 solver.cpp:237]     Train net output #1: loss = 1.64485 (* 1 = 1.64485 loss)
I1211 14:54:21.732810 16720 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1211 14:54:27.892288 16720 solver.cpp:218] Iteration 39900 (16.2367 iter/s, 6.15889s/100 iters), loss = 1.81772
I1211 14:54:27.892288 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:54:27.892288 16720 solver.cpp:237]     Train net output #1: loss = 1.81772 (* 1 = 1.81772 loss)
I1211 14:54:27.892288 16720 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1211 14:54:33.749711  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:54:33.990737 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_40000.caffemodel
I1211 14:54:34.006737 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_40000.solverstate
I1211 14:54:34.010737 16720 solver.cpp:330] Iteration 40000, Testing net (#0)
I1211 14:54:34.010737 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:54:35.346849 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:54:35.398851 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3515
I1211 14:54:35.398851 16720 solver.cpp:397]     Test net output #1: loss = 2.63865 (* 1 = 2.63865 loss)
I1211 14:54:35.457855 16720 solver.cpp:218] Iteration 40000 (13.2182 iter/s, 7.56535s/100 iters), loss = 1.75971
I1211 14:54:35.457855 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:54:35.457855 16720 solver.cpp:237]     Train net output #1: loss = 1.75971 (* 1 = 1.75971 loss)
I1211 14:54:35.457855 16720 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1211 14:54:41.619297 16720 solver.cpp:218] Iteration 40100 (16.2316 iter/s, 6.16083s/100 iters), loss = 1.35573
I1211 14:54:41.619297 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:54:41.619297 16720 solver.cpp:237]     Train net output #1: loss = 1.35573 (* 1 = 1.35573 loss)
I1211 14:54:41.619297 16720 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1211 14:54:47.778776 16720 solver.cpp:218] Iteration 40200 (16.2356 iter/s, 6.15932s/100 iters), loss = 1.28783
I1211 14:54:47.778776 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 14:54:47.778776 16720 solver.cpp:237]     Train net output #1: loss = 1.28783 (* 1 = 1.28783 loss)
I1211 14:54:47.778776 16720 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1211 14:54:53.945225 16720 solver.cpp:218] Iteration 40300 (16.2183 iter/s, 6.16588s/100 iters), loss = 1.71499
I1211 14:54:53.945724 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:54:53.945724 16720 solver.cpp:237]     Train net output #1: loss = 1.71499 (* 1 = 1.71499 loss)
I1211 14:54:53.945724 16720 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1211 14:55:00.109648 16720 solver.cpp:218] Iteration 40400 (16.2228 iter/s, 6.16417s/100 iters), loss = 1.75712
I1211 14:55:00.109648 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:55:00.109648 16720 solver.cpp:237]     Train net output #1: loss = 1.75712 (* 1 = 1.75712 loss)
I1211 14:55:00.109648 16720 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1211 14:55:05.977059  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:55:06.219070 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_40500.caffemodel
I1211 14:55:06.234071 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_40500.solverstate
I1211 14:55:06.239076 16720 solver.cpp:330] Iteration 40500, Testing net (#0)
I1211 14:55:06.239076 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:55:07.573163 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:55:07.626163 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3497
I1211 14:55:07.626163 16720 solver.cpp:397]     Test net output #1: loss = 2.58758 (* 1 = 2.58758 loss)
I1211 14:55:07.685168 16720 solver.cpp:218] Iteration 40500 (13.2012 iter/s, 7.57509s/100 iters), loss = 1.63276
I1211 14:55:07.685168 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:55:07.685168 16720 solver.cpp:237]     Train net output #1: loss = 1.63276 (* 1 = 1.63276 loss)
I1211 14:55:07.685168 16720 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1211 14:55:13.853670 16720 solver.cpp:218] Iteration 40600 (16.212 iter/s, 6.16828s/100 iters), loss = 1.54939
I1211 14:55:13.853670 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:55:13.853670 16720 solver.cpp:237]     Train net output #1: loss = 1.54939 (* 1 = 1.54939 loss)
I1211 14:55:13.854673 16720 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1211 14:55:20.013178 16720 solver.cpp:218] Iteration 40700 (16.2362 iter/s, 6.15909s/100 iters), loss = 1.45766
I1211 14:55:20.014178 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:55:20.014178 16720 solver.cpp:237]     Train net output #1: loss = 1.45766 (* 1 = 1.45766 loss)
I1211 14:55:20.014178 16720 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1211 14:55:26.174651 16720 solver.cpp:218] Iteration 40800 (16.232 iter/s, 6.16066s/100 iters), loss = 1.72785
I1211 14:55:26.174651 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:55:26.174651 16720 solver.cpp:237]     Train net output #1: loss = 1.72785 (* 1 = 1.72785 loss)
I1211 14:55:26.174651 16720 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1211 14:55:32.335098 16720 solver.cpp:218] Iteration 40900 (16.2337 iter/s, 6.16003s/100 iters), loss = 1.79918
I1211 14:55:32.335098 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:55:32.335098 16720 solver.cpp:237]     Train net output #1: loss = 1.79918 (* 1 = 1.79918 loss)
I1211 14:55:32.335098 16720 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1211 14:55:38.192467  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:55:38.435490 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_41000.caffemodel
I1211 14:55:38.451995 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_41000.solverstate
I1211 14:55:38.456499 16720 solver.cpp:330] Iteration 41000, Testing net (#0)
I1211 14:55:38.456499 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:55:39.792598 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:55:39.846102 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3361
I1211 14:55:39.846102 16720 solver.cpp:397]     Test net output #1: loss = 2.88182 (* 1 = 2.88182 loss)
I1211 14:55:39.904604 16720 solver.cpp:218] Iteration 41000 (13.2117 iter/s, 7.56902s/100 iters), loss = 1.71599
I1211 14:55:39.904604 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:55:39.904604 16720 solver.cpp:237]     Train net output #1: loss = 1.71599 (* 1 = 1.71599 loss)
I1211 14:55:39.904604 16720 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1211 14:55:46.068982 16720 solver.cpp:218] Iteration 41100 (16.2228 iter/s, 6.16418s/100 iters), loss = 1.5395
I1211 14:55:46.068982 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:55:46.068982 16720 solver.cpp:237]     Train net output #1: loss = 1.5395 (* 1 = 1.5395 loss)
I1211 14:55:46.068982 16720 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1211 14:55:52.224445 16720 solver.cpp:218] Iteration 41200 (16.247 iter/s, 6.15499s/100 iters), loss = 1.24137
I1211 14:55:52.224445 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 14:55:52.224445 16720 solver.cpp:237]     Train net output #1: loss = 1.24137 (* 1 = 1.24137 loss)
I1211 14:55:52.224445 16720 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1211 14:55:58.377871 16720 solver.cpp:218] Iteration 41300 (16.2535 iter/s, 6.15252s/100 iters), loss = 1.85311
I1211 14:55:58.377871 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:55:58.377871 16720 solver.cpp:237]     Train net output #1: loss = 1.85311 (* 1 = 1.85311 loss)
I1211 14:55:58.377871 16720 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1211 14:56:04.540455 16720 solver.cpp:218] Iteration 41400 (16.2273 iter/s, 6.16244s/100 iters), loss = 1.74599
I1211 14:56:04.540455 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:56:04.540455 16720 solver.cpp:237]     Train net output #1: loss = 1.74599 (* 1 = 1.74599 loss)
I1211 14:56:04.540455 16720 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1211 14:56:10.396385  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:56:10.638413 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_41500.caffemodel
I1211 14:56:10.653923 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_41500.solverstate
I1211 14:56:10.658922 16720 solver.cpp:330] Iteration 41500, Testing net (#0)
I1211 14:56:10.658922 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:56:11.995537 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:56:12.048542 16720 solver.cpp:397]     Test net output #0: accuracy = 0.4043
I1211 14:56:12.048542 16720 solver.cpp:397]     Test net output #1: loss = 2.32773 (* 1 = 2.32773 loss)
I1211 14:56:12.108199 16720 solver.cpp:218] Iteration 41500 (13.2162 iter/s, 7.56644s/100 iters), loss = 1.6498
I1211 14:56:12.108199 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:56:12.108199 16720 solver.cpp:237]     Train net output #1: loss = 1.6498 (* 1 = 1.6498 loss)
I1211 14:56:12.108199 16720 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1211 14:56:18.267640 16720 solver.cpp:218] Iteration 41600 (16.2341 iter/s, 6.15987s/100 iters), loss = 1.59645
I1211 14:56:18.267640 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:56:18.267640 16720 solver.cpp:237]     Train net output #1: loss = 1.59645 (* 1 = 1.59645 loss)
I1211 14:56:18.267640 16720 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1211 14:56:24.427235 16720 solver.cpp:218] Iteration 41700 (16.2369 iter/s, 6.15879s/100 iters), loss = 1.42464
I1211 14:56:24.427235 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:56:24.427235 16720 solver.cpp:237]     Train net output #1: loss = 1.42464 (* 1 = 1.42464 loss)
I1211 14:56:24.427235 16720 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1211 14:56:30.588713 16720 solver.cpp:218] Iteration 41800 (16.2298 iter/s, 6.1615s/100 iters), loss = 1.65822
I1211 14:56:30.589715 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:56:30.589715 16720 solver.cpp:237]     Train net output #1: loss = 1.65822 (* 1 = 1.65822 loss)
I1211 14:56:30.589715 16720 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1211 14:56:36.741101 16720 solver.cpp:218] Iteration 41900 (16.255 iter/s, 6.15194s/100 iters), loss = 1.86283
I1211 14:56:36.741101 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:56:36.741101 16720 solver.cpp:237]     Train net output #1: loss = 1.86283 (* 1 = 1.86283 loss)
I1211 14:56:36.741101 16720 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1211 14:56:42.597576  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:56:42.842584 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_42000.caffemodel
I1211 14:56:42.857587 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_42000.solverstate
I1211 14:56:42.863088 16720 solver.cpp:330] Iteration 42000, Testing net (#0)
I1211 14:56:42.863088 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:56:44.198707 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:56:44.250707 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3685
I1211 14:56:44.250707 16720 solver.cpp:397]     Test net output #1: loss = 2.50437 (* 1 = 2.50437 loss)
I1211 14:56:44.309716 16720 solver.cpp:218] Iteration 42000 (13.2132 iter/s, 7.56816s/100 iters), loss = 1.58923
I1211 14:56:44.310715 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 14:56:44.310715 16720 solver.cpp:237]     Train net output #1: loss = 1.58923 (* 1 = 1.58923 loss)
I1211 14:56:44.310715 16720 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1211 14:56:50.466156 16720 solver.cpp:218] Iteration 42100 (16.2464 iter/s, 6.15521s/100 iters), loss = 1.54664
I1211 14:56:50.466156 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 14:56:50.466156 16720 solver.cpp:237]     Train net output #1: loss = 1.54664 (* 1 = 1.54664 loss)
I1211 14:56:50.466156 16720 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1211 14:56:56.629695 16720 solver.cpp:218] Iteration 42200 (16.2244 iter/s, 6.16355s/100 iters), loss = 1.32849
I1211 14:56:56.629695 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 14:56:56.629695 16720 solver.cpp:237]     Train net output #1: loss = 1.32849 (* 1 = 1.32849 loss)
I1211 14:56:56.629695 16720 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1211 14:57:02.792125 16720 solver.cpp:218] Iteration 42300 (16.229 iter/s, 6.1618s/100 iters), loss = 1.88081
I1211 14:57:02.792125 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 14:57:02.792125 16720 solver.cpp:237]     Train net output #1: loss = 1.88081 (* 1 = 1.88081 loss)
I1211 14:57:02.792125 16720 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1211 14:57:08.951541 16720 solver.cpp:218] Iteration 42400 (16.2357 iter/s, 6.15928s/100 iters), loss = 1.73356
I1211 14:57:08.951541 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:57:08.951541 16720 solver.cpp:237]     Train net output #1: loss = 1.73356 (* 1 = 1.73356 loss)
I1211 14:57:08.951541 16720 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1211 14:57:14.806922  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:57:15.047935 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_42500.caffemodel
I1211 14:57:15.064440 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_42500.solverstate
I1211 14:57:15.068940 16720 solver.cpp:330] Iteration 42500, Testing net (#0)
I1211 14:57:15.068940 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:57:16.403955 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:57:16.456956 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3554
I1211 14:57:16.456956 16720 solver.cpp:397]     Test net output #1: loss = 2.68264 (* 1 = 2.68264 loss)
I1211 14:57:16.514955 16720 solver.cpp:218] Iteration 42500 (13.2234 iter/s, 7.56237s/100 iters), loss = 1.56937
I1211 14:57:16.514955 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:57:16.514955 16720 solver.cpp:237]     Train net output #1: loss = 1.56937 (* 1 = 1.56937 loss)
I1211 14:57:16.514955 16720 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1211 14:57:22.663239 16720 solver.cpp:218] Iteration 42600 (16.2659 iter/s, 6.14784s/100 iters), loss = 1.62969
I1211 14:57:22.663239 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:57:22.663239 16720 solver.cpp:237]     Train net output #1: loss = 1.62969 (* 1 = 1.62969 loss)
I1211 14:57:22.663239 16720 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1211 14:57:28.824638 16720 solver.cpp:218] Iteration 42700 (16.2315 iter/s, 6.16086s/100 iters), loss = 1.33334
I1211 14:57:28.824638 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 14:57:28.824638 16720 solver.cpp:237]     Train net output #1: loss = 1.33334 (* 1 = 1.33334 loss)
I1211 14:57:28.824638 16720 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1211 14:57:34.977617 16720 solver.cpp:218] Iteration 42800 (16.2534 iter/s, 6.15258s/100 iters), loss = 1.78316
I1211 14:57:34.977617 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:57:34.977617 16720 solver.cpp:237]     Train net output #1: loss = 1.78316 (* 1 = 1.78316 loss)
I1211 14:57:34.977617 16720 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1211 14:57:41.133589 16720 solver.cpp:218] Iteration 42900 (16.2437 iter/s, 6.15624s/100 iters), loss = 1.75262
I1211 14:57:41.133589 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:57:41.133589 16720 solver.cpp:237]     Train net output #1: loss = 1.75262 (* 1 = 1.75262 loss)
I1211 14:57:41.133589 16720 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1211 14:57:46.989003  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:57:47.232033 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_43000.caffemodel
I1211 14:57:47.247031 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_43000.solverstate
I1211 14:57:47.252034 16720 solver.cpp:330] Iteration 43000, Testing net (#0)
I1211 14:57:47.252034 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:57:48.586637 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:57:48.638137 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3411
I1211 14:57:48.639138 16720 solver.cpp:397]     Test net output #1: loss = 2.87433 (* 1 = 2.87433 loss)
I1211 14:57:48.697142 16720 solver.cpp:218] Iteration 43000 (13.2219 iter/s, 7.56323s/100 iters), loss = 1.71206
I1211 14:57:48.697142 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:57:48.698143 16720 solver.cpp:237]     Train net output #1: loss = 1.71206 (* 1 = 1.71206 loss)
I1211 14:57:48.698143 16720 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1211 14:57:54.857570 16720 solver.cpp:218] Iteration 43100 (16.2356 iter/s, 6.15931s/100 iters), loss = 1.60902
I1211 14:57:54.857570 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:57:54.857570 16720 solver.cpp:237]     Train net output #1: loss = 1.60902 (* 1 = 1.60902 loss)
I1211 14:57:54.857570 16720 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1211 14:58:01.014459 16720 solver.cpp:218] Iteration 43200 (16.2421 iter/s, 6.15686s/100 iters), loss = 1.29591
I1211 14:58:01.014459 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 14:58:01.014459 16720 solver.cpp:237]     Train net output #1: loss = 1.29591 (* 1 = 1.29591 loss)
I1211 14:58:01.014459 16720 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1211 14:58:07.165129 16720 solver.cpp:218] Iteration 43300 (16.2609 iter/s, 6.14973s/100 iters), loss = 1.62675
I1211 14:58:07.165129 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:58:07.165129 16720 solver.cpp:237]     Train net output #1: loss = 1.62675 (* 1 = 1.62675 loss)
I1211 14:58:07.165129 16720 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1211 14:58:13.313611 16720 solver.cpp:218] Iteration 43400 (16.2637 iter/s, 6.14865s/100 iters), loss = 1.73097
I1211 14:58:13.313611 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 14:58:13.313611 16720 solver.cpp:237]     Train net output #1: loss = 1.73097 (* 1 = 1.73097 loss)
I1211 14:58:13.313611 16720 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1211 14:58:19.167520  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:58:19.409059 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_43500.caffemodel
I1211 14:58:19.424058 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_43500.solverstate
I1211 14:58:19.429059 16720 solver.cpp:330] Iteration 43500, Testing net (#0)
I1211 14:58:19.429059 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:58:20.762230 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:58:20.814414 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3801
I1211 14:58:20.814414 16720 solver.cpp:397]     Test net output #1: loss = 2.44919 (* 1 = 2.44919 loss)
I1211 14:58:20.873426 16720 solver.cpp:218] Iteration 43500 (13.2297 iter/s, 7.55877s/100 iters), loss = 1.56042
I1211 14:58:20.873426 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:58:20.873426 16720 solver.cpp:237]     Train net output #1: loss = 1.56042 (* 1 = 1.56042 loss)
I1211 14:58:20.873426 16720 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1211 14:58:27.018883 16720 solver.cpp:218] Iteration 43600 (16.2726 iter/s, 6.14531s/100 iters), loss = 1.47107
I1211 14:58:27.018883 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:58:27.018883 16720 solver.cpp:237]     Train net output #1: loss = 1.47107 (* 1 = 1.47107 loss)
I1211 14:58:27.018883 16720 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1211 14:58:33.176578 16720 solver.cpp:218] Iteration 43700 (16.2403 iter/s, 6.15753s/100 iters), loss = 1.58306
I1211 14:58:33.176578 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:58:33.176578 16720 solver.cpp:237]     Train net output #1: loss = 1.58306 (* 1 = 1.58306 loss)
I1211 14:58:33.176578 16720 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1211 14:58:39.330045 16720 solver.cpp:218] Iteration 43800 (16.2524 iter/s, 6.15292s/100 iters), loss = 1.74152
I1211 14:58:39.330045 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:58:39.330045 16720 solver.cpp:237]     Train net output #1: loss = 1.74152 (* 1 = 1.74152 loss)
I1211 14:58:39.330045 16720 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1211 14:58:45.483470 16720 solver.cpp:218] Iteration 43900 (16.2514 iter/s, 6.1533s/100 iters), loss = 1.91975
I1211 14:58:45.483470 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:58:45.483470 16720 solver.cpp:237]     Train net output #1: loss = 1.91975 (* 1 = 1.91975 loss)
I1211 14:58:45.483470 16720 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1211 14:58:51.338878  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:58:51.582886 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_44000.caffemodel
I1211 14:58:51.597390 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_44000.solverstate
I1211 14:58:51.601891 16720 solver.cpp:330] Iteration 44000, Testing net (#0)
I1211 14:58:51.601891 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:58:52.938040 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:58:52.991039 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3392
I1211 14:58:52.991039 16720 solver.cpp:397]     Test net output #1: loss = 2.81351 (* 1 = 2.81351 loss)
I1211 14:58:53.049049 16720 solver.cpp:218] Iteration 44000 (13.2186 iter/s, 7.56511s/100 iters), loss = 1.81423
I1211 14:58:53.049049 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 14:58:53.049049 16720 solver.cpp:237]     Train net output #1: loss = 1.81423 (* 1 = 1.81423 loss)
I1211 14:58:53.049049 16720 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1211 14:58:59.202469 16720 solver.cpp:218] Iteration 44100 (16.2535 iter/s, 6.15254s/100 iters), loss = 1.69574
I1211 14:58:59.202970 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 14:58:59.202970 16720 solver.cpp:237]     Train net output #1: loss = 1.69574 (* 1 = 1.69574 loss)
I1211 14:58:59.202970 16720 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1211 14:59:05.358935 16720 solver.cpp:218] Iteration 44200 (16.2443 iter/s, 6.15599s/100 iters), loss = 1.37517
I1211 14:59:05.359436 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 14:59:05.359436 16720 solver.cpp:237]     Train net output #1: loss = 1.37517 (* 1 = 1.37517 loss)
I1211 14:59:05.359436 16720 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1211 14:59:11.515699 16720 solver.cpp:218] Iteration 44300 (16.243 iter/s, 6.1565s/100 iters), loss = 1.80547
I1211 14:59:11.515699 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 14:59:11.515699 16720 solver.cpp:237]     Train net output #1: loss = 1.80547 (* 1 = 1.80547 loss)
I1211 14:59:11.515699 16720 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1211 14:59:17.674701 16720 solver.cpp:218] Iteration 44400 (16.2385 iter/s, 6.15819s/100 iters), loss = 1.71353
I1211 14:59:17.674701 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 14:59:17.674701 16720 solver.cpp:237]     Train net output #1: loss = 1.71353 (* 1 = 1.71353 loss)
I1211 14:59:17.674701 16720 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1211 14:59:23.527460  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:59:23.770472 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_44500.caffemodel
I1211 14:59:23.787485 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_44500.solverstate
I1211 14:59:23.791985 16720 solver.cpp:330] Iteration 44500, Testing net (#0)
I1211 14:59:23.792488 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:59:25.126590 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:59:25.179590 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3694
I1211 14:59:25.179590 16720 solver.cpp:397]     Test net output #1: loss = 2.58352 (* 1 = 2.58352 loss)
I1211 14:59:25.238600 16720 solver.cpp:218] Iteration 44500 (13.2217 iter/s, 7.56335s/100 iters), loss = 1.59357
I1211 14:59:25.238600 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 14:59:25.238600 16720 solver.cpp:237]     Train net output #1: loss = 1.59357 (* 1 = 1.59357 loss)
I1211 14:59:25.238600 16720 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1211 14:59:31.382128 16720 solver.cpp:218] Iteration 44600 (16.2771 iter/s, 6.1436s/100 iters), loss = 1.51829
I1211 14:59:31.382128 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 14:59:31.382128 16720 solver.cpp:237]     Train net output #1: loss = 1.51829 (* 1 = 1.51829 loss)
I1211 14:59:31.382128 16720 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1211 14:59:37.534600 16720 solver.cpp:218] Iteration 44700 (16.2561 iter/s, 6.15152s/100 iters), loss = 1.38736
I1211 14:59:37.534600 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 14:59:37.534600 16720 solver.cpp:237]     Train net output #1: loss = 1.38736 (* 1 = 1.38736 loss)
I1211 14:59:37.534600 16720 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1211 14:59:43.689093 16720 solver.cpp:218] Iteration 44800 (16.2493 iter/s, 6.15412s/100 iters), loss = 1.80531
I1211 14:59:43.689093 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 14:59:43.689093 16720 solver.cpp:237]     Train net output #1: loss = 1.80531 (* 1 = 1.80531 loss)
I1211 14:59:43.689093 16720 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1211 14:59:49.843632 16720 solver.cpp:218] Iteration 44900 (16.2476 iter/s, 6.15474s/100 iters), loss = 1.77506
I1211 14:59:49.843632 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 14:59:49.844633 16720 solver.cpp:237]     Train net output #1: loss = 1.77506 (* 1 = 1.77506 loss)
I1211 14:59:49.844633 16720 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1211 14:59:55.698035  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:59:55.941066 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_45000.caffemodel
I1211 14:59:55.956071 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_45000.solverstate
I1211 14:59:55.961078 16720 solver.cpp:330] Iteration 45000, Testing net (#0)
I1211 14:59:55.961078 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 14:59:57.294731 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 14:59:57.347234 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3142
I1211 14:59:57.347234 16720 solver.cpp:397]     Test net output #1: loss = 2.96729 (* 1 = 2.96729 loss)
I1211 14:59:57.405237 16720 solver.cpp:218] Iteration 45000 (13.2261 iter/s, 7.56081s/100 iters), loss = 1.6368
I1211 14:59:57.405237 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 14:59:57.405237 16720 solver.cpp:237]     Train net output #1: loss = 1.6368 (* 1 = 1.6368 loss)
I1211 14:59:57.405237 16720 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1211 15:00:03.593008 16720 solver.cpp:218] Iteration 45100 (16.1632 iter/s, 6.18691s/100 iters), loss = 1.55094
I1211 15:00:03.593008 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 15:00:03.593008 16720 solver.cpp:237]     Train net output #1: loss = 1.55094 (* 1 = 1.55094 loss)
I1211 15:00:03.593008 16720 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1211 15:00:09.748489 16720 solver.cpp:218] Iteration 45200 (16.247 iter/s, 6.15497s/100 iters), loss = 1.33783
I1211 15:00:09.748489 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 15:00:09.748489 16720 solver.cpp:237]     Train net output #1: loss = 1.33783 (* 1 = 1.33783 loss)
I1211 15:00:09.748489 16720 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1211 15:00:15.917948 16720 solver.cpp:218] Iteration 45300 (16.2109 iter/s, 6.16867s/100 iters), loss = 1.67514
I1211 15:00:15.917948 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 15:00:15.917948 16720 solver.cpp:237]     Train net output #1: loss = 1.67514 (* 1 = 1.67514 loss)
I1211 15:00:15.917948 16720 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1211 15:00:22.079387 16720 solver.cpp:218] Iteration 45400 (16.229 iter/s, 6.16181s/100 iters), loss = 1.64226
I1211 15:00:22.079387 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 15:00:22.079387 16720 solver.cpp:237]     Train net output #1: loss = 1.64226 (* 1 = 1.64226 loss)
I1211 15:00:22.079387 16720 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1211 15:00:27.938879  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:00:28.182888 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_45500.caffemodel
I1211 15:00:28.198395 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_45500.solverstate
I1211 15:00:28.202895 16720 solver.cpp:330] Iteration 45500, Testing net (#0)
I1211 15:00:28.203395 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:00:29.539000 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:00:29.591502 16720 solver.cpp:397]     Test net output #0: accuracy = 0.397
I1211 15:00:29.591502 16720 solver.cpp:397]     Test net output #1: loss = 2.44894 (* 1 = 2.44894 loss)
I1211 15:00:29.650004 16720 solver.cpp:218] Iteration 45500 (13.2112 iter/s, 7.56935s/100 iters), loss = 1.57923
I1211 15:00:29.650004 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 15:00:29.650004 16720 solver.cpp:237]     Train net output #1: loss = 1.57923 (* 1 = 1.57923 loss)
I1211 15:00:29.650004 16720 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1211 15:00:35.801430 16720 solver.cpp:218] Iteration 45600 (16.2576 iter/s, 6.15097s/100 iters), loss = 1.47987
I1211 15:00:35.801430 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 15:00:35.801430 16720 solver.cpp:237]     Train net output #1: loss = 1.47987 (* 1 = 1.47987 loss)
I1211 15:00:35.801430 16720 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1211 15:00:41.947378 16720 solver.cpp:218] Iteration 45700 (16.2711 iter/s, 6.14587s/100 iters), loss = 1.34892
I1211 15:00:41.947378 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 15:00:41.947378 16720 solver.cpp:237]     Train net output #1: loss = 1.34892 (* 1 = 1.34892 loss)
I1211 15:00:41.947378 16720 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1211 15:00:48.084887 16720 solver.cpp:218] Iteration 45800 (16.2933 iter/s, 6.13749s/100 iters), loss = 1.77078
I1211 15:00:48.084887 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 15:00:48.084887 16720 solver.cpp:237]     Train net output #1: loss = 1.77078 (* 1 = 1.77078 loss)
I1211 15:00:48.084887 16720 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1211 15:00:54.223810 16720 solver.cpp:218] Iteration 45900 (16.2926 iter/s, 6.13774s/100 iters), loss = 1.79914
I1211 15:00:54.223810 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 15:00:54.223810 16720 solver.cpp:237]     Train net output #1: loss = 1.79914 (* 1 = 1.79914 loss)
I1211 15:00:54.223810 16720 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1211 15:01:00.068421  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:01:00.309449 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_46000.caffemodel
I1211 15:01:00.325453 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_46000.solverstate
I1211 15:01:00.329454 16720 solver.cpp:330] Iteration 46000, Testing net (#0)
I1211 15:01:00.329454 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:01:01.665536 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:01:01.718544 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2622
I1211 15:01:01.718544 16720 solver.cpp:397]     Test net output #1: loss = 3.64209 (* 1 = 3.64209 loss)
I1211 15:01:01.777542 16720 solver.cpp:218] Iteration 46000 (13.2387 iter/s, 7.55359s/100 iters), loss = 1.66263
I1211 15:01:01.777542 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 15:01:01.777542 16720 solver.cpp:237]     Train net output #1: loss = 1.66263 (* 1 = 1.66263 loss)
I1211 15:01:01.777542 16720 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1211 15:01:07.945055 16720 solver.cpp:218] Iteration 46100 (16.2152 iter/s, 6.16704s/100 iters), loss = 1.5209
I1211 15:01:07.945055 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 15:01:07.945055 16720 solver.cpp:237]     Train net output #1: loss = 1.5209 (* 1 = 1.5209 loss)
I1211 15:01:07.945055 16720 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1211 15:01:14.098717 16720 solver.cpp:218] Iteration 46200 (16.2524 iter/s, 6.15294s/100 iters), loss = 1.31186
I1211 15:01:14.098717 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 15:01:14.098717 16720 solver.cpp:237]     Train net output #1: loss = 1.31186 (* 1 = 1.31186 loss)
I1211 15:01:14.098717 16720 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1211 15:01:20.262287 16720 solver.cpp:218] Iteration 46300 (16.225 iter/s, 6.16331s/100 iters), loss = 1.68218
I1211 15:01:20.262287 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 15:01:20.262287 16720 solver.cpp:237]     Train net output #1: loss = 1.68218 (* 1 = 1.68218 loss)
I1211 15:01:20.262287 16720 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1211 15:01:26.418015 16720 solver.cpp:218] Iteration 46400 (16.2444 iter/s, 6.15598s/100 iters), loss = 1.92411
I1211 15:01:26.418015 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 15:01:26.418015 16720 solver.cpp:237]     Train net output #1: loss = 1.92411 (* 1 = 1.92411 loss)
I1211 15:01:26.418015 16720 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1211 15:01:32.274104  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:01:32.517199 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_46500.caffemodel
I1211 15:01:32.532203 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_46500.solverstate
I1211 15:01:32.536203 16720 solver.cpp:330] Iteration 46500, Testing net (#0)
I1211 15:01:32.536203 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:01:33.868778 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:01:33.921406 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2941
I1211 15:01:33.921406 16720 solver.cpp:397]     Test net output #1: loss = 3.19716 (* 1 = 3.19716 loss)
I1211 15:01:33.980388 16720 solver.cpp:218] Iteration 46500 (13.2247 iter/s, 7.56162s/100 iters), loss = 1.44815
I1211 15:01:33.980388 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 15:01:33.980388 16720 solver.cpp:237]     Train net output #1: loss = 1.44815 (* 1 = 1.44815 loss)
I1211 15:01:33.980388 16720 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1211 15:01:40.139935 16720 solver.cpp:218] Iteration 46600 (16.2367 iter/s, 6.15888s/100 iters), loss = 1.60993
I1211 15:01:40.139935 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 15:01:40.139935 16720 solver.cpp:237]     Train net output #1: loss = 1.60993 (* 1 = 1.60993 loss)
I1211 15:01:40.139935 16720 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1211 15:01:46.293517 16720 solver.cpp:218] Iteration 46700 (16.2511 iter/s, 6.15344s/100 iters), loss = 1.29441
I1211 15:01:46.293517 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 15:01:46.293517 16720 solver.cpp:237]     Train net output #1: loss = 1.29441 (* 1 = 1.29441 loss)
I1211 15:01:46.293517 16720 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1211 15:01:52.443964 16720 solver.cpp:218] Iteration 46800 (16.2597 iter/s, 6.15017s/100 iters), loss = 1.6245
I1211 15:01:52.443964 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 15:01:52.443964 16720 solver.cpp:237]     Train net output #1: loss = 1.6245 (* 1 = 1.6245 loss)
I1211 15:01:52.443964 16720 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1211 15:01:58.600571 16720 solver.cpp:218] Iteration 46900 (16.2442 iter/s, 6.15605s/100 iters), loss = 1.89154
I1211 15:01:58.600571 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 15:01:58.600571 16720 solver.cpp:237]     Train net output #1: loss = 1.89154 (* 1 = 1.89154 loss)
I1211 15:01:58.600571 16720 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1211 15:02:04.449888  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:02:04.692448 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_47000.caffemodel
I1211 15:02:04.707965 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_47000.solverstate
I1211 15:02:04.712952 16720 solver.cpp:330] Iteration 47000, Testing net (#0)
I1211 15:02:04.712952 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:02:06.046095 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:02:06.099097 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3457
I1211 15:02:06.099097 16720 solver.cpp:397]     Test net output #1: loss = 2.68838 (* 1 = 2.68838 loss)
I1211 15:02:06.158128 16720 solver.cpp:218] Iteration 47000 (13.2327 iter/s, 7.55704s/100 iters), loss = 1.63143
I1211 15:02:06.158128 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 15:02:06.158128 16720 solver.cpp:237]     Train net output #1: loss = 1.63143 (* 1 = 1.63143 loss)
I1211 15:02:06.158128 16720 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1211 15:02:12.309025 16720 solver.cpp:218] Iteration 47100 (16.2598 iter/s, 6.15013s/100 iters), loss = 1.5013
I1211 15:02:12.309025 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 15:02:12.309025 16720 solver.cpp:237]     Train net output #1: loss = 1.5013 (* 1 = 1.5013 loss)
I1211 15:02:12.309025 16720 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1211 15:02:18.466464 16720 solver.cpp:218] Iteration 47200 (16.2406 iter/s, 6.15741s/100 iters), loss = 1.37404
I1211 15:02:18.466464 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 15:02:18.466464 16720 solver.cpp:237]     Train net output #1: loss = 1.37404 (* 1 = 1.37404 loss)
I1211 15:02:18.466464 16720 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1211 15:02:24.637929 16720 solver.cpp:218] Iteration 47300 (16.2054 iter/s, 6.17077s/100 iters), loss = 1.71643
I1211 15:02:24.637929 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 15:02:24.637929 16720 solver.cpp:237]     Train net output #1: loss = 1.71643 (* 1 = 1.71643 loss)
I1211 15:02:24.637929 16720 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1211 15:02:30.801801 16720 solver.cpp:218] Iteration 47400 (16.2258 iter/s, 6.16302s/100 iters), loss = 1.73373
I1211 15:02:30.801801 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 15:02:30.801801 16720 solver.cpp:237]     Train net output #1: loss = 1.73373 (* 1 = 1.73373 loss)
I1211 15:02:30.801801 16720 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1211 15:02:36.648705  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:02:36.892719 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_47500.caffemodel
I1211 15:02:36.908222 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_47500.solverstate
I1211 15:02:36.912726 16720 solver.cpp:330] Iteration 47500, Testing net (#0)
I1211 15:02:36.912726 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:02:38.248822 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:02:38.300822 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3343
I1211 15:02:38.300822 16720 solver.cpp:397]     Test net output #1: loss = 2.7973 (* 1 = 2.7973 loss)
I1211 15:02:38.359836 16720 solver.cpp:218] Iteration 47500 (13.2307 iter/s, 7.55816s/100 iters), loss = 1.73881
I1211 15:02:38.359836 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 15:02:38.359836 16720 solver.cpp:237]     Train net output #1: loss = 1.73881 (* 1 = 1.73881 loss)
I1211 15:02:38.359836 16720 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1211 15:02:44.516369 16720 solver.cpp:218] Iteration 47600 (16.2448 iter/s, 6.15581s/100 iters), loss = 1.79074
I1211 15:02:44.516369 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 15:02:44.516369 16720 solver.cpp:237]     Train net output #1: loss = 1.79074 (* 1 = 1.79074 loss)
I1211 15:02:44.516369 16720 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1211 15:02:50.668764 16720 solver.cpp:218] Iteration 47700 (16.2556 iter/s, 6.15172s/100 iters), loss = 1.43521
I1211 15:02:50.668764 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 15:02:50.668764 16720 solver.cpp:237]     Train net output #1: loss = 1.43521 (* 1 = 1.43521 loss)
I1211 15:02:50.668764 16720 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1211 15:02:56.822244 16720 solver.cpp:218] Iteration 47800 (16.2524 iter/s, 6.15294s/100 iters), loss = 1.68231
I1211 15:02:56.822244 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 15:02:56.822244 16720 solver.cpp:237]     Train net output #1: loss = 1.68231 (* 1 = 1.68231 loss)
I1211 15:02:56.822244 16720 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1211 15:03:02.979724 16720 solver.cpp:218] Iteration 47900 (16.2403 iter/s, 6.15754s/100 iters), loss = 1.78227
I1211 15:03:02.980726 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 15:03:02.980726 16720 solver.cpp:237]     Train net output #1: loss = 1.78227 (* 1 = 1.78227 loss)
I1211 15:03:02.980726 16720 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1211 15:03:08.836274  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:03:09.079289 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_48000.caffemodel
I1211 15:03:09.095290 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_48000.solverstate
I1211 15:03:09.099797 16720 solver.cpp:330] Iteration 48000, Testing net (#0)
I1211 15:03:09.099797 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:03:10.437388 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:03:10.489384 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3187
I1211 15:03:10.489384 16720 solver.cpp:397]     Test net output #1: loss = 2.8588 (* 1 = 2.8588 loss)
I1211 15:03:10.548390 16720 solver.cpp:218] Iteration 48000 (13.2146 iter/s, 7.56741s/100 iters), loss = 1.72283
I1211 15:03:10.548390 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 15:03:10.548390 16720 solver.cpp:237]     Train net output #1: loss = 1.72283 (* 1 = 1.72283 loss)
I1211 15:03:10.548390 16720 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1211 15:03:16.709903 16720 solver.cpp:218] Iteration 48100 (16.2302 iter/s, 6.16134s/100 iters), loss = 1.56567
I1211 15:03:16.709903 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 15:03:16.709903 16720 solver.cpp:237]     Train net output #1: loss = 1.56567 (* 1 = 1.56567 loss)
I1211 15:03:16.709903 16720 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1211 15:03:22.862381 16720 solver.cpp:218] Iteration 48200 (16.2551 iter/s, 6.15193s/100 iters), loss = 1.38659
I1211 15:03:22.862381 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 15:03:22.862381 16720 solver.cpp:237]     Train net output #1: loss = 1.38659 (* 1 = 1.38659 loss)
I1211 15:03:22.862381 16720 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1211 15:03:29.021898 16720 solver.cpp:218] Iteration 48300 (16.2357 iter/s, 6.15925s/100 iters), loss = 1.66802
I1211 15:03:29.021898 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 15:03:29.021898 16720 solver.cpp:237]     Train net output #1: loss = 1.66802 (* 1 = 1.66802 loss)
I1211 15:03:29.021898 16720 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1211 15:03:35.180368 16720 solver.cpp:218] Iteration 48400 (16.2393 iter/s, 6.15791s/100 iters), loss = 1.58148
I1211 15:03:35.180368 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 15:03:35.180368 16720 solver.cpp:237]     Train net output #1: loss = 1.58148 (* 1 = 1.58148 loss)
I1211 15:03:35.180368 16720 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1211 15:03:41.041831  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:03:41.284843 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_48500.caffemodel
I1211 15:03:41.298843 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_48500.solverstate
I1211 15:03:41.304347 16720 solver.cpp:330] Iteration 48500, Testing net (#0)
I1211 15:03:41.304347 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:03:42.638942 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:03:42.691942 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2943
I1211 15:03:42.691942 16720 solver.cpp:397]     Test net output #1: loss = 3.31644 (* 1 = 3.31644 loss)
I1211 15:03:42.750946 16720 solver.cpp:218] Iteration 48500 (13.2096 iter/s, 7.57026s/100 iters), loss = 1.60298
I1211 15:03:42.750946 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 15:03:42.750946 16720 solver.cpp:237]     Train net output #1: loss = 1.60298 (* 1 = 1.60298 loss)
I1211 15:03:42.750946 16720 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1211 15:03:48.907945 16720 solver.cpp:218] Iteration 48600 (16.2431 iter/s, 6.15647s/100 iters), loss = 1.60069
I1211 15:03:48.907945 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 15:03:48.907945 16720 solver.cpp:237]     Train net output #1: loss = 1.60069 (* 1 = 1.60069 loss)
I1211 15:03:48.907945 16720 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1211 15:03:55.065874 16720 solver.cpp:218] Iteration 48700 (16.2393 iter/s, 6.1579s/100 iters), loss = 1.3559
I1211 15:03:55.065874 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 15:03:55.065874 16720 solver.cpp:237]     Train net output #1: loss = 1.3559 (* 1 = 1.3559 loss)
I1211 15:03:55.065874 16720 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1211 15:04:01.230351 16720 solver.cpp:218] Iteration 48800 (16.2234 iter/s, 6.16395s/100 iters), loss = 1.68641
I1211 15:04:01.230351 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 15:04:01.230351 16720 solver.cpp:237]     Train net output #1: loss = 1.68641 (* 1 = 1.68641 loss)
I1211 15:04:01.230351 16720 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1211 15:04:07.387816 16720 solver.cpp:218] Iteration 48900 (16.2428 iter/s, 6.15658s/100 iters), loss = 1.85261
I1211 15:04:07.387816 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 15:04:07.387816 16720 solver.cpp:237]     Train net output #1: loss = 1.85261 (* 1 = 1.85261 loss)
I1211 15:04:07.387816 16720 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1211 15:04:13.249256  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:04:13.491264 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_49000.caffemodel
I1211 15:04:13.505769 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_49000.solverstate
I1211 15:04:13.510269 16720 solver.cpp:330] Iteration 49000, Testing net (#0)
I1211 15:04:13.510269 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:04:14.845365 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:04:14.896363 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3226
I1211 15:04:14.896363 16720 solver.cpp:397]     Test net output #1: loss = 2.89829 (* 1 = 2.89829 loss)
I1211 15:04:14.955369 16720 solver.cpp:218] Iteration 49000 (13.2142 iter/s, 7.5676s/100 iters), loss = 1.74412
I1211 15:04:14.955369 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 15:04:14.955369 16720 solver.cpp:237]     Train net output #1: loss = 1.74412 (* 1 = 1.74412 loss)
I1211 15:04:14.955369 16720 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1211 15:04:21.105294 16720 solver.cpp:218] Iteration 49100 (16.2636 iter/s, 6.14868s/100 iters), loss = 1.57255
I1211 15:04:21.105294 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 15:04:21.105294 16720 solver.cpp:237]     Train net output #1: loss = 1.57255 (* 1 = 1.57255 loss)
I1211 15:04:21.105294 16720 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1211 15:04:27.263216 16720 solver.cpp:218] Iteration 49200 (16.2388 iter/s, 6.15809s/100 iters), loss = 1.39654
I1211 15:04:27.263216 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 15:04:27.263216 16720 solver.cpp:237]     Train net output #1: loss = 1.39654 (* 1 = 1.39654 loss)
I1211 15:04:27.263216 16720 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1211 15:04:33.417712 16720 solver.cpp:218] Iteration 49300 (16.2512 iter/s, 6.15339s/100 iters), loss = 1.68319
I1211 15:04:33.417712 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 15:04:33.417712 16720 solver.cpp:237]     Train net output #1: loss = 1.68319 (* 1 = 1.68319 loss)
I1211 15:04:33.417712 16720 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1211 15:04:39.571179 16720 solver.cpp:218] Iteration 49400 (16.2497 iter/s, 6.15395s/100 iters), loss = 1.84264
I1211 15:04:39.572180 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 15:04:39.572180 16720 solver.cpp:237]     Train net output #1: loss = 1.84264 (* 1 = 1.84264 loss)
I1211 15:04:39.572180 16720 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1211 15:04:45.427763  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:04:45.668773 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_49500.caffemodel
I1211 15:04:45.684772 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_49500.solverstate
I1211 15:04:45.688773 16720 solver.cpp:330] Iteration 49500, Testing net (#0)
I1211 15:04:45.688773 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:04:47.024870 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:04:47.077869 16720 solver.cpp:397]     Test net output #0: accuracy = 0.2771
I1211 15:04:47.077869 16720 solver.cpp:397]     Test net output #1: loss = 3.37191 (* 1 = 3.37191 loss)
I1211 15:04:47.136889 16720 solver.cpp:218] Iteration 49500 (13.2193 iter/s, 7.56468s/100 iters), loss = 1.65765
I1211 15:04:47.136889 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 15:04:47.136889 16720 solver.cpp:237]     Train net output #1: loss = 1.65765 (* 1 = 1.65765 loss)
I1211 15:04:47.136889 16720 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1211 15:04:53.287408 16720 solver.cpp:218] Iteration 49600 (16.2608 iter/s, 6.14975s/100 iters), loss = 1.70882
I1211 15:04:53.287408 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 15:04:53.287408 16720 solver.cpp:237]     Train net output #1: loss = 1.70882 (* 1 = 1.70882 loss)
I1211 15:04:53.287408 16720 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1211 15:04:59.451891 16720 solver.cpp:218] Iteration 49700 (16.2233 iter/s, 6.16399s/100 iters), loss = 1.37675
I1211 15:04:59.451891 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 15:04:59.451891 16720 solver.cpp:237]     Train net output #1: loss = 1.37675 (* 1 = 1.37675 loss)
I1211 15:04:59.451891 16720 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1211 15:05:05.607919 16720 solver.cpp:218] Iteration 49800 (16.2441 iter/s, 6.15606s/100 iters), loss = 1.66809
I1211 15:05:05.608419 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 15:05:05.608419 16720 solver.cpp:237]     Train net output #1: loss = 1.66809 (* 1 = 1.66809 loss)
I1211 15:05:05.608419 16720 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1211 15:05:11.765887 16720 solver.cpp:218] Iteration 49900 (16.2409 iter/s, 6.15728s/100 iters), loss = 1.65732
I1211 15:05:11.765887 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 15:05:11.765887 16720 solver.cpp:237]     Train net output #1: loss = 1.65732 (* 1 = 1.65732 loss)
I1211 15:05:11.765887 16720 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1211 15:05:17.627298  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:05:17.870319 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_50000.caffemodel
I1211 15:05:17.885319 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_50000.solverstate
I1211 15:05:17.890319 16720 solver.cpp:330] Iteration 50000, Testing net (#0)
I1211 15:05:17.890319 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:05:19.228428 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:05:19.281428 16720 solver.cpp:397]     Test net output #0: accuracy = 0.3395
I1211 15:05:19.281428 16720 solver.cpp:397]     Test net output #1: loss = 3.02216 (* 1 = 3.02216 loss)
I1211 15:05:19.340435 16720 solver.cpp:218] Iteration 50000 (13.2018 iter/s, 7.57473s/100 iters), loss = 1.46116
I1211 15:05:19.340435 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 15:05:19.340435 16720 solver.cpp:237]     Train net output #1: loss = 1.46116 (* 1 = 1.46116 loss)
I1211 15:05:19.340435 16720 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1211 15:05:19.340435 16720 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1211 15:05:25.491427 16720 solver.cpp:218] Iteration 50100 (16.2599 iter/s, 6.1501s/100 iters), loss = 1.23374
I1211 15:05:25.491427 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 15:05:25.491427 16720 solver.cpp:237]     Train net output #1: loss = 1.23374 (* 1 = 1.23374 loss)
I1211 15:05:25.491427 16720 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1211 15:05:31.642480 16720 solver.cpp:218] Iteration 50200 (16.2588 iter/s, 6.1505s/100 iters), loss = 0.97225
I1211 15:05:31.642480 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:05:31.642480 16720 solver.cpp:237]     Train net output #1: loss = 0.97225 (* 1 = 0.97225 loss)
I1211 15:05:31.642480 16720 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1211 15:05:37.793920 16720 solver.cpp:218] Iteration 50300 (16.2568 iter/s, 6.15128s/100 iters), loss = 1.1015
I1211 15:05:37.793920 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 15:05:37.793920 16720 solver.cpp:237]     Train net output #1: loss = 1.1015 (* 1 = 1.1015 loss)
I1211 15:05:37.793920 16720 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1211 15:05:43.942425 16720 solver.cpp:218] Iteration 50400 (16.2654 iter/s, 6.14801s/100 iters), loss = 1.17903
I1211 15:05:43.942425 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 15:05:43.942425 16720 solver.cpp:237]     Train net output #1: loss = 1.17903 (* 1 = 1.17903 loss)
I1211 15:05:43.942425 16720 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1211 15:05:49.790817  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:05:50.033835 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_50500.caffemodel
I1211 15:05:50.048835 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_50500.solverstate
I1211 15:05:50.052835 16720 solver.cpp:330] Iteration 50500, Testing net (#0)
I1211 15:05:50.053836 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:05:51.387933 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:05:51.439952 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6337
I1211 15:05:51.439952 16720 solver.cpp:397]     Test net output #1: loss = 1.28493 (* 1 = 1.28493 loss)
I1211 15:05:51.497952 16720 solver.cpp:218] Iteration 50500 (13.2357 iter/s, 7.55535s/100 iters), loss = 1.04748
I1211 15:05:51.497952 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:05:51.497952 16720 solver.cpp:237]     Train net output #1: loss = 1.04748 (* 1 = 1.04748 loss)
I1211 15:05:51.497952 16720 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1211 15:05:57.651489 16720 solver.cpp:218] Iteration 50600 (16.2532 iter/s, 6.15262s/100 iters), loss = 1.17033
I1211 15:05:57.651489 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 15:05:57.651489 16720 solver.cpp:237]     Train net output #1: loss = 1.17033 (* 1 = 1.17033 loss)
I1211 15:05:57.651489 16720 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1211 15:06:03.801925 16720 solver.cpp:218] Iteration 50700 (16.2607 iter/s, 6.14978s/100 iters), loss = 0.915092
I1211 15:06:03.801925 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:06:03.801925 16720 solver.cpp:237]     Train net output #1: loss = 0.915092 (* 1 = 0.915092 loss)
I1211 15:06:03.801925 16720 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1211 15:06:09.949450 16720 solver.cpp:218] Iteration 50800 (16.2676 iter/s, 6.1472s/100 iters), loss = 1.01967
I1211 15:06:09.949450 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:06:09.949450 16720 solver.cpp:237]     Train net output #1: loss = 1.01967 (* 1 = 1.01967 loss)
I1211 15:06:09.949450 16720 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1211 15:06:16.106866 16720 solver.cpp:218] Iteration 50900 (16.2416 iter/s, 6.15703s/100 iters), loss = 1.20977
I1211 15:06:16.106866 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 15:06:16.106866 16720 solver.cpp:237]     Train net output #1: loss = 1.20977 (* 1 = 1.20977 loss)
I1211 15:06:16.106866 16720 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1211 15:06:21.965337  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:06:22.208349 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_51000.caffemodel
I1211 15:06:22.224853 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_51000.solverstate
I1211 15:06:22.229353 16720 solver.cpp:330] Iteration 51000, Testing net (#0)
I1211 15:06:22.229353 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:06:23.562496 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:06:23.614496 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6375
I1211 15:06:23.614496 16720 solver.cpp:397]     Test net output #1: loss = 1.25723 (* 1 = 1.25723 loss)
I1211 15:06:23.673514 16720 solver.cpp:218] Iteration 51000 (13.2164 iter/s, 7.56636s/100 iters), loss = 0.952989
I1211 15:06:23.673514 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:06:23.673514 16720 solver.cpp:237]     Train net output #1: loss = 0.952989 (* 1 = 0.952989 loss)
I1211 15:06:23.673514 16720 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1211 15:06:29.818445 16720 solver.cpp:218] Iteration 51100 (16.2752 iter/s, 6.14432s/100 iters), loss = 1.10702
I1211 15:06:29.818945 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 15:06:29.818945 16720 solver.cpp:237]     Train net output #1: loss = 1.10702 (* 1 = 1.10702 loss)
I1211 15:06:29.818945 16720 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1211 15:06:35.976369 16720 solver.cpp:218] Iteration 51200 (16.2391 iter/s, 6.15798s/100 iters), loss = 0.869894
I1211 15:06:35.977370 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:06:35.977370 16720 solver.cpp:237]     Train net output #1: loss = 0.869894 (* 1 = 0.869894 loss)
I1211 15:06:35.977370 16720 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1211 15:06:42.138077 16720 solver.cpp:218] Iteration 51300 (16.2322 iter/s, 6.16058s/100 iters), loss = 1.05794
I1211 15:06:42.138077 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 15:06:42.138077 16720 solver.cpp:237]     Train net output #1: loss = 1.05794 (* 1 = 1.05794 loss)
I1211 15:06:42.138077 16720 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1211 15:06:48.295526 16720 solver.cpp:218] Iteration 51400 (16.2421 iter/s, 6.15684s/100 iters), loss = 1.09937
I1211 15:06:48.295526 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 15:06:48.295526 16720 solver.cpp:237]     Train net output #1: loss = 1.09937 (* 1 = 1.09937 loss)
I1211 15:06:48.295526 16720 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1211 15:06:54.150995  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:06:54.393005 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_51500.caffemodel
I1211 15:06:54.409005 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_51500.solverstate
I1211 15:06:54.413005 16720 solver.cpp:330] Iteration 51500, Testing net (#0)
I1211 15:06:54.414006 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:06:55.750110 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:06:55.802110 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6383
I1211 15:06:55.802110 16720 solver.cpp:397]     Test net output #1: loss = 1.25157 (* 1 = 1.25157 loss)
I1211 15:06:55.861115 16720 solver.cpp:218] Iteration 51500 (13.2176 iter/s, 7.56566s/100 iters), loss = 0.892192
I1211 15:06:55.861115 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:06:55.861115 16720 solver.cpp:237]     Train net output #1: loss = 0.892192 (* 1 = 0.892192 loss)
I1211 15:06:55.861115 16720 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1211 15:07:02.017530 16720 solver.cpp:218] Iteration 51600 (16.2459 iter/s, 6.15541s/100 iters), loss = 0.982756
I1211 15:07:02.017530 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:07:02.017530 16720 solver.cpp:237]     Train net output #1: loss = 0.982756 (* 1 = 0.982756 loss)
I1211 15:07:02.017530 16720 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1211 15:07:08.169960 16720 solver.cpp:218] Iteration 51700 (16.2557 iter/s, 6.15169s/100 iters), loss = 0.884641
I1211 15:07:08.169960 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:07:08.169960 16720 solver.cpp:237]     Train net output #1: loss = 0.884641 (* 1 = 0.884641 loss)
I1211 15:07:08.169960 16720 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1211 15:07:14.347744 16720 solver.cpp:218] Iteration 51800 (16.1873 iter/s, 6.17767s/100 iters), loss = 0.969278
I1211 15:07:14.347744 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:07:14.347744 16720 solver.cpp:237]     Train net output #1: loss = 0.969278 (* 1 = 0.969278 loss)
I1211 15:07:14.347744 16720 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1211 15:07:20.520048 16720 solver.cpp:218] Iteration 51900 (16.2035 iter/s, 6.17151s/100 iters), loss = 1.07756
I1211 15:07:20.520048 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 15:07:20.520048 16720 solver.cpp:237]     Train net output #1: loss = 1.07756 (* 1 = 1.07756 loss)
I1211 15:07:20.520048 16720 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1211 15:07:26.477576  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:07:26.726080 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_52000.caffemodel
I1211 15:07:26.747081 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_52000.solverstate
I1211 15:07:26.752581 16720 solver.cpp:330] Iteration 52000, Testing net (#0)
I1211 15:07:26.752581 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:07:28.110652 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:07:28.162652 16720 solver.cpp:397]     Test net output #0: accuracy = 0.64
I1211 15:07:28.162652 16720 solver.cpp:397]     Test net output #1: loss = 1.26417 (* 1 = 1.26417 loss)
I1211 15:07:28.223592 16720 solver.cpp:218] Iteration 52000 (12.9817 iter/s, 7.70313s/100 iters), loss = 0.815097
I1211 15:07:28.223592 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:07:28.223592 16720 solver.cpp:237]     Train net output #1: loss = 0.815097 (* 1 = 0.815097 loss)
I1211 15:07:28.223592 16720 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1211 15:07:34.473417 16720 solver.cpp:218] Iteration 52100 (16.0003 iter/s, 6.24987s/100 iters), loss = 1.03092
I1211 15:07:34.473417 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:07:34.473417 16720 solver.cpp:237]     Train net output #1: loss = 1.03092 (* 1 = 1.03092 loss)
I1211 15:07:34.473417 16720 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1211 15:07:40.765208 16720 solver.cpp:218] Iteration 52200 (15.895 iter/s, 6.29129s/100 iters), loss = 0.863911
I1211 15:07:40.765208 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:07:40.765208 16720 solver.cpp:237]     Train net output #1: loss = 0.863911 (* 1 = 0.863911 loss)
I1211 15:07:40.765208 16720 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1211 15:07:47.046681 16720 solver.cpp:218] Iteration 52300 (15.9225 iter/s, 6.28043s/100 iters), loss = 0.982929
I1211 15:07:47.046681 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:07:47.046681 16720 solver.cpp:237]     Train net output #1: loss = 0.982929 (* 1 = 0.982929 loss)
I1211 15:07:47.046681 16720 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1211 15:07:53.369077 16720 solver.cpp:218] Iteration 52400 (15.8172 iter/s, 6.32225s/100 iters), loss = 1.04142
I1211 15:07:53.369077 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 15:07:53.369077 16720 solver.cpp:237]     Train net output #1: loss = 1.04142 (* 1 = 1.04142 loss)
I1211 15:07:53.369077 16720 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1211 15:07:59.348781  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:07:59.598794 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_52500.caffemodel
I1211 15:07:59.615797 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_52500.solverstate
I1211 15:07:59.619801 16720 solver.cpp:330] Iteration 52500, Testing net (#0)
I1211 15:07:59.619801 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:08:00.980912 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:08:01.034916 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6414
I1211 15:08:01.034916 16720 solver.cpp:397]     Test net output #1: loss = 1.2462 (* 1 = 1.2462 loss)
I1211 15:08:01.093915 16720 solver.cpp:218] Iteration 52500 (12.9454 iter/s, 7.72477s/100 iters), loss = 0.811182
I1211 15:08:01.094915 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:08:01.094915 16720 solver.cpp:237]     Train net output #1: loss = 0.811182 (* 1 = 0.811182 loss)
I1211 15:08:01.094915 16720 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1211 15:08:07.394572 16720 solver.cpp:218] Iteration 52600 (15.8736 iter/s, 6.29977s/100 iters), loss = 0.943742
I1211 15:08:07.394572 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:08:07.394572 16720 solver.cpp:237]     Train net output #1: loss = 0.943742 (* 1 = 0.943742 loss)
I1211 15:08:07.394572 16720 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1211 15:08:13.721180 16720 solver.cpp:218] Iteration 52700 (15.8079 iter/s, 6.32596s/100 iters), loss = 0.845476
I1211 15:08:13.721180 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:08:13.721180 16720 solver.cpp:237]     Train net output #1: loss = 0.845476 (* 1 = 0.845476 loss)
I1211 15:08:13.721180 16720 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1211 15:08:20.016525 16720 solver.cpp:218] Iteration 52800 (15.887 iter/s, 6.29446s/100 iters), loss = 0.889961
I1211 15:08:20.016525 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:08:20.016525 16720 solver.cpp:237]     Train net output #1: loss = 0.889961 (* 1 = 0.889961 loss)
I1211 15:08:20.016525 16720 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1211 15:08:26.300457 16720 solver.cpp:218] Iteration 52900 (15.9153 iter/s, 6.28326s/100 iters), loss = 1.04726
I1211 15:08:26.300457 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 15:08:26.300457 16720 solver.cpp:237]     Train net output #1: loss = 1.04726 (* 1 = 1.04726 loss)
I1211 15:08:26.300457 16720 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1211 15:08:32.294689  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:08:32.536754 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_53000.caffemodel
I1211 15:08:32.551755 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_53000.solverstate
I1211 15:08:32.555754 16720 solver.cpp:330] Iteration 53000, Testing net (#0)
I1211 15:08:32.555754 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:08:33.899922 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:08:33.952998 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6421
I1211 15:08:33.952998 16720 solver.cpp:397]     Test net output #1: loss = 1.2347 (* 1 = 1.2347 loss)
I1211 15:08:34.013521 16720 solver.cpp:218] Iteration 53000 (12.9655 iter/s, 7.71278s/100 iters), loss = 0.70807
I1211 15:08:34.013521 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:08:34.013521 16720 solver.cpp:237]     Train net output #1: loss = 0.70807 (* 1 = 0.70807 loss)
I1211 15:08:34.013521 16720 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1211 15:08:40.246276 16720 solver.cpp:218] Iteration 53100 (16.0436 iter/s, 6.23302s/100 iters), loss = 0.937451
I1211 15:08:40.246276 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:08:40.247277 16720 solver.cpp:237]     Train net output #1: loss = 0.937451 (* 1 = 0.937451 loss)
I1211 15:08:40.247277 16720 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1211 15:08:46.466822 16720 solver.cpp:218] Iteration 53200 (16.0781 iter/s, 6.21965s/100 iters), loss = 0.7824
I1211 15:08:46.466822 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:08:46.466822 16720 solver.cpp:237]     Train net output #1: loss = 0.7824 (* 1 = 0.7824 loss)
I1211 15:08:46.466822 16720 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1211 15:08:52.704169 16720 solver.cpp:218] Iteration 53300 (16.035 iter/s, 6.23635s/100 iters), loss = 0.86261
I1211 15:08:52.704169 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:08:52.704169 16720 solver.cpp:237]     Train net output #1: loss = 0.86261 (* 1 = 0.86261 loss)
I1211 15:08:52.704169 16720 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1211 15:08:58.915223 16720 solver.cpp:218] Iteration 53400 (16.1014 iter/s, 6.21062s/100 iters), loss = 0.886876
I1211 15:08:58.915223 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:08:58.915223 16720 solver.cpp:237]     Train net output #1: loss = 0.886876 (* 1 = 0.886876 loss)
I1211 15:08:58.915223 16720 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1211 15:09:04.802458  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:09:05.045485 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_53500.caffemodel
I1211 15:09:05.060484 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_53500.solverstate
I1211 15:09:05.064486 16720 solver.cpp:330] Iteration 53500, Testing net (#0)
I1211 15:09:05.064486 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:09:06.400573 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:09:06.453583 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6355
I1211 15:09:06.453583 16720 solver.cpp:397]     Test net output #1: loss = 1.26714 (* 1 = 1.26714 loss)
I1211 15:09:06.512578 16720 solver.cpp:218] Iteration 53500 (13.1632 iter/s, 7.59691s/100 iters), loss = 0.799928
I1211 15:09:06.512578 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:09:06.512578 16720 solver.cpp:237]     Train net output #1: loss = 0.799928 (* 1 = 0.799928 loss)
I1211 15:09:06.512578 16720 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1211 15:09:12.664032 16720 solver.cpp:218] Iteration 53600 (16.2562 iter/s, 6.1515s/100 iters), loss = 0.902172
I1211 15:09:12.664032 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 15:09:12.664032 16720 solver.cpp:237]     Train net output #1: loss = 0.902172 (* 1 = 0.902172 loss)
I1211 15:09:12.664032 16720 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1211 15:09:18.815958 16720 solver.cpp:218] Iteration 53700 (16.2565 iter/s, 6.15138s/100 iters), loss = 0.823392
I1211 15:09:18.816458 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:09:18.816458 16720 solver.cpp:237]     Train net output #1: loss = 0.823392 (* 1 = 0.823392 loss)
I1211 15:09:18.816458 16720 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1211 15:09:24.966917 16720 solver.cpp:218] Iteration 53800 (16.2576 iter/s, 6.15097s/100 iters), loss = 0.890564
I1211 15:09:24.967916 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 15:09:24.967916 16720 solver.cpp:237]     Train net output #1: loss = 0.890564 (* 1 = 0.890564 loss)
I1211 15:09:24.967916 16720 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1211 15:09:31.122352 16720 solver.cpp:218] Iteration 53900 (16.2495 iter/s, 6.15403s/100 iters), loss = 0.976021
I1211 15:09:31.122352 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:09:31.122352 16720 solver.cpp:237]     Train net output #1: loss = 0.976021 (* 1 = 0.976021 loss)
I1211 15:09:31.122352 16720 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1211 15:09:36.976779  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:09:37.220293 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_54000.caffemodel
I1211 15:09:37.235798 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_54000.solverstate
I1211 15:09:37.240798 16720 solver.cpp:330] Iteration 54000, Testing net (#0)
I1211 15:09:37.240798 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:09:38.575928 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:09:38.628932 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6389
I1211 15:09:38.628932 16720 solver.cpp:397]     Test net output #1: loss = 1.27904 (* 1 = 1.27904 loss)
I1211 15:09:38.687927 16720 solver.cpp:218] Iteration 54000 (13.2188 iter/s, 7.56497s/100 iters), loss = 0.803991
I1211 15:09:38.687927 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:09:38.687927 16720 solver.cpp:237]     Train net output #1: loss = 0.803991 (* 1 = 0.803991 loss)
I1211 15:09:38.687927 16720 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1211 15:09:44.841572 16720 solver.cpp:218] Iteration 54100 (16.2511 iter/s, 6.15344s/100 iters), loss = 0.933723
I1211 15:09:44.841572 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:09:44.841572 16720 solver.cpp:237]     Train net output #1: loss = 0.933723 (* 1 = 0.933723 loss)
I1211 15:09:44.841572 16720 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1211 15:09:51.009114 16720 solver.cpp:218] Iteration 54200 (16.2134 iter/s, 6.16775s/100 iters), loss = 0.828469
I1211 15:09:51.010115 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:09:51.010115 16720 solver.cpp:237]     Train net output #1: loss = 0.828469 (* 1 = 0.828469 loss)
I1211 15:09:51.010115 16720 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1211 15:09:57.157586 16720 solver.cpp:218] Iteration 54300 (16.2662 iter/s, 6.14773s/100 iters), loss = 0.818197
I1211 15:09:57.157586 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:09:57.157586 16720 solver.cpp:237]     Train net output #1: loss = 0.818197 (* 1 = 0.818197 loss)
I1211 15:09:57.157586 16720 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1211 15:10:03.337205 16720 solver.cpp:218] Iteration 54400 (16.1847 iter/s, 6.17868s/100 iters), loss = 0.976004
I1211 15:10:03.337205 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:10:03.337205 16720 solver.cpp:237]     Train net output #1: loss = 0.976004 (* 1 = 0.976004 loss)
I1211 15:10:03.337205 16720 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1211 15:10:09.197626  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:10:09.440650 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_54500.caffemodel
I1211 15:10:09.455651 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_54500.solverstate
I1211 15:10:09.460650 16720 solver.cpp:330] Iteration 54500, Testing net (#0)
I1211 15:10:09.460650 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:10:10.796736 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:10:10.848759 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6339
I1211 15:10:10.848759 16720 solver.cpp:397]     Test net output #1: loss = 1.28406 (* 1 = 1.28406 loss)
I1211 15:10:10.907744 16720 solver.cpp:218] Iteration 54500 (13.2094 iter/s, 7.57039s/100 iters), loss = 0.722535
I1211 15:10:10.907744 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:10:10.907744 16720 solver.cpp:237]     Train net output #1: loss = 0.722535 (* 1 = 0.722535 loss)
I1211 15:10:10.907744 16720 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1211 15:10:17.067224 16720 solver.cpp:218] Iteration 54600 (16.2358 iter/s, 6.15924s/100 iters), loss = 0.85841
I1211 15:10:17.067224 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:10:17.067224 16720 solver.cpp:237]     Train net output #1: loss = 0.85841 (* 1 = 0.85841 loss)
I1211 15:10:17.067224 16720 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1211 15:10:23.378268 16720 solver.cpp:218] Iteration 54700 (15.8478 iter/s, 6.31002s/100 iters), loss = 0.810058
I1211 15:10:23.378268 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:10:23.378268 16720 solver.cpp:237]     Train net output #1: loss = 0.810058 (* 1 = 0.810058 loss)
I1211 15:10:23.378268 16720 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1211 15:10:29.688900 16720 solver.cpp:218] Iteration 54800 (15.847 iter/s, 6.31036s/100 iters), loss = 0.888151
I1211 15:10:29.688900 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:10:29.688900 16720 solver.cpp:237]     Train net output #1: loss = 0.888151 (* 1 = 0.888151 loss)
I1211 15:10:29.688900 16720 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1211 15:10:35.918395 16720 solver.cpp:218] Iteration 54900 (16.0545 iter/s, 6.22877s/100 iters), loss = 0.87568
I1211 15:10:35.918395 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:10:35.918395 16720 solver.cpp:237]     Train net output #1: loss = 0.87568 (* 1 = 0.87568 loss)
I1211 15:10:35.918395 16720 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1211 15:10:41.836946  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:10:42.081965 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_55000.caffemodel
I1211 15:10:42.097965 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_55000.solverstate
I1211 15:10:42.101965 16720 solver.cpp:330] Iteration 55000, Testing net (#0)
I1211 15:10:42.101965 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:10:43.457082 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:10:43.511080 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6395
I1211 15:10:43.511080 16720 solver.cpp:397]     Test net output #1: loss = 1.26883 (* 1 = 1.26883 loss)
I1211 15:10:43.571085 16720 solver.cpp:218] Iteration 55000 (13.0668 iter/s, 7.65298s/100 iters), loss = 0.717788
I1211 15:10:43.571085 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:10:43.571085 16720 solver.cpp:237]     Train net output #1: loss = 0.717788 (* 1 = 0.717788 loss)
I1211 15:10:43.571085 16720 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1211 15:10:49.864620 16720 solver.cpp:218] Iteration 55100 (15.892 iter/s, 6.29248s/100 iters), loss = 0.829838
I1211 15:10:49.864620 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:10:49.864620 16720 solver.cpp:237]     Train net output #1: loss = 0.829838 (* 1 = 0.829838 loss)
I1211 15:10:49.864620 16720 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1211 15:10:56.147814 16720 solver.cpp:218] Iteration 55200 (15.9153 iter/s, 6.28326s/100 iters), loss = 0.739224
I1211 15:10:56.147814 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:10:56.147814 16720 solver.cpp:237]     Train net output #1: loss = 0.739224 (* 1 = 0.739224 loss)
I1211 15:10:56.147814 16720 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1211 15:11:02.433044 16720 solver.cpp:218] Iteration 55300 (15.9128 iter/s, 6.28423s/100 iters), loss = 0.968168
I1211 15:11:02.433044 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 15:11:02.433044 16720 solver.cpp:237]     Train net output #1: loss = 0.968168 (* 1 = 0.968168 loss)
I1211 15:11:02.433044 16720 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1211 15:11:08.673128 16720 solver.cpp:218] Iteration 55400 (16.0263 iter/s, 6.23976s/100 iters), loss = 0.961612
I1211 15:11:08.673128 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:11:08.673128 16720 solver.cpp:237]     Train net output #1: loss = 0.961612 (* 1 = 0.961612 loss)
I1211 15:11:08.673128 16720 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1211 15:11:14.591570  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:11:14.837582 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_55500.caffemodel
I1211 15:11:14.852586 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_55500.solverstate
I1211 15:11:14.857585 16720 solver.cpp:330] Iteration 55500, Testing net (#0)
I1211 15:11:14.857585 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:11:16.201658 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:11:16.254668 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6323
I1211 15:11:16.254668 16720 solver.cpp:397]     Test net output #1: loss = 1.30798 (* 1 = 1.30798 loss)
I1211 15:11:16.315665 16720 solver.cpp:218] Iteration 55500 (13.0856 iter/s, 7.64196s/100 iters), loss = 0.715639
I1211 15:11:16.315665 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:11:16.315665 16720 solver.cpp:237]     Train net output #1: loss = 0.715639 (* 1 = 0.715639 loss)
I1211 15:11:16.315665 16720 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1211 15:11:22.536259 16720 solver.cpp:218] Iteration 55600 (16.0772 iter/s, 6.21999s/100 iters), loss = 0.906216
I1211 15:11:22.536259 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 15:11:22.536259 16720 solver.cpp:237]     Train net output #1: loss = 0.906216 (* 1 = 0.906216 loss)
I1211 15:11:22.536259 16720 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1211 15:11:28.764713 16720 solver.cpp:218] Iteration 55700 (16.0543 iter/s, 6.22887s/100 iters), loss = 0.741598
I1211 15:11:28.765712 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:11:28.765712 16720 solver.cpp:237]     Train net output #1: loss = 0.741598 (* 1 = 0.741598 loss)
I1211 15:11:28.765712 16720 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1211 15:11:34.976167 16720 solver.cpp:218] Iteration 55800 (16.1008 iter/s, 6.21087s/100 iters), loss = 0.907591
I1211 15:11:34.976167 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:11:34.976167 16720 solver.cpp:237]     Train net output #1: loss = 0.907591 (* 1 = 0.907591 loss)
I1211 15:11:34.976167 16720 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1211 15:11:41.208807 16720 solver.cpp:218] Iteration 55900 (16.0455 iter/s, 6.23228s/100 iters), loss = 0.862831
I1211 15:11:41.209807 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:11:41.209807 16720 solver.cpp:237]     Train net output #1: loss = 0.862831 (* 1 = 0.862831 loss)
I1211 15:11:41.209807 16720 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1211 15:11:47.210216  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:11:47.458894 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_56000.caffemodel
I1211 15:11:47.473891 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_56000.solverstate
I1211 15:11:47.478893 16720 solver.cpp:330] Iteration 56000, Testing net (#0)
I1211 15:11:47.478893 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:11:48.831074 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:11:48.883108 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6267
I1211 15:11:48.883108 16720 solver.cpp:397]     Test net output #1: loss = 1.31921 (* 1 = 1.31921 loss)
I1211 15:11:48.941628 16720 solver.cpp:218] Iteration 56000 (12.934 iter/s, 7.73155s/100 iters), loss = 0.728591
I1211 15:11:48.941628 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:11:48.941628 16720 solver.cpp:237]     Train net output #1: loss = 0.728591 (* 1 = 0.728591 loss)
I1211 15:11:48.941628 16720 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1211 15:11:55.250330 16720 solver.cpp:218] Iteration 56100 (15.8521 iter/s, 6.30831s/100 iters), loss = 0.845053
I1211 15:11:55.250330 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:11:55.250330 16720 solver.cpp:237]     Train net output #1: loss = 0.845053 (* 1 = 0.845053 loss)
I1211 15:11:55.250330 16720 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1211 15:12:01.560169 16720 solver.cpp:218] Iteration 56200 (15.8477 iter/s, 6.31006s/100 iters), loss = 0.748951
I1211 15:12:01.560169 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:12:01.560169 16720 solver.cpp:237]     Train net output #1: loss = 0.748951 (* 1 = 0.748951 loss)
I1211 15:12:01.560169 16720 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1211 15:12:07.854738 16720 solver.cpp:218] Iteration 56300 (15.8896 iter/s, 6.29344s/100 iters), loss = 0.810317
I1211 15:12:07.854738 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:12:07.854738 16720 solver.cpp:237]     Train net output #1: loss = 0.810317 (* 1 = 0.810317 loss)
I1211 15:12:07.854738 16720 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1211 15:12:14.130362 16720 solver.cpp:218] Iteration 56400 (15.9364 iter/s, 6.27496s/100 iters), loss = 0.899272
I1211 15:12:14.130362 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:12:14.130362 16720 solver.cpp:237]     Train net output #1: loss = 0.899272 (* 1 = 0.899272 loss)
I1211 15:12:14.130362 16720 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1211 15:12:20.099042  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:12:20.349066 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_56500.caffemodel
I1211 15:12:20.364569 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_56500.solverstate
I1211 15:12:20.369076 16720 solver.cpp:330] Iteration 56500, Testing net (#0)
I1211 15:12:20.369076 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:12:21.723186 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:12:21.777194 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6208
I1211 15:12:21.777194 16720 solver.cpp:397]     Test net output #1: loss = 1.37023 (* 1 = 1.37023 loss)
I1211 15:12:21.837193 16720 solver.cpp:218] Iteration 56500 (12.9761 iter/s, 7.7065s/100 iters), loss = 0.836235
I1211 15:12:21.837193 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:12:21.837193 16720 solver.cpp:237]     Train net output #1: loss = 0.836235 (* 1 = 0.836235 loss)
I1211 15:12:21.837193 16720 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1211 15:12:28.114799 16720 solver.cpp:218] Iteration 56600 (15.9299 iter/s, 6.2775s/100 iters), loss = 0.809429
I1211 15:12:28.114799 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:12:28.114799 16720 solver.cpp:237]     Train net output #1: loss = 0.809429 (* 1 = 0.809429 loss)
I1211 15:12:28.114799 16720 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1211 15:12:34.431355 16720 solver.cpp:218] Iteration 56700 (15.8333 iter/s, 6.3158s/100 iters), loss = 0.754306
I1211 15:12:34.431355 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:12:34.431355 16720 solver.cpp:237]     Train net output #1: loss = 0.754306 (* 1 = 0.754306 loss)
I1211 15:12:34.431355 16720 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1211 15:12:40.727397 16720 solver.cpp:218] Iteration 56800 (15.8843 iter/s, 6.29551s/100 iters), loss = 0.825694
I1211 15:12:40.727397 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:12:40.727397 16720 solver.cpp:237]     Train net output #1: loss = 0.825694 (* 1 = 0.825694 loss)
I1211 15:12:40.727397 16720 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1211 15:12:47.002914 16720 solver.cpp:218] Iteration 56900 (15.9365 iter/s, 6.27491s/100 iters), loss = 0.931503
I1211 15:12:47.002914 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:12:47.002914 16720 solver.cpp:237]     Train net output #1: loss = 0.931503 (* 1 = 0.931503 loss)
I1211 15:12:47.002914 16720 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1211 15:12:52.975903  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:12:53.220614 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_57000.caffemodel
I1211 15:12:53.236614 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_57000.solverstate
I1211 15:12:53.241616 16720 solver.cpp:330] Iteration 57000, Testing net (#0)
I1211 15:12:53.241616 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:12:54.595530 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:12:54.648525 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6266
I1211 15:12:54.649515 16720 solver.cpp:397]     Test net output #1: loss = 1.34242 (* 1 = 1.34242 loss)
I1211 15:12:54.709128 16720 solver.cpp:218] Iteration 57000 (12.9771 iter/s, 7.70586s/100 iters), loss = 0.748515
I1211 15:12:54.709128 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:12:54.709128 16720 solver.cpp:237]     Train net output #1: loss = 0.748515 (* 1 = 0.748515 loss)
I1211 15:12:54.709128 16720 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1211 15:13:00.934365 16720 solver.cpp:218] Iteration 57100 (16.0649 iter/s, 6.22475s/100 iters), loss = 0.737019
I1211 15:13:00.934365 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:13:00.934365 16720 solver.cpp:237]     Train net output #1: loss = 0.737019 (* 1 = 0.737019 loss)
I1211 15:13:00.934365 16720 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1211 15:13:07.165998 16720 solver.cpp:218] Iteration 57200 (16.0479 iter/s, 6.23136s/100 iters), loss = 0.815969
I1211 15:13:07.165998 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:13:07.165998 16720 solver.cpp:237]     Train net output #1: loss = 0.815969 (* 1 = 0.815969 loss)
I1211 15:13:07.165998 16720 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1211 15:13:13.382521 16720 solver.cpp:218] Iteration 57300 (16.0866 iter/s, 6.21634s/100 iters), loss = 0.862686
I1211 15:13:13.382521 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:13:13.382521 16720 solver.cpp:237]     Train net output #1: loss = 0.862686 (* 1 = 0.862686 loss)
I1211 15:13:13.382521 16720 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1211 15:13:19.587143 16720 solver.cpp:218] Iteration 57400 (16.1191 iter/s, 6.20383s/100 iters), loss = 0.947746
I1211 15:13:19.587143 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 15:13:19.587143 16720 solver.cpp:237]     Train net output #1: loss = 0.947746 (* 1 = 0.947746 loss)
I1211 15:13:19.587143 16720 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1211 15:13:25.469637  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:13:25.715656 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_57500.caffemodel
I1211 15:13:25.730656 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_57500.solverstate
I1211 15:13:25.735657 16720 solver.cpp:330] Iteration 57500, Testing net (#0)
I1211 15:13:25.735657 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:13:27.082789 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:13:27.136798 16720 solver.cpp:397]     Test net output #0: accuracy = 0.624
I1211 15:13:27.136798 16720 solver.cpp:397]     Test net output #1: loss = 1.34927 (* 1 = 1.34927 loss)
I1211 15:13:27.195801 16720 solver.cpp:218] Iteration 57500 (13.1433 iter/s, 7.60843s/100 iters), loss = 0.723855
I1211 15:13:27.195801 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:13:27.195801 16720 solver.cpp:237]     Train net output #1: loss = 0.723855 (* 1 = 0.723855 loss)
I1211 15:13:27.195801 16720 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1211 15:13:33.376181 16720 solver.cpp:218] Iteration 57600 (16.1835 iter/s, 6.17914s/100 iters), loss = 1.00083
I1211 15:13:33.376181 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 15:13:33.376181 16720 solver.cpp:237]     Train net output #1: loss = 1.00083 (* 1 = 1.00083 loss)
I1211 15:13:33.376181 16720 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1211 15:13:39.556843 16720 solver.cpp:218] Iteration 57700 (16.181 iter/s, 6.1801s/100 iters), loss = 0.750335
I1211 15:13:39.556843 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:13:39.556843 16720 solver.cpp:237]     Train net output #1: loss = 0.750335 (* 1 = 0.750335 loss)
I1211 15:13:39.556843 16720 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1211 15:13:45.740748 16720 solver.cpp:218] Iteration 57800 (16.1722 iter/s, 6.18346s/100 iters), loss = 0.77444
I1211 15:13:45.740748 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:13:45.740748 16720 solver.cpp:237]     Train net output #1: loss = 0.77444 (* 1 = 0.77444 loss)
I1211 15:13:45.740748 16720 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1211 15:13:51.913770 16720 solver.cpp:218] Iteration 57900 (16.2003 iter/s, 6.17274s/100 iters), loss = 0.877081
I1211 15:13:51.913770 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:13:51.913770 16720 solver.cpp:237]     Train net output #1: loss = 0.877081 (* 1 = 0.877081 loss)
I1211 15:13:51.913770 16720 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1211 15:13:57.799552  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:13:58.041570 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_58000.caffemodel
I1211 15:13:58.056569 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_58000.solverstate
I1211 15:13:58.061571 16720 solver.cpp:330] Iteration 58000, Testing net (#0)
I1211 15:13:58.061571 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:13:59.397835 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:13:59.451833 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6145
I1211 15:13:59.451833 16720 solver.cpp:397]     Test net output #1: loss = 1.40273 (* 1 = 1.40273 loss)
I1211 15:13:59.512845 16720 solver.cpp:218] Iteration 58000 (13.1607 iter/s, 7.5984s/100 iters), loss = 0.773532
I1211 15:13:59.512845 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:13:59.512845 16720 solver.cpp:237]     Train net output #1: loss = 0.773532 (* 1 = 0.773532 loss)
I1211 15:13:59.512845 16720 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1211 15:14:05.733058 16720 solver.cpp:218] Iteration 58100 (16.0783 iter/s, 6.21957s/100 iters), loss = 0.785067
I1211 15:14:05.733058 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:14:05.733058 16720 solver.cpp:237]     Train net output #1: loss = 0.785067 (* 1 = 0.785067 loss)
I1211 15:14:05.733058 16720 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1211 15:14:11.991330 16720 solver.cpp:218] Iteration 58200 (15.9778 iter/s, 6.25868s/100 iters), loss = 0.765491
I1211 15:14:11.992329 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:14:11.992329 16720 solver.cpp:237]     Train net output #1: loss = 0.765491 (* 1 = 0.765491 loss)
I1211 15:14:11.992329 16720 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1211 15:14:18.156788 16720 solver.cpp:218] Iteration 58300 (16.223 iter/s, 6.16408s/100 iters), loss = 0.782341
I1211 15:14:18.156788 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:14:18.156788 16720 solver.cpp:237]     Train net output #1: loss = 0.782341 (* 1 = 0.782341 loss)
I1211 15:14:18.156788 16720 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1211 15:14:24.411047 16720 solver.cpp:218] Iteration 58400 (15.99 iter/s, 6.25389s/100 iters), loss = 0.810285
I1211 15:14:24.411047 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:14:24.411047 16720 solver.cpp:237]     Train net output #1: loss = 0.810285 (* 1 = 0.810285 loss)
I1211 15:14:24.411047 16720 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1211 15:14:30.304702  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:14:30.545568 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_58500.caffemodel
I1211 15:14:30.562577 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_58500.solverstate
I1211 15:14:30.567572 16720 solver.cpp:330] Iteration 58500, Testing net (#0)
I1211 15:14:30.567572 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:14:31.924288 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:14:31.978292 16720 solver.cpp:397]     Test net output #0: accuracy = 0.634
I1211 15:14:31.978793 16720 solver.cpp:397]     Test net output #1: loss = 1.30661 (* 1 = 1.30661 loss)
I1211 15:14:32.039309 16720 solver.cpp:218] Iteration 58500 (13.1096 iter/s, 7.62801s/100 iters), loss = 0.867127
I1211 15:14:32.039309 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:14:32.039309 16720 solver.cpp:237]     Train net output #1: loss = 0.867127 (* 1 = 0.867127 loss)
I1211 15:14:32.039309 16720 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1211 15:14:38.278342 16720 solver.cpp:218] Iteration 58600 (16.0311 iter/s, 6.23789s/100 iters), loss = 0.838839
I1211 15:14:38.278342 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:14:38.278342 16720 solver.cpp:237]     Train net output #1: loss = 0.838839 (* 1 = 0.838839 loss)
I1211 15:14:38.278342 16720 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1211 15:14:44.492981 16720 solver.cpp:218] Iteration 58700 (16.092 iter/s, 6.21426s/100 iters), loss = 0.779435
I1211 15:14:44.492981 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:14:44.492981 16720 solver.cpp:237]     Train net output #1: loss = 0.779435 (* 1 = 0.779435 loss)
I1211 15:14:44.492981 16720 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1211 15:14:50.707481 16720 solver.cpp:218] Iteration 58800 (16.0909 iter/s, 6.21468s/100 iters), loss = 0.801493
I1211 15:14:50.707481 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:14:50.707481 16720 solver.cpp:237]     Train net output #1: loss = 0.801493 (* 1 = 0.801493 loss)
I1211 15:14:50.707481 16720 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1211 15:14:56.943270 16720 solver.cpp:218] Iteration 58900 (16.0389 iter/s, 6.23484s/100 iters), loss = 0.829562
I1211 15:14:56.943270 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:14:56.943270 16720 solver.cpp:237]     Train net output #1: loss = 0.829562 (* 1 = 0.829562 loss)
I1211 15:14:56.943270 16720 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1211 15:15:02.819567  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:15:03.061542 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_59000.caffemodel
I1211 15:15:03.077047 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_59000.solverstate
I1211 15:15:03.081537 16720 solver.cpp:330] Iteration 59000, Testing net (#0)
I1211 15:15:03.081537 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:15:04.415763 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:15:04.468794 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6174
I1211 15:15:04.468794 16720 solver.cpp:397]     Test net output #1: loss = 1.38302 (* 1 = 1.38302 loss)
I1211 15:15:04.527331 16720 solver.cpp:218] Iteration 59000 (13.1865 iter/s, 7.58349s/100 iters), loss = 0.717412
I1211 15:15:04.527331 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:15:04.527331 16720 solver.cpp:237]     Train net output #1: loss = 0.717412 (* 1 = 0.717412 loss)
I1211 15:15:04.527331 16720 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1211 15:15:10.688937 16720 solver.cpp:218] Iteration 59100 (16.2309 iter/s, 6.1611s/100 iters), loss = 0.824824
I1211 15:15:10.688937 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:15:10.688937 16720 solver.cpp:237]     Train net output #1: loss = 0.824824 (* 1 = 0.824824 loss)
I1211 15:15:10.688937 16720 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1211 15:15:16.855334 16720 solver.cpp:218] Iteration 59200 (16.2183 iter/s, 6.16587s/100 iters), loss = 0.68069
I1211 15:15:16.855334 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:15:16.855334 16720 solver.cpp:237]     Train net output #1: loss = 0.68069 (* 1 = 0.68069 loss)
I1211 15:15:16.855334 16720 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1211 15:15:23.036840 16720 solver.cpp:218] Iteration 59300 (16.1769 iter/s, 6.18165s/100 iters), loss = 0.711414
I1211 15:15:23.036840 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:15:23.036840 16720 solver.cpp:237]     Train net output #1: loss = 0.711414 (* 1 = 0.711414 loss)
I1211 15:15:23.036840 16720 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1211 15:15:29.215677 16720 solver.cpp:218] Iteration 59400 (16.1873 iter/s, 6.17768s/100 iters), loss = 0.908571
I1211 15:15:29.215677 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:15:29.215677 16720 solver.cpp:237]     Train net output #1: loss = 0.908571 (* 1 = 0.908571 loss)
I1211 15:15:29.215677 16720 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1211 15:15:35.070505  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:15:35.312525 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_59500.caffemodel
I1211 15:15:35.326526 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_59500.solverstate
I1211 15:15:35.332526 16720 solver.cpp:330] Iteration 59500, Testing net (#0)
I1211 15:15:35.332526 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:15:36.667613 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:15:36.719621 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6167
I1211 15:15:36.720621 16720 solver.cpp:397]     Test net output #1: loss = 1.38843 (* 1 = 1.38843 loss)
I1211 15:15:36.779620 16720 solver.cpp:218] Iteration 59500 (13.2214 iter/s, 7.56351s/100 iters), loss = 0.62599
I1211 15:15:36.779620 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:15:36.779620 16720 solver.cpp:237]     Train net output #1: loss = 0.62599 (* 1 = 0.62599 loss)
I1211 15:15:36.779620 16720 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1211 15:15:42.948076 16720 solver.cpp:218] Iteration 59600 (16.2123 iter/s, 6.16817s/100 iters), loss = 0.743322
I1211 15:15:42.948076 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:15:42.948076 16720 solver.cpp:237]     Train net output #1: loss = 0.743322 (* 1 = 0.743322 loss)
I1211 15:15:42.948076 16720 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1211 15:15:49.119604 16720 solver.cpp:218] Iteration 59700 (16.2049 iter/s, 6.17096s/100 iters), loss = 0.771011
I1211 15:15:49.119604 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:15:49.119604 16720 solver.cpp:237]     Train net output #1: loss = 0.771011 (* 1 = 0.771011 loss)
I1211 15:15:49.119604 16720 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1211 15:15:55.284303 16720 solver.cpp:218] Iteration 59800 (16.2204 iter/s, 6.16508s/100 iters), loss = 0.851394
I1211 15:15:55.284303 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:15:55.284303 16720 solver.cpp:237]     Train net output #1: loss = 0.851394 (* 1 = 0.851394 loss)
I1211 15:15:55.284303 16720 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1211 15:16:01.460410 16720 solver.cpp:218] Iteration 59900 (16.1927 iter/s, 6.17563s/100 iters), loss = 0.847842
I1211 15:16:01.461392 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:16:01.461392 16720 solver.cpp:237]     Train net output #1: loss = 0.847842 (* 1 = 0.847842 loss)
I1211 15:16:01.461392 16720 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1211 15:16:07.323575  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:16:07.567392 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_60000.caffemodel
I1211 15:16:07.583380 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_60000.solverstate
I1211 15:16:07.587378 16720 solver.cpp:330] Iteration 60000, Testing net (#0)
I1211 15:16:07.587378 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:16:08.925120 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:16:08.978138 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6265
I1211 15:16:08.978138 16720 solver.cpp:397]     Test net output #1: loss = 1.36926 (* 1 = 1.36926 loss)
I1211 15:16:09.037154 16720 solver.cpp:218] Iteration 60000 (13.1995 iter/s, 7.57604s/100 iters), loss = 0.649395
I1211 15:16:09.037154 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:16:09.037154 16720 solver.cpp:237]     Train net output #1: loss = 0.649395 (* 1 = 0.649395 loss)
I1211 15:16:09.037154 16720 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1211 15:16:15.192502 16720 solver.cpp:218] Iteration 60100 (16.2488 iter/s, 6.15431s/100 iters), loss = 0.846098
I1211 15:16:15.192502 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:16:15.192502 16720 solver.cpp:237]     Train net output #1: loss = 0.846098 (* 1 = 0.846098 loss)
I1211 15:16:15.192502 16720 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1211 15:16:21.375954 16720 solver.cpp:218] Iteration 60200 (16.1722 iter/s, 6.18345s/100 iters), loss = 0.703597
I1211 15:16:21.375954 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:16:21.375954 16720 solver.cpp:237]     Train net output #1: loss = 0.703597 (* 1 = 0.703597 loss)
I1211 15:16:21.375954 16720 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1211 15:16:27.562443 16720 solver.cpp:218] Iteration 60300 (16.1667 iter/s, 6.18554s/100 iters), loss = 0.73114
I1211 15:16:27.562443 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:16:27.562443 16720 solver.cpp:237]     Train net output #1: loss = 0.73114 (* 1 = 0.73114 loss)
I1211 15:16:27.562443 16720 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1211 15:16:33.725885 16720 solver.cpp:218] Iteration 60400 (16.2259 iter/s, 6.16299s/100 iters), loss = 0.793203
I1211 15:16:33.725885 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:16:33.725885 16720 solver.cpp:237]     Train net output #1: loss = 0.793203 (* 1 = 0.793203 loss)
I1211 15:16:33.725885 16720 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1211 15:16:39.596451  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:16:39.839490 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_60500.caffemodel
I1211 15:16:39.854490 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_60500.solverstate
I1211 15:16:39.859489 16720 solver.cpp:330] Iteration 60500, Testing net (#0)
I1211 15:16:39.859489 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:16:41.195740 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:16:41.247748 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6111
I1211 15:16:41.247748 16720 solver.cpp:397]     Test net output #1: loss = 1.45239 (* 1 = 1.45239 loss)
I1211 15:16:41.307749 16720 solver.cpp:218] Iteration 60500 (13.1903 iter/s, 7.58133s/100 iters), loss = 0.711265
I1211 15:16:41.307749 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:16:41.307749 16720 solver.cpp:237]     Train net output #1: loss = 0.711265 (* 1 = 0.711265 loss)
I1211 15:16:41.307749 16720 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1211 15:16:47.487172 16720 solver.cpp:218] Iteration 60600 (16.1836 iter/s, 6.17909s/100 iters), loss = 0.798639
I1211 15:16:47.487172 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:16:47.487172 16720 solver.cpp:237]     Train net output #1: loss = 0.798639 (* 1 = 0.798639 loss)
I1211 15:16:47.487172 16720 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1211 15:16:53.655596 16720 solver.cpp:218] Iteration 60700 (16.2127 iter/s, 6.168s/100 iters), loss = 0.70145
I1211 15:16:53.655596 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:16:53.655596 16720 solver.cpp:237]     Train net output #1: loss = 0.70145 (* 1 = 0.70145 loss)
I1211 15:16:53.655596 16720 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1211 15:16:59.822041 16720 solver.cpp:218] Iteration 60800 (16.2176 iter/s, 6.16615s/100 iters), loss = 0.740385
I1211 15:16:59.822541 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:16:59.822541 16720 solver.cpp:237]     Train net output #1: loss = 0.740385 (* 1 = 0.740385 loss)
I1211 15:16:59.822541 16720 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1211 15:17:05.982506 16720 solver.cpp:218] Iteration 60900 (16.2345 iter/s, 6.15971s/100 iters), loss = 0.864097
I1211 15:17:05.982506 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:17:05.982506 16720 solver.cpp:237]     Train net output #1: loss = 0.864097 (* 1 = 0.864097 loss)
I1211 15:17:05.982506 16720 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1211 15:17:11.928992  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:17:12.171996 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_61000.caffemodel
I1211 15:17:12.188997 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_61000.solverstate
I1211 15:17:12.192996 16720 solver.cpp:330] Iteration 61000, Testing net (#0)
I1211 15:17:12.192996 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:17:13.528139 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:17:13.581137 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6065
I1211 15:17:13.581137 16720 solver.cpp:397]     Test net output #1: loss = 1.45306 (* 1 = 1.45306 loss)
I1211 15:17:13.639143 16720 solver.cpp:218] Iteration 61000 (13.0602 iter/s, 7.65684s/100 iters), loss = 0.840123
I1211 15:17:13.639143 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:17:13.640143 16720 solver.cpp:237]     Train net output #1: loss = 0.840123 (* 1 = 0.840123 loss)
I1211 15:17:13.640143 16720 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1211 15:17:19.926754 16720 solver.cpp:218] Iteration 61100 (15.9063 iter/s, 6.28681s/100 iters), loss = 0.853952
I1211 15:17:19.926754 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 15:17:19.926754 16720 solver.cpp:237]     Train net output #1: loss = 0.853952 (* 1 = 0.853952 loss)
I1211 15:17:19.926754 16720 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1211 15:17:26.210947 16720 solver.cpp:218] Iteration 61200 (15.9154 iter/s, 6.28322s/100 iters), loss = 0.799843
I1211 15:17:26.210947 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:17:26.210947 16720 solver.cpp:237]     Train net output #1: loss = 0.799843 (* 1 = 0.799843 loss)
I1211 15:17:26.210947 16720 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1211 15:17:32.562741 16720 solver.cpp:218] Iteration 61300 (15.7448 iter/s, 6.35132s/100 iters), loss = 0.810456
I1211 15:17:32.562741 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:17:32.562741 16720 solver.cpp:237]     Train net output #1: loss = 0.810456 (* 1 = 0.810456 loss)
I1211 15:17:32.562741 16720 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1211 15:17:38.829360 16720 solver.cpp:218] Iteration 61400 (15.9587 iter/s, 6.26616s/100 iters), loss = 0.871764
I1211 15:17:38.829360 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:17:38.829360 16720 solver.cpp:237]     Train net output #1: loss = 0.871764 (* 1 = 0.871764 loss)
I1211 15:17:38.829360 16720 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1211 15:17:44.799449  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:17:45.047448 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_61500.caffemodel
I1211 15:17:45.063449 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_61500.solverstate
I1211 15:17:45.067950 16720 solver.cpp:330] Iteration 61500, Testing net (#0)
I1211 15:17:45.067950 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:17:46.439450 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:17:46.493449 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6062
I1211 15:17:46.493449 16720 solver.cpp:397]     Test net output #1: loss = 1.45762 (* 1 = 1.45762 loss)
I1211 15:17:46.553948 16720 solver.cpp:218] Iteration 61500 (12.9464 iter/s, 7.72415s/100 iters), loss = 0.655459
I1211 15:17:46.554448 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:17:46.554448 16720 solver.cpp:237]     Train net output #1: loss = 0.655459 (* 1 = 0.655459 loss)
I1211 15:17:46.554448 16720 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1211 15:17:52.807514 16720 solver.cpp:218] Iteration 61600 (15.991 iter/s, 6.25353s/100 iters), loss = 0.78361
I1211 15:17:52.807514 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:17:52.807514 16720 solver.cpp:237]     Train net output #1: loss = 0.78361 (* 1 = 0.78361 loss)
I1211 15:17:52.807514 16720 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1211 15:17:58.959414 16720 solver.cpp:218] Iteration 61700 (16.2565 iter/s, 6.1514s/100 iters), loss = 0.726316
I1211 15:17:58.959414 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:17:58.959414 16720 solver.cpp:237]     Train net output #1: loss = 0.726316 (* 1 = 0.726316 loss)
I1211 15:17:58.959414 16720 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1211 15:18:05.113296 16720 solver.cpp:218] Iteration 61800 (16.2527 iter/s, 6.15282s/100 iters), loss = 0.71664
I1211 15:18:05.113296 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:18:05.113296 16720 solver.cpp:237]     Train net output #1: loss = 0.71664 (* 1 = 0.71664 loss)
I1211 15:18:05.113296 16720 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1211 15:18:11.271200 16720 solver.cpp:218] Iteration 61900 (16.2384 iter/s, 6.15824s/100 iters), loss = 0.83358
I1211 15:18:11.271200 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:18:11.271200 16720 solver.cpp:237]     Train net output #1: loss = 0.83358 (* 1 = 0.83358 loss)
I1211 15:18:11.271200 16720 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1211 15:18:17.128705  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:18:17.369720 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_62000.caffemodel
I1211 15:18:17.384721 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_62000.solverstate
I1211 15:18:17.389739 16720 solver.cpp:330] Iteration 62000, Testing net (#0)
I1211 15:18:17.389739 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:18:18.727843 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:18:18.779851 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6147
I1211 15:18:18.779851 16720 solver.cpp:397]     Test net output #1: loss = 1.41976 (* 1 = 1.41976 loss)
I1211 15:18:18.838850 16720 solver.cpp:218] Iteration 62000 (13.2163 iter/s, 7.56641s/100 iters), loss = 0.738528
I1211 15:18:18.838850 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:18:18.838850 16720 solver.cpp:237]     Train net output #1: loss = 0.738528 (* 1 = 0.738528 loss)
I1211 15:18:18.838850 16720 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1211 15:18:24.988373 16720 solver.cpp:218] Iteration 62100 (16.2621 iter/s, 6.14928s/100 iters), loss = 0.691893
I1211 15:18:24.988373 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:18:24.988373 16720 solver.cpp:237]     Train net output #1: loss = 0.691893 (* 1 = 0.691893 loss)
I1211 15:18:24.988373 16720 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1211 15:18:31.150285 16720 solver.cpp:218] Iteration 62200 (16.2306 iter/s, 6.1612s/100 iters), loss = 0.670145
I1211 15:18:31.150285 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:18:31.150285 16720 solver.cpp:237]     Train net output #1: loss = 0.670145 (* 1 = 0.670145 loss)
I1211 15:18:31.150285 16720 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1211 15:18:37.304240 16720 solver.cpp:218] Iteration 62300 (16.249 iter/s, 6.15423s/100 iters), loss = 0.858888
I1211 15:18:37.304240 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:18:37.304240 16720 solver.cpp:237]     Train net output #1: loss = 0.858888 (* 1 = 0.858888 loss)
I1211 15:18:37.304240 16720 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1211 15:18:43.452174 16720 solver.cpp:218] Iteration 62400 (16.268 iter/s, 6.14706s/100 iters), loss = 0.88037
I1211 15:18:43.452174 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:18:43.452174 16720 solver.cpp:237]     Train net output #1: loss = 0.88037 (* 1 = 0.88037 loss)
I1211 15:18:43.452174 16720 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1211 15:18:49.301079  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:18:49.543090 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_62500.caffemodel
I1211 15:18:49.557091 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_62500.solverstate
I1211 15:18:49.562095 16720 solver.cpp:330] Iteration 62500, Testing net (#0)
I1211 15:18:49.562095 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:18:50.898200 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:18:50.951200 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5923
I1211 15:18:50.951200 16720 solver.cpp:397]     Test net output #1: loss = 1.53059 (* 1 = 1.53059 loss)
I1211 15:18:51.009202 16720 solver.cpp:218] Iteration 62500 (13.2328 iter/s, 7.55701s/100 iters), loss = 0.678475
I1211 15:18:51.009202 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:18:51.009202 16720 solver.cpp:237]     Train net output #1: loss = 0.678475 (* 1 = 0.678475 loss)
I1211 15:18:51.009202 16720 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1211 15:18:57.167708 16720 solver.cpp:218] Iteration 62600 (16.2402 iter/s, 6.15758s/100 iters), loss = 0.751288
I1211 15:18:57.167708 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:18:57.167708 16720 solver.cpp:237]     Train net output #1: loss = 0.751288 (* 1 = 0.751288 loss)
I1211 15:18:57.167708 16720 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1211 15:19:03.331215 16720 solver.cpp:218] Iteration 62700 (16.2258 iter/s, 6.16303s/100 iters), loss = 0.757572
I1211 15:19:03.331215 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:19:03.331215 16720 solver.cpp:237]     Train net output #1: loss = 0.757572 (* 1 = 0.757572 loss)
I1211 15:19:03.331215 16720 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1211 15:19:09.483654 16720 solver.cpp:218] Iteration 62800 (16.2547 iter/s, 6.15207s/100 iters), loss = 0.756014
I1211 15:19:09.483654 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:19:09.483654 16720 solver.cpp:237]     Train net output #1: loss = 0.756014 (* 1 = 0.756014 loss)
I1211 15:19:09.483654 16720 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1211 15:19:15.634248 16720 solver.cpp:218] Iteration 62900 (16.2599 iter/s, 6.1501s/100 iters), loss = 0.780354
I1211 15:19:15.634248 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:19:15.634248 16720 solver.cpp:237]     Train net output #1: loss = 0.780354 (* 1 = 0.780354 loss)
I1211 15:19:15.634248 16720 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1211 15:19:21.476775  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:19:21.722795 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_63000.caffemodel
I1211 15:19:21.739795 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_63000.solverstate
I1211 15:19:21.744299 16720 solver.cpp:330] Iteration 63000, Testing net (#0)
I1211 15:19:21.744299 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:19:23.080899 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:19:23.132899 16720 solver.cpp:397]     Test net output #0: accuracy = 0.578
I1211 15:19:23.132899 16720 solver.cpp:397]     Test net output #1: loss = 1.57439 (* 1 = 1.57439 loss)
I1211 15:19:23.190904 16720 solver.cpp:218] Iteration 63000 (13.2332 iter/s, 7.55677s/100 iters), loss = 0.716212
I1211 15:19:23.190904 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:19:23.190904 16720 solver.cpp:237]     Train net output #1: loss = 0.716212 (* 1 = 0.716212 loss)
I1211 15:19:23.190904 16720 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1211 15:19:29.335306 16720 solver.cpp:218] Iteration 63100 (16.2755 iter/s, 6.14419s/100 iters), loss = 0.801162
I1211 15:19:29.335306 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:19:29.335306 16720 solver.cpp:237]     Train net output #1: loss = 0.801162 (* 1 = 0.801162 loss)
I1211 15:19:29.336308 16720 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1211 15:19:35.481730 16720 solver.cpp:218] Iteration 63200 (16.2723 iter/s, 6.14543s/100 iters), loss = 0.733172
I1211 15:19:35.481730 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:19:35.481730 16720 solver.cpp:237]     Train net output #1: loss = 0.733172 (* 1 = 0.733172 loss)
I1211 15:19:35.481730 16720 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1211 15:19:41.636117 16720 solver.cpp:218] Iteration 63300 (16.2489 iter/s, 6.15424s/100 iters), loss = 0.724492
I1211 15:19:41.636117 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:19:41.636117 16720 solver.cpp:237]     Train net output #1: loss = 0.724492 (* 1 = 0.724492 loss)
I1211 15:19:41.636117 16720 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1211 15:19:47.794566 16720 solver.cpp:218] Iteration 63400 (16.2389 iter/s, 6.15804s/100 iters), loss = 0.81754
I1211 15:19:47.794566 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:19:47.794566 16720 solver.cpp:237]     Train net output #1: loss = 0.81754 (* 1 = 0.81754 loss)
I1211 15:19:47.794566 16720 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1211 15:19:53.647047  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:19:53.889065 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_63500.caffemodel
I1211 15:19:53.905066 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_63500.solverstate
I1211 15:19:53.910066 16720 solver.cpp:330] Iteration 63500, Testing net (#0)
I1211 15:19:53.910066 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:19:55.245159 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:19:55.297163 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5877
I1211 15:19:55.297163 16720 solver.cpp:397]     Test net output #1: loss = 1.52979 (* 1 = 1.52979 loss)
I1211 15:19:55.356165 16720 solver.cpp:218] Iteration 63500 (13.2263 iter/s, 7.56067s/100 iters), loss = 0.672074
I1211 15:19:55.356165 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:19:55.356165 16720 solver.cpp:237]     Train net output #1: loss = 0.672074 (* 1 = 0.672074 loss)
I1211 15:19:55.356165 16720 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1211 15:20:01.540283 16720 solver.cpp:218] Iteration 63600 (16.1703 iter/s, 6.18418s/100 iters), loss = 0.770802
I1211 15:20:01.540283 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:20:01.540283 16720 solver.cpp:237]     Train net output #1: loss = 0.770802 (* 1 = 0.770802 loss)
I1211 15:20:01.540283 16720 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1211 15:20:07.729357 16720 solver.cpp:218] Iteration 63700 (16.1591 iter/s, 6.18845s/100 iters), loss = 0.712798
I1211 15:20:07.729357 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:20:07.729357 16720 solver.cpp:237]     Train net output #1: loss = 0.712798 (* 1 = 0.712798 loss)
I1211 15:20:07.729357 16720 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1211 15:20:13.888826 16720 solver.cpp:218] Iteration 63800 (16.2369 iter/s, 6.15882s/100 iters), loss = 0.681023
I1211 15:20:13.888826 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:20:13.888826 16720 solver.cpp:237]     Train net output #1: loss = 0.681023 (* 1 = 0.681023 loss)
I1211 15:20:13.888826 16720 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1211 15:20:20.048825 16720 solver.cpp:218] Iteration 63900 (16.2356 iter/s, 6.1593s/100 iters), loss = 0.817789
I1211 15:20:20.048825 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:20:20.048825 16720 solver.cpp:237]     Train net output #1: loss = 0.817789 (* 1 = 0.817789 loss)
I1211 15:20:20.048825 16720 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1211 15:20:25.895798  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:20:26.138808 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_64000.caffemodel
I1211 15:20:26.154311 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_64000.solverstate
I1211 15:20:26.158812 16720 solver.cpp:330] Iteration 64000, Testing net (#0)
I1211 15:20:26.158812 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:20:27.493904 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:20:27.545904 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5979
I1211 15:20:27.545904 16720 solver.cpp:397]     Test net output #1: loss = 1.49419 (* 1 = 1.49419 loss)
I1211 15:20:27.604912 16720 solver.cpp:218] Iteration 64000 (13.2343 iter/s, 7.55612s/100 iters), loss = 0.674195
I1211 15:20:27.604912 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:20:27.604912 16720 solver.cpp:237]     Train net output #1: loss = 0.674195 (* 1 = 0.674195 loss)
I1211 15:20:27.604912 16720 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1211 15:20:33.768398 16720 solver.cpp:218] Iteration 64100 (16.2254 iter/s, 6.16317s/100 iters), loss = 0.809161
I1211 15:20:33.768398 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:20:33.768398 16720 solver.cpp:237]     Train net output #1: loss = 0.809161 (* 1 = 0.809161 loss)
I1211 15:20:33.768398 16720 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1211 15:20:39.919486 16720 solver.cpp:218] Iteration 64200 (16.2593 iter/s, 6.15031s/100 iters), loss = 0.745331
I1211 15:20:39.919486 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:20:39.919486 16720 solver.cpp:237]     Train net output #1: loss = 0.745331 (* 1 = 0.745331 loss)
I1211 15:20:39.919486 16720 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1211 15:20:46.075358 16720 solver.cpp:218] Iteration 64300 (16.2466 iter/s, 6.15512s/100 iters), loss = 0.864182
I1211 15:20:46.075358 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:20:46.075358 16720 solver.cpp:237]     Train net output #1: loss = 0.864182 (* 1 = 0.864182 loss)
I1211 15:20:46.075358 16720 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1211 15:20:52.228765 16720 solver.cpp:218] Iteration 64400 (16.2512 iter/s, 6.15338s/100 iters), loss = 0.920467
I1211 15:20:52.228765 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:20:52.228765 16720 solver.cpp:237]     Train net output #1: loss = 0.920467 (* 1 = 0.920467 loss)
I1211 15:20:52.228765 16720 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1211 15:20:58.086172  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:20:58.331184 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_64500.caffemodel
I1211 15:20:58.346185 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_64500.solverstate
I1211 15:20:58.351184 16720 solver.cpp:330] Iteration 64500, Testing net (#0)
I1211 15:20:58.351184 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:20:59.685283 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:20:59.738283 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5794
I1211 15:20:59.738283 16720 solver.cpp:397]     Test net output #1: loss = 1.66884 (* 1 = 1.66884 loss)
I1211 15:20:59.796294 16720 solver.cpp:218] Iteration 64500 (13.2153 iter/s, 7.56698s/100 iters), loss = 0.669093
I1211 15:20:59.796294 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:20:59.796294 16720 solver.cpp:237]     Train net output #1: loss = 0.669093 (* 1 = 0.669093 loss)
I1211 15:20:59.796294 16720 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1211 15:21:05.961848 16720 solver.cpp:218] Iteration 64600 (16.2212 iter/s, 6.16476s/100 iters), loss = 0.713026
I1211 15:21:05.961848 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:21:05.961848 16720 solver.cpp:237]     Train net output #1: loss = 0.713026 (* 1 = 0.713026 loss)
I1211 15:21:05.961848 16720 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1211 15:21:12.125335 16720 solver.cpp:218] Iteration 64700 (16.2241 iter/s, 6.16365s/100 iters), loss = 0.806579
I1211 15:21:12.125335 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:21:12.125335 16720 solver.cpp:237]     Train net output #1: loss = 0.806579 (* 1 = 0.806579 loss)
I1211 15:21:12.125335 16720 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1211 15:21:18.292208 16720 solver.cpp:218] Iteration 64800 (16.2184 iter/s, 6.16584s/100 iters), loss = 0.784656
I1211 15:21:18.292208 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:21:18.292208 16720 solver.cpp:237]     Train net output #1: loss = 0.784656 (* 1 = 0.784656 loss)
I1211 15:21:18.292208 16720 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1211 15:21:24.451148 16720 solver.cpp:218] Iteration 64900 (16.2366 iter/s, 6.15891s/100 iters), loss = 0.945263
I1211 15:21:24.451148 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:21:24.451148 16720 solver.cpp:237]     Train net output #1: loss = 0.945263 (* 1 = 0.945263 loss)
I1211 15:21:24.451148 16720 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1211 15:21:30.306604  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:21:30.550617 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_65000.caffemodel
I1211 15:21:30.565619 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_65000.solverstate
I1211 15:21:30.570621 16720 solver.cpp:330] Iteration 65000, Testing net (#0)
I1211 15:21:30.570621 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:21:31.903728 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:21:31.956727 16720 solver.cpp:397]     Test net output #0: accuracy = 0.597
I1211 15:21:31.956727 16720 solver.cpp:397]     Test net output #1: loss = 1.5261 (* 1 = 1.5261 loss)
I1211 15:21:32.014734 16720 solver.cpp:218] Iteration 65000 (13.2217 iter/s, 7.56334s/100 iters), loss = 0.704198
I1211 15:21:32.014734 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:21:32.014734 16720 solver.cpp:237]     Train net output #1: loss = 0.704198 (* 1 = 0.704198 loss)
I1211 15:21:32.014734 16720 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1211 15:21:38.167239 16720 solver.cpp:218] Iteration 65100 (16.2556 iter/s, 6.15173s/100 iters), loss = 0.86363
I1211 15:21:38.167239 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:21:38.167239 16720 solver.cpp:237]     Train net output #1: loss = 0.86363 (* 1 = 0.86363 loss)
I1211 15:21:38.167239 16720 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1211 15:21:44.315814 16720 solver.cpp:218] Iteration 65200 (16.2652 iter/s, 6.14809s/100 iters), loss = 0.679035
I1211 15:21:44.315814 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:21:44.315814 16720 solver.cpp:237]     Train net output #1: loss = 0.679035 (* 1 = 0.679035 loss)
I1211 15:21:44.315814 16720 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1211 15:21:50.477325 16720 solver.cpp:218] Iteration 65300 (16.2311 iter/s, 6.16101s/100 iters), loss = 0.732767
I1211 15:21:50.477325 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:21:50.477325 16720 solver.cpp:237]     Train net output #1: loss = 0.732767 (* 1 = 0.732767 loss)
I1211 15:21:50.477325 16720 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1211 15:21:56.636793 16720 solver.cpp:218] Iteration 65400 (16.2352 iter/s, 6.15947s/100 iters), loss = 0.803086
I1211 15:21:56.636793 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:21:56.636793 16720 solver.cpp:237]     Train net output #1: loss = 0.803086 (* 1 = 0.803086 loss)
I1211 15:21:56.636793 16720 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1211 15:22:02.494715  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:22:02.739243 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_65500.caffemodel
I1211 15:22:02.754242 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_65500.solverstate
I1211 15:22:02.758242 16720 solver.cpp:330] Iteration 65500, Testing net (#0)
I1211 15:22:02.758242 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:22:04.092859 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:22:04.145359 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5935
I1211 15:22:04.145359 16720 solver.cpp:397]     Test net output #1: loss = 1.53072 (* 1 = 1.53072 loss)
I1211 15:22:04.205391 16720 solver.cpp:218] Iteration 65500 (13.2138 iter/s, 7.56784s/100 iters), loss = 0.751841
I1211 15:22:04.205391 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:22:04.205391 16720 solver.cpp:237]     Train net output #1: loss = 0.751841 (* 1 = 0.751841 loss)
I1211 15:22:04.205391 16720 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1211 15:22:10.374866 16720 solver.cpp:218] Iteration 65600 (16.209 iter/s, 6.1694s/100 iters), loss = 0.799652
I1211 15:22:10.374866 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:22:10.374866 16720 solver.cpp:237]     Train net output #1: loss = 0.799652 (* 1 = 0.799652 loss)
I1211 15:22:10.374866 16720 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1211 15:22:16.533329 16720 solver.cpp:218] Iteration 65700 (16.2387 iter/s, 6.15812s/100 iters), loss = 0.644819
I1211 15:22:16.533329 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:22:16.533329 16720 solver.cpp:237]     Train net output #1: loss = 0.644819 (* 1 = 0.644819 loss)
I1211 15:22:16.533329 16720 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1211 15:22:22.692690 16720 solver.cpp:218] Iteration 65800 (16.2381 iter/s, 6.15836s/100 iters), loss = 0.69934
I1211 15:22:22.692690 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:22:22.692690 16720 solver.cpp:237]     Train net output #1: loss = 0.69934 (* 1 = 0.69934 loss)
I1211 15:22:22.692690 16720 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1211 15:22:28.840092 16720 solver.cpp:218] Iteration 65900 (16.2684 iter/s, 6.14688s/100 iters), loss = 0.863252
I1211 15:22:28.840092 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:22:28.840092 16720 solver.cpp:237]     Train net output #1: loss = 0.863252 (* 1 = 0.863252 loss)
I1211 15:22:28.840092 16720 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1211 15:22:34.690030  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:22:34.931543 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_66000.caffemodel
I1211 15:22:34.947543 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_66000.solverstate
I1211 15:22:34.952544 16720 solver.cpp:330] Iteration 66000, Testing net (#0)
I1211 15:22:34.952544 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:22:36.289156 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:22:36.341668 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5912
I1211 15:22:36.341668 16720 solver.cpp:397]     Test net output #1: loss = 1.5343 (* 1 = 1.5343 loss)
I1211 15:22:36.400662 16720 solver.cpp:218] Iteration 66000 (13.228 iter/s, 7.55973s/100 iters), loss = 0.686054
I1211 15:22:36.400662 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:22:36.400662 16720 solver.cpp:237]     Train net output #1: loss = 0.686054 (* 1 = 0.686054 loss)
I1211 15:22:36.400662 16720 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1211 15:22:42.553056 16720 solver.cpp:218] Iteration 66100 (16.2549 iter/s, 6.15198s/100 iters), loss = 0.722385
I1211 15:22:42.553056 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:22:42.553056 16720 solver.cpp:237]     Train net output #1: loss = 0.722385 (* 1 = 0.722385 loss)
I1211 15:22:42.553056 16720 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1211 15:22:48.701508 16720 solver.cpp:218] Iteration 66200 (16.2653 iter/s, 6.14804s/100 iters), loss = 0.707668
I1211 15:22:48.701508 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:22:48.701508 16720 solver.cpp:237]     Train net output #1: loss = 0.707668 (* 1 = 0.707668 loss)
I1211 15:22:48.701508 16720 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1211 15:22:54.856958 16720 solver.cpp:218] Iteration 66300 (16.2465 iter/s, 6.15519s/100 iters), loss = 0.933305
I1211 15:22:54.856958 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:22:54.856958 16720 solver.cpp:237]     Train net output #1: loss = 0.933305 (* 1 = 0.933305 loss)
I1211 15:22:54.856958 16720 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1211 15:23:01.009433 16720 solver.cpp:218] Iteration 66400 (16.253 iter/s, 6.15273s/100 iters), loss = 0.888686
I1211 15:23:01.009433 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:23:01.010434 16720 solver.cpp:237]     Train net output #1: loss = 0.888686 (* 1 = 0.888686 loss)
I1211 15:23:01.010434 16720 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1211 15:23:06.853648  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:23:07.098222 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_66500.caffemodel
I1211 15:23:07.117229 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_66500.solverstate
I1211 15:23:07.122231 16720 solver.cpp:330] Iteration 66500, Testing net (#0)
I1211 15:23:07.122231 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:23:08.456527 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:23:08.509548 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5891
I1211 15:23:08.509548 16720 solver.cpp:397]     Test net output #1: loss = 1.52027 (* 1 = 1.52027 loss)
I1211 15:23:08.567564 16720 solver.cpp:218] Iteration 66500 (13.2325 iter/s, 7.55715s/100 iters), loss = 0.777358
I1211 15:23:08.567564 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:23:08.567564 16720 solver.cpp:237]     Train net output #1: loss = 0.777358 (* 1 = 0.777358 loss)
I1211 15:23:08.567564 16720 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1211 15:23:14.717243 16720 solver.cpp:218] Iteration 66600 (16.2633 iter/s, 6.14881s/100 iters), loss = 0.712977
I1211 15:23:14.717243 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:23:14.717243 16720 solver.cpp:237]     Train net output #1: loss = 0.712977 (* 1 = 0.712977 loss)
I1211 15:23:14.717243 16720 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1211 15:23:20.865106 16720 solver.cpp:218] Iteration 66700 (16.2654 iter/s, 6.14803s/100 iters), loss = 0.734488
I1211 15:23:20.865106 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:23:20.865106 16720 solver.cpp:237]     Train net output #1: loss = 0.734488 (* 1 = 0.734488 loss)
I1211 15:23:20.865106 16720 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1211 15:23:27.022963 16720 solver.cpp:218] Iteration 66800 (16.2405 iter/s, 6.15745s/100 iters), loss = 0.803408
I1211 15:23:27.022963 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:23:27.022963 16720 solver.cpp:237]     Train net output #1: loss = 0.803408 (* 1 = 0.803408 loss)
I1211 15:23:27.022963 16720 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1211 15:23:33.179759 16720 solver.cpp:218] Iteration 66900 (16.2431 iter/s, 6.15645s/100 iters), loss = 0.827294
I1211 15:23:33.179759 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:23:33.179759 16720 solver.cpp:237]     Train net output #1: loss = 0.827294 (* 1 = 0.827294 loss)
I1211 15:23:33.179759 16720 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1211 15:23:39.036444  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:23:39.279469 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_67000.caffemodel
I1211 15:23:39.294977 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_67000.solverstate
I1211 15:23:39.299479 16720 solver.cpp:330] Iteration 67000, Testing net (#0)
I1211 15:23:39.299479 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:23:40.633651 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:23:40.686650 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6021
I1211 15:23:40.686650 16720 solver.cpp:397]     Test net output #1: loss = 1.51212 (* 1 = 1.51212 loss)
I1211 15:23:40.744659 16720 solver.cpp:218] Iteration 67000 (13.2194 iter/s, 7.56464s/100 iters), loss = 0.597743
I1211 15:23:40.745661 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:23:40.745661 16720 solver.cpp:237]     Train net output #1: loss = 0.597743 (* 1 = 0.597743 loss)
I1211 15:23:40.745661 16720 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1211 15:23:46.900023 16720 solver.cpp:218] Iteration 67100 (16.2495 iter/s, 6.15402s/100 iters), loss = 0.845423
I1211 15:23:46.900023 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:23:46.900023 16720 solver.cpp:237]     Train net output #1: loss = 0.845423 (* 1 = 0.845423 loss)
I1211 15:23:46.900023 16720 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1211 15:23:53.055315 16720 solver.cpp:218] Iteration 67200 (16.2466 iter/s, 6.15512s/100 iters), loss = 0.73447
I1211 15:23:53.055315 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:23:53.055315 16720 solver.cpp:237]     Train net output #1: loss = 0.73447 (* 1 = 0.73447 loss)
I1211 15:23:53.055315 16720 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1211 15:23:59.205906 16720 solver.cpp:218] Iteration 67300 (16.2597 iter/s, 6.15017s/100 iters), loss = 0.80339
I1211 15:23:59.205906 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:23:59.205906 16720 solver.cpp:237]     Train net output #1: loss = 0.80339 (* 1 = 0.80339 loss)
I1211 15:23:59.205906 16720 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1211 15:24:05.356160 16720 solver.cpp:218] Iteration 67400 (16.2597 iter/s, 6.15017s/100 iters), loss = 0.856826
I1211 15:24:05.356160 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 15:24:05.356160 16720 solver.cpp:237]     Train net output #1: loss = 0.856826 (* 1 = 0.856826 loss)
I1211 15:24:05.356160 16720 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1211 15:24:11.212184  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:24:11.455209 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_67500.caffemodel
I1211 15:24:11.470209 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_67500.solverstate
I1211 15:24:11.474210 16720 solver.cpp:330] Iteration 67500, Testing net (#0)
I1211 15:24:11.475210 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:24:12.810953 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:24:12.862458 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6078
I1211 15:24:12.862458 16720 solver.cpp:397]     Test net output #1: loss = 1.47125 (* 1 = 1.47125 loss)
I1211 15:24:12.920964 16720 solver.cpp:218] Iteration 67500 (13.2204 iter/s, 7.56405s/100 iters), loss = 0.729982
I1211 15:24:12.921463 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:24:12.921463 16720 solver.cpp:237]     Train net output #1: loss = 0.729982 (* 1 = 0.729982 loss)
I1211 15:24:12.921463 16720 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1211 15:24:19.082247 16720 solver.cpp:218] Iteration 67600 (16.2305 iter/s, 6.16123s/100 iters), loss = 0.668995
I1211 15:24:19.082247 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:24:19.082247 16720 solver.cpp:237]     Train net output #1: loss = 0.668995 (* 1 = 0.668995 loss)
I1211 15:24:19.082247 16720 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1211 15:24:25.249930 16720 solver.cpp:218] Iteration 67700 (16.2161 iter/s, 6.16671s/100 iters), loss = 0.693756
I1211 15:24:25.249930 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:24:25.249930 16720 solver.cpp:237]     Train net output #1: loss = 0.693756 (* 1 = 0.693756 loss)
I1211 15:24:25.249930 16720 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1211 15:24:31.409837 16720 solver.cpp:218] Iteration 67800 (16.2357 iter/s, 6.15925s/100 iters), loss = 0.700899
I1211 15:24:31.409837 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:24:31.409837 16720 solver.cpp:237]     Train net output #1: loss = 0.700899 (* 1 = 0.700899 loss)
I1211 15:24:31.409837 16720 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1211 15:24:37.578270 16720 solver.cpp:218] Iteration 67900 (16.2118 iter/s, 6.16833s/100 iters), loss = 0.961848
I1211 15:24:37.578270 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 15:24:37.578270 16720 solver.cpp:237]     Train net output #1: loss = 0.961848 (* 1 = 0.961848 loss)
I1211 15:24:37.578270 16720 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1211 15:24:43.432019  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:24:43.674933 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_68000.caffemodel
I1211 15:24:43.689940 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_68000.solverstate
I1211 15:24:43.693933 16720 solver.cpp:330] Iteration 68000, Testing net (#0)
I1211 15:24:43.693933 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:24:45.027122 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:24:45.080121 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5923
I1211 15:24:45.080121 16720 solver.cpp:397]     Test net output #1: loss = 1.57809 (* 1 = 1.57809 loss)
I1211 15:24:45.139129 16720 solver.cpp:218] Iteration 68000 (13.2271 iter/s, 7.56023s/100 iters), loss = 0.61971
I1211 15:24:45.139129 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:24:45.139129 16720 solver.cpp:237]     Train net output #1: loss = 0.61971 (* 1 = 0.61971 loss)
I1211 15:24:45.139129 16720 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1211 15:24:51.297997 16720 solver.cpp:218] Iteration 68100 (16.2385 iter/s, 6.15819s/100 iters), loss = 0.762164
I1211 15:24:51.297997 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:24:51.297997 16720 solver.cpp:237]     Train net output #1: loss = 0.762164 (* 1 = 0.762164 loss)
I1211 15:24:51.297997 16720 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1211 15:24:57.452744 16720 solver.cpp:218] Iteration 68200 (16.2465 iter/s, 6.15517s/100 iters), loss = 0.674253
I1211 15:24:57.452744 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:24:57.452744 16720 solver.cpp:237]     Train net output #1: loss = 0.674253 (* 1 = 0.674253 loss)
I1211 15:24:57.452744 16720 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1211 15:25:03.610416 16720 solver.cpp:218] Iteration 68300 (16.2427 iter/s, 6.15661s/100 iters), loss = 0.77853
I1211 15:25:03.610416 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:25:03.610416 16720 solver.cpp:237]     Train net output #1: loss = 0.77853 (* 1 = 0.77853 loss)
I1211 15:25:03.610416 16720 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1211 15:25:09.764283 16720 solver.cpp:218] Iteration 68400 (16.2511 iter/s, 6.15344s/100 iters), loss = 0.880056
I1211 15:25:09.764283 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:25:09.764283 16720 solver.cpp:237]     Train net output #1: loss = 0.880056 (* 1 = 0.880056 loss)
I1211 15:25:09.764283 16720 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1211 15:25:15.614711  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:25:15.855725 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_68500.caffemodel
I1211 15:25:15.870723 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_68500.solverstate
I1211 15:25:15.874723 16720 solver.cpp:330] Iteration 68500, Testing net (#0)
I1211 15:25:15.874723 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:25:17.208832 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:25:17.261837 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5605
I1211 15:25:17.261837 16720 solver.cpp:397]     Test net output #1: loss = 1.72964 (* 1 = 1.72964 loss)
I1211 15:25:17.320338 16720 solver.cpp:218] Iteration 68500 (13.2353 iter/s, 7.55557s/100 iters), loss = 0.652447
I1211 15:25:17.320338 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:25:17.320338 16720 solver.cpp:237]     Train net output #1: loss = 0.652447 (* 1 = 0.652447 loss)
I1211 15:25:17.320338 16720 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1211 15:25:23.471261 16720 solver.cpp:218] Iteration 68600 (16.2583 iter/s, 6.1507s/100 iters), loss = 0.731229
I1211 15:25:23.471261 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:25:23.471261 16720 solver.cpp:237]     Train net output #1: loss = 0.731229 (* 1 = 0.731229 loss)
I1211 15:25:23.471261 16720 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1211 15:25:29.624691 16720 solver.cpp:218] Iteration 68700 (16.2528 iter/s, 6.1528s/100 iters), loss = 0.714
I1211 15:25:29.624691 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:25:29.624691 16720 solver.cpp:237]     Train net output #1: loss = 0.714 (* 1 = 0.714 loss)
I1211 15:25:29.624691 16720 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1211 15:25:35.765193 16720 solver.cpp:218] Iteration 68800 (16.2857 iter/s, 6.14036s/100 iters), loss = 0.935394
I1211 15:25:35.765193 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:25:35.765193 16720 solver.cpp:237]     Train net output #1: loss = 0.935394 (* 1 = 0.935394 loss)
I1211 15:25:35.765193 16720 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1211 15:25:41.914641 16720 solver.cpp:218] Iteration 68900 (16.2634 iter/s, 6.14877s/100 iters), loss = 0.810163
I1211 15:25:41.915140 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:25:41.915140 16720 solver.cpp:237]     Train net output #1: loss = 0.810163 (* 1 = 0.810163 loss)
I1211 15:25:41.915140 16720 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1211 15:25:47.767084  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:25:48.008095 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_69000.caffemodel
I1211 15:25:48.023600 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_69000.solverstate
I1211 15:25:48.028105 16720 solver.cpp:330] Iteration 69000, Testing net (#0)
I1211 15:25:48.028105 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:25:49.361197 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:25:49.413700 16720 solver.cpp:397]     Test net output #0: accuracy = 0.587
I1211 15:25:49.413700 16720 solver.cpp:397]     Test net output #1: loss = 1.59671 (* 1 = 1.59671 loss)
I1211 15:25:49.472203 16720 solver.cpp:218] Iteration 69000 (13.232 iter/s, 7.55744s/100 iters), loss = 0.683066
I1211 15:25:49.472203 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:25:49.472203 16720 solver.cpp:237]     Train net output #1: loss = 0.683066 (* 1 = 0.683066 loss)
I1211 15:25:49.472203 16720 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1211 15:25:55.615695 16720 solver.cpp:218] Iteration 69100 (16.2799 iter/s, 6.14255s/100 iters), loss = 0.657763
I1211 15:25:55.615695 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:25:55.615695 16720 solver.cpp:237]     Train net output #1: loss = 0.657763 (* 1 = 0.657763 loss)
I1211 15:25:55.615695 16720 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1211 15:26:01.763114 16720 solver.cpp:218] Iteration 69200 (16.2674 iter/s, 6.14725s/100 iters), loss = 0.630137
I1211 15:26:01.763114 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:26:01.763114 16720 solver.cpp:237]     Train net output #1: loss = 0.630137 (* 1 = 0.630137 loss)
I1211 15:26:01.763114 16720 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1211 15:26:07.907573 16720 solver.cpp:218] Iteration 69300 (16.2751 iter/s, 6.14437s/100 iters), loss = 0.848262
I1211 15:26:07.907573 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:26:07.907573 16720 solver.cpp:237]     Train net output #1: loss = 0.848262 (* 1 = 0.848262 loss)
I1211 15:26:07.907573 16720 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1211 15:26:14.050026 16720 solver.cpp:218] Iteration 69400 (16.2832 iter/s, 6.14131s/100 iters), loss = 0.738811
I1211 15:26:14.050026 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:26:14.050026 16720 solver.cpp:237]     Train net output #1: loss = 0.738811 (* 1 = 0.738811 loss)
I1211 15:26:14.050026 16720 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1211 15:26:19.898916  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:26:20.141515 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_69500.caffemodel
I1211 15:26:20.157513 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_69500.solverstate
I1211 15:26:20.162513 16720 solver.cpp:330] Iteration 69500, Testing net (#0)
I1211 15:26:20.162513 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:26:21.496443 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:26:21.548027 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5877
I1211 15:26:21.548027 16720 solver.cpp:397]     Test net output #1: loss = 1.57641 (* 1 = 1.57641 loss)
I1211 15:26:21.607041 16720 solver.cpp:218] Iteration 69500 (13.2327 iter/s, 7.55705s/100 iters), loss = 0.543788
I1211 15:26:21.607041 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:26:21.607041 16720 solver.cpp:237]     Train net output #1: loss = 0.543788 (* 1 = 0.543788 loss)
I1211 15:26:21.607041 16720 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1211 15:26:27.753943 16720 solver.cpp:218] Iteration 69600 (16.2695 iter/s, 6.14645s/100 iters), loss = 0.798391
I1211 15:26:27.753943 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:26:27.753943 16720 solver.cpp:237]     Train net output #1: loss = 0.798391 (* 1 = 0.798391 loss)
I1211 15:26:27.753943 16720 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1211 15:26:33.908457 16720 solver.cpp:218] Iteration 69700 (16.25 iter/s, 6.15384s/100 iters), loss = 0.644578
I1211 15:26:33.908457 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:26:33.908457 16720 solver.cpp:237]     Train net output #1: loss = 0.644578 (* 1 = 0.644578 loss)
I1211 15:26:33.908457 16720 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1211 15:26:40.072343 16720 solver.cpp:218] Iteration 69800 (16.2245 iter/s, 6.1635s/100 iters), loss = 0.89732
I1211 15:26:40.072343 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 15:26:40.072343 16720 solver.cpp:237]     Train net output #1: loss = 0.89732 (* 1 = 0.89732 loss)
I1211 15:26:40.072343 16720 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1211 15:26:46.224259 16720 solver.cpp:218] Iteration 69900 (16.2566 iter/s, 6.15133s/100 iters), loss = 0.726765
I1211 15:26:46.224259 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:26:46.224259 16720 solver.cpp:237]     Train net output #1: loss = 0.726765 (* 1 = 0.726765 loss)
I1211 15:26:46.224259 16720 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1211 15:26:52.076200  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:26:52.319221 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_70000.caffemodel
I1211 15:26:52.335723 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_70000.solverstate
I1211 15:26:52.340229 16720 solver.cpp:330] Iteration 70000, Testing net (#0)
I1211 15:26:52.340229 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:26:53.673306 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:26:53.725809 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5874
I1211 15:26:53.725809 16720 solver.cpp:397]     Test net output #1: loss = 1.56646 (* 1 = 1.56646 loss)
I1211 15:26:53.784312 16720 solver.cpp:218] Iteration 70000 (13.2275 iter/s, 7.56s/100 iters), loss = 0.672278
I1211 15:26:53.784312 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:26:53.784312 16720 solver.cpp:237]     Train net output #1: loss = 0.672278 (* 1 = 0.672278 loss)
I1211 15:26:53.784312 16720 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1211 15:26:59.944761 16720 solver.cpp:218] Iteration 70100 (16.2355 iter/s, 6.15934s/100 iters), loss = 0.873663
I1211 15:26:59.944761 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:26:59.944761 16720 solver.cpp:237]     Train net output #1: loss = 0.873663 (* 1 = 0.873663 loss)
I1211 15:26:59.944761 16720 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1211 15:27:06.111203 16720 solver.cpp:218] Iteration 70200 (16.2163 iter/s, 6.16664s/100 iters), loss = 0.644399
I1211 15:27:06.111203 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:27:06.111203 16720 solver.cpp:237]     Train net output #1: loss = 0.644399 (* 1 = 0.644399 loss)
I1211 15:27:06.111203 16720 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1211 15:27:12.279695 16720 solver.cpp:218] Iteration 70300 (16.2139 iter/s, 6.16756s/100 iters), loss = 0.776622
I1211 15:27:12.279695 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:27:12.279695 16720 solver.cpp:237]     Train net output #1: loss = 0.776622 (* 1 = 0.776622 loss)
I1211 15:27:12.279695 16720 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1211 15:27:18.446182 16720 solver.cpp:218] Iteration 70400 (16.217 iter/s, 6.16637s/100 iters), loss = 0.748967
I1211 15:27:18.446182 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:27:18.446182 16720 solver.cpp:237]     Train net output #1: loss = 0.748967 (* 1 = 0.748967 loss)
I1211 15:27:18.446182 16720 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1211 15:27:24.300591  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:27:24.543608 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_70500.caffemodel
I1211 15:27:24.559608 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_70500.solverstate
I1211 15:27:24.563608 16720 solver.cpp:330] Iteration 70500, Testing net (#0)
I1211 15:27:24.563608 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:27:25.900683 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:27:25.952694 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5763
I1211 15:27:25.953696 16720 solver.cpp:397]     Test net output #1: loss = 1.63909 (* 1 = 1.63909 loss)
I1211 15:27:26.011693 16720 solver.cpp:218] Iteration 70500 (13.2191 iter/s, 7.56483s/100 iters), loss = 0.652164
I1211 15:27:26.011693 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:27:26.011693 16720 solver.cpp:237]     Train net output #1: loss = 0.652164 (* 1 = 0.652164 loss)
I1211 15:27:26.011693 16720 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1211 15:27:32.161173 16720 solver.cpp:218] Iteration 70600 (16.2618 iter/s, 6.14938s/100 iters), loss = 0.693141
I1211 15:27:32.161173 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:27:32.161173 16720 solver.cpp:237]     Train net output #1: loss = 0.693141 (* 1 = 0.693141 loss)
I1211 15:27:32.161173 16720 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1211 15:27:38.312662 16720 solver.cpp:218] Iteration 70700 (16.2576 iter/s, 6.15097s/100 iters), loss = 0.588574
I1211 15:27:38.312662 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:27:38.312662 16720 solver.cpp:237]     Train net output #1: loss = 0.588574 (* 1 = 0.588574 loss)
I1211 15:27:38.312662 16720 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1211 15:27:44.465137 16720 solver.cpp:218] Iteration 70800 (16.2553 iter/s, 6.15185s/100 iters), loss = 0.791947
I1211 15:27:44.465137 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:27:44.465137 16720 solver.cpp:237]     Train net output #1: loss = 0.791947 (* 1 = 0.791947 loss)
I1211 15:27:44.465137 16720 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1211 15:27:50.623617 16720 solver.cpp:218] Iteration 70900 (16.238 iter/s, 6.15839s/100 iters), loss = 0.818475
I1211 15:27:50.623617 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 15:27:50.623617 16720 solver.cpp:237]     Train net output #1: loss = 0.818475 (* 1 = 0.818475 loss)
I1211 15:27:50.623617 16720 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1211 15:27:56.457026  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:27:56.701064 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_71000.caffemodel
I1211 15:27:56.717063 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_71000.solverstate
I1211 15:27:56.722064 16720 solver.cpp:330] Iteration 71000, Testing net (#0)
I1211 15:27:56.722064 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:27:58.058156 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:27:58.109161 16720 solver.cpp:397]     Test net output #0: accuracy = 0.584
I1211 15:27:58.109161 16720 solver.cpp:397]     Test net output #1: loss = 1.5941 (* 1 = 1.5941 loss)
I1211 15:27:58.169162 16720 solver.cpp:218] Iteration 71000 (13.2552 iter/s, 7.54419s/100 iters), loss = 0.520121
I1211 15:27:58.169162 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:27:58.169162 16720 solver.cpp:237]     Train net output #1: loss = 0.520121 (* 1 = 0.520121 loss)
I1211 15:27:58.169162 16720 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1211 15:28:04.326628 16720 solver.cpp:218] Iteration 71100 (16.2401 iter/s, 6.15759s/100 iters), loss = 0.814727
I1211 15:28:04.326628 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:28:04.326628 16720 solver.cpp:237]     Train net output #1: loss = 0.814727 (* 1 = 0.814727 loss)
I1211 15:28:04.326628 16720 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1211 15:28:10.481057 16720 solver.cpp:218] Iteration 71200 (16.2507 iter/s, 6.15359s/100 iters), loss = 0.653695
I1211 15:28:10.481057 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:28:10.481057 16720 solver.cpp:237]     Train net output #1: loss = 0.653695 (* 1 = 0.653695 loss)
I1211 15:28:10.481057 16720 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1211 15:28:16.636608 16720 solver.cpp:218] Iteration 71300 (16.246 iter/s, 6.15537s/100 iters), loss = 0.885645
I1211 15:28:16.636608 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 15:28:16.636608 16720 solver.cpp:237]     Train net output #1: loss = 0.885645 (* 1 = 0.885645 loss)
I1211 15:28:16.636608 16720 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1211 15:28:22.793023 16720 solver.cpp:218] Iteration 71400 (16.2454 iter/s, 6.15559s/100 iters), loss = 0.799384
I1211 15:28:22.793023 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:28:22.793023 16720 solver.cpp:237]     Train net output #1: loss = 0.799384 (* 1 = 0.799384 loss)
I1211 15:28:22.793023 16720 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1211 15:28:28.658448  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:28:28.899298 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_71500.caffemodel
I1211 15:28:28.914297 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_71500.solverstate
I1211 15:28:28.918298 16720 solver.cpp:330] Iteration 71500, Testing net (#0)
I1211 15:28:28.918298 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:28:30.248191 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:28:30.300776 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5843
I1211 15:28:30.300776 16720 solver.cpp:397]     Test net output #1: loss = 1.58671 (* 1 = 1.58671 loss)
I1211 15:28:30.359786 16720 solver.cpp:218] Iteration 71500 (13.216 iter/s, 7.56656s/100 iters), loss = 0.706726
I1211 15:28:30.359786 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:28:30.359786 16720 solver.cpp:237]     Train net output #1: loss = 0.706726 (* 1 = 0.706726 loss)
I1211 15:28:30.359786 16720 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1211 15:28:36.509752 16720 solver.cpp:218] Iteration 71600 (16.2617 iter/s, 6.14943s/100 iters), loss = 0.719631
I1211 15:28:36.509752 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:28:36.509752 16720 solver.cpp:237]     Train net output #1: loss = 0.719631 (* 1 = 0.719631 loss)
I1211 15:28:36.509752 16720 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1211 15:28:42.653087 16720 solver.cpp:218] Iteration 71700 (16.2794 iter/s, 6.14272s/100 iters), loss = 0.704246
I1211 15:28:42.653087 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:28:42.653087 16720 solver.cpp:237]     Train net output #1: loss = 0.704246 (* 1 = 0.704246 loss)
I1211 15:28:42.653087 16720 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1211 15:28:48.813630 16720 solver.cpp:218] Iteration 71800 (16.232 iter/s, 6.16066s/100 iters), loss = 0.789112
I1211 15:28:48.813630 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:28:48.813630 16720 solver.cpp:237]     Train net output #1: loss = 0.789112 (* 1 = 0.789112 loss)
I1211 15:28:48.813630 16720 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1211 15:28:54.967095 16720 solver.cpp:218] Iteration 71900 (16.2521 iter/s, 6.15304s/100 iters), loss = 0.730727
I1211 15:28:54.967095 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:28:54.967095 16720 solver.cpp:237]     Train net output #1: loss = 0.730727 (* 1 = 0.730727 loss)
I1211 15:28:54.967095 16720 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1211 15:29:00.815558  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:29:01.059571 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_72000.caffemodel
I1211 15:29:01.074571 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_72000.solverstate
I1211 15:29:01.078572 16720 solver.cpp:330] Iteration 72000, Testing net (#0)
I1211 15:29:01.078572 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:29:02.414674 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:29:02.467674 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5707
I1211 15:29:02.467674 16720 solver.cpp:397]     Test net output #1: loss = 1.66408 (* 1 = 1.66408 loss)
I1211 15:29:02.526680 16720 solver.cpp:218] Iteration 72000 (13.2289 iter/s, 7.55921s/100 iters), loss = 0.645277
I1211 15:29:02.526680 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:29:02.526680 16720 solver.cpp:237]     Train net output #1: loss = 0.645277 (* 1 = 0.645277 loss)
I1211 15:29:02.526680 16720 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1211 15:29:08.685219 16720 solver.cpp:218] Iteration 72100 (16.2397 iter/s, 6.15774s/100 iters), loss = 0.69083
I1211 15:29:08.685219 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:29:08.685219 16720 solver.cpp:237]     Train net output #1: loss = 0.69083 (* 1 = 0.69083 loss)
I1211 15:29:08.685219 16720 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1211 15:29:14.839354 16720 solver.cpp:218] Iteration 72200 (16.2492 iter/s, 6.15414s/100 iters), loss = 0.695156
I1211 15:29:14.839354 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:29:14.839354 16720 solver.cpp:237]     Train net output #1: loss = 0.695156 (* 1 = 0.695156 loss)
I1211 15:29:14.839354 16720 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1211 15:29:20.992328 16720 solver.cpp:218] Iteration 72300 (16.2533 iter/s, 6.15259s/100 iters), loss = 0.824637
I1211 15:29:20.992328 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:29:20.992328 16720 solver.cpp:237]     Train net output #1: loss = 0.824637 (* 1 = 0.824637 loss)
I1211 15:29:20.992328 16720 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1211 15:29:27.142729 16720 solver.cpp:218] Iteration 72400 (16.2606 iter/s, 6.14983s/100 iters), loss = 0.769486
I1211 15:29:27.142729 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:29:27.142729 16720 solver.cpp:237]     Train net output #1: loss = 0.769486 (* 1 = 0.769486 loss)
I1211 15:29:27.142729 16720 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1211 15:29:33.009672  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:29:33.252188 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_72500.caffemodel
I1211 15:29:33.268187 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_72500.solverstate
I1211 15:29:33.272198 16720 solver.cpp:330] Iteration 72500, Testing net (#0)
I1211 15:29:33.272198 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:29:34.610810 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:29:34.662313 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5531
I1211 15:29:34.662313 16720 solver.cpp:397]     Test net output #1: loss = 1.76129 (* 1 = 1.76129 loss)
I1211 15:29:34.721318 16720 solver.cpp:218] Iteration 72500 (13.1969 iter/s, 7.57754s/100 iters), loss = 0.738591
I1211 15:29:34.721318 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:29:34.721318 16720 solver.cpp:237]     Train net output #1: loss = 0.738591 (* 1 = 0.738591 loss)
I1211 15:29:34.721318 16720 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1211 15:29:40.886744 16720 solver.cpp:218] Iteration 72600 (16.22 iter/s, 6.16523s/100 iters), loss = 0.643724
I1211 15:29:40.886744 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:29:40.886744 16720 solver.cpp:237]     Train net output #1: loss = 0.643724 (* 1 = 0.643724 loss)
I1211 15:29:40.886744 16720 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1211 15:29:47.047183 16720 solver.cpp:218] Iteration 72700 (16.2333 iter/s, 6.16018s/100 iters), loss = 0.71046
I1211 15:29:47.047183 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:29:47.047183 16720 solver.cpp:237]     Train net output #1: loss = 0.71046 (* 1 = 0.71046 loss)
I1211 15:29:47.047183 16720 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1211 15:29:53.203109 16720 solver.cpp:218] Iteration 72800 (16.2463 iter/s, 6.15526s/100 iters), loss = 0.753704
I1211 15:29:53.203608 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:29:53.203608 16720 solver.cpp:237]     Train net output #1: loss = 0.753704 (* 1 = 0.753704 loss)
I1211 15:29:53.203608 16720 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1211 15:29:59.359588 16720 solver.cpp:218] Iteration 72900 (16.2438 iter/s, 6.15618s/100 iters), loss = 0.828281
I1211 15:29:59.359588 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:29:59.359588 16720 solver.cpp:237]     Train net output #1: loss = 0.828281 (* 1 = 0.828281 loss)
I1211 15:29:59.359588 16720 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1211 15:30:05.248152  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:30:05.491164 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_73000.caffemodel
I1211 15:30:05.506667 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_73000.solverstate
I1211 15:30:05.510668 16720 solver.cpp:330] Iteration 73000, Testing net (#0)
I1211 15:30:05.511169 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:30:06.847259 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:30:06.899268 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5712
I1211 15:30:06.899761 16720 solver.cpp:397]     Test net output #1: loss = 1.64758 (* 1 = 1.64758 loss)
I1211 15:30:06.958264 16720 solver.cpp:218] Iteration 73000 (13.1615 iter/s, 7.59793s/100 iters), loss = 0.66631
I1211 15:30:06.958264 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:30:06.958264 16720 solver.cpp:237]     Train net output #1: loss = 0.66631 (* 1 = 0.66631 loss)
I1211 15:30:06.958264 16720 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1211 15:30:13.111724 16720 solver.cpp:218] Iteration 73100 (16.2522 iter/s, 6.153s/100 iters), loss = 0.71031
I1211 15:30:13.111724 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:30:13.112224 16720 solver.cpp:237]     Train net output #1: loss = 0.71031 (* 1 = 0.71031 loss)
I1211 15:30:13.112224 16720 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1211 15:30:19.264243 16720 solver.cpp:218] Iteration 73200 (16.254 iter/s, 6.15235s/100 iters), loss = 0.771466
I1211 15:30:19.264243 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:30:19.264243 16720 solver.cpp:237]     Train net output #1: loss = 0.771466 (* 1 = 0.771466 loss)
I1211 15:30:19.264243 16720 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1211 15:30:25.412731 16720 solver.cpp:218] Iteration 73300 (16.2669 iter/s, 6.14745s/100 iters), loss = 0.756337
I1211 15:30:25.412731 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:30:25.412731 16720 solver.cpp:237]     Train net output #1: loss = 0.756337 (* 1 = 0.756337 loss)
I1211 15:30:25.412731 16720 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1211 15:30:31.569185 16720 solver.cpp:218] Iteration 73400 (16.243 iter/s, 6.15649s/100 iters), loss = 0.900103
I1211 15:30:31.569185 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:30:31.569185 16720 solver.cpp:237]     Train net output #1: loss = 0.900103 (* 1 = 0.900103 loss)
I1211 15:30:31.569185 16720 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1211 15:30:37.410585  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:30:37.652597 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_73500.caffemodel
I1211 15:30:37.668598 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_73500.solverstate
I1211 15:30:37.672598 16720 solver.cpp:330] Iteration 73500, Testing net (#0)
I1211 15:30:37.672598 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:30:39.007702 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:30:39.059701 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5788
I1211 15:30:39.059701 16720 solver.cpp:397]     Test net output #1: loss = 1.67269 (* 1 = 1.67269 loss)
I1211 15:30:39.118708 16720 solver.cpp:218] Iteration 73500 (13.2466 iter/s, 7.5491s/100 iters), loss = 0.606461
I1211 15:30:39.118708 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:30:39.118708 16720 solver.cpp:237]     Train net output #1: loss = 0.606461 (* 1 = 0.606461 loss)
I1211 15:30:39.118708 16720 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1211 15:30:45.271162 16720 solver.cpp:218] Iteration 73600 (16.2554 iter/s, 6.15181s/100 iters), loss = 0.806973
I1211 15:30:45.271162 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:30:45.271162 16720 solver.cpp:237]     Train net output #1: loss = 0.806973 (* 1 = 0.806973 loss)
I1211 15:30:45.271162 16720 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1211 15:30:51.425227 16720 solver.cpp:218] Iteration 73700 (16.2489 iter/s, 6.15427s/100 iters), loss = 0.677186
I1211 15:30:51.426229 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:30:51.426229 16720 solver.cpp:237]     Train net output #1: loss = 0.677186 (* 1 = 0.677186 loss)
I1211 15:30:51.426229 16720 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1211 15:30:57.572420 16720 solver.cpp:218] Iteration 73800 (16.2703 iter/s, 6.14617s/100 iters), loss = 0.857651
I1211 15:30:57.572420 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:30:57.572420 16720 solver.cpp:237]     Train net output #1: loss = 0.857651 (* 1 = 0.857651 loss)
I1211 15:30:57.572420 16720 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1211 15:31:03.724897 16720 solver.cpp:218] Iteration 73900 (16.255 iter/s, 6.15194s/100 iters), loss = 0.842694
I1211 15:31:03.724897 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:31:03.724897 16720 solver.cpp:237]     Train net output #1: loss = 0.842694 (* 1 = 0.842694 loss)
I1211 15:31:03.724897 16720 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1211 15:31:09.579361  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:31:09.821382 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_74000.caffemodel
I1211 15:31:09.836381 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_74000.solverstate
I1211 15:31:09.841382 16720 solver.cpp:330] Iteration 74000, Testing net (#0)
I1211 15:31:09.841382 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:31:11.175541 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:31:11.227547 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6154
I1211 15:31:11.227547 16720 solver.cpp:397]     Test net output #1: loss = 1.42326 (* 1 = 1.42326 loss)
I1211 15:31:11.287050 16720 solver.cpp:218] Iteration 74000 (13.2243 iter/s, 7.56184s/100 iters), loss = 0.656581
I1211 15:31:11.287549 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:31:11.287549 16720 solver.cpp:237]     Train net output #1: loss = 0.656581 (* 1 = 0.656581 loss)
I1211 15:31:11.287549 16720 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1211 15:31:17.442039 16720 solver.cpp:218] Iteration 74100 (16.2474 iter/s, 6.15482s/100 iters), loss = 0.790493
I1211 15:31:17.442039 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:31:17.442039 16720 solver.cpp:237]     Train net output #1: loss = 0.790493 (* 1 = 0.790493 loss)
I1211 15:31:17.442039 16720 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1211 15:31:23.600942 16720 solver.cpp:218] Iteration 74200 (16.2394 iter/s, 6.15785s/100 iters), loss = 0.729845
I1211 15:31:23.600942 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:31:23.600942 16720 solver.cpp:237]     Train net output #1: loss = 0.729845 (* 1 = 0.729845 loss)
I1211 15:31:23.600942 16720 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1211 15:31:29.756840 16720 solver.cpp:218] Iteration 74300 (16.2443 iter/s, 6.15601s/100 iters), loss = 0.723907
I1211 15:31:29.756840 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:31:29.756840 16720 solver.cpp:237]     Train net output #1: loss = 0.723907 (* 1 = 0.723907 loss)
I1211 15:31:29.756840 16720 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1211 15:31:35.907320 16720 solver.cpp:218] Iteration 74400 (16.2597 iter/s, 6.15017s/100 iters), loss = 0.768268
I1211 15:31:35.907320 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:31:35.907320 16720 solver.cpp:237]     Train net output #1: loss = 0.768268 (* 1 = 0.768268 loss)
I1211 15:31:35.907320 16720 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1211 15:31:41.752776  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:31:41.995787 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_74500.caffemodel
I1211 15:31:42.010792 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_74500.solverstate
I1211 15:31:42.014791 16720 solver.cpp:330] Iteration 74500, Testing net (#0)
I1211 15:31:42.014791 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:31:43.349886 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:31:43.401890 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5611
I1211 15:31:43.401890 16720 solver.cpp:397]     Test net output #1: loss = 1.71631 (* 1 = 1.71631 loss)
I1211 15:31:43.460893 16720 solver.cpp:218] Iteration 74500 (13.2403 iter/s, 7.55272s/100 iters), loss = 0.78235
I1211 15:31:43.460893 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:31:43.460893 16720 solver.cpp:237]     Train net output #1: loss = 0.78235 (* 1 = 0.78235 loss)
I1211 15:31:43.460893 16720 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1211 15:31:49.621336 16720 solver.cpp:218] Iteration 74600 (16.2345 iter/s, 6.15972s/100 iters), loss = 0.709378
I1211 15:31:49.621336 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:31:49.621336 16720 solver.cpp:237]     Train net output #1: loss = 0.709378 (* 1 = 0.709378 loss)
I1211 15:31:49.621336 16720 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1211 15:31:55.779793 16720 solver.cpp:218] Iteration 74700 (16.2376 iter/s, 6.15853s/100 iters), loss = 0.663483
I1211 15:31:55.779793 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:31:55.779793 16720 solver.cpp:237]     Train net output #1: loss = 0.663483 (* 1 = 0.663483 loss)
I1211 15:31:55.779793 16720 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1211 15:32:01.941354 16720 solver.cpp:218] Iteration 74800 (16.2312 iter/s, 6.16098s/100 iters), loss = 0.871101
I1211 15:32:01.941354 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:32:01.941354 16720 solver.cpp:237]     Train net output #1: loss = 0.871101 (* 1 = 0.871101 loss)
I1211 15:32:01.941354 16720 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1211 15:32:08.099279 16720 solver.cpp:218] Iteration 74900 (16.2407 iter/s, 6.15735s/100 iters), loss = 0.746477
I1211 15:32:08.099279 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:32:08.099279 16720 solver.cpp:237]     Train net output #1: loss = 0.746477 (* 1 = 0.746477 loss)
I1211 15:32:08.099279 16720 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1211 15:32:13.957201  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:32:14.200217 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_75000.caffemodel
I1211 15:32:14.218226 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_75000.solverstate
I1211 15:32:14.223227 16720 solver.cpp:330] Iteration 75000, Testing net (#0)
I1211 15:32:14.223227 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:32:15.556306 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:32:15.609310 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5813
I1211 15:32:15.609310 16720 solver.cpp:397]     Test net output #1: loss = 1.5933 (* 1 = 1.5933 loss)
I1211 15:32:15.667310 16720 solver.cpp:218] Iteration 75000 (13.2142 iter/s, 7.56764s/100 iters), loss = 0.678008
I1211 15:32:15.667310 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:32:15.667310 16720 solver.cpp:237]     Train net output #1: loss = 0.678008 (* 1 = 0.678008 loss)
I1211 15:32:15.667310 16720 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1211 15:32:21.820452 16720 solver.cpp:218] Iteration 75100 (16.2541 iter/s, 6.15231s/100 iters), loss = 0.663697
I1211 15:32:21.820452 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:32:21.820452 16720 solver.cpp:237]     Train net output #1: loss = 0.663697 (* 1 = 0.663697 loss)
I1211 15:32:21.820452 16720 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1211 15:32:27.976047 16720 solver.cpp:218] Iteration 75200 (16.2449 iter/s, 6.15576s/100 iters), loss = 0.703755
I1211 15:32:27.976047 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:32:27.976047 16720 solver.cpp:237]     Train net output #1: loss = 0.703755 (* 1 = 0.703755 loss)
I1211 15:32:27.976047 16720 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1211 15:32:34.123523 16720 solver.cpp:218] Iteration 75300 (16.2674 iter/s, 6.14725s/100 iters), loss = 0.885088
I1211 15:32:34.124526 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:32:34.124526 16720 solver.cpp:237]     Train net output #1: loss = 0.885088 (* 1 = 0.885088 loss)
I1211 15:32:34.124526 16720 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1211 15:32:40.276418 16720 solver.cpp:218] Iteration 75400 (16.2547 iter/s, 6.15206s/100 iters), loss = 0.704966
I1211 15:32:40.276418 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:32:40.276418 16720 solver.cpp:237]     Train net output #1: loss = 0.704966 (* 1 = 0.704966 loss)
I1211 15:32:40.276418 16720 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1211 15:32:46.131407  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:32:46.374416 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_75500.caffemodel
I1211 15:32:46.389417 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_75500.solverstate
I1211 15:32:46.393417 16720 solver.cpp:330] Iteration 75500, Testing net (#0)
I1211 15:32:46.393417 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:32:47.728505 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:32:47.781505 16720 solver.cpp:397]     Test net output #0: accuracy = 0.608
I1211 15:32:47.781505 16720 solver.cpp:397]     Test net output #1: loss = 1.46473 (* 1 = 1.46473 loss)
I1211 15:32:47.842510 16720 solver.cpp:218] Iteration 75500 (13.2176 iter/s, 7.56567s/100 iters), loss = 0.600549
I1211 15:32:47.842510 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:32:47.842510 16720 solver.cpp:237]     Train net output #1: loss = 0.600549 (* 1 = 0.600549 loss)
I1211 15:32:47.842510 16720 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1211 15:32:54.042409 16720 solver.cpp:218] Iteration 75600 (16.1315 iter/s, 6.19904s/100 iters), loss = 0.754493
I1211 15:32:54.042409 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:32:54.042409 16720 solver.cpp:237]     Train net output #1: loss = 0.754493 (* 1 = 0.754493 loss)
I1211 15:32:54.042409 16720 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1211 15:33:00.185480 16720 solver.cpp:218] Iteration 75700 (16.2786 iter/s, 6.14304s/100 iters), loss = 0.752008
I1211 15:33:00.185480 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:33:00.185480 16720 solver.cpp:237]     Train net output #1: loss = 0.752008 (* 1 = 0.752008 loss)
I1211 15:33:00.185480 16720 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1211 15:33:06.329959 16720 solver.cpp:218] Iteration 75800 (16.2763 iter/s, 6.1439s/100 iters), loss = 0.67386
I1211 15:33:06.329959 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:33:06.329959 16720 solver.cpp:237]     Train net output #1: loss = 0.67386 (* 1 = 0.67386 loss)
I1211 15:33:06.329959 16720 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1211 15:33:12.474414 16720 solver.cpp:218] Iteration 75900 (16.2756 iter/s, 6.14416s/100 iters), loss = 0.880555
I1211 15:33:12.474414 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:33:12.474414 16720 solver.cpp:237]     Train net output #1: loss = 0.880555 (* 1 = 0.880555 loss)
I1211 15:33:12.474414 16720 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1211 15:33:18.309445  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:33:18.551959 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_76000.caffemodel
I1211 15:33:18.571959 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_76000.solverstate
I1211 15:33:18.576961 16720 solver.cpp:330] Iteration 76000, Testing net (#0)
I1211 15:33:18.576961 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:33:19.913049 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:33:19.965059 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5737
I1211 15:33:19.965059 16720 solver.cpp:397]     Test net output #1: loss = 1.67703 (* 1 = 1.67703 loss)
I1211 15:33:20.024056 16720 solver.cpp:218] Iteration 76000 (13.2474 iter/s, 7.54863s/100 iters), loss = 0.608498
I1211 15:33:20.024056 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:33:20.024056 16720 solver.cpp:237]     Train net output #1: loss = 0.608498 (* 1 = 0.608498 loss)
I1211 15:33:20.024056 16720 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1211 15:33:26.154508 16720 solver.cpp:218] Iteration 76100 (16.3107 iter/s, 6.13094s/100 iters), loss = 0.766485
I1211 15:33:26.155509 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:33:26.155509 16720 solver.cpp:237]     Train net output #1: loss = 0.766485 (* 1 = 0.766485 loss)
I1211 15:33:26.155509 16720 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1211 15:33:32.288962 16720 solver.cpp:218] Iteration 76200 (16.3025 iter/s, 6.13404s/100 iters), loss = 0.656421
I1211 15:33:32.289963 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:33:32.289963 16720 solver.cpp:237]     Train net output #1: loss = 0.656421 (* 1 = 0.656421 loss)
I1211 15:33:32.289963 16720 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1211 15:33:38.426381 16720 solver.cpp:218] Iteration 76300 (16.2957 iter/s, 6.1366s/100 iters), loss = 0.686774
I1211 15:33:38.426381 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:33:38.426381 16720 solver.cpp:237]     Train net output #1: loss = 0.686774 (* 1 = 0.686774 loss)
I1211 15:33:38.426381 16720 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1211 15:33:44.569821 16720 solver.cpp:218] Iteration 76400 (16.2789 iter/s, 6.1429s/100 iters), loss = 0.788313
I1211 15:33:44.569821 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:33:44.569821 16720 solver.cpp:237]     Train net output #1: loss = 0.788313 (* 1 = 0.788313 loss)
I1211 15:33:44.569821 16720 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1211 15:33:50.416736  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:33:50.659258 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_76500.caffemodel
I1211 15:33:50.674258 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_76500.solverstate
I1211 15:33:50.678257 16720 solver.cpp:330] Iteration 76500, Testing net (#0)
I1211 15:33:50.678257 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:33:52.010884 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:33:52.062928 16720 solver.cpp:397]     Test net output #0: accuracy = 0.565
I1211 15:33:52.062928 16720 solver.cpp:397]     Test net output #1: loss = 1.69818 (* 1 = 1.69818 loss)
I1211 15:33:52.121433 16720 solver.cpp:218] Iteration 76500 (13.242 iter/s, 7.55171s/100 iters), loss = 0.610318
I1211 15:33:52.122432 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:33:52.122432 16720 solver.cpp:237]     Train net output #1: loss = 0.610318 (* 1 = 0.610318 loss)
I1211 15:33:52.122432 16720 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1211 15:33:58.264868 16720 solver.cpp:218] Iteration 76600 (16.2795 iter/s, 6.14269s/100 iters), loss = 0.63507
I1211 15:33:58.264868 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:33:58.264868 16720 solver.cpp:237]     Train net output #1: loss = 0.63507 (* 1 = 0.63507 loss)
I1211 15:33:58.264868 16720 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1211 15:34:04.412710 16720 solver.cpp:218] Iteration 76700 (16.2684 iter/s, 6.14689s/100 iters), loss = 0.588943
I1211 15:34:04.412710 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:34:04.413208 16720 solver.cpp:237]     Train net output #1: loss = 0.588943 (* 1 = 0.588943 loss)
I1211 15:34:04.413208 16720 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1211 15:34:10.556593 16720 solver.cpp:218] Iteration 76800 (16.2782 iter/s, 6.14317s/100 iters), loss = 0.709284
I1211 15:34:10.556593 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:34:10.556593 16720 solver.cpp:237]     Train net output #1: loss = 0.709284 (* 1 = 0.709284 loss)
I1211 15:34:10.556593 16720 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1211 15:34:16.698035 16720 solver.cpp:218] Iteration 76900 (16.283 iter/s, 6.14138s/100 iters), loss = 0.864654
I1211 15:34:16.698035 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:34:16.698035 16720 solver.cpp:237]     Train net output #1: loss = 0.864654 (* 1 = 0.864654 loss)
I1211 15:34:16.698035 16720 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1211 15:34:22.540607  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:34:22.782194 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_77000.caffemodel
I1211 15:34:22.798190 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_77000.solverstate
I1211 15:34:22.802191 16720 solver.cpp:330] Iteration 77000, Testing net (#0)
I1211 15:34:22.802191 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:34:24.130905 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:34:24.183904 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5581
I1211 15:34:24.183904 16720 solver.cpp:397]     Test net output #1: loss = 1.74387 (* 1 = 1.74387 loss)
I1211 15:34:24.242436 16720 solver.cpp:218] Iteration 77000 (13.2568 iter/s, 7.54329s/100 iters), loss = 0.618977
I1211 15:34:24.242436 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:34:24.242436 16720 solver.cpp:237]     Train net output #1: loss = 0.618977 (* 1 = 0.618977 loss)
I1211 15:34:24.242436 16720 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1211 15:34:30.381642 16720 solver.cpp:218] Iteration 77100 (16.2876 iter/s, 6.13966s/100 iters), loss = 0.732969
I1211 15:34:30.382650 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:34:30.382650 16720 solver.cpp:237]     Train net output #1: loss = 0.732969 (* 1 = 0.732969 loss)
I1211 15:34:30.382650 16720 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1211 15:34:36.516608 16720 solver.cpp:218] Iteration 77200 (16.3032 iter/s, 6.13376s/100 iters), loss = 0.640243
I1211 15:34:36.516608 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:34:36.516608 16720 solver.cpp:237]     Train net output #1: loss = 0.640243 (* 1 = 0.640243 loss)
I1211 15:34:36.516608 16720 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1211 15:34:42.660558 16720 solver.cpp:218] Iteration 77300 (16.2772 iter/s, 6.14357s/100 iters), loss = 0.71745
I1211 15:34:42.660558 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:34:42.660558 16720 solver.cpp:237]     Train net output #1: loss = 0.71745 (* 1 = 0.71745 loss)
I1211 15:34:42.660558 16720 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1211 15:34:48.794104 16720 solver.cpp:218] Iteration 77400 (16.3032 iter/s, 6.13378s/100 iters), loss = 0.733236
I1211 15:34:48.795104 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:34:48.795104 16720 solver.cpp:237]     Train net output #1: loss = 0.733236 (* 1 = 0.733236 loss)
I1211 15:34:48.795104 16720 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1211 15:34:54.631562  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:34:54.871573 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_77500.caffemodel
I1211 15:34:54.887573 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_77500.solverstate
I1211 15:34:54.892575 16720 solver.cpp:330] Iteration 77500, Testing net (#0)
I1211 15:34:54.892575 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:34:56.223666 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:34:56.275668 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5756
I1211 15:34:56.275668 16720 solver.cpp:397]     Test net output #1: loss = 1.62642 (* 1 = 1.62642 loss)
I1211 15:34:56.333673 16720 solver.cpp:218] Iteration 77500 (13.2649 iter/s, 7.5387s/100 iters), loss = 0.605019
I1211 15:34:56.333673 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:34:56.333673 16720 solver.cpp:237]     Train net output #1: loss = 0.605019 (* 1 = 0.605019 loss)
I1211 15:34:56.333673 16720 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1211 15:35:02.481101 16720 solver.cpp:218] Iteration 77600 (16.2686 iter/s, 6.1468s/100 iters), loss = 0.748642
I1211 15:35:02.481101 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:35:02.481101 16720 solver.cpp:237]     Train net output #1: loss = 0.748642 (* 1 = 0.748642 loss)
I1211 15:35:02.481101 16720 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1211 15:35:08.623054 16720 solver.cpp:218] Iteration 77700 (16.2829 iter/s, 6.14141s/100 iters), loss = 0.6324
I1211 15:35:08.623054 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:35:08.623054 16720 solver.cpp:237]     Train net output #1: loss = 0.6324 (* 1 = 0.6324 loss)
I1211 15:35:08.623054 16720 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1211 15:35:14.764045 16720 solver.cpp:218] Iteration 77800 (16.2838 iter/s, 6.14108s/100 iters), loss = 0.71626
I1211 15:35:14.764045 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:35:14.764045 16720 solver.cpp:237]     Train net output #1: loss = 0.71626 (* 1 = 0.71626 loss)
I1211 15:35:14.764045 16720 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1211 15:35:20.907233 16720 solver.cpp:218] Iteration 77900 (16.2792 iter/s, 6.1428s/100 iters), loss = 0.792637
I1211 15:35:20.907233 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:35:20.907233 16720 solver.cpp:237]     Train net output #1: loss = 0.792637 (* 1 = 0.792637 loss)
I1211 15:35:20.907233 16720 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1211 15:35:26.754686  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:35:26.998703 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_78000.caffemodel
I1211 15:35:27.015707 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_78000.solverstate
I1211 15:35:27.020709 16720 solver.cpp:330] Iteration 78000, Testing net (#0)
I1211 15:35:27.020709 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:35:28.351972 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:35:28.403967 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5871
I1211 15:35:28.403967 16720 solver.cpp:397]     Test net output #1: loss = 1.58667 (* 1 = 1.58667 loss)
I1211 15:35:28.462994 16720 solver.cpp:218] Iteration 78000 (13.2365 iter/s, 7.5549s/100 iters), loss = 0.560835
I1211 15:35:28.462994 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:35:28.462994 16720 solver.cpp:237]     Train net output #1: loss = 0.560835 (* 1 = 0.560835 loss)
I1211 15:35:28.462994 16720 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1211 15:35:34.599483 16720 solver.cpp:218] Iteration 78100 (16.2976 iter/s, 6.13589s/100 iters), loss = 0.681065
I1211 15:35:34.599483 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:35:34.599483 16720 solver.cpp:237]     Train net output #1: loss = 0.681065 (* 1 = 0.681065 loss)
I1211 15:35:34.599483 16720 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1211 15:35:40.737982 16720 solver.cpp:218] Iteration 78200 (16.2912 iter/s, 6.13828s/100 iters), loss = 0.665156
I1211 15:35:40.737982 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:35:40.737982 16720 solver.cpp:237]     Train net output #1: loss = 0.665156 (* 1 = 0.665156 loss)
I1211 15:35:40.737982 16720 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1211 15:35:46.884421 16720 solver.cpp:218] Iteration 78300 (16.2694 iter/s, 6.14653s/100 iters), loss = 0.729876
I1211 15:35:46.885422 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:35:46.885422 16720 solver.cpp:237]     Train net output #1: loss = 0.729876 (* 1 = 0.729876 loss)
I1211 15:35:46.885422 16720 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1211 15:35:53.017853 16720 solver.cpp:218] Iteration 78400 (16.3072 iter/s, 6.13228s/100 iters), loss = 0.876379
I1211 15:35:53.017853 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:35:53.017853 16720 solver.cpp:237]     Train net output #1: loss = 0.876379 (* 1 = 0.876379 loss)
I1211 15:35:53.017853 16720 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1211 15:35:58.856361  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:35:59.099385 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_78500.caffemodel
I1211 15:35:59.114385 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_78500.solverstate
I1211 15:35:59.119391 16720 solver.cpp:330] Iteration 78500, Testing net (#0)
I1211 15:35:59.119891 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:36:00.450498 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:36:00.502497 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5493
I1211 15:36:00.502497 16720 solver.cpp:397]     Test net output #1: loss = 1.87309 (* 1 = 1.87309 loss)
I1211 15:36:00.561502 16720 solver.cpp:218] Iteration 78500 (13.2569 iter/s, 7.54323s/100 iters), loss = 0.628463
I1211 15:36:00.561502 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:36:00.561502 16720 solver.cpp:237]     Train net output #1: loss = 0.628463 (* 1 = 0.628463 loss)
I1211 15:36:00.561502 16720 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1211 15:36:06.700083 16720 solver.cpp:218] Iteration 78600 (16.2911 iter/s, 6.13833s/100 iters), loss = 0.809745
I1211 15:36:06.700083 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:36:06.700083 16720 solver.cpp:237]     Train net output #1: loss = 0.809745 (* 1 = 0.809745 loss)
I1211 15:36:06.700083 16720 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1211 15:36:12.836555 16720 solver.cpp:218] Iteration 78700 (16.2971 iter/s, 6.13605s/100 iters), loss = 0.694367
I1211 15:36:12.836555 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:36:12.836555 16720 solver.cpp:237]     Train net output #1: loss = 0.694367 (* 1 = 0.694367 loss)
I1211 15:36:12.836555 16720 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1211 15:36:18.976968 16720 solver.cpp:218] Iteration 78800 (16.2869 iter/s, 6.1399s/100 iters), loss = 0.792843
I1211 15:36:18.976968 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:36:18.976968 16720 solver.cpp:237]     Train net output #1: loss = 0.792843 (* 1 = 0.792843 loss)
I1211 15:36:18.976968 16720 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1211 15:36:25.115418 16720 solver.cpp:218] Iteration 78900 (16.2933 iter/s, 6.13751s/100 iters), loss = 0.830792
I1211 15:36:25.115418 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:36:25.115418 16720 solver.cpp:237]     Train net output #1: loss = 0.830792 (* 1 = 0.830792 loss)
I1211 15:36:25.115418 16720 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1211 15:36:30.959877  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:36:31.202893 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_79000.caffemodel
I1211 15:36:31.217895 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_79000.solverstate
I1211 15:36:31.223400 16720 solver.cpp:330] Iteration 79000, Testing net (#0)
I1211 15:36:31.223400 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:36:32.551990 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:36:32.604990 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5913
I1211 15:36:32.604990 16720 solver.cpp:397]     Test net output #1: loss = 1.56754 (* 1 = 1.56754 loss)
I1211 15:36:32.663995 16720 solver.cpp:218] Iteration 79000 (13.2484 iter/s, 7.54806s/100 iters), loss = 0.615247
I1211 15:36:32.663995 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:36:32.663995 16720 solver.cpp:237]     Train net output #1: loss = 0.615247 (* 1 = 0.615247 loss)
I1211 15:36:32.663995 16720 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1211 15:36:38.795445 16720 solver.cpp:218] Iteration 79100 (16.3091 iter/s, 6.13156s/100 iters), loss = 0.681189
I1211 15:36:38.795445 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:36:38.795445 16720 solver.cpp:237]     Train net output #1: loss = 0.681189 (* 1 = 0.681189 loss)
I1211 15:36:38.795445 16720 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1211 15:36:44.936913 16720 solver.cpp:218] Iteration 79200 (16.2848 iter/s, 6.14069s/100 iters), loss = 0.577704
I1211 15:36:44.936913 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:36:44.936913 16720 solver.cpp:237]     Train net output #1: loss = 0.577704 (* 1 = 0.577704 loss)
I1211 15:36:44.936913 16720 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1211 15:36:51.074396 16720 solver.cpp:218] Iteration 79300 (16.2933 iter/s, 6.13748s/100 iters), loss = 0.65714
I1211 15:36:51.074396 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:36:51.074396 16720 solver.cpp:237]     Train net output #1: loss = 0.65714 (* 1 = 0.65714 loss)
I1211 15:36:51.074396 16720 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1211 15:36:57.221323 16720 solver.cpp:218] Iteration 79400 (16.27 iter/s, 6.14628s/100 iters), loss = 0.880317
I1211 15:36:57.221323 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:36:57.221323 16720 solver.cpp:237]     Train net output #1: loss = 0.880317 (* 1 = 0.880317 loss)
I1211 15:36:57.221323 16720 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1211 15:37:03.055263  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:37:03.297276 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_79500.caffemodel
I1211 15:37:03.312275 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_79500.solverstate
I1211 15:37:03.317276 16720 solver.cpp:330] Iteration 79500, Testing net (#0)
I1211 15:37:03.317276 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:37:04.647383 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:37:04.699383 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5734
I1211 15:37:04.700383 16720 solver.cpp:397]     Test net output #1: loss = 1.67058 (* 1 = 1.67058 loss)
I1211 15:37:04.758388 16720 solver.cpp:218] Iteration 79500 (13.2689 iter/s, 7.5364s/100 iters), loss = 0.5123
I1211 15:37:04.758388 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:37:04.758388 16720 solver.cpp:237]     Train net output #1: loss = 0.5123 (* 1 = 0.5123 loss)
I1211 15:37:04.758388 16720 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1211 15:37:10.904860 16720 solver.cpp:218] Iteration 79600 (16.271 iter/s, 6.1459s/100 iters), loss = 0.621846
I1211 15:37:10.904860 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:37:10.904860 16720 solver.cpp:237]     Train net output #1: loss = 0.621846 (* 1 = 0.621846 loss)
I1211 15:37:10.904860 16720 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1211 15:37:17.048513 16720 solver.cpp:218] Iteration 79700 (16.2776 iter/s, 6.14342s/100 iters), loss = 0.65524
I1211 15:37:17.048513 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:37:17.048513 16720 solver.cpp:237]     Train net output #1: loss = 0.65524 (* 1 = 0.65524 loss)
I1211 15:37:17.048513 16720 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1211 15:37:23.186952 16720 solver.cpp:218] Iteration 79800 (16.2919 iter/s, 6.13803s/100 iters), loss = 0.745533
I1211 15:37:23.186952 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:37:23.186952 16720 solver.cpp:237]     Train net output #1: loss = 0.745533 (* 1 = 0.745533 loss)
I1211 15:37:23.186952 16720 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1211 15:37:29.316622 16720 solver.cpp:218] Iteration 79900 (16.3149 iter/s, 6.12938s/100 iters), loss = 0.915339
I1211 15:37:29.317123 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:37:29.317123 16720 solver.cpp:237]     Train net output #1: loss = 0.915339 (* 1 = 0.915339 loss)
I1211 15:37:29.317123 16720 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1211 15:37:35.156489  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:37:35.397502 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_80000.caffemodel
I1211 15:37:35.412508 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_80000.solverstate
I1211 15:37:35.416507 16720 solver.cpp:330] Iteration 80000, Testing net (#0)
I1211 15:37:35.416507 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:37:36.747602 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:37:36.800106 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5802
I1211 15:37:36.800106 16720 solver.cpp:397]     Test net output #1: loss = 1.62022 (* 1 = 1.62022 loss)
I1211 15:37:36.858608 16720 solver.cpp:218] Iteration 80000 (13.2606 iter/s, 7.54115s/100 iters), loss = 0.593148
I1211 15:37:36.858608 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:37:36.858608 16720 solver.cpp:237]     Train net output #1: loss = 0.593148 (* 1 = 0.593148 loss)
I1211 15:37:36.858608 16720 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1211 15:37:42.984119 16720 solver.cpp:218] Iteration 80100 (16.325 iter/s, 6.12558s/100 iters), loss = 0.721691
I1211 15:37:42.984119 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:37:42.984119 16720 solver.cpp:237]     Train net output #1: loss = 0.721691 (* 1 = 0.721691 loss)
I1211 15:37:42.984119 16720 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1211 15:37:49.116544 16720 solver.cpp:218] Iteration 80200 (16.309 iter/s, 6.1316s/100 iters), loss = 0.679821
I1211 15:37:49.116544 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:37:49.116544 16720 solver.cpp:237]     Train net output #1: loss = 0.679821 (* 1 = 0.679821 loss)
I1211 15:37:49.116544 16720 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1211 15:37:55.255029 16720 solver.cpp:218] Iteration 80300 (16.29 iter/s, 6.13874s/100 iters), loss = 0.904543
I1211 15:37:55.255029 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:37:55.255029 16720 solver.cpp:237]     Train net output #1: loss = 0.904543 (* 1 = 0.904543 loss)
I1211 15:37:55.255029 16720 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1211 15:38:01.390425 16720 solver.cpp:218] Iteration 80400 (16.301 iter/s, 6.13458s/100 iters), loss = 0.815381
I1211 15:38:01.390425 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:38:01.390425 16720 solver.cpp:237]     Train net output #1: loss = 0.815381 (* 1 = 0.815381 loss)
I1211 15:38:01.390425 16720 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1211 15:38:07.230859  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:38:07.471871 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_80500.caffemodel
I1211 15:38:07.486871 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_80500.solverstate
I1211 15:38:07.491871 16720 solver.cpp:330] Iteration 80500, Testing net (#0)
I1211 15:38:07.491871 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:38:08.822969 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:38:08.874963 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5459
I1211 15:38:08.874963 16720 solver.cpp:397]     Test net output #1: loss = 1.85523 (* 1 = 1.85523 loss)
I1211 15:38:08.933972 16720 solver.cpp:218] Iteration 80500 (13.257 iter/s, 7.54317s/100 iters), loss = 0.603971
I1211 15:38:08.933972 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:38:08.933972 16720 solver.cpp:237]     Train net output #1: loss = 0.603971 (* 1 = 0.603971 loss)
I1211 15:38:08.933972 16720 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1211 15:38:15.078420 16720 solver.cpp:218] Iteration 80600 (16.2753 iter/s, 6.14426s/100 iters), loss = 0.741785
I1211 15:38:15.078420 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:38:15.078420 16720 solver.cpp:237]     Train net output #1: loss = 0.741785 (* 1 = 0.741785 loss)
I1211 15:38:15.078420 16720 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1211 15:38:21.229848 16720 solver.cpp:218] Iteration 80700 (16.2596 iter/s, 6.15023s/100 iters), loss = 0.655342
I1211 15:38:21.229848 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:38:21.229848 16720 solver.cpp:237]     Train net output #1: loss = 0.655342 (* 1 = 0.655342 loss)
I1211 15:38:21.229848 16720 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1211 15:38:27.376296 16720 solver.cpp:218] Iteration 80800 (16.2709 iter/s, 6.14593s/100 iters), loss = 0.674196
I1211 15:38:27.376296 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:38:27.376296 16720 solver.cpp:237]     Train net output #1: loss = 0.674196 (* 1 = 0.674196 loss)
I1211 15:38:27.376296 16720 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1211 15:38:33.517657 16720 solver.cpp:218] Iteration 80900 (16.282 iter/s, 6.14177s/100 iters), loss = 0.889769
I1211 15:38:33.517657 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:38:33.517657 16720 solver.cpp:237]     Train net output #1: loss = 0.889769 (* 1 = 0.889769 loss)
I1211 15:38:33.517657 16720 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1211 15:38:39.349103  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:38:39.589114 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_81000.caffemodel
I1211 15:38:39.605619 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_81000.solverstate
I1211 15:38:39.610121 16720 solver.cpp:330] Iteration 81000, Testing net (#0)
I1211 15:38:39.610620 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:38:40.941223 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:38:40.994225 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5894
I1211 15:38:40.994225 16720 solver.cpp:397]     Test net output #1: loss = 1.5645 (* 1 = 1.5645 loss)
I1211 15:38:41.053231 16720 solver.cpp:218] Iteration 81000 (13.2726 iter/s, 7.53435s/100 iters), loss = 0.71259
I1211 15:38:41.053231 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:38:41.053231 16720 solver.cpp:237]     Train net output #1: loss = 0.71259 (* 1 = 0.71259 loss)
I1211 15:38:41.053231 16720 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1211 15:38:47.201154 16720 solver.cpp:218] Iteration 81100 (16.2663 iter/s, 6.14767s/100 iters), loss = 0.746633
I1211 15:38:47.201154 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:38:47.201154 16720 solver.cpp:237]     Train net output #1: loss = 0.746633 (* 1 = 0.746633 loss)
I1211 15:38:47.201154 16720 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1211 15:38:53.343138 16720 solver.cpp:218] Iteration 81200 (16.282 iter/s, 6.14175s/100 iters), loss = 0.594794
I1211 15:38:53.343138 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:38:53.343138 16720 solver.cpp:237]     Train net output #1: loss = 0.594794 (* 1 = 0.594794 loss)
I1211 15:38:53.343138 16720 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1211 15:38:59.481592 16720 solver.cpp:218] Iteration 81300 (16.2928 iter/s, 6.1377s/100 iters), loss = 0.68453
I1211 15:38:59.481592 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:38:59.481592 16720 solver.cpp:237]     Train net output #1: loss = 0.68453 (* 1 = 0.68453 loss)
I1211 15:38:59.481592 16720 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1211 15:39:05.623049 16720 solver.cpp:218] Iteration 81400 (16.2821 iter/s, 6.14171s/100 iters), loss = 0.787328
I1211 15:39:05.623049 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:39:05.623049 16720 solver.cpp:237]     Train net output #1: loss = 0.787328 (* 1 = 0.787328 loss)
I1211 15:39:05.623049 16720 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1211 15:39:11.463634  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:39:11.705649 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_81500.caffemodel
I1211 15:39:11.719652 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_81500.solverstate
I1211 15:39:11.724653 16720 solver.cpp:330] Iteration 81500, Testing net (#0)
I1211 15:39:11.724653 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:39:13.052738 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:39:13.105242 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6012
I1211 15:39:13.105242 16720 solver.cpp:397]     Test net output #1: loss = 1.4808 (* 1 = 1.4808 loss)
I1211 15:39:13.163743 16720 solver.cpp:218] Iteration 81500 (13.2628 iter/s, 7.53991s/100 iters), loss = 0.467344
I1211 15:39:13.163743 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:39:13.163743 16720 solver.cpp:237]     Train net output #1: loss = 0.467344 (* 1 = 0.467344 loss)
I1211 15:39:13.163743 16720 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1211 15:39:19.312762 16720 solver.cpp:218] Iteration 81600 (16.2653 iter/s, 6.14805s/100 iters), loss = 0.642685
I1211 15:39:19.312762 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:39:19.312762 16720 solver.cpp:237]     Train net output #1: loss = 0.642685 (* 1 = 0.642685 loss)
I1211 15:39:19.312762 16720 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1211 15:39:25.452859 16720 solver.cpp:218] Iteration 81700 (16.2876 iter/s, 6.13963s/100 iters), loss = 0.592803
I1211 15:39:25.452859 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:39:25.452859 16720 solver.cpp:237]     Train net output #1: loss = 0.592803 (* 1 = 0.592803 loss)
I1211 15:39:25.452859 16720 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1211 15:39:31.593346 16720 solver.cpp:218] Iteration 81800 (16.2857 iter/s, 6.14034s/100 iters), loss = 0.693379
I1211 15:39:31.593346 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:39:31.593346 16720 solver.cpp:237]     Train net output #1: loss = 0.693379 (* 1 = 0.693379 loss)
I1211 15:39:31.593346 16720 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1211 15:39:37.739914 16720 solver.cpp:218] Iteration 81900 (16.2709 iter/s, 6.14595s/100 iters), loss = 0.837933
I1211 15:39:37.739914 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:39:37.739914 16720 solver.cpp:237]     Train net output #1: loss = 0.837933 (* 1 = 0.837933 loss)
I1211 15:39:37.739914 16720 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1211 15:39:43.588351  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:39:43.831372 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_82000.caffemodel
I1211 15:39:43.846369 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_82000.solverstate
I1211 15:39:43.850369 16720 solver.cpp:330] Iteration 82000, Testing net (#0)
I1211 15:39:43.850369 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:39:45.182495 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:39:45.234501 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5831
I1211 15:39:45.234501 16720 solver.cpp:397]     Test net output #1: loss = 1.60438 (* 1 = 1.60438 loss)
I1211 15:39:45.293499 16720 solver.cpp:218] Iteration 82000 (13.2396 iter/s, 7.55312s/100 iters), loss = 0.496114
I1211 15:39:45.293499 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:39:45.293499 16720 solver.cpp:237]     Train net output #1: loss = 0.496114 (* 1 = 0.496114 loss)
I1211 15:39:45.293499 16720 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1211 15:39:51.426950 16720 solver.cpp:218] Iteration 82100 (16.3051 iter/s, 6.13305s/100 iters), loss = 0.794158
I1211 15:39:51.426950 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:39:51.426950 16720 solver.cpp:237]     Train net output #1: loss = 0.794158 (* 1 = 0.794158 loss)
I1211 15:39:51.426950 16720 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1211 15:39:57.574376 16720 solver.cpp:218] Iteration 82200 (16.2681 iter/s, 6.147s/100 iters), loss = 0.681928
I1211 15:39:57.574376 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:39:57.574376 16720 solver.cpp:237]     Train net output #1: loss = 0.681928 (* 1 = 0.681928 loss)
I1211 15:39:57.574376 16720 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1211 15:40:03.710222 16720 solver.cpp:218] Iteration 82300 (16.2985 iter/s, 6.13553s/100 iters), loss = 0.740076
I1211 15:40:03.710222 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:40:03.710222 16720 solver.cpp:237]     Train net output #1: loss = 0.740076 (* 1 = 0.740076 loss)
I1211 15:40:03.710222 16720 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1211 15:40:09.847287 16720 solver.cpp:218] Iteration 82400 (16.2963 iter/s, 6.13636s/100 iters), loss = 0.924086
I1211 15:40:09.847287 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 15:40:09.847287 16720 solver.cpp:237]     Train net output #1: loss = 0.924086 (* 1 = 0.924086 loss)
I1211 15:40:09.847287 16720 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1211 15:40:15.683181  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:40:15.925240 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_82500.caffemodel
I1211 15:40:15.940260 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_82500.solverstate
I1211 15:40:15.945272 16720 solver.cpp:330] Iteration 82500, Testing net (#0)
I1211 15:40:15.945272 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:40:17.276532 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:40:17.328588 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5815
I1211 15:40:17.328588 16720 solver.cpp:397]     Test net output #1: loss = 1.60489 (* 1 = 1.60489 loss)
I1211 15:40:17.386584 16720 solver.cpp:218] Iteration 82500 (13.2638 iter/s, 7.53931s/100 iters), loss = 0.584214
I1211 15:40:17.386584 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:40:17.386584 16720 solver.cpp:237]     Train net output #1: loss = 0.584214 (* 1 = 0.584214 loss)
I1211 15:40:17.386584 16720 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1211 15:40:23.518205 16720 solver.cpp:218] Iteration 82600 (16.3112 iter/s, 6.13076s/100 iters), loss = 0.766789
I1211 15:40:23.518205 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:40:23.518205 16720 solver.cpp:237]     Train net output #1: loss = 0.766789 (* 1 = 0.766789 loss)
I1211 15:40:23.518205 16720 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1211 15:40:29.659211 16720 solver.cpp:218] Iteration 82700 (16.2836 iter/s, 6.14114s/100 iters), loss = 0.682573
I1211 15:40:29.659211 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:40:29.659211 16720 solver.cpp:237]     Train net output #1: loss = 0.682573 (* 1 = 0.682573 loss)
I1211 15:40:29.659211 16720 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1211 15:40:35.804795 16720 solver.cpp:218] Iteration 82800 (16.2727 iter/s, 6.14526s/100 iters), loss = 0.71548
I1211 15:40:35.804795 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:40:35.804795 16720 solver.cpp:237]     Train net output #1: loss = 0.71548 (* 1 = 0.71548 loss)
I1211 15:40:35.804795 16720 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1211 15:40:41.947234 16720 solver.cpp:218] Iteration 82900 (16.2816 iter/s, 6.14189s/100 iters), loss = 0.825628
I1211 15:40:41.947234 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:40:41.947234 16720 solver.cpp:237]     Train net output #1: loss = 0.825628 (* 1 = 0.825628 loss)
I1211 15:40:41.947234 16720 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1211 15:40:47.787677  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:40:48.030689 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_83000.caffemodel
I1211 15:40:48.045692 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_83000.solverstate
I1211 15:40:48.049692 16720 solver.cpp:330] Iteration 83000, Testing net (#0)
I1211 15:40:48.049692 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:40:49.383795 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:40:49.436800 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5796
I1211 15:40:49.436800 16720 solver.cpp:397]     Test net output #1: loss = 1.62236 (* 1 = 1.62236 loss)
I1211 15:40:49.495801 16720 solver.cpp:218] Iteration 83000 (13.2485 iter/s, 7.54801s/100 iters), loss = 0.594157
I1211 15:40:49.495801 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:40:49.495801 16720 solver.cpp:237]     Train net output #1: loss = 0.594157 (* 1 = 0.594157 loss)
I1211 15:40:49.495801 16720 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1211 15:40:55.636433 16720 solver.cpp:218] Iteration 83100 (16.2863 iter/s, 6.14013s/100 iters), loss = 0.774172
I1211 15:40:55.636433 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:40:55.636433 16720 solver.cpp:237]     Train net output #1: loss = 0.774172 (* 1 = 0.774172 loss)
I1211 15:40:55.636433 16720 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1211 15:41:01.790899 16720 solver.cpp:218] Iteration 83200 (16.2499 iter/s, 6.15388s/100 iters), loss = 0.782927
I1211 15:41:01.790899 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:41:01.790899 16720 solver.cpp:237]     Train net output #1: loss = 0.782927 (* 1 = 0.782927 loss)
I1211 15:41:01.790899 16720 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1211 15:41:07.924304 16720 solver.cpp:218] Iteration 83300 (16.3057 iter/s, 6.13283s/100 iters), loss = 0.732488
I1211 15:41:07.924304 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:41:07.924304 16720 solver.cpp:237]     Train net output #1: loss = 0.732488 (* 1 = 0.732488 loss)
I1211 15:41:07.924304 16720 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1211 15:41:14.059041 16720 solver.cpp:218] Iteration 83400 (16.3011 iter/s, 6.13455s/100 iters), loss = 0.706929
I1211 15:41:14.059041 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:41:14.059041 16720 solver.cpp:237]     Train net output #1: loss = 0.706929 (* 1 = 0.706929 loss)
I1211 15:41:14.059041 16720 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1211 15:41:19.887897  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:41:20.128949 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_83500.caffemodel
I1211 15:41:20.143934 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_83500.solverstate
I1211 15:41:20.148938 16720 solver.cpp:330] Iteration 83500, Testing net (#0)
I1211 15:41:20.148938 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:41:21.478379 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:41:21.531419 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5831
I1211 15:41:21.531419 16720 solver.cpp:397]     Test net output #1: loss = 1.6264 (* 1 = 1.6264 loss)
I1211 15:41:21.590421 16720 solver.cpp:218] Iteration 83500 (13.2793 iter/s, 7.53052s/100 iters), loss = 0.557995
I1211 15:41:21.590421 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:41:21.590421 16720 solver.cpp:237]     Train net output #1: loss = 0.557995 (* 1 = 0.557995 loss)
I1211 15:41:21.590421 16720 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1211 15:41:27.721774 16720 solver.cpp:218] Iteration 83600 (16.3092 iter/s, 6.13151s/100 iters), loss = 0.721831
I1211 15:41:27.721774 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:41:27.721774 16720 solver.cpp:237]     Train net output #1: loss = 0.721831 (* 1 = 0.721831 loss)
I1211 15:41:27.721774 16720 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1211 15:41:33.860278 16720 solver.cpp:218] Iteration 83700 (16.2913 iter/s, 6.13824s/100 iters), loss = 0.669188
I1211 15:41:33.860278 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:41:33.860278 16720 solver.cpp:237]     Train net output #1: loss = 0.669188 (* 1 = 0.669188 loss)
I1211 15:41:33.860278 16720 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1211 15:41:39.991780 16720 solver.cpp:218] Iteration 83800 (16.3123 iter/s, 6.13034s/100 iters), loss = 0.801685
I1211 15:41:39.991780 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:41:39.991780 16720 solver.cpp:237]     Train net output #1: loss = 0.801685 (* 1 = 0.801685 loss)
I1211 15:41:39.991780 16720 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1211 15:41:46.121311 16720 solver.cpp:218] Iteration 83900 (16.3152 iter/s, 6.12925s/100 iters), loss = 0.718693
I1211 15:41:46.121311 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:41:46.121311 16720 solver.cpp:237]     Train net output #1: loss = 0.718693 (* 1 = 0.718693 loss)
I1211 15:41:46.121311 16720 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1211 15:41:51.963727  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:41:52.205749 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_84000.caffemodel
I1211 15:41:52.219748 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_84000.solverstate
I1211 15:41:52.224750 16720 solver.cpp:330] Iteration 84000, Testing net (#0)
I1211 15:41:52.224750 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:41:53.559860 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:41:53.611863 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5573
I1211 15:41:53.611863 16720 solver.cpp:397]     Test net output #1: loss = 1.73196 (* 1 = 1.73196 loss)
I1211 15:41:53.670868 16720 solver.cpp:218] Iteration 84000 (13.2463 iter/s, 7.54928s/100 iters), loss = 0.695143
I1211 15:41:53.670868 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:41:53.670868 16720 solver.cpp:237]     Train net output #1: loss = 0.695143 (* 1 = 0.695143 loss)
I1211 15:41:53.670868 16720 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1211 15:41:59.809319 16720 solver.cpp:218] Iteration 84100 (16.2922 iter/s, 6.13789s/100 iters), loss = 0.68077
I1211 15:41:59.809319 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:41:59.809319 16720 solver.cpp:237]     Train net output #1: loss = 0.68077 (* 1 = 0.68077 loss)
I1211 15:41:59.809319 16720 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1211 15:42:05.943773 16720 solver.cpp:218] Iteration 84200 (16.3026 iter/s, 6.13398s/100 iters), loss = 0.757126
I1211 15:42:05.943773 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:42:05.943773 16720 solver.cpp:237]     Train net output #1: loss = 0.757126 (* 1 = 0.757126 loss)
I1211 15:42:05.943773 16720 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1211 15:42:12.089257 16720 solver.cpp:218] Iteration 84300 (16.2719 iter/s, 6.14557s/100 iters), loss = 0.746481
I1211 15:42:12.089257 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:42:12.089257 16720 solver.cpp:237]     Train net output #1: loss = 0.746481 (* 1 = 0.746481 loss)
I1211 15:42:12.089257 16720 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1211 15:42:18.236232 16720 solver.cpp:218] Iteration 84400 (16.2706 iter/s, 6.14606s/100 iters), loss = 0.782009
I1211 15:42:18.236232 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:42:18.236232 16720 solver.cpp:237]     Train net output #1: loss = 0.782009 (* 1 = 0.782009 loss)
I1211 15:42:18.236232 16720 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1211 15:42:24.078173  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:42:24.320183 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_84500.caffemodel
I1211 15:42:24.340698 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_84500.solverstate
I1211 15:42:24.345700 16720 solver.cpp:330] Iteration 84500, Testing net (#0)
I1211 15:42:24.346199 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:42:25.677297 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:42:25.729297 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5896
I1211 15:42:25.729297 16720 solver.cpp:397]     Test net output #1: loss = 1.56378 (* 1 = 1.56378 loss)
I1211 15:42:25.788318 16720 solver.cpp:218] Iteration 84500 (13.2418 iter/s, 7.55184s/100 iters), loss = 0.524695
I1211 15:42:25.788318 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:42:25.788318 16720 solver.cpp:237]     Train net output #1: loss = 0.524695 (* 1 = 0.524695 loss)
I1211 15:42:25.788318 16720 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1211 15:42:31.934764 16720 solver.cpp:218] Iteration 84600 (16.2709 iter/s, 6.14593s/100 iters), loss = 0.701143
I1211 15:42:31.934764 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:42:31.934764 16720 solver.cpp:237]     Train net output #1: loss = 0.701143 (* 1 = 0.701143 loss)
I1211 15:42:31.934764 16720 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1211 15:42:38.073588 16720 solver.cpp:218] Iteration 84700 (16.291 iter/s, 6.13837s/100 iters), loss = 0.626869
I1211 15:42:38.073588 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:42:38.073588 16720 solver.cpp:237]     Train net output #1: loss = 0.626869 (* 1 = 0.626869 loss)
I1211 15:42:38.073588 16720 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1211 15:42:44.219393 16720 solver.cpp:218] Iteration 84800 (16.2734 iter/s, 6.14499s/100 iters), loss = 0.618931
I1211 15:42:44.219393 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:42:44.219393 16720 solver.cpp:237]     Train net output #1: loss = 0.618931 (* 1 = 0.618931 loss)
I1211 15:42:44.219393 16720 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1211 15:42:50.360915 16720 solver.cpp:218] Iteration 84900 (16.2827 iter/s, 6.1415s/100 iters), loss = 0.744725
I1211 15:42:50.360915 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:42:50.360915 16720 solver.cpp:237]     Train net output #1: loss = 0.744725 (* 1 = 0.744725 loss)
I1211 15:42:50.360915 16720 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1211 15:42:56.200409  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:42:56.442432 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_85000.caffemodel
I1211 15:42:56.458439 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_85000.solverstate
I1211 15:42:56.462440 16720 solver.cpp:330] Iteration 85000, Testing net (#0)
I1211 15:42:56.462440 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:42:57.792518 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:42:57.845021 16720 solver.cpp:397]     Test net output #0: accuracy = 0.589
I1211 15:42:57.845021 16720 solver.cpp:397]     Test net output #1: loss = 1.59111 (* 1 = 1.59111 loss)
I1211 15:42:57.903522 16720 solver.cpp:218] Iteration 85000 (13.2585 iter/s, 7.54231s/100 iters), loss = 0.755646
I1211 15:42:57.903522 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:42:57.903522 16720 solver.cpp:237]     Train net output #1: loss = 0.755646 (* 1 = 0.755646 loss)
I1211 15:42:57.903522 16720 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1211 15:43:04.033937 16720 solver.cpp:218] Iteration 85100 (16.3146 iter/s, 6.12947s/100 iters), loss = 0.773039
I1211 15:43:04.033937 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:43:04.033937 16720 solver.cpp:237]     Train net output #1: loss = 0.773039 (* 1 = 0.773039 loss)
I1211 15:43:04.033937 16720 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1211 15:43:10.164389 16720 solver.cpp:218] Iteration 85200 (16.3112 iter/s, 6.13076s/100 iters), loss = 0.570858
I1211 15:43:10.164389 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:43:10.164389 16720 solver.cpp:237]     Train net output #1: loss = 0.570858 (* 1 = 0.570858 loss)
I1211 15:43:10.164389 16720 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1211 15:43:16.297891 16720 solver.cpp:218] Iteration 85300 (16.3056 iter/s, 6.13286s/100 iters), loss = 0.821073
I1211 15:43:16.297891 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:43:16.297891 16720 solver.cpp:237]     Train net output #1: loss = 0.821073 (* 1 = 0.821073 loss)
I1211 15:43:16.297891 16720 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1211 15:43:22.443884 16720 solver.cpp:218] Iteration 85400 (16.2735 iter/s, 6.14496s/100 iters), loss = 0.809312
I1211 15:43:22.443884 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:43:22.443884 16720 solver.cpp:237]     Train net output #1: loss = 0.809312 (* 1 = 0.809312 loss)
I1211 15:43:22.443884 16720 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1211 15:43:28.272714  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:43:28.514003 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_85500.caffemodel
I1211 15:43:28.530004 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_85500.solverstate
I1211 15:43:28.534003 16720 solver.cpp:330] Iteration 85500, Testing net (#0)
I1211 15:43:28.534003 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:43:29.864998 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:43:29.916983 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5553
I1211 15:43:29.916983 16720 solver.cpp:397]     Test net output #1: loss = 1.8431 (* 1 = 1.8431 loss)
I1211 15:43:29.975625 16720 solver.cpp:218] Iteration 85500 (13.2768 iter/s, 7.53193s/100 iters), loss = 0.672211
I1211 15:43:29.975625 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:43:29.975625 16720 solver.cpp:237]     Train net output #1: loss = 0.672211 (* 1 = 0.672211 loss)
I1211 15:43:29.975625 16720 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1211 15:43:36.110090 16720 solver.cpp:218] Iteration 85600 (16.3042 iter/s, 6.13337s/100 iters), loss = 0.723694
I1211 15:43:36.110090 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:43:36.110090 16720 solver.cpp:237]     Train net output #1: loss = 0.723694 (* 1 = 0.723694 loss)
I1211 15:43:36.110090 16720 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1211 15:43:42.242538 16720 solver.cpp:218] Iteration 85700 (16.3054 iter/s, 6.13293s/100 iters), loss = 0.619214
I1211 15:43:42.242538 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:43:42.243538 16720 solver.cpp:237]     Train net output #1: loss = 0.619214 (* 1 = 0.619214 loss)
I1211 15:43:42.243538 16720 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1211 15:43:48.382985 16720 solver.cpp:218] Iteration 85800 (16.289 iter/s, 6.13912s/100 iters), loss = 0.858035
I1211 15:43:48.382985 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:43:48.382985 16720 solver.cpp:237]     Train net output #1: loss = 0.858035 (* 1 = 0.858035 loss)
I1211 15:43:48.382985 16720 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1211 15:43:54.524482 16720 solver.cpp:218] Iteration 85900 (16.2825 iter/s, 6.14155s/100 iters), loss = 0.683119
I1211 15:43:54.524482 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:43:54.524482 16720 solver.cpp:237]     Train net output #1: loss = 0.683119 (* 1 = 0.683119 loss)
I1211 15:43:54.524482 16720 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1211 15:44:00.367980  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:44:00.608994 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_86000.caffemodel
I1211 15:44:00.623994 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_86000.solverstate
I1211 15:44:00.628995 16720 solver.cpp:330] Iteration 86000, Testing net (#0)
I1211 15:44:00.628995 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:44:01.962648 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:44:02.015151 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5861
I1211 15:44:02.015151 16720 solver.cpp:397]     Test net output #1: loss = 1.58766 (* 1 = 1.58766 loss)
I1211 15:44:02.074154 16720 solver.cpp:218] Iteration 86000 (13.2472 iter/s, 7.54876s/100 iters), loss = 0.576982
I1211 15:44:02.074154 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 15:44:02.074154 16720 solver.cpp:237]     Train net output #1: loss = 0.576982 (* 1 = 0.576982 loss)
I1211 15:44:02.074154 16720 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1211 15:44:08.218592 16720 solver.cpp:218] Iteration 86100 (16.2744 iter/s, 6.14461s/100 iters), loss = 0.853262
I1211 15:44:08.218592 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:44:08.218592 16720 solver.cpp:237]     Train net output #1: loss = 0.853262 (* 1 = 0.853262 loss)
I1211 15:44:08.218592 16720 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1211 15:44:14.365259 16720 solver.cpp:218] Iteration 86200 (16.2716 iter/s, 6.14567s/100 iters), loss = 0.649025
I1211 15:44:14.365259 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:44:14.365259 16720 solver.cpp:237]     Train net output #1: loss = 0.649025 (* 1 = 0.649025 loss)
I1211 15:44:14.365259 16720 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1211 15:44:20.511868 16720 solver.cpp:218] Iteration 86300 (16.2686 iter/s, 6.14679s/100 iters), loss = 0.783752
I1211 15:44:20.511868 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:44:20.511868 16720 solver.cpp:237]     Train net output #1: loss = 0.783752 (* 1 = 0.783752 loss)
I1211 15:44:20.511868 16720 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1211 15:44:26.658797 16720 solver.cpp:218] Iteration 86400 (16.2712 iter/s, 6.14585s/100 iters), loss = 0.856698
I1211 15:44:26.658797 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:44:26.658797 16720 solver.cpp:237]     Train net output #1: loss = 0.856698 (* 1 = 0.856698 loss)
I1211 15:44:26.658797 16720 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1211 15:44:32.491765  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:44:32.733788 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_86500.caffemodel
I1211 15:44:32.748787 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_86500.solverstate
I1211 15:44:32.753788 16720 solver.cpp:330] Iteration 86500, Testing net (#0)
I1211 15:44:32.754294 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:44:34.088920 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:44:34.140928 16720 solver.cpp:397]     Test net output #0: accuracy = 0.601
I1211 15:44:34.140928 16720 solver.cpp:397]     Test net output #1: loss = 1.50546 (* 1 = 1.50546 loss)
I1211 15:44:34.199935 16720 solver.cpp:218] Iteration 86500 (13.2601 iter/s, 7.54142s/100 iters), loss = 0.537113
I1211 15:44:34.199935 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:44:34.199935 16720 solver.cpp:237]     Train net output #1: loss = 0.537113 (* 1 = 0.537113 loss)
I1211 15:44:34.199935 16720 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1211 15:44:40.347407 16720 solver.cpp:218] Iteration 86600 (16.2679 iter/s, 6.14708s/100 iters), loss = 0.806692
I1211 15:44:40.348408 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:44:40.348408 16720 solver.cpp:237]     Train net output #1: loss = 0.806692 (* 1 = 0.806692 loss)
I1211 15:44:40.348408 16720 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1211 15:44:46.490869 16720 solver.cpp:218] Iteration 86700 (16.2788 iter/s, 6.14295s/100 iters), loss = 0.634484
I1211 15:44:46.490869 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:44:46.491869 16720 solver.cpp:237]     Train net output #1: loss = 0.634484 (* 1 = 0.634484 loss)
I1211 15:44:46.491869 16720 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1211 15:44:52.635313 16720 solver.cpp:218] Iteration 86800 (16.2777 iter/s, 6.14337s/100 iters), loss = 0.655311
I1211 15:44:52.635313 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:44:52.635313 16720 solver.cpp:237]     Train net output #1: loss = 0.655311 (* 1 = 0.655311 loss)
I1211 15:44:52.635313 16720 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1211 15:44:58.777778 16720 solver.cpp:218] Iteration 86900 (16.2798 iter/s, 6.14259s/100 iters), loss = 0.701975
I1211 15:44:58.777778 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:44:58.777778 16720 solver.cpp:237]     Train net output #1: loss = 0.701975 (* 1 = 0.701975 loss)
I1211 15:44:58.777778 16720 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1211 15:45:04.615244  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:45:04.858758 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_87000.caffemodel
I1211 15:45:04.873262 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_87000.solverstate
I1211 15:45:04.878262 16720 solver.cpp:330] Iteration 87000, Testing net (#0)
I1211 15:45:04.878262 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:45:06.210361 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:45:06.262862 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5869
I1211 15:45:06.262862 16720 solver.cpp:397]     Test net output #1: loss = 1.58465 (* 1 = 1.58465 loss)
I1211 15:45:06.321365 16720 solver.cpp:218] Iteration 87000 (13.2575 iter/s, 7.54288s/100 iters), loss = 0.617141
I1211 15:45:06.321365 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:45:06.321365 16720 solver.cpp:237]     Train net output #1: loss = 0.617141 (* 1 = 0.617141 loss)
I1211 15:45:06.321365 16720 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1211 15:45:12.464383 16720 solver.cpp:218] Iteration 87100 (16.2813 iter/s, 6.142s/100 iters), loss = 0.713582
I1211 15:45:12.464383 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:45:12.464383 16720 solver.cpp:237]     Train net output #1: loss = 0.713582 (* 1 = 0.713582 loss)
I1211 15:45:12.464383 16720 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1211 15:45:18.599050 16720 solver.cpp:218] Iteration 87200 (16.3002 iter/s, 6.13488s/100 iters), loss = 0.703472
I1211 15:45:18.599050 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:45:18.599050 16720 solver.cpp:237]     Train net output #1: loss = 0.703472 (* 1 = 0.703472 loss)
I1211 15:45:18.599050 16720 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1211 15:45:24.746225 16720 solver.cpp:218] Iteration 87300 (16.2687 iter/s, 6.14678s/100 iters), loss = 0.701882
I1211 15:45:24.746225 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:45:24.746225 16720 solver.cpp:237]     Train net output #1: loss = 0.701882 (* 1 = 0.701882 loss)
I1211 15:45:24.746225 16720 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1211 15:45:30.894199 16720 solver.cpp:218] Iteration 87400 (16.2684 iter/s, 6.14688s/100 iters), loss = 0.754145
I1211 15:45:30.894199 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:45:30.894199 16720 solver.cpp:237]     Train net output #1: loss = 0.754145 (* 1 = 0.754145 loss)
I1211 15:45:30.894199 16720 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1211 15:45:36.724663  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:45:36.966689 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_87500.caffemodel
I1211 15:45:36.981693 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_87500.solverstate
I1211 15:45:36.985693 16720 solver.cpp:330] Iteration 87500, Testing net (#0)
I1211 15:45:36.985693 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:45:38.317800 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:45:38.370802 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5704
I1211 15:45:38.370802 16720 solver.cpp:397]     Test net output #1: loss = 1.71048 (* 1 = 1.71048 loss)
I1211 15:45:38.429805 16720 solver.cpp:218] Iteration 87500 (13.2708 iter/s, 7.53535s/100 iters), loss = 0.66591
I1211 15:45:38.429805 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:45:38.429805 16720 solver.cpp:237]     Train net output #1: loss = 0.66591 (* 1 = 0.66591 loss)
I1211 15:45:38.429805 16720 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1211 15:45:44.577739 16720 solver.cpp:218] Iteration 87600 (16.2664 iter/s, 6.14763s/100 iters), loss = 0.578528
I1211 15:45:44.577739 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:45:44.577739 16720 solver.cpp:237]     Train net output #1: loss = 0.578528 (* 1 = 0.578528 loss)
I1211 15:45:44.577739 16720 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1211 15:45:50.735064 16720 solver.cpp:218] Iteration 87700 (16.2424 iter/s, 6.15673s/100 iters), loss = 0.682068
I1211 15:45:50.735064 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:45:50.735064 16720 solver.cpp:237]     Train net output #1: loss = 0.682068 (* 1 = 0.682068 loss)
I1211 15:45:50.735064 16720 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1211 15:45:56.879526 16720 solver.cpp:218] Iteration 87800 (16.2757 iter/s, 6.14414s/100 iters), loss = 0.743374
I1211 15:45:56.879526 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:45:56.879526 16720 solver.cpp:237]     Train net output #1: loss = 0.743374 (* 1 = 0.743374 loss)
I1211 15:45:56.879526 16720 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1211 15:46:03.020961 16720 solver.cpp:218] Iteration 87900 (16.283 iter/s, 6.14139s/100 iters), loss = 0.771707
I1211 15:46:03.020961 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:46:03.020961 16720 solver.cpp:237]     Train net output #1: loss = 0.771707 (* 1 = 0.771707 loss)
I1211 15:46:03.020961 16720 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1211 15:46:08.869907  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:46:09.112422 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_88000.caffemodel
I1211 15:46:09.127423 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_88000.solverstate
I1211 15:46:09.132423 16720 solver.cpp:330] Iteration 88000, Testing net (#0)
I1211 15:46:09.132423 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:46:10.461506 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:46:10.514513 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5593
I1211 15:46:10.514513 16720 solver.cpp:397]     Test net output #1: loss = 1.77335 (* 1 = 1.77335 loss)
I1211 15:46:10.573514 16720 solver.cpp:218] Iteration 88000 (13.2425 iter/s, 7.55145s/100 iters), loss = 0.662697
I1211 15:46:10.573514 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:46:10.573514 16720 solver.cpp:237]     Train net output #1: loss = 0.662697 (* 1 = 0.662697 loss)
I1211 15:46:10.573514 16720 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1211 15:46:16.717937 16720 solver.cpp:218] Iteration 88100 (16.2756 iter/s, 6.14418s/100 iters), loss = 0.706086
I1211 15:46:16.717937 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:46:16.717937 16720 solver.cpp:237]     Train net output #1: loss = 0.706086 (* 1 = 0.706086 loss)
I1211 15:46:16.717937 16720 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1211 15:46:22.868353 16720 solver.cpp:218] Iteration 88200 (16.259 iter/s, 6.15045s/100 iters), loss = 0.610402
I1211 15:46:22.868353 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:46:22.868353 16720 solver.cpp:237]     Train net output #1: loss = 0.610402 (* 1 = 0.610402 loss)
I1211 15:46:22.868353 16720 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1211 15:46:29.012785 16720 solver.cpp:218] Iteration 88300 (16.2755 iter/s, 6.14421s/100 iters), loss = 0.5736
I1211 15:46:29.013785 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:46:29.013785 16720 solver.cpp:237]     Train net output #1: loss = 0.5736 (* 1 = 0.5736 loss)
I1211 15:46:29.013785 16720 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1211 15:46:35.155194 16720 solver.cpp:218] Iteration 88400 (16.2838 iter/s, 6.14108s/100 iters), loss = 0.82229
I1211 15:46:35.155194 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:46:35.155194 16720 solver.cpp:237]     Train net output #1: loss = 0.82229 (* 1 = 0.82229 loss)
I1211 15:46:35.155194 16720 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1211 15:46:40.994583  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:46:41.236598 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_88500.caffemodel
I1211 15:46:41.251597 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_88500.solverstate
I1211 15:46:41.256599 16720 solver.cpp:330] Iteration 88500, Testing net (#0)
I1211 15:46:41.256599 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:46:42.587724 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:46:42.640728 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5728
I1211 15:46:42.640728 16720 solver.cpp:397]     Test net output #1: loss = 1.68537 (* 1 = 1.68537 loss)
I1211 15:46:42.699731 16720 solver.cpp:218] Iteration 88500 (13.255 iter/s, 7.54432s/100 iters), loss = 0.580757
I1211 15:46:42.699731 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:46:42.699731 16720 solver.cpp:237]     Train net output #1: loss = 0.580757 (* 1 = 0.580757 loss)
I1211 15:46:42.699731 16720 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1211 15:46:48.844306 16720 solver.cpp:218] Iteration 88600 (16.2741 iter/s, 6.14474s/100 iters), loss = 0.721727
I1211 15:46:48.845305 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:46:48.845305 16720 solver.cpp:237]     Train net output #1: loss = 0.721727 (* 1 = 0.721727 loss)
I1211 15:46:48.845305 16720 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1211 15:46:54.986752 16720 solver.cpp:218] Iteration 88700 (16.2829 iter/s, 6.14143s/100 iters), loss = 0.627523
I1211 15:46:54.986752 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:46:54.986752 16720 solver.cpp:237]     Train net output #1: loss = 0.627523 (* 1 = 0.627523 loss)
I1211 15:46:54.986752 16720 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1211 15:47:01.127228 16720 solver.cpp:218] Iteration 88800 (16.2874 iter/s, 6.13971s/100 iters), loss = 0.766647
I1211 15:47:01.127228 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:47:01.127228 16720 solver.cpp:237]     Train net output #1: loss = 0.766647 (* 1 = 0.766647 loss)
I1211 15:47:01.127228 16720 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1211 15:47:07.265202 16720 solver.cpp:218] Iteration 88900 (16.2926 iter/s, 6.13774s/100 iters), loss = 0.742857
I1211 15:47:07.265202 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:47:07.265202 16720 solver.cpp:237]     Train net output #1: loss = 0.742857 (* 1 = 0.742857 loss)
I1211 15:47:07.265202 16720 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1211 15:47:13.112654  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:47:13.354671 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_89000.caffemodel
I1211 15:47:13.369670 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_89000.solverstate
I1211 15:47:13.374671 16720 solver.cpp:330] Iteration 89000, Testing net (#0)
I1211 15:47:13.374671 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:47:14.707819 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:47:14.759816 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5898
I1211 15:47:14.759816 16720 solver.cpp:397]     Test net output #1: loss = 1.55633 (* 1 = 1.55633 loss)
I1211 15:47:14.817822 16720 solver.cpp:218] Iteration 89000 (13.2408 iter/s, 7.55242s/100 iters), loss = 0.629304
I1211 15:47:14.817822 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:47:14.817822 16720 solver.cpp:237]     Train net output #1: loss = 0.629304 (* 1 = 0.629304 loss)
I1211 15:47:14.817822 16720 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1211 15:47:20.958145 16720 solver.cpp:218] Iteration 89100 (16.2873 iter/s, 6.13974s/100 iters), loss = 0.675886
I1211 15:47:20.958145 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:47:20.958145 16720 solver.cpp:237]     Train net output #1: loss = 0.675886 (* 1 = 0.675886 loss)
I1211 15:47:20.958145 16720 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1211 15:47:27.098639 16720 solver.cpp:218] Iteration 89200 (16.287 iter/s, 6.13986s/100 iters), loss = 0.66967
I1211 15:47:27.098639 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:47:27.098639 16720 solver.cpp:237]     Train net output #1: loss = 0.66967 (* 1 = 0.66967 loss)
I1211 15:47:27.098639 16720 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1211 15:47:33.234946 16720 solver.cpp:218] Iteration 89300 (16.2977 iter/s, 6.13584s/100 iters), loss = 0.753934
I1211 15:47:33.234946 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:47:33.234946 16720 solver.cpp:237]     Train net output #1: loss = 0.753934 (* 1 = 0.753934 loss)
I1211 15:47:33.234946 16720 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1211 15:47:39.371948 16720 solver.cpp:218] Iteration 89400 (16.2964 iter/s, 6.13633s/100 iters), loss = 0.739827
I1211 15:47:39.371948 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:47:39.371948 16720 solver.cpp:237]     Train net output #1: loss = 0.739827 (* 1 = 0.739827 loss)
I1211 15:47:39.371948 16720 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1211 15:47:45.207918  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:47:45.449931 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_89500.caffemodel
I1211 15:47:45.464931 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_89500.solverstate
I1211 15:47:45.470435 16720 solver.cpp:330] Iteration 89500, Testing net (#0)
I1211 15:47:45.470435 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:47:46.803052 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:47:46.856051 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5734
I1211 15:47:46.856051 16720 solver.cpp:397]     Test net output #1: loss = 1.70575 (* 1 = 1.70575 loss)
I1211 15:47:46.915055 16720 solver.cpp:218] Iteration 89500 (13.2581 iter/s, 7.54258s/100 iters), loss = 0.616801
I1211 15:47:46.915055 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:47:46.915055 16720 solver.cpp:237]     Train net output #1: loss = 0.616801 (* 1 = 0.616801 loss)
I1211 15:47:46.915055 16720 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1211 15:47:53.055527 16720 solver.cpp:218] Iteration 89600 (16.2848 iter/s, 6.14069s/100 iters), loss = 0.81966
I1211 15:47:53.055527 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:47:53.055527 16720 solver.cpp:237]     Train net output #1: loss = 0.81966 (* 1 = 0.81966 loss)
I1211 15:47:53.055527 16720 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1211 15:47:59.197007 16720 solver.cpp:218] Iteration 89700 (16.285 iter/s, 6.14063s/100 iters), loss = 0.704561
I1211 15:47:59.197007 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:47:59.197007 16720 solver.cpp:237]     Train net output #1: loss = 0.704561 (* 1 = 0.704561 loss)
I1211 15:47:59.197007 16720 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1211 15:48:05.332427 16720 solver.cpp:218] Iteration 89800 (16.2992 iter/s, 6.13526s/100 iters), loss = 0.798193
I1211 15:48:05.332427 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 15:48:05.332427 16720 solver.cpp:237]     Train net output #1: loss = 0.798193 (* 1 = 0.798193 loss)
I1211 15:48:05.332427 16720 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1211 15:48:11.461850 16720 solver.cpp:218] Iteration 89900 (16.3161 iter/s, 6.1289s/100 iters), loss = 0.732733
I1211 15:48:11.461850 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:48:11.461850 16720 solver.cpp:237]     Train net output #1: loss = 0.732733 (* 1 = 0.732733 loss)
I1211 15:48:11.461850 16720 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1211 15:48:17.297435  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:48:17.541443 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90000.caffemodel
I1211 15:48:17.556443 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90000.solverstate
I1211 15:48:17.561444 16720 solver.cpp:330] Iteration 90000, Testing net (#0)
I1211 15:48:17.561444 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:48:18.893563 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:48:18.945552 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5639
I1211 15:48:18.945552 16720 solver.cpp:397]     Test net output #1: loss = 1.73094 (* 1 = 1.73094 loss)
I1211 15:48:19.004559 16720 solver.cpp:218] Iteration 90000 (13.2591 iter/s, 7.54196s/100 iters), loss = 0.625828
I1211 15:48:19.004559 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:48:19.004559 16720 solver.cpp:237]     Train net output #1: loss = 0.625828 (* 1 = 0.625828 loss)
I1211 15:48:19.004559 16720 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1211 15:48:25.153194 16720 solver.cpp:218] Iteration 90100 (16.2653 iter/s, 6.14805s/100 iters), loss = 0.681092
I1211 15:48:25.153194 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:48:25.153194 16720 solver.cpp:237]     Train net output #1: loss = 0.681092 (* 1 = 0.681092 loss)
I1211 15:48:25.153194 16720 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1211 15:48:31.294647 16720 solver.cpp:218] Iteration 90200 (16.2837 iter/s, 6.1411s/100 iters), loss = 0.57683
I1211 15:48:31.294647 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:48:31.294647 16720 solver.cpp:237]     Train net output #1: loss = 0.57683 (* 1 = 0.57683 loss)
I1211 15:48:31.294647 16720 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1211 15:48:37.438097 16720 solver.cpp:218] Iteration 90300 (16.2777 iter/s, 6.14336s/100 iters), loss = 0.779214
I1211 15:48:37.438097 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:48:37.438097 16720 solver.cpp:237]     Train net output #1: loss = 0.779214 (* 1 = 0.779214 loss)
I1211 15:48:37.438097 16720 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1211 15:48:43.590520 16720 solver.cpp:218] Iteration 90400 (16.2545 iter/s, 6.15212s/100 iters), loss = 0.741978
I1211 15:48:43.590520 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:48:43.590520 16720 solver.cpp:237]     Train net output #1: loss = 0.741978 (* 1 = 0.741978 loss)
I1211 15:48:43.590520 16720 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1211 15:48:49.430969  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:48:49.674485 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90500.caffemodel
I1211 15:48:49.689985 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_90500.solverstate
I1211 15:48:49.693989 16720 solver.cpp:330] Iteration 90500, Testing net (#0)
I1211 15:48:49.693989 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:48:51.026090 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:48:51.079092 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5681
I1211 15:48:51.079092 16720 solver.cpp:397]     Test net output #1: loss = 1.71336 (* 1 = 1.71336 loss)
I1211 15:48:51.138098 16720 solver.cpp:218] Iteration 90500 (13.2503 iter/s, 7.54698s/100 iters), loss = 0.525021
I1211 15:48:51.138098 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:48:51.138098 16720 solver.cpp:237]     Train net output #1: loss = 0.525021 (* 1 = 0.525021 loss)
I1211 15:48:51.138098 16720 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1211 15:48:57.289139 16720 solver.cpp:218] Iteration 90600 (16.2598 iter/s, 6.15014s/100 iters), loss = 0.716879
I1211 15:48:57.289139 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:48:57.289139 16720 solver.cpp:237]     Train net output #1: loss = 0.716879 (* 1 = 0.716879 loss)
I1211 15:48:57.289139 16720 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1211 15:49:03.436116 16720 solver.cpp:218] Iteration 90700 (16.2689 iter/s, 6.1467s/100 iters), loss = 0.563943
I1211 15:49:03.436116 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:49:03.436116 16720 solver.cpp:237]     Train net output #1: loss = 0.563943 (* 1 = 0.563943 loss)
I1211 15:49:03.436116 16720 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1211 15:49:09.577107 16720 solver.cpp:218] Iteration 90800 (16.285 iter/s, 6.14061s/100 iters), loss = 0.811235
I1211 15:49:09.577107 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:49:09.577107 16720 solver.cpp:237]     Train net output #1: loss = 0.811235 (* 1 = 0.811235 loss)
I1211 15:49:09.577107 16720 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1211 15:49:15.707062 16720 solver.cpp:218] Iteration 90900 (16.314 iter/s, 6.12971s/100 iters), loss = 0.71626
I1211 15:49:15.707062 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:49:15.707062 16720 solver.cpp:237]     Train net output #1: loss = 0.71626 (* 1 = 0.71626 loss)
I1211 15:49:15.707062 16720 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1211 15:49:21.544498  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:49:21.783548 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91000.caffemodel
I1211 15:49:21.800125 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91000.solverstate
I1211 15:49:21.804124 16720 solver.cpp:330] Iteration 91000, Testing net (#0)
I1211 15:49:21.805124 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:49:23.136929 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:49:23.189450 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5733
I1211 15:49:23.189450 16720 solver.cpp:397]     Test net output #1: loss = 1.69206 (* 1 = 1.69206 loss)
I1211 15:49:23.248945 16720 solver.cpp:218] Iteration 91000 (13.2603 iter/s, 7.54133s/100 iters), loss = 0.621594
I1211 15:49:23.248945 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:49:23.248945 16720 solver.cpp:237]     Train net output #1: loss = 0.621594 (* 1 = 0.621594 loss)
I1211 15:49:23.248945 16720 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1211 15:49:29.721441 16720 solver.cpp:218] Iteration 91100 (15.4505 iter/s, 6.47228s/100 iters), loss = 0.68867
I1211 15:49:29.721441 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:49:29.721441 16720 solver.cpp:237]     Train net output #1: loss = 0.68867 (* 1 = 0.68867 loss)
I1211 15:49:29.721441 16720 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1211 15:49:35.951238 16720 solver.cpp:218] Iteration 91200 (16.0546 iter/s, 6.22873s/100 iters), loss = 0.671317
I1211 15:49:35.951238 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:49:35.951238 16720 solver.cpp:237]     Train net output #1: loss = 0.671317 (* 1 = 0.671317 loss)
I1211 15:49:35.951238 16720 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1211 15:49:42.140715 16720 solver.cpp:218] Iteration 91300 (16.1572 iter/s, 6.18921s/100 iters), loss = 0.833771
I1211 15:49:42.140715 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:49:42.140715 16720 solver.cpp:237]     Train net output #1: loss = 0.833771 (* 1 = 0.833771 loss)
I1211 15:49:42.140715 16720 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1211 15:49:48.345026 16720 solver.cpp:218] Iteration 91400 (16.1188 iter/s, 6.20394s/100 iters), loss = 0.75168
I1211 15:49:48.345026 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:49:48.345026 16720 solver.cpp:237]     Train net output #1: loss = 0.75168 (* 1 = 0.75168 loss)
I1211 15:49:48.345026 16720 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1211 15:49:54.235350  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:49:54.477391 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91500.caffemodel
I1211 15:49:54.494395 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_91500.solverstate
I1211 15:49:54.498895 16720 solver.cpp:330] Iteration 91500, Testing net (#0)
I1211 15:49:54.498895 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:49:55.853235 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:49:55.906826 16720 solver.cpp:397]     Test net output #0: accuracy = 0.561
I1211 15:49:55.906826 16720 solver.cpp:397]     Test net output #1: loss = 1.81399 (* 1 = 1.81399 loss)
I1211 15:49:55.965828 16720 solver.cpp:218] Iteration 91500 (13.1225 iter/s, 7.62051s/100 iters), loss = 0.503665
I1211 15:49:55.965828 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 15:49:55.965828 16720 solver.cpp:237]     Train net output #1: loss = 0.503665 (* 1 = 0.503665 loss)
I1211 15:49:55.965828 16720 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1211 15:50:02.160573 16720 solver.cpp:218] Iteration 91600 (16.1445 iter/s, 6.19405s/100 iters), loss = 0.561349
I1211 15:50:02.160573 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:50:02.160573 16720 solver.cpp:237]     Train net output #1: loss = 0.561349 (* 1 = 0.561349 loss)
I1211 15:50:02.160573 16720 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1211 15:50:08.354007 16720 solver.cpp:218] Iteration 91700 (16.1489 iter/s, 6.19236s/100 iters), loss = 0.708829
I1211 15:50:08.354007 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:50:08.354007 16720 solver.cpp:237]     Train net output #1: loss = 0.708829 (* 1 = 0.708829 loss)
I1211 15:50:08.354007 16720 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1211 15:50:14.553107 16720 solver.cpp:218] Iteration 91800 (16.131 iter/s, 6.19925s/100 iters), loss = 0.667211
I1211 15:50:14.553107 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:50:14.553107 16720 solver.cpp:237]     Train net output #1: loss = 0.667211 (* 1 = 0.667211 loss)
I1211 15:50:14.553107 16720 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1211 15:50:20.720679 16720 solver.cpp:218] Iteration 91900 (16.2166 iter/s, 6.16651s/100 iters), loss = 0.670362
I1211 15:50:20.720679 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 15:50:20.720679 16720 solver.cpp:237]     Train net output #1: loss = 0.670362 (* 1 = 0.670362 loss)
I1211 15:50:20.720679 16720 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1211 15:50:26.624182  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:50:26.866210 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92000.caffemodel
I1211 15:50:26.883210 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92000.solverstate
I1211 15:50:26.888211 16720 solver.cpp:330] Iteration 92000, Testing net (#0)
I1211 15:50:26.888211 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:50:28.236335 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:50:28.288336 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5762
I1211 15:50:28.288336 16720 solver.cpp:397]     Test net output #1: loss = 1.64388 (* 1 = 1.64388 loss)
I1211 15:50:28.347339 16720 solver.cpp:218] Iteration 92000 (13.112 iter/s, 7.6266s/100 iters), loss = 0.597895
I1211 15:50:28.347339 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:50:28.347339 16720 solver.cpp:237]     Train net output #1: loss = 0.597895 (* 1 = 0.597895 loss)
I1211 15:50:28.347339 16720 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1211 15:50:34.578277 16720 solver.cpp:218] Iteration 92100 (16.0502 iter/s, 6.23044s/100 iters), loss = 0.758351
I1211 15:50:34.578277 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:50:34.578277 16720 solver.cpp:237]     Train net output #1: loss = 0.758351 (* 1 = 0.758351 loss)
I1211 15:50:34.578277 16720 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1211 15:50:40.764732 16720 solver.cpp:218] Iteration 92200 (16.1653 iter/s, 6.18608s/100 iters), loss = 0.688194
I1211 15:50:40.764732 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:50:40.764732 16720 solver.cpp:237]     Train net output #1: loss = 0.688194 (* 1 = 0.688194 loss)
I1211 15:50:40.764732 16720 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1211 15:50:46.960228 16720 solver.cpp:218] Iteration 92300 (16.1427 iter/s, 6.19473s/100 iters), loss = 0.688513
I1211 15:50:46.960228 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:50:46.960228 16720 solver.cpp:237]     Train net output #1: loss = 0.688513 (* 1 = 0.688513 loss)
I1211 15:50:46.960228 16720 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1211 15:50:53.133858 16720 solver.cpp:218] Iteration 92400 (16.1999 iter/s, 6.17289s/100 iters), loss = 0.8325
I1211 15:50:53.133858 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 15:50:53.133858 16720 solver.cpp:237]     Train net output #1: loss = 0.8325 (* 1 = 0.8325 loss)
I1211 15:50:53.133858 16720 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1211 15:50:59.054692  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:50:59.302795 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92500.caffemodel
I1211 15:50:59.318789 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_92500.solverstate
I1211 15:50:59.323791 16720 solver.cpp:330] Iteration 92500, Testing net (#0)
I1211 15:50:59.323791 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:51:00.666740 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:51:00.719743 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5921
I1211 15:51:00.719743 16720 solver.cpp:397]     Test net output #1: loss = 1.60814 (* 1 = 1.60814 loss)
I1211 15:51:00.779112 16720 solver.cpp:218] Iteration 92500 (13.0803 iter/s, 7.64511s/100 iters), loss = 0.639708
I1211 15:51:00.779112 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:51:00.779112 16720 solver.cpp:237]     Train net output #1: loss = 0.639708 (* 1 = 0.639708 loss)
I1211 15:51:00.779112 16720 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1211 15:51:07.011256 16720 solver.cpp:218] Iteration 92600 (16.0467 iter/s, 6.23182s/100 iters), loss = 0.654279
I1211 15:51:07.011256 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:51:07.011256 16720 solver.cpp:237]     Train net output #1: loss = 0.654279 (* 1 = 0.654279 loss)
I1211 15:51:07.011256 16720 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1211 15:51:13.224573 16720 solver.cpp:218] Iteration 92700 (16.0971 iter/s, 6.21229s/100 iters), loss = 0.55293
I1211 15:51:13.224573 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:51:13.224573 16720 solver.cpp:237]     Train net output #1: loss = 0.55293 (* 1 = 0.55293 loss)
I1211 15:51:13.224573 16720 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1211 15:51:19.440688 16720 solver.cpp:218] Iteration 92800 (16.0881 iter/s, 6.21577s/100 iters), loss = 0.655766
I1211 15:51:19.440688 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:51:19.440688 16720 solver.cpp:237]     Train net output #1: loss = 0.655766 (* 1 = 0.655766 loss)
I1211 15:51:19.440688 16720 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1211 15:51:25.649278 16720 solver.cpp:218] Iteration 92900 (16.1086 iter/s, 6.20785s/100 iters), loss = 0.657572
I1211 15:51:25.649278 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:51:25.649278 16720 solver.cpp:237]     Train net output #1: loss = 0.657572 (* 1 = 0.657572 loss)
I1211 15:51:25.649278 16720 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1211 15:51:31.513321  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:51:31.758461 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93000.caffemodel
I1211 15:51:31.773460 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93000.solverstate
I1211 15:51:31.778461 16720 solver.cpp:330] Iteration 93000, Testing net (#0)
I1211 15:51:31.778461 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:51:33.124095 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:51:33.177603 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5796
I1211 15:51:33.177603 16720 solver.cpp:397]     Test net output #1: loss = 1.61491 (* 1 = 1.61491 loss)
I1211 15:51:33.236120 16720 solver.cpp:218] Iteration 93000 (13.1807 iter/s, 7.58683s/100 iters), loss = 0.53324
I1211 15:51:33.236618 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:51:33.236618 16720 solver.cpp:237]     Train net output #1: loss = 0.53324 (* 1 = 0.53324 loss)
I1211 15:51:33.236618 16720 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1211 15:51:39.458901 16720 solver.cpp:218] Iteration 93100 (16.0703 iter/s, 6.22265s/100 iters), loss = 0.726129
I1211 15:51:39.458901 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:51:39.458901 16720 solver.cpp:237]     Train net output #1: loss = 0.726129 (* 1 = 0.726129 loss)
I1211 15:51:39.458901 16720 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1211 15:51:45.693109 16720 solver.cpp:218] Iteration 93200 (16.0425 iter/s, 6.23343s/100 iters), loss = 0.601356
I1211 15:51:45.693109 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:51:45.693109 16720 solver.cpp:237]     Train net output #1: loss = 0.601356 (* 1 = 0.601356 loss)
I1211 15:51:45.693109 16720 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1211 15:51:51.971071 16720 solver.cpp:218] Iteration 93300 (15.9287 iter/s, 6.27798s/100 iters), loss = 0.77416
I1211 15:51:51.971071 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 15:51:51.971071 16720 solver.cpp:237]     Train net output #1: loss = 0.77416 (* 1 = 0.77416 loss)
I1211 15:51:51.971071 16720 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1211 15:51:58.218780 16720 solver.cpp:218] Iteration 93400 (16.0074 iter/s, 6.24713s/100 iters), loss = 0.718078
I1211 15:51:58.218780 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 15:51:58.218780 16720 solver.cpp:237]     Train net output #1: loss = 0.718078 (* 1 = 0.718078 loss)
I1211 15:51:58.218780 16720 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1211 15:52:04.138435  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:52:04.382452 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93500.caffemodel
I1211 15:52:04.398453 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_93500.solverstate
I1211 15:52:04.402453 16720 solver.cpp:330] Iteration 93500, Testing net (#0)
I1211 15:52:04.402453 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:52:05.753271 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:52:05.805771 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5559
I1211 15:52:05.805771 16720 solver.cpp:397]     Test net output #1: loss = 1.79168 (* 1 = 1.79168 loss)
I1211 15:52:05.864271 16720 solver.cpp:218] Iteration 93500 (13.0811 iter/s, 7.64463s/100 iters), loss = 0.512238
I1211 15:52:05.864771 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:52:05.864771 16720 solver.cpp:237]     Train net output #1: loss = 0.512238 (* 1 = 0.512238 loss)
I1211 15:52:05.864771 16720 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1211 15:52:12.106662 16720 solver.cpp:218] Iteration 93600 (16.0199 iter/s, 6.24222s/100 iters), loss = 0.67452
I1211 15:52:12.106662 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:52:12.106662 16720 solver.cpp:237]     Train net output #1: loss = 0.67452 (* 1 = 0.67452 loss)
I1211 15:52:12.106662 16720 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1211 15:52:18.314921 16720 solver.cpp:218] Iteration 93700 (16.1095 iter/s, 6.20754s/100 iters), loss = 0.656416
I1211 15:52:18.315423 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:52:18.315423 16720 solver.cpp:237]     Train net output #1: loss = 0.656416 (* 1 = 0.656416 loss)
I1211 15:52:18.315423 16720 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1211 15:52:24.523330 16720 solver.cpp:218] Iteration 93800 (16.1096 iter/s, 6.20748s/100 iters), loss = 0.64589
I1211 15:52:24.523330 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:52:24.523330 16720 solver.cpp:237]     Train net output #1: loss = 0.64589 (* 1 = 0.64589 loss)
I1211 15:52:24.523330 16720 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1211 15:52:30.711715 16720 solver.cpp:218] Iteration 93900 (16.1602 iter/s, 6.18804s/100 iters), loss = 0.870956
I1211 15:52:30.711715 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:52:30.711715 16720 solver.cpp:237]     Train net output #1: loss = 0.870956 (* 1 = 0.870956 loss)
I1211 15:52:30.711715 16720 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1211 15:52:36.611330  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:52:36.856339 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94000.caffemodel
I1211 15:52:36.872339 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94000.solverstate
I1211 15:52:36.877344 16720 solver.cpp:330] Iteration 94000, Testing net (#0)
I1211 15:52:36.877846 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:52:38.232477 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:52:38.285480 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5582
I1211 15:52:38.285480 16720 solver.cpp:397]     Test net output #1: loss = 1.79709 (* 1 = 1.79709 loss)
I1211 15:52:38.346482 16720 solver.cpp:218] Iteration 94000 (13.0988 iter/s, 7.63429s/100 iters), loss = 0.512288
I1211 15:52:38.346482 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:52:38.346482 16720 solver.cpp:237]     Train net output #1: loss = 0.512288 (* 1 = 0.512288 loss)
I1211 15:52:38.346482 16720 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1211 15:52:44.581996 16720 solver.cpp:218] Iteration 94100 (16.038 iter/s, 6.23518s/100 iters), loss = 0.679264
I1211 15:52:44.581996 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 15:52:44.581996 16720 solver.cpp:237]     Train net output #1: loss = 0.679264 (* 1 = 0.679264 loss)
I1211 15:52:44.581996 16720 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1211 15:52:50.733783 16720 solver.cpp:218] Iteration 94200 (16.2555 iter/s, 6.15177s/100 iters), loss = 0.532384
I1211 15:52:50.733783 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:52:50.733783 16720 solver.cpp:237]     Train net output #1: loss = 0.532384 (* 1 = 0.532384 loss)
I1211 15:52:50.733783 16720 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1211 15:52:56.889008 16720 solver.cpp:218] Iteration 94300 (16.2488 iter/s, 6.15431s/100 iters), loss = 0.740094
I1211 15:52:56.889008 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 15:52:56.889008 16720 solver.cpp:237]     Train net output #1: loss = 0.740094 (* 1 = 0.740094 loss)
I1211 15:52:56.889008 16720 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1211 15:53:03.052119 16720 solver.cpp:218] Iteration 94400 (16.2266 iter/s, 6.16271s/100 iters), loss = 0.891118
I1211 15:53:03.052119 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 15:53:03.052119 16720 solver.cpp:237]     Train net output #1: loss = 0.891118 (* 1 = 0.891118 loss)
I1211 15:53:03.052119 16720 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1211 15:53:08.981186  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:53:09.223206 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94500.caffemodel
I1211 15:53:09.238205 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_94500.solverstate
I1211 15:53:09.243206 16720 solver.cpp:330] Iteration 94500, Testing net (#0)
I1211 15:53:09.243206 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:53:10.591841 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:53:10.644345 16720 solver.cpp:397]     Test net output #0: accuracy = 0.573
I1211 15:53:10.644345 16720 solver.cpp:397]     Test net output #1: loss = 1.63761 (* 1 = 1.63761 loss)
I1211 15:53:10.703387 16720 solver.cpp:218] Iteration 94500 (13.0708 iter/s, 7.65064s/100 iters), loss = 0.504299
I1211 15:53:10.703858 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:53:10.703858 16720 solver.cpp:237]     Train net output #1: loss = 0.504299 (* 1 = 0.504299 loss)
I1211 15:53:10.703858 16720 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1211 15:53:16.950867 16720 solver.cpp:218] Iteration 94600 (16.0078 iter/s, 6.24694s/100 iters), loss = 0.727201
I1211 15:53:16.950867 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 15:53:16.950867 16720 solver.cpp:237]     Train net output #1: loss = 0.727201 (* 1 = 0.727201 loss)
I1211 15:53:16.950867 16720 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1211 15:53:23.187026 16720 solver.cpp:218] Iteration 94700 (16.0364 iter/s, 6.2358s/100 iters), loss = 0.571844
I1211 15:53:23.187026 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:53:23.187026 16720 solver.cpp:237]     Train net output #1: loss = 0.571844 (* 1 = 0.571844 loss)
I1211 15:53:23.187026 16720 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1211 15:53:29.355834 16720 solver.cpp:218] Iteration 94800 (16.2114 iter/s, 6.16851s/100 iters), loss = 0.719469
I1211 15:53:29.355834 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 15:53:29.355834 16720 solver.cpp:237]     Train net output #1: loss = 0.719469 (* 1 = 0.719469 loss)
I1211 15:53:29.355834 16720 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1211 15:53:35.579716 16720 solver.cpp:218] Iteration 94900 (16.0702 iter/s, 6.22269s/100 iters), loss = 0.797922
I1211 15:53:35.579716 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 15:53:35.579716 16720 solver.cpp:237]     Train net output #1: loss = 0.797922 (* 1 = 0.797922 loss)
I1211 15:53:35.579716 16720 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1211 15:53:41.501549  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:53:41.747409 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95000.caffemodel
I1211 15:53:41.762408 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95000.solverstate
I1211 15:53:41.767410 16720 solver.cpp:330] Iteration 95000, Testing net (#0)
I1211 15:53:41.767410 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:53:43.112020 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:53:43.165050 16720 solver.cpp:397]     Test net output #0: accuracy = 0.5924
I1211 15:53:43.165050 16720 solver.cpp:397]     Test net output #1: loss = 1.58845 (* 1 = 1.58845 loss)
I1211 15:53:43.223400 16720 solver.cpp:218] Iteration 95000 (13.0842 iter/s, 7.64283s/100 iters), loss = 0.599441
I1211 15:53:43.223400 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:53:43.223400 16720 solver.cpp:237]     Train net output #1: loss = 0.599441 (* 1 = 0.599441 loss)
I1211 15:53:43.223400 16720 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1211 15:53:43.223400 16720 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1211 15:53:49.418550 16720 solver.cpp:218] Iteration 95100 (16.1429 iter/s, 6.19467s/100 iters), loss = 0.572117
I1211 15:53:49.418550 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:53:49.418550 16720 solver.cpp:237]     Train net output #1: loss = 0.572117 (* 1 = 0.572117 loss)
I1211 15:53:49.418550 16720 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1211 15:53:55.569528 16720 solver.cpp:218] Iteration 95200 (16.2566 iter/s, 6.15134s/100 iters), loss = 0.50869
I1211 15:53:55.569528 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 15:53:55.569528 16720 solver.cpp:237]     Train net output #1: loss = 0.50869 (* 1 = 0.50869 loss)
I1211 15:53:55.569528 16720 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1211 15:54:01.750756 16720 solver.cpp:218] Iteration 95300 (16.1805 iter/s, 6.18028s/100 iters), loss = 0.524459
I1211 15:54:01.750756 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:54:01.750756 16720 solver.cpp:237]     Train net output #1: loss = 0.524459 (* 1 = 0.524459 loss)
I1211 15:54:01.750756 16720 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1211 15:54:07.900920 16720 solver.cpp:218] Iteration 95400 (16.2622 iter/s, 6.14925s/100 iters), loss = 0.48404
I1211 15:54:07.900920 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:54:07.900920 16720 solver.cpp:237]     Train net output #1: loss = 0.48404 (* 1 = 0.48404 loss)
I1211 15:54:07.900920 16720 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1211 15:54:13.761634  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:54:14.009479 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95500.caffemodel
I1211 15:54:14.025481 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_95500.solverstate
I1211 15:54:14.030481 16720 solver.cpp:330] Iteration 95500, Testing net (#0)
I1211 15:54:14.030481 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:54:15.381634 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:54:15.436166 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6712
I1211 15:54:15.436166 16720 solver.cpp:397]     Test net output #1: loss = 1.19029 (* 1 = 1.19029 loss)
I1211 15:54:15.496765 16720 solver.cpp:218] Iteration 95500 (13.1652 iter/s, 7.59576s/100 iters), loss = 0.416073
I1211 15:54:15.496765 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:54:15.496765 16720 solver.cpp:237]     Train net output #1: loss = 0.416073 (* 1 = 0.416073 loss)
I1211 15:54:15.496765 16720 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1211 15:54:21.734586 16720 solver.cpp:218] Iteration 95600 (16.0312 iter/s, 6.23784s/100 iters), loss = 0.568788
I1211 15:54:21.735587 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:54:21.735587 16720 solver.cpp:237]     Train net output #1: loss = 0.568788 (* 1 = 0.568788 loss)
I1211 15:54:21.735587 16720 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1211 15:54:27.961418 16720 solver.cpp:218] Iteration 95700 (16.0617 iter/s, 6.22598s/100 iters), loss = 0.477034
I1211 15:54:27.961418 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:54:27.961418 16720 solver.cpp:237]     Train net output #1: loss = 0.477034 (* 1 = 0.477034 loss)
I1211 15:54:27.961418 16720 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1211 15:54:34.206759 16720 solver.cpp:218] Iteration 95800 (16.0147 iter/s, 6.24428s/100 iters), loss = 0.454376
I1211 15:54:34.206759 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 15:54:34.206759 16720 solver.cpp:237]     Train net output #1: loss = 0.454376 (* 1 = 0.454376 loss)
I1211 15:54:34.206759 16720 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1211 15:54:40.457857 16720 solver.cpp:218] Iteration 95900 (15.9969 iter/s, 6.25121s/100 iters), loss = 0.438578
I1211 15:54:40.457857 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:54:40.457857 16720 solver.cpp:237]     Train net output #1: loss = 0.438578 (* 1 = 0.438578 loss)
I1211 15:54:40.457857 16720 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1211 15:54:46.361714  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:54:46.609743 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96000.caffemodel
I1211 15:54:46.625743 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96000.solverstate
I1211 15:54:46.630743 16720 solver.cpp:330] Iteration 96000, Testing net (#0)
I1211 15:54:46.630743 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:54:47.978607 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:54:48.032608 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6768
I1211 15:54:48.032608 16720 solver.cpp:397]     Test net output #1: loss = 1.17937 (* 1 = 1.17937 loss)
I1211 15:54:48.093626 16720 solver.cpp:218] Iteration 96000 (13.0965 iter/s, 7.63563s/100 iters), loss = 0.409605
I1211 15:54:48.094626 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 15:54:48.094626 16720 solver.cpp:237]     Train net output #1: loss = 0.409605 (* 1 = 0.409605 loss)
I1211 15:54:48.094626 16720 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1211 15:54:54.330339 16720 solver.cpp:218] Iteration 96100 (16.036 iter/s, 6.23598s/100 iters), loss = 0.532628
I1211 15:54:54.330339 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 15:54:54.330339 16720 solver.cpp:237]     Train net output #1: loss = 0.532628 (* 1 = 0.532628 loss)
I1211 15:54:54.330339 16720 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1211 15:55:00.575472 16720 solver.cpp:218] Iteration 96200 (16.0153 iter/s, 6.24405s/100 iters), loss = 0.44016
I1211 15:55:00.575472 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:55:00.575472 16720 solver.cpp:237]     Train net output #1: loss = 0.44016 (* 1 = 0.44016 loss)
I1211 15:55:00.575472 16720 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1211 15:55:06.820777 16720 solver.cpp:218] Iteration 96300 (16.0122 iter/s, 6.24524s/100 iters), loss = 0.46085
I1211 15:55:06.820777 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:55:06.820777 16720 solver.cpp:237]     Train net output #1: loss = 0.46085 (* 1 = 0.46085 loss)
I1211 15:55:06.820777 16720 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1211 15:55:13.049152 16720 solver.cpp:218] Iteration 96400 (16.0565 iter/s, 6.228s/100 iters), loss = 0.459045
I1211 15:55:13.049654 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:55:13.049654 16720 solver.cpp:237]     Train net output #1: loss = 0.459045 (* 1 = 0.459045 loss)
I1211 15:55:13.049654 16720 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1211 15:55:18.967006  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:55:19.211053 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96500.caffemodel
I1211 15:55:19.227053 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_96500.solverstate
I1211 15:55:19.231053 16720 solver.cpp:330] Iteration 96500, Testing net (#0)
I1211 15:55:19.231053 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:55:20.589699 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:55:20.642699 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6772
I1211 15:55:20.642699 16720 solver.cpp:397]     Test net output #1: loss = 1.18687 (* 1 = 1.18687 loss)
I1211 15:55:20.702718 16720 solver.cpp:218] Iteration 96500 (13.0672 iter/s, 7.65277s/100 iters), loss = 0.43507
I1211 15:55:20.702718 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:55:20.702718 16720 solver.cpp:237]     Train net output #1: loss = 0.43507 (* 1 = 0.43507 loss)
I1211 15:55:20.702718 16720 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1211 15:55:26.874949 16720 solver.cpp:218] Iteration 96600 (16.2031 iter/s, 6.17165s/100 iters), loss = 0.490109
I1211 15:55:26.874949 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:55:26.874949 16720 solver.cpp:237]     Train net output #1: loss = 0.490109 (* 1 = 0.490109 loss)
I1211 15:55:26.874949 16720 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1211 15:55:33.099627 16720 solver.cpp:218] Iteration 96700 (16.0654 iter/s, 6.22456s/100 iters), loss = 0.362403
I1211 15:55:33.099627 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 15:55:33.099627 16720 solver.cpp:237]     Train net output #1: loss = 0.362403 (* 1 = 0.362403 loss)
I1211 15:55:33.099627 16720 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1211 15:55:39.338263 16720 solver.cpp:218] Iteration 96800 (16.0302 iter/s, 6.23821s/100 iters), loss = 0.474136
I1211 15:55:39.338263 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:55:39.338263 16720 solver.cpp:237]     Train net output #1: loss = 0.474136 (* 1 = 0.474136 loss)
I1211 15:55:39.338263 16720 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1211 15:55:45.581027 16720 solver.cpp:218] Iteration 96900 (16.0214 iter/s, 6.24166s/100 iters), loss = 0.391975
I1211 15:55:45.581027 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:55:45.581027 16720 solver.cpp:237]     Train net output #1: loss = 0.391975 (* 1 = 0.391975 loss)
I1211 15:55:45.581027 16720 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1211 15:55:51.502771  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:55:51.749111 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97000.caffemodel
I1211 15:55:51.767619 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97000.solverstate
I1211 15:55:51.771838 16720 solver.cpp:330] Iteration 97000, Testing net (#0)
I1211 15:55:51.771838 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:55:53.134749 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:55:53.188761 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6768
I1211 15:55:53.188761 16720 solver.cpp:397]     Test net output #1: loss = 1.1819 (* 1 = 1.1819 loss)
I1211 15:55:53.248759 16720 solver.cpp:218] Iteration 97000 (13.0427 iter/s, 7.66713s/100 iters), loss = 0.345821
I1211 15:55:53.248759 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:55:53.248759 16720 solver.cpp:237]     Train net output #1: loss = 0.345821 (* 1 = 0.345821 loss)
I1211 15:55:53.248759 16720 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1211 15:55:59.476583 16720 solver.cpp:218] Iteration 97100 (16.0585 iter/s, 6.22722s/100 iters), loss = 0.421554
I1211 15:55:59.476583 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:55:59.476583 16720 solver.cpp:237]     Train net output #1: loss = 0.421554 (* 1 = 0.421554 loss)
I1211 15:55:59.476583 16720 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1211 15:56:05.661953 16720 solver.cpp:218] Iteration 97200 (16.166 iter/s, 6.18581s/100 iters), loss = 0.406508
I1211 15:56:05.661953 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 15:56:05.661953 16720 solver.cpp:237]     Train net output #1: loss = 0.406508 (* 1 = 0.406508 loss)
I1211 15:56:05.661953 16720 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1211 15:56:11.831841 16720 solver.cpp:218] Iteration 97300 (16.2115 iter/s, 6.16845s/100 iters), loss = 0.508736
I1211 15:56:11.831841 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 15:56:11.831841 16720 solver.cpp:237]     Train net output #1: loss = 0.508736 (* 1 = 0.508736 loss)
I1211 15:56:11.831841 16720 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1211 15:56:18.066272 16720 solver.cpp:218] Iteration 97400 (16.0397 iter/s, 6.23453s/100 iters), loss = 0.433932
I1211 15:56:18.066272 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:56:18.066272 16720 solver.cpp:237]     Train net output #1: loss = 0.433932 (* 1 = 0.433932 loss)
I1211 15:56:18.066272 16720 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1211 15:56:23.987344  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:56:24.233409 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97500.caffemodel
I1211 15:56:24.249424 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_97500.solverstate
I1211 15:56:24.254426 16720 solver.cpp:330] Iteration 97500, Testing net (#0)
I1211 15:56:24.254426 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:56:25.604826 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:56:25.657829 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6743
I1211 15:56:25.657829 16720 solver.cpp:397]     Test net output #1: loss = 1.18577 (* 1 = 1.18577 loss)
I1211 15:56:25.716826 16720 solver.cpp:218] Iteration 97500 (13.0725 iter/s, 7.64965s/100 iters), loss = 0.419436
I1211 15:56:25.716826 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:56:25.716826 16720 solver.cpp:237]     Train net output #1: loss = 0.419436 (* 1 = 0.419436 loss)
I1211 15:56:25.716826 16720 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1211 15:56:31.970850 16720 solver.cpp:218] Iteration 97600 (15.9902 iter/s, 6.25382s/100 iters), loss = 0.411325
I1211 15:56:31.971351 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:56:31.971351 16720 solver.cpp:237]     Train net output #1: loss = 0.411325 (* 1 = 0.411325 loss)
I1211 15:56:31.971351 16720 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1211 15:56:38.184798 16720 solver.cpp:218] Iteration 97700 (16.0932 iter/s, 6.21379s/100 iters), loss = 0.388942
I1211 15:56:38.184798 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 15:56:38.184798 16720 solver.cpp:237]     Train net output #1: loss = 0.388942 (* 1 = 0.388942 loss)
I1211 15:56:38.184798 16720 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1211 15:56:44.413429 16720 solver.cpp:218] Iteration 97800 (16.0582 iter/s, 6.22733s/100 iters), loss = 0.434995
I1211 15:56:44.413429 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:56:44.413429 16720 solver.cpp:237]     Train net output #1: loss = 0.434995 (* 1 = 0.434995 loss)
I1211 15:56:44.413429 16720 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1211 15:56:50.585197 16720 solver.cpp:218] Iteration 97900 (16.2024 iter/s, 6.17193s/100 iters), loss = 0.42873
I1211 15:56:50.585197 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:56:50.585197 16720 solver.cpp:237]     Train net output #1: loss = 0.42873 (* 1 = 0.42873 loss)
I1211 15:56:50.585197 16720 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1211 15:56:56.523968  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:56:56.773988 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98000.caffemodel
I1211 15:56:56.787993 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98000.solverstate
I1211 15:56:56.792994 16720 solver.cpp:330] Iteration 98000, Testing net (#0)
I1211 15:56:56.792994 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:56:58.135119 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:56:58.188139 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1211 15:56:58.188139 16720 solver.cpp:397]     Test net output #1: loss = 1.18423 (* 1 = 1.18423 loss)
I1211 15:56:58.248129 16720 solver.cpp:218] Iteration 98000 (13.0508 iter/s, 7.66236s/100 iters), loss = 0.390648
I1211 15:56:58.248129 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:56:58.248129 16720 solver.cpp:237]     Train net output #1: loss = 0.390648 (* 1 = 0.390648 loss)
I1211 15:56:58.248129 16720 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1211 15:57:04.466339 16720 solver.cpp:218] Iteration 98100 (16.0837 iter/s, 6.21748s/100 iters), loss = 0.486381
I1211 15:57:04.466339 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:57:04.466339 16720 solver.cpp:237]     Train net output #1: loss = 0.486382 (* 1 = 0.486382 loss)
I1211 15:57:04.466339 16720 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1211 15:57:10.676913 16720 solver.cpp:218] Iteration 98200 (16.1028 iter/s, 6.21009s/100 iters), loss = 0.359046
I1211 15:57:10.676913 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 15:57:10.676913 16720 solver.cpp:237]     Train net output #1: loss = 0.359047 (* 1 = 0.359047 loss)
I1211 15:57:10.676913 16720 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1211 15:57:16.888226 16720 solver.cpp:218] Iteration 98300 (16.1012 iter/s, 6.21072s/100 iters), loss = 0.425716
I1211 15:57:16.888226 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:57:16.888226 16720 solver.cpp:237]     Train net output #1: loss = 0.425717 (* 1 = 0.425717 loss)
I1211 15:57:16.888226 16720 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1211 15:57:23.090623 16720 solver.cpp:218] Iteration 98400 (16.122 iter/s, 6.2027s/100 iters), loss = 0.45768
I1211 15:57:23.090623 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:57:23.090623 16720 solver.cpp:237]     Train net output #1: loss = 0.457681 (* 1 = 0.457681 loss)
I1211 15:57:23.090623 16720 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1211 15:57:28.955127  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:57:29.205441 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98500.caffemodel
I1211 15:57:29.220443 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_98500.solverstate
I1211 15:57:29.225441 16720 solver.cpp:330] Iteration 98500, Testing net (#0)
I1211 15:57:29.225441 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:57:30.571794 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:57:30.625299 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6773
I1211 15:57:30.625299 16720 solver.cpp:397]     Test net output #1: loss = 1.20297 (* 1 = 1.20297 loss)
I1211 15:57:30.683802 16720 solver.cpp:218] Iteration 98500 (13.1717 iter/s, 7.59204s/100 iters), loss = 0.333196
I1211 15:57:30.683802 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 15:57:30.683802 16720 solver.cpp:237]     Train net output #1: loss = 0.333197 (* 1 = 0.333197 loss)
I1211 15:57:30.683802 16720 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1211 15:57:36.908841 16720 solver.cpp:218] Iteration 98600 (16.0634 iter/s, 6.22534s/100 iters), loss = 0.397894
I1211 15:57:36.909842 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:57:36.909842 16720 solver.cpp:237]     Train net output #1: loss = 0.397894 (* 1 = 0.397894 loss)
I1211 15:57:36.909842 16720 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1211 15:57:43.111327 16720 solver.cpp:218] Iteration 98700 (16.1247 iter/s, 6.20167s/100 iters), loss = 0.370837
I1211 15:57:43.111327 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:57:43.111327 16720 solver.cpp:237]     Train net output #1: loss = 0.370837 (* 1 = 0.370837 loss)
I1211 15:57:43.111327 16720 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1211 15:57:49.353611 16720 solver.cpp:218] Iteration 98800 (16.0223 iter/s, 6.24129s/100 iters), loss = 0.403765
I1211 15:57:49.353611 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:57:49.353611 16720 solver.cpp:237]     Train net output #1: loss = 0.403765 (* 1 = 0.403765 loss)
I1211 15:57:49.353611 16720 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1211 15:57:55.577044 16720 solver.cpp:218] Iteration 98900 (16.0697 iter/s, 6.22289s/100 iters), loss = 0.375316
I1211 15:57:55.577044 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 15:57:55.577044 16720 solver.cpp:237]     Train net output #1: loss = 0.375316 (* 1 = 0.375316 loss)
I1211 15:57:55.577044 16720 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1211 15:58:01.474762  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:58:01.716776 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99000.caffemodel
I1211 15:58:01.733777 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99000.solverstate
I1211 15:58:01.737776 16720 solver.cpp:330] Iteration 99000, Testing net (#0)
I1211 15:58:01.738777 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:58:03.074882 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:58:03.126895 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6748
I1211 15:58:03.127887 16720 solver.cpp:397]     Test net output #1: loss = 1.18769 (* 1 = 1.18769 loss)
I1211 15:58:03.185886 16720 solver.cpp:218] Iteration 99000 (13.1432 iter/s, 7.60848s/100 iters), loss = 0.326179
I1211 15:58:03.185886 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:58:03.185886 16720 solver.cpp:237]     Train net output #1: loss = 0.326179 (* 1 = 0.326179 loss)
I1211 15:58:03.185886 16720 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1211 15:58:09.373380 16720 solver.cpp:218] Iteration 99100 (16.161 iter/s, 6.18775s/100 iters), loss = 0.460721
I1211 15:58:09.374382 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 15:58:09.374382 16720 solver.cpp:237]     Train net output #1: loss = 0.460721 (* 1 = 0.460721 loss)
I1211 15:58:09.374382 16720 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1211 15:58:15.572947 16720 solver.cpp:218] Iteration 99200 (16.1332 iter/s, 6.19841s/100 iters), loss = 0.318472
I1211 15:58:15.572947 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:58:15.572947 16720 solver.cpp:237]     Train net output #1: loss = 0.318472 (* 1 = 0.318472 loss)
I1211 15:58:15.572947 16720 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1211 15:58:21.731426 16720 solver.cpp:218] Iteration 99300 (16.2393 iter/s, 6.15791s/100 iters), loss = 0.523173
I1211 15:58:21.731426 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:58:21.731426 16720 solver.cpp:237]     Train net output #1: loss = 0.523173 (* 1 = 0.523173 loss)
I1211 15:58:21.731426 16720 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1211 15:58:27.954074 16720 solver.cpp:218] Iteration 99400 (16.0717 iter/s, 6.22213s/100 iters), loss = 0.446181
I1211 15:58:27.954074 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 15:58:27.954074 16720 solver.cpp:237]     Train net output #1: loss = 0.446181 (* 1 = 0.446181 loss)
I1211 15:58:27.954074 16720 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1211 15:58:33.865563  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:58:34.108589 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99500.caffemodel
I1211 15:58:34.125592 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_99500.solverstate
I1211 15:58:34.130594 16720 solver.cpp:330] Iteration 99500, Testing net (#0)
I1211 15:58:34.130594 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:58:35.476704 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:58:35.529711 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1211 15:58:35.529711 16720 solver.cpp:397]     Test net output #1: loss = 1.20002 (* 1 = 1.20002 loss)
I1211 15:58:35.588711 16720 solver.cpp:218] Iteration 99500 (13.0976 iter/s, 7.63498s/100 iters), loss = 0.289308
I1211 15:58:35.588711 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 15:58:35.589711 16720 solver.cpp:237]     Train net output #1: loss = 0.289308 (* 1 = 0.289308 loss)
I1211 15:58:35.589711 16720 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1211 15:58:41.818066 16720 solver.cpp:218] Iteration 99600 (16.0547 iter/s, 6.22869s/100 iters), loss = 0.408363
I1211 15:58:41.818066 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:58:41.818066 16720 solver.cpp:237]     Train net output #1: loss = 0.408363 (* 1 = 0.408363 loss)
I1211 15:58:41.818066 16720 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1211 15:58:48.045580 16720 solver.cpp:218] Iteration 99700 (16.0602 iter/s, 6.22658s/100 iters), loss = 0.32388
I1211 15:58:48.045580 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 15:58:48.045580 16720 solver.cpp:237]     Train net output #1: loss = 0.323881 (* 1 = 0.323881 loss)
I1211 15:58:48.045580 16720 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1211 15:58:54.270045 16720 solver.cpp:218] Iteration 99800 (16.0671 iter/s, 6.22389s/100 iters), loss = 0.348787
I1211 15:58:54.270045 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:58:54.270045 16720 solver.cpp:237]     Train net output #1: loss = 0.348787 (* 1 = 0.348787 loss)
I1211 15:58:54.270045 16720 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1211 15:59:00.524801 16720 solver.cpp:218] Iteration 99900 (15.9879 iter/s, 6.25472s/100 iters), loss = 0.449565
I1211 15:59:00.524801 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 15:59:00.524801 16720 solver.cpp:237]     Train net output #1: loss = 0.449565 (* 1 = 0.449565 loss)
I1211 15:59:00.524801 16720 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1211 15:59:06.453642  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:59:06.698668 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100000.caffemodel
I1211 15:59:06.714673 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100000.solverstate
I1211 15:59:06.719672 16720 solver.cpp:330] Iteration 100000, Testing net (#0)
I1211 15:59:06.719672 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:59:08.068833 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:59:08.120838 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 15:59:08.120838 16720 solver.cpp:397]     Test net output #1: loss = 1.20022 (* 1 = 1.20022 loss)
I1211 15:59:08.179838 16720 solver.cpp:218] Iteration 100000 (13.0645 iter/s, 7.6543s/100 iters), loss = 0.281647
I1211 15:59:08.179838 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 15:59:08.179838 16720 solver.cpp:237]     Train net output #1: loss = 0.281647 (* 1 = 0.281647 loss)
I1211 15:59:08.179838 16720 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1211 15:59:14.409778 16720 solver.cpp:218] Iteration 100100 (16.0526 iter/s, 6.22953s/100 iters), loss = 0.425355
I1211 15:59:14.409778 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 15:59:14.409778 16720 solver.cpp:237]     Train net output #1: loss = 0.425355 (* 1 = 0.425355 loss)
I1211 15:59:14.409778 16720 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1211 15:59:20.617828 16720 solver.cpp:218] Iteration 100200 (16.1088 iter/s, 6.20779s/100 iters), loss = 0.377541
I1211 15:59:20.617828 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:59:20.617828 16720 solver.cpp:237]     Train net output #1: loss = 0.377541 (* 1 = 0.377541 loss)
I1211 15:59:20.617828 16720 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1211 15:59:26.821450 16720 solver.cpp:218] Iteration 100300 (16.1205 iter/s, 6.20329s/100 iters), loss = 0.421897
I1211 15:59:26.821450 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:59:26.821450 16720 solver.cpp:237]     Train net output #1: loss = 0.421897 (* 1 = 0.421897 loss)
I1211 15:59:26.821450 16720 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1211 15:59:33.060760 16720 solver.cpp:218] Iteration 100400 (16.03 iter/s, 6.2383s/100 iters), loss = 0.410011
I1211 15:59:33.060760 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 15:59:33.060760 16720 solver.cpp:237]     Train net output #1: loss = 0.410011 (* 1 = 0.410011 loss)
I1211 15:59:33.060760 16720 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1211 15:59:38.970846  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:59:39.212859 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100500.caffemodel
I1211 15:59:39.228859 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_100500.solverstate
I1211 15:59:39.233860 16720 solver.cpp:330] Iteration 100500, Testing net (#0)
I1211 15:59:39.233860 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 15:59:40.573084 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 15:59:40.627084 16720 solver.cpp:397]     Test net output #0: accuracy = 0.678
I1211 15:59:40.627084 16720 solver.cpp:397]     Test net output #1: loss = 1.21061 (* 1 = 1.21061 loss)
I1211 15:59:40.688092 16720 solver.cpp:218] Iteration 100500 (13.1103 iter/s, 7.62762s/100 iters), loss = 0.300893
I1211 15:59:40.688092 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 15:59:40.688092 16720 solver.cpp:237]     Train net output #1: loss = 0.300893 (* 1 = 0.300893 loss)
I1211 15:59:40.688092 16720 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1211 15:59:46.871497 16720 solver.cpp:218] Iteration 100600 (16.1759 iter/s, 6.18205s/100 iters), loss = 0.394559
I1211 15:59:46.871497 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 15:59:46.871497 16720 solver.cpp:237]     Train net output #1: loss = 0.394559 (* 1 = 0.394559 loss)
I1211 15:59:46.871497 16720 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1211 15:59:53.096032 16720 solver.cpp:218] Iteration 100700 (16.0643 iter/s, 6.22498s/100 iters), loss = 0.378652
I1211 15:59:53.096032 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 15:59:53.096032 16720 solver.cpp:237]     Train net output #1: loss = 0.378652 (* 1 = 0.378652 loss)
I1211 15:59:53.096032 16720 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1211 15:59:59.318598 16720 solver.cpp:218] Iteration 100800 (16.074 iter/s, 6.22124s/100 iters), loss = 0.408508
I1211 15:59:59.318598 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 15:59:59.318598 16720 solver.cpp:237]     Train net output #1: loss = 0.408508 (* 1 = 0.408508 loss)
I1211 15:59:59.318598 16720 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1211 16:00:05.561854 16720 solver.cpp:218] Iteration 100900 (16.0186 iter/s, 6.24275s/100 iters), loss = 0.39152
I1211 16:00:05.561854 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:00:05.561854 16720 solver.cpp:237]     Train net output #1: loss = 0.39152 (* 1 = 0.39152 loss)
I1211 16:00:05.561854 16720 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1211 16:00:11.461089  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:00:11.705603 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101000.caffemodel
I1211 16:00:11.721604 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101000.solverstate
I1211 16:00:11.726605 16720 solver.cpp:330] Iteration 101000, Testing net (#0)
I1211 16:00:11.726605 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:00:13.088752 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:00:13.142751 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6799
I1211 16:00:13.142751 16720 solver.cpp:397]     Test net output #1: loss = 1.20251 (* 1 = 1.20251 loss)
I1211 16:00:13.202756 16720 solver.cpp:218] Iteration 101000 (13.0874 iter/s, 7.64095s/100 iters), loss = 0.32228
I1211 16:00:13.202756 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:00:13.202756 16720 solver.cpp:237]     Train net output #1: loss = 0.32228 (* 1 = 0.32228 loss)
I1211 16:00:13.202756 16720 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1211 16:00:19.403282 16720 solver.cpp:218] Iteration 101100 (16.1308 iter/s, 6.19932s/100 iters), loss = 0.419523
I1211 16:00:19.403282 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 16:00:19.403282 16720 solver.cpp:237]     Train net output #1: loss = 0.419523 (* 1 = 0.419523 loss)
I1211 16:00:19.403282 16720 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1211 16:00:25.568801 16720 solver.cpp:218] Iteration 101200 (16.2196 iter/s, 6.16537s/100 iters), loss = 0.310481
I1211 16:00:25.568801 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:00:25.568801 16720 solver.cpp:237]     Train net output #1: loss = 0.310481 (* 1 = 0.310481 loss)
I1211 16:00:25.568801 16720 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1211 16:00:31.741222 16720 solver.cpp:218] Iteration 101300 (16.202 iter/s, 6.17207s/100 iters), loss = 0.341483
I1211 16:00:31.741222 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:00:31.741222 16720 solver.cpp:237]     Train net output #1: loss = 0.341483 (* 1 = 0.341483 loss)
I1211 16:00:31.741222 16720 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1211 16:00:37.892659 16720 solver.cpp:218] Iteration 101400 (16.2574 iter/s, 6.15104s/100 iters), loss = 0.407163
I1211 16:00:37.893159 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 16:00:37.893159 16720 solver.cpp:237]     Train net output #1: loss = 0.407163 (* 1 = 0.407163 loss)
I1211 16:00:37.893159 16720 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1211 16:00:43.740280  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:00:43.982374 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101500.caffemodel
I1211 16:00:43.997897 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_101500.solverstate
I1211 16:00:44.002383 16720 solver.cpp:330] Iteration 101500, Testing net (#0)
I1211 16:00:44.002383 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:00:45.338116 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:00:45.391142 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6747
I1211 16:00:45.391142 16720 solver.cpp:397]     Test net output #1: loss = 1.21454 (* 1 = 1.21454 loss)
I1211 16:00:45.450152 16720 solver.cpp:218] Iteration 101500 (13.2329 iter/s, 7.55692s/100 iters), loss = 0.354511
I1211 16:00:45.450152 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:00:45.450152 16720 solver.cpp:237]     Train net output #1: loss = 0.354511 (* 1 = 0.354511 loss)
I1211 16:00:45.450152 16720 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1211 16:00:51.601656 16720 solver.cpp:218] Iteration 101600 (16.2581 iter/s, 6.15077s/100 iters), loss = 0.385356
I1211 16:00:51.601656 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:00:51.601656 16720 solver.cpp:237]     Train net output #1: loss = 0.385356 (* 1 = 0.385356 loss)
I1211 16:00:51.601656 16720 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1211 16:00:57.757814 16720 solver.cpp:218] Iteration 101700 (16.2445 iter/s, 6.15591s/100 iters), loss = 0.38691
I1211 16:00:57.757814 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:00:57.757814 16720 solver.cpp:237]     Train net output #1: loss = 0.38691 (* 1 = 0.38691 loss)
I1211 16:00:57.757814 16720 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1211 16:01:03.913040 16720 solver.cpp:218] Iteration 101800 (16.246 iter/s, 6.15535s/100 iters), loss = 0.34847
I1211 16:01:03.913040 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:01:03.913040 16720 solver.cpp:237]     Train net output #1: loss = 0.34847 (* 1 = 0.34847 loss)
I1211 16:01:03.913040 16720 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1211 16:01:10.072324 16720 solver.cpp:218] Iteration 101900 (16.2372 iter/s, 6.1587s/100 iters), loss = 0.394441
I1211 16:01:10.072324 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:01:10.072324 16720 solver.cpp:237]     Train net output #1: loss = 0.394441 (* 1 = 0.394441 loss)
I1211 16:01:10.072324 16720 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1211 16:01:15.921772  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:01:16.163796 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102000.caffemodel
I1211 16:01:16.179796 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102000.solverstate
I1211 16:01:16.184798 16720 solver.cpp:330] Iteration 102000, Testing net (#0)
I1211 16:01:16.184798 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:01:17.520081 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:01:17.573081 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6741
I1211 16:01:17.573081 16720 solver.cpp:397]     Test net output #1: loss = 1.21211 (* 1 = 1.21211 loss)
I1211 16:01:17.631636 16720 solver.cpp:218] Iteration 102000 (13.2292 iter/s, 7.55905s/100 iters), loss = 0.334421
I1211 16:01:17.631636 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:01:17.631636 16720 solver.cpp:237]     Train net output #1: loss = 0.334421 (* 1 = 0.334421 loss)
I1211 16:01:17.631636 16720 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1211 16:01:23.794446 16720 solver.cpp:218] Iteration 102100 (16.2293 iter/s, 6.16169s/100 iters), loss = 0.394056
I1211 16:01:23.794446 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:01:23.794446 16720 solver.cpp:237]     Train net output #1: loss = 0.394056 (* 1 = 0.394056 loss)
I1211 16:01:23.794446 16720 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1211 16:01:29.953310 16720 solver.cpp:218] Iteration 102200 (16.2365 iter/s, 6.15896s/100 iters), loss = 0.284678
I1211 16:01:29.953310 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:01:29.953310 16720 solver.cpp:237]     Train net output #1: loss = 0.284678 (* 1 = 0.284678 loss)
I1211 16:01:29.953310 16720 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1211 16:01:36.108911 16720 solver.cpp:218] Iteration 102300 (16.2478 iter/s, 6.15469s/100 iters), loss = 0.432009
I1211 16:01:36.108911 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:01:36.108911 16720 solver.cpp:237]     Train net output #1: loss = 0.432009 (* 1 = 0.432009 loss)
I1211 16:01:36.108911 16720 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1211 16:01:42.269728 16720 solver.cpp:218] Iteration 102400 (16.2329 iter/s, 6.16034s/100 iters), loss = 0.488632
I1211 16:01:42.269728 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 16:01:42.269728 16720 solver.cpp:237]     Train net output #1: loss = 0.488632 (* 1 = 0.488632 loss)
I1211 16:01:42.269728 16720 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1211 16:01:48.129634  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:01:48.372655 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102500.caffemodel
I1211 16:01:48.387655 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_102500.solverstate
I1211 16:01:48.391655 16720 solver.cpp:330] Iteration 102500, Testing net (#0)
I1211 16:01:48.392657 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:01:49.730005 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:01:49.782003 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6756
I1211 16:01:49.782003 16720 solver.cpp:397]     Test net output #1: loss = 1.21629 (* 1 = 1.21629 loss)
I1211 16:01:49.841013 16720 solver.cpp:218] Iteration 102500 (13.2083 iter/s, 7.57101s/100 iters), loss = 0.35835
I1211 16:01:49.841013 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:01:49.841013 16720 solver.cpp:237]     Train net output #1: loss = 0.35835 (* 1 = 0.35835 loss)
I1211 16:01:49.841013 16720 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1211 16:01:55.989815 16720 solver.cpp:218] Iteration 102600 (16.2647 iter/s, 6.1483s/100 iters), loss = 0.3452
I1211 16:01:55.989815 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:01:55.989815 16720 solver.cpp:237]     Train net output #1: loss = 0.345201 (* 1 = 0.345201 loss)
I1211 16:01:55.989815 16720 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1211 16:02:02.138669 16720 solver.cpp:218] Iteration 102700 (16.2633 iter/s, 6.14882s/100 iters), loss = 0.377239
I1211 16:02:02.138669 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:02:02.138669 16720 solver.cpp:237]     Train net output #1: loss = 0.377239 (* 1 = 0.377239 loss)
I1211 16:02:02.138669 16720 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1211 16:02:08.287488 16720 solver.cpp:218] Iteration 102800 (16.2644 iter/s, 6.14842s/100 iters), loss = 0.382831
I1211 16:02:08.287488 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:02:08.287488 16720 solver.cpp:237]     Train net output #1: loss = 0.382831 (* 1 = 0.382831 loss)
I1211 16:02:08.287488 16720 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1211 16:02:14.439215 16720 solver.cpp:218] Iteration 102900 (16.2557 iter/s, 6.15168s/100 iters), loss = 0.296132
I1211 16:02:14.440217 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:02:14.440217 16720 solver.cpp:237]     Train net output #1: loss = 0.296132 (* 1 = 0.296132 loss)
I1211 16:02:14.440217 16720 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1211 16:02:20.287266  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:02:20.530299 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103000.caffemodel
I1211 16:02:20.546298 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103000.solverstate
I1211 16:02:20.550298 16720 solver.cpp:330] Iteration 103000, Testing net (#0)
I1211 16:02:20.550298 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:02:21.887610 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:02:21.940623 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6743
I1211 16:02:21.940623 16720 solver.cpp:397]     Test net output #1: loss = 1.21816 (* 1 = 1.21816 loss)
I1211 16:02:21.998620 16720 solver.cpp:218] Iteration 103000 (13.2301 iter/s, 7.55852s/100 iters), loss = 0.299315
I1211 16:02:21.998620 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:02:21.998620 16720 solver.cpp:237]     Train net output #1: loss = 0.299315 (* 1 = 0.299315 loss)
I1211 16:02:21.998620 16720 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1211 16:02:28.153409 16720 solver.cpp:218] Iteration 103100 (16.2479 iter/s, 6.15465s/100 iters), loss = 0.342059
I1211 16:02:28.153409 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:02:28.153409 16720 solver.cpp:237]     Train net output #1: loss = 0.342059 (* 1 = 0.342059 loss)
I1211 16:02:28.153409 16720 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1211 16:02:34.307327 16720 solver.cpp:218] Iteration 103200 (16.2521 iter/s, 6.15305s/100 iters), loss = 0.323724
I1211 16:02:34.307327 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:02:34.307327 16720 solver.cpp:237]     Train net output #1: loss = 0.323724 (* 1 = 0.323724 loss)
I1211 16:02:34.307327 16720 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1211 16:02:40.469228 16720 solver.cpp:218] Iteration 103300 (16.2289 iter/s, 6.16186s/100 iters), loss = 0.363999
I1211 16:02:40.469228 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:02:40.469228 16720 solver.cpp:237]     Train net output #1: loss = 0.363999 (* 1 = 0.363999 loss)
I1211 16:02:40.469228 16720 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1211 16:02:46.635987 16720 solver.cpp:218] Iteration 103400 (16.2173 iter/s, 6.16626s/100 iters), loss = 0.442153
I1211 16:02:46.635987 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:02:46.635987 16720 solver.cpp:237]     Train net output #1: loss = 0.442153 (* 1 = 0.442153 loss)
I1211 16:02:46.635987 16720 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1211 16:02:52.498888  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:02:52.741917 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103500.caffemodel
I1211 16:02:52.756917 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_103500.solverstate
I1211 16:02:52.761919 16720 solver.cpp:330] Iteration 103500, Testing net (#0)
I1211 16:02:52.761919 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:02:54.098156 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:02:54.151167 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1211 16:02:54.151167 16720 solver.cpp:397]     Test net output #1: loss = 1.21767 (* 1 = 1.21767 loss)
I1211 16:02:54.210165 16720 solver.cpp:218] Iteration 103500 (13.2038 iter/s, 7.57357s/100 iters), loss = 0.259203
I1211 16:02:54.210165 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:02:54.210165 16720 solver.cpp:237]     Train net output #1: loss = 0.259203 (* 1 = 0.259203 loss)
I1211 16:02:54.210165 16720 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1211 16:03:00.362334 16720 solver.cpp:218] Iteration 103600 (16.2562 iter/s, 6.15149s/100 iters), loss = 0.371857
I1211 16:03:00.362334 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:03:00.362334 16720 solver.cpp:237]     Train net output #1: loss = 0.371857 (* 1 = 0.371857 loss)
I1211 16:03:00.362334 16720 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1211 16:03:06.519976 16720 solver.cpp:218] Iteration 103700 (16.2415 iter/s, 6.15708s/100 iters), loss = 0.360031
I1211 16:03:06.519976 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:03:06.519976 16720 solver.cpp:237]     Train net output #1: loss = 0.360031 (* 1 = 0.360031 loss)
I1211 16:03:06.519976 16720 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1211 16:03:12.664127 16720 solver.cpp:218] Iteration 103800 (16.2765 iter/s, 6.14383s/100 iters), loss = 0.337664
I1211 16:03:12.664127 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:03:12.664127 16720 solver.cpp:237]     Train net output #1: loss = 0.337664 (* 1 = 0.337664 loss)
I1211 16:03:12.664127 16720 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1211 16:03:18.813599 16720 solver.cpp:218] Iteration 103900 (16.2622 iter/s, 6.14922s/100 iters), loss = 0.373886
I1211 16:03:18.813599 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:03:18.813599 16720 solver.cpp:237]     Train net output #1: loss = 0.373886 (* 1 = 0.373886 loss)
I1211 16:03:18.813599 16720 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1211 16:03:24.671047  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:03:24.912083 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104000.caffemodel
I1211 16:03:24.927587 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104000.solverstate
I1211 16:03:24.932087 16720 solver.cpp:330] Iteration 104000, Testing net (#0)
I1211 16:03:24.932587 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:03:26.269194 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:03:26.322697 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6758
I1211 16:03:26.323197 16720 solver.cpp:397]     Test net output #1: loss = 1.23637 (* 1 = 1.23637 loss)
I1211 16:03:26.381198 16720 solver.cpp:218] Iteration 104000 (13.2159 iter/s, 7.56667s/100 iters), loss = 0.336384
I1211 16:03:26.381198 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:03:26.381198 16720 solver.cpp:237]     Train net output #1: loss = 0.336385 (* 1 = 0.336385 loss)
I1211 16:03:26.381198 16720 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1211 16:03:32.537109 16720 solver.cpp:218] Iteration 104100 (16.2427 iter/s, 6.15662s/100 iters), loss = 0.340498
I1211 16:03:32.538359 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:03:32.538359 16720 solver.cpp:237]     Train net output #1: loss = 0.340498 (* 1 = 0.340498 loss)
I1211 16:03:32.538359 16720 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1211 16:03:38.676729 16720 solver.cpp:218] Iteration 104200 (16.2895 iter/s, 6.13893s/100 iters), loss = 0.317106
I1211 16:03:38.677729 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:03:38.677729 16720 solver.cpp:237]     Train net output #1: loss = 0.317106 (* 1 = 0.317106 loss)
I1211 16:03:38.677729 16720 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1211 16:03:44.838171 16720 solver.cpp:218] Iteration 104300 (16.2337 iter/s, 6.16003s/100 iters), loss = 0.316437
I1211 16:03:44.838171 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:03:44.838171 16720 solver.cpp:237]     Train net output #1: loss = 0.316437 (* 1 = 0.316437 loss)
I1211 16:03:44.838171 16720 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1211 16:03:50.995666 16720 solver.cpp:218] Iteration 104400 (16.2407 iter/s, 6.15736s/100 iters), loss = 0.349575
I1211 16:03:50.995666 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:03:50.995666 16720 solver.cpp:237]     Train net output #1: loss = 0.349575 (* 1 = 0.349575 loss)
I1211 16:03:50.995666 16720 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1211 16:03:56.851084  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:03:57.095095 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104500.caffemodel
I1211 16:03:57.110095 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_104500.solverstate
I1211 16:03:57.114096 16720 solver.cpp:330] Iteration 104500, Testing net (#0)
I1211 16:03:57.114096 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:03:58.451207 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:03:58.503207 16720 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1211 16:03:58.503207 16720 solver.cpp:397]     Test net output #1: loss = 1.2234 (* 1 = 1.2234 loss)
I1211 16:03:58.562213 16720 solver.cpp:218] Iteration 104500 (13.2163 iter/s, 7.56642s/100 iters), loss = 0.313887
I1211 16:03:58.562213 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:03:58.562213 16720 solver.cpp:237]     Train net output #1: loss = 0.313887 (* 1 = 0.313887 loss)
I1211 16:03:58.562213 16720 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1211 16:04:04.723656 16720 solver.cpp:218] Iteration 104600 (16.231 iter/s, 6.16104s/100 iters), loss = 0.385235
I1211 16:04:04.723656 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:04:04.723656 16720 solver.cpp:237]     Train net output #1: loss = 0.385235 (* 1 = 0.385235 loss)
I1211 16:04:04.723656 16720 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1211 16:04:10.881088 16720 solver.cpp:218] Iteration 104700 (16.2431 iter/s, 6.15645s/100 iters), loss = 0.306199
I1211 16:04:10.881088 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:04:10.881088 16720 solver.cpp:237]     Train net output #1: loss = 0.306199 (* 1 = 0.306199 loss)
I1211 16:04:10.881088 16720 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1211 16:04:17.046566 16720 solver.cpp:218] Iteration 104800 (16.2211 iter/s, 6.16482s/100 iters), loss = 0.363215
I1211 16:04:17.046566 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:04:17.046566 16720 solver.cpp:237]     Train net output #1: loss = 0.363215 (* 1 = 0.363215 loss)
I1211 16:04:17.046566 16720 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1211 16:04:23.209066 16720 solver.cpp:218] Iteration 104900 (16.2285 iter/s, 6.16201s/100 iters), loss = 0.348424
I1211 16:04:23.209066 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:04:23.209066 16720 solver.cpp:237]     Train net output #1: loss = 0.348424 (* 1 = 0.348424 loss)
I1211 16:04:23.209066 16720 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1211 16:04:29.068440  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:04:29.312451 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105000.caffemodel
I1211 16:04:29.327955 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105000.solverstate
I1211 16:04:29.332955 16720 solver.cpp:330] Iteration 105000, Testing net (#0)
I1211 16:04:29.332955 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:04:30.668550 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:04:30.721549 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6755
I1211 16:04:30.721549 16720 solver.cpp:397]     Test net output #1: loss = 1.23296 (* 1 = 1.23296 loss)
I1211 16:04:30.780048 16720 solver.cpp:218] Iteration 105000 (13.2092 iter/s, 7.57045s/100 iters), loss = 0.301505
I1211 16:04:30.780048 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:04:30.780048 16720 solver.cpp:237]     Train net output #1: loss = 0.301505 (* 1 = 0.301505 loss)
I1211 16:04:30.780048 16720 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1211 16:04:36.929805 16720 solver.cpp:218] Iteration 105100 (16.2612 iter/s, 6.14961s/100 iters), loss = 0.314743
I1211 16:04:36.929805 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:04:36.929805 16720 solver.cpp:237]     Train net output #1: loss = 0.314743 (* 1 = 0.314743 loss)
I1211 16:04:36.929805 16720 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1211 16:04:43.088296 16720 solver.cpp:218] Iteration 105200 (16.2392 iter/s, 6.15795s/100 iters), loss = 0.314222
I1211 16:04:43.088296 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:04:43.088296 16720 solver.cpp:237]     Train net output #1: loss = 0.314222 (* 1 = 0.314222 loss)
I1211 16:04:43.088296 16720 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1211 16:04:49.243719 16720 solver.cpp:218] Iteration 105300 (16.2475 iter/s, 6.15478s/100 iters), loss = 0.334945
I1211 16:04:49.243719 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:04:49.243719 16720 solver.cpp:237]     Train net output #1: loss = 0.334945 (* 1 = 0.334945 loss)
I1211 16:04:49.243719 16720 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1211 16:04:55.405165 16720 solver.cpp:218] Iteration 105400 (16.23 iter/s, 6.16142s/100 iters), loss = 0.431231
I1211 16:04:55.405165 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 16:04:55.405165 16720 solver.cpp:237]     Train net output #1: loss = 0.431231 (* 1 = 0.431231 loss)
I1211 16:04:55.405165 16720 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1211 16:05:01.265589  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:05:01.509601 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105500.caffemodel
I1211 16:05:01.524602 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_105500.solverstate
I1211 16:05:01.529610 16720 solver.cpp:330] Iteration 105500, Testing net (#0)
I1211 16:05:01.529610 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:05:02.863706 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:05:02.916710 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1211 16:05:02.916710 16720 solver.cpp:397]     Test net output #1: loss = 1.23845 (* 1 = 1.23845 loss)
I1211 16:05:02.974716 16720 solver.cpp:218] Iteration 105500 (13.2112 iter/s, 7.56935s/100 iters), loss = 0.276121
I1211 16:05:02.974716 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:05:02.974716 16720 solver.cpp:237]     Train net output #1: loss = 0.276121 (* 1 = 0.276121 loss)
I1211 16:05:02.974716 16720 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1211 16:05:09.142159 16720 solver.cpp:218] Iteration 105600 (16.2169 iter/s, 6.16641s/100 iters), loss = 0.382596
I1211 16:05:09.142159 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:05:09.142159 16720 solver.cpp:237]     Train net output #1: loss = 0.382596 (* 1 = 0.382596 loss)
I1211 16:05:09.142159 16720 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1211 16:05:15.302629 16720 solver.cpp:218] Iteration 105700 (16.2336 iter/s, 6.16008s/100 iters), loss = 0.291458
I1211 16:05:15.302629 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:05:15.302629 16720 solver.cpp:237]     Train net output #1: loss = 0.291458 (* 1 = 0.291458 loss)
I1211 16:05:15.302629 16720 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1211 16:05:21.451655 16720 solver.cpp:218] Iteration 105800 (16.2645 iter/s, 6.14835s/100 iters), loss = 0.354238
I1211 16:05:21.451655 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:05:21.451655 16720 solver.cpp:237]     Train net output #1: loss = 0.354238 (* 1 = 0.354238 loss)
I1211 16:05:21.451655 16720 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1211 16:05:27.613663 16720 solver.cpp:218] Iteration 105900 (16.2291 iter/s, 6.16178s/100 iters), loss = 0.408538
I1211 16:05:27.613663 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:05:27.613663 16720 solver.cpp:237]     Train net output #1: loss = 0.408538 (* 1 = 0.408538 loss)
I1211 16:05:27.613663 16720 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1211 16:05:33.469125  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:05:33.711136 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106000.caffemodel
I1211 16:05:33.726136 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106000.solverstate
I1211 16:05:33.731137 16720 solver.cpp:330] Iteration 106000, Testing net (#0)
I1211 16:05:33.731137 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:05:35.068281 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:05:35.121280 16720 solver.cpp:397]     Test net output #0: accuracy = 0.676
I1211 16:05:35.121280 16720 solver.cpp:397]     Test net output #1: loss = 1.2364 (* 1 = 1.2364 loss)
I1211 16:05:35.180289 16720 solver.cpp:218] Iteration 106000 (13.2172 iter/s, 7.56591s/100 iters), loss = 0.296903
I1211 16:05:35.180289 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:05:35.180289 16720 solver.cpp:237]     Train net output #1: loss = 0.296903 (* 1 = 0.296903 loss)
I1211 16:05:35.180289 16720 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1211 16:05:41.319799 16720 solver.cpp:218] Iteration 106100 (16.2871 iter/s, 6.13982s/100 iters), loss = 0.391713
I1211 16:05:41.320799 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:05:41.320799 16720 solver.cpp:237]     Train net output #1: loss = 0.391713 (* 1 = 0.391713 loss)
I1211 16:05:41.320799 16720 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1211 16:05:47.480285 16720 solver.cpp:218] Iteration 106200 (16.2338 iter/s, 6.16s/100 iters), loss = 0.314818
I1211 16:05:47.481284 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:05:47.481284 16720 solver.cpp:237]     Train net output #1: loss = 0.314818 (* 1 = 0.314818 loss)
I1211 16:05:47.481284 16720 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1211 16:05:53.645758 16720 solver.cpp:218] Iteration 106300 (16.2226 iter/s, 6.16424s/100 iters), loss = 0.377259
I1211 16:05:53.645758 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:05:53.645758 16720 solver.cpp:237]     Train net output #1: loss = 0.377259 (* 1 = 0.377259 loss)
I1211 16:05:53.645758 16720 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1211 16:05:59.799288 16720 solver.cpp:218] Iteration 106400 (16.2527 iter/s, 6.15282s/100 iters), loss = 0.445319
I1211 16:05:59.799288 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:05:59.799288 16720 solver.cpp:237]     Train net output #1: loss = 0.445319 (* 1 = 0.445319 loss)
I1211 16:05:59.799288 16720 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1211 16:06:05.641788  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:06:05.883803 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106500.caffemodel
I1211 16:06:05.899803 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_106500.solverstate
I1211 16:06:05.903803 16720 solver.cpp:330] Iteration 106500, Testing net (#0)
I1211 16:06:05.903803 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:06:07.241952 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:06:07.294950 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1211 16:06:07.294950 16720 solver.cpp:397]     Test net output #1: loss = 1.23522 (* 1 = 1.23522 loss)
I1211 16:06:07.353952 16720 solver.cpp:218] Iteration 106500 (13.237 iter/s, 7.5546s/100 iters), loss = 0.266118
I1211 16:06:07.354454 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:06:07.354454 16720 solver.cpp:237]     Train net output #1: loss = 0.266118 (* 1 = 0.266118 loss)
I1211 16:06:07.354454 16720 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1211 16:06:13.517822 16720 solver.cpp:218] Iteration 106600 (16.2241 iter/s, 6.16368s/100 iters), loss = 0.348809
I1211 16:06:13.517822 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:06:13.517822 16720 solver.cpp:237]     Train net output #1: loss = 0.348809 (* 1 = 0.348809 loss)
I1211 16:06:13.517822 16720 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1211 16:06:19.673305 16720 solver.cpp:218] Iteration 106700 (16.2466 iter/s, 6.15513s/100 iters), loss = 0.280535
I1211 16:06:19.673305 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:06:19.673305 16720 solver.cpp:237]     Train net output #1: loss = 0.280535 (* 1 = 0.280535 loss)
I1211 16:06:19.673305 16720 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1211 16:06:25.820803 16720 solver.cpp:218] Iteration 106800 (16.2695 iter/s, 6.14646s/100 iters), loss = 0.459097
I1211 16:06:25.820803 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:06:25.820803 16720 solver.cpp:237]     Train net output #1: loss = 0.459097 (* 1 = 0.459097 loss)
I1211 16:06:25.820803 16720 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1211 16:06:31.977301 16720 solver.cpp:218] Iteration 106900 (16.2422 iter/s, 6.1568s/100 iters), loss = 0.349346
I1211 16:06:31.978302 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:06:31.978302 16720 solver.cpp:237]     Train net output #1: loss = 0.349346 (* 1 = 0.349346 loss)
I1211 16:06:31.978302 16720 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1211 16:06:37.830749  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:06:38.072767 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107000.caffemodel
I1211 16:06:38.086766 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107000.solverstate
I1211 16:06:38.091765 16720 solver.cpp:330] Iteration 107000, Testing net (#0)
I1211 16:06:38.091765 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:06:39.427882 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:06:39.479889 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1211 16:06:39.479889 16720 solver.cpp:397]     Test net output #1: loss = 1.24266 (* 1 = 1.24266 loss)
I1211 16:06:39.539887 16720 solver.cpp:218] Iteration 107000 (13.2253 iter/s, 7.56128s/100 iters), loss = 0.221353
I1211 16:06:39.539887 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:06:39.539887 16720 solver.cpp:237]     Train net output #1: loss = 0.221354 (* 1 = 0.221354 loss)
I1211 16:06:39.539887 16720 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1211 16:06:45.696409 16720 solver.cpp:218] Iteration 107100 (16.2428 iter/s, 6.15657s/100 iters), loss = 0.389374
I1211 16:06:45.696409 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:06:45.696409 16720 solver.cpp:237]     Train net output #1: loss = 0.389374 (* 1 = 0.389374 loss)
I1211 16:06:45.696409 16720 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1211 16:06:51.857906 16720 solver.cpp:218] Iteration 107200 (16.2317 iter/s, 6.16078s/100 iters), loss = 0.24579
I1211 16:06:51.857906 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:06:51.857906 16720 solver.cpp:237]     Train net output #1: loss = 0.24579 (* 1 = 0.24579 loss)
I1211 16:06:51.857906 16720 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1211 16:06:58.013424 16720 solver.cpp:218] Iteration 107300 (16.2464 iter/s, 6.1552s/100 iters), loss = 0.333897
I1211 16:06:58.013424 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:06:58.013424 16720 solver.cpp:237]     Train net output #1: loss = 0.333897 (* 1 = 0.333897 loss)
I1211 16:06:58.013424 16720 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1211 16:07:04.162410 16720 solver.cpp:218] Iteration 107400 (16.2647 iter/s, 6.14828s/100 iters), loss = 0.371836
I1211 16:07:04.162410 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:07:04.162410 16720 solver.cpp:237]     Train net output #1: loss = 0.371836 (* 1 = 0.371836 loss)
I1211 16:07:04.162410 16720 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1211 16:07:10.017405  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:07:10.258921 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107500.caffemodel
I1211 16:07:10.275424 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_107500.solverstate
I1211 16:07:10.280426 16720 solver.cpp:330] Iteration 107500, Testing net (#0)
I1211 16:07:10.280426 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:07:11.615545 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:07:11.668550 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6767
I1211 16:07:11.668550 16720 solver.cpp:397]     Test net output #1: loss = 1.24491 (* 1 = 1.24491 loss)
I1211 16:07:11.726549 16720 solver.cpp:218] Iteration 107500 (13.2209 iter/s, 7.56379s/100 iters), loss = 0.277151
I1211 16:07:11.726549 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:07:11.726549 16720 solver.cpp:237]     Train net output #1: loss = 0.277152 (* 1 = 0.277152 loss)
I1211 16:07:11.726549 16720 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1211 16:07:17.892622 16720 solver.cpp:218] Iteration 107600 (16.2199 iter/s, 6.16526s/100 iters), loss = 0.331231
I1211 16:07:17.892622 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:07:17.892622 16720 solver.cpp:237]     Train net output #1: loss = 0.331231 (* 1 = 0.331231 loss)
I1211 16:07:17.892622 16720 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1211 16:07:24.055091 16720 solver.cpp:218] Iteration 107700 (16.2288 iter/s, 6.16189s/100 iters), loss = 0.343607
I1211 16:07:24.055091 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:07:24.055091 16720 solver.cpp:237]     Train net output #1: loss = 0.343607 (* 1 = 0.343607 loss)
I1211 16:07:24.055091 16720 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1211 16:07:30.216490 16720 solver.cpp:218] Iteration 107800 (16.23 iter/s, 6.16143s/100 iters), loss = 0.34775
I1211 16:07:30.216490 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:07:30.216490 16720 solver.cpp:237]     Train net output #1: loss = 0.34775 (* 1 = 0.34775 loss)
I1211 16:07:30.216490 16720 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1211 16:07:36.364692 16720 solver.cpp:218] Iteration 107900 (16.2663 iter/s, 6.14769s/100 iters), loss = 0.348335
I1211 16:07:36.365193 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:07:36.365193 16720 solver.cpp:237]     Train net output #1: loss = 0.348335 (* 1 = 0.348335 loss)
I1211 16:07:36.365193 16720 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1211 16:07:42.217640  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:07:42.460187 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108000.caffemodel
I1211 16:07:42.476207 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108000.solverstate
I1211 16:07:42.480207 16720 solver.cpp:330] Iteration 108000, Testing net (#0)
I1211 16:07:42.480207 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:07:43.815814 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:07:43.868815 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1211 16:07:43.868815 16720 solver.cpp:397]     Test net output #1: loss = 1.23855 (* 1 = 1.23855 loss)
I1211 16:07:43.927819 16720 solver.cpp:218] Iteration 108000 (13.2233 iter/s, 7.56238s/100 iters), loss = 0.28011
I1211 16:07:43.927819 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:07:43.927819 16720 solver.cpp:237]     Train net output #1: loss = 0.28011 (* 1 = 0.28011 loss)
I1211 16:07:43.927819 16720 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1211 16:07:50.075249 16720 solver.cpp:218] Iteration 108100 (16.2667 iter/s, 6.14751s/100 iters), loss = 0.32245
I1211 16:07:50.075249 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:07:50.075249 16720 solver.cpp:237]     Train net output #1: loss = 0.32245 (* 1 = 0.32245 loss)
I1211 16:07:50.075249 16720 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1211 16:07:56.228672 16720 solver.cpp:218] Iteration 108200 (16.2522 iter/s, 6.153s/100 iters), loss = 0.318986
I1211 16:07:56.228672 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:07:56.228672 16720 solver.cpp:237]     Train net output #1: loss = 0.318986 (* 1 = 0.318986 loss)
I1211 16:07:56.228672 16720 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1211 16:08:02.381119 16720 solver.cpp:218] Iteration 108300 (16.2561 iter/s, 6.15155s/100 iters), loss = 0.32873
I1211 16:08:02.381119 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:08:02.381119 16720 solver.cpp:237]     Train net output #1: loss = 0.32873 (* 1 = 0.32873 loss)
I1211 16:08:02.381119 16720 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1211 16:08:08.533968 16720 solver.cpp:218] Iteration 108400 (16.2542 iter/s, 6.15224s/100 iters), loss = 0.28458
I1211 16:08:08.533968 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:08:08.533968 16720 solver.cpp:237]     Train net output #1: loss = 0.28458 (* 1 = 0.28458 loss)
I1211 16:08:08.533968 16720 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1211 16:08:14.385108  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:08:14.626662 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108500.caffemodel
I1211 16:08:14.641664 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_108500.solverstate
I1211 16:08:14.646669 16720 solver.cpp:330] Iteration 108500, Testing net (#0)
I1211 16:08:14.646669 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:08:15.983755 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:08:16.036160 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6748
I1211 16:08:16.036160 16720 solver.cpp:397]     Test net output #1: loss = 1.24538 (* 1 = 1.24538 loss)
I1211 16:08:16.094667 16720 solver.cpp:218] Iteration 108500 (13.2261 iter/s, 7.56083s/100 iters), loss = 0.259971
I1211 16:08:16.094667 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:08:16.094667 16720 solver.cpp:237]     Train net output #1: loss = 0.259971 (* 1 = 0.259971 loss)
I1211 16:08:16.094667 16720 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1211 16:08:22.250178 16720 solver.cpp:218] Iteration 108600 (16.2463 iter/s, 6.15523s/100 iters), loss = 0.354062
I1211 16:08:22.250178 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:08:22.250178 16720 solver.cpp:237]     Train net output #1: loss = 0.354062 (* 1 = 0.354062 loss)
I1211 16:08:22.250178 16720 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1211 16:08:28.398361 16720 solver.cpp:218] Iteration 108700 (16.2679 iter/s, 6.14708s/100 iters), loss = 0.293014
I1211 16:08:28.398361 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:08:28.398361 16720 solver.cpp:237]     Train net output #1: loss = 0.293014 (* 1 = 0.293014 loss)
I1211 16:08:28.398361 16720 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1211 16:08:34.599966 16720 solver.cpp:218] Iteration 108800 (16.1263 iter/s, 6.20104s/100 iters), loss = 0.332003
I1211 16:08:34.599966 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:08:34.599966 16720 solver.cpp:237]     Train net output #1: loss = 0.332004 (* 1 = 0.332004 loss)
I1211 16:08:34.599966 16720 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1211 16:08:40.756399 16720 solver.cpp:218] Iteration 108900 (16.2438 iter/s, 6.15619s/100 iters), loss = 0.386949
I1211 16:08:40.756399 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:08:40.756399 16720 solver.cpp:237]     Train net output #1: loss = 0.386949 (* 1 = 0.386949 loss)
I1211 16:08:40.756399 16720 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1211 16:08:46.607218  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:08:46.847720 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109000.caffemodel
I1211 16:08:46.863720 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109000.solverstate
I1211 16:08:46.868721 16720 solver.cpp:330] Iteration 109000, Testing net (#0)
I1211 16:08:46.868721 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:08:48.205237 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:08:48.257246 16720 solver.cpp:397]     Test net output #0: accuracy = 0.676
I1211 16:08:48.257246 16720 solver.cpp:397]     Test net output #1: loss = 1.25087 (* 1 = 1.25087 loss)
I1211 16:08:48.316758 16720 solver.cpp:218] Iteration 109000 (13.2276 iter/s, 7.55995s/100 iters), loss = 0.243392
I1211 16:08:48.316758 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:08:48.316758 16720 solver.cpp:237]     Train net output #1: loss = 0.243392 (* 1 = 0.243392 loss)
I1211 16:08:48.316758 16720 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1211 16:08:54.475683 16720 solver.cpp:218] Iteration 109100 (16.2369 iter/s, 6.15881s/100 iters), loss = 0.293452
I1211 16:08:54.475683 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:08:54.475683 16720 solver.cpp:237]     Train net output #1: loss = 0.293452 (* 1 = 0.293452 loss)
I1211 16:08:54.475683 16720 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1211 16:09:00.624106 16720 solver.cpp:218] Iteration 109200 (16.2666 iter/s, 6.14758s/100 iters), loss = 0.295164
I1211 16:09:00.624106 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:09:00.624106 16720 solver.cpp:237]     Train net output #1: loss = 0.295164 (* 1 = 0.295164 loss)
I1211 16:09:00.624106 16720 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1211 16:09:06.782568 16720 solver.cpp:218] Iteration 109300 (16.238 iter/s, 6.15839s/100 iters), loss = 0.366127
I1211 16:09:06.782568 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:09:06.782568 16720 solver.cpp:237]     Train net output #1: loss = 0.366127 (* 1 = 0.366127 loss)
I1211 16:09:06.782568 16720 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1211 16:09:12.940021 16720 solver.cpp:218] Iteration 109400 (16.2409 iter/s, 6.15729s/100 iters), loss = 0.365513
I1211 16:09:12.940021 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:09:12.940021 16720 solver.cpp:237]     Train net output #1: loss = 0.365513 (* 1 = 0.365513 loss)
I1211 16:09:12.940021 16720 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1211 16:09:18.793282  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:09:19.034601 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109500.caffemodel
I1211 16:09:19.050307 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_109500.solverstate
I1211 16:09:19.055307 16720 solver.cpp:330] Iteration 109500, Testing net (#0)
I1211 16:09:19.055307 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:09:20.388766 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:09:20.441426 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6742
I1211 16:09:20.441426 16720 solver.cpp:397]     Test net output #1: loss = 1.25468 (* 1 = 1.25468 loss)
I1211 16:09:20.500437 16720 solver.cpp:218] Iteration 109500 (13.2286 iter/s, 7.55936s/100 iters), loss = 0.203349
I1211 16:09:20.500437 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:09:20.500437 16720 solver.cpp:237]     Train net output #1: loss = 0.20335 (* 1 = 0.20335 loss)
I1211 16:09:20.500437 16720 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1211 16:09:26.650986 16720 solver.cpp:218] Iteration 109600 (16.2601 iter/s, 6.15003s/100 iters), loss = 0.314051
I1211 16:09:26.650986 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:09:26.650986 16720 solver.cpp:237]     Train net output #1: loss = 0.314051 (* 1 = 0.314051 loss)
I1211 16:09:26.650986 16720 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1211 16:09:32.802095 16720 solver.cpp:218] Iteration 109700 (16.2579 iter/s, 6.15084s/100 iters), loss = 0.266791
I1211 16:09:32.802095 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:09:32.802095 16720 solver.cpp:237]     Train net output #1: loss = 0.266791 (* 1 = 0.266791 loss)
I1211 16:09:32.802095 16720 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1211 16:09:38.956379 16720 solver.cpp:218] Iteration 109800 (16.2486 iter/s, 6.15439s/100 iters), loss = 0.324466
I1211 16:09:38.956379 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:09:38.956379 16720 solver.cpp:237]     Train net output #1: loss = 0.324467 (* 1 = 0.324467 loss)
I1211 16:09:38.956379 16720 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1211 16:09:45.100705 16720 solver.cpp:218] Iteration 109900 (16.277 iter/s, 6.14362s/100 iters), loss = 0.373862
I1211 16:09:45.100705 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:09:45.100705 16720 solver.cpp:237]     Train net output #1: loss = 0.373862 (* 1 = 0.373862 loss)
I1211 16:09:45.100705 16720 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1211 16:09:50.951263  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:09:51.192283 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110000.caffemodel
I1211 16:09:51.207283 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110000.solverstate
I1211 16:09:51.211283 16720 solver.cpp:330] Iteration 110000, Testing net (#0)
I1211 16:09:51.212282 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:09:52.548388 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:09:52.600396 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1211 16:09:52.600396 16720 solver.cpp:397]     Test net output #1: loss = 1.26859 (* 1 = 1.26859 loss)
I1211 16:09:52.659400 16720 solver.cpp:218] Iteration 110000 (13.2301 iter/s, 7.55851s/100 iters), loss = 0.239168
I1211 16:09:52.660414 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:09:52.660414 16720 solver.cpp:237]     Train net output #1: loss = 0.239168 (* 1 = 0.239168 loss)
I1211 16:09:52.660414 16720 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1211 16:09:58.823976 16720 solver.cpp:218] Iteration 110100 (16.2254 iter/s, 6.16318s/100 iters), loss = 0.363864
I1211 16:09:58.823976 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:09:58.823976 16720 solver.cpp:237]     Train net output #1: loss = 0.363864 (* 1 = 0.363864 loss)
I1211 16:09:58.823976 16720 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1211 16:10:05.042750 16720 solver.cpp:218] Iteration 110200 (16.0808 iter/s, 6.2186s/100 iters), loss = 0.299793
I1211 16:10:05.042750 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:10:05.042750 16720 solver.cpp:237]     Train net output #1: loss = 0.299793 (* 1 = 0.299793 loss)
I1211 16:10:05.042750 16720 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1211 16:10:11.198184 16720 solver.cpp:218] Iteration 110300 (16.2476 iter/s, 6.15474s/100 iters), loss = 0.310528
I1211 16:10:11.198184 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:10:11.198184 16720 solver.cpp:237]     Train net output #1: loss = 0.310528 (* 1 = 0.310528 loss)
I1211 16:10:11.198184 16720 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1211 16:10:17.359633 16720 solver.cpp:218] Iteration 110400 (16.2311 iter/s, 6.161s/100 iters), loss = 0.387916
I1211 16:10:17.359633 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 16:10:17.359633 16720 solver.cpp:237]     Train net output #1: loss = 0.387916 (* 1 = 0.387916 loss)
I1211 16:10:17.359633 16720 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1211 16:10:23.219091  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:10:23.463120 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110500.caffemodel
I1211 16:10:23.478112 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_110500.solverstate
I1211 16:10:23.482111 16720 solver.cpp:330] Iteration 110500, Testing net (#0)
I1211 16:10:23.483114 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:10:24.820214 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:10:24.872221 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6728
I1211 16:10:24.872221 16720 solver.cpp:397]     Test net output #1: loss = 1.274 (* 1 = 1.274 loss)
I1211 16:10:24.931221 16720 solver.cpp:218] Iteration 110500 (13.2077 iter/s, 7.57131s/100 iters), loss = 0.24398
I1211 16:10:24.931221 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:10:24.931221 16720 solver.cpp:237]     Train net output #1: loss = 0.24398 (* 1 = 0.24398 loss)
I1211 16:10:24.931221 16720 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1211 16:10:31.093725 16720 solver.cpp:218] Iteration 110600 (16.2274 iter/s, 6.16243s/100 iters), loss = 0.380595
I1211 16:10:31.093725 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:10:31.093725 16720 solver.cpp:237]     Train net output #1: loss = 0.380595 (* 1 = 0.380595 loss)
I1211 16:10:31.093725 16720 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1211 16:10:37.247685 16720 solver.cpp:218] Iteration 110700 (16.2529 iter/s, 6.15275s/100 iters), loss = 0.217798
I1211 16:10:37.247685 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:10:37.247685 16720 solver.cpp:237]     Train net output #1: loss = 0.217798 (* 1 = 0.217798 loss)
I1211 16:10:37.247685 16720 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1211 16:10:43.407644 16720 solver.cpp:218] Iteration 110800 (16.2356 iter/s, 6.15929s/100 iters), loss = 0.285639
I1211 16:10:43.407644 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:10:43.407644 16720 solver.cpp:237]     Train net output #1: loss = 0.285639 (* 1 = 0.285639 loss)
I1211 16:10:43.407644 16720 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1211 16:10:49.570071 16720 solver.cpp:218] Iteration 110900 (16.2287 iter/s, 6.16194s/100 iters), loss = 0.398472
I1211 16:10:49.570071 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:10:49.570071 16720 solver.cpp:237]     Train net output #1: loss = 0.398472 (* 1 = 0.398472 loss)
I1211 16:10:49.570071 16720 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1211 16:10:55.425531  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:10:55.666548 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111000.caffemodel
I1211 16:10:55.682546 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111000.solverstate
I1211 16:10:55.686545 16720 solver.cpp:330] Iteration 111000, Testing net (#0)
I1211 16:10:55.686545 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:10:57.024698 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:10:57.077705 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1211 16:10:57.077705 16720 solver.cpp:397]     Test net output #1: loss = 1.25742 (* 1 = 1.25742 loss)
I1211 16:10:57.137706 16720 solver.cpp:218] Iteration 111000 (13.2153 iter/s, 7.56699s/100 iters), loss = 0.272514
I1211 16:10:57.137706 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:10:57.137706 16720 solver.cpp:237]     Train net output #1: loss = 0.272514 (* 1 = 0.272514 loss)
I1211 16:10:57.137706 16720 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1211 16:11:03.287147 16720 solver.cpp:218] Iteration 111100 (16.2603 iter/s, 6.14995s/100 iters), loss = 0.292657
I1211 16:11:03.288147 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:11:03.288147 16720 solver.cpp:237]     Train net output #1: loss = 0.292657 (* 1 = 0.292657 loss)
I1211 16:11:03.288147 16720 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1211 16:11:09.443161 16720 solver.cpp:218] Iteration 111200 (16.2475 iter/s, 6.15478s/100 iters), loss = 0.28158
I1211 16:11:09.443161 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:11:09.443161 16720 solver.cpp:237]     Train net output #1: loss = 0.28158 (* 1 = 0.28158 loss)
I1211 16:11:09.443161 16720 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1211 16:11:15.602210 16720 solver.cpp:218] Iteration 111300 (16.2357 iter/s, 6.15928s/100 iters), loss = 0.344828
I1211 16:11:15.602210 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:11:15.602210 16720 solver.cpp:237]     Train net output #1: loss = 0.344828 (* 1 = 0.344828 loss)
I1211 16:11:15.602210 16720 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1211 16:11:21.758723 16720 solver.cpp:218] Iteration 111400 (16.2448 iter/s, 6.1558s/100 iters), loss = 0.439264
I1211 16:11:21.758723 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 16:11:21.758723 16720 solver.cpp:237]     Train net output #1: loss = 0.439264 (* 1 = 0.439264 loss)
I1211 16:11:21.758723 16720 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1211 16:11:27.623144  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:11:27.865165 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111500.caffemodel
I1211 16:11:27.880164 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_111500.solverstate
I1211 16:11:27.884166 16720 solver.cpp:330] Iteration 111500, Testing net (#0)
I1211 16:11:27.884166 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:11:29.219280 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:11:29.271302 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6726
I1211 16:11:29.271302 16720 solver.cpp:397]     Test net output #1: loss = 1.26339 (* 1 = 1.26339 loss)
I1211 16:11:29.329293 16720 solver.cpp:218] Iteration 111500 (13.2092 iter/s, 7.57047s/100 iters), loss = 0.262076
I1211 16:11:29.329293 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:11:29.330293 16720 solver.cpp:237]     Train net output #1: loss = 0.262076 (* 1 = 0.262076 loss)
I1211 16:11:29.330293 16720 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1211 16:11:35.483242 16720 solver.cpp:218] Iteration 111600 (16.251 iter/s, 6.15346s/100 iters), loss = 0.33146
I1211 16:11:35.483242 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:11:35.483242 16720 solver.cpp:237]     Train net output #1: loss = 0.33146 (* 1 = 0.33146 loss)
I1211 16:11:35.483242 16720 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1211 16:11:41.643775 16720 solver.cpp:218] Iteration 111700 (16.2348 iter/s, 6.1596s/100 iters), loss = 0.313399
I1211 16:11:41.643775 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:11:41.643775 16720 solver.cpp:237]     Train net output #1: loss = 0.313399 (* 1 = 0.313399 loss)
I1211 16:11:41.643775 16720 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1211 16:11:47.788836 16720 solver.cpp:218] Iteration 111800 (16.2744 iter/s, 6.14461s/100 iters), loss = 0.308462
I1211 16:11:47.788836 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:11:47.788836 16720 solver.cpp:237]     Train net output #1: loss = 0.308462 (* 1 = 0.308462 loss)
I1211 16:11:47.788836 16720 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1211 16:11:53.942028 16720 solver.cpp:218] Iteration 111900 (16.2533 iter/s, 6.15261s/100 iters), loss = 0.337298
I1211 16:11:53.942028 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:11:53.942028 16720 solver.cpp:237]     Train net output #1: loss = 0.337299 (* 1 = 0.337299 loss)
I1211 16:11:53.942028 16720 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1211 16:11:59.793501  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:12:00.035121 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112000.caffemodel
I1211 16:12:00.050122 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112000.solverstate
I1211 16:12:00.055122 16720 solver.cpp:330] Iteration 112000, Testing net (#0)
I1211 16:12:00.055122 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:12:01.389315 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:12:01.441298 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1211 16:12:01.441298 16720 solver.cpp:397]     Test net output #1: loss = 1.2582 (* 1 = 1.2582 loss)
I1211 16:12:01.499320 16720 solver.cpp:218] Iteration 112000 (13.232 iter/s, 7.55746s/100 iters), loss = 0.28536
I1211 16:12:01.499320 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:12:01.499320 16720 solver.cpp:237]     Train net output #1: loss = 0.28536 (* 1 = 0.28536 loss)
I1211 16:12:01.499320 16720 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1211 16:12:07.648457 16720 solver.cpp:218] Iteration 112100 (16.2645 iter/s, 6.14838s/100 iters), loss = 0.34701
I1211 16:12:07.648457 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:12:07.648457 16720 solver.cpp:237]     Train net output #1: loss = 0.34701 (* 1 = 0.34701 loss)
I1211 16:12:07.648457 16720 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1211 16:12:13.801208 16720 solver.cpp:218] Iteration 112200 (16.2545 iter/s, 6.15216s/100 iters), loss = 0.264856
I1211 16:12:13.801208 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:12:13.801208 16720 solver.cpp:237]     Train net output #1: loss = 0.264856 (* 1 = 0.264856 loss)
I1211 16:12:13.801208 16720 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1211 16:12:19.953240 16720 solver.cpp:218] Iteration 112300 (16.2558 iter/s, 6.15163s/100 iters), loss = 0.369689
I1211 16:12:19.953240 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:12:19.953240 16720 solver.cpp:237]     Train net output #1: loss = 0.369689 (* 1 = 0.369689 loss)
I1211 16:12:19.953240 16720 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1211 16:12:26.109088 16720 solver.cpp:218] Iteration 112400 (16.2458 iter/s, 6.15545s/100 iters), loss = 0.355711
I1211 16:12:26.109088 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:12:26.109088 16720 solver.cpp:237]     Train net output #1: loss = 0.355711 (* 1 = 0.355711 loss)
I1211 16:12:26.109088 16720 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1211 16:12:31.965857  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:12:32.208883 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112500.caffemodel
I1211 16:12:32.224884 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_112500.solverstate
I1211 16:12:32.228881 16720 solver.cpp:330] Iteration 112500, Testing net (#0)
I1211 16:12:32.229883 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:12:33.564028 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:12:33.617048 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6752
I1211 16:12:33.617048 16720 solver.cpp:397]     Test net output #1: loss = 1.26901 (* 1 = 1.26901 loss)
I1211 16:12:33.676547 16720 solver.cpp:218] Iteration 112500 (13.2156 iter/s, 7.56681s/100 iters), loss = 0.282923
I1211 16:12:33.676547 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:12:33.676547 16720 solver.cpp:237]     Train net output #1: loss = 0.282923 (* 1 = 0.282923 loss)
I1211 16:12:33.676547 16720 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1211 16:12:39.843113 16720 solver.cpp:218] Iteration 112600 (16.2171 iter/s, 6.16634s/100 iters), loss = 0.344891
I1211 16:12:39.843113 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:12:39.843113 16720 solver.cpp:237]     Train net output #1: loss = 0.344892 (* 1 = 0.344892 loss)
I1211 16:12:39.843113 16720 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1211 16:12:46.005421 16720 solver.cpp:218] Iteration 112700 (16.2278 iter/s, 6.16225s/100 iters), loss = 0.323562
I1211 16:12:46.006422 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:12:46.006422 16720 solver.cpp:237]     Train net output #1: loss = 0.323562 (* 1 = 0.323562 loss)
I1211 16:12:46.006422 16720 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1211 16:12:52.167313 16720 solver.cpp:218] Iteration 112800 (16.2312 iter/s, 6.16096s/100 iters), loss = 0.425335
I1211 16:12:52.167313 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:12:52.167313 16720 solver.cpp:237]     Train net output #1: loss = 0.425335 (* 1 = 0.425335 loss)
I1211 16:12:52.167313 16720 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1211 16:12:58.331267 16720 solver.cpp:218] Iteration 112900 (16.2248 iter/s, 6.1634s/100 iters), loss = 0.37345
I1211 16:12:58.331267 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:12:58.331267 16720 solver.cpp:237]     Train net output #1: loss = 0.37345 (* 1 = 0.37345 loss)
I1211 16:12:58.331267 16720 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1211 16:13:04.181980  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:13:04.423702 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113000.caffemodel
I1211 16:13:04.438699 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113000.solverstate
I1211 16:13:04.443699 16720 solver.cpp:330] Iteration 113000, Testing net (#0)
I1211 16:13:04.443699 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:13:05.778795 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:13:05.831809 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 16:13:05.831809 16720 solver.cpp:397]     Test net output #1: loss = 1.26998 (* 1 = 1.26998 loss)
I1211 16:13:05.889806 16720 solver.cpp:218] Iteration 113000 (13.231 iter/s, 7.55803s/100 iters), loss = 0.248216
I1211 16:13:05.889806 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:13:05.889806 16720 solver.cpp:237]     Train net output #1: loss = 0.248216 (* 1 = 0.248216 loss)
I1211 16:13:05.889806 16720 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1211 16:13:12.041738 16720 solver.cpp:218] Iteration 113100 (16.2546 iter/s, 6.15212s/100 iters), loss = 0.369186
I1211 16:13:12.042739 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:13:12.042739 16720 solver.cpp:237]     Train net output #1: loss = 0.369187 (* 1 = 0.369187 loss)
I1211 16:13:12.042739 16720 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1211 16:13:18.198441 16720 solver.cpp:218] Iteration 113200 (16.2462 iter/s, 6.15528s/100 iters), loss = 0.270692
I1211 16:13:18.198441 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:13:18.198441 16720 solver.cpp:237]     Train net output #1: loss = 0.270692 (* 1 = 0.270692 loss)
I1211 16:13:18.198441 16720 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1211 16:13:24.348170 16720 solver.cpp:218] Iteration 113300 (16.2596 iter/s, 6.1502s/100 iters), loss = 0.309058
I1211 16:13:24.349170 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:13:24.349170 16720 solver.cpp:237]     Train net output #1: loss = 0.309058 (* 1 = 0.309058 loss)
I1211 16:13:24.349170 16720 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1211 16:13:30.498618 16720 solver.cpp:218] Iteration 113400 (16.2603 iter/s, 6.14993s/100 iters), loss = 0.318262
I1211 16:13:30.498618 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:13:30.498618 16720 solver.cpp:237]     Train net output #1: loss = 0.318263 (* 1 = 0.318263 loss)
I1211 16:13:30.498618 16720 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1211 16:13:36.356045  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:13:36.597070 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113500.caffemodel
I1211 16:13:36.612071 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_113500.solverstate
I1211 16:13:36.618072 16720 solver.cpp:330] Iteration 113500, Testing net (#0)
I1211 16:13:36.618072 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:13:37.954185 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:13:38.006189 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1211 16:13:38.006189 16720 solver.cpp:397]     Test net output #1: loss = 1.25777 (* 1 = 1.25777 loss)
I1211 16:13:38.065188 16720 solver.cpp:218] Iteration 113500 (13.2176 iter/s, 7.56569s/100 iters), loss = 0.226245
I1211 16:13:38.065188 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 16:13:38.065188 16720 solver.cpp:237]     Train net output #1: loss = 0.226245 (* 1 = 0.226245 loss)
I1211 16:13:38.065188 16720 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1211 16:13:44.212678 16720 solver.cpp:218] Iteration 113600 (16.2689 iter/s, 6.14672s/100 iters), loss = 0.313502
I1211 16:13:44.212678 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:13:44.212678 16720 solver.cpp:237]     Train net output #1: loss = 0.313502 (* 1 = 0.313502 loss)
I1211 16:13:44.212678 16720 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1211 16:13:50.362094 16720 solver.cpp:218] Iteration 113700 (16.2616 iter/s, 6.14945s/100 iters), loss = 0.269214
I1211 16:13:50.362094 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:13:50.362094 16720 solver.cpp:237]     Train net output #1: loss = 0.269214 (* 1 = 0.269214 loss)
I1211 16:13:50.362094 16720 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1211 16:13:56.507586 16720 solver.cpp:218] Iteration 113800 (16.2728 iter/s, 6.14521s/100 iters), loss = 0.32519
I1211 16:13:56.507586 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:13:56.507586 16720 solver.cpp:237]     Train net output #1: loss = 0.32519 (* 1 = 0.32519 loss)
I1211 16:13:56.507586 16720 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1211 16:14:02.667008 16720 solver.cpp:218] Iteration 113900 (16.2363 iter/s, 6.15903s/100 iters), loss = 0.355222
I1211 16:14:02.667008 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:14:02.667008 16720 solver.cpp:237]     Train net output #1: loss = 0.355222 (* 1 = 0.355222 loss)
I1211 16:14:02.667008 16720 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1211 16:14:08.511442  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:14:08.754453 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114000.caffemodel
I1211 16:14:08.769454 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114000.solverstate
I1211 16:14:08.773453 16720 solver.cpp:330] Iteration 114000, Testing net (#0)
I1211 16:14:08.773453 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:14:10.111541 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:14:10.164539 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6706
I1211 16:14:10.164539 16720 solver.cpp:397]     Test net output #1: loss = 1.27594 (* 1 = 1.27594 loss)
I1211 16:14:10.223543 16720 solver.cpp:218] Iteration 114000 (13.2349 iter/s, 7.5558s/100 iters), loss = 0.251255
I1211 16:14:10.223543 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:14:10.223543 16720 solver.cpp:237]     Train net output #1: loss = 0.251255 (* 1 = 0.251255 loss)
I1211 16:14:10.223543 16720 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1211 16:14:16.386210 16720 solver.cpp:218] Iteration 114100 (16.2286 iter/s, 6.16197s/100 iters), loss = 0.2632
I1211 16:14:16.386210 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:14:16.386210 16720 solver.cpp:237]     Train net output #1: loss = 0.2632 (* 1 = 0.2632 loss)
I1211 16:14:16.386210 16720 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1211 16:14:22.538735 16720 solver.cpp:218] Iteration 114200 (16.2529 iter/s, 6.15275s/100 iters), loss = 0.263389
I1211 16:14:22.538735 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:14:22.538735 16720 solver.cpp:237]     Train net output #1: loss = 0.263389 (* 1 = 0.263389 loss)
I1211 16:14:22.538735 16720 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1211 16:14:28.688716 16720 solver.cpp:218] Iteration 114300 (16.2625 iter/s, 6.14911s/100 iters), loss = 0.312169
I1211 16:14:28.688716 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:14:28.689218 16720 solver.cpp:237]     Train net output #1: loss = 0.312169 (* 1 = 0.312169 loss)
I1211 16:14:28.689218 16720 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1211 16:14:34.848665 16720 solver.cpp:218] Iteration 114400 (16.2344 iter/s, 6.15977s/100 iters), loss = 0.330059
I1211 16:14:34.848665 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:14:34.848665 16720 solver.cpp:237]     Train net output #1: loss = 0.330059 (* 1 = 0.330059 loss)
I1211 16:14:34.848665 16720 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1211 16:14:40.703068  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:14:40.943078 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114500.caffemodel
I1211 16:14:40.958078 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_114500.solverstate
I1211 16:14:40.962079 16720 solver.cpp:330] Iteration 114500, Testing net (#0)
I1211 16:14:40.962079 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:14:42.299183 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:14:42.352183 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1211 16:14:42.352183 16720 solver.cpp:397]     Test net output #1: loss = 1.28105 (* 1 = 1.28105 loss)
I1211 16:14:42.412202 16720 solver.cpp:218] Iteration 114500 (13.2231 iter/s, 7.56252s/100 iters), loss = 0.244578
I1211 16:14:42.412202 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:14:42.412202 16720 solver.cpp:237]     Train net output #1: loss = 0.244578 (* 1 = 0.244578 loss)
I1211 16:14:42.412202 16720 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1211 16:14:48.558645 16720 solver.cpp:218] Iteration 114600 (16.2696 iter/s, 6.14643s/100 iters), loss = 0.328073
I1211 16:14:48.558645 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:14:48.558645 16720 solver.cpp:237]     Train net output #1: loss = 0.328073 (* 1 = 0.328073 loss)
I1211 16:14:48.558645 16720 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1211 16:14:54.708129 16720 solver.cpp:218] Iteration 114700 (16.2622 iter/s, 6.14922s/100 iters), loss = 0.251275
I1211 16:14:54.708129 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:14:54.708129 16720 solver.cpp:237]     Train net output #1: loss = 0.251275 (* 1 = 0.251275 loss)
I1211 16:14:54.708129 16720 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1211 16:15:00.846807 16720 solver.cpp:218] Iteration 114800 (16.2911 iter/s, 6.13833s/100 iters), loss = 0.272541
I1211 16:15:00.846807 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:15:00.846807 16720 solver.cpp:237]     Train net output #1: loss = 0.272541 (* 1 = 0.272541 loss)
I1211 16:15:00.846807 16720 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1211 16:15:06.995717 16720 solver.cpp:218] Iteration 114900 (16.2648 iter/s, 6.14825s/100 iters), loss = 0.353278
I1211 16:15:06.996217 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:15:06.996217 16720 solver.cpp:237]     Train net output #1: loss = 0.353278 (* 1 = 0.353278 loss)
I1211 16:15:06.996217 16720 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1211 16:15:12.850673  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:15:13.093185 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115000.caffemodel
I1211 16:15:13.108690 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115000.solverstate
I1211 16:15:13.112689 16720 solver.cpp:330] Iteration 115000, Testing net (#0)
I1211 16:15:13.112689 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:15:14.447790 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:15:14.499791 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6764
I1211 16:15:14.499791 16720 solver.cpp:397]     Test net output #1: loss = 1.26701 (* 1 = 1.26701 loss)
I1211 16:15:14.559793 16720 solver.cpp:218] Iteration 115000 (13.2219 iter/s, 7.5632s/100 iters), loss = 0.190916
I1211 16:15:14.559793 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:15:14.559793 16720 solver.cpp:237]     Train net output #1: loss = 0.190916 (* 1 = 0.190916 loss)
I1211 16:15:14.559793 16720 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1211 16:15:20.713474 16720 solver.cpp:218] Iteration 115100 (16.2495 iter/s, 6.15405s/100 iters), loss = 0.385174
I1211 16:15:20.713474 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:15:20.713474 16720 solver.cpp:237]     Train net output #1: loss = 0.385174 (* 1 = 0.385174 loss)
I1211 16:15:20.713474 16720 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1211 16:15:26.916954 16720 solver.cpp:218] Iteration 115200 (16.1229 iter/s, 6.20234s/100 iters), loss = 0.268231
I1211 16:15:26.916954 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:15:26.916954 16720 solver.cpp:237]     Train net output #1: loss = 0.268232 (* 1 = 0.268232 loss)
I1211 16:15:26.916954 16720 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1211 16:15:33.067165 16720 solver.cpp:218] Iteration 115300 (16.2588 iter/s, 6.15051s/100 iters), loss = 0.333423
I1211 16:15:33.067165 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:15:33.068167 16720 solver.cpp:237]     Train net output #1: loss = 0.333423 (* 1 = 0.333423 loss)
I1211 16:15:33.068167 16720 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1211 16:15:39.207193 16720 solver.cpp:218] Iteration 115400 (16.2888 iter/s, 6.13917s/100 iters), loss = 0.326391
I1211 16:15:39.207193 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:15:39.207193 16720 solver.cpp:237]     Train net output #1: loss = 0.326391 (* 1 = 0.326391 loss)
I1211 16:15:39.207193 16720 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1211 16:15:45.039168  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:15:45.281188 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115500.caffemodel
I1211 16:15:45.298204 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_115500.solverstate
I1211 16:15:45.302706 16720 solver.cpp:330] Iteration 115500, Testing net (#0)
I1211 16:15:45.302706 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:15:46.634596 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:15:46.687597 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6728
I1211 16:15:46.687597 16720 solver.cpp:397]     Test net output #1: loss = 1.27186 (* 1 = 1.27186 loss)
I1211 16:15:46.746613 16720 solver.cpp:218] Iteration 115500 (13.2642 iter/s, 7.53912s/100 iters), loss = 0.253529
I1211 16:15:46.746613 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:15:46.746613 16720 solver.cpp:237]     Train net output #1: loss = 0.253529 (* 1 = 0.253529 loss)
I1211 16:15:46.746613 16720 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1211 16:15:52.892347 16720 solver.cpp:218] Iteration 115600 (16.2733 iter/s, 6.14503s/100 iters), loss = 0.300052
I1211 16:15:52.892347 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:15:52.892347 16720 solver.cpp:237]     Train net output #1: loss = 0.300052 (* 1 = 0.300052 loss)
I1211 16:15:52.892347 16720 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1211 16:15:59.037328 16720 solver.cpp:218] Iteration 115700 (16.2755 iter/s, 6.14421s/100 iters), loss = 0.325122
I1211 16:15:59.037328 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:15:59.037328 16720 solver.cpp:237]     Train net output #1: loss = 0.325123 (* 1 = 0.325123 loss)
I1211 16:15:59.037328 16720 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1211 16:16:05.185201 16720 solver.cpp:218] Iteration 115800 (16.2662 iter/s, 6.14772s/100 iters), loss = 0.302362
I1211 16:16:05.185201 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:16:05.185201 16720 solver.cpp:237]     Train net output #1: loss = 0.302363 (* 1 = 0.302363 loss)
I1211 16:16:05.185201 16720 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1211 16:16:11.335266 16720 solver.cpp:218] Iteration 115900 (16.2606 iter/s, 6.14982s/100 iters), loss = 0.343642
I1211 16:16:11.335266 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:16:11.335266 16720 solver.cpp:237]     Train net output #1: loss = 0.343642 (* 1 = 0.343642 loss)
I1211 16:16:11.335266 16720 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1211 16:16:17.178731  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:16:17.419747 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116000.caffemodel
I1211 16:16:17.435747 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116000.solverstate
I1211 16:16:17.440747 16720 solver.cpp:330] Iteration 116000, Testing net (#0)
I1211 16:16:17.440747 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:16:18.772845 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:16:18.824851 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6733
I1211 16:16:18.824851 16720 solver.cpp:397]     Test net output #1: loss = 1.2728 (* 1 = 1.2728 loss)
I1211 16:16:18.883849 16720 solver.cpp:218] Iteration 116000 (13.2488 iter/s, 7.54786s/100 iters), loss = 0.23049
I1211 16:16:18.883849 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:16:18.883849 16720 solver.cpp:237]     Train net output #1: loss = 0.23049 (* 1 = 0.23049 loss)
I1211 16:16:18.883849 16720 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1211 16:16:25.024300 16720 solver.cpp:218] Iteration 116100 (16.285 iter/s, 6.14064s/100 iters), loss = 0.294125
I1211 16:16:25.024300 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:16:25.024300 16720 solver.cpp:237]     Train net output #1: loss = 0.294125 (* 1 = 0.294125 loss)
I1211 16:16:25.024300 16720 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1211 16:16:31.170737 16720 solver.cpp:218] Iteration 116200 (16.2728 iter/s, 6.14524s/100 iters), loss = 0.308326
I1211 16:16:31.170737 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:16:31.170737 16720 solver.cpp:237]     Train net output #1: loss = 0.308326 (* 1 = 0.308326 loss)
I1211 16:16:31.170737 16720 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1211 16:16:37.316159 16720 solver.cpp:218] Iteration 116300 (16.272 iter/s, 6.14553s/100 iters), loss = 0.296406
I1211 16:16:37.316159 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:16:37.316159 16720 solver.cpp:237]     Train net output #1: loss = 0.296406 (* 1 = 0.296406 loss)
I1211 16:16:37.316159 16720 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1211 16:16:43.465582 16720 solver.cpp:218] Iteration 116400 (16.2629 iter/s, 6.14895s/100 iters), loss = 0.313216
I1211 16:16:43.465582 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:16:43.465582 16720 solver.cpp:237]     Train net output #1: loss = 0.313216 (* 1 = 0.313216 loss)
I1211 16:16:43.465582 16720 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1211 16:16:49.311002  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:16:49.552018 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116500.caffemodel
I1211 16:16:49.567018 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_116500.solverstate
I1211 16:16:49.572019 16720 solver.cpp:330] Iteration 116500, Testing net (#0)
I1211 16:16:49.572019 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:16:50.906620 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:16:50.958129 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6734
I1211 16:16:50.958129 16720 solver.cpp:397]     Test net output #1: loss = 1.27847 (* 1 = 1.27847 loss)
I1211 16:16:51.017125 16720 solver.cpp:218] Iteration 116500 (13.2438 iter/s, 7.5507s/100 iters), loss = 0.237224
I1211 16:16:51.017125 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:16:51.017125 16720 solver.cpp:237]     Train net output #1: loss = 0.237224 (* 1 = 0.237224 loss)
I1211 16:16:51.017125 16720 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1211 16:16:57.163534 16720 solver.cpp:218] Iteration 116600 (16.2705 iter/s, 6.14611s/100 iters), loss = 0.339206
I1211 16:16:57.163534 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:16:57.163534 16720 solver.cpp:237]     Train net output #1: loss = 0.339206 (* 1 = 0.339206 loss)
I1211 16:16:57.163534 16720 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1211 16:17:03.306493 16720 solver.cpp:218] Iteration 116700 (16.2806 iter/s, 6.14229s/100 iters), loss = 0.301613
I1211 16:17:03.306493 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:17:03.306493 16720 solver.cpp:237]     Train net output #1: loss = 0.301613 (* 1 = 0.301613 loss)
I1211 16:17:03.306493 16720 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1211 16:17:09.448400 16720 solver.cpp:218] Iteration 116800 (16.2828 iter/s, 6.14144s/100 iters), loss = 0.309732
I1211 16:17:09.448400 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:17:09.448400 16720 solver.cpp:237]     Train net output #1: loss = 0.309733 (* 1 = 0.309733 loss)
I1211 16:17:09.448400 16720 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1211 16:17:15.586911 16720 solver.cpp:218] Iteration 116900 (16.2906 iter/s, 6.13853s/100 iters), loss = 0.331665
I1211 16:17:15.586911 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:17:15.586911 16720 solver.cpp:237]     Train net output #1: loss = 0.331665 (* 1 = 0.331665 loss)
I1211 16:17:15.586911 16720 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1211 16:17:21.430761  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:17:21.671784 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117000.caffemodel
I1211 16:17:21.686775 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117000.solverstate
I1211 16:17:21.691785 16720 solver.cpp:330] Iteration 117000, Testing net (#0)
I1211 16:17:21.691785 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:17:23.023893 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:17:23.076886 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6716
I1211 16:17:23.076886 16720 solver.cpp:397]     Test net output #1: loss = 1.28918 (* 1 = 1.28918 loss)
I1211 16:17:23.134891 16720 solver.cpp:218] Iteration 117000 (13.2486 iter/s, 7.54798s/100 iters), loss = 0.216541
I1211 16:17:23.135892 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:17:23.135892 16720 solver.cpp:237]     Train net output #1: loss = 0.216541 (* 1 = 0.216541 loss)
I1211 16:17:23.135892 16720 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1211 16:17:29.273332 16720 solver.cpp:218] Iteration 117100 (16.2937 iter/s, 6.13736s/100 iters), loss = 0.287742
I1211 16:17:29.273332 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:17:29.273332 16720 solver.cpp:237]     Train net output #1: loss = 0.287742 (* 1 = 0.287742 loss)
I1211 16:17:29.273332 16720 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1211 16:17:35.421658 16720 solver.cpp:218] Iteration 117200 (16.2647 iter/s, 6.14827s/100 iters), loss = 0.227797
I1211 16:17:35.421658 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:17:35.421658 16720 solver.cpp:237]     Train net output #1: loss = 0.227797 (* 1 = 0.227797 loss)
I1211 16:17:35.421658 16720 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1211 16:17:41.567071 16720 solver.cpp:218] Iteration 117300 (16.2729 iter/s, 6.1452s/100 iters), loss = 0.332369
I1211 16:17:41.567071 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:17:41.567071 16720 solver.cpp:237]     Train net output #1: loss = 0.332369 (* 1 = 0.332369 loss)
I1211 16:17:41.567071 16720 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1211 16:17:47.703526 16720 solver.cpp:218] Iteration 117400 (16.298 iter/s, 6.13571s/100 iters), loss = 0.351903
I1211 16:17:47.703526 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:17:47.703526 16720 solver.cpp:237]     Train net output #1: loss = 0.351903 (* 1 = 0.351903 loss)
I1211 16:17:47.703526 16720 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1211 16:17:53.545049  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:17:53.787066 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117500.caffemodel
I1211 16:17:53.802065 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_117500.solverstate
I1211 16:17:53.807066 16720 solver.cpp:330] Iteration 117500, Testing net (#0)
I1211 16:17:53.807066 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:17:55.137153 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:17:55.189162 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6716
I1211 16:17:55.189162 16720 solver.cpp:397]     Test net output #1: loss = 1.28846 (* 1 = 1.28846 loss)
I1211 16:17:55.248162 16720 solver.cpp:218] Iteration 117500 (13.2559 iter/s, 7.54381s/100 iters), loss = 0.220328
I1211 16:17:55.248162 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:17:55.248162 16720 solver.cpp:237]     Train net output #1: loss = 0.220328 (* 1 = 0.220328 loss)
I1211 16:17:55.248162 16720 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1211 16:18:01.387586 16720 solver.cpp:218] Iteration 117600 (16.2875 iter/s, 6.13968s/100 iters), loss = 0.296551
I1211 16:18:01.387586 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:18:01.387586 16720 solver.cpp:237]     Train net output #1: loss = 0.296551 (* 1 = 0.296551 loss)
I1211 16:18:01.387586 16720 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1211 16:18:07.531018 16720 solver.cpp:218] Iteration 117700 (16.2787 iter/s, 6.14299s/100 iters), loss = 0.280891
I1211 16:18:07.531018 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:18:07.531018 16720 solver.cpp:237]     Train net output #1: loss = 0.280891 (* 1 = 0.280891 loss)
I1211 16:18:07.531018 16720 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1211 16:18:13.672001 16720 solver.cpp:218] Iteration 117800 (16.2866 iter/s, 6.14002s/100 iters), loss = 0.336489
I1211 16:18:13.672001 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:18:13.672001 16720 solver.cpp:237]     Train net output #1: loss = 0.336489 (* 1 = 0.336489 loss)
I1211 16:18:13.672001 16720 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1211 16:18:19.825542 16720 solver.cpp:218] Iteration 117900 (16.2515 iter/s, 6.1533s/100 iters), loss = 0.326378
I1211 16:18:19.825542 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:18:19.825542 16720 solver.cpp:237]     Train net output #1: loss = 0.326378 (* 1 = 0.326378 loss)
I1211 16:18:19.825542 16720 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1211 16:18:25.658946  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:18:25.900959 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118000.caffemodel
I1211 16:18:25.914960 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118000.solverstate
I1211 16:18:25.919960 16720 solver.cpp:330] Iteration 118000, Testing net (#0)
I1211 16:18:25.919960 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:18:27.251040 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:18:27.303047 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1211 16:18:27.303047 16720 solver.cpp:397]     Test net output #1: loss = 1.28659 (* 1 = 1.28659 loss)
I1211 16:18:27.362046 16720 solver.cpp:218] Iteration 118000 (13.2698 iter/s, 7.53589s/100 iters), loss = 0.318897
I1211 16:18:27.362046 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:18:27.362046 16720 solver.cpp:237]     Train net output #1: loss = 0.318897 (* 1 = 0.318897 loss)
I1211 16:18:27.362046 16720 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1211 16:18:33.503458 16720 solver.cpp:218] Iteration 118100 (16.2841 iter/s, 6.14094s/100 iters), loss = 0.293739
I1211 16:18:33.503458 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:18:33.503458 16720 solver.cpp:237]     Train net output #1: loss = 0.293739 (* 1 = 0.293739 loss)
I1211 16:18:33.503458 16720 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1211 16:18:39.651926 16720 solver.cpp:218] Iteration 118200 (16.2644 iter/s, 6.1484s/100 iters), loss = 0.263772
I1211 16:18:39.651926 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:18:39.651926 16720 solver.cpp:237]     Train net output #1: loss = 0.263772 (* 1 = 0.263772 loss)
I1211 16:18:39.651926 16720 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1211 16:18:45.802464 16720 solver.cpp:218] Iteration 118300 (16.2613 iter/s, 6.14955s/100 iters), loss = 0.326254
I1211 16:18:45.802464 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:18:45.802464 16720 solver.cpp:237]     Train net output #1: loss = 0.326254 (* 1 = 0.326254 loss)
I1211 16:18:45.802464 16720 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1211 16:18:51.947937 16720 solver.cpp:218] Iteration 118400 (16.2721 iter/s, 6.1455s/100 iters), loss = 0.323035
I1211 16:18:51.947937 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:18:51.947937 16720 solver.cpp:237]     Train net output #1: loss = 0.323035 (* 1 = 0.323035 loss)
I1211 16:18:51.947937 16720 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1211 16:18:57.786381  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:18:58.026392 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118500.caffemodel
I1211 16:18:58.041395 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_118500.solverstate
I1211 16:18:58.045400 16720 solver.cpp:330] Iteration 118500, Testing net (#0)
I1211 16:18:58.045400 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:18:59.378582 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:18:59.431118 16720 solver.cpp:397]     Test net output #0: accuracy = 0.677
I1211 16:18:59.431118 16720 solver.cpp:397]     Test net output #1: loss = 1.28458 (* 1 = 1.28458 loss)
I1211 16:18:59.489603 16720 solver.cpp:218] Iteration 118500 (13.2613 iter/s, 7.54077s/100 iters), loss = 0.291838
I1211 16:18:59.489603 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:18:59.489603 16720 solver.cpp:237]     Train net output #1: loss = 0.291838 (* 1 = 0.291838 loss)
I1211 16:18:59.489603 16720 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1211 16:19:05.635617 16720 solver.cpp:218] Iteration 118600 (16.271 iter/s, 6.14591s/100 iters), loss = 0.261152
I1211 16:19:05.636118 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:19:05.636118 16720 solver.cpp:237]     Train net output #1: loss = 0.261152 (* 1 = 0.261152 loss)
I1211 16:19:05.636118 16720 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1211 16:19:11.781049 16720 solver.cpp:218] Iteration 118700 (16.274 iter/s, 6.14477s/100 iters), loss = 0.229672
I1211 16:19:11.781049 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:19:11.781049 16720 solver.cpp:237]     Train net output #1: loss = 0.229672 (* 1 = 0.229672 loss)
I1211 16:19:11.781049 16720 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1211 16:19:17.932523 16720 solver.cpp:218] Iteration 118800 (16.2571 iter/s, 6.15115s/100 iters), loss = 0.277916
I1211 16:19:17.932523 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:19:17.932523 16720 solver.cpp:237]     Train net output #1: loss = 0.277916 (* 1 = 0.277916 loss)
I1211 16:19:17.932523 16720 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1211 16:19:24.083963 16720 solver.cpp:218] Iteration 118900 (16.256 iter/s, 6.15158s/100 iters), loss = 0.331617
I1211 16:19:24.084964 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:19:24.084964 16720 solver.cpp:237]     Train net output #1: loss = 0.331617 (* 1 = 0.331617 loss)
I1211 16:19:24.084964 16720 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1211 16:19:29.936466  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:19:30.179481 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119000.caffemodel
I1211 16:19:30.195482 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119000.solverstate
I1211 16:19:30.199482 16720 solver.cpp:330] Iteration 119000, Testing net (#0)
I1211 16:19:30.199482 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:19:31.530585 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:19:31.582594 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6725
I1211 16:19:31.582594 16720 solver.cpp:397]     Test net output #1: loss = 1.29222 (* 1 = 1.29222 loss)
I1211 16:19:31.641597 16720 solver.cpp:218] Iteration 119000 (13.2339 iter/s, 7.55633s/100 iters), loss = 0.23928
I1211 16:19:31.641597 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:19:31.641597 16720 solver.cpp:237]     Train net output #1: loss = 0.23928 (* 1 = 0.23928 loss)
I1211 16:19:31.641597 16720 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1211 16:19:37.793469 16720 solver.cpp:218] Iteration 119100 (16.2563 iter/s, 6.15147s/100 iters), loss = 0.248081
I1211 16:19:37.793469 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:19:37.793469 16720 solver.cpp:237]     Train net output #1: loss = 0.248081 (* 1 = 0.248081 loss)
I1211 16:19:37.793469 16720 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1211 16:19:43.952886 16720 solver.cpp:218] Iteration 119200 (16.2359 iter/s, 6.15918s/100 iters), loss = 0.28141
I1211 16:19:43.953387 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:19:43.953387 16720 solver.cpp:237]     Train net output #1: loss = 0.28141 (* 1 = 0.28141 loss)
I1211 16:19:43.953387 16720 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1211 16:19:50.101860 16720 solver.cpp:218] Iteration 119300 (16.2653 iter/s, 6.14807s/100 iters), loss = 0.302263
I1211 16:19:50.101860 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:19:50.101860 16720 solver.cpp:237]     Train net output #1: loss = 0.302263 (* 1 = 0.302263 loss)
I1211 16:19:50.101860 16720 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1211 16:19:56.250828 16720 solver.cpp:218] Iteration 119400 (16.2644 iter/s, 6.1484s/100 iters), loss = 0.294205
I1211 16:19:56.250828 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:19:56.250828 16720 solver.cpp:237]     Train net output #1: loss = 0.294205 (* 1 = 0.294205 loss)
I1211 16:19:56.250828 16720 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1211 16:20:02.090741  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:20:02.332751 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119500.caffemodel
I1211 16:20:02.347755 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_119500.solverstate
I1211 16:20:02.352262 16720 solver.cpp:330] Iteration 119500, Testing net (#0)
I1211 16:20:02.352756 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:20:03.684108 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:20:03.737108 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6742
I1211 16:20:03.737108 16720 solver.cpp:397]     Test net output #1: loss = 1.29697 (* 1 = 1.29697 loss)
I1211 16:20:03.796113 16720 solver.cpp:218] Iteration 119500 (13.2544 iter/s, 7.54465s/100 iters), loss = 0.253824
I1211 16:20:03.796113 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:20:03.796113 16720 solver.cpp:237]     Train net output #1: loss = 0.253824 (* 1 = 0.253824 loss)
I1211 16:20:03.796113 16720 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1211 16:20:09.934581 16720 solver.cpp:218] Iteration 119600 (16.2915 iter/s, 6.13817s/100 iters), loss = 0.274513
I1211 16:20:09.934581 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:20:09.934581 16720 solver.cpp:237]     Train net output #1: loss = 0.274513 (* 1 = 0.274513 loss)
I1211 16:20:09.934581 16720 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1211 16:20:16.075053 16720 solver.cpp:218] Iteration 119700 (16.286 iter/s, 6.14025s/100 iters), loss = 0.226897
I1211 16:20:16.075053 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:20:16.075053 16720 solver.cpp:237]     Train net output #1: loss = 0.226897 (* 1 = 0.226897 loss)
I1211 16:20:16.075053 16720 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1211 16:20:22.210533 16720 solver.cpp:218] Iteration 119800 (16.3004 iter/s, 6.13481s/100 iters), loss = 0.309663
I1211 16:20:22.210533 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:20:22.210533 16720 solver.cpp:237]     Train net output #1: loss = 0.309663 (* 1 = 0.309663 loss)
I1211 16:20:22.210533 16720 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1211 16:20:28.355482 16720 solver.cpp:218] Iteration 119900 (16.2747 iter/s, 6.14452s/100 iters), loss = 0.305291
I1211 16:20:28.355482 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:20:28.355482 16720 solver.cpp:237]     Train net output #1: loss = 0.305291 (* 1 = 0.305291 loss)
I1211 16:20:28.355482 16720 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1211 16:20:34.187521  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:20:34.430531 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120000.caffemodel
I1211 16:20:34.446035 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120000.solverstate
I1211 16:20:34.450536 16720 solver.cpp:330] Iteration 120000, Testing net (#0)
I1211 16:20:34.450536 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:20:35.780620 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:20:35.832619 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1211 16:20:35.832619 16720 solver.cpp:397]     Test net output #1: loss = 1.29076 (* 1 = 1.29076 loss)
I1211 16:20:35.891624 16720 solver.cpp:218] Iteration 120000 (13.2703 iter/s, 7.53562s/100 iters), loss = 0.220457
I1211 16:20:35.891624 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:20:35.891624 16720 solver.cpp:237]     Train net output #1: loss = 0.220457 (* 1 = 0.220457 loss)
I1211 16:20:35.891624 16720 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1211 16:20:42.039103 16720 solver.cpp:218] Iteration 120100 (16.2671 iter/s, 6.14738s/100 iters), loss = 0.361727
I1211 16:20:42.039103 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:20:42.039103 16720 solver.cpp:237]     Train net output #1: loss = 0.361727 (* 1 = 0.361727 loss)
I1211 16:20:42.039103 16720 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1211 16:20:48.179572 16720 solver.cpp:218] Iteration 120200 (16.2876 iter/s, 6.13964s/100 iters), loss = 0.25624
I1211 16:20:48.179572 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:20:48.179572 16720 solver.cpp:237]     Train net output #1: loss = 0.25624 (* 1 = 0.25624 loss)
I1211 16:20:48.179572 16720 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1211 16:20:54.316016 16720 solver.cpp:218] Iteration 120300 (16.2972 iter/s, 6.13603s/100 iters), loss = 0.267663
I1211 16:20:54.316016 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:20:54.316016 16720 solver.cpp:237]     Train net output #1: loss = 0.267663 (* 1 = 0.267663 loss)
I1211 16:20:54.316016 16720 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1211 16:21:00.456643 16720 solver.cpp:218] Iteration 120400 (16.287 iter/s, 6.13987s/100 iters), loss = 0.289961
I1211 16:21:00.456643 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:21:00.456643 16720 solver.cpp:237]     Train net output #1: loss = 0.289961 (* 1 = 0.289961 loss)
I1211 16:21:00.456643 16720 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1211 16:21:06.296432  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:21:06.538446 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120500.caffemodel
I1211 16:21:06.553949 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_120500.solverstate
I1211 16:21:06.558450 16720 solver.cpp:330] Iteration 120500, Testing net (#0)
I1211 16:21:06.558450 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:21:07.889544 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:21:07.941543 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6726
I1211 16:21:07.941543 16720 solver.cpp:397]     Test net output #1: loss = 1.30478 (* 1 = 1.30478 loss)
I1211 16:21:08.000550 16720 solver.cpp:218] Iteration 120500 (13.2549 iter/s, 7.54436s/100 iters), loss = 0.154748
I1211 16:21:08.000550 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 16:21:08.000550 16720 solver.cpp:237]     Train net output #1: loss = 0.154748 (* 1 = 0.154748 loss)
I1211 16:21:08.001549 16720 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1211 16:21:14.147907 16720 solver.cpp:218] Iteration 120600 (16.2751 iter/s, 6.14435s/100 iters), loss = 0.263296
I1211 16:21:14.147907 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:21:14.147907 16720 solver.cpp:237]     Train net output #1: loss = 0.263296 (* 1 = 0.263296 loss)
I1211 16:21:14.147907 16720 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1211 16:21:20.289381 16720 solver.cpp:218] Iteration 120700 (16.2857 iter/s, 6.14035s/100 iters), loss = 0.236259
I1211 16:21:20.289381 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:21:20.289381 16720 solver.cpp:237]     Train net output #1: loss = 0.236259 (* 1 = 0.236259 loss)
I1211 16:21:20.289381 16720 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1211 16:21:26.418809 16720 solver.cpp:218] Iteration 120800 (16.3145 iter/s, 6.12952s/100 iters), loss = 0.315119
I1211 16:21:26.418809 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 16:21:26.418809 16720 solver.cpp:237]     Train net output #1: loss = 0.315119 (* 1 = 0.315119 loss)
I1211 16:21:26.418809 16720 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1211 16:21:32.561319 16720 solver.cpp:218] Iteration 120900 (16.2801 iter/s, 6.14247s/100 iters), loss = 0.366427
I1211 16:21:32.562320 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:21:32.562320 16720 solver.cpp:237]     Train net output #1: loss = 0.366427 (* 1 = 0.366427 loss)
I1211 16:21:32.562320 16720 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1211 16:21:38.405807  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:21:38.647820 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121000.caffemodel
I1211 16:21:38.662820 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121000.solverstate
I1211 16:21:38.667821 16720 solver.cpp:330] Iteration 121000, Testing net (#0)
I1211 16:21:38.667821 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:21:40.002923 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:21:40.054927 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6749
I1211 16:21:40.054927 16720 solver.cpp:397]     Test net output #1: loss = 1.29183 (* 1 = 1.29183 loss)
I1211 16:21:40.112926 16720 solver.cpp:218] Iteration 121000 (13.2438 iter/s, 7.55072s/100 iters), loss = 0.242762
I1211 16:21:40.112926 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:21:40.112926 16720 solver.cpp:237]     Train net output #1: loss = 0.242762 (* 1 = 0.242762 loss)
I1211 16:21:40.112926 16720 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1211 16:21:46.247514 16720 solver.cpp:218] Iteration 121100 (16.3028 iter/s, 6.1339s/100 iters), loss = 0.327615
I1211 16:21:46.247514 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:21:46.247514 16720 solver.cpp:237]     Train net output #1: loss = 0.327615 (* 1 = 0.327615 loss)
I1211 16:21:46.247514 16720 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1211 16:21:52.390758 16720 solver.cpp:218] Iteration 121200 (16.2795 iter/s, 6.1427s/100 iters), loss = 0.258508
I1211 16:21:52.390758 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:21:52.390758 16720 solver.cpp:237]     Train net output #1: loss = 0.258508 (* 1 = 0.258508 loss)
I1211 16:21:52.390758 16720 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1211 16:21:58.535245 16720 solver.cpp:218] Iteration 121300 (16.2763 iter/s, 6.14391s/100 iters), loss = 0.344707
I1211 16:21:58.535245 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:21:58.535245 16720 solver.cpp:237]     Train net output #1: loss = 0.344707 (* 1 = 0.344707 loss)
I1211 16:21:58.535245 16720 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1211 16:22:04.682575 16720 solver.cpp:218] Iteration 121400 (16.2677 iter/s, 6.14714s/100 iters), loss = 0.276874
I1211 16:22:04.682575 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:22:04.682575 16720 solver.cpp:237]     Train net output #1: loss = 0.276874 (* 1 = 0.276874 loss)
I1211 16:22:04.682575 16720 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1211 16:22:10.521147  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:22:10.763172 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121500.caffemodel
I1211 16:22:10.778676 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_121500.solverstate
I1211 16:22:10.783176 16720 solver.cpp:330] Iteration 121500, Testing net (#0)
I1211 16:22:10.783176 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:22:12.114269 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:22:12.167271 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6711
I1211 16:22:12.167271 16720 solver.cpp:397]     Test net output #1: loss = 1.30658 (* 1 = 1.30658 loss)
I1211 16:22:12.226275 16720 solver.cpp:218] Iteration 121500 (13.2566 iter/s, 7.54339s/100 iters), loss = 0.231673
I1211 16:22:12.226275 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:22:12.226275 16720 solver.cpp:237]     Train net output #1: loss = 0.231673 (* 1 = 0.231673 loss)
I1211 16:22:12.226275 16720 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1211 16:22:18.372880 16720 solver.cpp:218] Iteration 121600 (16.27 iter/s, 6.14628s/100 iters), loss = 0.300255
I1211 16:22:18.372880 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:22:18.372880 16720 solver.cpp:237]     Train net output #1: loss = 0.300255 (* 1 = 0.300255 loss)
I1211 16:22:18.372880 16720 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1211 16:22:24.511813 16720 solver.cpp:218] Iteration 121700 (16.2899 iter/s, 6.13877s/100 iters), loss = 0.233826
I1211 16:22:24.511813 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:22:24.511813 16720 solver.cpp:237]     Train net output #1: loss = 0.233826 (* 1 = 0.233826 loss)
I1211 16:22:24.511813 16720 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1211 16:22:30.648553 16720 solver.cpp:218] Iteration 121800 (16.2967 iter/s, 6.1362s/100 iters), loss = 0.300509
I1211 16:22:30.648553 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:22:30.648553 16720 solver.cpp:237]     Train net output #1: loss = 0.300509 (* 1 = 0.300509 loss)
I1211 16:22:30.648553 16720 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1211 16:22:36.791841 16720 solver.cpp:218] Iteration 121900 (16.2811 iter/s, 6.14207s/100 iters), loss = 0.35435
I1211 16:22:36.791841 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:22:36.791841 16720 solver.cpp:237]     Train net output #1: loss = 0.35435 (* 1 = 0.35435 loss)
I1211 16:22:36.791841 16720 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1211 16:22:42.635244  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:22:42.877254 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122000.caffemodel
I1211 16:22:42.893257 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122000.solverstate
I1211 16:22:42.897758 16720 solver.cpp:330] Iteration 122000, Testing net (#0)
I1211 16:22:42.897758 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:22:44.227337 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:22:44.280338 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1211 16:22:44.280338 16720 solver.cpp:397]     Test net output #1: loss = 1.30928 (* 1 = 1.30928 loss)
I1211 16:22:44.339342 16720 solver.cpp:218] Iteration 122000 (13.2498 iter/s, 7.54731s/100 iters), loss = 0.17393
I1211 16:22:44.339342 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:22:44.339342 16720 solver.cpp:237]     Train net output #1: loss = 0.17393 (* 1 = 0.17393 loss)
I1211 16:22:44.339342 16720 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1211 16:22:50.480775 16720 solver.cpp:218] Iteration 122100 (16.2841 iter/s, 6.14095s/100 iters), loss = 0.339299
I1211 16:22:50.480775 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:22:50.480775 16720 solver.cpp:237]     Train net output #1: loss = 0.3393 (* 1 = 0.3393 loss)
I1211 16:22:50.480775 16720 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1211 16:22:56.615201 16720 solver.cpp:218] Iteration 122200 (16.3017 iter/s, 6.13433s/100 iters), loss = 0.294504
I1211 16:22:56.615201 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:22:56.615201 16720 solver.cpp:237]     Train net output #1: loss = 0.294504 (* 1 = 0.294504 loss)
I1211 16:22:56.615201 16720 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1211 16:23:02.750646 16720 solver.cpp:218] Iteration 122300 (16.2996 iter/s, 6.13511s/100 iters), loss = 0.341134
I1211 16:23:02.750646 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:23:02.750646 16720 solver.cpp:237]     Train net output #1: loss = 0.341134 (* 1 = 0.341134 loss)
I1211 16:23:02.750646 16720 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1211 16:23:08.901104 16720 solver.cpp:218] Iteration 122400 (16.2609 iter/s, 6.14971s/100 iters), loss = 0.330323
I1211 16:23:08.901104 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:23:08.901104 16720 solver.cpp:237]     Train net output #1: loss = 0.330323 (* 1 = 0.330323 loss)
I1211 16:23:08.901104 16720 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1211 16:23:14.742555  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:23:14.983566 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122500.caffemodel
I1211 16:23:14.999079 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_122500.solverstate
I1211 16:23:15.004081 16720 solver.cpp:330] Iteration 122500, Testing net (#0)
I1211 16:23:15.004580 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:23:16.335675 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:23:16.388674 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6729
I1211 16:23:16.388674 16720 solver.cpp:397]     Test net output #1: loss = 1.31832 (* 1 = 1.31832 loss)
I1211 16:23:16.447682 16720 solver.cpp:218] Iteration 122500 (13.2516 iter/s, 7.54626s/100 iters), loss = 0.201014
I1211 16:23:16.447682 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:23:16.447682 16720 solver.cpp:237]     Train net output #1: loss = 0.201014 (* 1 = 0.201014 loss)
I1211 16:23:16.447682 16720 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1211 16:23:22.580148 16720 solver.cpp:218] Iteration 122600 (16.3076 iter/s, 6.13212s/100 iters), loss = 0.27916
I1211 16:23:22.580148 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:23:22.580148 16720 solver.cpp:237]     Train net output #1: loss = 0.27916 (* 1 = 0.27916 loss)
I1211 16:23:22.580148 16720 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1211 16:23:28.713892 16720 solver.cpp:218] Iteration 122700 (16.3044 iter/s, 6.13331s/100 iters), loss = 0.323566
I1211 16:23:28.713892 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:23:28.713892 16720 solver.cpp:237]     Train net output #1: loss = 0.323566 (* 1 = 0.323566 loss)
I1211 16:23:28.713892 16720 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1211 16:23:34.853971 16720 solver.cpp:218] Iteration 122800 (16.2882 iter/s, 6.13943s/100 iters), loss = 0.318375
I1211 16:23:34.853971 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:23:34.853971 16720 solver.cpp:237]     Train net output #1: loss = 0.318375 (* 1 = 0.318375 loss)
I1211 16:23:34.853971 16720 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1211 16:23:40.992205 16720 solver.cpp:218] Iteration 122900 (16.2925 iter/s, 6.13778s/100 iters), loss = 0.312473
I1211 16:23:40.992205 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:23:40.992205 16720 solver.cpp:237]     Train net output #1: loss = 0.312473 (* 1 = 0.312473 loss)
I1211 16:23:40.992205 16720 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1211 16:23:46.827711  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:23:47.070721 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123000.caffemodel
I1211 16:23:47.084722 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123000.solverstate
I1211 16:23:47.088721 16720 solver.cpp:330] Iteration 123000, Testing net (#0)
I1211 16:23:47.089722 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:23:48.420842 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:23:48.472841 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1211 16:23:48.472841 16720 solver.cpp:397]     Test net output #1: loss = 1.31461 (* 1 = 1.31461 loss)
I1211 16:23:48.531848 16720 solver.cpp:218] Iteration 123000 (13.2635 iter/s, 7.53949s/100 iters), loss = 0.222508
I1211 16:23:48.531848 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:23:48.531848 16720 solver.cpp:237]     Train net output #1: loss = 0.222509 (* 1 = 0.222509 loss)
I1211 16:23:48.531848 16720 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1211 16:23:54.685400 16720 solver.cpp:218] Iteration 123100 (16.2528 iter/s, 6.15277s/100 iters), loss = 0.293592
I1211 16:23:54.685400 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:23:54.685400 16720 solver.cpp:237]     Train net output #1: loss = 0.293592 (* 1 = 0.293592 loss)
I1211 16:23:54.685400 16720 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1211 16:24:00.835917 16720 solver.cpp:218] Iteration 123200 (16.2593 iter/s, 6.15031s/100 iters), loss = 0.254164
I1211 16:24:00.835917 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:24:00.835917 16720 solver.cpp:237]     Train net output #1: loss = 0.254164 (* 1 = 0.254164 loss)
I1211 16:24:00.835917 16720 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1211 16:24:06.982395 16720 solver.cpp:218] Iteration 123300 (16.2715 iter/s, 6.14573s/100 iters), loss = 0.285681
I1211 16:24:06.982395 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:24:06.982395 16720 solver.cpp:237]     Train net output #1: loss = 0.285681 (* 1 = 0.285681 loss)
I1211 16:24:06.982395 16720 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1211 16:24:13.135927 16720 solver.cpp:218] Iteration 123400 (16.2509 iter/s, 6.15352s/100 iters), loss = 0.257298
I1211 16:24:13.135927 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:24:13.135927 16720 solver.cpp:237]     Train net output #1: loss = 0.257298 (* 1 = 0.257298 loss)
I1211 16:24:13.135927 16720 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1211 16:24:18.985942  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:24:19.227473 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123500.caffemodel
I1211 16:24:19.242475 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_123500.solverstate
I1211 16:24:19.247474 16720 solver.cpp:330] Iteration 123500, Testing net (#0)
I1211 16:24:19.247474 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:24:20.580067 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:24:20.632571 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6748
I1211 16:24:20.632571 16720 solver.cpp:397]     Test net output #1: loss = 1.30572 (* 1 = 1.30572 loss)
I1211 16:24:20.690574 16720 solver.cpp:218] Iteration 123500 (13.2376 iter/s, 7.55425s/100 iters), loss = 0.252304
I1211 16:24:20.690574 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:24:20.690574 16720 solver.cpp:237]     Train net output #1: loss = 0.252304 (* 1 = 0.252304 loss)
I1211 16:24:20.690574 16720 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1211 16:24:26.832960 16720 solver.cpp:218] Iteration 123600 (16.2829 iter/s, 6.14141s/100 iters), loss = 0.300909
I1211 16:24:26.832960 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:24:26.832960 16720 solver.cpp:237]     Train net output #1: loss = 0.300909 (* 1 = 0.300909 loss)
I1211 16:24:26.832960 16720 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1211 16:24:32.978922 16720 solver.cpp:218] Iteration 123700 (16.2718 iter/s, 6.1456s/100 iters), loss = 0.267181
I1211 16:24:32.978922 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:24:32.978922 16720 solver.cpp:237]     Train net output #1: loss = 0.267181 (* 1 = 0.267181 loss)
I1211 16:24:32.978922 16720 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1211 16:24:39.125910 16720 solver.cpp:218] Iteration 123800 (16.2687 iter/s, 6.14678s/100 iters), loss = 0.339362
I1211 16:24:39.125910 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:24:39.125910 16720 solver.cpp:237]     Train net output #1: loss = 0.339362 (* 1 = 0.339362 loss)
I1211 16:24:39.125910 16720 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1211 16:24:45.274876 16720 solver.cpp:218] Iteration 123900 (16.2639 iter/s, 6.14859s/100 iters), loss = 0.277049
I1211 16:24:45.274876 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:24:45.274876 16720 solver.cpp:237]     Train net output #1: loss = 0.277049 (* 1 = 0.277049 loss)
I1211 16:24:45.274876 16720 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1211 16:24:51.122874  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:24:51.364882 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124000.caffemodel
I1211 16:24:51.380889 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124000.solverstate
I1211 16:24:51.385390 16720 solver.cpp:330] Iteration 124000, Testing net (#0)
I1211 16:24:51.385390 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:24:52.719014 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:24:52.771011 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6747
I1211 16:24:52.771011 16720 solver.cpp:397]     Test net output #1: loss = 1.31622 (* 1 = 1.31622 loss)
I1211 16:24:52.830025 16720 solver.cpp:218] Iteration 124000 (13.2369 iter/s, 7.55465s/100 iters), loss = 0.18137
I1211 16:24:52.830025 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 16:24:52.830025 16720 solver.cpp:237]     Train net output #1: loss = 0.18137 (* 1 = 0.18137 loss)
I1211 16:24:52.830025 16720 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1211 16:24:58.968463 16720 solver.cpp:218] Iteration 124100 (16.2906 iter/s, 6.13849s/100 iters), loss = 0.249368
I1211 16:24:58.968463 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:24:58.968463 16720 solver.cpp:237]     Train net output #1: loss = 0.249368 (* 1 = 0.249368 loss)
I1211 16:24:58.968463 16720 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1211 16:25:05.109927 16720 solver.cpp:218] Iteration 124200 (16.2857 iter/s, 6.14035s/100 iters), loss = 0.200243
I1211 16:25:05.109927 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:25:05.109927 16720 solver.cpp:237]     Train net output #1: loss = 0.200243 (* 1 = 0.200243 loss)
I1211 16:25:05.109927 16720 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1211 16:25:11.248399 16720 solver.cpp:218] Iteration 124300 (16.2899 iter/s, 6.13875s/100 iters), loss = 0.2793
I1211 16:25:11.248399 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:25:11.248399 16720 solver.cpp:237]     Train net output #1: loss = 0.2793 (* 1 = 0.2793 loss)
I1211 16:25:11.248399 16720 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1211 16:25:17.389504 16720 solver.cpp:218] Iteration 124400 (16.2868 iter/s, 6.13994s/100 iters), loss = 0.294153
I1211 16:25:17.389504 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:25:17.389504 16720 solver.cpp:237]     Train net output #1: loss = 0.294153 (* 1 = 0.294153 loss)
I1211 16:25:17.389504 16720 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1211 16:25:23.232487  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:25:23.473496 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124500.caffemodel
I1211 16:25:23.490001 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_124500.solverstate
I1211 16:25:23.494506 16720 solver.cpp:330] Iteration 124500, Testing net (#0)
I1211 16:25:23.494506 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:25:24.827632 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:25:24.879644 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1211 16:25:24.879644 16720 solver.cpp:397]     Test net output #1: loss = 1.31847 (* 1 = 1.31847 loss)
I1211 16:25:24.938647 16720 solver.cpp:218] Iteration 124500 (13.2468 iter/s, 7.549s/100 iters), loss = 0.222523
I1211 16:25:24.938647 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:25:24.938647 16720 solver.cpp:237]     Train net output #1: loss = 0.222523 (* 1 = 0.222523 loss)
I1211 16:25:24.938647 16720 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1211 16:25:31.083102 16720 solver.cpp:218] Iteration 124600 (16.2776 iter/s, 6.14342s/100 iters), loss = 0.293969
I1211 16:25:31.083102 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:25:31.083102 16720 solver.cpp:237]     Train net output #1: loss = 0.293969 (* 1 = 0.293969 loss)
I1211 16:25:31.083102 16720 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1211 16:25:37.233212 16720 solver.cpp:218] Iteration 124700 (16.2595 iter/s, 6.15025s/100 iters), loss = 0.25188
I1211 16:25:37.233212 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:25:37.233212 16720 solver.cpp:237]     Train net output #1: loss = 0.25188 (* 1 = 0.25188 loss)
I1211 16:25:37.233212 16720 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1211 16:25:43.382091 16720 solver.cpp:218] Iteration 124800 (16.265 iter/s, 6.14818s/100 iters), loss = 0.344349
I1211 16:25:43.382091 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:25:43.382091 16720 solver.cpp:237]     Train net output #1: loss = 0.344349 (* 1 = 0.344349 loss)
I1211 16:25:43.382591 16720 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1211 16:25:49.524044 16720 solver.cpp:218] Iteration 124900 (16.2833 iter/s, 6.14128s/100 iters), loss = 0.330751
I1211 16:25:49.524044 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:25:49.524044 16720 solver.cpp:237]     Train net output #1: loss = 0.330751 (* 1 = 0.330751 loss)
I1211 16:25:49.524044 16720 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1211 16:25:55.374506  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:25:55.617523 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125000.caffemodel
I1211 16:25:55.633523 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125000.solverstate
I1211 16:25:55.638525 16720 solver.cpp:330] Iteration 125000, Testing net (#0)
I1211 16:25:55.638525 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:25:56.969638 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:25:57.022646 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6713
I1211 16:25:57.022646 16720 solver.cpp:397]     Test net output #1: loss = 1.32207 (* 1 = 1.32207 loss)
I1211 16:25:57.081147 16720 solver.cpp:218] Iteration 125000 (13.2335 iter/s, 7.55657s/100 iters), loss = 0.225511
I1211 16:25:57.081147 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 16:25:57.081147 16720 solver.cpp:237]     Train net output #1: loss = 0.225512 (* 1 = 0.225512 loss)
I1211 16:25:57.081147 16720 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1211 16:26:03.219065 16720 solver.cpp:218] Iteration 125100 (16.292 iter/s, 6.13797s/100 iters), loss = 0.341473
I1211 16:26:03.219065 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:26:03.219065 16720 solver.cpp:237]     Train net output #1: loss = 0.341473 (* 1 = 0.341473 loss)
I1211 16:26:03.219065 16720 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1211 16:26:09.361582 16720 solver.cpp:218] Iteration 125200 (16.2814 iter/s, 6.14199s/100 iters), loss = 0.254345
I1211 16:26:09.361582 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:26:09.361582 16720 solver.cpp:237]     Train net output #1: loss = 0.254345 (* 1 = 0.254345 loss)
I1211 16:26:09.361582 16720 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1211 16:26:15.490103 16720 solver.cpp:218] Iteration 125300 (16.3188 iter/s, 6.12789s/100 iters), loss = 0.292532
I1211 16:26:15.490103 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 16:26:15.490103 16720 solver.cpp:237]     Train net output #1: loss = 0.292532 (* 1 = 0.292532 loss)
I1211 16:26:15.490103 16720 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1211 16:26:21.626654 16720 solver.cpp:218] Iteration 125400 (16.297 iter/s, 6.13611s/100 iters), loss = 0.269117
I1211 16:26:21.626654 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:26:21.626654 16720 solver.cpp:237]     Train net output #1: loss = 0.269117 (* 1 = 0.269117 loss)
I1211 16:26:21.626654 16720 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1211 16:26:27.461052  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:26:27.702072 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125500.caffemodel
I1211 16:26:27.717072 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_125500.solverstate
I1211 16:26:27.722074 16720 solver.cpp:330] Iteration 125500, Testing net (#0)
I1211 16:26:27.722074 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:26:29.053321 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:26:29.105325 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6718
I1211 16:26:29.105325 16720 solver.cpp:397]     Test net output #1: loss = 1.32593 (* 1 = 1.32593 loss)
I1211 16:26:29.164327 16720 solver.cpp:218] Iteration 125500 (13.2666 iter/s, 7.53771s/100 iters), loss = 0.23661
I1211 16:26:29.165326 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:26:29.165326 16720 solver.cpp:237]     Train net output #1: loss = 0.23661 (* 1 = 0.23661 loss)
I1211 16:26:29.165326 16720 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1211 16:26:35.308650 16720 solver.cpp:218] Iteration 125600 (16.2779 iter/s, 6.14331s/100 iters), loss = 0.322356
I1211 16:26:35.308650 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 16:26:35.308650 16720 solver.cpp:237]     Train net output #1: loss = 0.322357 (* 1 = 0.322357 loss)
I1211 16:26:35.308650 16720 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1211 16:26:41.452050 16720 solver.cpp:218] Iteration 125700 (16.2783 iter/s, 6.14316s/100 iters), loss = 0.271413
I1211 16:26:41.452050 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:26:41.452050 16720 solver.cpp:237]     Train net output #1: loss = 0.271413 (* 1 = 0.271413 loss)
I1211 16:26:41.452050 16720 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1211 16:26:47.594974 16720 solver.cpp:218] Iteration 125800 (16.2811 iter/s, 6.14209s/100 iters), loss = 0.248137
I1211 16:26:47.594974 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:26:47.594974 16720 solver.cpp:237]     Train net output #1: loss = 0.248137 (* 1 = 0.248137 loss)
I1211 16:26:47.594974 16720 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1211 16:26:53.729935 16720 solver.cpp:218] Iteration 125900 (16.2999 iter/s, 6.13501s/100 iters), loss = 0.34537
I1211 16:26:53.729935 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:26:53.729935 16720 solver.cpp:237]     Train net output #1: loss = 0.34537 (* 1 = 0.34537 loss)
I1211 16:26:53.729935 16720 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1211 16:26:59.574378  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:26:59.815397 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_126000.caffemodel
I1211 16:26:59.830396 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_126000.solverstate
I1211 16:26:59.835397 16720 solver.cpp:330] Iteration 126000, Testing net (#0)
I1211 16:26:59.835397 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:27:01.169504 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:27:01.221516 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1211 16:27:01.221516 16720 solver.cpp:397]     Test net output #1: loss = 1.32705 (* 1 = 1.32705 loss)
I1211 16:27:01.279508 16720 solver.cpp:218] Iteration 126000 (13.246 iter/s, 7.54942s/100 iters), loss = 0.204112
I1211 16:27:01.280508 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 16:27:01.280508 16720 solver.cpp:237]     Train net output #1: loss = 0.204112 (* 1 = 0.204112 loss)
I1211 16:27:01.280508 16720 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1211 16:27:07.424999 16720 solver.cpp:218] Iteration 126100 (16.2741 iter/s, 6.14474s/100 iters), loss = 0.365354
I1211 16:27:07.424999 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 16:27:07.424999 16720 solver.cpp:237]     Train net output #1: loss = 0.365354 (* 1 = 0.365354 loss)
I1211 16:27:07.424999 16720 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1211 16:27:13.578454 16720 solver.cpp:218] Iteration 126200 (16.2536 iter/s, 6.15249s/100 iters), loss = 0.26036
I1211 16:27:13.578454 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:27:13.578454 16720 solver.cpp:237]     Train net output #1: loss = 0.26036 (* 1 = 0.26036 loss)
I1211 16:27:13.578454 16720 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1211 16:27:19.725906 16720 solver.cpp:218] Iteration 126300 (16.2674 iter/s, 6.14726s/100 iters), loss = 0.282438
I1211 16:27:19.725906 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:27:19.725906 16720 solver.cpp:237]     Train net output #1: loss = 0.282438 (* 1 = 0.282438 loss)
I1211 16:27:19.725906 16720 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1211 16:27:25.871374 16720 solver.cpp:218] Iteration 126400 (16.2724 iter/s, 6.14538s/100 iters), loss = 0.278218
I1211 16:27:25.871374 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:27:25.871374 16720 solver.cpp:237]     Train net output #1: loss = 0.278218 (* 1 = 0.278218 loss)
I1211 16:27:25.871374 16720 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1211 16:27:31.724889  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:27:31.968909 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_126500.caffemodel
I1211 16:27:31.983907 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_126500.solverstate
I1211 16:27:31.988912 16720 solver.cpp:330] Iteration 126500, Testing net (#0)
I1211 16:27:31.988912 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:27:33.320013 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:27:33.372010 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6727
I1211 16:27:33.372010 16720 solver.cpp:397]     Test net output #1: loss = 1.32123 (* 1 = 1.32123 loss)
I1211 16:27:33.431016 16720 solver.cpp:218] Iteration 126500 (13.2295 iter/s, 7.55888s/100 iters), loss = 0.234592
I1211 16:27:33.431016 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 16:27:33.431016 16720 solver.cpp:237]     Train net output #1: loss = 0.234592 (* 1 = 0.234592 loss)
I1211 16:27:33.431016 16720 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1211 16:27:39.569370 16720 solver.cpp:218] Iteration 126600 (16.2921 iter/s, 6.13795s/100 iters), loss = 0.289409
I1211 16:27:39.569370 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:27:39.569370 16720 solver.cpp:237]     Train net output #1: loss = 0.289409 (* 1 = 0.289409 loss)
I1211 16:27:39.569370 16720 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1211 16:27:45.714849 16720 solver.cpp:218] Iteration 126700 (16.2719 iter/s, 6.14555s/100 iters), loss = 0.314371
I1211 16:27:45.714849 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 16:27:45.714849 16720 solver.cpp:237]     Train net output #1: loss = 0.314371 (* 1 = 0.314371 loss)
I1211 16:27:45.715842 16720 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1211 16:27:51.848264 16720 solver.cpp:218] Iteration 126800 (16.3065 iter/s, 6.13254s/100 iters), loss = 0.271666
I1211 16:27:51.848264 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 16:27:51.848264 16720 solver.cpp:237]     Train net output #1: loss = 0.271666 (* 1 = 0.271666 loss)
I1211 16:27:51.848264 16720 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1211 16:27:57.990720 16720 solver.cpp:218] Iteration 126900 (16.2807 iter/s, 6.14225s/100 iters), loss = 0.349762
I1211 16:27:57.990720 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 16:27:57.990720 16720 solver.cpp:237]     Train net output #1: loss = 0.349762 (* 1 = 0.349762 loss)
I1211 16:27:57.990720 16720 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1211 16:28:03.824144  8040 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:28:04.066164 16720 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_127000.caffemodel
I1211 16:28:04.082165 16720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_stridedconv_L15_v2_wnonlin_iter_127000.solverstate
I1211 16:28:04.087167 16720 solver.cpp:330] Iteration 127000, Testing net (#0)
I1211 16:28:04.087167 16720 net.cpp:676] Ignoring source layer accuracy_training
I1211 16:28:05.755491 11892 data_layer.cpp:73] Restarting data prefetching from start.
I1211 16:28:05.809506 16720 solver.cpp:397]     Test net output #0: accuracy = 0.6691
I1211 16:28:05.809506 16720 solver.cpp:397]     Test net output #1: loss = 1.33382 (* 1 = 1.33382 loss)
I1211 16:28:05.867512 16720 solver.cpp:218] Iteration 127000 (12.6959 iter/s, 7.87654s/100 iters), loss = 0.242592
I1211 16:28:05.867512 16720 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 16:28:05.868512 16720 solver.cpp:237]     Train net output #1: loss = 0.242592 (* 1 = 0.242592 loss)
I1211 16:28:05.868512 16720 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1211 16: