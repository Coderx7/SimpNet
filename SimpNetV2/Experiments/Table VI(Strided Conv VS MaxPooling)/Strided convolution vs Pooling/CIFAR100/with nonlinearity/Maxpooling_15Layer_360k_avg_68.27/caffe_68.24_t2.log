I1211 10:46:57.515300 15296 caffe.cpp:219] Using GPUs 0
I1211 10:46:57.708811 15296 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1211 10:46:58.024801 15296 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 10:46:58.041800 15296 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1211 10:46:58.042300 15296 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 10:46:58.042800 15296 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 10:46:58.042800 15296 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_added1
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_added2
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1211 10:46:58.043300 15296 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1211 10:46:58.043300 15296 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added1"
  type: "BatchNorm"
  bottom: "newconv_added1"
  top: "newconv_added1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added1"
  type: "Scale"
  bottom: "newconv_added1"
  top: "newconv_added1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added1"
  type: "ReLU"
  bottom: "newconv_added1"
  top: "newconv_added1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added2"
  type: "BatchNorm"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added2"
  type: "Scale"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added2"
  type: "ReLU"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 10:46:58.074815 15296 layer_factory.cpp:58] Creating layer cifar
I1211 10:46:58.078301 15296 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1211 10:46:58.078800 15296 net.cpp:84] Creating Layer cifar
I1211 10:46:58.078800 15296 net.cpp:380] cifar -> data
I1211 10:46:58.078800 15296 net.cpp:380] cifar -> label
I1211 10:46:58.079799 15296 data_layer.cpp:45] output data size: 100,3,32,32
I1211 10:46:58.088301 15296 net.cpp:122] Setting up cifar
I1211 10:46:58.088301 15296 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 10:46:58.088301 15296 net.cpp:129] Top shape: 100 (100)
I1211 10:46:58.088301 15296 net.cpp:137] Memory required for data: 1229200
I1211 10:46:58.088301 15296 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 10:46:58.088301 15296 net.cpp:84] Creating Layer label_cifar_1_split
I1211 10:46:58.088301 15296 net.cpp:406] label_cifar_1_split <- label
I1211 10:46:58.088301 15296 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 10:46:58.088301 15296 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 10:46:58.088800 15296 net.cpp:122] Setting up label_cifar_1_split
I1211 10:46:58.088800 15296 net.cpp:129] Top shape: 100 (100)
I1211 10:46:58.088800 15296 net.cpp:129] Top shape: 100 (100)
I1211 10:46:58.088800 15296 net.cpp:137] Memory required for data: 1230000
I1211 10:46:58.088800 15296 layer_factory.cpp:58] Creating layer conv1
I1211 10:46:58.088800 15296 net.cpp:84] Creating Layer conv1
I1211 10:46:58.088800 15296 net.cpp:406] conv1 <- data
I1211 10:46:58.088800 15296 net.cpp:380] conv1 -> conv1
I1211 10:46:58.089799 11760 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 10:46:58.360801 15296 net.cpp:122] Setting up conv1
I1211 10:46:58.360801 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.360801 15296 net.cpp:137] Memory required for data: 13518000
I1211 10:46:58.360801 15296 layer_factory.cpp:58] Creating layer bn1
I1211 10:46:58.360801 15296 net.cpp:84] Creating Layer bn1
I1211 10:46:58.360801 15296 net.cpp:406] bn1 <- conv1
I1211 10:46:58.360801 15296 net.cpp:367] bn1 -> conv1 (in-place)
I1211 10:46:58.361301 15296 net.cpp:122] Setting up bn1
I1211 10:46:58.361301 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.361301 15296 net.cpp:137] Memory required for data: 25806000
I1211 10:46:58.361301 15296 layer_factory.cpp:58] Creating layer scale1
I1211 10:46:58.361301 15296 net.cpp:84] Creating Layer scale1
I1211 10:46:58.361301 15296 net.cpp:406] scale1 <- conv1
I1211 10:46:58.361301 15296 net.cpp:367] scale1 -> conv1 (in-place)
I1211 10:46:58.361301 15296 layer_factory.cpp:58] Creating layer scale1
I1211 10:46:58.361301 15296 net.cpp:122] Setting up scale1
I1211 10:46:58.361301 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.361301 15296 net.cpp:137] Memory required for data: 38094000
I1211 10:46:58.361301 15296 layer_factory.cpp:58] Creating layer relu1
I1211 10:46:58.361301 15296 net.cpp:84] Creating Layer relu1
I1211 10:46:58.361301 15296 net.cpp:406] relu1 <- conv1
I1211 10:46:58.361301 15296 net.cpp:367] relu1 -> conv1 (in-place)
I1211 10:46:58.361799 15296 net.cpp:122] Setting up relu1
I1211 10:46:58.361799 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.361799 15296 net.cpp:137] Memory required for data: 50382000
I1211 10:46:58.361799 15296 layer_factory.cpp:58] Creating layer conv1_0
I1211 10:46:58.361799 15296 net.cpp:84] Creating Layer conv1_0
I1211 10:46:58.361799 15296 net.cpp:406] conv1_0 <- conv1
I1211 10:46:58.361799 15296 net.cpp:380] conv1_0 -> conv1_0
I1211 10:46:58.363801 15296 net.cpp:122] Setting up conv1_0
I1211 10:46:58.363801 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.363801 15296 net.cpp:137] Memory required for data: 66766000
I1211 10:46:58.363801 15296 layer_factory.cpp:58] Creating layer bn1_0
I1211 10:46:58.363801 15296 net.cpp:84] Creating Layer bn1_0
I1211 10:46:58.363801 15296 net.cpp:406] bn1_0 <- conv1_0
I1211 10:46:58.363801 15296 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 10:46:58.363801 15296 net.cpp:122] Setting up bn1_0
I1211 10:46:58.363801 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.363801 15296 net.cpp:137] Memory required for data: 83150000
I1211 10:46:58.363801 15296 layer_factory.cpp:58] Creating layer scale1_0
I1211 10:46:58.364300 15296 net.cpp:84] Creating Layer scale1_0
I1211 10:46:58.364300 15296 net.cpp:406] scale1_0 <- conv1_0
I1211 10:46:58.364300 15296 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 10:46:58.364300 15296 layer_factory.cpp:58] Creating layer scale1_0
I1211 10:46:58.364300 15296 net.cpp:122] Setting up scale1_0
I1211 10:46:58.364300 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.364300 15296 net.cpp:137] Memory required for data: 99534000
I1211 10:46:58.364300 15296 layer_factory.cpp:58] Creating layer relu1_0
I1211 10:46:58.364300 15296 net.cpp:84] Creating Layer relu1_0
I1211 10:46:58.364300 15296 net.cpp:406] relu1_0 <- conv1_0
I1211 10:46:58.364300 15296 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 10:46:58.364300 15296 net.cpp:122] Setting up relu1_0
I1211 10:46:58.364300 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.364300 15296 net.cpp:137] Memory required for data: 115918000
I1211 10:46:58.364300 15296 layer_factory.cpp:58] Creating layer conv2
I1211 10:46:58.364300 15296 net.cpp:84] Creating Layer conv2
I1211 10:46:58.364300 15296 net.cpp:406] conv2 <- conv1_0
I1211 10:46:58.364300 15296 net.cpp:380] conv2 -> conv2
I1211 10:46:58.365799 15296 net.cpp:122] Setting up conv2
I1211 10:46:58.365799 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.365799 15296 net.cpp:137] Memory required for data: 132302000
I1211 10:46:58.365799 15296 layer_factory.cpp:58] Creating layer bn2
I1211 10:46:58.365799 15296 net.cpp:84] Creating Layer bn2
I1211 10:46:58.365799 15296 net.cpp:406] bn2 <- conv2
I1211 10:46:58.366302 15296 net.cpp:367] bn2 -> conv2 (in-place)
I1211 10:46:58.366302 15296 net.cpp:122] Setting up bn2
I1211 10:46:58.366302 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.366302 15296 net.cpp:137] Memory required for data: 148686000
I1211 10:46:58.366302 15296 layer_factory.cpp:58] Creating layer scale2
I1211 10:46:58.366302 15296 net.cpp:84] Creating Layer scale2
I1211 10:46:58.366302 15296 net.cpp:406] scale2 <- conv2
I1211 10:46:58.366302 15296 net.cpp:367] scale2 -> conv2 (in-place)
I1211 10:46:58.366801 15296 layer_factory.cpp:58] Creating layer scale2
I1211 10:46:58.366801 15296 net.cpp:122] Setting up scale2
I1211 10:46:58.366801 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.366801 15296 net.cpp:137] Memory required for data: 165070000
I1211 10:46:58.366801 15296 layer_factory.cpp:58] Creating layer relu2
I1211 10:46:58.366801 15296 net.cpp:84] Creating Layer relu2
I1211 10:46:58.366801 15296 net.cpp:406] relu2 <- conv2
I1211 10:46:58.366801 15296 net.cpp:367] relu2 -> conv2 (in-place)
I1211 10:46:58.367301 15296 net.cpp:122] Setting up relu2
I1211 10:46:58.367301 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.367301 15296 net.cpp:137] Memory required for data: 181454000
I1211 10:46:58.367301 15296 layer_factory.cpp:58] Creating layer conv2_1
I1211 10:46:58.367301 15296 net.cpp:84] Creating Layer conv2_1
I1211 10:46:58.367301 15296 net.cpp:406] conv2_1 <- conv2
I1211 10:46:58.367301 15296 net.cpp:380] conv2_1 -> conv2_1
I1211 10:46:58.368801 15296 net.cpp:122] Setting up conv2_1
I1211 10:46:58.368801 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.368801 15296 net.cpp:137] Memory required for data: 197838000
I1211 10:46:58.368801 15296 layer_factory.cpp:58] Creating layer bn2_1
I1211 10:46:58.368801 15296 net.cpp:84] Creating Layer bn2_1
I1211 10:46:58.368801 15296 net.cpp:406] bn2_1 <- conv2_1
I1211 10:46:58.368801 15296 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 10:46:58.368801 15296 net.cpp:122] Setting up bn2_1
I1211 10:46:58.368801 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.368801 15296 net.cpp:137] Memory required for data: 214222000
I1211 10:46:58.368801 15296 layer_factory.cpp:58] Creating layer scale2_1
I1211 10:46:58.368801 15296 net.cpp:84] Creating Layer scale2_1
I1211 10:46:58.368801 15296 net.cpp:406] scale2_1 <- conv2_1
I1211 10:46:58.368801 15296 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 10:46:58.368801 15296 layer_factory.cpp:58] Creating layer scale2_1
I1211 10:46:58.369300 15296 net.cpp:122] Setting up scale2_1
I1211 10:46:58.369300 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.369300 15296 net.cpp:137] Memory required for data: 230606000
I1211 10:46:58.369300 15296 layer_factory.cpp:58] Creating layer relu2_1
I1211 10:46:58.369300 15296 net.cpp:84] Creating Layer relu2_1
I1211 10:46:58.369300 15296 net.cpp:406] relu2_1 <- conv2_1
I1211 10:46:58.369300 15296 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 10:46:58.369300 15296 net.cpp:122] Setting up relu2_1
I1211 10:46:58.369300 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.369300 15296 net.cpp:137] Memory required for data: 246990000
I1211 10:46:58.369300 15296 layer_factory.cpp:58] Creating layer conv2_2
I1211 10:46:58.369300 15296 net.cpp:84] Creating Layer conv2_2
I1211 10:46:58.369300 15296 net.cpp:406] conv2_2 <- conv2_1
I1211 10:46:58.369300 15296 net.cpp:380] conv2_2 -> conv2_2
I1211 10:46:58.371301 15296 net.cpp:122] Setting up conv2_2
I1211 10:46:58.371301 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.371301 15296 net.cpp:137] Memory required for data: 267470000
I1211 10:46:58.371301 15296 layer_factory.cpp:58] Creating layer bn2_2
I1211 10:46:58.371301 15296 net.cpp:84] Creating Layer bn2_2
I1211 10:46:58.371301 15296 net.cpp:406] bn2_2 <- conv2_2
I1211 10:46:58.371301 15296 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 10:46:58.371800 15296 net.cpp:122] Setting up bn2_2
I1211 10:46:58.371800 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.371800 15296 net.cpp:137] Memory required for data: 287950000
I1211 10:46:58.371800 15296 layer_factory.cpp:58] Creating layer scale2_2
I1211 10:46:58.371800 15296 net.cpp:84] Creating Layer scale2_2
I1211 10:46:58.371800 15296 net.cpp:406] scale2_2 <- conv2_2
I1211 10:46:58.371800 15296 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 10:46:58.371800 15296 layer_factory.cpp:58] Creating layer scale2_2
I1211 10:46:58.371800 15296 net.cpp:122] Setting up scale2_2
I1211 10:46:58.371800 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.371800 15296 net.cpp:137] Memory required for data: 308430000
I1211 10:46:58.371800 15296 layer_factory.cpp:58] Creating layer relu2_2
I1211 10:46:58.371800 15296 net.cpp:84] Creating Layer relu2_2
I1211 10:46:58.371800 15296 net.cpp:406] relu2_2 <- conv2_2
I1211 10:46:58.371800 15296 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 10:46:58.372303 15296 net.cpp:122] Setting up relu2_2
I1211 10:46:58.372303 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.372303 15296 net.cpp:137] Memory required for data: 328910000
I1211 10:46:58.372303 15296 layer_factory.cpp:58] Creating layer newconv_added1
I1211 10:46:58.372303 15296 net.cpp:84] Creating Layer newconv_added1
I1211 10:46:58.372303 15296 net.cpp:406] newconv_added1 <- conv2_2
I1211 10:46:58.372303 15296 net.cpp:380] newconv_added1 -> newconv_added1
I1211 10:46:58.373800 15296 net.cpp:122] Setting up newconv_added1
I1211 10:46:58.373800 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.373800 15296 net.cpp:137] Memory required for data: 349390000
I1211 10:46:58.373800 15296 layer_factory.cpp:58] Creating layer bn_added1
I1211 10:46:58.373800 15296 net.cpp:84] Creating Layer bn_added1
I1211 10:46:58.373800 15296 net.cpp:406] bn_added1 <- newconv_added1
I1211 10:46:58.373800 15296 net.cpp:367] bn_added1 -> newconv_added1 (in-place)
I1211 10:46:58.373800 15296 net.cpp:122] Setting up bn_added1
I1211 10:46:58.373800 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.373800 15296 net.cpp:137] Memory required for data: 369870000
I1211 10:46:58.373800 15296 layer_factory.cpp:58] Creating layer scale_added1
I1211 10:46:58.373800 15296 net.cpp:84] Creating Layer scale_added1
I1211 10:46:58.373800 15296 net.cpp:406] scale_added1 <- newconv_added1
I1211 10:46:58.373800 15296 net.cpp:367] scale_added1 -> newconv_added1 (in-place)
I1211 10:46:58.373800 15296 layer_factory.cpp:58] Creating layer scale_added1
I1211 10:46:58.373800 15296 net.cpp:122] Setting up scale_added1
I1211 10:46:58.373800 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.373800 15296 net.cpp:137] Memory required for data: 390350000
I1211 10:46:58.373800 15296 layer_factory.cpp:58] Creating layer relu_added1
I1211 10:46:58.373800 15296 net.cpp:84] Creating Layer relu_added1
I1211 10:46:58.374301 15296 net.cpp:406] relu_added1 <- newconv_added1
I1211 10:46:58.374301 15296 net.cpp:367] relu_added1 -> newconv_added1 (in-place)
I1211 10:46:58.374802 15296 net.cpp:122] Setting up relu_added1
I1211 10:46:58.374802 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.374802 15296 net.cpp:137] Memory required for data: 410830000
I1211 10:46:58.374802 15296 layer_factory.cpp:58] Creating layer pool2_1
I1211 10:46:58.374802 15296 net.cpp:84] Creating Layer pool2_1
I1211 10:46:58.374802 15296 net.cpp:406] pool2_1 <- newconv_added1
I1211 10:46:58.374802 15296 net.cpp:380] pool2_1 -> pool2_1
I1211 10:46:58.374802 15296 net.cpp:122] Setting up pool2_1
I1211 10:46:58.374802 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.374802 15296 net.cpp:137] Memory required for data: 415950000
I1211 10:46:58.374802 15296 layer_factory.cpp:58] Creating layer conv3
I1211 10:46:58.374802 15296 net.cpp:84] Creating Layer conv3
I1211 10:46:58.374802 15296 net.cpp:406] conv3 <- pool2_1
I1211 10:46:58.374802 15296 net.cpp:380] conv3 -> conv3
I1211 10:46:58.376301 15296 net.cpp:122] Setting up conv3
I1211 10:46:58.376301 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.376301 15296 net.cpp:137] Memory required for data: 421070000
I1211 10:46:58.376301 15296 layer_factory.cpp:58] Creating layer bn3
I1211 10:46:58.376301 15296 net.cpp:84] Creating Layer bn3
I1211 10:46:58.376301 15296 net.cpp:406] bn3 <- conv3
I1211 10:46:58.376301 15296 net.cpp:367] bn3 -> conv3 (in-place)
I1211 10:46:58.376801 15296 net.cpp:122] Setting up bn3
I1211 10:46:58.376801 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.376801 15296 net.cpp:137] Memory required for data: 426190000
I1211 10:46:58.376801 15296 layer_factory.cpp:58] Creating layer scale3
I1211 10:46:58.376801 15296 net.cpp:84] Creating Layer scale3
I1211 10:46:58.376801 15296 net.cpp:406] scale3 <- conv3
I1211 10:46:58.376801 15296 net.cpp:367] scale3 -> conv3 (in-place)
I1211 10:46:58.376801 15296 layer_factory.cpp:58] Creating layer scale3
I1211 10:46:58.376801 15296 net.cpp:122] Setting up scale3
I1211 10:46:58.376801 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.376801 15296 net.cpp:137] Memory required for data: 431310000
I1211 10:46:58.376801 15296 layer_factory.cpp:58] Creating layer relu3
I1211 10:46:58.376801 15296 net.cpp:84] Creating Layer relu3
I1211 10:46:58.376801 15296 net.cpp:406] relu3 <- conv3
I1211 10:46:58.376801 15296 net.cpp:367] relu3 -> conv3 (in-place)
I1211 10:46:58.377300 15296 net.cpp:122] Setting up relu3
I1211 10:46:58.377300 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.377300 15296 net.cpp:137] Memory required for data: 436430000
I1211 10:46:58.377300 15296 layer_factory.cpp:58] Creating layer conv3_1
I1211 10:46:58.377300 15296 net.cpp:84] Creating Layer conv3_1
I1211 10:46:58.377300 15296 net.cpp:406] conv3_1 <- conv3
I1211 10:46:58.377300 15296 net.cpp:380] conv3_1 -> conv3_1
I1211 10:46:58.378300 15296 net.cpp:122] Setting up conv3_1
I1211 10:46:58.378300 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.378300 15296 net.cpp:137] Memory required for data: 441550000
I1211 10:46:58.378300 15296 layer_factory.cpp:58] Creating layer bn3_1
I1211 10:46:58.378300 15296 net.cpp:84] Creating Layer bn3_1
I1211 10:46:58.378300 15296 net.cpp:406] bn3_1 <- conv3_1
I1211 10:46:58.378300 15296 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 10:46:58.378801 15296 net.cpp:122] Setting up bn3_1
I1211 10:46:58.378801 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.378801 15296 net.cpp:137] Memory required for data: 446670000
I1211 10:46:58.378801 15296 layer_factory.cpp:58] Creating layer scale3_1
I1211 10:46:58.378801 15296 net.cpp:84] Creating Layer scale3_1
I1211 10:46:58.378801 15296 net.cpp:406] scale3_1 <- conv3_1
I1211 10:46:58.378801 15296 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 10:46:58.378801 15296 layer_factory.cpp:58] Creating layer scale3_1
I1211 10:46:58.378801 15296 net.cpp:122] Setting up scale3_1
I1211 10:46:58.378801 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.378801 15296 net.cpp:137] Memory required for data: 451790000
I1211 10:46:58.378801 15296 layer_factory.cpp:58] Creating layer relu3_1
I1211 10:46:58.378801 15296 net.cpp:84] Creating Layer relu3_1
I1211 10:46:58.378801 15296 net.cpp:406] relu3_1 <- conv3_1
I1211 10:46:58.378801 15296 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 10:46:58.379299 15296 net.cpp:122] Setting up relu3_1
I1211 10:46:58.379299 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.379299 15296 net.cpp:137] Memory required for data: 456910000
I1211 10:46:58.379299 15296 layer_factory.cpp:58] Creating layer conv4
I1211 10:46:58.379299 15296 net.cpp:84] Creating Layer conv4
I1211 10:46:58.379299 15296 net.cpp:406] conv4 <- conv3_1
I1211 10:46:58.379299 15296 net.cpp:380] conv4 -> conv4
I1211 10:46:58.380300 15296 net.cpp:122] Setting up conv4
I1211 10:46:58.380300 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.380300 15296 net.cpp:137] Memory required for data: 462030000
I1211 10:46:58.380300 15296 layer_factory.cpp:58] Creating layer bn4
I1211 10:46:58.380300 15296 net.cpp:84] Creating Layer bn4
I1211 10:46:58.380300 15296 net.cpp:406] bn4 <- conv4
I1211 10:46:58.380300 15296 net.cpp:367] bn4 -> conv4 (in-place)
I1211 10:46:58.380800 15296 net.cpp:122] Setting up bn4
I1211 10:46:58.380800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.380800 15296 net.cpp:137] Memory required for data: 467150000
I1211 10:46:58.380800 15296 layer_factory.cpp:58] Creating layer scale4
I1211 10:46:58.380800 15296 net.cpp:84] Creating Layer scale4
I1211 10:46:58.380800 15296 net.cpp:406] scale4 <- conv4
I1211 10:46:58.380800 15296 net.cpp:367] scale4 -> conv4 (in-place)
I1211 10:46:58.380800 15296 layer_factory.cpp:58] Creating layer scale4
I1211 10:46:58.380800 15296 net.cpp:122] Setting up scale4
I1211 10:46:58.380800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.380800 15296 net.cpp:137] Memory required for data: 472270000
I1211 10:46:58.380800 15296 layer_factory.cpp:58] Creating layer relu4
I1211 10:46:58.380800 15296 net.cpp:84] Creating Layer relu4
I1211 10:46:58.380800 15296 net.cpp:406] relu4 <- conv4
I1211 10:46:58.380800 15296 net.cpp:367] relu4 -> conv4 (in-place)
I1211 10:46:58.381306 15296 net.cpp:122] Setting up relu4
I1211 10:46:58.381306 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.381306 15296 net.cpp:137] Memory required for data: 477390000
I1211 10:46:58.381306 15296 layer_factory.cpp:58] Creating layer conv4_1
I1211 10:46:58.381306 15296 net.cpp:84] Creating Layer conv4_1
I1211 10:46:58.381306 15296 net.cpp:406] conv4_1 <- conv4
I1211 10:46:58.381306 15296 net.cpp:380] conv4_1 -> conv4_1
I1211 10:46:58.382800 15296 net.cpp:122] Setting up conv4_1
I1211 10:46:58.382800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.382800 15296 net.cpp:137] Memory required for data: 482510000
I1211 10:46:58.383301 15296 layer_factory.cpp:58] Creating layer bn4_1
I1211 10:46:58.383301 15296 net.cpp:84] Creating Layer bn4_1
I1211 10:46:58.383301 15296 net.cpp:406] bn4_1 <- conv4_1
I1211 10:46:58.383301 15296 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 10:46:58.383301 15296 net.cpp:122] Setting up bn4_1
I1211 10:46:58.383301 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.383301 15296 net.cpp:137] Memory required for data: 487630000
I1211 10:46:58.383301 15296 layer_factory.cpp:58] Creating layer scale4_1
I1211 10:46:58.383301 15296 net.cpp:84] Creating Layer scale4_1
I1211 10:46:58.383301 15296 net.cpp:406] scale4_1 <- conv4_1
I1211 10:46:58.383301 15296 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 10:46:58.383301 15296 layer_factory.cpp:58] Creating layer scale4_1
I1211 10:46:58.383800 15296 net.cpp:122] Setting up scale4_1
I1211 10:46:58.383800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.383800 15296 net.cpp:137] Memory required for data: 492750000
I1211 10:46:58.383800 15296 layer_factory.cpp:58] Creating layer relu4_1
I1211 10:46:58.383800 15296 net.cpp:84] Creating Layer relu4_1
I1211 10:46:58.383800 15296 net.cpp:406] relu4_1 <- conv4_1
I1211 10:46:58.383800 15296 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 10:46:58.383800 15296 net.cpp:122] Setting up relu4_1
I1211 10:46:58.383800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.383800 15296 net.cpp:137] Memory required for data: 497870000
I1211 10:46:58.383800 15296 layer_factory.cpp:58] Creating layer conv4_2
I1211 10:46:58.383800 15296 net.cpp:84] Creating Layer conv4_2
I1211 10:46:58.383800 15296 net.cpp:406] conv4_2 <- conv4_1
I1211 10:46:58.383800 15296 net.cpp:380] conv4_2 -> conv4_2
I1211 10:46:58.385299 15296 net.cpp:122] Setting up conv4_2
I1211 10:46:58.385299 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.385299 15296 net.cpp:137] Memory required for data: 503809200
I1211 10:46:58.385299 15296 layer_factory.cpp:58] Creating layer bn4_2
I1211 10:46:58.385299 15296 net.cpp:84] Creating Layer bn4_2
I1211 10:46:58.385299 15296 net.cpp:406] bn4_2 <- conv4_2
I1211 10:46:58.385299 15296 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 10:46:58.385800 15296 net.cpp:122] Setting up bn4_2
I1211 10:46:58.385800 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.385800 15296 net.cpp:137] Memory required for data: 509748400
I1211 10:46:58.385800 15296 layer_factory.cpp:58] Creating layer scale4_2
I1211 10:46:58.385800 15296 net.cpp:84] Creating Layer scale4_2
I1211 10:46:58.385800 15296 net.cpp:406] scale4_2 <- conv4_2
I1211 10:46:58.385800 15296 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 10:46:58.385800 15296 layer_factory.cpp:58] Creating layer scale4_2
I1211 10:46:58.385800 15296 net.cpp:122] Setting up scale4_2
I1211 10:46:58.385800 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.385800 15296 net.cpp:137] Memory required for data: 515687600
I1211 10:46:58.385800 15296 layer_factory.cpp:58] Creating layer relu4_2
I1211 10:46:58.385800 15296 net.cpp:84] Creating Layer relu4_2
I1211 10:46:58.385800 15296 net.cpp:406] relu4_2 <- conv4_2
I1211 10:46:58.385800 15296 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 10:46:58.386301 15296 net.cpp:122] Setting up relu4_2
I1211 10:46:58.386301 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.386301 15296 net.cpp:137] Memory required for data: 521626800
I1211 10:46:58.386301 15296 layer_factory.cpp:58] Creating layer added_new_conv2
I1211 10:46:58.386301 15296 net.cpp:84] Creating Layer added_new_conv2
I1211 10:46:58.386301 15296 net.cpp:406] added_new_conv2 <- conv4_2
I1211 10:46:58.386301 15296 net.cpp:380] added_new_conv2 -> added_new_conv2
I1211 10:46:58.387799 15296 net.cpp:122] Setting up added_new_conv2
I1211 10:46:58.388300 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.388300 15296 net.cpp:137] Memory required for data: 527566000
I1211 10:46:58.388300 15296 layer_factory.cpp:58] Creating layer bn_added2
I1211 10:46:58.388300 15296 net.cpp:84] Creating Layer bn_added2
I1211 10:46:58.388300 15296 net.cpp:406] bn_added2 <- added_new_conv2
I1211 10:46:58.388300 15296 net.cpp:367] bn_added2 -> added_new_conv2 (in-place)
I1211 10:46:58.388300 15296 net.cpp:122] Setting up bn_added2
I1211 10:46:58.388300 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.388300 15296 net.cpp:137] Memory required for data: 533505200
I1211 10:46:58.388300 15296 layer_factory.cpp:58] Creating layer scale_added2
I1211 10:46:58.388300 15296 net.cpp:84] Creating Layer scale_added2
I1211 10:46:58.388300 15296 net.cpp:406] scale_added2 <- added_new_conv2
I1211 10:46:58.388300 15296 net.cpp:367] scale_added2 -> added_new_conv2 (in-place)
I1211 10:46:58.388300 15296 layer_factory.cpp:58] Creating layer scale_added2
I1211 10:46:58.388300 15296 net.cpp:122] Setting up scale_added2
I1211 10:46:58.388300 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.388300 15296 net.cpp:137] Memory required for data: 539444400
I1211 10:46:58.388300 15296 layer_factory.cpp:58] Creating layer relu_added2
I1211 10:46:58.388300 15296 net.cpp:84] Creating Layer relu_added2
I1211 10:46:58.388800 15296 net.cpp:406] relu_added2 <- added_new_conv2
I1211 10:46:58.388800 15296 net.cpp:367] relu_added2 -> added_new_conv2 (in-place)
I1211 10:46:58.389302 15296 net.cpp:122] Setting up relu_added2
I1211 10:46:58.389302 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.389302 15296 net.cpp:137] Memory required for data: 545383600
I1211 10:46:58.389302 15296 layer_factory.cpp:58] Creating layer pool4_2
I1211 10:46:58.389302 15296 net.cpp:84] Creating Layer pool4_2
I1211 10:46:58.389302 15296 net.cpp:406] pool4_2 <- added_new_conv2
I1211 10:46:58.389302 15296 net.cpp:380] pool4_2 -> pool4_2
I1211 10:46:58.389302 15296 net.cpp:122] Setting up pool4_2
I1211 10:46:58.389302 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.389302 15296 net.cpp:137] Memory required for data: 546868400
I1211 10:46:58.389302 15296 layer_factory.cpp:58] Creating layer conv4_0
I1211 10:46:58.389302 15296 net.cpp:84] Creating Layer conv4_0
I1211 10:46:58.389302 15296 net.cpp:406] conv4_0 <- pool4_2
I1211 10:46:58.389302 15296 net.cpp:380] conv4_0 -> conv4_0
I1211 10:46:58.390801 15296 net.cpp:122] Setting up conv4_0
I1211 10:46:58.390801 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.390801 15296 net.cpp:137] Memory required for data: 548353200
I1211 10:46:58.390801 15296 layer_factory.cpp:58] Creating layer bn4_0
I1211 10:46:58.390801 15296 net.cpp:84] Creating Layer bn4_0
I1211 10:46:58.390801 15296 net.cpp:406] bn4_0 <- conv4_0
I1211 10:46:58.390801 15296 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 10:46:58.390801 15296 net.cpp:122] Setting up bn4_0
I1211 10:46:58.390801 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.390801 15296 net.cpp:137] Memory required for data: 549838000
I1211 10:46:58.390801 15296 layer_factory.cpp:58] Creating layer scale4_0
I1211 10:46:58.390801 15296 net.cpp:84] Creating Layer scale4_0
I1211 10:46:58.390801 15296 net.cpp:406] scale4_0 <- conv4_0
I1211 10:46:58.390801 15296 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 10:46:58.390801 15296 layer_factory.cpp:58] Creating layer scale4_0
I1211 10:46:58.390801 15296 net.cpp:122] Setting up scale4_0
I1211 10:46:58.390801 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.390801 15296 net.cpp:137] Memory required for data: 551322800
I1211 10:46:58.390801 15296 layer_factory.cpp:58] Creating layer relu4_0
I1211 10:46:58.391301 15296 net.cpp:84] Creating Layer relu4_0
I1211 10:46:58.391301 15296 net.cpp:406] relu4_0 <- conv4_0
I1211 10:46:58.391301 15296 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 10:46:58.391301 15296 net.cpp:122] Setting up relu4_0
I1211 10:46:58.391301 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.391301 15296 net.cpp:137] Memory required for data: 552807600
I1211 10:46:58.391301 15296 layer_factory.cpp:58] Creating layer conv11
I1211 10:46:58.391301 15296 net.cpp:84] Creating Layer conv11
I1211 10:46:58.391301 15296 net.cpp:406] conv11 <- conv4_0
I1211 10:46:58.391301 15296 net.cpp:380] conv11 -> conv11
I1211 10:46:58.392801 15296 net.cpp:122] Setting up conv11
I1211 10:46:58.392801 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.392801 15296 net.cpp:137] Memory required for data: 554599600
I1211 10:46:58.392801 15296 layer_factory.cpp:58] Creating layer bn_conv11
I1211 10:46:58.392801 15296 net.cpp:84] Creating Layer bn_conv11
I1211 10:46:58.392801 15296 net.cpp:406] bn_conv11 <- conv11
I1211 10:46:58.392801 15296 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 10:46:58.393301 15296 net.cpp:122] Setting up bn_conv11
I1211 10:46:58.393301 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.393301 15296 net.cpp:137] Memory required for data: 556391600
I1211 10:46:58.393301 15296 layer_factory.cpp:58] Creating layer scale_conv11
I1211 10:46:58.393301 15296 net.cpp:84] Creating Layer scale_conv11
I1211 10:46:58.393301 15296 net.cpp:406] scale_conv11 <- conv11
I1211 10:46:58.393301 15296 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 10:46:58.393301 15296 layer_factory.cpp:58] Creating layer scale_conv11
I1211 10:46:58.393301 15296 net.cpp:122] Setting up scale_conv11
I1211 10:46:58.393301 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.393301 15296 net.cpp:137] Memory required for data: 558183600
I1211 10:46:58.393301 15296 layer_factory.cpp:58] Creating layer relu_conv11
I1211 10:46:58.393301 15296 net.cpp:84] Creating Layer relu_conv11
I1211 10:46:58.393301 15296 net.cpp:406] relu_conv11 <- conv11
I1211 10:46:58.393301 15296 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 10:46:58.393800 15296 net.cpp:122] Setting up relu_conv11
I1211 10:46:58.393800 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.393800 15296 net.cpp:137] Memory required for data: 559975600
I1211 10:46:58.393800 15296 layer_factory.cpp:58] Creating layer conv12
I1211 10:46:58.393800 15296 net.cpp:84] Creating Layer conv12
I1211 10:46:58.393800 15296 net.cpp:406] conv12 <- conv11
I1211 10:46:58.393800 15296 net.cpp:380] conv12 -> conv12
I1211 10:46:58.395303 15296 net.cpp:122] Setting up conv12
I1211 10:46:58.395303 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.395303 15296 net.cpp:137] Memory required for data: 562279600
I1211 10:46:58.395303 15296 layer_factory.cpp:58] Creating layer bn_conv12
I1211 10:46:58.395303 15296 net.cpp:84] Creating Layer bn_conv12
I1211 10:46:58.395303 15296 net.cpp:406] bn_conv12 <- conv12
I1211 10:46:58.395303 15296 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 10:46:58.395800 15296 net.cpp:122] Setting up bn_conv12
I1211 10:46:58.395800 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.395800 15296 net.cpp:137] Memory required for data: 564583600
I1211 10:46:58.395800 15296 layer_factory.cpp:58] Creating layer scale_conv12
I1211 10:46:58.395800 15296 net.cpp:84] Creating Layer scale_conv12
I1211 10:46:58.395800 15296 net.cpp:406] scale_conv12 <- conv12
I1211 10:46:58.395800 15296 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 10:46:58.395800 15296 layer_factory.cpp:58] Creating layer scale_conv12
I1211 10:46:58.395800 15296 net.cpp:122] Setting up scale_conv12
I1211 10:46:58.395800 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.395800 15296 net.cpp:137] Memory required for data: 566887600
I1211 10:46:58.395800 15296 layer_factory.cpp:58] Creating layer relu_conv12
I1211 10:46:58.395800 15296 net.cpp:84] Creating Layer relu_conv12
I1211 10:46:58.395800 15296 net.cpp:406] relu_conv12 <- conv12
I1211 10:46:58.395800 15296 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 10:46:58.396301 15296 net.cpp:122] Setting up relu_conv12
I1211 10:46:58.396301 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.396301 15296 net.cpp:137] Memory required for data: 569191600
I1211 10:46:58.396301 15296 layer_factory.cpp:58] Creating layer poolcp6
I1211 10:46:58.396301 15296 net.cpp:84] Creating Layer poolcp6
I1211 10:46:58.396301 15296 net.cpp:406] poolcp6 <- conv12
I1211 10:46:58.396301 15296 net.cpp:380] poolcp6 -> poolcp6
I1211 10:46:58.396301 15296 net.cpp:122] Setting up poolcp6
I1211 10:46:58.396301 15296 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 10:46:58.396301 15296 net.cpp:137] Memory required for data: 569227600
I1211 10:46:58.396301 15296 layer_factory.cpp:58] Creating layer ip1
I1211 10:46:58.396301 15296 net.cpp:84] Creating Layer ip1
I1211 10:46:58.396301 15296 net.cpp:406] ip1 <- poolcp6
I1211 10:46:58.396301 15296 net.cpp:380] ip1 -> ip1
I1211 10:46:58.396800 15296 net.cpp:122] Setting up ip1
I1211 10:46:58.396800 15296 net.cpp:129] Top shape: 100 100 (10000)
I1211 10:46:58.396800 15296 net.cpp:137] Memory required for data: 569267600
I1211 10:46:58.396800 15296 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 10:46:58.396800 15296 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 10:46:58.396800 15296 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 10:46:58.396800 15296 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 10:46:58.396800 15296 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 10:46:58.396800 15296 net.cpp:122] Setting up ip1_ip1_0_split
I1211 10:46:58.396800 15296 net.cpp:129] Top shape: 100 100 (10000)
I1211 10:46:58.396800 15296 net.cpp:129] Top shape: 100 100 (10000)
I1211 10:46:58.396800 15296 net.cpp:137] Memory required for data: 569347600
I1211 10:46:58.396800 15296 layer_factory.cpp:58] Creating layer accuracy_training
I1211 10:46:58.396800 15296 net.cpp:84] Creating Layer accuracy_training
I1211 10:46:58.396800 15296 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1211 10:46:58.396800 15296 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1211 10:46:58.396800 15296 net.cpp:380] accuracy_training -> accuracy_training
I1211 10:46:58.396800 15296 net.cpp:122] Setting up accuracy_training
I1211 10:46:58.396800 15296 net.cpp:129] Top shape: (1)
I1211 10:46:58.396800 15296 net.cpp:137] Memory required for data: 569347604
I1211 10:46:58.396800 15296 layer_factory.cpp:58] Creating layer loss
I1211 10:46:58.396800 15296 net.cpp:84] Creating Layer loss
I1211 10:46:58.396800 15296 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 10:46:58.396800 15296 net.cpp:406] loss <- label_cifar_1_split_1
I1211 10:46:58.396800 15296 net.cpp:380] loss -> loss
I1211 10:46:58.396800 15296 layer_factory.cpp:58] Creating layer loss
I1211 10:46:58.397301 15296 net.cpp:122] Setting up loss
I1211 10:46:58.397301 15296 net.cpp:129] Top shape: (1)
I1211 10:46:58.397301 15296 net.cpp:132]     with loss weight 1
I1211 10:46:58.397301 15296 net.cpp:137] Memory required for data: 569347608
I1211 10:46:58.397301 15296 net.cpp:198] loss needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:200] accuracy_training does not need backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] ip1 needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] poolcp6 needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] relu_conv12 needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] scale_conv12 needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] bn_conv12 needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] conv12 needs backward computation.
I1211 10:46:58.397301 15296 net.cpp:198] relu_conv11 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale_conv11 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn_conv11 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv11 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu4_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale4_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn4_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv4_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] pool4_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu_added2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale_added2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn_added2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] added_new_conv2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu4_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale4_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn4_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv4_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu4_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale4_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn4_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv4_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu4 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale4 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn4 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv4 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu3_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale3_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn3_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv3_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu3 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale3 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn3 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv3 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] pool2_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu_added1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale_added1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn_added1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] newconv_added1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu2_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale2_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn2_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv2_2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu2_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale2_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn2_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv2_1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv2 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu1_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale1_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn1_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv1_0 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] relu1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] scale1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] bn1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:198] conv1 needs backward computation.
I1211 10:46:58.397801 15296 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 10:46:58.397801 15296 net.cpp:200] cifar does not need backward computation.
I1211 10:46:58.397801 15296 net.cpp:242] This network produces output accuracy_training
I1211 10:46:58.397801 15296 net.cpp:242] This network produces output loss
I1211 10:46:58.397801 15296 net.cpp:255] Network initialization done.
I1211 10:46:58.398800 15296 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 10:46:58.398800 15296 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 10:46:58.398800 15296 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_added1
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_added2
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1211 10:46:58.399299 15296 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1211 10:46:58.399299 15296 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added1"
  type: "BatchNorm"
  bottom: "newconv_added1"
  top: "newconv_added1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added1"
  type: "Scale"
  bottom: "newconv_added1"
  top: "newconv_added1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added1"
  type: "ReLU"
  bottom: "newconv_added1"
  top: "newconv_added1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added2"
  type: "BatchNorm"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added2"
  type: "Scale"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added2"
  type: "ReLU"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 10:46:58.399801 15296 layer_factory.cpp:58] Creating layer cifar
I1211 10:46:58.405799 15296 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1211 10:46:58.405799 15296 net.cpp:84] Creating Layer cifar
I1211 10:46:58.405799 15296 net.cpp:380] cifar -> data
I1211 10:46:58.405799 15296 net.cpp:380] cifar -> label
I1211 10:46:58.406301 15296 data_layer.cpp:45] output data size: 100,3,32,32
I1211 10:46:58.412806 15296 net.cpp:122] Setting up cifar
I1211 10:46:58.412806 15296 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 10:46:58.412806 15296 net.cpp:129] Top shape: 100 (100)
I1211 10:46:58.412806 15296 net.cpp:137] Memory required for data: 1229200
I1211 10:46:58.412806 15296 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 10:46:58.412806 15296 net.cpp:84] Creating Layer label_cifar_1_split
I1211 10:46:58.412806 15296 net.cpp:406] label_cifar_1_split <- label
I1211 10:46:58.412806 15296 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 10:46:58.412806 15296 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 10:46:58.412806 15296 net.cpp:122] Setting up label_cifar_1_split
I1211 10:46:58.412806 15296 net.cpp:129] Top shape: 100 (100)
I1211 10:46:58.412806 15296 net.cpp:129] Top shape: 100 (100)
I1211 10:46:58.412806 15296 net.cpp:137] Memory required for data: 1230000
I1211 10:46:58.412806 15296 layer_factory.cpp:58] Creating layer conv1
I1211 10:46:58.412806 15296 net.cpp:84] Creating Layer conv1
I1211 10:46:58.412806 15296 net.cpp:406] conv1 <- data
I1211 10:46:58.412806 15296 net.cpp:380] conv1 -> conv1
I1211 10:46:58.414317  3272 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 10:46:58.414317 15296 net.cpp:122] Setting up conv1
I1211 10:46:58.414317 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.414317 15296 net.cpp:137] Memory required for data: 13518000
I1211 10:46:58.414317 15296 layer_factory.cpp:58] Creating layer bn1
I1211 10:46:58.414317 15296 net.cpp:84] Creating Layer bn1
I1211 10:46:58.414317 15296 net.cpp:406] bn1 <- conv1
I1211 10:46:58.414317 15296 net.cpp:367] bn1 -> conv1 (in-place)
I1211 10:46:58.414815 15296 net.cpp:122] Setting up bn1
I1211 10:46:58.414815 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.414815 15296 net.cpp:137] Memory required for data: 25806000
I1211 10:46:58.414815 15296 layer_factory.cpp:58] Creating layer scale1
I1211 10:46:58.414815 15296 net.cpp:84] Creating Layer scale1
I1211 10:46:58.414815 15296 net.cpp:406] scale1 <- conv1
I1211 10:46:58.414815 15296 net.cpp:367] scale1 -> conv1 (in-place)
I1211 10:46:58.414815 15296 layer_factory.cpp:58] Creating layer scale1
I1211 10:46:58.415314 15296 net.cpp:122] Setting up scale1
I1211 10:46:58.415314 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.415314 15296 net.cpp:137] Memory required for data: 38094000
I1211 10:46:58.415314 15296 layer_factory.cpp:58] Creating layer relu1
I1211 10:46:58.415314 15296 net.cpp:84] Creating Layer relu1
I1211 10:46:58.415314 15296 net.cpp:406] relu1 <- conv1
I1211 10:46:58.415314 15296 net.cpp:367] relu1 -> conv1 (in-place)
I1211 10:46:58.416316 15296 net.cpp:122] Setting up relu1
I1211 10:46:58.416316 15296 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 10:46:58.416316 15296 net.cpp:137] Memory required for data: 50382000
I1211 10:46:58.416316 15296 layer_factory.cpp:58] Creating layer conv1_0
I1211 10:46:58.416316 15296 net.cpp:84] Creating Layer conv1_0
I1211 10:46:58.416316 15296 net.cpp:406] conv1_0 <- conv1
I1211 10:46:58.416316 15296 net.cpp:380] conv1_0 -> conv1_0
I1211 10:46:58.418316 15296 net.cpp:122] Setting up conv1_0
I1211 10:46:58.418316 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.418316 15296 net.cpp:137] Memory required for data: 66766000
I1211 10:46:58.418316 15296 layer_factory.cpp:58] Creating layer bn1_0
I1211 10:46:58.418316 15296 net.cpp:84] Creating Layer bn1_0
I1211 10:46:58.418316 15296 net.cpp:406] bn1_0 <- conv1_0
I1211 10:46:58.418316 15296 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 10:46:58.418316 15296 net.cpp:122] Setting up bn1_0
I1211 10:46:58.418316 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.418316 15296 net.cpp:137] Memory required for data: 83150000
I1211 10:46:58.418316 15296 layer_factory.cpp:58] Creating layer scale1_0
I1211 10:46:58.418316 15296 net.cpp:84] Creating Layer scale1_0
I1211 10:46:58.418316 15296 net.cpp:406] scale1_0 <- conv1_0
I1211 10:46:58.418316 15296 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 10:46:58.418316 15296 layer_factory.cpp:58] Creating layer scale1_0
I1211 10:46:58.418815 15296 net.cpp:122] Setting up scale1_0
I1211 10:46:58.418815 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.418815 15296 net.cpp:137] Memory required for data: 99534000
I1211 10:46:58.418815 15296 layer_factory.cpp:58] Creating layer relu1_0
I1211 10:46:58.418815 15296 net.cpp:84] Creating Layer relu1_0
I1211 10:46:58.418815 15296 net.cpp:406] relu1_0 <- conv1_0
I1211 10:46:58.418815 15296 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 10:46:58.418815 15296 net.cpp:122] Setting up relu1_0
I1211 10:46:58.418815 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.418815 15296 net.cpp:137] Memory required for data: 115918000
I1211 10:46:58.418815 15296 layer_factory.cpp:58] Creating layer conv2
I1211 10:46:58.418815 15296 net.cpp:84] Creating Layer conv2
I1211 10:46:58.418815 15296 net.cpp:406] conv2 <- conv1_0
I1211 10:46:58.418815 15296 net.cpp:380] conv2 -> conv2
I1211 10:46:58.420815 15296 net.cpp:122] Setting up conv2
I1211 10:46:58.420815 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.420815 15296 net.cpp:137] Memory required for data: 132302000
I1211 10:46:58.420815 15296 layer_factory.cpp:58] Creating layer bn2
I1211 10:46:58.420815 15296 net.cpp:84] Creating Layer bn2
I1211 10:46:58.420815 15296 net.cpp:406] bn2 <- conv2
I1211 10:46:58.420815 15296 net.cpp:367] bn2 -> conv2 (in-place)
I1211 10:46:58.421303 15296 net.cpp:122] Setting up bn2
I1211 10:46:58.421303 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.421303 15296 net.cpp:137] Memory required for data: 148686000
I1211 10:46:58.421303 15296 layer_factory.cpp:58] Creating layer scale2
I1211 10:46:58.421303 15296 net.cpp:84] Creating Layer scale2
I1211 10:46:58.421303 15296 net.cpp:406] scale2 <- conv2
I1211 10:46:58.421303 15296 net.cpp:367] scale2 -> conv2 (in-place)
I1211 10:46:58.421303 15296 layer_factory.cpp:58] Creating layer scale2
I1211 10:46:58.421303 15296 net.cpp:122] Setting up scale2
I1211 10:46:58.421303 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.421303 15296 net.cpp:137] Memory required for data: 165070000
I1211 10:46:58.421303 15296 layer_factory.cpp:58] Creating layer relu2
I1211 10:46:58.421303 15296 net.cpp:84] Creating Layer relu2
I1211 10:46:58.421303 15296 net.cpp:406] relu2 <- conv2
I1211 10:46:58.421303 15296 net.cpp:367] relu2 -> conv2 (in-place)
I1211 10:46:58.421802 15296 net.cpp:122] Setting up relu2
I1211 10:46:58.421802 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.421802 15296 net.cpp:137] Memory required for data: 181454000
I1211 10:46:58.421802 15296 layer_factory.cpp:58] Creating layer conv2_1
I1211 10:46:58.421802 15296 net.cpp:84] Creating Layer conv2_1
I1211 10:46:58.421802 15296 net.cpp:406] conv2_1 <- conv2
I1211 10:46:58.421802 15296 net.cpp:380] conv2_1 -> conv2_1
I1211 10:46:58.423316 15296 net.cpp:122] Setting up conv2_1
I1211 10:46:58.423316 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.423316 15296 net.cpp:137] Memory required for data: 197838000
I1211 10:46:58.423815 15296 layer_factory.cpp:58] Creating layer bn2_1
I1211 10:46:58.423815 15296 net.cpp:84] Creating Layer bn2_1
I1211 10:46:58.423815 15296 net.cpp:406] bn2_1 <- conv2_1
I1211 10:46:58.423815 15296 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 10:46:58.423815 15296 net.cpp:122] Setting up bn2_1
I1211 10:46:58.423815 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.423815 15296 net.cpp:137] Memory required for data: 214222000
I1211 10:46:58.423815 15296 layer_factory.cpp:58] Creating layer scale2_1
I1211 10:46:58.423815 15296 net.cpp:84] Creating Layer scale2_1
I1211 10:46:58.423815 15296 net.cpp:406] scale2_1 <- conv2_1
I1211 10:46:58.423815 15296 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 10:46:58.424300 15296 layer_factory.cpp:58] Creating layer scale2_1
I1211 10:46:58.424300 15296 net.cpp:122] Setting up scale2_1
I1211 10:46:58.424300 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.424300 15296 net.cpp:137] Memory required for data: 230606000
I1211 10:46:58.424300 15296 layer_factory.cpp:58] Creating layer relu2_1
I1211 10:46:58.424300 15296 net.cpp:84] Creating Layer relu2_1
I1211 10:46:58.424300 15296 net.cpp:406] relu2_1 <- conv2_1
I1211 10:46:58.424300 15296 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 10:46:58.424300 15296 net.cpp:122] Setting up relu2_1
I1211 10:46:58.424300 15296 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 10:46:58.424300 15296 net.cpp:137] Memory required for data: 246990000
I1211 10:46:58.424300 15296 layer_factory.cpp:58] Creating layer conv2_2
I1211 10:46:58.424300 15296 net.cpp:84] Creating Layer conv2_2
I1211 10:46:58.424814 15296 net.cpp:406] conv2_2 <- conv2_1
I1211 10:46:58.424814 15296 net.cpp:380] conv2_2 -> conv2_2
I1211 10:46:58.426301 15296 net.cpp:122] Setting up conv2_2
I1211 10:46:58.426301 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.426301 15296 net.cpp:137] Memory required for data: 267470000
I1211 10:46:58.426301 15296 layer_factory.cpp:58] Creating layer bn2_2
I1211 10:46:58.426301 15296 net.cpp:84] Creating Layer bn2_2
I1211 10:46:58.426301 15296 net.cpp:406] bn2_2 <- conv2_2
I1211 10:46:58.426301 15296 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 10:46:58.426815 15296 net.cpp:122] Setting up bn2_2
I1211 10:46:58.426815 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.426815 15296 net.cpp:137] Memory required for data: 287950000
I1211 10:46:58.426815 15296 layer_factory.cpp:58] Creating layer scale2_2
I1211 10:46:58.426815 15296 net.cpp:84] Creating Layer scale2_2
I1211 10:46:58.426815 15296 net.cpp:406] scale2_2 <- conv2_2
I1211 10:46:58.426815 15296 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 10:46:58.426815 15296 layer_factory.cpp:58] Creating layer scale2_2
I1211 10:46:58.426815 15296 net.cpp:122] Setting up scale2_2
I1211 10:46:58.426815 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.426815 15296 net.cpp:137] Memory required for data: 308430000
I1211 10:46:58.426815 15296 layer_factory.cpp:58] Creating layer relu2_2
I1211 10:46:58.426815 15296 net.cpp:84] Creating Layer relu2_2
I1211 10:46:58.426815 15296 net.cpp:406] relu2_2 <- conv2_2
I1211 10:46:58.426815 15296 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 10:46:58.427315 15296 net.cpp:122] Setting up relu2_2
I1211 10:46:58.427315 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.427315 15296 net.cpp:137] Memory required for data: 328910000
I1211 10:46:58.427315 15296 layer_factory.cpp:58] Creating layer newconv_added1
I1211 10:46:58.427315 15296 net.cpp:84] Creating Layer newconv_added1
I1211 10:46:58.427315 15296 net.cpp:406] newconv_added1 <- conv2_2
I1211 10:46:58.427315 15296 net.cpp:380] newconv_added1 -> newconv_added1
I1211 10:46:58.429316 15296 net.cpp:122] Setting up newconv_added1
I1211 10:46:58.429316 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.429316 15296 net.cpp:137] Memory required for data: 349390000
I1211 10:46:58.429316 15296 layer_factory.cpp:58] Creating layer bn_added1
I1211 10:46:58.429316 15296 net.cpp:84] Creating Layer bn_added1
I1211 10:46:58.429316 15296 net.cpp:406] bn_added1 <- newconv_added1
I1211 10:46:58.429316 15296 net.cpp:367] bn_added1 -> newconv_added1 (in-place)
I1211 10:46:58.429814 15296 net.cpp:122] Setting up bn_added1
I1211 10:46:58.429814 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.429814 15296 net.cpp:137] Memory required for data: 369870000
I1211 10:46:58.429814 15296 layer_factory.cpp:58] Creating layer scale_added1
I1211 10:46:58.429814 15296 net.cpp:84] Creating Layer scale_added1
I1211 10:46:58.429814 15296 net.cpp:406] scale_added1 <- newconv_added1
I1211 10:46:58.429814 15296 net.cpp:367] scale_added1 -> newconv_added1 (in-place)
I1211 10:46:58.429814 15296 layer_factory.cpp:58] Creating layer scale_added1
I1211 10:46:58.429814 15296 net.cpp:122] Setting up scale_added1
I1211 10:46:58.429814 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.429814 15296 net.cpp:137] Memory required for data: 390350000
I1211 10:46:58.429814 15296 layer_factory.cpp:58] Creating layer relu_added1
I1211 10:46:58.429814 15296 net.cpp:84] Creating Layer relu_added1
I1211 10:46:58.429814 15296 net.cpp:406] relu_added1 <- newconv_added1
I1211 10:46:58.429814 15296 net.cpp:367] relu_added1 -> newconv_added1 (in-place)
I1211 10:46:58.430315 15296 net.cpp:122] Setting up relu_added1
I1211 10:46:58.430315 15296 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 10:46:58.430315 15296 net.cpp:137] Memory required for data: 410830000
I1211 10:46:58.430315 15296 layer_factory.cpp:58] Creating layer pool2_1
I1211 10:46:58.430315 15296 net.cpp:84] Creating Layer pool2_1
I1211 10:46:58.430315 15296 net.cpp:406] pool2_1 <- newconv_added1
I1211 10:46:58.430315 15296 net.cpp:380] pool2_1 -> pool2_1
I1211 10:46:58.430816 15296 net.cpp:122] Setting up pool2_1
I1211 10:46:58.430816 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.430816 15296 net.cpp:137] Memory required for data: 415950000
I1211 10:46:58.430816 15296 layer_factory.cpp:58] Creating layer conv3
I1211 10:46:58.430816 15296 net.cpp:84] Creating Layer conv3
I1211 10:46:58.430816 15296 net.cpp:406] conv3 <- pool2_1
I1211 10:46:58.430816 15296 net.cpp:380] conv3 -> conv3
I1211 10:46:58.431800 15296 net.cpp:122] Setting up conv3
I1211 10:46:58.431800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.431800 15296 net.cpp:137] Memory required for data: 421070000
I1211 10:46:58.431800 15296 layer_factory.cpp:58] Creating layer bn3
I1211 10:46:58.431800 15296 net.cpp:84] Creating Layer bn3
I1211 10:46:58.431800 15296 net.cpp:406] bn3 <- conv3
I1211 10:46:58.431800 15296 net.cpp:367] bn3 -> conv3 (in-place)
I1211 10:46:58.431800 15296 net.cpp:122] Setting up bn3
I1211 10:46:58.431800 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.431800 15296 net.cpp:137] Memory required for data: 426190000
I1211 10:46:58.432298 15296 layer_factory.cpp:58] Creating layer scale3
I1211 10:46:58.432298 15296 net.cpp:84] Creating Layer scale3
I1211 10:46:58.432298 15296 net.cpp:406] scale3 <- conv3
I1211 10:46:58.432298 15296 net.cpp:367] scale3 -> conv3 (in-place)
I1211 10:46:58.432298 15296 layer_factory.cpp:58] Creating layer scale3
I1211 10:46:58.432298 15296 net.cpp:122] Setting up scale3
I1211 10:46:58.432298 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.432298 15296 net.cpp:137] Memory required for data: 431310000
I1211 10:46:58.432298 15296 layer_factory.cpp:58] Creating layer relu3
I1211 10:46:58.432298 15296 net.cpp:84] Creating Layer relu3
I1211 10:46:58.432298 15296 net.cpp:406] relu3 <- conv3
I1211 10:46:58.432298 15296 net.cpp:367] relu3 -> conv3 (in-place)
I1211 10:46:58.433310 15296 net.cpp:122] Setting up relu3
I1211 10:46:58.433310 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.433310 15296 net.cpp:137] Memory required for data: 436430000
I1211 10:46:58.433310 15296 layer_factory.cpp:58] Creating layer conv3_1
I1211 10:46:58.433310 15296 net.cpp:84] Creating Layer conv3_1
I1211 10:46:58.433310 15296 net.cpp:406] conv3_1 <- conv3
I1211 10:46:58.433310 15296 net.cpp:380] conv3_1 -> conv3_1
I1211 10:46:58.434803 15296 net.cpp:122] Setting up conv3_1
I1211 10:46:58.434803 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.434803 15296 net.cpp:137] Memory required for data: 441550000
I1211 10:46:58.434803 15296 layer_factory.cpp:58] Creating layer bn3_1
I1211 10:46:58.434803 15296 net.cpp:84] Creating Layer bn3_1
I1211 10:46:58.434803 15296 net.cpp:406] bn3_1 <- conv3_1
I1211 10:46:58.434803 15296 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 10:46:58.435312 15296 net.cpp:122] Setting up bn3_1
I1211 10:46:58.435312 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.435312 15296 net.cpp:137] Memory required for data: 446670000
I1211 10:46:58.435312 15296 layer_factory.cpp:58] Creating layer scale3_1
I1211 10:46:58.435312 15296 net.cpp:84] Creating Layer scale3_1
I1211 10:46:58.435312 15296 net.cpp:406] scale3_1 <- conv3_1
I1211 10:46:58.435312 15296 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 10:46:58.435312 15296 layer_factory.cpp:58] Creating layer scale3_1
I1211 10:46:58.435312 15296 net.cpp:122] Setting up scale3_1
I1211 10:46:58.435312 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.435312 15296 net.cpp:137] Memory required for data: 451790000
I1211 10:46:58.435312 15296 layer_factory.cpp:58] Creating layer relu3_1
I1211 10:46:58.435312 15296 net.cpp:84] Creating Layer relu3_1
I1211 10:46:58.435312 15296 net.cpp:406] relu3_1 <- conv3_1
I1211 10:46:58.435312 15296 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 10:46:58.435811 15296 net.cpp:122] Setting up relu3_1
I1211 10:46:58.435811 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.435811 15296 net.cpp:137] Memory required for data: 456910000
I1211 10:46:58.435811 15296 layer_factory.cpp:58] Creating layer conv4
I1211 10:46:58.435811 15296 net.cpp:84] Creating Layer conv4
I1211 10:46:58.435811 15296 net.cpp:406] conv4 <- conv3_1
I1211 10:46:58.435811 15296 net.cpp:380] conv4 -> conv4
I1211 10:46:58.437310 15296 net.cpp:122] Setting up conv4
I1211 10:46:58.437310 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.437310 15296 net.cpp:137] Memory required for data: 462030000
I1211 10:46:58.437310 15296 layer_factory.cpp:58] Creating layer bn4
I1211 10:46:58.437310 15296 net.cpp:84] Creating Layer bn4
I1211 10:46:58.437310 15296 net.cpp:406] bn4 <- conv4
I1211 10:46:58.437310 15296 net.cpp:367] bn4 -> conv4 (in-place)
I1211 10:46:58.437310 15296 net.cpp:122] Setting up bn4
I1211 10:46:58.437310 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.437310 15296 net.cpp:137] Memory required for data: 467150000
I1211 10:46:58.437310 15296 layer_factory.cpp:58] Creating layer scale4
I1211 10:46:58.437310 15296 net.cpp:84] Creating Layer scale4
I1211 10:46:58.437310 15296 net.cpp:406] scale4 <- conv4
I1211 10:46:58.437310 15296 net.cpp:367] scale4 -> conv4 (in-place)
I1211 10:46:58.437310 15296 layer_factory.cpp:58] Creating layer scale4
I1211 10:46:58.437809 15296 net.cpp:122] Setting up scale4
I1211 10:46:58.437809 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.437809 15296 net.cpp:137] Memory required for data: 472270000
I1211 10:46:58.437809 15296 layer_factory.cpp:58] Creating layer relu4
I1211 10:46:58.437809 15296 net.cpp:84] Creating Layer relu4
I1211 10:46:58.437809 15296 net.cpp:406] relu4 <- conv4
I1211 10:46:58.437809 15296 net.cpp:367] relu4 -> conv4 (in-place)
I1211 10:46:58.437809 15296 net.cpp:122] Setting up relu4
I1211 10:46:58.437809 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.437809 15296 net.cpp:137] Memory required for data: 477390000
I1211 10:46:58.437809 15296 layer_factory.cpp:58] Creating layer conv4_1
I1211 10:46:58.437809 15296 net.cpp:84] Creating Layer conv4_1
I1211 10:46:58.437809 15296 net.cpp:406] conv4_1 <- conv4
I1211 10:46:58.437809 15296 net.cpp:380] conv4_1 -> conv4_1
I1211 10:46:58.439311 15296 net.cpp:122] Setting up conv4_1
I1211 10:46:58.439311 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.439311 15296 net.cpp:137] Memory required for data: 482510000
I1211 10:46:58.439311 15296 layer_factory.cpp:58] Creating layer bn4_1
I1211 10:46:58.439311 15296 net.cpp:84] Creating Layer bn4_1
I1211 10:46:58.439311 15296 net.cpp:406] bn4_1 <- conv4_1
I1211 10:46:58.439311 15296 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 10:46:58.439311 15296 net.cpp:122] Setting up bn4_1
I1211 10:46:58.439311 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.439311 15296 net.cpp:137] Memory required for data: 487630000
I1211 10:46:58.439311 15296 layer_factory.cpp:58] Creating layer scale4_1
I1211 10:46:58.439311 15296 net.cpp:84] Creating Layer scale4_1
I1211 10:46:58.439311 15296 net.cpp:406] scale4_1 <- conv4_1
I1211 10:46:58.439311 15296 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 10:46:58.439810 15296 layer_factory.cpp:58] Creating layer scale4_1
I1211 10:46:58.439810 15296 net.cpp:122] Setting up scale4_1
I1211 10:46:58.439810 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.439810 15296 net.cpp:137] Memory required for data: 492750000
I1211 10:46:58.439810 15296 layer_factory.cpp:58] Creating layer relu4_1
I1211 10:46:58.439810 15296 net.cpp:84] Creating Layer relu4_1
I1211 10:46:58.439810 15296 net.cpp:406] relu4_1 <- conv4_1
I1211 10:46:58.439810 15296 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 10:46:58.439810 15296 net.cpp:122] Setting up relu4_1
I1211 10:46:58.439810 15296 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 10:46:58.439810 15296 net.cpp:137] Memory required for data: 497870000
I1211 10:46:58.439810 15296 layer_factory.cpp:58] Creating layer conv4_2
I1211 10:46:58.439810 15296 net.cpp:84] Creating Layer conv4_2
I1211 10:46:58.439810 15296 net.cpp:406] conv4_2 <- conv4_1
I1211 10:46:58.439810 15296 net.cpp:380] conv4_2 -> conv4_2
I1211 10:46:58.441310 15296 net.cpp:122] Setting up conv4_2
I1211 10:46:58.441310 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.441310 15296 net.cpp:137] Memory required for data: 503809200
I1211 10:46:58.441810 15296 layer_factory.cpp:58] Creating layer bn4_2
I1211 10:46:58.441810 15296 net.cpp:84] Creating Layer bn4_2
I1211 10:46:58.441810 15296 net.cpp:406] bn4_2 <- conv4_2
I1211 10:46:58.441810 15296 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 10:46:58.441810 15296 net.cpp:122] Setting up bn4_2
I1211 10:46:58.441810 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.441810 15296 net.cpp:137] Memory required for data: 509748400
I1211 10:46:58.441810 15296 layer_factory.cpp:58] Creating layer scale4_2
I1211 10:46:58.441810 15296 net.cpp:84] Creating Layer scale4_2
I1211 10:46:58.441810 15296 net.cpp:406] scale4_2 <- conv4_2
I1211 10:46:58.441810 15296 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 10:46:58.441810 15296 layer_factory.cpp:58] Creating layer scale4_2
I1211 10:46:58.441810 15296 net.cpp:122] Setting up scale4_2
I1211 10:46:58.441810 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.441810 15296 net.cpp:137] Memory required for data: 515687600
I1211 10:46:58.441810 15296 layer_factory.cpp:58] Creating layer relu4_2
I1211 10:46:58.441810 15296 net.cpp:84] Creating Layer relu4_2
I1211 10:46:58.441810 15296 net.cpp:406] relu4_2 <- conv4_2
I1211 10:46:58.441810 15296 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 10:46:58.442309 15296 net.cpp:122] Setting up relu4_2
I1211 10:46:58.442309 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.442309 15296 net.cpp:137] Memory required for data: 521626800
I1211 10:46:58.442309 15296 layer_factory.cpp:58] Creating layer added_new_conv2
I1211 10:46:58.442309 15296 net.cpp:84] Creating Layer added_new_conv2
I1211 10:46:58.442309 15296 net.cpp:406] added_new_conv2 <- conv4_2
I1211 10:46:58.442309 15296 net.cpp:380] added_new_conv2 -> added_new_conv2
I1211 10:46:58.443811 15296 net.cpp:122] Setting up added_new_conv2
I1211 10:46:58.443811 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.443811 15296 net.cpp:137] Memory required for data: 527566000
I1211 10:46:58.443811 15296 layer_factory.cpp:58] Creating layer bn_added2
I1211 10:46:58.443811 15296 net.cpp:84] Creating Layer bn_added2
I1211 10:46:58.443811 15296 net.cpp:406] bn_added2 <- added_new_conv2
I1211 10:46:58.443811 15296 net.cpp:367] bn_added2 -> added_new_conv2 (in-place)
I1211 10:46:58.443811 15296 net.cpp:122] Setting up bn_added2
I1211 10:46:58.443811 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.444309 15296 net.cpp:137] Memory required for data: 533505200
I1211 10:46:58.444309 15296 layer_factory.cpp:58] Creating layer scale_added2
I1211 10:46:58.444309 15296 net.cpp:84] Creating Layer scale_added2
I1211 10:46:58.444309 15296 net.cpp:406] scale_added2 <- added_new_conv2
I1211 10:46:58.444309 15296 net.cpp:367] scale_added2 -> added_new_conv2 (in-place)
I1211 10:46:58.444309 15296 layer_factory.cpp:58] Creating layer scale_added2
I1211 10:46:58.444309 15296 net.cpp:122] Setting up scale_added2
I1211 10:46:58.444309 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.444309 15296 net.cpp:137] Memory required for data: 539444400
I1211 10:46:58.444309 15296 layer_factory.cpp:58] Creating layer relu_added2
I1211 10:46:58.444309 15296 net.cpp:84] Creating Layer relu_added2
I1211 10:46:58.444309 15296 net.cpp:406] relu_added2 <- added_new_conv2
I1211 10:46:58.444309 15296 net.cpp:367] relu_added2 -> added_new_conv2 (in-place)
I1211 10:46:58.444802 15296 net.cpp:122] Setting up relu_added2
I1211 10:46:58.444802 15296 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 10:46:58.444802 15296 net.cpp:137] Memory required for data: 545383600
I1211 10:46:58.444802 15296 layer_factory.cpp:58] Creating layer pool4_2
I1211 10:46:58.444802 15296 net.cpp:84] Creating Layer pool4_2
I1211 10:46:58.444802 15296 net.cpp:406] pool4_2 <- added_new_conv2
I1211 10:46:58.444802 15296 net.cpp:380] pool4_2 -> pool4_2
I1211 10:46:58.444802 15296 net.cpp:122] Setting up pool4_2
I1211 10:46:58.444802 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.444802 15296 net.cpp:137] Memory required for data: 546868400
I1211 10:46:58.444802 15296 layer_factory.cpp:58] Creating layer conv4_0
I1211 10:46:58.444802 15296 net.cpp:84] Creating Layer conv4_0
I1211 10:46:58.444802 15296 net.cpp:406] conv4_0 <- pool4_2
I1211 10:46:58.444802 15296 net.cpp:380] conv4_0 -> conv4_0
I1211 10:46:58.447310 15296 net.cpp:122] Setting up conv4_0
I1211 10:46:58.447310 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.447310 15296 net.cpp:137] Memory required for data: 548353200
I1211 10:46:58.447310 15296 layer_factory.cpp:58] Creating layer bn4_0
I1211 10:46:58.447310 15296 net.cpp:84] Creating Layer bn4_0
I1211 10:46:58.447310 15296 net.cpp:406] bn4_0 <- conv4_0
I1211 10:46:58.447310 15296 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 10:46:58.447810 15296 net.cpp:122] Setting up bn4_0
I1211 10:46:58.447810 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.447810 15296 net.cpp:137] Memory required for data: 549838000
I1211 10:46:58.447810 15296 layer_factory.cpp:58] Creating layer scale4_0
I1211 10:46:58.447810 15296 net.cpp:84] Creating Layer scale4_0
I1211 10:46:58.447810 15296 net.cpp:406] scale4_0 <- conv4_0
I1211 10:46:58.447810 15296 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 10:46:58.447810 15296 layer_factory.cpp:58] Creating layer scale4_0
I1211 10:46:58.447810 15296 net.cpp:122] Setting up scale4_0
I1211 10:46:58.447810 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.447810 15296 net.cpp:137] Memory required for data: 551322800
I1211 10:46:58.447810 15296 layer_factory.cpp:58] Creating layer relu4_0
I1211 10:46:58.447810 15296 net.cpp:84] Creating Layer relu4_0
I1211 10:46:58.447810 15296 net.cpp:406] relu4_0 <- conv4_0
I1211 10:46:58.447810 15296 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 10:46:58.448310 15296 net.cpp:122] Setting up relu4_0
I1211 10:46:58.448310 15296 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 10:46:58.448310 15296 net.cpp:137] Memory required for data: 552807600
I1211 10:46:58.448310 15296 layer_factory.cpp:58] Creating layer conv11
I1211 10:46:58.448310 15296 net.cpp:84] Creating Layer conv11
I1211 10:46:58.448310 15296 net.cpp:406] conv11 <- conv4_0
I1211 10:46:58.448814 15296 net.cpp:380] conv11 -> conv11
I1211 10:46:58.450307 15296 net.cpp:122] Setting up conv11
I1211 10:46:58.450307 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.450307 15296 net.cpp:137] Memory required for data: 554599600
I1211 10:46:58.450307 15296 layer_factory.cpp:58] Creating layer bn_conv11
I1211 10:46:58.450809 15296 net.cpp:84] Creating Layer bn_conv11
I1211 10:46:58.450809 15296 net.cpp:406] bn_conv11 <- conv11
I1211 10:46:58.450809 15296 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 10:46:58.450809 15296 net.cpp:122] Setting up bn_conv11
I1211 10:46:58.450809 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.450809 15296 net.cpp:137] Memory required for data: 556391600
I1211 10:46:58.450809 15296 layer_factory.cpp:58] Creating layer scale_conv11
I1211 10:46:58.450809 15296 net.cpp:84] Creating Layer scale_conv11
I1211 10:46:58.450809 15296 net.cpp:406] scale_conv11 <- conv11
I1211 10:46:58.450809 15296 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 10:46:58.450809 15296 layer_factory.cpp:58] Creating layer scale_conv11
I1211 10:46:58.451303 15296 net.cpp:122] Setting up scale_conv11
I1211 10:46:58.451303 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.451303 15296 net.cpp:137] Memory required for data: 558183600
I1211 10:46:58.451303 15296 layer_factory.cpp:58] Creating layer relu_conv11
I1211 10:46:58.451303 15296 net.cpp:84] Creating Layer relu_conv11
I1211 10:46:58.451303 15296 net.cpp:406] relu_conv11 <- conv11
I1211 10:46:58.451303 15296 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 10:46:58.451303 15296 net.cpp:122] Setting up relu_conv11
I1211 10:46:58.451303 15296 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 10:46:58.451303 15296 net.cpp:137] Memory required for data: 559975600
I1211 10:46:58.451303 15296 layer_factory.cpp:58] Creating layer conv12
I1211 10:46:58.451303 15296 net.cpp:84] Creating Layer conv12
I1211 10:46:58.451303 15296 net.cpp:406] conv12 <- conv11
I1211 10:46:58.451303 15296 net.cpp:380] conv12 -> conv12
I1211 10:46:58.453302 15296 net.cpp:122] Setting up conv12
I1211 10:46:58.453302 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.453302 15296 net.cpp:137] Memory required for data: 562279600
I1211 10:46:58.453302 15296 layer_factory.cpp:58] Creating layer bn_conv12
I1211 10:46:58.453302 15296 net.cpp:84] Creating Layer bn_conv12
I1211 10:46:58.453302 15296 net.cpp:406] bn_conv12 <- conv12
I1211 10:46:58.453302 15296 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 10:46:58.453810 15296 net.cpp:122] Setting up bn_conv12
I1211 10:46:58.453810 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.453810 15296 net.cpp:137] Memory required for data: 564583600
I1211 10:46:58.453810 15296 layer_factory.cpp:58] Creating layer scale_conv12
I1211 10:46:58.453810 15296 net.cpp:84] Creating Layer scale_conv12
I1211 10:46:58.453810 15296 net.cpp:406] scale_conv12 <- conv12
I1211 10:46:58.453810 15296 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 10:46:58.453810 15296 layer_factory.cpp:58] Creating layer scale_conv12
I1211 10:46:58.453810 15296 net.cpp:122] Setting up scale_conv12
I1211 10:46:58.453810 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.453810 15296 net.cpp:137] Memory required for data: 566887600
I1211 10:46:58.453810 15296 layer_factory.cpp:58] Creating layer relu_conv12
I1211 10:46:58.453810 15296 net.cpp:84] Creating Layer relu_conv12
I1211 10:46:58.453810 15296 net.cpp:406] relu_conv12 <- conv12
I1211 10:46:58.453810 15296 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 10:46:58.454310 15296 net.cpp:122] Setting up relu_conv12
I1211 10:46:58.454310 15296 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 10:46:58.454310 15296 net.cpp:137] Memory required for data: 569191600
I1211 10:46:58.454310 15296 layer_factory.cpp:58] Creating layer poolcp6
I1211 10:46:58.454310 15296 net.cpp:84] Creating Layer poolcp6
I1211 10:46:58.454310 15296 net.cpp:406] poolcp6 <- conv12
I1211 10:46:58.454310 15296 net.cpp:380] poolcp6 -> poolcp6
I1211 10:46:58.454310 15296 net.cpp:122] Setting up poolcp6
I1211 10:46:58.454310 15296 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 10:46:58.454310 15296 net.cpp:137] Memory required for data: 569227600
I1211 10:46:58.454310 15296 layer_factory.cpp:58] Creating layer ip1
I1211 10:46:58.454310 15296 net.cpp:84] Creating Layer ip1
I1211 10:46:58.454310 15296 net.cpp:406] ip1 <- poolcp6
I1211 10:46:58.454310 15296 net.cpp:380] ip1 -> ip1
I1211 10:46:58.454310 15296 net.cpp:122] Setting up ip1
I1211 10:46:58.454799 15296 net.cpp:129] Top shape: 100 100 (10000)
I1211 10:46:58.454799 15296 net.cpp:137] Memory required for data: 569267600
I1211 10:46:58.454799 15296 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 10:46:58.454799 15296 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 10:46:58.454799 15296 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 10:46:58.454799 15296 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 10:46:58.454799 15296 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 10:46:58.454799 15296 net.cpp:122] Setting up ip1_ip1_0_split
I1211 10:46:58.454799 15296 net.cpp:129] Top shape: 100 100 (10000)
I1211 10:46:58.454799 15296 net.cpp:129] Top shape: 100 100 (10000)
I1211 10:46:58.454799 15296 net.cpp:137] Memory required for data: 569347600
I1211 10:46:58.454799 15296 layer_factory.cpp:58] Creating layer accuracy
I1211 10:46:58.454799 15296 net.cpp:84] Creating Layer accuracy
I1211 10:46:58.454799 15296 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1211 10:46:58.454799 15296 net.cpp:406] accuracy <- label_cifar_1_split_0
I1211 10:46:58.454799 15296 net.cpp:380] accuracy -> accuracy
I1211 10:46:58.454799 15296 net.cpp:122] Setting up accuracy
I1211 10:46:58.454799 15296 net.cpp:129] Top shape: (1)
I1211 10:46:58.454799 15296 net.cpp:137] Memory required for data: 569347604
I1211 10:46:58.454799 15296 layer_factory.cpp:58] Creating layer loss
I1211 10:46:58.454799 15296 net.cpp:84] Creating Layer loss
I1211 10:46:58.454799 15296 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 10:46:58.454799 15296 net.cpp:406] loss <- label_cifar_1_split_1
I1211 10:46:58.454799 15296 net.cpp:380] loss -> loss
I1211 10:46:58.454799 15296 layer_factory.cpp:58] Creating layer loss
I1211 10:46:58.455302 15296 net.cpp:122] Setting up loss
I1211 10:46:58.455302 15296 net.cpp:129] Top shape: (1)
I1211 10:46:58.455302 15296 net.cpp:132]     with loss weight 1
I1211 10:46:58.455302 15296 net.cpp:137] Memory required for data: 569347608
I1211 10:46:58.455302 15296 net.cpp:198] loss needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:200] accuracy does not need backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] ip1 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] poolcp6 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] relu_conv12 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] scale_conv12 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] bn_conv12 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] conv12 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] relu_conv11 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] scale_conv11 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] bn_conv11 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] conv11 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] relu4_0 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] scale4_0 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] bn4_0 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] conv4_0 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] pool4_2 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] relu_added2 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] scale_added2 needs backward computation.
I1211 10:46:58.455302 15296 net.cpp:198] bn_added2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] added_new_conv2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu4_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale4_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn4_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv4_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu4_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale4_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn4_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv4_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu4 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale4 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn4 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv4 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu3_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale3_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn3_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv3_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu3 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale3 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn3 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv3 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] pool2_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu_added1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale_added1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn_added1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] newconv_added1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu2_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale2_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn2_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv2_2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu2_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale2_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn2_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv2_1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv2 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu1_0 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale1_0 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn1_0 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv1_0 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] relu1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] scale1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] bn1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:198] conv1 needs backward computation.
I1211 10:46:58.455816 15296 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 10:46:58.455816 15296 net.cpp:200] cifar does not need backward computation.
I1211 10:46:58.455816 15296 net.cpp:242] This network produces output accuracy
I1211 10:46:58.455816 15296 net.cpp:242] This network produces output loss
I1211 10:46:58.455816 15296 net.cpp:255] Network initialization done.
I1211 10:46:58.456315 15296 solver.cpp:56] Solver scaffolding done.
I1211 10:46:58.460810 15296 caffe.cpp:249] Starting Optimization
I1211 10:46:58.460810 15296 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_360k
I1211 10:46:58.460810 15296 solver.cpp:273] Learning Rate Policy: multistep
I1211 10:46:58.463802 15296 solver.cpp:330] Iteration 0, Testing net (#0)
I1211 10:46:58.466300 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:47:00.097301  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:47:00.158799 15296 solver.cpp:397]     Test net output #0: accuracy = 0.0104
I1211 10:47:00.158799 15296 solver.cpp:397]     Test net output #1: loss = 86.4282 (* 1 = 86.4282 loss)
I1211 10:47:00.278380 15296 solver.cpp:218] Iteration 0 (-nan iter/s, 1.81603s/100 iters), loss = 6.65199
I1211 10:47:00.278380 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.01
I1211 10:47:00.278380 15296 solver.cpp:237]     Train net output #1: loss = 6.65199 (* 1 = 6.65199 loss)
I1211 10:47:00.278380 15296 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1211 10:47:06.858891 15296 solver.cpp:218] Iteration 100 (15.1974 iter/s, 6.58006s/100 iters), loss = 4.56906
I1211 10:47:06.858891 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.02
I1211 10:47:06.858891 15296 solver.cpp:237]     Train net output #1: loss = 4.56906 (* 1 = 4.56906 loss)
I1211 10:47:06.858891 15296 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1211 10:47:13.424258 15296 solver.cpp:218] Iteration 200 (15.2331 iter/s, 6.56467s/100 iters), loss = 4.31246
I1211 10:47:13.424258 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.01
I1211 10:47:13.424258 15296 solver.cpp:237]     Train net output #1: loss = 4.31246 (* 1 = 4.31246 loss)
I1211 10:47:13.424258 15296 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1211 10:47:19.984764 15296 solver.cpp:218] Iteration 300 (15.2439 iter/s, 6.55999s/100 iters), loss = 4.1916
I1211 10:47:19.984764 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.04
I1211 10:47:19.984764 15296 solver.cpp:237]     Train net output #1: loss = 4.1916 (* 1 = 4.1916 loss)
I1211 10:47:19.984764 15296 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1211 10:47:26.543387 15296 solver.cpp:218] Iteration 400 (15.2485 iter/s, 6.55803s/100 iters), loss = 4.07523
I1211 10:47:26.543387 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1211 10:47:26.543387 15296 solver.cpp:237]     Train net output #1: loss = 4.07523 (* 1 = 4.07523 loss)
I1211 10:47:26.543387 15296 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1211 10:47:32.781443 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:47:33.038444 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_500.caffemodel
I1211 10:47:33.060444 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_500.solverstate
I1211 10:47:33.065446 15296 solver.cpp:330] Iteration 500, Testing net (#0)
I1211 10:47:33.065446 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:47:34.628444  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:47:34.689944 15296 solver.cpp:397]     Test net output #0: accuracy = 0.0542
I1211 10:47:34.689944 15296 solver.cpp:397]     Test net output #1: loss = 4.27733 (* 1 = 4.27733 loss)
I1211 10:47:34.752955 15296 solver.cpp:218] Iteration 500 (12.1813 iter/s, 8.20933s/100 iters), loss = 3.97297
I1211 10:47:34.752955 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1211 10:47:34.753443 15296 solver.cpp:237]     Train net output #1: loss = 3.97297 (* 1 = 3.97297 loss)
I1211 10:47:34.753443 15296 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1211 10:47:41.321418 15296 solver.cpp:218] Iteration 600 (15.2256 iter/s, 6.56787s/100 iters), loss = 3.87668
I1211 10:47:41.321418 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I1211 10:47:41.321418 15296 solver.cpp:237]     Train net output #1: loss = 3.87668 (* 1 = 3.87668 loss)
I1211 10:47:41.321418 15296 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1211 10:47:47.895740 15296 solver.cpp:218] Iteration 700 (15.2123 iter/s, 6.57365s/100 iters), loss = 3.71907
I1211 10:47:47.895740 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1211 10:47:47.895740 15296 solver.cpp:237]     Train net output #1: loss = 3.71907 (* 1 = 3.71907 loss)
I1211 10:47:47.895740 15296 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1211 10:47:54.467972 15296 solver.cpp:218] Iteration 800 (15.2161 iter/s, 6.57197s/100 iters), loss = 3.62902
I1211 10:47:54.468458 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.15
I1211 10:47:54.468458 15296 solver.cpp:237]     Train net output #1: loss = 3.62902 (* 1 = 3.62902 loss)
I1211 10:47:54.468458 15296 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1211 10:48:01.043212 15296 solver.cpp:218] Iteration 900 (15.2098 iter/s, 6.57473s/100 iters), loss = 3.68324
I1211 10:48:01.043714 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.11
I1211 10:48:01.043714 15296 solver.cpp:237]     Train net output #1: loss = 3.68324 (* 1 = 3.68324 loss)
I1211 10:48:01.043714 15296 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1211 10:48:07.299055 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:48:07.558050 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1000.caffemodel
I1211 10:48:07.573536 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1000.solverstate
I1211 10:48:07.578552 15296 solver.cpp:330] Iteration 1000, Testing net (#0)
I1211 10:48:07.578552 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:48:09.144600  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:48:09.206609 15296 solver.cpp:397]     Test net output #0: accuracy = 0.0862
I1211 10:48:09.206609 15296 solver.cpp:397]     Test net output #1: loss = 4.09157 (* 1 = 4.09157 loss)
I1211 10:48:09.270109 15296 solver.cpp:218] Iteration 1000 (12.1564 iter/s, 8.22613s/100 iters), loss = 3.52735
I1211 10:48:09.270109 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 10:48:09.270109 15296 solver.cpp:237]     Train net output #1: loss = 3.52735 (* 1 = 3.52735 loss)
I1211 10:48:09.270109 15296 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1211 10:48:15.841159 15296 solver.cpp:218] Iteration 1100 (15.2188 iter/s, 6.57081s/100 iters), loss = 3.57132
I1211 10:48:15.841660 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1211 10:48:15.841660 15296 solver.cpp:237]     Train net output #1: loss = 3.57132 (* 1 = 3.57132 loss)
I1211 10:48:15.841660 15296 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1211 10:48:22.440392 15296 solver.cpp:218] Iteration 1200 (15.1553 iter/s, 6.59833s/100 iters), loss = 3.12853
I1211 10:48:22.440392 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.21
I1211 10:48:22.440392 15296 solver.cpp:237]     Train net output #1: loss = 3.12853 (* 1 = 3.12853 loss)
I1211 10:48:22.440392 15296 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1211 10:48:29.046231 15296 solver.cpp:218] Iteration 1300 (15.1388 iter/s, 6.60556s/100 iters), loss = 3.18344
I1211 10:48:29.046231 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 10:48:29.046231 15296 solver.cpp:237]     Train net output #1: loss = 3.18344 (* 1 = 3.18344 loss)
I1211 10:48:29.046231 15296 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1211 10:48:35.653234 15296 solver.cpp:218] Iteration 1400 (15.1367 iter/s, 6.60648s/100 iters), loss = 3.56257
I1211 10:48:35.653234 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.12
I1211 10:48:35.653234 15296 solver.cpp:237]     Train net output #1: loss = 3.56257 (* 1 = 3.56257 loss)
I1211 10:48:35.653234 15296 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1211 10:48:41.829803 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:48:42.078923 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1500.caffemodel
I1211 10:48:42.094909 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1500.solverstate
I1211 10:48:42.100909 15296 solver.cpp:330] Iteration 1500, Testing net (#0)
I1211 10:48:42.101913 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:48:43.635251  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:48:43.696847 15296 solver.cpp:397]     Test net output #0: accuracy = 0.1543
I1211 10:48:43.696847 15296 solver.cpp:397]     Test net output #1: loss = 3.59285 (* 1 = 3.59285 loss)
I1211 10:48:43.759872 15296 solver.cpp:218] Iteration 1500 (12.3368 iter/s, 8.10583s/100 iters), loss = 3.11644
I1211 10:48:43.759872 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 10:48:43.759872 15296 solver.cpp:237]     Train net output #1: loss = 3.11644 (* 1 = 3.11644 loss)
I1211 10:48:43.759872 15296 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1211 10:48:50.229523 15296 solver.cpp:218] Iteration 1600 (15.4582 iter/s, 6.46907s/100 iters), loss = 3.27489
I1211 10:48:50.229523 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1211 10:48:50.229523 15296 solver.cpp:237]     Train net output #1: loss = 3.27489 (* 1 = 3.27489 loss)
I1211 10:48:50.229523 15296 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1211 10:48:56.782434 15296 solver.cpp:218] Iteration 1700 (15.2614 iter/s, 6.55248s/100 iters), loss = 2.7122
I1211 10:48:56.782434 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.28
I1211 10:48:56.782434 15296 solver.cpp:237]     Train net output #1: loss = 2.7122 (* 1 = 2.7122 loss)
I1211 10:48:56.782434 15296 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1211 10:49:03.399811 15296 solver.cpp:218] Iteration 1800 (15.1126 iter/s, 6.61702s/100 iters), loss = 2.78643
I1211 10:49:03.399811 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.28
I1211 10:49:03.399811 15296 solver.cpp:237]     Train net output #1: loss = 2.78643 (* 1 = 2.78643 loss)
I1211 10:49:03.399811 15296 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1211 10:49:09.965561 15296 solver.cpp:218] Iteration 1900 (15.2321 iter/s, 6.56509s/100 iters), loss = 3.01636
I1211 10:49:09.965561 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.22
I1211 10:49:09.965561 15296 solver.cpp:237]     Train net output #1: loss = 3.01636 (* 1 = 3.01636 loss)
I1211 10:49:09.965561 15296 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1211 10:49:16.218255 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:49:16.476755 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2000.caffemodel
I1211 10:49:16.492754 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2000.solverstate
I1211 10:49:16.497254 15296 solver.cpp:330] Iteration 2000, Testing net (#0)
I1211 10:49:16.497254 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:49:18.068755  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:49:18.132256 15296 solver.cpp:397]     Test net output #0: accuracy = 0.1973
I1211 10:49:18.132256 15296 solver.cpp:397]     Test net output #1: loss = 3.35015 (* 1 = 3.35015 loss)
I1211 10:49:18.194756 15296 solver.cpp:218] Iteration 2000 (12.1528 iter/s, 8.22856s/100 iters), loss = 2.77411
I1211 10:49:18.194756 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 10:49:18.194756 15296 solver.cpp:237]     Train net output #1: loss = 2.77411 (* 1 = 2.77411 loss)
I1211 10:49:18.194756 15296 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1211 10:49:24.781107 15296 solver.cpp:218] Iteration 2100 (15.1832 iter/s, 6.58624s/100 iters), loss = 2.69059
I1211 10:49:24.781608 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.24
I1211 10:49:24.781608 15296 solver.cpp:237]     Train net output #1: loss = 2.69059 (* 1 = 2.69059 loss)
I1211 10:49:24.781608 15296 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1211 10:49:31.363737 15296 solver.cpp:218] Iteration 2200 (15.1931 iter/s, 6.58192s/100 iters), loss = 2.44281
I1211 10:49:31.363737 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 10:49:31.363737 15296 solver.cpp:237]     Train net output #1: loss = 2.44281 (* 1 = 2.44281 loss)
I1211 10:49:31.363737 15296 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1211 10:49:37.945849 15296 solver.cpp:218] Iteration 2300 (15.194 iter/s, 6.58153s/100 iters), loss = 2.75695
I1211 10:49:37.945849 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 10:49:37.945849 15296 solver.cpp:237]     Train net output #1: loss = 2.75695 (* 1 = 2.75695 loss)
I1211 10:49:37.945849 15296 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1211 10:49:44.520107 15296 solver.cpp:218] Iteration 2400 (15.2117 iter/s, 6.5739s/100 iters), loss = 2.69821
I1211 10:49:44.520107 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1211 10:49:44.520107 15296 solver.cpp:237]     Train net output #1: loss = 2.69821 (* 1 = 2.69821 loss)
I1211 10:49:44.520107 15296 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1211 10:49:50.778008 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:49:51.036007 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2500.caffemodel
I1211 10:49:51.052510 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2500.solverstate
I1211 10:49:51.057508 15296 solver.cpp:330] Iteration 2500, Testing net (#0)
I1211 10:49:51.057508 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:49:52.626507  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:49:52.688007 15296 solver.cpp:397]     Test net output #0: accuracy = 0.195
I1211 10:49:52.688007 15296 solver.cpp:397]     Test net output #1: loss = 3.3482 (* 1 = 3.3482 loss)
I1211 10:49:52.750006 15296 solver.cpp:218] Iteration 2500 (12.1519 iter/s, 8.22918s/100 iters), loss = 2.65507
I1211 10:49:52.750006 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 10:49:52.750006 15296 solver.cpp:237]     Train net output #1: loss = 2.65507 (* 1 = 2.65507 loss)
I1211 10:49:52.750006 15296 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1211 10:49:59.243697 15296 solver.cpp:218] Iteration 2600 (15.4005 iter/s, 6.49329s/100 iters), loss = 2.47479
I1211 10:49:59.243697 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1211 10:49:59.243697 15296 solver.cpp:237]     Train net output #1: loss = 2.47479 (* 1 = 2.47479 loss)
I1211 10:49:59.243697 15296 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1211 10:50:05.724947 15296 solver.cpp:218] Iteration 2700 (15.4301 iter/s, 6.48086s/100 iters), loss = 2.32578
I1211 10:50:05.724947 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:50:05.725448 15296 solver.cpp:237]     Train net output #1: loss = 2.32578 (* 1 = 2.32578 loss)
I1211 10:50:05.725448 15296 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1211 10:50:12.188313 15296 solver.cpp:218] Iteration 2800 (15.4737 iter/s, 6.46257s/100 iters), loss = 2.57308
I1211 10:50:12.188313 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 10:50:12.188313 15296 solver.cpp:237]     Train net output #1: loss = 2.57308 (* 1 = 2.57308 loss)
I1211 10:50:12.188313 15296 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1211 10:50:18.649804 15296 solver.cpp:218] Iteration 2900 (15.4772 iter/s, 6.46111s/100 iters), loss = 2.57719
I1211 10:50:18.649804 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1211 10:50:18.649804 15296 solver.cpp:237]     Train net output #1: loss = 2.57719 (* 1 = 2.57719 loss)
I1211 10:50:18.649804 15296 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1211 10:50:24.797421 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:50:25.051918 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3000.caffemodel
I1211 10:50:25.067418 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3000.solverstate
I1211 10:50:25.072918 15296 solver.cpp:330] Iteration 3000, Testing net (#0)
I1211 10:50:25.073418 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:50:26.626421  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:50:26.688421 15296 solver.cpp:397]     Test net output #0: accuracy = 0.262
I1211 10:50:26.688421 15296 solver.cpp:397]     Test net output #1: loss = 2.87099 (* 1 = 2.87099 loss)
I1211 10:50:26.750427 15296 solver.cpp:218] Iteration 3000 (12.3459 iter/s, 8.09983s/100 iters), loss = 2.50353
I1211 10:50:26.750427 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1211 10:50:26.750427 15296 solver.cpp:237]     Train net output #1: loss = 2.50353 (* 1 = 2.50353 loss)
I1211 10:50:26.750427 15296 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1211 10:50:33.232362 15296 solver.cpp:218] Iteration 3100 (15.4282 iter/s, 6.48165s/100 iters), loss = 2.42739
I1211 10:50:33.232362 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1211 10:50:33.232362 15296 solver.cpp:237]     Train net output #1: loss = 2.42739 (* 1 = 2.42739 loss)
I1211 10:50:33.232362 15296 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1211 10:50:39.706028 15296 solver.cpp:218] Iteration 3200 (15.4482 iter/s, 6.47323s/100 iters), loss = 2.08605
I1211 10:50:39.706028 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:50:39.706028 15296 solver.cpp:237]     Train net output #1: loss = 2.08605 (* 1 = 2.08605 loss)
I1211 10:50:39.706028 15296 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1211 10:50:46.175853 15296 solver.cpp:218] Iteration 3300 (15.4575 iter/s, 6.46935s/100 iters), loss = 2.35409
I1211 10:50:46.175853 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 10:50:46.175853 15296 solver.cpp:237]     Train net output #1: loss = 2.35409 (* 1 = 2.35409 loss)
I1211 10:50:46.175853 15296 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1211 10:50:52.650478 15296 solver.cpp:218] Iteration 3400 (15.4462 iter/s, 6.4741s/100 iters), loss = 2.38344
I1211 10:50:52.650478 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 10:50:52.650478 15296 solver.cpp:237]     Train net output #1: loss = 2.38344 (* 1 = 2.38344 loss)
I1211 10:50:52.650478 15296 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1211 10:50:58.805691 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:50:59.060189 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3500.caffemodel
I1211 10:50:59.078689 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3500.solverstate
I1211 10:50:59.085189 15296 solver.cpp:330] Iteration 3500, Testing net (#0)
I1211 10:50:59.085690 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:51:00.636286  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:51:00.697278 15296 solver.cpp:397]     Test net output #0: accuracy = 0.1716
I1211 10:51:00.697278 15296 solver.cpp:397]     Test net output #1: loss = 3.60446 (* 1 = 3.60446 loss)
I1211 10:51:00.759794 15296 solver.cpp:218] Iteration 3500 (12.3327 iter/s, 8.1085s/100 iters), loss = 2.31259
I1211 10:51:00.759794 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 10:51:00.759794 15296 solver.cpp:237]     Train net output #1: loss = 2.31259 (* 1 = 2.31259 loss)
I1211 10:51:00.759794 15296 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1211 10:51:07.230758 15296 solver.cpp:218] Iteration 3600 (15.4545 iter/s, 6.47061s/100 iters), loss = 2.23079
I1211 10:51:07.230758 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 10:51:07.230758 15296 solver.cpp:237]     Train net output #1: loss = 2.23079 (* 1 = 2.23079 loss)
I1211 10:51:07.230758 15296 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1211 10:51:13.714653 15296 solver.cpp:218] Iteration 3700 (15.4235 iter/s, 6.48361s/100 iters), loss = 1.96286
I1211 10:51:13.714653 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 10:51:13.714653 15296 solver.cpp:237]     Train net output #1: loss = 1.96286 (* 1 = 1.96286 loss)
I1211 10:51:13.714653 15296 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1211 10:51:20.193817 15296 solver.cpp:218] Iteration 3800 (15.4355 iter/s, 6.47856s/100 iters), loss = 2.28785
I1211 10:51:20.193817 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 10:51:20.193817 15296 solver.cpp:237]     Train net output #1: loss = 2.28785 (* 1 = 2.28785 loss)
I1211 10:51:20.193817 15296 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1211 10:51:26.703827 15296 solver.cpp:218] Iteration 3900 (15.362 iter/s, 6.50959s/100 iters), loss = 2.35701
I1211 10:51:26.703827 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1211 10:51:26.703827 15296 solver.cpp:237]     Train net output #1: loss = 2.35701 (* 1 = 2.35701 loss)
I1211 10:51:26.703827 15296 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1211 10:51:32.954828 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:51:33.214828 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4000.caffemodel
I1211 10:51:33.230829 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4000.solverstate
I1211 10:51:33.235829 15296 solver.cpp:330] Iteration 4000, Testing net (#0)
I1211 10:51:33.235829 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:51:34.810827  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:51:34.871840 15296 solver.cpp:397]     Test net output #0: accuracy = 0.237
I1211 10:51:34.871840 15296 solver.cpp:397]     Test net output #1: loss = 3.26552 (* 1 = 3.26552 loss)
I1211 10:51:34.934330 15296 solver.cpp:218] Iteration 4000 (12.1505 iter/s, 8.23015s/100 iters), loss = 2.38245
I1211 10:51:34.934829 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:51:34.934829 15296 solver.cpp:237]     Train net output #1: loss = 2.38245 (* 1 = 2.38245 loss)
I1211 10:51:34.934829 15296 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1211 10:51:41.418669 15296 solver.cpp:218] Iteration 4100 (15.4239 iter/s, 6.48346s/100 iters), loss = 2.05679
I1211 10:51:41.418669 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 10:51:41.418669 15296 solver.cpp:237]     Train net output #1: loss = 2.05679 (* 1 = 2.05679 loss)
I1211 10:51:41.418669 15296 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1211 10:51:47.975466 15296 solver.cpp:218] Iteration 4200 (15.2522 iter/s, 6.55644s/100 iters), loss = 1.9416
I1211 10:51:47.975466 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 10:51:47.975466 15296 solver.cpp:237]     Train net output #1: loss = 1.9416 (* 1 = 1.9416 loss)
I1211 10:51:47.975466 15296 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1211 10:51:54.551856 15296 solver.cpp:218] Iteration 4300 (15.2067 iter/s, 6.57605s/100 iters), loss = 2.25979
I1211 10:51:54.552356 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:51:54.552356 15296 solver.cpp:237]     Train net output #1: loss = 2.25979 (* 1 = 2.25979 loss)
I1211 10:51:54.552356 15296 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1211 10:52:01.118548 15296 solver.cpp:218] Iteration 4400 (15.2306 iter/s, 6.56575s/100 iters), loss = 2.30877
I1211 10:52:01.118548 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 10:52:01.118548 15296 solver.cpp:237]     Train net output #1: loss = 2.30877 (* 1 = 2.30877 loss)
I1211 10:52:01.118548 15296 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1211 10:52:07.308493 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:52:07.562994 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4500.caffemodel
I1211 10:52:07.578994 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4500.solverstate
I1211 10:52:07.583981 15296 solver.cpp:330] Iteration 4500, Testing net (#0)
I1211 10:52:07.583981 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:52:09.130038  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:52:09.191535 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2506
I1211 10:52:09.191535 15296 solver.cpp:397]     Test net output #1: loss = 3.28707 (* 1 = 3.28707 loss)
I1211 10:52:09.253044 15296 solver.cpp:218] Iteration 4500 (12.2942 iter/s, 8.13392s/100 iters), loss = 2.24523
I1211 10:52:09.253044 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1211 10:52:09.253044 15296 solver.cpp:237]     Train net output #1: loss = 2.24523 (* 1 = 2.24523 loss)
I1211 10:52:09.253044 15296 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1211 10:52:15.731667 15296 solver.cpp:218] Iteration 4600 (15.436 iter/s, 6.47835s/100 iters), loss = 2.08655
I1211 10:52:15.731667 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1211 10:52:15.731667 15296 solver.cpp:237]     Train net output #1: loss = 2.08655 (* 1 = 2.08655 loss)
I1211 10:52:15.731667 15296 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1211 10:52:22.219650 15296 solver.cpp:218] Iteration 4700 (15.414 iter/s, 6.4876s/100 iters), loss = 1.89154
I1211 10:52:22.219650 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 10:52:22.219650 15296 solver.cpp:237]     Train net output #1: loss = 1.89154 (* 1 = 1.89154 loss)
I1211 10:52:22.219650 15296 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1211 10:52:28.695807 15296 solver.cpp:218] Iteration 4800 (15.4426 iter/s, 6.47558s/100 iters), loss = 2.17808
I1211 10:52:28.695807 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 10:52:28.695807 15296 solver.cpp:237]     Train net output #1: loss = 2.17808 (* 1 = 2.17808 loss)
I1211 10:52:28.695807 15296 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1211 10:52:35.178745 15296 solver.cpp:218] Iteration 4900 (15.4267 iter/s, 6.48228s/100 iters), loss = 2.43183
I1211 10:52:35.178745 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 10:52:35.178745 15296 solver.cpp:237]     Train net output #1: loss = 2.43183 (* 1 = 2.43183 loss)
I1211 10:52:35.178745 15296 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1211 10:52:41.339704 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:52:41.595705 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5000.caffemodel
I1211 10:52:41.611204 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5000.solverstate
I1211 10:52:41.616205 15296 solver.cpp:330] Iteration 5000, Testing net (#0)
I1211 10:52:41.616205 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:52:43.166204  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:52:43.227705 15296 solver.cpp:397]     Test net output #0: accuracy = 0.0925
I1211 10:52:43.227705 15296 solver.cpp:397]     Test net output #1: loss = 5.73137 (* 1 = 5.73137 loss)
I1211 10:52:43.288703 15296 solver.cpp:218] Iteration 5000 (12.331 iter/s, 8.10962s/100 iters), loss = 2.2126
I1211 10:52:43.288703 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 10:52:43.288703 15296 solver.cpp:237]     Train net output #1: loss = 2.2126 (* 1 = 2.2126 loss)
I1211 10:52:43.288703 15296 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1211 10:52:49.747161 15296 solver.cpp:218] Iteration 5100 (15.485 iter/s, 6.45786s/100 iters), loss = 2.06357
I1211 10:52:49.747161 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1211 10:52:49.747161 15296 solver.cpp:237]     Train net output #1: loss = 2.06357 (* 1 = 2.06357 loss)
I1211 10:52:49.747161 15296 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1211 10:52:56.214902 15296 solver.cpp:218] Iteration 5200 (15.4619 iter/s, 6.4675s/100 iters), loss = 1.6615
I1211 10:52:56.214902 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 10:52:56.214902 15296 solver.cpp:237]     Train net output #1: loss = 1.6615 (* 1 = 1.6615 loss)
I1211 10:52:56.214902 15296 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1211 10:53:02.677700 15296 solver.cpp:218] Iteration 5300 (15.4748 iter/s, 6.46211s/100 iters), loss = 2.14714
I1211 10:53:02.677700 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 10:53:02.677700 15296 solver.cpp:237]     Train net output #1: loss = 2.14714 (* 1 = 2.14714 loss)
I1211 10:53:02.677700 15296 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1211 10:53:09.171181 15296 solver.cpp:218] Iteration 5400 (15.4007 iter/s, 6.49322s/100 iters), loss = 2.27836
I1211 10:53:09.171181 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 10:53:09.171181 15296 solver.cpp:237]     Train net output #1: loss = 2.27836 (* 1 = 2.27836 loss)
I1211 10:53:09.171181 15296 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1211 10:53:15.293751 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:53:15.546753 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5500.caffemodel
I1211 10:53:15.562259 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5500.solverstate
I1211 10:53:15.567260 15296 solver.cpp:330] Iteration 5500, Testing net (#0)
I1211 10:53:15.567260 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:53:17.098865  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:53:17.159366 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2819
I1211 10:53:17.159366 15296 solver.cpp:397]     Test net output #1: loss = 3.02177 (* 1 = 3.02177 loss)
I1211 10:53:17.219867 15296 solver.cpp:218] Iteration 5500 (12.4248 iter/s, 8.0484s/100 iters), loss = 2.09496
I1211 10:53:17.219867 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 10:53:17.219867 15296 solver.cpp:237]     Train net output #1: loss = 2.09496 (* 1 = 2.09496 loss)
I1211 10:53:17.219867 15296 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1211 10:53:23.627424 15296 solver.cpp:218] Iteration 5600 (15.607 iter/s, 6.40738s/100 iters), loss = 1.99597
I1211 10:53:23.628423 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 10:53:23.628423 15296 solver.cpp:237]     Train net output #1: loss = 1.99597 (* 1 = 1.99597 loss)
I1211 10:53:23.628423 15296 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1211 10:53:29.973917 15296 solver.cpp:218] Iteration 5700 (15.7607 iter/s, 6.34489s/100 iters), loss = 1.77028
I1211 10:53:29.973917 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 10:53:29.973917 15296 solver.cpp:237]     Train net output #1: loss = 1.77028 (* 1 = 1.77028 loss)
I1211 10:53:29.973917 15296 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1211 10:53:36.336261 15296 solver.cpp:218] Iteration 5800 (15.7183 iter/s, 6.362s/100 iters), loss = 2.00708
I1211 10:53:36.336261 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 10:53:36.336261 15296 solver.cpp:237]     Train net output #1: loss = 2.00708 (* 1 = 2.00708 loss)
I1211 10:53:36.336261 15296 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1211 10:53:42.808853 15296 solver.cpp:218] Iteration 5900 (15.4506 iter/s, 6.47226s/100 iters), loss = 2.12087
I1211 10:53:42.808853 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 10:53:42.808853 15296 solver.cpp:237]     Train net output #1: loss = 2.12087 (* 1 = 2.12087 loss)
I1211 10:53:42.808853 15296 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1211 10:53:48.984843 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:53:49.241364 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6000.caffemodel
I1211 10:53:49.259363 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6000.solverstate
I1211 10:53:49.264364 15296 solver.cpp:330] Iteration 6000, Testing net (#0)
I1211 10:53:49.264364 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:53:50.820540  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:53:50.881526 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2379
I1211 10:53:50.882529 15296 solver.cpp:397]     Test net output #1: loss = 3.36035 (* 1 = 3.36035 loss)
I1211 10:53:50.944537 15296 solver.cpp:218] Iteration 6000 (12.292 iter/s, 8.13535s/100 iters), loss = 1.99579
I1211 10:53:50.944537 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 10:53:50.944537 15296 solver.cpp:237]     Train net output #1: loss = 1.99579 (* 1 = 1.99579 loss)
I1211 10:53:50.944537 15296 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1211 10:53:57.439748 15296 solver.cpp:218] Iteration 6100 (15.398 iter/s, 6.49436s/100 iters), loss = 1.95169
I1211 10:53:57.439748 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:53:57.439748 15296 solver.cpp:237]     Train net output #1: loss = 1.95169 (* 1 = 1.95169 loss)
I1211 10:53:57.439748 15296 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1211 10:54:03.882217 15296 solver.cpp:218] Iteration 6200 (15.5226 iter/s, 6.44221s/100 iters), loss = 1.65367
I1211 10:54:03.882217 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 10:54:03.882217 15296 solver.cpp:237]     Train net output #1: loss = 1.65367 (* 1 = 1.65367 loss)
I1211 10:54:03.882217 15296 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1211 10:54:10.264739 15296 solver.cpp:218] Iteration 6300 (15.668 iter/s, 6.38242s/100 iters), loss = 2.23242
I1211 10:54:10.264739 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 10:54:10.264739 15296 solver.cpp:237]     Train net output #1: loss = 2.23242 (* 1 = 2.23242 loss)
I1211 10:54:10.264739 15296 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1211 10:54:16.616207 15296 solver.cpp:218] Iteration 6400 (15.7459 iter/s, 6.35085s/100 iters), loss = 2.10259
I1211 10:54:16.616708 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 10:54:16.616708 15296 solver.cpp:237]     Train net output #1: loss = 2.10259 (* 1 = 2.10259 loss)
I1211 10:54:16.616708 15296 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1211 10:54:22.694654 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:54:22.946676 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6500.caffemodel
I1211 10:54:22.961676 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6500.solverstate
I1211 10:54:22.966677 15296 solver.cpp:330] Iteration 6500, Testing net (#0)
I1211 10:54:22.966677 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:54:24.515709  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:54:24.576211 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2662
I1211 10:54:24.577213 15296 solver.cpp:397]     Test net output #1: loss = 3.2165 (* 1 = 3.2165 loss)
I1211 10:54:24.639215 15296 solver.cpp:218] Iteration 6500 (12.4654 iter/s, 8.02222s/100 iters), loss = 2.17037
I1211 10:54:24.639215 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 10:54:24.639215 15296 solver.cpp:237]     Train net output #1: loss = 2.17037 (* 1 = 2.17037 loss)
I1211 10:54:24.639215 15296 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1211 10:54:31.121702 15296 solver.cpp:218] Iteration 6600 (15.4267 iter/s, 6.48228s/100 iters), loss = 1.8712
I1211 10:54:31.121702 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:54:31.122202 15296 solver.cpp:237]     Train net output #1: loss = 1.8712 (* 1 = 1.8712 loss)
I1211 10:54:31.122202 15296 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1211 10:54:37.589270 15296 solver.cpp:218] Iteration 6700 (15.4633 iter/s, 6.46693s/100 iters), loss = 1.77932
I1211 10:54:37.589270 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 10:54:37.589270 15296 solver.cpp:237]     Train net output #1: loss = 1.77932 (* 1 = 1.77932 loss)
I1211 10:54:37.589270 15296 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1211 10:54:44.078763 15296 solver.cpp:218] Iteration 6800 (15.4102 iter/s, 6.48919s/100 iters), loss = 2.0416
I1211 10:54:44.078763 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 10:54:44.078763 15296 solver.cpp:237]     Train net output #1: loss = 2.0416 (* 1 = 2.0416 loss)
I1211 10:54:44.078763 15296 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1211 10:54:50.535735 15296 solver.cpp:218] Iteration 6900 (15.4884 iter/s, 6.45643s/100 iters), loss = 2.10573
I1211 10:54:50.535735 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 10:54:50.535735 15296 solver.cpp:237]     Train net output #1: loss = 2.10573 (* 1 = 2.10573 loss)
I1211 10:54:50.535735 15296 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1211 10:54:56.607698 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:54:56.857702 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7000.caffemodel
I1211 10:54:56.872702 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7000.solverstate
I1211 10:54:56.877702 15296 solver.cpp:330] Iteration 7000, Testing net (#0)
I1211 10:54:56.877702 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:54:58.400805  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:54:58.460813 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3983
I1211 10:54:58.460813 15296 solver.cpp:397]     Test net output #1: loss = 2.31784 (* 1 = 2.31784 loss)
I1211 10:54:58.521311 15296 solver.cpp:218] Iteration 7000 (12.5234 iter/s, 7.98504s/100 iters), loss = 2.01471
I1211 10:54:58.521311 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:54:58.521311 15296 solver.cpp:237]     Train net output #1: loss = 2.01471 (* 1 = 2.01471 loss)
I1211 10:54:58.521311 15296 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1211 10:55:04.865311 15296 solver.cpp:218] Iteration 7100 (15.7643 iter/s, 6.34345s/100 iters), loss = 1.81755
I1211 10:55:04.865311 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:55:04.865311 15296 solver.cpp:237]     Train net output #1: loss = 1.81755 (* 1 = 1.81755 loss)
I1211 10:55:04.865311 15296 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1211 10:55:11.203780 15296 solver.cpp:218] Iteration 7200 (15.7763 iter/s, 6.33864s/100 iters), loss = 1.65768
I1211 10:55:11.203780 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 10:55:11.203780 15296 solver.cpp:237]     Train net output #1: loss = 1.65768 (* 1 = 1.65768 loss)
I1211 10:55:11.203780 15296 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1211 10:55:17.569304 15296 solver.cpp:218] Iteration 7300 (15.7113 iter/s, 6.36484s/100 iters), loss = 2.02142
I1211 10:55:17.569304 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 10:55:17.569304 15296 solver.cpp:237]     Train net output #1: loss = 2.02142 (* 1 = 2.02142 loss)
I1211 10:55:17.569304 15296 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1211 10:55:23.940789 15296 solver.cpp:218] Iteration 7400 (15.6958 iter/s, 6.37112s/100 iters), loss = 2.09734
I1211 10:55:23.940789 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:55:23.940789 15296 solver.cpp:237]     Train net output #1: loss = 2.09734 (* 1 = 2.09734 loss)
I1211 10:55:23.940789 15296 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1211 10:55:29.991215 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:55:30.242228 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7500.caffemodel
I1211 10:55:30.263238 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7500.solverstate
I1211 10:55:30.268240 15296 solver.cpp:330] Iteration 7500, Testing net (#0)
I1211 10:55:30.268240 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:55:31.801339  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:55:31.861346 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3716
I1211 10:55:31.861346 15296 solver.cpp:397]     Test net output #1: loss = 2.42265 (* 1 = 2.42265 loss)
I1211 10:55:31.923346 15296 solver.cpp:218] Iteration 7500 (12.5291 iter/s, 7.98144s/100 iters), loss = 1.98261
I1211 10:55:31.923346 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 10:55:31.923346 15296 solver.cpp:237]     Train net output #1: loss = 1.98261 (* 1 = 1.98261 loss)
I1211 10:55:31.923346 15296 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1211 10:55:38.319844 15296 solver.cpp:218] Iteration 7600 (15.6328 iter/s, 6.39683s/100 iters), loss = 1.91509
I1211 10:55:38.319844 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 10:55:38.319844 15296 solver.cpp:237]     Train net output #1: loss = 1.91509 (* 1 = 1.91509 loss)
I1211 10:55:38.319844 15296 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1211 10:55:44.758402 15296 solver.cpp:218] Iteration 7700 (15.5335 iter/s, 6.43771s/100 iters), loss = 1.63331
I1211 10:55:44.758402 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 10:55:44.758402 15296 solver.cpp:237]     Train net output #1: loss = 1.63331 (* 1 = 1.63331 loss)
I1211 10:55:44.758402 15296 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1211 10:55:51.285403 15296 solver.cpp:218] Iteration 7800 (15.322 iter/s, 6.52656s/100 iters), loss = 2.01624
I1211 10:55:51.285903 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:55:51.285903 15296 solver.cpp:237]     Train net output #1: loss = 2.01624 (* 1 = 2.01624 loss)
I1211 10:55:51.285903 15296 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1211 10:55:57.784730 15296 solver.cpp:218] Iteration 7900 (15.388 iter/s, 6.49856s/100 iters), loss = 2.09405
I1211 10:55:57.784730 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 10:55:57.784730 15296 solver.cpp:237]     Train net output #1: loss = 2.09405 (* 1 = 2.09405 loss)
I1211 10:55:57.784730 15296 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1211 10:56:03.980476 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:56:04.237478 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8000.caffemodel
I1211 10:56:04.253476 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8000.solverstate
I1211 10:56:04.258476 15296 solver.cpp:330] Iteration 8000, Testing net (#0)
I1211 10:56:04.258476 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:56:05.807487  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:56:05.868476 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3871
I1211 10:56:05.868476 15296 solver.cpp:397]     Test net output #1: loss = 2.36961 (* 1 = 2.36961 loss)
I1211 10:56:05.931475 15296 solver.cpp:218] Iteration 8000 (12.2761 iter/s, 8.14592s/100 iters), loss = 2.07567
I1211 10:56:05.931475 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 10:56:05.931475 15296 solver.cpp:237]     Train net output #1: loss = 2.07567 (* 1 = 2.07567 loss)
I1211 10:56:05.931475 15296 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1211 10:56:12.400140 15296 solver.cpp:218] Iteration 8100 (15.4595 iter/s, 6.46851s/100 iters), loss = 1.79871
I1211 10:56:12.400140 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 10:56:12.400640 15296 solver.cpp:237]     Train net output #1: loss = 1.79871 (* 1 = 1.79871 loss)
I1211 10:56:12.400640 15296 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1211 10:56:18.745638 15296 solver.cpp:218] Iteration 8200 (15.7612 iter/s, 6.3447s/100 iters), loss = 1.6029
I1211 10:56:18.745638 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 10:56:18.745638 15296 solver.cpp:237]     Train net output #1: loss = 1.6029 (* 1 = 1.6029 loss)
I1211 10:56:18.745638 15296 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1211 10:56:25.078974 15296 solver.cpp:218] Iteration 8300 (15.79 iter/s, 6.33313s/100 iters), loss = 2.18109
I1211 10:56:25.078974 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:56:25.078974 15296 solver.cpp:237]     Train net output #1: loss = 2.18109 (* 1 = 2.18109 loss)
I1211 10:56:25.078974 15296 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1211 10:56:31.400887 15296 solver.cpp:218] Iteration 8400 (15.8176 iter/s, 6.32207s/100 iters), loss = 2.03116
I1211 10:56:31.400887 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 10:56:31.400887 15296 solver.cpp:237]     Train net output #1: loss = 2.03116 (* 1 = 2.03116 loss)
I1211 10:56:31.400887 15296 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1211 10:56:37.426204 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:56:37.674757 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8500.caffemodel
I1211 10:56:37.689750 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8500.solverstate
I1211 10:56:37.694751 15296 solver.cpp:330] Iteration 8500, Testing net (#0)
I1211 10:56:37.694751 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:56:39.212877  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:56:39.272886 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3202
I1211 10:56:39.272886 15296 solver.cpp:397]     Test net output #1: loss = 2.77934 (* 1 = 2.77934 loss)
I1211 10:56:39.333885 15296 solver.cpp:218] Iteration 8500 (12.6068 iter/s, 7.93224s/100 iters), loss = 2.04347
I1211 10:56:39.333885 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 10:56:39.333885 15296 solver.cpp:237]     Train net output #1: loss = 2.04347 (* 1 = 2.04347 loss)
I1211 10:56:39.333885 15296 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1211 10:56:45.718372 15296 solver.cpp:218] Iteration 8600 (15.6645 iter/s, 6.38386s/100 iters), loss = 1.93176
I1211 10:56:45.718372 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:56:45.718372 15296 solver.cpp:237]     Train net output #1: loss = 1.93176 (* 1 = 1.93176 loss)
I1211 10:56:45.718372 15296 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1211 10:56:52.265872 15296 solver.cpp:218] Iteration 8700 (15.2749 iter/s, 6.54668s/100 iters), loss = 1.54731
I1211 10:56:52.265872 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 10:56:52.265872 15296 solver.cpp:237]     Train net output #1: loss = 1.54731 (* 1 = 1.54731 loss)
I1211 10:56:52.265872 15296 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1211 10:56:58.789373 15296 solver.cpp:218] Iteration 8800 (15.3301 iter/s, 6.52311s/100 iters), loss = 2.11257
I1211 10:56:58.789373 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:56:58.789373 15296 solver.cpp:237]     Train net output #1: loss = 2.11257 (* 1 = 2.11257 loss)
I1211 10:56:58.789373 15296 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1211 10:57:05.307373 15296 solver.cpp:218] Iteration 8900 (15.3436 iter/s, 6.51735s/100 iters), loss = 2.06508
I1211 10:57:05.307373 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:57:05.307373 15296 solver.cpp:237]     Train net output #1: loss = 2.06508 (* 1 = 2.06508 loss)
I1211 10:57:05.307373 15296 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1211 10:57:11.510373 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:57:11.766372 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9000.caffemodel
I1211 10:57:11.783373 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9000.solverstate
I1211 10:57:11.787873 15296 solver.cpp:330] Iteration 9000, Testing net (#0)
I1211 10:57:11.788373 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:57:13.342874  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:57:13.403873 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2844
I1211 10:57:13.403873 15296 solver.cpp:397]     Test net output #1: loss = 3.12549 (* 1 = 3.12549 loss)
I1211 10:57:13.466872 15296 solver.cpp:218] Iteration 9000 (12.2564 iter/s, 8.15901s/100 iters), loss = 2.09947
I1211 10:57:13.466872 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:57:13.466872 15296 solver.cpp:237]     Train net output #1: loss = 2.09947 (* 1 = 2.09947 loss)
I1211 10:57:13.466872 15296 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1211 10:57:19.988518 15296 solver.cpp:218] Iteration 9100 (15.3353 iter/s, 6.5209s/100 iters), loss = 1.78006
I1211 10:57:19.988518 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 10:57:19.988518 15296 solver.cpp:237]     Train net output #1: loss = 1.78006 (* 1 = 1.78006 loss)
I1211 10:57:19.988518 15296 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1211 10:57:26.507979 15296 solver.cpp:218] Iteration 9200 (15.3389 iter/s, 6.51935s/100 iters), loss = 1.56578
I1211 10:57:26.507979 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 10:57:26.507979 15296 solver.cpp:237]     Train net output #1: loss = 1.56578 (* 1 = 1.56578 loss)
I1211 10:57:26.507979 15296 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1211 10:57:33.028187 15296 solver.cpp:218] Iteration 9300 (15.3381 iter/s, 6.51971s/100 iters), loss = 1.97994
I1211 10:57:33.028187 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 10:57:33.028187 15296 solver.cpp:237]     Train net output #1: loss = 1.97994 (* 1 = 1.97994 loss)
I1211 10:57:33.028187 15296 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1211 10:57:39.534510 15296 solver.cpp:218] Iteration 9400 (15.3712 iter/s, 6.50569s/100 iters), loss = 1.98218
I1211 10:57:39.534510 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:57:39.534510 15296 solver.cpp:237]     Train net output #1: loss = 1.98218 (* 1 = 1.98218 loss)
I1211 10:57:39.534510 15296 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1211 10:57:45.739033 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:57:45.992511 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9500.caffemodel
I1211 10:57:46.008008 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9500.solverstate
I1211 10:57:46.013509 15296 solver.cpp:330] Iteration 9500, Testing net (#0)
I1211 10:57:46.013509 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:57:47.563560  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:57:47.625558 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3493
I1211 10:57:47.625558 15296 solver.cpp:397]     Test net output #1: loss = 2.59766 (* 1 = 2.59766 loss)
I1211 10:57:47.688058 15296 solver.cpp:218] Iteration 9500 (12.2653 iter/s, 8.15307s/100 iters), loss = 2.03512
I1211 10:57:47.688058 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 10:57:47.688058 15296 solver.cpp:237]     Train net output #1: loss = 2.03512 (* 1 = 2.03512 loss)
I1211 10:57:47.688058 15296 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1211 10:57:54.181226 15296 solver.cpp:218] Iteration 9600 (15.4023 iter/s, 6.49255s/100 iters), loss = 1.83489
I1211 10:57:54.181226 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:57:54.181226 15296 solver.cpp:237]     Train net output #1: loss = 1.83489 (* 1 = 1.83489 loss)
I1211 10:57:54.181226 15296 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1211 10:58:00.682840 15296 solver.cpp:218] Iteration 9700 (15.3814 iter/s, 6.50135s/100 iters), loss = 1.66092
I1211 10:58:00.683336 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 10:58:00.683336 15296 solver.cpp:237]     Train net output #1: loss = 1.66092 (* 1 = 1.66092 loss)
I1211 10:58:00.683336 15296 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1211 10:58:07.188396 15296 solver.cpp:218] Iteration 9800 (15.3738 iter/s, 6.50458s/100 iters), loss = 2.18756
I1211 10:58:07.188396 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 10:58:07.188396 15296 solver.cpp:237]     Train net output #1: loss = 2.18756 (* 1 = 2.18756 loss)
I1211 10:58:07.188396 15296 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1211 10:58:13.724469 15296 solver.cpp:218] Iteration 9900 (15.3006 iter/s, 6.53568s/100 iters), loss = 2.0486
I1211 10:58:13.724469 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 10:58:13.724469 15296 solver.cpp:237]     Train net output #1: loss = 2.0486 (* 1 = 2.0486 loss)
I1211 10:58:13.724469 15296 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1211 10:58:19.916970 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:58:20.174470 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10000.caffemodel
I1211 10:58:20.190470 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10000.solverstate
I1211 10:58:20.195472 15296 solver.cpp:330] Iteration 10000, Testing net (#0)
I1211 10:58:20.195472 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:58:21.751969  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:58:21.812978 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3974
I1211 10:58:21.812978 15296 solver.cpp:397]     Test net output #1: loss = 2.23021 (* 1 = 2.23021 loss)
I1211 10:58:21.875469 15296 solver.cpp:218] Iteration 10000 (12.269 iter/s, 8.1506s/100 iters), loss = 1.91715
I1211 10:58:21.875469 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 10:58:21.875469 15296 solver.cpp:237]     Train net output #1: loss = 1.91715 (* 1 = 1.91715 loss)
I1211 10:58:21.875469 15296 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1211 10:58:28.390552 15296 solver.cpp:218] Iteration 10100 (15.3507 iter/s, 6.51438s/100 iters), loss = 1.87374
I1211 10:58:28.390552 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:58:28.390552 15296 solver.cpp:237]     Train net output #1: loss = 1.87374 (* 1 = 1.87374 loss)
I1211 10:58:28.390552 15296 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1211 10:58:34.917553 15296 solver.cpp:218] Iteration 10200 (15.3214 iter/s, 6.52681s/100 iters), loss = 1.52844
I1211 10:58:34.917553 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 10:58:34.918054 15296 solver.cpp:237]     Train net output #1: loss = 1.52844 (* 1 = 1.52844 loss)
I1211 10:58:34.918054 15296 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1211 10:58:41.439054 15296 solver.cpp:218] Iteration 10300 (15.3356 iter/s, 6.52078s/100 iters), loss = 1.98421
I1211 10:58:41.439054 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 10:58:41.439054 15296 solver.cpp:237]     Train net output #1: loss = 1.98421 (* 1 = 1.98421 loss)
I1211 10:58:41.439054 15296 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1211 10:58:47.957054 15296 solver.cpp:218] Iteration 10400 (15.3443 iter/s, 6.51707s/100 iters), loss = 2.00591
I1211 10:58:47.957054 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 10:58:47.957054 15296 solver.cpp:237]     Train net output #1: loss = 2.00591 (* 1 = 2.00591 loss)
I1211 10:58:47.957054 15296 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1211 10:58:54.174556 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:58:54.438052 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10500.caffemodel
I1211 10:58:54.454552 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10500.solverstate
I1211 10:58:54.459555 15296 solver.cpp:330] Iteration 10500, Testing net (#0)
I1211 10:58:54.459555 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:58:56.021055  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:58:56.081557 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2911
I1211 10:58:56.081557 15296 solver.cpp:397]     Test net output #1: loss = 2.98924 (* 1 = 2.98924 loss)
I1211 10:58:56.145052 15296 solver.cpp:218] Iteration 10500 (12.2132 iter/s, 8.18785s/100 iters), loss = 2.10708
I1211 10:58:56.145052 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 10:58:56.145553 15296 solver.cpp:237]     Train net output #1: loss = 2.10708 (* 1 = 2.10708 loss)
I1211 10:58:56.145553 15296 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1211 10:59:02.670439 15296 solver.cpp:218] Iteration 10600 (15.3264 iter/s, 6.5247s/100 iters), loss = 1.86534
I1211 10:59:02.670439 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:59:02.670439 15296 solver.cpp:237]     Train net output #1: loss = 1.86534 (* 1 = 1.86534 loss)
I1211 10:59:02.670439 15296 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1211 10:59:09.189627 15296 solver.cpp:218] Iteration 10700 (15.3406 iter/s, 6.51865s/100 iters), loss = 1.48322
I1211 10:59:09.189627 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 10:59:09.189627 15296 solver.cpp:237]     Train net output #1: loss = 1.48322 (* 1 = 1.48322 loss)
I1211 10:59:09.189627 15296 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1211 10:59:15.710626 15296 solver.cpp:218] Iteration 10800 (15.3368 iter/s, 6.52027s/100 iters), loss = 1.91043
I1211 10:59:15.710626 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 10:59:15.710626 15296 solver.cpp:237]     Train net output #1: loss = 1.91043 (* 1 = 1.91043 loss)
I1211 10:59:15.710626 15296 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1211 10:59:22.233798 15296 solver.cpp:218] Iteration 10900 (15.3306 iter/s, 6.52289s/100 iters), loss = 1.99699
I1211 10:59:22.233798 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:59:22.233798 15296 solver.cpp:237]     Train net output #1: loss = 1.99699 (* 1 = 1.99699 loss)
I1211 10:59:22.233798 15296 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1211 10:59:28.431769 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:59:28.689270 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11000.caffemodel
I1211 10:59:28.705269 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11000.solverstate
I1211 10:59:28.710769 15296 solver.cpp:330] Iteration 11000, Testing net (#0)
I1211 10:59:28.710769 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 10:59:30.264269  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 10:59:30.325769 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2555
I1211 10:59:30.325769 15296 solver.cpp:397]     Test net output #1: loss = 3.13723 (* 1 = 3.13723 loss)
I1211 10:59:30.388768 15296 solver.cpp:218] Iteration 11000 (12.2632 iter/s, 8.15447s/100 iters), loss = 2.05866
I1211 10:59:30.388768 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 10:59:30.388768 15296 solver.cpp:237]     Train net output #1: loss = 2.05866 (* 1 = 2.05866 loss)
I1211 10:59:30.388768 15296 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1211 10:59:36.904541 15296 solver.cpp:218] Iteration 11100 (15.3482 iter/s, 6.51544s/100 iters), loss = 1.72518
I1211 10:59:36.905042 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 10:59:36.905042 15296 solver.cpp:237]     Train net output #1: loss = 1.72518 (* 1 = 1.72518 loss)
I1211 10:59:36.905042 15296 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1211 10:59:43.405599 15296 solver.cpp:218] Iteration 11200 (15.3837 iter/s, 6.5004s/100 iters), loss = 1.49562
I1211 10:59:43.405599 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 10:59:43.406100 15296 solver.cpp:237]     Train net output #1: loss = 1.49562 (* 1 = 1.49562 loss)
I1211 10:59:43.406100 15296 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1211 10:59:49.906872 15296 solver.cpp:218] Iteration 11300 (15.3831 iter/s, 6.50064s/100 iters), loss = 2.07815
I1211 10:59:49.906872 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 10:59:49.906872 15296 solver.cpp:237]     Train net output #1: loss = 2.07815 (* 1 = 2.07815 loss)
I1211 10:59:49.906872 15296 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1211 10:59:56.445371 15296 solver.cpp:218] Iteration 11400 (15.2955 iter/s, 6.53787s/100 iters), loss = 1.91068
I1211 10:59:56.445371 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 10:59:56.445371 15296 solver.cpp:237]     Train net output #1: loss = 1.91068 (* 1 = 1.91068 loss)
I1211 10:59:56.445371 15296 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1211 11:00:02.691872 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:00:02.948871 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11500.caffemodel
I1211 11:00:02.964871 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11500.solverstate
I1211 11:00:02.970373 15296 solver.cpp:330] Iteration 11500, Testing net (#0)
I1211 11:00:02.970373 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:00:04.527873  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:00:04.589372 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3412
I1211 11:00:04.589372 15296 solver.cpp:397]     Test net output #1: loss = 2.62451 (* 1 = 2.62451 loss)
I1211 11:00:04.651371 15296 solver.cpp:218] Iteration 11500 (12.1868 iter/s, 8.20559s/100 iters), loss = 1.75321
I1211 11:00:04.651871 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:00:04.651871 15296 solver.cpp:237]     Train net output #1: loss = 1.75321 (* 1 = 1.75321 loss)
I1211 11:00:04.651871 15296 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1211 11:00:11.178871 15296 solver.cpp:218] Iteration 11600 (15.3212 iter/s, 6.5269s/100 iters), loss = 1.68885
I1211 11:00:11.178871 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:00:11.179373 15296 solver.cpp:237]     Train net output #1: loss = 1.68885 (* 1 = 1.68885 loss)
I1211 11:00:11.179373 15296 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1211 11:00:17.710067 15296 solver.cpp:218] Iteration 11700 (15.3125 iter/s, 6.53062s/100 iters), loss = 1.36844
I1211 11:00:17.710067 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:00:17.710067 15296 solver.cpp:237]     Train net output #1: loss = 1.36844 (* 1 = 1.36844 loss)
I1211 11:00:17.710067 15296 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1211 11:00:24.229244 15296 solver.cpp:218] Iteration 11800 (15.3414 iter/s, 6.51833s/100 iters), loss = 2.15803
I1211 11:00:24.229244 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:00:24.229244 15296 solver.cpp:237]     Train net output #1: loss = 2.15803 (* 1 = 2.15803 loss)
I1211 11:00:24.229244 15296 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1211 11:00:30.742358 15296 solver.cpp:218] Iteration 11900 (15.3549 iter/s, 6.5126s/100 iters), loss = 1.97992
I1211 11:00:30.742358 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:00:30.742358 15296 solver.cpp:237]     Train net output #1: loss = 1.97992 (* 1 = 1.97992 loss)
I1211 11:00:30.742358 15296 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1211 11:00:36.933859 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:00:37.191359 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12000.caffemodel
I1211 11:00:37.207361 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12000.solverstate
I1211 11:00:37.211859 15296 solver.cpp:330] Iteration 12000, Testing net (#0)
I1211 11:00:37.211859 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:00:38.767859  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:00:38.829360 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2469
I1211 11:00:38.829859 15296 solver.cpp:397]     Test net output #1: loss = 3.52974 (* 1 = 3.52974 loss)
I1211 11:00:38.891839 15296 solver.cpp:218] Iteration 12000 (12.2715 iter/s, 8.149s/100 iters), loss = 1.95594
I1211 11:00:38.891839 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:00:38.891839 15296 solver.cpp:237]     Train net output #1: loss = 1.95594 (* 1 = 1.95594 loss)
I1211 11:00:38.891839 15296 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1211 11:00:45.411505 15296 solver.cpp:218] Iteration 12100 (15.3393 iter/s, 6.51921s/100 iters), loss = 1.70351
I1211 11:00:45.411505 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:00:45.411505 15296 solver.cpp:237]     Train net output #1: loss = 1.70351 (* 1 = 1.70351 loss)
I1211 11:00:45.411505 15296 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1211 11:00:51.923784 15296 solver.cpp:218] Iteration 12200 (15.357 iter/s, 6.5117s/100 iters), loss = 1.51589
I1211 11:00:51.923784 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:00:51.923784 15296 solver.cpp:237]     Train net output #1: loss = 1.51589 (* 1 = 1.51589 loss)
I1211 11:00:51.923784 15296 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1211 11:00:58.439947 15296 solver.cpp:218] Iteration 12300 (15.3474 iter/s, 6.51578s/100 iters), loss = 1.94836
I1211 11:00:58.439947 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:00:58.439947 15296 solver.cpp:237]     Train net output #1: loss = 1.94836 (* 1 = 1.94836 loss)
I1211 11:00:58.439947 15296 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1211 11:01:04.945365 15296 solver.cpp:218] Iteration 12400 (15.3729 iter/s, 6.50494s/100 iters), loss = 2.08054
I1211 11:01:04.945365 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 11:01:04.945365 15296 solver.cpp:237]     Train net output #1: loss = 2.08054 (* 1 = 2.08054 loss)
I1211 11:01:04.945365 15296 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1211 11:01:11.142468 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:01:11.401968 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12500.caffemodel
I1211 11:01:11.417469 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12500.solverstate
I1211 11:01:11.422468 15296 solver.cpp:330] Iteration 12500, Testing net (#0)
I1211 11:01:11.422468 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:01:12.978468  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:01:13.039469 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3562
I1211 11:01:13.039968 15296 solver.cpp:397]     Test net output #1: loss = 2.54549 (* 1 = 2.54549 loss)
I1211 11:01:13.101969 15296 solver.cpp:218] Iteration 12500 (12.2605 iter/s, 8.15626s/100 iters), loss = 1.93851
I1211 11:01:13.101969 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:01:13.101969 15296 solver.cpp:237]     Train net output #1: loss = 1.93851 (* 1 = 1.93851 loss)
I1211 11:01:13.101969 15296 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1211 11:01:19.624970 15296 solver.cpp:218] Iteration 12600 (15.3314 iter/s, 6.52257s/100 iters), loss = 1.79792
I1211 11:01:19.624970 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:01:19.624970 15296 solver.cpp:237]     Train net output #1: loss = 1.79792 (* 1 = 1.79792 loss)
I1211 11:01:19.624970 15296 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1211 11:01:26.154979 15296 solver.cpp:218] Iteration 12700 (15.3157 iter/s, 6.52925s/100 iters), loss = 1.3143
I1211 11:01:26.154979 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:01:26.154979 15296 solver.cpp:237]     Train net output #1: loss = 1.3143 (* 1 = 1.3143 loss)
I1211 11:01:26.154979 15296 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1211 11:01:32.668979 15296 solver.cpp:218] Iteration 12800 (15.3522 iter/s, 6.51371s/100 iters), loss = 1.79141
I1211 11:01:32.668979 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:01:32.668979 15296 solver.cpp:237]     Train net output #1: loss = 1.79141 (* 1 = 1.79141 loss)
I1211 11:01:32.668979 15296 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1211 11:01:39.197479 15296 solver.cpp:218] Iteration 12900 (15.3187 iter/s, 6.52795s/100 iters), loss = 1.9242
I1211 11:01:39.197479 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 11:01:39.197479 15296 solver.cpp:237]     Train net output #1: loss = 1.9242 (* 1 = 1.9242 loss)
I1211 11:01:39.197479 15296 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1211 11:01:45.397979 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:01:45.653980 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13000.caffemodel
I1211 11:01:45.668980 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13000.solverstate
I1211 11:01:45.673981 15296 solver.cpp:330] Iteration 13000, Testing net (#0)
I1211 11:01:45.673981 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:01:47.230480  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:01:47.292480 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3914
I1211 11:01:47.292480 15296 solver.cpp:397]     Test net output #1: loss = 2.38667 (* 1 = 2.38667 loss)
I1211 11:01:47.355479 15296 solver.cpp:218] Iteration 13000 (12.2587 iter/s, 8.15748s/100 iters), loss = 1.985
I1211 11:01:47.355479 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:01:47.355479 15296 solver.cpp:237]     Train net output #1: loss = 1.985 (* 1 = 1.985 loss)
I1211 11:01:47.355479 15296 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1211 11:01:53.870481 15296 solver.cpp:218] Iteration 13100 (15.3505 iter/s, 6.51445s/100 iters), loss = 1.71784
I1211 11:01:53.870481 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 11:01:53.870481 15296 solver.cpp:237]     Train net output #1: loss = 1.71784 (* 1 = 1.71784 loss)
I1211 11:01:53.870481 15296 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1211 11:02:00.207979 15296 solver.cpp:218] Iteration 13200 (15.7797 iter/s, 6.33726s/100 iters), loss = 1.52305
I1211 11:02:00.207979 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:02:00.208480 15296 solver.cpp:237]     Train net output #1: loss = 1.52305 (* 1 = 1.52305 loss)
I1211 11:02:00.208480 15296 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1211 11:02:06.544980 15296 solver.cpp:218] Iteration 13300 (15.7821 iter/s, 6.33628s/100 iters), loss = 2.00711
I1211 11:02:06.544980 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 11:02:06.544980 15296 solver.cpp:237]     Train net output #1: loss = 2.00711 (* 1 = 2.00711 loss)
I1211 11:02:06.544980 15296 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1211 11:02:12.880481 15296 solver.cpp:218] Iteration 13400 (15.7855 iter/s, 6.33493s/100 iters), loss = 1.77624
I1211 11:02:12.880481 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:02:12.880481 15296 solver.cpp:237]     Train net output #1: loss = 1.77624 (* 1 = 1.77624 loss)
I1211 11:02:12.880481 15296 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1211 11:02:18.902426 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:02:19.153437 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13500.caffemodel
I1211 11:02:19.173943 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13500.solverstate
I1211 11:02:19.178447 15296 solver.cpp:330] Iteration 13500, Testing net (#0)
I1211 11:02:19.178447 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:02:20.694563  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:02:20.755563 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3265
I1211 11:02:20.755563 15296 solver.cpp:397]     Test net output #1: loss = 2.81014 (* 1 = 2.81014 loss)
I1211 11:02:20.815579 15296 solver.cpp:218] Iteration 13500 (12.6017 iter/s, 7.93547s/100 iters), loss = 2.02425
I1211 11:02:20.815579 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:02:20.815579 15296 solver.cpp:237]     Train net output #1: loss = 2.02425 (* 1 = 2.02425 loss)
I1211 11:02:20.815579 15296 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1211 11:02:27.148175 15296 solver.cpp:218] Iteration 13600 (15.7931 iter/s, 6.33187s/100 iters), loss = 1.67693
I1211 11:02:27.148175 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:02:27.148175 15296 solver.cpp:237]     Train net output #1: loss = 1.67693 (* 1 = 1.67693 loss)
I1211 11:02:27.148175 15296 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1211 11:02:33.481580 15296 solver.cpp:218] Iteration 13700 (15.7909 iter/s, 6.33278s/100 iters), loss = 1.42734
I1211 11:02:33.481580 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:02:33.481580 15296 solver.cpp:237]     Train net output #1: loss = 1.42734 (* 1 = 1.42734 loss)
I1211 11:02:33.481580 15296 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1211 11:02:39.815995 15296 solver.cpp:218] Iteration 13800 (15.7885 iter/s, 6.33373s/100 iters), loss = 1.92459
I1211 11:02:39.815995 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:02:39.815995 15296 solver.cpp:237]     Train net output #1: loss = 1.92459 (* 1 = 1.92459 loss)
I1211 11:02:39.815995 15296 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1211 11:02:46.146497 15296 solver.cpp:218] Iteration 13900 (15.7968 iter/s, 6.33038s/100 iters), loss = 1.95594
I1211 11:02:46.146497 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:02:46.146497 15296 solver.cpp:237]     Train net output #1: loss = 1.95594 (* 1 = 1.95594 loss)
I1211 11:02:46.146497 15296 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1211 11:02:52.172449 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:02:52.423964 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14000.caffemodel
I1211 11:02:52.438963 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14000.solverstate
I1211 11:02:52.443964 15296 solver.cpp:330] Iteration 14000, Testing net (#0)
I1211 11:02:52.443964 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:02:53.960110  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:02:54.020118 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2931
I1211 11:02:54.020118 15296 solver.cpp:397]     Test net output #1: loss = 3.19339 (* 1 = 3.19339 loss)
I1211 11:02:54.080122 15296 solver.cpp:218] Iteration 14000 (12.6053 iter/s, 7.93317s/100 iters), loss = 1.67441
I1211 11:02:54.080122 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:02:54.080122 15296 solver.cpp:237]     Train net output #1: loss = 1.67441 (* 1 = 1.67441 loss)
I1211 11:02:54.080122 15296 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1211 11:03:00.420598 15296 solver.cpp:218] Iteration 14100 (15.7734 iter/s, 6.33978s/100 iters), loss = 1.61057
I1211 11:03:00.420598 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:03:00.420598 15296 solver.cpp:237]     Train net output #1: loss = 1.61057 (* 1 = 1.61057 loss)
I1211 11:03:00.420598 15296 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1211 11:03:06.754307 15296 solver.cpp:218] Iteration 14200 (15.7889 iter/s, 6.33357s/100 iters), loss = 1.43316
I1211 11:03:06.754307 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:03:06.754307 15296 solver.cpp:237]     Train net output #1: loss = 1.43316 (* 1 = 1.43316 loss)
I1211 11:03:06.754307 15296 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1211 11:03:13.075585 15296 solver.cpp:218] Iteration 14300 (15.8218 iter/s, 6.32041s/100 iters), loss = 1.85286
I1211 11:03:13.075585 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 11:03:13.075585 15296 solver.cpp:237]     Train net output #1: loss = 1.85286 (* 1 = 1.85286 loss)
I1211 11:03:13.075585 15296 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1211 11:03:19.408051 15296 solver.cpp:218] Iteration 14400 (15.7907 iter/s, 6.33282s/100 iters), loss = 1.90627
I1211 11:03:19.408051 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:03:19.408051 15296 solver.cpp:237]     Train net output #1: loss = 1.90627 (* 1 = 1.90627 loss)
I1211 11:03:19.408051 15296 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1211 11:03:25.435717 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:03:25.685773 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14500.caffemodel
I1211 11:03:25.700780 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14500.solverstate
I1211 11:03:25.704776 15296 solver.cpp:330] Iteration 14500, Testing net (#0)
I1211 11:03:25.704776 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:03:27.221300  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:03:27.282337 15296 solver.cpp:397]     Test net output #0: accuracy = 0.33
I1211 11:03:27.282337 15296 solver.cpp:397]     Test net output #1: loss = 2.8219 (* 1 = 2.8219 loss)
I1211 11:03:27.342350 15296 solver.cpp:218] Iteration 14500 (12.6044 iter/s, 7.93373s/100 iters), loss = 1.78746
I1211 11:03:27.342350 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:03:27.342350 15296 solver.cpp:237]     Train net output #1: loss = 1.78746 (* 1 = 1.78746 loss)
I1211 11:03:27.342350 15296 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1211 11:03:33.664911 15296 solver.cpp:218] Iteration 14600 (15.8181 iter/s, 6.32188s/100 iters), loss = 1.71563
I1211 11:03:33.664911 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:03:33.664911 15296 solver.cpp:237]     Train net output #1: loss = 1.71563 (* 1 = 1.71563 loss)
I1211 11:03:33.664911 15296 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1211 11:03:39.986563 15296 solver.cpp:218] Iteration 14700 (15.8207 iter/s, 6.32082s/100 iters), loss = 1.44476
I1211 11:03:39.986563 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:03:39.986563 15296 solver.cpp:237]     Train net output #1: loss = 1.44476 (* 1 = 1.44476 loss)
I1211 11:03:39.986563 15296 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1211 11:03:46.313524 15296 solver.cpp:218] Iteration 14800 (15.8065 iter/s, 6.32651s/100 iters), loss = 1.95682
I1211 11:03:46.313524 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:03:46.313524 15296 solver.cpp:237]     Train net output #1: loss = 1.95682 (* 1 = 1.95682 loss)
I1211 11:03:46.313524 15296 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1211 11:03:52.638576 15296 solver.cpp:218] Iteration 14900 (15.8096 iter/s, 6.32528s/100 iters), loss = 1.89637
I1211 11:03:52.638576 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:03:52.638576 15296 solver.cpp:237]     Train net output #1: loss = 1.89637 (* 1 = 1.89637 loss)
I1211 11:03:52.638576 15296 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1211 11:03:58.656002 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:03:58.906117 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15000.caffemodel
I1211 11:03:58.921128 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15000.solverstate
I1211 11:03:58.926132 15296 solver.cpp:330] Iteration 15000, Testing net (#0)
I1211 11:03:58.926132 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:04:00.442908  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:04:00.502952 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3693
I1211 11:04:00.502952 15296 solver.cpp:397]     Test net output #1: loss = 2.41577 (* 1 = 2.41577 loss)
I1211 11:04:00.563938 15296 solver.cpp:218] Iteration 15000 (12.6187 iter/s, 7.92472s/100 iters), loss = 1.95706
I1211 11:04:00.563938 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:04:00.563938 15296 solver.cpp:237]     Train net output #1: loss = 1.95706 (* 1 = 1.95706 loss)
I1211 11:04:00.563938 15296 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1211 11:04:06.913764 15296 solver.cpp:218] Iteration 15100 (15.7487 iter/s, 6.34973s/100 iters), loss = 1.73036
I1211 11:04:06.914754 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:04:06.914754 15296 solver.cpp:237]     Train net output #1: loss = 1.73036 (* 1 = 1.73036 loss)
I1211 11:04:06.914754 15296 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1211 11:04:13.256208 15296 solver.cpp:218] Iteration 15200 (15.7685 iter/s, 6.34177s/100 iters), loss = 1.38004
I1211 11:04:13.256208 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:04:13.256208 15296 solver.cpp:237]     Train net output #1: loss = 1.38004 (* 1 = 1.38004 loss)
I1211 11:04:13.256208 15296 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1211 11:04:19.589813 15296 solver.cpp:218] Iteration 15300 (15.79 iter/s, 6.33312s/100 iters), loss = 1.85159
I1211 11:04:19.589813 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:04:19.589813 15296 solver.cpp:237]     Train net output #1: loss = 1.85159 (* 1 = 1.85159 loss)
I1211 11:04:19.589813 15296 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1211 11:04:25.926627 15296 solver.cpp:218] Iteration 15400 (15.7814 iter/s, 6.33657s/100 iters), loss = 1.75091
I1211 11:04:25.926627 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:04:25.926627 15296 solver.cpp:237]     Train net output #1: loss = 1.75091 (* 1 = 1.75091 loss)
I1211 11:04:25.926627 15296 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1211 11:04:31.954558 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:04:32.205143 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15500.caffemodel
I1211 11:04:32.220633 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15500.solverstate
I1211 11:04:32.224647 15296 solver.cpp:330] Iteration 15500, Testing net (#0)
I1211 11:04:32.224647 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:04:33.742252  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:04:33.802247 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3626
I1211 11:04:33.802247 15296 solver.cpp:397]     Test net output #1: loss = 2.53003 (* 1 = 2.53003 loss)
I1211 11:04:33.862777 15296 solver.cpp:218] Iteration 15500 (12.6023 iter/s, 7.93504s/100 iters), loss = 1.82794
I1211 11:04:33.862777 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:04:33.862777 15296 solver.cpp:237]     Train net output #1: loss = 1.82794 (* 1 = 1.82794 loss)
I1211 11:04:33.862777 15296 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1211 11:04:40.179425 15296 solver.cpp:218] Iteration 15600 (15.8319 iter/s, 6.31637s/100 iters), loss = 1.73042
I1211 11:04:40.179425 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:04:40.179425 15296 solver.cpp:237]     Train net output #1: loss = 1.73042 (* 1 = 1.73042 loss)
I1211 11:04:40.179425 15296 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1211 11:04:46.505667 15296 solver.cpp:218] Iteration 15700 (15.8074 iter/s, 6.32614s/100 iters), loss = 1.57436
I1211 11:04:46.505667 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:04:46.505667 15296 solver.cpp:237]     Train net output #1: loss = 1.57436 (* 1 = 1.57436 loss)
I1211 11:04:46.505667 15296 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1211 11:04:52.826581 15296 solver.cpp:218] Iteration 15800 (15.8234 iter/s, 6.31975s/100 iters), loss = 1.93839
I1211 11:04:52.826581 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:04:52.826581 15296 solver.cpp:237]     Train net output #1: loss = 1.93839 (* 1 = 1.93839 loss)
I1211 11:04:52.826581 15296 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1211 11:04:59.156250 15296 solver.cpp:218] Iteration 15900 (15.7982 iter/s, 6.32983s/100 iters), loss = 1.89531
I1211 11:04:59.156250 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:04:59.156250 15296 solver.cpp:237]     Train net output #1: loss = 1.89531 (* 1 = 1.89531 loss)
I1211 11:04:59.156250 15296 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1211 11:05:05.167801 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:05:05.416815 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16000.caffemodel
I1211 11:05:05.432818 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16000.solverstate
I1211 11:05:05.437319 15296 solver.cpp:330] Iteration 16000, Testing net (#0)
I1211 11:05:05.437319 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:05:06.950501  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:05:07.010500 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3963
I1211 11:05:07.010500 15296 solver.cpp:397]     Test net output #1: loss = 2.30972 (* 1 = 2.30972 loss)
I1211 11:05:07.070549 15296 solver.cpp:218] Iteration 16000 (12.6356 iter/s, 7.91413s/100 iters), loss = 1.7423
I1211 11:05:07.070549 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:05:07.070549 15296 solver.cpp:237]     Train net output #1: loss = 1.7423 (* 1 = 1.7423 loss)
I1211 11:05:07.070549 15296 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1211 11:05:13.404728 15296 solver.cpp:218] Iteration 16100 (15.7884 iter/s, 6.33376s/100 iters), loss = 1.69474
I1211 11:05:13.404728 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:05:13.405730 15296 solver.cpp:237]     Train net output #1: loss = 1.69474 (* 1 = 1.69474 loss)
I1211 11:05:13.405730 15296 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1211 11:05:19.745249 15296 solver.cpp:218] Iteration 16200 (15.7734 iter/s, 6.33979s/100 iters), loss = 1.41445
I1211 11:05:19.745249 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:05:19.745249 15296 solver.cpp:237]     Train net output #1: loss = 1.41445 (* 1 = 1.41445 loss)
I1211 11:05:19.745249 15296 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1211 11:05:26.085738 15296 solver.cpp:218] Iteration 16300 (15.772 iter/s, 6.34033s/100 iters), loss = 1.84312
I1211 11:05:26.085738 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:05:26.085738 15296 solver.cpp:237]     Train net output #1: loss = 1.84312 (* 1 = 1.84312 loss)
I1211 11:05:26.085738 15296 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1211 11:05:32.430119 15296 solver.cpp:218] Iteration 16400 (15.7643 iter/s, 6.34346s/100 iters), loss = 1.94879
I1211 11:05:32.430620 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:05:32.430620 15296 solver.cpp:237]     Train net output #1: loss = 1.94879 (* 1 = 1.94879 loss)
I1211 11:05:32.430620 15296 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1211 11:05:38.459547 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:05:38.708556 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16500.caffemodel
I1211 11:05:38.723556 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16500.solverstate
I1211 11:05:38.728561 15296 solver.cpp:330] Iteration 16500, Testing net (#0)
I1211 11:05:38.728561 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:05:40.247740  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:05:40.307740 15296 solver.cpp:397]     Test net output #0: accuracy = 0.323
I1211 11:05:40.307740 15296 solver.cpp:397]     Test net output #1: loss = 2.85489 (* 1 = 2.85489 loss)
I1211 11:05:40.368746 15296 solver.cpp:218] Iteration 16500 (12.598 iter/s, 7.93774s/100 iters), loss = 1.76752
I1211 11:05:40.368746 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:05:40.368746 15296 solver.cpp:237]     Train net output #1: loss = 1.76752 (* 1 = 1.76752 loss)
I1211 11:05:40.368746 15296 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1211 11:05:46.706305 15296 solver.cpp:218] Iteration 16600 (15.7795 iter/s, 6.33732s/100 iters), loss = 1.82111
I1211 11:05:46.706305 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 11:05:46.706305 15296 solver.cpp:237]     Train net output #1: loss = 1.82111 (* 1 = 1.82111 loss)
I1211 11:05:46.706305 15296 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1211 11:05:53.032630 15296 solver.cpp:218] Iteration 16700 (15.8083 iter/s, 6.32581s/100 iters), loss = 1.42927
I1211 11:05:53.032630 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:05:53.032630 15296 solver.cpp:237]     Train net output #1: loss = 1.42927 (* 1 = 1.42927 loss)
I1211 11:05:53.032630 15296 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1211 11:05:59.365195 15296 solver.cpp:218] Iteration 16800 (15.791 iter/s, 6.33273s/100 iters), loss = 1.9305
I1211 11:05:59.365195 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:05:59.365195 15296 solver.cpp:237]     Train net output #1: loss = 1.9305 (* 1 = 1.9305 loss)
I1211 11:05:59.365195 15296 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1211 11:06:05.707336 15296 solver.cpp:218] Iteration 16900 (15.7705 iter/s, 6.34094s/100 iters), loss = 1.89577
I1211 11:06:05.707336 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:06:05.707336 15296 solver.cpp:237]     Train net output #1: loss = 1.89577 (* 1 = 1.89577 loss)
I1211 11:06:05.707336 15296 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1211 11:06:11.742527 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:06:11.991611 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17000.caffemodel
I1211 11:06:12.007613 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17000.solverstate
I1211 11:06:12.011616 15296 solver.cpp:330] Iteration 17000, Testing net (#0)
I1211 11:06:12.011616 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:06:13.529116  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:06:13.588172 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3402
I1211 11:06:13.589172 15296 solver.cpp:397]     Test net output #1: loss = 2.67789 (* 1 = 2.67789 loss)
I1211 11:06:13.649685 15296 solver.cpp:218] Iteration 17000 (12.5911 iter/s, 7.9421s/100 iters), loss = 1.91678
I1211 11:06:13.649685 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:06:13.649685 15296 solver.cpp:237]     Train net output #1: loss = 1.91678 (* 1 = 1.91678 loss)
I1211 11:06:13.649685 15296 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1211 11:06:19.989439 15296 solver.cpp:218] Iteration 17100 (15.7731 iter/s, 6.33991s/100 iters), loss = 1.62909
I1211 11:06:19.989439 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:06:19.989439 15296 solver.cpp:237]     Train net output #1: loss = 1.62909 (* 1 = 1.62909 loss)
I1211 11:06:19.989439 15296 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1211 11:06:26.310699 15296 solver.cpp:218] Iteration 17200 (15.8215 iter/s, 6.32053s/100 iters), loss = 1.44533
I1211 11:06:26.310699 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:06:26.310699 15296 solver.cpp:237]     Train net output #1: loss = 1.44533 (* 1 = 1.44533 loss)
I1211 11:06:26.310699 15296 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1211 11:06:32.644184 15296 solver.cpp:218] Iteration 17300 (15.7903 iter/s, 6.33301s/100 iters), loss = 1.89075
I1211 11:06:32.644184 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 11:06:32.644184 15296 solver.cpp:237]     Train net output #1: loss = 1.89075 (* 1 = 1.89075 loss)
I1211 11:06:32.644184 15296 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1211 11:06:38.967820 15296 solver.cpp:218] Iteration 17400 (15.8152 iter/s, 6.32303s/100 iters), loss = 1.8865
I1211 11:06:38.967820 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:06:38.967820 15296 solver.cpp:237]     Train net output #1: loss = 1.8865 (* 1 = 1.8865 loss)
I1211 11:06:38.967820 15296 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1211 11:06:44.980834 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:06:45.231751 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17500.caffemodel
I1211 11:06:45.246752 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17500.solverstate
I1211 11:06:45.250751 15296 solver.cpp:330] Iteration 17500, Testing net (#0)
I1211 11:06:45.250751 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:06:46.765620  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:06:46.825636 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2631
I1211 11:06:46.825636 15296 solver.cpp:397]     Test net output #1: loss = 3.26552 (* 1 = 3.26552 loss)
I1211 11:06:46.885660 15296 solver.cpp:218] Iteration 17500 (12.6298 iter/s, 7.91778s/100 iters), loss = 1.96497
I1211 11:06:46.885660 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:06:46.885660 15296 solver.cpp:237]     Train net output #1: loss = 1.96497 (* 1 = 1.96497 loss)
I1211 11:06:46.885660 15296 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1211 11:06:53.215265 15296 solver.cpp:218] Iteration 17600 (15.7999 iter/s, 6.32917s/100 iters), loss = 1.69857
I1211 11:06:53.215265 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:06:53.215265 15296 solver.cpp:237]     Train net output #1: loss = 1.69857 (* 1 = 1.69857 loss)
I1211 11:06:53.215265 15296 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1211 11:06:59.541971 15296 solver.cpp:218] Iteration 17700 (15.8076 iter/s, 6.32608s/100 iters), loss = 1.50737
I1211 11:06:59.541971 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:06:59.541971 15296 solver.cpp:237]     Train net output #1: loss = 1.50737 (* 1 = 1.50737 loss)
I1211 11:06:59.541971 15296 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1211 11:07:05.863555 15296 solver.cpp:218] Iteration 17800 (15.8205 iter/s, 6.32093s/100 iters), loss = 1.78942
I1211 11:07:05.863555 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:07:05.863555 15296 solver.cpp:237]     Train net output #1: loss = 1.78942 (* 1 = 1.78942 loss)
I1211 11:07:05.863555 15296 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1211 11:07:12.189083 15296 solver.cpp:218] Iteration 17900 (15.8092 iter/s, 6.32543s/100 iters), loss = 1.91065
I1211 11:07:12.189083 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:07:12.189083 15296 solver.cpp:237]     Train net output #1: loss = 1.91065 (* 1 = 1.91065 loss)
I1211 11:07:12.189083 15296 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1211 11:07:18.204121 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:07:18.455204 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18000.caffemodel
I1211 11:07:18.470203 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18000.solverstate
I1211 11:07:18.474205 15296 solver.cpp:330] Iteration 18000, Testing net (#0)
I1211 11:07:18.474205 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:07:19.989744  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:07:20.049756 15296 solver.cpp:397]     Test net output #0: accuracy = 0.368
I1211 11:07:20.049756 15296 solver.cpp:397]     Test net output #1: loss = 2.52991 (* 1 = 2.52991 loss)
I1211 11:07:20.110762 15296 solver.cpp:218] Iteration 18000 (12.625 iter/s, 7.92077s/100 iters), loss = 1.93911
I1211 11:07:20.110762 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:07:20.110762 15296 solver.cpp:237]     Train net output #1: loss = 1.93911 (* 1 = 1.93911 loss)
I1211 11:07:20.110762 15296 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1211 11:07:26.450973 15296 solver.cpp:218] Iteration 18100 (15.7728 iter/s, 6.34002s/100 iters), loss = 1.57033
I1211 11:07:26.450973 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:07:26.450973 15296 solver.cpp:237]     Train net output #1: loss = 1.57033 (* 1 = 1.57033 loss)
I1211 11:07:26.450973 15296 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1211 11:07:32.788835 15296 solver.cpp:218] Iteration 18200 (15.7783 iter/s, 6.3378s/100 iters), loss = 1.49694
I1211 11:07:32.788835 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:07:32.788835 15296 solver.cpp:237]     Train net output #1: loss = 1.49694 (* 1 = 1.49694 loss)
I1211 11:07:32.788835 15296 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1211 11:07:39.119040 15296 solver.cpp:218] Iteration 18300 (15.8004 iter/s, 6.32895s/100 iters), loss = 1.90876
I1211 11:07:39.119040 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 11:07:39.119040 15296 solver.cpp:237]     Train net output #1: loss = 1.90876 (* 1 = 1.90876 loss)
I1211 11:07:39.119040 15296 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1211 11:07:45.451634 15296 solver.cpp:218] Iteration 18400 (15.7914 iter/s, 6.33256s/100 iters), loss = 1.87529
I1211 11:07:45.451634 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:07:45.451634 15296 solver.cpp:237]     Train net output #1: loss = 1.87529 (* 1 = 1.87529 loss)
I1211 11:07:45.451634 15296 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1211 11:07:51.472671 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:07:51.723475 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18500.caffemodel
I1211 11:07:51.737614 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18500.solverstate
I1211 11:07:51.742619 15296 solver.cpp:330] Iteration 18500, Testing net (#0)
I1211 11:07:51.742619 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:07:53.259802  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:07:53.320327 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3587
I1211 11:07:53.320327 15296 solver.cpp:397]     Test net output #1: loss = 2.48688 (* 1 = 2.48688 loss)
I1211 11:07:53.380838 15296 solver.cpp:218] Iteration 18500 (12.6124 iter/s, 7.92873s/100 iters), loss = 1.68475
I1211 11:07:53.380838 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:07:53.380838 15296 solver.cpp:237]     Train net output #1: loss = 1.68475 (* 1 = 1.68475 loss)
I1211 11:07:53.380838 15296 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1211 11:07:59.710395 15296 solver.cpp:218] Iteration 18600 (15.7999 iter/s, 6.32917s/100 iters), loss = 1.7306
I1211 11:07:59.710395 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:07:59.710395 15296 solver.cpp:237]     Train net output #1: loss = 1.7306 (* 1 = 1.7306 loss)
I1211 11:07:59.710395 15296 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1211 11:08:06.037974 15296 solver.cpp:218] Iteration 18700 (15.8058 iter/s, 6.32679s/100 iters), loss = 1.41953
I1211 11:08:06.037974 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:08:06.037974 15296 solver.cpp:237]     Train net output #1: loss = 1.41953 (* 1 = 1.41953 loss)
I1211 11:08:06.037974 15296 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1211 11:08:12.366667 15296 solver.cpp:218] Iteration 18800 (15.8018 iter/s, 6.32838s/100 iters), loss = 1.93007
I1211 11:08:12.366667 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:08:12.366667 15296 solver.cpp:237]     Train net output #1: loss = 1.93007 (* 1 = 1.93007 loss)
I1211 11:08:12.366667 15296 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1211 11:08:18.697592 15296 solver.cpp:218] Iteration 18900 (15.797 iter/s, 6.33031s/100 iters), loss = 1.73244
I1211 11:08:18.697592 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:08:18.697592 15296 solver.cpp:237]     Train net output #1: loss = 1.73244 (* 1 = 1.73244 loss)
I1211 11:08:18.697592 15296 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1211 11:08:24.717525 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:08:24.967571 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19000.caffemodel
I1211 11:08:24.982570 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19000.solverstate
I1211 11:08:24.987572 15296 solver.cpp:330] Iteration 19000, Testing net (#0)
I1211 11:08:24.987572 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:08:26.505605  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:08:26.565608 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3372
I1211 11:08:26.565608 15296 solver.cpp:397]     Test net output #1: loss = 2.68026 (* 1 = 2.68026 loss)
I1211 11:08:26.625612 15296 solver.cpp:218] Iteration 19000 (12.613 iter/s, 7.92834s/100 iters), loss = 1.87588
I1211 11:08:26.625612 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:08:26.625612 15296 solver.cpp:237]     Train net output #1: loss = 1.87588 (* 1 = 1.87588 loss)
I1211 11:08:26.625612 15296 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1211 11:08:32.957077 15296 solver.cpp:218] Iteration 19100 (15.796 iter/s, 6.3307s/100 iters), loss = 1.70656
I1211 11:08:32.957077 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:08:32.957077 15296 solver.cpp:237]     Train net output #1: loss = 1.70656 (* 1 = 1.70656 loss)
I1211 11:08:32.957077 15296 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1211 11:08:39.281585 15296 solver.cpp:218] Iteration 19200 (15.8144 iter/s, 6.32333s/100 iters), loss = 1.47917
I1211 11:08:39.281585 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:08:39.281585 15296 solver.cpp:237]     Train net output #1: loss = 1.47917 (* 1 = 1.47917 loss)
I1211 11:08:39.281585 15296 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1211 11:08:45.613669 15296 solver.cpp:218] Iteration 19300 (15.7933 iter/s, 6.33181s/100 iters), loss = 1.9767
I1211 11:08:45.613669 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:08:45.613669 15296 solver.cpp:237]     Train net output #1: loss = 1.9767 (* 1 = 1.9767 loss)
I1211 11:08:45.613669 15296 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1211 11:08:51.947680 15296 solver.cpp:218] Iteration 19400 (15.789 iter/s, 6.33351s/100 iters), loss = 1.77528
I1211 11:08:51.947680 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:08:51.947680 15296 solver.cpp:237]     Train net output #1: loss = 1.77528 (* 1 = 1.77528 loss)
I1211 11:08:51.947680 15296 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1211 11:08:57.970170 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:08:58.221187 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19500.caffemodel
I1211 11:08:58.237187 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19500.solverstate
I1211 11:08:58.241189 15296 solver.cpp:330] Iteration 19500, Testing net (#0)
I1211 11:08:58.241189 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:08:59.758303  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:08:59.818307 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3332
I1211 11:08:59.818307 15296 solver.cpp:397]     Test net output #1: loss = 2.68095 (* 1 = 2.68095 loss)
I1211 11:08:59.879310 15296 solver.cpp:218] Iteration 19500 (12.6078 iter/s, 7.93162s/100 iters), loss = 1.79519
I1211 11:08:59.879310 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:08:59.879310 15296 solver.cpp:237]     Train net output #1: loss = 1.79519 (* 1 = 1.79519 loss)
I1211 11:08:59.879310 15296 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1211 11:09:06.212311 15296 solver.cpp:218] Iteration 19600 (15.7919 iter/s, 6.33235s/100 iters), loss = 1.66582
I1211 11:09:06.212311 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:09:06.212311 15296 solver.cpp:237]     Train net output #1: loss = 1.66582 (* 1 = 1.66582 loss)
I1211 11:09:06.212311 15296 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1211 11:09:12.552319 15296 solver.cpp:218] Iteration 19700 (15.7732 iter/s, 6.33989s/100 iters), loss = 1.38758
I1211 11:09:12.552319 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:09:12.552319 15296 solver.cpp:237]     Train net output #1: loss = 1.38758 (* 1 = 1.38758 loss)
I1211 11:09:12.552319 15296 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1211 11:09:18.889732 15296 solver.cpp:218] Iteration 19800 (15.7806 iter/s, 6.33688s/100 iters), loss = 1.81472
I1211 11:09:18.889732 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:09:18.889732 15296 solver.cpp:237]     Train net output #1: loss = 1.81472 (* 1 = 1.81472 loss)
I1211 11:09:18.889732 15296 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1211 11:09:25.231195 15296 solver.cpp:218] Iteration 19900 (15.7707 iter/s, 6.34085s/100 iters), loss = 1.87711
I1211 11:09:25.231195 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:09:25.231195 15296 solver.cpp:237]     Train net output #1: loss = 1.87711 (* 1 = 1.87711 loss)
I1211 11:09:25.231195 15296 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1211 11:09:31.259721 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:09:31.510735 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20000.caffemodel
I1211 11:09:31.524739 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20000.solverstate
I1211 11:09:31.529741 15296 solver.cpp:330] Iteration 20000, Testing net (#0)
I1211 11:09:31.529741 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:09:33.046859  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:09:33.107867 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4143
I1211 11:09:33.107867 15296 solver.cpp:397]     Test net output #1: loss = 2.28305 (* 1 = 2.28305 loss)
I1211 11:09:33.167881 15296 solver.cpp:218] Iteration 20000 (12.6006 iter/s, 7.93611s/100 iters), loss = 1.69297
I1211 11:09:33.167881 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:09:33.167881 15296 solver.cpp:237]     Train net output #1: loss = 1.69297 (* 1 = 1.69297 loss)
I1211 11:09:33.167881 15296 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1211 11:09:39.497371 15296 solver.cpp:218] Iteration 20100 (15.7989 iter/s, 6.32957s/100 iters), loss = 1.83588
I1211 11:09:39.497371 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:09:39.497371 15296 solver.cpp:237]     Train net output #1: loss = 1.83588 (* 1 = 1.83588 loss)
I1211 11:09:39.497371 15296 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1211 11:09:45.823873 15296 solver.cpp:218] Iteration 20200 (15.8077 iter/s, 6.32603s/100 iters), loss = 1.55726
I1211 11:09:45.823873 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:09:45.823873 15296 solver.cpp:237]     Train net output #1: loss = 1.55726 (* 1 = 1.55726 loss)
I1211 11:09:45.823873 15296 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1211 11:09:52.146433 15296 solver.cpp:218] Iteration 20300 (15.8185 iter/s, 6.32173s/100 iters), loss = 1.77772
I1211 11:09:52.146433 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:09:52.146433 15296 solver.cpp:237]     Train net output #1: loss = 1.77772 (* 1 = 1.77772 loss)
I1211 11:09:52.146433 15296 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1211 11:09:58.476934 15296 solver.cpp:218] Iteration 20400 (15.7982 iter/s, 6.32983s/100 iters), loss = 1.68393
I1211 11:09:58.476934 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:09:58.476934 15296 solver.cpp:237]     Train net output #1: loss = 1.68393 (* 1 = 1.68393 loss)
I1211 11:09:58.476934 15296 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1211 11:10:04.529325 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:10:04.778336 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20500.caffemodel
I1211 11:10:04.793838 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20500.solverstate
I1211 11:10:04.798339 15296 solver.cpp:330] Iteration 20500, Testing net (#0)
I1211 11:10:04.798840 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:10:06.317472  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:10:06.377473 15296 solver.cpp:397]     Test net output #0: accuracy = 0.213
I1211 11:10:06.377473 15296 solver.cpp:397]     Test net output #1: loss = 3.7855 (* 1 = 3.7855 loss)
I1211 11:10:06.438478 15296 solver.cpp:218] Iteration 20500 (12.5612 iter/s, 7.96105s/100 iters), loss = 1.74172
I1211 11:10:06.438478 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:10:06.438478 15296 solver.cpp:237]     Train net output #1: loss = 1.74172 (* 1 = 1.74172 loss)
I1211 11:10:06.438478 15296 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1211 11:10:12.772892 15296 solver.cpp:218] Iteration 20600 (15.7867 iter/s, 6.33446s/100 iters), loss = 1.73454
I1211 11:10:12.772892 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:10:12.772892 15296 solver.cpp:237]     Train net output #1: loss = 1.73454 (* 1 = 1.73454 loss)
I1211 11:10:12.772892 15296 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1211 11:10:19.104866 15296 solver.cpp:218] Iteration 20700 (15.795 iter/s, 6.33113s/100 iters), loss = 1.53901
I1211 11:10:19.104866 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:10:19.104866 15296 solver.cpp:237]     Train net output #1: loss = 1.53901 (* 1 = 1.53901 loss)
I1211 11:10:19.104866 15296 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1211 11:10:25.437887 15296 solver.cpp:218] Iteration 20800 (15.7916 iter/s, 6.33247s/100 iters), loss = 1.90879
I1211 11:10:25.437887 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:10:25.437887 15296 solver.cpp:237]     Train net output #1: loss = 1.90879 (* 1 = 1.90879 loss)
I1211 11:10:25.437887 15296 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1211 11:10:31.772325 15296 solver.cpp:218] Iteration 20900 (15.7862 iter/s, 6.33464s/100 iters), loss = 1.82874
I1211 11:10:31.772325 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:10:31.772325 15296 solver.cpp:237]     Train net output #1: loss = 1.82874 (* 1 = 1.82874 loss)
I1211 11:10:31.772325 15296 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1211 11:10:37.798374 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:10:38.047888 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21000.caffemodel
I1211 11:10:38.062887 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21000.solverstate
I1211 11:10:38.067888 15296 solver.cpp:330] Iteration 21000, Testing net (#0)
I1211 11:10:38.067888 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:10:39.584448  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:10:39.644451 15296 solver.cpp:397]     Test net output #0: accuracy = 0.386
I1211 11:10:39.644451 15296 solver.cpp:397]     Test net output #1: loss = 2.47778 (* 1 = 2.47778 loss)
I1211 11:10:39.705466 15296 solver.cpp:218] Iteration 21000 (12.6071 iter/s, 7.93205s/100 iters), loss = 1.98122
I1211 11:10:39.705466 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:10:39.705466 15296 solver.cpp:237]     Train net output #1: loss = 1.98122 (* 1 = 1.98122 loss)
I1211 11:10:39.705466 15296 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1211 11:10:46.044881 15296 solver.cpp:218] Iteration 21100 (15.776 iter/s, 6.33876s/100 iters), loss = 1.64903
I1211 11:10:46.044881 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:10:46.044881 15296 solver.cpp:237]     Train net output #1: loss = 1.64903 (* 1 = 1.64903 loss)
I1211 11:10:46.044881 15296 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1211 11:10:52.379336 15296 solver.cpp:218] Iteration 21200 (15.7857 iter/s, 6.33484s/100 iters), loss = 1.45709
I1211 11:10:52.379336 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 11:10:52.379336 15296 solver.cpp:237]     Train net output #1: loss = 1.45709 (* 1 = 1.45709 loss)
I1211 11:10:52.379336 15296 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1211 11:10:58.718799 15296 solver.cpp:218] Iteration 21300 (15.7751 iter/s, 6.33911s/100 iters), loss = 1.90369
I1211 11:10:58.719800 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 11:10:58.719800 15296 solver.cpp:237]     Train net output #1: loss = 1.90369 (* 1 = 1.90369 loss)
I1211 11:10:58.719800 15296 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1211 11:11:05.055222 15296 solver.cpp:218] Iteration 21400 (15.784 iter/s, 6.33551s/100 iters), loss = 1.81573
I1211 11:11:05.055222 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:11:05.055222 15296 solver.cpp:237]     Train net output #1: loss = 1.81573 (* 1 = 1.81573 loss)
I1211 11:11:05.055222 15296 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1211 11:11:11.081631 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:11:11.332659 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21500.caffemodel
I1211 11:11:11.346659 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21500.solverstate
I1211 11:11:11.351658 15296 solver.cpp:330] Iteration 21500, Testing net (#0)
I1211 11:11:11.351658 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:11:12.868796  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:11:12.929800 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3398
I1211 11:11:12.929800 15296 solver.cpp:397]     Test net output #1: loss = 2.71272 (* 1 = 2.71272 loss)
I1211 11:11:12.990799 15296 solver.cpp:218] Iteration 21500 (12.6016 iter/s, 7.93548s/100 iters), loss = 1.76336
I1211 11:11:12.990799 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:11:12.990799 15296 solver.cpp:237]     Train net output #1: loss = 1.76336 (* 1 = 1.76336 loss)
I1211 11:11:12.990799 15296 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1211 11:11:19.331288 15296 solver.cpp:218] Iteration 21600 (15.7747 iter/s, 6.33927s/100 iters), loss = 1.57354
I1211 11:11:19.331288 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:11:19.331288 15296 solver.cpp:237]     Train net output #1: loss = 1.57354 (* 1 = 1.57354 loss)
I1211 11:11:19.331288 15296 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1211 11:11:25.648762 15296 solver.cpp:218] Iteration 21700 (15.83 iter/s, 6.31712s/100 iters), loss = 1.48104
I1211 11:11:25.648762 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:11:25.648762 15296 solver.cpp:237]     Train net output #1: loss = 1.48104 (* 1 = 1.48104 loss)
I1211 11:11:25.648762 15296 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1211 11:11:31.981246 15296 solver.cpp:218] Iteration 21800 (15.7907 iter/s, 6.33286s/100 iters), loss = 1.91763
I1211 11:11:31.982247 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 11:11:31.982247 15296 solver.cpp:237]     Train net output #1: loss = 1.91763 (* 1 = 1.91763 loss)
I1211 11:11:31.982247 15296 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1211 11:11:38.314738 15296 solver.cpp:218] Iteration 21900 (15.7916 iter/s, 6.33249s/100 iters), loss = 1.66809
I1211 11:11:38.314738 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:11:38.314738 15296 solver.cpp:237]     Train net output #1: loss = 1.66809 (* 1 = 1.66809 loss)
I1211 11:11:38.314738 15296 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1211 11:11:44.339160 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:11:44.589167 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22000.caffemodel
I1211 11:11:44.604171 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22000.solverstate
I1211 11:11:44.608672 15296 solver.cpp:330] Iteration 22000, Testing net (#0)
I1211 11:11:44.608672 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:11:46.127315  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:11:46.187315 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3909
I1211 11:11:46.187315 15296 solver.cpp:397]     Test net output #1: loss = 2.50062 (* 1 = 2.50062 loss)
I1211 11:11:46.247319 15296 solver.cpp:218] Iteration 22000 (12.6068 iter/s, 7.93221s/100 iters), loss = 1.78698
I1211 11:11:46.247319 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:11:46.247319 15296 solver.cpp:237]     Train net output #1: loss = 1.78698 (* 1 = 1.78698 loss)
I1211 11:11:46.247319 15296 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1211 11:11:52.575856 15296 solver.cpp:218] Iteration 22100 (15.8023 iter/s, 6.32818s/100 iters), loss = 1.57093
I1211 11:11:52.575856 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:11:52.575856 15296 solver.cpp:237]     Train net output #1: loss = 1.57093 (* 1 = 1.57093 loss)
I1211 11:11:52.575856 15296 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1211 11:11:58.902994 15296 solver.cpp:218] Iteration 22200 (15.8079 iter/s, 6.32596s/100 iters), loss = 1.44167
I1211 11:11:58.902994 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:11:58.902994 15296 solver.cpp:237]     Train net output #1: loss = 1.44167 (* 1 = 1.44167 loss)
I1211 11:11:58.902994 15296 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1211 11:12:05.233983 15296 solver.cpp:218] Iteration 22300 (15.7954 iter/s, 6.33096s/100 iters), loss = 1.79066
I1211 11:12:05.233983 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:12:05.233983 15296 solver.cpp:237]     Train net output #1: loss = 1.79066 (* 1 = 1.79066 loss)
I1211 11:12:05.233983 15296 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1211 11:12:11.557425 15296 solver.cpp:218] Iteration 22400 (15.8147 iter/s, 6.32324s/100 iters), loss = 1.64058
I1211 11:12:11.557425 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:12:11.557425 15296 solver.cpp:237]     Train net output #1: loss = 1.64058 (* 1 = 1.64058 loss)
I1211 11:12:11.557425 15296 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1211 11:12:17.583927 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:12:17.833959 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22500.caffemodel
I1211 11:12:17.848960 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22500.solverstate
I1211 11:12:17.852960 15296 solver.cpp:330] Iteration 22500, Testing net (#0)
I1211 11:12:17.852960 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:12:19.375068  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:12:19.434072 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3423
I1211 11:12:19.434072 15296 solver.cpp:397]     Test net output #1: loss = 2.74056 (* 1 = 2.74056 loss)
I1211 11:12:19.495072 15296 solver.cpp:218] Iteration 22500 (12.5988 iter/s, 7.93727s/100 iters), loss = 2.0015
I1211 11:12:19.496073 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:12:19.496073 15296 solver.cpp:237]     Train net output #1: loss = 2.0015 (* 1 = 2.0015 loss)
I1211 11:12:19.496073 15296 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1211 11:12:25.835516 15296 solver.cpp:218] Iteration 22600 (15.7746 iter/s, 6.3393s/100 iters), loss = 1.77492
I1211 11:12:25.835516 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:12:25.835516 15296 solver.cpp:237]     Train net output #1: loss = 1.77492 (* 1 = 1.77492 loss)
I1211 11:12:25.835516 15296 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1211 11:12:32.173964 15296 solver.cpp:218] Iteration 22700 (15.7763 iter/s, 6.33861s/100 iters), loss = 1.48338
I1211 11:12:32.173964 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:12:32.173964 15296 solver.cpp:237]     Train net output #1: loss = 1.48338 (* 1 = 1.48338 loss)
I1211 11:12:32.173964 15296 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1211 11:12:38.510460 15296 solver.cpp:218] Iteration 22800 (15.784 iter/s, 6.33554s/100 iters), loss = 1.69378
I1211 11:12:38.510460 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:12:38.510460 15296 solver.cpp:237]     Train net output #1: loss = 1.69378 (* 1 = 1.69378 loss)
I1211 11:12:38.510460 15296 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1211 11:12:44.838943 15296 solver.cpp:218] Iteration 22900 (15.8012 iter/s, 6.32864s/100 iters), loss = 1.94733
I1211 11:12:44.838943 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:12:44.838943 15296 solver.cpp:237]     Train net output #1: loss = 1.94733 (* 1 = 1.94733 loss)
I1211 11:12:44.838943 15296 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1211 11:12:50.856426 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:12:51.106945 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23000.caffemodel
I1211 11:12:51.122448 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23000.solverstate
I1211 11:12:51.126448 15296 solver.cpp:330] Iteration 23000, Testing net (#0)
I1211 11:12:51.126448 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:12:52.646564  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:12:52.706565 15296 solver.cpp:397]     Test net output #0: accuracy = 0.362
I1211 11:12:52.706565 15296 solver.cpp:397]     Test net output #1: loss = 2.54184 (* 1 = 2.54184 loss)
I1211 11:12:52.766566 15296 solver.cpp:218] Iteration 23000 (12.6151 iter/s, 7.92699s/100 iters), loss = 1.81289
I1211 11:12:52.766566 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:12:52.766566 15296 solver.cpp:237]     Train net output #1: loss = 1.81289 (* 1 = 1.81289 loss)
I1211 11:12:52.766566 15296 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1211 11:12:59.101709 15296 solver.cpp:218] Iteration 23100 (15.7857 iter/s, 6.33483s/100 iters), loss = 1.53415
I1211 11:12:59.101709 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:12:59.101709 15296 solver.cpp:237]     Train net output #1: loss = 1.53415 (* 1 = 1.53415 loss)
I1211 11:12:59.101709 15296 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1211 11:13:05.435241 15296 solver.cpp:218] Iteration 23200 (15.7909 iter/s, 6.33278s/100 iters), loss = 1.38364
I1211 11:13:05.435241 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:13:05.435241 15296 solver.cpp:237]     Train net output #1: loss = 1.38364 (* 1 = 1.38364 loss)
I1211 11:13:05.435241 15296 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1211 11:13:11.896701 15296 solver.cpp:218] Iteration 23300 (15.4778 iter/s, 6.46086s/100 iters), loss = 1.84447
I1211 11:13:11.897202 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:13:11.897202 15296 solver.cpp:237]     Train net output #1: loss = 1.84447 (* 1 = 1.84447 loss)
I1211 11:13:11.897202 15296 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1211 11:13:18.446192 15296 solver.cpp:218] Iteration 23400 (15.2704 iter/s, 6.54864s/100 iters), loss = 1.7134
I1211 11:13:18.446192 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:13:18.446192 15296 solver.cpp:237]     Train net output #1: loss = 1.7134 (* 1 = 1.7134 loss)
I1211 11:13:18.446192 15296 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1211 11:13:24.680807 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:13:24.940807 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23500.caffemodel
I1211 11:13:24.957808 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23500.solverstate
I1211 11:13:24.962807 15296 solver.cpp:330] Iteration 23500, Testing net (#0)
I1211 11:13:24.962807 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:13:26.528307  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:13:26.593308 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3301
I1211 11:13:26.593308 15296 solver.cpp:397]     Test net output #1: loss = 2.778 (* 1 = 2.778 loss)
I1211 11:13:26.657806 15296 solver.cpp:218] Iteration 23500 (12.1781 iter/s, 8.21144s/100 iters), loss = 1.7242
I1211 11:13:26.658308 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:13:26.658308 15296 solver.cpp:237]     Train net output #1: loss = 1.7242 (* 1 = 1.7242 loss)
I1211 11:13:26.658308 15296 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1211 11:13:33.187829 15296 solver.cpp:218] Iteration 23600 (15.3164 iter/s, 6.52896s/100 iters), loss = 1.46275
I1211 11:13:33.187829 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:13:33.187829 15296 solver.cpp:237]     Train net output #1: loss = 1.46275 (* 1 = 1.46275 loss)
I1211 11:13:33.188319 15296 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1211 11:13:39.700260 15296 solver.cpp:218] Iteration 23700 (15.3575 iter/s, 6.51146s/100 iters), loss = 1.30181
I1211 11:13:39.700260 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:13:39.700260 15296 solver.cpp:237]     Train net output #1: loss = 1.30181 (* 1 = 1.30181 loss)
I1211 11:13:39.700260 15296 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1211 11:13:46.214853 15296 solver.cpp:218] Iteration 23800 (15.3514 iter/s, 6.51406s/100 iters), loss = 1.79057
I1211 11:13:46.214853 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:13:46.214853 15296 solver.cpp:237]     Train net output #1: loss = 1.79057 (* 1 = 1.79057 loss)
I1211 11:13:46.214853 15296 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1211 11:13:52.726979 15296 solver.cpp:218] Iteration 23900 (15.3566 iter/s, 6.51186s/100 iters), loss = 1.68246
I1211 11:13:52.726979 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:13:52.726979 15296 solver.cpp:237]     Train net output #1: loss = 1.68246 (* 1 = 1.68246 loss)
I1211 11:13:52.726979 15296 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1211 11:13:58.911636 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:13:59.169641 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24000.caffemodel
I1211 11:13:59.185652 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24000.solverstate
I1211 11:13:59.190639 15296 solver.cpp:330] Iteration 24000, Testing net (#0)
I1211 11:13:59.191136 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:14:00.745635  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:14:00.807137 15296 solver.cpp:397]     Test net output #0: accuracy = 0.389
I1211 11:14:00.807137 15296 solver.cpp:397]     Test net output #1: loss = 2.3766 (* 1 = 2.3766 loss)
I1211 11:14:00.869150 15296 solver.cpp:218] Iteration 24000 (12.2827 iter/s, 8.14151s/100 iters), loss = 1.91363
I1211 11:14:00.869150 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:14:00.869150 15296 solver.cpp:237]     Train net output #1: loss = 1.91363 (* 1 = 1.91363 loss)
I1211 11:14:00.869150 15296 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1211 11:14:07.377053 15296 solver.cpp:218] Iteration 24100 (15.3672 iter/s, 6.50735s/100 iters), loss = 1.54578
I1211 11:14:07.377053 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:14:07.377053 15296 solver.cpp:237]     Train net output #1: loss = 1.54578 (* 1 = 1.54578 loss)
I1211 11:14:07.377053 15296 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1211 11:14:13.888011 15296 solver.cpp:218] Iteration 24200 (15.3595 iter/s, 6.51064s/100 iters), loss = 1.47295
I1211 11:14:13.888011 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:14:13.888011 15296 solver.cpp:237]     Train net output #1: loss = 1.47295 (* 1 = 1.47295 loss)
I1211 11:14:13.888011 15296 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1211 11:14:20.403812 15296 solver.cpp:218] Iteration 24300 (15.3487 iter/s, 6.51521s/100 iters), loss = 1.86238
I1211 11:14:20.403812 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:14:20.403812 15296 solver.cpp:237]     Train net output #1: loss = 1.86238 (* 1 = 1.86238 loss)
I1211 11:14:20.403812 15296 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1211 11:14:26.912637 15296 solver.cpp:218] Iteration 24400 (15.3641 iter/s, 6.5087s/100 iters), loss = 1.74462
I1211 11:14:26.913138 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:14:26.913138 15296 solver.cpp:237]     Train net output #1: loss = 1.74462 (* 1 = 1.74462 loss)
I1211 11:14:26.913138 15296 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1211 11:14:33.102402 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:14:33.358901 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24500.caffemodel
I1211 11:14:33.374402 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24500.solverstate
I1211 11:14:33.379900 15296 solver.cpp:330] Iteration 24500, Testing net (#0)
I1211 11:14:33.379900 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:14:34.927919  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:14:34.989400 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2909
I1211 11:14:34.989400 15296 solver.cpp:397]     Test net output #1: loss = 3.16093 (* 1 = 3.16093 loss)
I1211 11:14:35.052399 15296 solver.cpp:218] Iteration 24500 (12.2865 iter/s, 8.13902s/100 iters), loss = 1.96563
I1211 11:14:35.052399 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:14:35.052399 15296 solver.cpp:237]     Train net output #1: loss = 1.96563 (* 1 = 1.96563 loss)
I1211 11:14:35.052399 15296 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1211 11:14:41.570168 15296 solver.cpp:218] Iteration 24600 (15.3438 iter/s, 6.51727s/100 iters), loss = 1.59423
I1211 11:14:41.570168 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:14:41.570168 15296 solver.cpp:237]     Train net output #1: loss = 1.59423 (* 1 = 1.59423 loss)
I1211 11:14:41.570168 15296 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1211 11:14:48.090168 15296 solver.cpp:218] Iteration 24700 (15.3386 iter/s, 6.51949s/100 iters), loss = 1.30515
I1211 11:14:48.090168 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:14:48.090168 15296 solver.cpp:237]     Train net output #1: loss = 1.30515 (* 1 = 1.30515 loss)
I1211 11:14:48.090168 15296 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1211 11:14:54.608496 15296 solver.cpp:218] Iteration 24800 (15.3431 iter/s, 6.51759s/100 iters), loss = 1.8294
I1211 11:14:54.608496 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:14:54.608496 15296 solver.cpp:237]     Train net output #1: loss = 1.8294 (* 1 = 1.8294 loss)
I1211 11:14:54.608496 15296 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1211 11:15:01.125676 15296 solver.cpp:218] Iteration 24900 (15.3448 iter/s, 6.51686s/100 iters), loss = 1.82133
I1211 11:15:01.125676 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:15:01.125676 15296 solver.cpp:237]     Train net output #1: loss = 1.82133 (* 1 = 1.82133 loss)
I1211 11:15:01.125676 15296 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1211 11:15:07.324275 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:15:07.582267 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25000.caffemodel
I1211 11:15:07.597766 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25000.solverstate
I1211 11:15:07.602267 15296 solver.cpp:330] Iteration 25000, Testing net (#0)
I1211 11:15:07.602766 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:15:09.154765  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:15:09.215768 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4049
I1211 11:15:09.215768 15296 solver.cpp:397]     Test net output #1: loss = 2.27243 (* 1 = 2.27243 loss)
I1211 11:15:09.277776 15296 solver.cpp:218] Iteration 25000 (12.2677 iter/s, 8.15148s/100 iters), loss = 1.74877
I1211 11:15:09.277776 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:15:09.277776 15296 solver.cpp:237]     Train net output #1: loss = 1.74877 (* 1 = 1.74877 loss)
I1211 11:15:09.277776 15296 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1211 11:15:15.805276 15296 solver.cpp:218] Iteration 25100 (15.3203 iter/s, 6.52727s/100 iters), loss = 1.63967
I1211 11:15:15.805778 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:15:15.805778 15296 solver.cpp:237]     Train net output #1: loss = 1.63967 (* 1 = 1.63967 loss)
I1211 11:15:15.805778 15296 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1211 11:15:22.330130 15296 solver.cpp:218] Iteration 25200 (15.3281 iter/s, 6.52398s/100 iters), loss = 1.4007
I1211 11:15:22.330130 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:15:22.330130 15296 solver.cpp:237]     Train net output #1: loss = 1.4007 (* 1 = 1.4007 loss)
I1211 11:15:22.330130 15296 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1211 11:15:28.859081 15296 solver.cpp:218] Iteration 25300 (15.3171 iter/s, 6.52864s/100 iters), loss = 1.73552
I1211 11:15:28.859081 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:15:28.859081 15296 solver.cpp:237]     Train net output #1: loss = 1.73552 (* 1 = 1.73552 loss)
I1211 11:15:28.859081 15296 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1211 11:15:35.374871 15296 solver.cpp:218] Iteration 25400 (15.3486 iter/s, 6.51524s/100 iters), loss = 1.77745
I1211 11:15:35.374871 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:15:35.374871 15296 solver.cpp:237]     Train net output #1: loss = 1.77745 (* 1 = 1.77745 loss)
I1211 11:15:35.374871 15296 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1211 11:15:41.568235 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:15:41.825234 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25500.caffemodel
I1211 11:15:41.841235 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25500.solverstate
I1211 11:15:41.845736 15296 solver.cpp:330] Iteration 25500, Testing net (#0)
I1211 11:15:41.846235 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:15:43.397735  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:15:43.457736 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3828
I1211 11:15:43.458250 15296 solver.cpp:397]     Test net output #1: loss = 2.47159 (* 1 = 2.47159 loss)
I1211 11:15:43.518734 15296 solver.cpp:218] Iteration 25500 (12.28 iter/s, 8.14331s/100 iters), loss = 1.88577
I1211 11:15:43.518734 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:15:43.518734 15296 solver.cpp:237]     Train net output #1: loss = 1.88577 (* 1 = 1.88577 loss)
I1211 11:15:43.518734 15296 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1211 11:15:49.864734 15296 solver.cpp:218] Iteration 25600 (15.7593 iter/s, 6.34547s/100 iters), loss = 1.59682
I1211 11:15:49.864734 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:15:49.864734 15296 solver.cpp:237]     Train net output #1: loss = 1.59682 (* 1 = 1.59682 loss)
I1211 11:15:49.864734 15296 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1211 11:15:56.287209 15296 solver.cpp:218] Iteration 25700 (15.5715 iter/s, 6.422s/100 iters), loss = 1.34104
I1211 11:15:56.287209 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 11:15:56.287209 15296 solver.cpp:237]     Train net output #1: loss = 1.34104 (* 1 = 1.34104 loss)
I1211 11:15:56.287209 15296 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1211 11:16:02.803817 15296 solver.cpp:218] Iteration 25800 (15.3463 iter/s, 6.51621s/100 iters), loss = 1.90159
I1211 11:16:02.803817 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:16:02.803817 15296 solver.cpp:237]     Train net output #1: loss = 1.90159 (* 1 = 1.90159 loss)
I1211 11:16:02.803817 15296 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1211 11:16:09.329330 15296 solver.cpp:218] Iteration 25900 (15.3264 iter/s, 6.52469s/100 iters), loss = 1.89068
I1211 11:16:09.329330 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:16:09.329330 15296 solver.cpp:237]     Train net output #1: loss = 1.89068 (* 1 = 1.89068 loss)
I1211 11:16:09.329330 15296 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1211 11:16:15.533840 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:16:15.791837 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26000.caffemodel
I1211 11:16:15.807838 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26000.solverstate
I1211 11:16:15.812839 15296 solver.cpp:330] Iteration 26000, Testing net (#0)
I1211 11:16:15.812839 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:16:17.365839  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:16:17.427837 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3324
I1211 11:16:17.427837 15296 solver.cpp:397]     Test net output #1: loss = 2.85619 (* 1 = 2.85619 loss)
I1211 11:16:17.489837 15296 solver.cpp:218] Iteration 26000 (12.2547 iter/s, 8.16011s/100 iters), loss = 1.84296
I1211 11:16:17.489837 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:16:17.489837 15296 solver.cpp:237]     Train net output #1: loss = 1.84296 (* 1 = 1.84296 loss)
I1211 11:16:17.489837 15296 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1211 11:16:24.000336 15296 solver.cpp:218] Iteration 26100 (15.3603 iter/s, 6.51028s/100 iters), loss = 1.43505
I1211 11:16:24.000838 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:16:24.000838 15296 solver.cpp:237]     Train net output #1: loss = 1.43505 (* 1 = 1.43505 loss)
I1211 11:16:24.000838 15296 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1211 11:16:30.512837 15296 solver.cpp:218] Iteration 26200 (15.3564 iter/s, 6.51193s/100 iters), loss = 1.40014
I1211 11:16:30.512837 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:16:30.513339 15296 solver.cpp:237]     Train net output #1: loss = 1.40014 (* 1 = 1.40014 loss)
I1211 11:16:30.513339 15296 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1211 11:16:37.030339 15296 solver.cpp:218] Iteration 26300 (15.3451 iter/s, 6.51672s/100 iters), loss = 1.77084
I1211 11:16:37.030339 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:16:37.030339 15296 solver.cpp:237]     Train net output #1: loss = 1.77084 (* 1 = 1.77084 loss)
I1211 11:16:37.030339 15296 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1211 11:16:43.518339 15296 solver.cpp:218] Iteration 26400 (15.4143 iter/s, 6.48746s/100 iters), loss = 1.66728
I1211 11:16:43.518339 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:16:43.518339 15296 solver.cpp:237]     Train net output #1: loss = 1.66728 (* 1 = 1.66728 loss)
I1211 11:16:43.518339 15296 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1211 11:16:49.639338 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:16:49.889838 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26500.caffemodel
I1211 11:16:49.907838 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26500.solverstate
I1211 11:16:49.912338 15296 solver.cpp:330] Iteration 26500, Testing net (#0)
I1211 11:16:49.912338 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:16:51.436337  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:16:51.496840 15296 solver.cpp:397]     Test net output #0: accuracy = 0.404
I1211 11:16:51.496840 15296 solver.cpp:397]     Test net output #1: loss = 2.31675 (* 1 = 2.31675 loss)
I1211 11:16:51.557837 15296 solver.cpp:218] Iteration 26500 (12.4392 iter/s, 8.03911s/100 iters), loss = 1.69251
I1211 11:16:51.558339 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:16:51.558339 15296 solver.cpp:237]     Train net output #1: loss = 1.69251 (* 1 = 1.69251 loss)
I1211 11:16:51.558339 15296 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1211 11:16:57.945411 15296 solver.cpp:218] Iteration 26600 (15.6579 iter/s, 6.38657s/100 iters), loss = 1.60519
I1211 11:16:57.945411 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:16:57.945411 15296 solver.cpp:237]     Train net output #1: loss = 1.60519 (* 1 = 1.60519 loss)
I1211 11:16:57.945411 15296 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1211 11:17:04.289048 15296 solver.cpp:218] Iteration 26700 (15.764 iter/s, 6.34357s/100 iters), loss = 1.29147
I1211 11:17:04.289554 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:17:04.289554 15296 solver.cpp:237]     Train net output #1: loss = 1.29147 (* 1 = 1.29147 loss)
I1211 11:17:04.289554 15296 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1211 11:17:10.785653 15296 solver.cpp:218] Iteration 26800 (15.3929 iter/s, 6.49652s/100 iters), loss = 1.91333
I1211 11:17:10.785653 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:17:10.785653 15296 solver.cpp:237]     Train net output #1: loss = 1.91333 (* 1 = 1.91333 loss)
I1211 11:17:10.785653 15296 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1211 11:17:17.227063 15296 solver.cpp:218] Iteration 26900 (15.5258 iter/s, 6.44089s/100 iters), loss = 1.81268
I1211 11:17:17.227063 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:17:17.227063 15296 solver.cpp:237]     Train net output #1: loss = 1.81268 (* 1 = 1.81268 loss)
I1211 11:17:17.227063 15296 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1211 11:17:23.321447 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:17:23.577034 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27000.caffemodel
I1211 11:17:23.593036 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27000.solverstate
I1211 11:17:23.598034 15296 solver.cpp:330] Iteration 27000, Testing net (#0)
I1211 11:17:23.598034 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:17:25.157932  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:17:25.219878 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3349
I1211 11:17:25.219878 15296 solver.cpp:397]     Test net output #1: loss = 2.95789 (* 1 = 2.95789 loss)
I1211 11:17:25.281879 15296 solver.cpp:218] Iteration 27000 (12.4165 iter/s, 8.05381s/100 iters), loss = 1.89228
I1211 11:17:25.281879 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:17:25.281879 15296 solver.cpp:237]     Train net output #1: loss = 1.89228 (* 1 = 1.89228 loss)
I1211 11:17:25.281879 15296 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1211 11:17:31.719683 15296 solver.cpp:218] Iteration 27100 (15.5351 iter/s, 6.43705s/100 iters), loss = 1.65488
I1211 11:17:31.719683 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:17:31.719683 15296 solver.cpp:237]     Train net output #1: loss = 1.65488 (* 1 = 1.65488 loss)
I1211 11:17:31.719683 15296 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1211 11:17:38.213244 15296 solver.cpp:218] Iteration 27200 (15.4016 iter/s, 6.49281s/100 iters), loss = 1.27441
I1211 11:17:38.213244 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:17:38.213244 15296 solver.cpp:237]     Train net output #1: loss = 1.27441 (* 1 = 1.27441 loss)
I1211 11:17:38.213244 15296 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1211 11:17:44.755034 15296 solver.cpp:218] Iteration 27300 (15.2864 iter/s, 6.54178s/100 iters), loss = 1.84349
I1211 11:17:44.755034 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:17:44.755034 15296 solver.cpp:237]     Train net output #1: loss = 1.84349 (* 1 = 1.84349 loss)
I1211 11:17:44.755034 15296 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1211 11:17:51.255336 15296 solver.cpp:218] Iteration 27400 (15.3841 iter/s, 6.50022s/100 iters), loss = 1.70516
I1211 11:17:51.256336 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:17:51.256336 15296 solver.cpp:237]     Train net output #1: loss = 1.70516 (* 1 = 1.70516 loss)
I1211 11:17:51.256336 15296 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1211 11:17:57.273821 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:17:57.523831 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27500.caffemodel
I1211 11:17:57.541836 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27500.solverstate
I1211 11:17:57.546836 15296 solver.cpp:330] Iteration 27500, Testing net (#0)
I1211 11:17:57.546836 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:17:59.065961  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:17:59.126966 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3473
I1211 11:17:59.126966 15296 solver.cpp:397]     Test net output #1: loss = 2.6441 (* 1 = 2.6441 loss)
I1211 11:17:59.187970 15296 solver.cpp:218] Iteration 27500 (12.6074 iter/s, 7.93183s/100 iters), loss = 1.90139
I1211 11:17:59.187970 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:17:59.187970 15296 solver.cpp:237]     Train net output #1: loss = 1.90139 (* 1 = 1.90139 loss)
I1211 11:17:59.187970 15296 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1211 11:18:05.536406 15296 solver.cpp:218] Iteration 27600 (15.7526 iter/s, 6.34815s/100 iters), loss = 1.74925
I1211 11:18:05.536406 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:18:05.536406 15296 solver.cpp:237]     Train net output #1: loss = 1.74925 (* 1 = 1.74925 loss)
I1211 11:18:05.536406 15296 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1211 11:18:11.872890 15296 solver.cpp:218] Iteration 27700 (15.7842 iter/s, 6.33546s/100 iters), loss = 1.4442
I1211 11:18:11.872890 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:18:11.872890 15296 solver.cpp:237]     Train net output #1: loss = 1.4442 (* 1 = 1.4442 loss)
I1211 11:18:11.872890 15296 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1211 11:18:18.218009 15296 solver.cpp:218] Iteration 27800 (15.7614 iter/s, 6.34463s/100 iters), loss = 1.85732
I1211 11:18:18.218009 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:18:18.218009 15296 solver.cpp:237]     Train net output #1: loss = 1.85732 (* 1 = 1.85732 loss)
I1211 11:18:18.218009 15296 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1211 11:18:24.552980 15296 solver.cpp:218] Iteration 27900 (15.7873 iter/s, 6.33419s/100 iters), loss = 1.8202
I1211 11:18:24.552980 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:18:24.552980 15296 solver.cpp:237]     Train net output #1: loss = 1.8202 (* 1 = 1.8202 loss)
I1211 11:18:24.552980 15296 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1211 11:18:30.587379 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:18:30.837394 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28000.caffemodel
I1211 11:18:30.852394 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28000.solverstate
I1211 11:18:30.856393 15296 solver.cpp:330] Iteration 28000, Testing net (#0)
I1211 11:18:30.856393 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:18:32.379688  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:18:32.439738 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3592
I1211 11:18:32.439738 15296 solver.cpp:397]     Test net output #1: loss = 2.60232 (* 1 = 2.60232 loss)
I1211 11:18:32.501722 15296 solver.cpp:218] Iteration 28000 (12.5802 iter/s, 7.94899s/100 iters), loss = 1.75402
I1211 11:18:32.501722 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:18:32.501722 15296 solver.cpp:237]     Train net output #1: loss = 1.75402 (* 1 = 1.75402 loss)
I1211 11:18:32.501722 15296 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1211 11:18:38.843232 15296 solver.cpp:218] Iteration 28100 (15.7715 iter/s, 6.34057s/100 iters), loss = 1.70632
I1211 11:18:38.843232 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:18:38.843232 15296 solver.cpp:237]     Train net output #1: loss = 1.70632 (* 1 = 1.70632 loss)
I1211 11:18:38.843232 15296 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1211 11:18:45.187731 15296 solver.cpp:218] Iteration 28200 (15.7613 iter/s, 6.34465s/100 iters), loss = 1.32954
I1211 11:18:45.187731 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:18:45.187731 15296 solver.cpp:237]     Train net output #1: loss = 1.32954 (* 1 = 1.32954 loss)
I1211 11:18:45.187731 15296 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1211 11:18:51.529284 15296 solver.cpp:218] Iteration 28300 (15.772 iter/s, 6.34033s/100 iters), loss = 1.9188
I1211 11:18:51.529284 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:18:51.529284 15296 solver.cpp:237]     Train net output #1: loss = 1.9188 (* 1 = 1.9188 loss)
I1211 11:18:51.529284 15296 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1211 11:18:57.868752 15296 solver.cpp:218] Iteration 28400 (15.7731 iter/s, 6.33991s/100 iters), loss = 1.82996
I1211 11:18:57.869757 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:18:57.869757 15296 solver.cpp:237]     Train net output #1: loss = 1.82996 (* 1 = 1.82996 loss)
I1211 11:18:57.869757 15296 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1211 11:19:03.898223 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:19:04.147238 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28500.caffemodel
I1211 11:19:04.164239 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28500.solverstate
I1211 11:19:04.169239 15296 solver.cpp:330] Iteration 28500, Testing net (#0)
I1211 11:19:04.169239 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:19:05.687361  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:19:05.747370 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2871
I1211 11:19:05.747370 15296 solver.cpp:397]     Test net output #1: loss = 3.03775 (* 1 = 3.03775 loss)
I1211 11:19:05.808369 15296 solver.cpp:218] Iteration 28500 (12.5968 iter/s, 7.93851s/100 iters), loss = 1.76745
I1211 11:19:05.808369 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:19:05.808369 15296 solver.cpp:237]     Train net output #1: loss = 1.76745 (* 1 = 1.76745 loss)
I1211 11:19:05.808369 15296 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1211 11:19:12.155937 15296 solver.cpp:218] Iteration 28600 (15.7543 iter/s, 6.34748s/100 iters), loss = 1.47273
I1211 11:19:12.155937 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:19:12.155937 15296 solver.cpp:237]     Train net output #1: loss = 1.47273 (* 1 = 1.47273 loss)
I1211 11:19:12.155937 15296 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1211 11:19:18.500444 15296 solver.cpp:218] Iteration 28700 (15.7625 iter/s, 6.34416s/100 iters), loss = 1.4253
I1211 11:19:18.500444 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:19:18.500444 15296 solver.cpp:237]     Train net output #1: loss = 1.4253 (* 1 = 1.4253 loss)
I1211 11:19:18.500444 15296 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1211 11:19:24.850849 15296 solver.cpp:218] Iteration 28800 (15.748 iter/s, 6.35s/100 iters), loss = 1.80413
I1211 11:19:24.850849 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:19:24.850849 15296 solver.cpp:237]     Train net output #1: loss = 1.80413 (* 1 = 1.80413 loss)
I1211 11:19:24.850849 15296 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1211 11:19:31.215354 15296 solver.cpp:218] Iteration 28900 (15.7144 iter/s, 6.36359s/100 iters), loss = 1.60202
I1211 11:19:31.215354 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:19:31.215354 15296 solver.cpp:237]     Train net output #1: loss = 1.60202 (* 1 = 1.60202 loss)
I1211 11:19:31.215354 15296 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1211 11:19:37.248960 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:19:37.498986 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29000.caffemodel
I1211 11:19:37.513984 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29000.solverstate
I1211 11:19:37.518987 15296 solver.cpp:330] Iteration 29000, Testing net (#0)
I1211 11:19:37.518987 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:19:39.038111  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:19:39.098116 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3768
I1211 11:19:39.098116 15296 solver.cpp:397]     Test net output #1: loss = 2.54906 (* 1 = 2.54906 loss)
I1211 11:19:39.158120 15296 solver.cpp:218] Iteration 29000 (12.5902 iter/s, 7.94271s/100 iters), loss = 1.90802
I1211 11:19:39.158120 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:19:39.158120 15296 solver.cpp:237]     Train net output #1: loss = 1.90802 (* 1 = 1.90802 loss)
I1211 11:19:39.158120 15296 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1211 11:19:45.500634 15296 solver.cpp:218] Iteration 29100 (15.768 iter/s, 6.34196s/100 iters), loss = 1.59225
I1211 11:19:45.500634 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:19:45.500634 15296 solver.cpp:237]     Train net output #1: loss = 1.59225 (* 1 = 1.59225 loss)
I1211 11:19:45.500634 15296 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1211 11:19:51.840487 15296 solver.cpp:218] Iteration 29200 (15.7759 iter/s, 6.3388s/100 iters), loss = 1.37122
I1211 11:19:51.840487 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:19:51.840487 15296 solver.cpp:237]     Train net output #1: loss = 1.37122 (* 1 = 1.37122 loss)
I1211 11:19:51.840487 15296 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1211 11:19:58.177791 15296 solver.cpp:218] Iteration 29300 (15.7807 iter/s, 6.33685s/100 iters), loss = 1.67608
I1211 11:19:58.177791 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:19:58.177791 15296 solver.cpp:237]     Train net output #1: loss = 1.67608 (* 1 = 1.67608 loss)
I1211 11:19:58.177791 15296 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1211 11:20:04.565115 15296 solver.cpp:218] Iteration 29400 (15.6573 iter/s, 6.38678s/100 iters), loss = 1.79907
I1211 11:20:04.565115 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:20:04.565115 15296 solver.cpp:237]     Train net output #1: loss = 1.79907 (* 1 = 1.79907 loss)
I1211 11:20:04.565115 15296 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1211 11:20:10.597821 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:20:10.848764 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29500.caffemodel
I1211 11:20:10.862766 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29500.solverstate
I1211 11:20:10.867764 15296 solver.cpp:330] Iteration 29500, Testing net (#0)
I1211 11:20:10.867764 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:20:12.385438  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:20:12.445750 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3439
I1211 11:20:12.445750 15296 solver.cpp:397]     Test net output #1: loss = 2.69007 (* 1 = 2.69007 loss)
I1211 11:20:12.507773 15296 solver.cpp:218] Iteration 29500 (12.591 iter/s, 7.94218s/100 iters), loss = 1.85249
I1211 11:20:12.507773 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:20:12.507773 15296 solver.cpp:237]     Train net output #1: loss = 1.85249 (* 1 = 1.85249 loss)
I1211 11:20:12.507773 15296 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1211 11:20:18.844719 15296 solver.cpp:218] Iteration 29600 (15.7814 iter/s, 6.33656s/100 iters), loss = 1.73017
I1211 11:20:18.844719 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:20:18.844719 15296 solver.cpp:237]     Train net output #1: loss = 1.73017 (* 1 = 1.73017 loss)
I1211 11:20:18.844719 15296 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1211 11:20:25.185209 15296 solver.cpp:218] Iteration 29700 (15.7709 iter/s, 6.34077s/100 iters), loss = 1.4823
I1211 11:20:25.185209 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:20:25.185209 15296 solver.cpp:237]     Train net output #1: loss = 1.4823 (* 1 = 1.4823 loss)
I1211 11:20:25.185209 15296 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1211 11:20:31.524729 15296 solver.cpp:218] Iteration 29800 (15.7769 iter/s, 6.33838s/100 iters), loss = 1.83104
I1211 11:20:31.524729 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:20:31.524729 15296 solver.cpp:237]     Train net output #1: loss = 1.83104 (* 1 = 1.83104 loss)
I1211 11:20:31.524729 15296 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1211 11:20:37.860254 15296 solver.cpp:218] Iteration 29900 (15.7832 iter/s, 6.33585s/100 iters), loss = 1.78059
I1211 11:20:37.860254 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:20:37.860254 15296 solver.cpp:237]     Train net output #1: loss = 1.78059 (* 1 = 1.78059 loss)
I1211 11:20:37.860254 15296 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1211 11:20:43.907246 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:20:44.157765 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30000.caffemodel
I1211 11:20:44.176765 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30000.solverstate
I1211 11:20:44.181766 15296 solver.cpp:330] Iteration 30000, Testing net (#0)
I1211 11:20:44.181766 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:20:45.699898  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:20:45.760905 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2755
I1211 11:20:45.760905 15296 solver.cpp:397]     Test net output #1: loss = 3.33333 (* 1 = 3.33333 loss)
I1211 11:20:45.820907 15296 solver.cpp:218] Iteration 30000 (12.5625 iter/s, 7.96022s/100 iters), loss = 1.68156
I1211 11:20:45.820907 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:20:45.820907 15296 solver.cpp:237]     Train net output #1: loss = 1.68156 (* 1 = 1.68156 loss)
I1211 11:20:45.820907 15296 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1211 11:20:52.182826 15296 solver.cpp:218] Iteration 30100 (15.7217 iter/s, 6.36063s/100 iters), loss = 1.70197
I1211 11:20:52.182826 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:20:52.182826 15296 solver.cpp:237]     Train net output #1: loss = 1.70197 (* 1 = 1.70197 loss)
I1211 11:20:52.182826 15296 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1211 11:20:58.560814 15296 solver.cpp:218] Iteration 30200 (15.678 iter/s, 6.37838s/100 iters), loss = 1.27323
I1211 11:20:58.560814 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:20:58.560814 15296 solver.cpp:237]     Train net output #1: loss = 1.27323 (* 1 = 1.27323 loss)
I1211 11:20:58.560814 15296 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1211 11:21:04.914338 15296 solver.cpp:218] Iteration 30300 (15.7408 iter/s, 6.35292s/100 iters), loss = 1.72476
I1211 11:21:04.914338 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:21:04.914338 15296 solver.cpp:237]     Train net output #1: loss = 1.72476 (* 1 = 1.72476 loss)
I1211 11:21:04.914338 15296 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1211 11:21:11.265806 15296 solver.cpp:218] Iteration 30400 (15.7465 iter/s, 6.35062s/100 iters), loss = 1.74939
I1211 11:21:11.265806 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:21:11.265806 15296 solver.cpp:237]     Train net output #1: loss = 1.74939 (* 1 = 1.74939 loss)
I1211 11:21:11.265806 15296 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1211 11:21:17.294773 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:21:17.543303 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30500.caffemodel
I1211 11:21:17.558303 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30500.solverstate
I1211 11:21:17.562302 15296 solver.cpp:330] Iteration 30500, Testing net (#0)
I1211 11:21:17.562302 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:21:19.079505  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:21:19.140533 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2929
I1211 11:21:19.140533 15296 solver.cpp:397]     Test net output #1: loss = 3.12617 (* 1 = 3.12617 loss)
I1211 11:21:19.201536 15296 solver.cpp:218] Iteration 30500 (12.602 iter/s, 7.93523s/100 iters), loss = 1.79015
I1211 11:21:19.201536 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:21:19.201536 15296 solver.cpp:237]     Train net output #1: loss = 1.79015 (* 1 = 1.79015 loss)
I1211 11:21:19.201536 15296 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1211 11:21:25.560991 15296 solver.cpp:218] Iteration 30600 (15.7264 iter/s, 6.35875s/100 iters), loss = 1.67784
I1211 11:21:25.560991 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:21:25.560991 15296 solver.cpp:237]     Train net output #1: loss = 1.67784 (* 1 = 1.67784 loss)
I1211 11:21:25.560991 15296 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1211 11:21:31.891032 15296 solver.cpp:218] Iteration 30700 (15.7986 iter/s, 6.32967s/100 iters), loss = 1.40756
I1211 11:21:31.891032 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 11:21:31.891032 15296 solver.cpp:237]     Train net output #1: loss = 1.40756 (* 1 = 1.40756 loss)
I1211 11:21:31.891032 15296 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1211 11:21:38.223013 15296 solver.cpp:218] Iteration 30800 (15.7933 iter/s, 6.33178s/100 iters), loss = 1.77375
I1211 11:21:38.223013 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:21:38.223013 15296 solver.cpp:237]     Train net output #1: loss = 1.77375 (* 1 = 1.77375 loss)
I1211 11:21:38.223013 15296 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1211 11:21:44.549530 15296 solver.cpp:218] Iteration 30900 (15.8071 iter/s, 6.32629s/100 iters), loss = 1.90563
I1211 11:21:44.549530 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:21:44.549530 15296 solver.cpp:237]     Train net output #1: loss = 1.90563 (* 1 = 1.90563 loss)
I1211 11:21:44.549530 15296 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1211 11:21:50.570966 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:21:50.819991 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31000.caffemodel
I1211 11:21:50.833991 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31000.solverstate
I1211 11:21:50.838991 15296 solver.cpp:330] Iteration 31000, Testing net (#0)
I1211 11:21:50.838991 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:21:52.359086  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:21:52.419111 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2788
I1211 11:21:52.419111 15296 solver.cpp:397]     Test net output #1: loss = 3.33708 (* 1 = 3.33708 loss)
I1211 11:21:52.480109 15296 solver.cpp:218] Iteration 31000 (12.6108 iter/s, 7.92969s/100 iters), loss = 1.81403
I1211 11:21:52.480109 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:21:52.480109 15296 solver.cpp:237]     Train net output #1: loss = 1.81403 (* 1 = 1.81403 loss)
I1211 11:21:52.480109 15296 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1211 11:21:58.817550 15296 solver.cpp:218] Iteration 31100 (15.7805 iter/s, 6.33695s/100 iters), loss = 1.61439
I1211 11:21:58.817550 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:21:58.817550 15296 solver.cpp:237]     Train net output #1: loss = 1.61439 (* 1 = 1.61439 loss)
I1211 11:21:58.817550 15296 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1211 11:22:05.144997 15296 solver.cpp:218] Iteration 31200 (15.8044 iter/s, 6.32734s/100 iters), loss = 1.40068
I1211 11:22:05.144997 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:22:05.144997 15296 solver.cpp:237]     Train net output #1: loss = 1.40068 (* 1 = 1.40068 loss)
I1211 11:22:05.144997 15296 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1211 11:22:11.476575 15296 solver.cpp:218] Iteration 31300 (15.7955 iter/s, 6.33093s/100 iters), loss = 1.86055
I1211 11:22:11.476575 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:22:11.476575 15296 solver.cpp:237]     Train net output #1: loss = 1.86055 (* 1 = 1.86055 loss)
I1211 11:22:11.476575 15296 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1211 11:22:17.795555 15296 solver.cpp:218] Iteration 31400 (15.8264 iter/s, 6.31856s/100 iters), loss = 1.89018
I1211 11:22:17.795555 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:22:17.795555 15296 solver.cpp:237]     Train net output #1: loss = 1.89018 (* 1 = 1.89018 loss)
I1211 11:22:17.795555 15296 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1211 11:22:23.813172 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:22:24.062202 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31500.caffemodel
I1211 11:22:24.078203 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31500.solverstate
I1211 11:22:24.083216 15296 solver.cpp:330] Iteration 31500, Testing net (#0)
I1211 11:22:24.083216 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:22:25.600711  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:22:25.660729 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2744
I1211 11:22:25.660729 15296 solver.cpp:397]     Test net output #1: loss = 3.20878 (* 1 = 3.20878 loss)
I1211 11:22:25.721761 15296 solver.cpp:218] Iteration 31500 (12.6172 iter/s, 7.92572s/100 iters), loss = 1.76381
I1211 11:22:25.721761 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:22:25.721761 15296 solver.cpp:237]     Train net output #1: loss = 1.76381 (* 1 = 1.76381 loss)
I1211 11:22:25.721761 15296 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1211 11:22:32.062011 15296 solver.cpp:218] Iteration 31600 (15.7722 iter/s, 6.34029s/100 iters), loss = 1.61962
I1211 11:22:32.062011 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:22:32.062011 15296 solver.cpp:237]     Train net output #1: loss = 1.61962 (* 1 = 1.61962 loss)
I1211 11:22:32.062011 15296 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1211 11:22:38.391054 15296 solver.cpp:218] Iteration 31700 (15.8021 iter/s, 6.32828s/100 iters), loss = 1.34513
I1211 11:22:38.391054 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:22:38.391054 15296 solver.cpp:237]     Train net output #1: loss = 1.34513 (* 1 = 1.34513 loss)
I1211 11:22:38.391054 15296 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1211 11:22:44.722110 15296 solver.cpp:218] Iteration 31800 (15.795 iter/s, 6.33112s/100 iters), loss = 1.65355
I1211 11:22:44.722110 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:22:44.722110 15296 solver.cpp:237]     Train net output #1: loss = 1.65355 (* 1 = 1.65355 loss)
I1211 11:22:44.722110 15296 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1211 11:22:51.049580 15296 solver.cpp:218] Iteration 31900 (15.8062 iter/s, 6.32662s/100 iters), loss = 1.82973
I1211 11:22:51.049580 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:22:51.049580 15296 solver.cpp:237]     Train net output #1: loss = 1.82973 (* 1 = 1.82973 loss)
I1211 11:22:51.049580 15296 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1211 11:22:57.070988 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:22:57.320999 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32000.caffemodel
I1211 11:22:57.335503 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32000.solverstate
I1211 11:22:57.340004 15296 solver.cpp:330] Iteration 32000, Testing net (#0)
I1211 11:22:57.340004 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:22:58.857137  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:22:58.918136 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4131
I1211 11:22:58.918136 15296 solver.cpp:397]     Test net output #1: loss = 2.25429 (* 1 = 2.25429 loss)
I1211 11:22:58.978140 15296 solver.cpp:218] Iteration 32000 (12.6133 iter/s, 7.92815s/100 iters), loss = 1.78311
I1211 11:22:58.978140 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:22:58.978140 15296 solver.cpp:237]     Train net output #1: loss = 1.78311 (* 1 = 1.78311 loss)
I1211 11:22:58.978140 15296 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1211 11:23:05.309578 15296 solver.cpp:218] Iteration 32100 (15.7937 iter/s, 6.33162s/100 iters), loss = 1.63418
I1211 11:23:05.310580 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:23:05.310580 15296 solver.cpp:237]     Train net output #1: loss = 1.63418 (* 1 = 1.63418 loss)
I1211 11:23:05.310580 15296 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1211 11:23:11.647042 15296 solver.cpp:218] Iteration 32200 (15.7825 iter/s, 6.33613s/100 iters), loss = 1.34759
I1211 11:23:11.647042 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:23:11.647042 15296 solver.cpp:237]     Train net output #1: loss = 1.34759 (* 1 = 1.34759 loss)
I1211 11:23:11.647042 15296 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1211 11:23:17.977524 15296 solver.cpp:218] Iteration 32300 (15.7968 iter/s, 6.33041s/100 iters), loss = 1.69239
I1211 11:23:17.977524 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:23:17.977524 15296 solver.cpp:237]     Train net output #1: loss = 1.69239 (* 1 = 1.69239 loss)
I1211 11:23:17.977524 15296 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1211 11:23:24.312932 15296 solver.cpp:218] Iteration 32400 (15.784 iter/s, 6.33554s/100 iters), loss = 1.72251
I1211 11:23:24.313932 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:23:24.313932 15296 solver.cpp:237]     Train net output #1: loss = 1.72251 (* 1 = 1.72251 loss)
I1211 11:23:24.313932 15296 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1211 11:23:30.333431 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:23:30.582444 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32500.caffemodel
I1211 11:23:30.597445 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32500.solverstate
I1211 11:23:30.601445 15296 solver.cpp:330] Iteration 32500, Testing net (#0)
I1211 11:23:30.601445 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:23:32.120571  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:23:32.180582 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3269
I1211 11:23:32.180582 15296 solver.cpp:397]     Test net output #1: loss = 2.87874 (* 1 = 2.87874 loss)
I1211 11:23:32.242084 15296 solver.cpp:218] Iteration 32500 (12.614 iter/s, 7.92771s/100 iters), loss = 1.82836
I1211 11:23:32.242084 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:23:32.242084 15296 solver.cpp:237]     Train net output #1: loss = 1.82836 (* 1 = 1.82836 loss)
I1211 11:23:32.242084 15296 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1211 11:23:38.574019 15296 solver.cpp:218] Iteration 32600 (15.7929 iter/s, 6.33195s/100 iters), loss = 1.7487
I1211 11:23:38.574019 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:23:38.574019 15296 solver.cpp:237]     Train net output #1: loss = 1.7487 (* 1 = 1.7487 loss)
I1211 11:23:38.574019 15296 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1211 11:23:44.918498 15296 solver.cpp:218] Iteration 32700 (15.763 iter/s, 6.34399s/100 iters), loss = 1.44466
I1211 11:23:44.918498 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:23:44.918498 15296 solver.cpp:237]     Train net output #1: loss = 1.44466 (* 1 = 1.44466 loss)
I1211 11:23:44.918498 15296 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1211 11:23:51.247799 15296 solver.cpp:218] Iteration 32800 (15.8009 iter/s, 6.32874s/100 iters), loss = 1.8864
I1211 11:23:51.247799 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:23:51.247799 15296 solver.cpp:237]     Train net output #1: loss = 1.8864 (* 1 = 1.8864 loss)
I1211 11:23:51.247799 15296 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1211 11:23:57.572440 15296 solver.cpp:218] Iteration 32900 (15.8122 iter/s, 6.32424s/100 iters), loss = 1.77241
I1211 11:23:57.572440 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:23:57.572440 15296 solver.cpp:237]     Train net output #1: loss = 1.77241 (* 1 = 1.77241 loss)
I1211 11:23:57.572440 15296 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1211 11:24:03.596765 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:24:03.846396 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33000.caffemodel
I1211 11:24:03.863394 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33000.solverstate
I1211 11:24:03.868396 15296 solver.cpp:330] Iteration 33000, Testing net (#0)
I1211 11:24:03.868396 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:24:05.385745  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:24:05.445765 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3423
I1211 11:24:05.445765 15296 solver.cpp:397]     Test net output #1: loss = 2.63964 (* 1 = 2.63964 loss)
I1211 11:24:05.506788 15296 solver.cpp:218] Iteration 33000 (12.6048 iter/s, 7.93351s/100 iters), loss = 1.78698
I1211 11:24:05.506788 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:24:05.506788 15296 solver.cpp:237]     Train net output #1: loss = 1.78698 (* 1 = 1.78698 loss)
I1211 11:24:05.506788 15296 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1211 11:24:11.843802 15296 solver.cpp:218] Iteration 33100 (15.7791 iter/s, 6.33751s/100 iters), loss = 1.68036
I1211 11:24:11.844792 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:24:11.844792 15296 solver.cpp:237]     Train net output #1: loss = 1.68036 (* 1 = 1.68036 loss)
I1211 11:24:11.844792 15296 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1211 11:24:18.179321 15296 solver.cpp:218] Iteration 33200 (15.7868 iter/s, 6.33439s/100 iters), loss = 1.32986
I1211 11:24:18.179321 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 11:24:18.179321 15296 solver.cpp:237]     Train net output #1: loss = 1.32986 (* 1 = 1.32986 loss)
I1211 11:24:18.179321 15296 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1211 11:24:24.510267 15296 solver.cpp:218] Iteration 33300 (15.7967 iter/s, 6.33045s/100 iters), loss = 1.82015
I1211 11:24:24.510267 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:24:24.510267 15296 solver.cpp:237]     Train net output #1: loss = 1.82015 (* 1 = 1.82015 loss)
I1211 11:24:24.510267 15296 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1211 11:24:30.850288 15296 solver.cpp:218] Iteration 33400 (15.7738 iter/s, 6.33964s/100 iters), loss = 1.79226
I1211 11:24:30.850288 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:24:30.850288 15296 solver.cpp:237]     Train net output #1: loss = 1.79226 (* 1 = 1.79226 loss)
I1211 11:24:30.850288 15296 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1211 11:24:36.878749 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:24:37.129784 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33500.caffemodel
I1211 11:24:37.146785 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33500.solverstate
I1211 11:24:37.150784 15296 solver.cpp:330] Iteration 33500, Testing net (#0)
I1211 11:24:37.150784 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:24:38.669936  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:24:38.729946 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2775
I1211 11:24:38.729946 15296 solver.cpp:397]     Test net output #1: loss = 3.09572 (* 1 = 3.09572 loss)
I1211 11:24:38.789945 15296 solver.cpp:218] Iteration 33500 (12.5947 iter/s, 7.93983s/100 iters), loss = 1.75262
I1211 11:24:38.789945 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:24:38.789945 15296 solver.cpp:237]     Train net output #1: loss = 1.75262 (* 1 = 1.75262 loss)
I1211 11:24:38.789945 15296 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1211 11:24:45.155010 15296 solver.cpp:218] Iteration 33600 (15.7129 iter/s, 6.36419s/100 iters), loss = 1.68384
I1211 11:24:45.155010 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:24:45.155010 15296 solver.cpp:237]     Train net output #1: loss = 1.68384 (* 1 = 1.68384 loss)
I1211 11:24:45.155010 15296 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1211 11:24:51.505517 15296 solver.cpp:218] Iteration 33700 (15.7488 iter/s, 6.34971s/100 iters), loss = 1.27837
I1211 11:24:51.505517 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 11:24:51.505517 15296 solver.cpp:237]     Train net output #1: loss = 1.27837 (* 1 = 1.27837 loss)
I1211 11:24:51.505517 15296 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1211 11:24:57.890547 15296 solver.cpp:218] Iteration 33800 (15.662 iter/s, 6.3849s/100 iters), loss = 1.83024
I1211 11:24:57.890547 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:24:57.890547 15296 solver.cpp:237]     Train net output #1: loss = 1.83024 (* 1 = 1.83024 loss)
I1211 11:24:57.890547 15296 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1211 11:25:04.380095 15296 solver.cpp:218] Iteration 33900 (15.4105 iter/s, 6.48907s/100 iters), loss = 1.77496
I1211 11:25:04.380095 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:25:04.380095 15296 solver.cpp:237]     Train net output #1: loss = 1.77496 (* 1 = 1.77496 loss)
I1211 11:25:04.380095 15296 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1211 11:25:10.408607 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:25:10.658257 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34000.caffemodel
I1211 11:25:10.674239 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34000.solverstate
I1211 11:25:10.678241 15296 solver.cpp:330] Iteration 34000, Testing net (#0)
I1211 11:25:10.678241 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:25:12.197746  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:25:12.258798 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3249
I1211 11:25:12.258798 15296 solver.cpp:397]     Test net output #1: loss = 2.74877 (* 1 = 2.74877 loss)
I1211 11:25:12.319805 15296 solver.cpp:218] Iteration 34000 (12.5958 iter/s, 7.93916s/100 iters), loss = 1.6622
I1211 11:25:12.319805 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:25:12.319805 15296 solver.cpp:237]     Train net output #1: loss = 1.6622 (* 1 = 1.6622 loss)
I1211 11:25:12.319805 15296 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1211 11:25:18.641423 15296 solver.cpp:218] Iteration 34100 (15.8187 iter/s, 6.32162s/100 iters), loss = 1.68087
I1211 11:25:18.641423 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:25:18.641423 15296 solver.cpp:237]     Train net output #1: loss = 1.68087 (* 1 = 1.68087 loss)
I1211 11:25:18.641423 15296 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1211 11:25:24.975967 15296 solver.cpp:218] Iteration 34200 (15.7886 iter/s, 6.33367s/100 iters), loss = 1.27194
I1211 11:25:24.975967 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:25:24.975967 15296 solver.cpp:237]     Train net output #1: loss = 1.27194 (* 1 = 1.27194 loss)
I1211 11:25:24.975967 15296 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1211 11:25:31.297425 15296 solver.cpp:218] Iteration 34300 (15.8203 iter/s, 6.32101s/100 iters), loss = 1.67709
I1211 11:25:31.297425 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:25:31.297425 15296 solver.cpp:237]     Train net output #1: loss = 1.67709 (* 1 = 1.67709 loss)
I1211 11:25:31.297425 15296 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1211 11:25:37.623380 15296 solver.cpp:218] Iteration 34400 (15.8091 iter/s, 6.32548s/100 iters), loss = 1.76708
I1211 11:25:37.623380 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:25:37.623380 15296 solver.cpp:237]     Train net output #1: loss = 1.76708 (* 1 = 1.76708 loss)
I1211 11:25:37.623380 15296 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1211 11:25:43.648320 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:25:43.897334 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34500.caffemodel
I1211 11:25:43.912837 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34500.solverstate
I1211 11:25:43.917338 15296 solver.cpp:330] Iteration 34500, Testing net (#0)
I1211 11:25:43.917839 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:25:45.437600  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:25:45.497601 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3037
I1211 11:25:45.497601 15296 solver.cpp:397]     Test net output #1: loss = 3.14168 (* 1 = 3.14168 loss)
I1211 11:25:45.558604 15296 solver.cpp:218] Iteration 34500 (12.6028 iter/s, 7.93477s/100 iters), loss = 1.63371
I1211 11:25:45.558604 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:25:45.558604 15296 solver.cpp:237]     Train net output #1: loss = 1.63371 (* 1 = 1.63371 loss)
I1211 11:25:45.558604 15296 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1211 11:25:51.890033 15296 solver.cpp:218] Iteration 34600 (15.7959 iter/s, 6.33075s/100 iters), loss = 1.57983
I1211 11:25:51.890033 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:25:51.890033 15296 solver.cpp:237]     Train net output #1: loss = 1.57983 (* 1 = 1.57983 loss)
I1211 11:25:51.890033 15296 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1211 11:25:58.226513 15296 solver.cpp:218] Iteration 34700 (15.7815 iter/s, 6.33652s/100 iters), loss = 1.29847
I1211 11:25:58.227015 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:25:58.227015 15296 solver.cpp:237]     Train net output #1: loss = 1.29847 (* 1 = 1.29847 loss)
I1211 11:25:58.227015 15296 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1211 11:26:04.554075 15296 solver.cpp:218] Iteration 34800 (15.8047 iter/s, 6.32723s/100 iters), loss = 1.8295
I1211 11:26:04.554075 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 11:26:04.554075 15296 solver.cpp:237]     Train net output #1: loss = 1.8295 (* 1 = 1.8295 loss)
I1211 11:26:04.554075 15296 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1211 11:26:10.883553 15296 solver.cpp:218] Iteration 34900 (15.8011 iter/s, 6.32869s/100 iters), loss = 1.82703
I1211 11:26:10.883553 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:26:10.883553 15296 solver.cpp:237]     Train net output #1: loss = 1.82703 (* 1 = 1.82703 loss)
I1211 11:26:10.883553 15296 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1211 11:26:16.904084 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:26:17.154125 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35000.caffemodel
I1211 11:26:17.169124 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35000.solverstate
I1211 11:26:17.174125 15296 solver.cpp:330] Iteration 35000, Testing net (#0)
I1211 11:26:17.174125 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:26:18.692239  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:26:18.752243 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3079
I1211 11:26:18.752243 15296 solver.cpp:397]     Test net output #1: loss = 3.00237 (* 1 = 3.00237 loss)
I1211 11:26:18.813242 15296 solver.cpp:218] Iteration 35000 (12.611 iter/s, 7.92961s/100 iters), loss = 1.71948
I1211 11:26:18.813242 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:26:18.813242 15296 solver.cpp:237]     Train net output #1: loss = 1.71948 (* 1 = 1.71948 loss)
I1211 11:26:18.813242 15296 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1211 11:26:25.146689 15296 solver.cpp:218] Iteration 35100 (15.7899 iter/s, 6.33315s/100 iters), loss = 1.63312
I1211 11:26:25.146689 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:26:25.146689 15296 solver.cpp:237]     Train net output #1: loss = 1.63312 (* 1 = 1.63312 loss)
I1211 11:26:25.146689 15296 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1211 11:26:31.482149 15296 solver.cpp:218] Iteration 35200 (15.7851 iter/s, 6.33507s/100 iters), loss = 1.31904
I1211 11:26:31.482149 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:26:31.482149 15296 solver.cpp:237]     Train net output #1: loss = 1.31904 (* 1 = 1.31904 loss)
I1211 11:26:31.482149 15296 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1211 11:26:37.820128 15296 solver.cpp:218] Iteration 35300 (15.7797 iter/s, 6.33726s/100 iters), loss = 1.86816
I1211 11:26:37.820128 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:26:37.820128 15296 solver.cpp:237]     Train net output #1: loss = 1.86816 (* 1 = 1.86816 loss)
I1211 11:26:37.820629 15296 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1211 11:26:44.163069 15296 solver.cpp:218] Iteration 35400 (15.7665 iter/s, 6.34257s/100 iters), loss = 1.68567
I1211 11:26:44.163069 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:26:44.163069 15296 solver.cpp:237]     Train net output #1: loss = 1.68567 (* 1 = 1.68567 loss)
I1211 11:26:44.163069 15296 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1211 11:26:50.190564 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:26:50.440582 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35500.caffemodel
I1211 11:26:50.455582 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35500.solverstate
I1211 11:26:50.460582 15296 solver.cpp:330] Iteration 35500, Testing net (#0)
I1211 11:26:50.460582 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:26:51.977666  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:26:52.037672 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3964
I1211 11:26:52.037672 15296 solver.cpp:397]     Test net output #1: loss = 2.35353 (* 1 = 2.35353 loss)
I1211 11:26:52.098675 15296 solver.cpp:218] Iteration 35500 (12.6019 iter/s, 7.9353s/100 iters), loss = 1.63425
I1211 11:26:52.098675 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:26:52.098675 15296 solver.cpp:237]     Train net output #1: loss = 1.63425 (* 1 = 1.63425 loss)
I1211 11:26:52.098675 15296 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1211 11:26:58.426584 15296 solver.cpp:218] Iteration 35600 (15.8059 iter/s, 6.32675s/100 iters), loss = 1.70008
I1211 11:26:58.426584 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:26:58.426584 15296 solver.cpp:237]     Train net output #1: loss = 1.70008 (* 1 = 1.70008 loss)
I1211 11:26:58.426584 15296 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1211 11:27:04.755458 15296 solver.cpp:218] Iteration 35700 (15.8004 iter/s, 6.32895s/100 iters), loss = 1.27059
I1211 11:27:04.755458 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:27:04.755458 15296 solver.cpp:237]     Train net output #1: loss = 1.27059 (* 1 = 1.27059 loss)
I1211 11:27:04.755458 15296 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1211 11:27:11.085942 15296 solver.cpp:218] Iteration 35800 (15.7989 iter/s, 6.32956s/100 iters), loss = 1.87133
I1211 11:27:11.085942 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:27:11.085942 15296 solver.cpp:237]     Train net output #1: loss = 1.87133 (* 1 = 1.87133 loss)
I1211 11:27:11.085942 15296 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1211 11:27:17.403394 15296 solver.cpp:218] Iteration 35900 (15.8301 iter/s, 6.31709s/100 iters), loss = 1.84961
I1211 11:27:17.403394 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:27:17.403394 15296 solver.cpp:237]     Train net output #1: loss = 1.84961 (* 1 = 1.84961 loss)
I1211 11:27:17.403394 15296 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1211 11:27:23.423825 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:27:23.672873 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36000.caffemodel
I1211 11:27:23.687875 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36000.solverstate
I1211 11:27:23.692874 15296 solver.cpp:330] Iteration 36000, Testing net (#0)
I1211 11:27:23.692874 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:27:25.211975  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:27:25.271978 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3353
I1211 11:27:25.272979 15296 solver.cpp:397]     Test net output #1: loss = 2.73045 (* 1 = 2.73045 loss)
I1211 11:27:25.333978 15296 solver.cpp:218] Iteration 36000 (12.6096 iter/s, 7.93047s/100 iters), loss = 1.81047
I1211 11:27:25.333978 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:27:25.333978 15296 solver.cpp:237]     Train net output #1: loss = 1.81047 (* 1 = 1.81047 loss)
I1211 11:27:25.333978 15296 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1211 11:27:31.670462 15296 solver.cpp:218] Iteration 36100 (15.782 iter/s, 6.33635s/100 iters), loss = 1.53353
I1211 11:27:31.670462 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:27:31.670462 15296 solver.cpp:237]     Train net output #1: loss = 1.53353 (* 1 = 1.53353 loss)
I1211 11:27:31.670462 15296 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1211 11:27:38.005856 15296 solver.cpp:218] Iteration 36200 (15.7853 iter/s, 6.33501s/100 iters), loss = 1.3449
I1211 11:27:38.005856 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:27:38.005856 15296 solver.cpp:237]     Train net output #1: loss = 1.3449 (* 1 = 1.3449 loss)
I1211 11:27:38.005856 15296 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1211 11:27:44.348834 15296 solver.cpp:218] Iteration 36300 (15.7679 iter/s, 6.342s/100 iters), loss = 1.82009
I1211 11:27:44.348834 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:27:44.348834 15296 solver.cpp:237]     Train net output #1: loss = 1.82009 (* 1 = 1.82009 loss)
I1211 11:27:44.348834 15296 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1211 11:27:50.679819 15296 solver.cpp:218] Iteration 36400 (15.7968 iter/s, 6.33041s/100 iters), loss = 1.70793
I1211 11:27:50.679819 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:27:50.679819 15296 solver.cpp:237]     Train net output #1: loss = 1.70793 (* 1 = 1.70793 loss)
I1211 11:27:50.679819 15296 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1211 11:27:56.703335 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:27:56.954346 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36500.caffemodel
I1211 11:27:56.968349 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36500.solverstate
I1211 11:27:56.973351 15296 solver.cpp:330] Iteration 36500, Testing net (#0)
I1211 11:27:56.973351 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:27:58.494526  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:27:58.554536 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2957
I1211 11:27:58.554536 15296 solver.cpp:397]     Test net output #1: loss = 3.09155 (* 1 = 3.09155 loss)
I1211 11:27:58.615540 15296 solver.cpp:218] Iteration 36500 (12.6018 iter/s, 7.93537s/100 iters), loss = 1.78949
I1211 11:27:58.615540 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:27:58.615540 15296 solver.cpp:237]     Train net output #1: loss = 1.78949 (* 1 = 1.78949 loss)
I1211 11:27:58.615540 15296 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1211 11:28:04.956991 15296 solver.cpp:218] Iteration 36600 (15.7706 iter/s, 6.34092s/100 iters), loss = 1.66424
I1211 11:28:04.956991 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 11:28:04.956991 15296 solver.cpp:237]     Train net output #1: loss = 1.66424 (* 1 = 1.66424 loss)
I1211 11:28:04.956991 15296 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1211 11:28:11.298450 15296 solver.cpp:218] Iteration 36700 (15.7696 iter/s, 6.34132s/100 iters), loss = 1.43148
I1211 11:28:11.298450 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:28:11.298450 15296 solver.cpp:237]     Train net output #1: loss = 1.43148 (* 1 = 1.43148 loss)
I1211 11:28:11.298450 15296 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1211 11:28:17.702045 15296 solver.cpp:218] Iteration 36800 (15.6176 iter/s, 6.40304s/100 iters), loss = 1.894
I1211 11:28:17.702045 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:28:17.702045 15296 solver.cpp:237]     Train net output #1: loss = 1.894 (* 1 = 1.894 loss)
I1211 11:28:17.702045 15296 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1211 11:28:24.059506 15296 solver.cpp:218] Iteration 36900 (15.7303 iter/s, 6.35714s/100 iters), loss = 1.65916
I1211 11:28:24.059506 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:28:24.059506 15296 solver.cpp:237]     Train net output #1: loss = 1.65916 (* 1 = 1.65916 loss)
I1211 11:28:24.059506 15296 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1211 11:28:30.232111 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:28:30.489163 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37000.caffemodel
I1211 11:28:30.506325 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37000.solverstate
I1211 11:28:30.511328 15296 solver.cpp:330] Iteration 37000, Testing net (#0)
I1211 11:28:30.511328 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:28:32.067744  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:28:32.129334 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3666
I1211 11:28:32.129334 15296 solver.cpp:397]     Test net output #1: loss = 2.57348 (* 1 = 2.57348 loss)
I1211 11:28:32.192338 15296 solver.cpp:218] Iteration 37000 (12.2965 iter/s, 8.13241s/100 iters), loss = 1.76904
I1211 11:28:32.192338 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:28:32.192838 15296 solver.cpp:237]     Train net output #1: loss = 1.76904 (* 1 = 1.76904 loss)
I1211 11:28:32.192838 15296 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1211 11:28:38.714730 15296 solver.cpp:218] Iteration 37100 (15.332 iter/s, 6.52229s/100 iters), loss = 1.61507
I1211 11:28:38.714730 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:28:38.715711 15296 solver.cpp:237]     Train net output #1: loss = 1.61507 (* 1 = 1.61507 loss)
I1211 11:28:38.715711 15296 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1211 11:28:45.247241 15296 solver.cpp:218] Iteration 37200 (15.3118 iter/s, 6.53091s/100 iters), loss = 1.3762
I1211 11:28:45.247241 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:28:45.247241 15296 solver.cpp:237]     Train net output #1: loss = 1.3762 (* 1 = 1.3762 loss)
I1211 11:28:45.247241 15296 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1211 11:28:51.777828 15296 solver.cpp:218] Iteration 37300 (15.3123 iter/s, 6.53072s/100 iters), loss = 1.59354
I1211 11:28:51.777828 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:28:51.777828 15296 solver.cpp:237]     Train net output #1: loss = 1.59354 (* 1 = 1.59354 loss)
I1211 11:28:51.777828 15296 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1211 11:28:58.298619 15296 solver.cpp:218] Iteration 37400 (15.3369 iter/s, 6.52022s/100 iters), loss = 1.72205
I1211 11:28:58.298619 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:28:58.298619 15296 solver.cpp:237]     Train net output #1: loss = 1.72205 (* 1 = 1.72205 loss)
I1211 11:28:58.298619 15296 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1211 11:29:04.487023 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:29:04.742485 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37500.caffemodel
I1211 11:29:04.762485 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37500.solverstate
I1211 11:29:04.767485 15296 solver.cpp:330] Iteration 37500, Testing net (#0)
I1211 11:29:04.767485 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:29:06.323495  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:29:06.384495 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4164
I1211 11:29:06.384495 15296 solver.cpp:397]     Test net output #1: loss = 2.26687 (* 1 = 2.26687 loss)
I1211 11:29:06.445674 15296 solver.cpp:218] Iteration 37500 (12.2752 iter/s, 8.14651s/100 iters), loss = 1.86837
I1211 11:29:06.445674 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:29:06.445674 15296 solver.cpp:237]     Train net output #1: loss = 1.86837 (* 1 = 1.86837 loss)
I1211 11:29:06.445674 15296 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1211 11:29:12.954715 15296 solver.cpp:218] Iteration 37600 (15.364 iter/s, 6.50871s/100 iters), loss = 1.61301
I1211 11:29:12.954715 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:29:12.954715 15296 solver.cpp:237]     Train net output #1: loss = 1.61301 (* 1 = 1.61301 loss)
I1211 11:29:12.954715 15296 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1211 11:29:19.492044 15296 solver.cpp:218] Iteration 37700 (15.2988 iter/s, 6.53646s/100 iters), loss = 1.37483
I1211 11:29:19.492044 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:29:19.492044 15296 solver.cpp:237]     Train net output #1: loss = 1.37483 (* 1 = 1.37483 loss)
I1211 11:29:19.492044 15296 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1211 11:29:25.972271 15296 solver.cpp:218] Iteration 37800 (15.432 iter/s, 6.48005s/100 iters), loss = 1.86764
I1211 11:29:25.972271 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:29:25.972271 15296 solver.cpp:237]     Train net output #1: loss = 1.86764 (* 1 = 1.86764 loss)
I1211 11:29:25.972271 15296 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1211 11:29:32.324648 15296 solver.cpp:218] Iteration 37900 (15.7448 iter/s, 6.35131s/100 iters), loss = 1.60972
I1211 11:29:32.324648 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:29:32.324648 15296 solver.cpp:237]     Train net output #1: loss = 1.60972 (* 1 = 1.60972 loss)
I1211 11:29:32.324648 15296 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1211 11:29:38.359833 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:29:38.610963 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38000.caffemodel
I1211 11:29:38.628465 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38000.solverstate
I1211 11:29:38.632467 15296 solver.cpp:330] Iteration 38000, Testing net (#0)
I1211 11:29:38.632467 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:29:40.153501  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:29:40.213505 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3663
I1211 11:29:40.213505 15296 solver.cpp:397]     Test net output #1: loss = 2.5099 (* 1 = 2.5099 loss)
I1211 11:29:40.274545 15296 solver.cpp:218] Iteration 38000 (12.5792 iter/s, 7.94963s/100 iters), loss = 1.71884
I1211 11:29:40.274545 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:29:40.274545 15296 solver.cpp:237]     Train net output #1: loss = 1.71884 (* 1 = 1.71884 loss)
I1211 11:29:40.274545 15296 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1211 11:29:46.614581 15296 solver.cpp:218] Iteration 38100 (15.7738 iter/s, 6.33964s/100 iters), loss = 1.75192
I1211 11:29:46.614581 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:29:46.614581 15296 solver.cpp:237]     Train net output #1: loss = 1.75192 (* 1 = 1.75192 loss)
I1211 11:29:46.614581 15296 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1211 11:29:52.953197 15296 solver.cpp:218] Iteration 38200 (15.7771 iter/s, 6.33828s/100 iters), loss = 1.17779
I1211 11:29:52.953197 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:29:52.953197 15296 solver.cpp:237]     Train net output #1: loss = 1.17779 (* 1 = 1.17779 loss)
I1211 11:29:52.953197 15296 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1211 11:29:59.303704 15296 solver.cpp:218] Iteration 38300 (15.7483 iter/s, 6.3499s/100 iters), loss = 1.71601
I1211 11:29:59.303704 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:29:59.303704 15296 solver.cpp:237]     Train net output #1: loss = 1.71601 (* 1 = 1.71601 loss)
I1211 11:29:59.303704 15296 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1211 11:30:05.690827 15296 solver.cpp:218] Iteration 38400 (15.6574 iter/s, 6.38676s/100 iters), loss = 1.81092
I1211 11:30:05.690827 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:30:05.690827 15296 solver.cpp:237]     Train net output #1: loss = 1.81092 (* 1 = 1.81092 loss)
I1211 11:30:05.690827 15296 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1211 11:30:11.756026 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:30:12.009138 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38500.caffemodel
I1211 11:30:12.025138 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38500.solverstate
I1211 11:30:12.029150 15296 solver.cpp:330] Iteration 38500, Testing net (#0)
I1211 11:30:12.029150 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:30:13.577078  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:30:13.637079 15296 solver.cpp:397]     Test net output #0: accuracy = 0.326
I1211 11:30:13.637079 15296 solver.cpp:397]     Test net output #1: loss = 2.75061 (* 1 = 2.75061 loss)
I1211 11:30:13.697124 15296 solver.cpp:218] Iteration 38500 (12.4901 iter/s, 8.00636s/100 iters), loss = 1.86046
I1211 11:30:13.697124 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:30:13.698112 15296 solver.cpp:237]     Train net output #1: loss = 1.86046 (* 1 = 1.86046 loss)
I1211 11:30:13.698112 15296 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1211 11:30:20.076449 15296 solver.cpp:218] Iteration 38600 (15.6769 iter/s, 6.37881s/100 iters), loss = 1.58466
I1211 11:30:20.076449 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:30:20.076449 15296 solver.cpp:237]     Train net output #1: loss = 1.58466 (* 1 = 1.58466 loss)
I1211 11:30:20.076449 15296 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1211 11:30:26.424230 15296 solver.cpp:218] Iteration 38700 (15.7555 iter/s, 6.34698s/100 iters), loss = 1.37763
I1211 11:30:26.424230 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 11:30:26.424230 15296 solver.cpp:237]     Train net output #1: loss = 1.37763 (* 1 = 1.37763 loss)
I1211 11:30:26.424230 15296 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1211 11:30:32.765730 15296 solver.cpp:218] Iteration 38800 (15.7711 iter/s, 6.34073s/100 iters), loss = 1.70973
I1211 11:30:32.765730 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:30:32.765730 15296 solver.cpp:237]     Train net output #1: loss = 1.70973 (* 1 = 1.70973 loss)
I1211 11:30:32.765730 15296 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1211 11:30:39.106063 15296 solver.cpp:218] Iteration 38900 (15.7735 iter/s, 6.33973s/100 iters), loss = 1.76311
I1211 11:30:39.106063 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:30:39.106063 15296 solver.cpp:237]     Train net output #1: loss = 1.76311 (* 1 = 1.76311 loss)
I1211 11:30:39.106063 15296 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1211 11:30:45.122603 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:30:45.372436 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39000.caffemodel
I1211 11:30:45.387434 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39000.solverstate
I1211 11:30:45.392439 15296 solver.cpp:330] Iteration 39000, Testing net (#0)
I1211 11:30:45.392439 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:30:46.909900  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:30:46.970423 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4131
I1211 11:30:46.970423 15296 solver.cpp:397]     Test net output #1: loss = 2.26795 (* 1 = 2.26795 loss)
I1211 11:30:47.031411 15296 solver.cpp:218] Iteration 39000 (12.6185 iter/s, 7.92486s/100 iters), loss = 1.64474
I1211 11:30:47.031411 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:30:47.031411 15296 solver.cpp:237]     Train net output #1: loss = 1.64474 (* 1 = 1.64474 loss)
I1211 11:30:47.031411 15296 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1211 11:30:53.360327 15296 solver.cpp:218] Iteration 39100 (15.8009 iter/s, 6.32877s/100 iters), loss = 1.73894
I1211 11:30:53.360327 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:30:53.360327 15296 solver.cpp:237]     Train net output #1: loss = 1.73894 (* 1 = 1.73894 loss)
I1211 11:30:53.360327 15296 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1211 11:30:59.686738 15296 solver.cpp:218] Iteration 39200 (15.8085 iter/s, 6.32572s/100 iters), loss = 1.35195
I1211 11:30:59.686738 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:30:59.686738 15296 solver.cpp:237]     Train net output #1: loss = 1.35195 (* 1 = 1.35195 loss)
I1211 11:30:59.686738 15296 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1211 11:31:06.020210 15296 solver.cpp:218] Iteration 39300 (15.7894 iter/s, 6.33337s/100 iters), loss = 1.78771
I1211 11:31:06.020210 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:31:06.020210 15296 solver.cpp:237]     Train net output #1: loss = 1.78771 (* 1 = 1.78771 loss)
I1211 11:31:06.020210 15296 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1211 11:31:12.515442 15296 solver.cpp:218] Iteration 39400 (15.3987 iter/s, 6.49405s/100 iters), loss = 1.73553
I1211 11:31:12.515442 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:31:12.515442 15296 solver.cpp:237]     Train net output #1: loss = 1.73553 (* 1 = 1.73553 loss)
I1211 11:31:12.515442 15296 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1211 11:31:18.581989 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:31:18.831002 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39500.caffemodel
I1211 11:31:18.846001 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39500.solverstate
I1211 11:31:18.851002 15296 solver.cpp:330] Iteration 39500, Testing net (#0)
I1211 11:31:18.851002 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:31:20.370616  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:31:20.430119 15296 solver.cpp:397]     Test net output #0: accuracy = 0.437
I1211 11:31:20.430119 15296 solver.cpp:397]     Test net output #1: loss = 2.13186 (* 1 = 2.13186 loss)
I1211 11:31:20.490124 15296 solver.cpp:218] Iteration 39500 (12.5392 iter/s, 7.97496s/100 iters), loss = 1.69102
I1211 11:31:20.491125 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:31:20.491125 15296 solver.cpp:237]     Train net output #1: loss = 1.69102 (* 1 = 1.69102 loss)
I1211 11:31:20.491125 15296 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1211 11:31:26.890698 15296 solver.cpp:218] Iteration 39600 (15.6259 iter/s, 6.39964s/100 iters), loss = 1.51466
I1211 11:31:26.890698 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:31:26.890698 15296 solver.cpp:237]     Train net output #1: loss = 1.51466 (* 1 = 1.51466 loss)
I1211 11:31:26.890698 15296 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1211 11:31:33.314702 15296 solver.cpp:218] Iteration 39700 (15.568 iter/s, 6.42342s/100 iters), loss = 1.55224
I1211 11:31:33.314702 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:31:33.314702 15296 solver.cpp:237]     Train net output #1: loss = 1.55224 (* 1 = 1.55224 loss)
I1211 11:31:33.314702 15296 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1211 11:31:39.695108 15296 solver.cpp:218] Iteration 39800 (15.673 iter/s, 6.38039s/100 iters), loss = 1.68398
I1211 11:31:39.695108 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:31:39.695108 15296 solver.cpp:237]     Train net output #1: loss = 1.68398 (* 1 = 1.68398 loss)
I1211 11:31:39.695108 15296 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1211 11:31:46.092348 15296 solver.cpp:218] Iteration 39900 (15.6346 iter/s, 6.39609s/100 iters), loss = 1.75868
I1211 11:31:46.092348 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:31:46.092348 15296 solver.cpp:237]     Train net output #1: loss = 1.75868 (* 1 = 1.75868 loss)
I1211 11:31:46.092348 15296 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1211 11:31:52.139997 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:31:52.390170 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40000.caffemodel
I1211 11:31:52.406170 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40000.solverstate
I1211 11:31:52.411175 15296 solver.cpp:330] Iteration 40000, Testing net (#0)
I1211 11:31:52.411175 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:31:53.928762  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:31:53.988772 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2737
I1211 11:31:53.988772 15296 solver.cpp:397]     Test net output #1: loss = 3.21351 (* 1 = 3.21351 loss)
I1211 11:31:54.049525 15296 solver.cpp:218] Iteration 40000 (12.5675 iter/s, 7.95701s/100 iters), loss = 1.64853
I1211 11:31:54.049525 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:31:54.049525 15296 solver.cpp:237]     Train net output #1: loss = 1.64853 (* 1 = 1.64853 loss)
I1211 11:31:54.049525 15296 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1211 11:32:00.405779 15296 solver.cpp:218] Iteration 40100 (15.7332 iter/s, 6.35599s/100 iters), loss = 1.58479
I1211 11:32:00.405779 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 11:32:00.405779 15296 solver.cpp:237]     Train net output #1: loss = 1.58479 (* 1 = 1.58479 loss)
I1211 11:32:00.405779 15296 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1211 11:32:06.746259 15296 solver.cpp:218] Iteration 40200 (15.7738 iter/s, 6.33964s/100 iters), loss = 1.3243
I1211 11:32:06.746259 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:32:06.746259 15296 solver.cpp:237]     Train net output #1: loss = 1.3243 (* 1 = 1.3243 loss)
I1211 11:32:06.746259 15296 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1211 11:32:13.084957 15296 solver.cpp:218] Iteration 40300 (15.7769 iter/s, 6.33838s/100 iters), loss = 1.74281
I1211 11:32:13.084957 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:32:13.085458 15296 solver.cpp:237]     Train net output #1: loss = 1.74281 (* 1 = 1.74281 loss)
I1211 11:32:13.085458 15296 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1211 11:32:19.425595 15296 solver.cpp:218] Iteration 40400 (15.7711 iter/s, 6.3407s/100 iters), loss = 1.87176
I1211 11:32:19.426595 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:32:19.426595 15296 solver.cpp:237]     Train net output #1: loss = 1.87176 (* 1 = 1.87176 loss)
I1211 11:32:19.426595 15296 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1211 11:32:25.452045 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:32:25.702059 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40500.caffemodel
I1211 11:32:25.718058 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40500.solverstate
I1211 11:32:25.722059 15296 solver.cpp:330] Iteration 40500, Testing net (#0)
I1211 11:32:25.722059 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:32:27.241171  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:32:27.302177 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3742
I1211 11:32:27.302177 15296 solver.cpp:397]     Test net output #1: loss = 2.506 (* 1 = 2.506 loss)
I1211 11:32:27.363178 15296 solver.cpp:218] Iteration 40500 (12.6005 iter/s, 7.93619s/100 iters), loss = 1.82536
I1211 11:32:27.363178 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:32:27.363178 15296 solver.cpp:237]     Train net output #1: loss = 1.82536 (* 1 = 1.82536 loss)
I1211 11:32:27.363178 15296 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1211 11:32:33.694664 15296 solver.cpp:218] Iteration 40600 (15.7952 iter/s, 6.33104s/100 iters), loss = 1.61883
I1211 11:32:33.694664 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 11:32:33.694664 15296 solver.cpp:237]     Train net output #1: loss = 1.61883 (* 1 = 1.61883 loss)
I1211 11:32:33.694664 15296 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1211 11:32:40.017292 15296 solver.cpp:218] Iteration 40700 (15.817 iter/s, 6.32232s/100 iters), loss = 1.26978
I1211 11:32:40.017292 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:32:40.017292 15296 solver.cpp:237]     Train net output #1: loss = 1.26978 (* 1 = 1.26978 loss)
I1211 11:32:40.017292 15296 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1211 11:32:46.348573 15296 solver.cpp:218] Iteration 40800 (15.7945 iter/s, 6.3313s/100 iters), loss = 1.79659
I1211 11:32:46.348573 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:32:46.348573 15296 solver.cpp:237]     Train net output #1: loss = 1.79659 (* 1 = 1.79659 loss)
I1211 11:32:46.348573 15296 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1211 11:32:52.680619 15296 solver.cpp:218] Iteration 40900 (15.7935 iter/s, 6.33171s/100 iters), loss = 1.75311
I1211 11:32:52.680619 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:32:52.680619 15296 solver.cpp:237]     Train net output #1: loss = 1.75311 (* 1 = 1.75311 loss)
I1211 11:32:52.680619 15296 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1211 11:32:58.706426 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:32:58.954385 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41000.caffemodel
I1211 11:32:58.969385 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41000.solverstate
I1211 11:32:58.973403 15296 solver.cpp:330] Iteration 41000, Testing net (#0)
I1211 11:32:58.974385 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:33:00.493239  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:33:00.553267 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3909
I1211 11:33:00.553267 15296 solver.cpp:397]     Test net output #1: loss = 2.46585 (* 1 = 2.46585 loss)
I1211 11:33:00.613284 15296 solver.cpp:218] Iteration 41000 (12.6079 iter/s, 7.9315s/100 iters), loss = 1.7698
I1211 11:33:00.613284 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:33:00.613284 15296 solver.cpp:237]     Train net output #1: loss = 1.7698 (* 1 = 1.7698 loss)
I1211 11:33:00.613284 15296 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1211 11:33:06.938962 15296 solver.cpp:218] Iteration 41100 (15.8089 iter/s, 6.32557s/100 iters), loss = 1.53621
I1211 11:33:06.938962 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:33:06.938962 15296 solver.cpp:237]     Train net output #1: loss = 1.53621 (* 1 = 1.53621 loss)
I1211 11:33:06.938962 15296 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1211 11:33:13.276432 15296 solver.cpp:218] Iteration 41200 (15.7812 iter/s, 6.33666s/100 iters), loss = 1.44386
I1211 11:33:13.276432 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:33:13.276432 15296 solver.cpp:237]     Train net output #1: loss = 1.44386 (* 1 = 1.44386 loss)
I1211 11:33:13.276432 15296 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1211 11:33:19.607484 15296 solver.cpp:218] Iteration 41300 (15.7969 iter/s, 6.33036s/100 iters), loss = 1.97581
I1211 11:33:19.607484 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:33:19.607484 15296 solver.cpp:237]     Train net output #1: loss = 1.97581 (* 1 = 1.97581 loss)
I1211 11:33:19.607484 15296 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1211 11:33:25.939452 15296 solver.cpp:218] Iteration 41400 (15.7922 iter/s, 6.33223s/100 iters), loss = 1.70708
I1211 11:33:25.939452 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:33:25.939452 15296 solver.cpp:237]     Train net output #1: loss = 1.70708 (* 1 = 1.70708 loss)
I1211 11:33:25.939452 15296 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1211 11:33:31.967949 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:33:32.217967 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41500.caffemodel
I1211 11:33:32.232969 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41500.solverstate
I1211 11:33:32.236969 15296 solver.cpp:330] Iteration 41500, Testing net (#0)
I1211 11:33:32.236969 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:33:33.757081  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:33:33.818086 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3611
I1211 11:33:33.818086 15296 solver.cpp:397]     Test net output #1: loss = 2.6074 (* 1 = 2.6074 loss)
I1211 11:33:33.878584 15296 solver.cpp:218] Iteration 41500 (12.5977 iter/s, 7.93793s/100 iters), loss = 1.74204
I1211 11:33:33.878584 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:33:33.878584 15296 solver.cpp:237]     Train net output #1: loss = 1.74204 (* 1 = 1.74204 loss)
I1211 11:33:33.878584 15296 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1211 11:33:40.209575 15296 solver.cpp:218] Iteration 41600 (15.7957 iter/s, 6.33083s/100 iters), loss = 1.59525
I1211 11:33:40.209575 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:33:40.209575 15296 solver.cpp:237]     Train net output #1: loss = 1.59525 (* 1 = 1.59525 loss)
I1211 11:33:40.209575 15296 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1211 11:33:46.536048 15296 solver.cpp:218] Iteration 41700 (15.8063 iter/s, 6.32658s/100 iters), loss = 1.3951
I1211 11:33:46.536048 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:33:46.536048 15296 solver.cpp:237]     Train net output #1: loss = 1.3951 (* 1 = 1.3951 loss)
I1211 11:33:46.536048 15296 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1211 11:33:52.867995 15296 solver.cpp:218] Iteration 41800 (15.7953 iter/s, 6.33098s/100 iters), loss = 1.92057
I1211 11:33:52.867995 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:33:52.867995 15296 solver.cpp:237]     Train net output #1: loss = 1.92057 (* 1 = 1.92057 loss)
I1211 11:33:52.867995 15296 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1211 11:33:59.212962 15296 solver.cpp:218] Iteration 41900 (15.7605 iter/s, 6.34498s/100 iters), loss = 1.79893
I1211 11:33:59.212962 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:33:59.212962 15296 solver.cpp:237]     Train net output #1: loss = 1.79893 (* 1 = 1.79893 loss)
I1211 11:33:59.212962 15296 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1211 11:34:05.258411 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:34:05.508430 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42000.caffemodel
I1211 11:34:05.526430 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42000.solverstate
I1211 11:34:05.531430 15296 solver.cpp:330] Iteration 42000, Testing net (#0)
I1211 11:34:05.531430 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:34:07.071053  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:34:07.133556 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3281
I1211 11:34:07.133556 15296 solver.cpp:397]     Test net output #1: loss = 2.87278 (* 1 = 2.87278 loss)
I1211 11:34:07.196558 15296 solver.cpp:218] Iteration 42000 (12.5274 iter/s, 7.9825s/100 iters), loss = 1.76428
I1211 11:34:07.196558 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:34:07.196558 15296 solver.cpp:237]     Train net output #1: loss = 1.76428 (* 1 = 1.76428 loss)
I1211 11:34:07.196558 15296 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1211 11:34:13.568034 15296 solver.cpp:218] Iteration 42100 (15.6964 iter/s, 6.37089s/100 iters), loss = 1.68426
I1211 11:34:13.568034 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:34:13.568034 15296 solver.cpp:237]     Train net output #1: loss = 1.68426 (* 1 = 1.68426 loss)
I1211 11:34:13.568034 15296 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1211 11:34:19.909636 15296 solver.cpp:218] Iteration 42200 (15.7694 iter/s, 6.34139s/100 iters), loss = 1.34409
I1211 11:34:19.909636 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:34:19.909636 15296 solver.cpp:237]     Train net output #1: loss = 1.34409 (* 1 = 1.34409 loss)
I1211 11:34:19.909636 15296 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1211 11:34:26.263099 15296 solver.cpp:218] Iteration 42300 (15.7409 iter/s, 6.35287s/100 iters), loss = 1.76292
I1211 11:34:26.263099 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:34:26.263099 15296 solver.cpp:237]     Train net output #1: loss = 1.76292 (* 1 = 1.76292 loss)
I1211 11:34:26.263099 15296 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1211 11:34:32.608564 15296 solver.cpp:218] Iteration 42400 (15.7604 iter/s, 6.345s/100 iters), loss = 1.7944
I1211 11:34:32.608564 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:34:32.608564 15296 solver.cpp:237]     Train net output #1: loss = 1.7944 (* 1 = 1.7944 loss)
I1211 11:34:32.608564 15296 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1211 11:34:38.637974 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:34:38.891048 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42500.caffemodel
I1211 11:34:38.908057 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42500.solverstate
I1211 11:34:38.913049 15296 solver.cpp:330] Iteration 42500, Testing net (#0)
I1211 11:34:38.913049 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:34:40.432543  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:34:40.492584 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3524
I1211 11:34:40.492584 15296 solver.cpp:397]     Test net output #1: loss = 2.64359 (* 1 = 2.64359 loss)
I1211 11:34:40.552579 15296 solver.cpp:218] Iteration 42500 (12.5886 iter/s, 7.94372s/100 iters), loss = 1.70057
I1211 11:34:40.552579 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:34:40.552579 15296 solver.cpp:237]     Train net output #1: loss = 1.70057 (* 1 = 1.70057 loss)
I1211 11:34:40.552579 15296 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1211 11:34:46.893183 15296 solver.cpp:218] Iteration 42600 (15.771 iter/s, 6.34075s/100 iters), loss = 1.71804
I1211 11:34:46.894186 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:34:46.894186 15296 solver.cpp:237]     Train net output #1: loss = 1.71804 (* 1 = 1.71804 loss)
I1211 11:34:46.894186 15296 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1211 11:34:53.241755 15296 solver.cpp:218] Iteration 42700 (15.7534 iter/s, 6.34785s/100 iters), loss = 1.45963
I1211 11:34:53.241755 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:34:53.241755 15296 solver.cpp:237]     Train net output #1: loss = 1.45963 (* 1 = 1.45963 loss)
I1211 11:34:53.241755 15296 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1211 11:34:59.616478 15296 solver.cpp:218] Iteration 42800 (15.6883 iter/s, 6.37417s/100 iters), loss = 1.78716
I1211 11:34:59.616478 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:34:59.616478 15296 solver.cpp:237]     Train net output #1: loss = 1.78716 (* 1 = 1.78716 loss)
I1211 11:34:59.616478 15296 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1211 11:35:05.964998 15296 solver.cpp:218] Iteration 42900 (15.7538 iter/s, 6.34766s/100 iters), loss = 1.85493
I1211 11:35:05.964998 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:35:05.964998 15296 solver.cpp:237]     Train net output #1: loss = 1.85493 (* 1 = 1.85493 loss)
I1211 11:35:05.964998 15296 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1211 11:35:12.023581 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:35:12.278604 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43000.caffemodel
I1211 11:35:12.293612 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43000.solverstate
I1211 11:35:12.297612 15296 solver.cpp:330] Iteration 43000, Testing net (#0)
I1211 11:35:12.297612 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:35:13.837811  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:35:13.897819 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3682
I1211 11:35:13.897819 15296 solver.cpp:397]     Test net output #1: loss = 2.70254 (* 1 = 2.70254 loss)
I1211 11:35:13.958818 15296 solver.cpp:218] Iteration 43000 (12.5097 iter/s, 7.99381s/100 iters), loss = 1.76757
I1211 11:35:13.958818 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:35:13.958818 15296 solver.cpp:237]     Train net output #1: loss = 1.76757 (* 1 = 1.76757 loss)
I1211 11:35:13.958818 15296 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1211 11:35:20.321368 15296 solver.cpp:218] Iteration 43100 (15.7175 iter/s, 6.36233s/100 iters), loss = 1.61178
I1211 11:35:20.322369 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:35:20.322369 15296 solver.cpp:237]     Train net output #1: loss = 1.61178 (* 1 = 1.61178 loss)
I1211 11:35:20.322369 15296 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1211 11:35:26.688062 15296 solver.cpp:218] Iteration 43200 (15.7101 iter/s, 6.36533s/100 iters), loss = 1.53842
I1211 11:35:26.688062 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:35:26.688062 15296 solver.cpp:237]     Train net output #1: loss = 1.53842 (* 1 = 1.53842 loss)
I1211 11:35:26.688062 15296 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1211 11:35:33.055016 15296 solver.cpp:218] Iteration 43300 (15.7064 iter/s, 6.36684s/100 iters), loss = 1.91022
I1211 11:35:33.055016 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:35:33.055016 15296 solver.cpp:237]     Train net output #1: loss = 1.91022 (* 1 = 1.91022 loss)
I1211 11:35:33.055016 15296 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1211 11:35:39.410488 15296 solver.cpp:218] Iteration 43400 (15.7362 iter/s, 6.35479s/100 iters), loss = 1.58756
I1211 11:35:39.410488 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:35:39.410488 15296 solver.cpp:237]     Train net output #1: loss = 1.58756 (* 1 = 1.58756 loss)
I1211 11:35:39.410488 15296 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1211 11:35:45.449898 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:35:45.699921 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43500.caffemodel
I1211 11:35:45.715921 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43500.solverstate
I1211 11:35:45.719921 15296 solver.cpp:330] Iteration 43500, Testing net (#0)
I1211 11:35:45.719921 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:35:47.241056  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:35:47.301061 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3272
I1211 11:35:47.301061 15296 solver.cpp:397]     Test net output #1: loss = 2.85463 (* 1 = 2.85463 loss)
I1211 11:35:47.363060 15296 solver.cpp:218] Iteration 43500 (12.5758 iter/s, 7.9518s/100 iters), loss = 1.82925
I1211 11:35:47.363060 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:35:47.363060 15296 solver.cpp:237]     Train net output #1: loss = 1.82925 (* 1 = 1.82925 loss)
I1211 11:35:47.363060 15296 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1211 11:35:53.724365 15296 solver.cpp:218] Iteration 43600 (15.7203 iter/s, 6.36122s/100 iters), loss = 1.56978
I1211 11:35:53.724365 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:35:53.724365 15296 solver.cpp:237]     Train net output #1: loss = 1.56978 (* 1 = 1.56978 loss)
I1211 11:35:53.724365 15296 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1211 11:36:00.104903 15296 solver.cpp:218] Iteration 43700 (15.6738 iter/s, 6.38009s/100 iters), loss = 1.35658
I1211 11:36:00.104903 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:36:00.104903 15296 solver.cpp:237]     Train net output #1: loss = 1.35658 (* 1 = 1.35658 loss)
I1211 11:36:00.104903 15296 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1211 11:36:06.469384 15296 solver.cpp:218] Iteration 43800 (15.7137 iter/s, 6.36388s/100 iters), loss = 1.70911
I1211 11:36:06.469384 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:36:06.469384 15296 solver.cpp:237]     Train net output #1: loss = 1.70911 (* 1 = 1.70911 loss)
I1211 11:36:06.469384 15296 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1211 11:36:12.870858 15296 solver.cpp:218] Iteration 43900 (15.6228 iter/s, 6.40089s/100 iters), loss = 1.81672
I1211 11:36:12.870858 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:36:12.870858 15296 solver.cpp:237]     Train net output #1: loss = 1.81672 (* 1 = 1.81672 loss)
I1211 11:36:12.870858 15296 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1211 11:36:18.950299 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:36:19.201313 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44000.caffemodel
I1211 11:36:19.216312 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44000.solverstate
I1211 11:36:19.221313 15296 solver.cpp:330] Iteration 44000, Testing net (#0)
I1211 11:36:19.221313 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:36:20.740433  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:36:20.800441 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3548
I1211 11:36:20.800441 15296 solver.cpp:397]     Test net output #1: loss = 2.63155 (* 1 = 2.63155 loss)
I1211 11:36:20.860438 15296 solver.cpp:218] Iteration 44000 (12.5165 iter/s, 7.98943s/100 iters), loss = 1.82005
I1211 11:36:20.860438 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:36:20.860438 15296 solver.cpp:237]     Train net output #1: loss = 1.82005 (* 1 = 1.82005 loss)
I1211 11:36:20.860438 15296 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1211 11:36:27.228993 15296 solver.cpp:218] Iteration 44100 (15.7041 iter/s, 6.36774s/100 iters), loss = 1.51065
I1211 11:36:27.228993 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:36:27.228993 15296 solver.cpp:237]     Train net output #1: loss = 1.51065 (* 1 = 1.51065 loss)
I1211 11:36:27.228993 15296 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1211 11:36:33.649657 15296 solver.cpp:218] Iteration 44200 (15.5761 iter/s, 6.42008s/100 iters), loss = 1.4295
I1211 11:36:33.649657 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 11:36:33.649657 15296 solver.cpp:237]     Train net output #1: loss = 1.4295 (* 1 = 1.4295 loss)
I1211 11:36:33.649657 15296 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1211 11:36:40.071295 15296 solver.cpp:218] Iteration 44300 (15.5728 iter/s, 6.42147s/100 iters), loss = 1.76116
I1211 11:36:40.072293 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:36:40.072293 15296 solver.cpp:237]     Train net output #1: loss = 1.76116 (* 1 = 1.76116 loss)
I1211 11:36:40.072293 15296 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1211 11:36:46.614784 15296 solver.cpp:218] Iteration 44400 (15.2843 iter/s, 6.54267s/100 iters), loss = 1.71864
I1211 11:36:46.614784 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:36:46.614784 15296 solver.cpp:237]     Train net output #1: loss = 1.71864 (* 1 = 1.71864 loss)
I1211 11:36:46.614784 15296 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1211 11:36:52.769613 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:36:53.019737 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44500.caffemodel
I1211 11:36:53.033735 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44500.solverstate
I1211 11:36:53.038734 15296 solver.cpp:330] Iteration 44500, Testing net (#0)
I1211 11:36:53.038734 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:36:54.558209  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:36:54.618274 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2798
I1211 11:36:54.618274 15296 solver.cpp:397]     Test net output #1: loss = 3.06874 (* 1 = 3.06874 loss)
I1211 11:36:54.678267 15296 solver.cpp:218] Iteration 44500 (12.402 iter/s, 8.06321s/100 iters), loss = 1.60015
I1211 11:36:54.679280 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:36:54.679280 15296 solver.cpp:237]     Train net output #1: loss = 1.60015 (* 1 = 1.60015 loss)
I1211 11:36:54.679280 15296 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1211 11:37:01.007400 15296 solver.cpp:218] Iteration 44600 (15.8036 iter/s, 6.32769s/100 iters), loss = 1.51701
I1211 11:37:01.007400 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:37:01.007400 15296 solver.cpp:237]     Train net output #1: loss = 1.51701 (* 1 = 1.51701 loss)
I1211 11:37:01.007400 15296 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1211 11:37:07.341325 15296 solver.cpp:218] Iteration 44700 (15.7879 iter/s, 6.33398s/100 iters), loss = 1.25348
I1211 11:37:07.341325 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:37:07.341325 15296 solver.cpp:237]     Train net output #1: loss = 1.25348 (* 1 = 1.25348 loss)
I1211 11:37:07.341325 15296 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1211 11:37:13.670141 15296 solver.cpp:218] Iteration 44800 (15.8012 iter/s, 6.32862s/100 iters), loss = 1.80255
I1211 11:37:13.670141 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:37:13.670141 15296 solver.cpp:237]     Train net output #1: loss = 1.80255 (* 1 = 1.80255 loss)
I1211 11:37:13.670141 15296 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1211 11:37:20.008497 15296 solver.cpp:218] Iteration 44900 (15.7787 iter/s, 6.33764s/100 iters), loss = 1.59202
I1211 11:37:20.008497 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 11:37:20.008497 15296 solver.cpp:237]     Train net output #1: loss = 1.59202 (* 1 = 1.59202 loss)
I1211 11:37:20.008497 15296 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1211 11:37:26.060932 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:37:26.309962 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45000.caffemodel
I1211 11:37:26.325963 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45000.solverstate
I1211 11:37:26.329962 15296 solver.cpp:330] Iteration 45000, Testing net (#0)
I1211 11:37:26.329962 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:37:27.850155  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:37:27.910163 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4171
I1211 11:37:27.910163 15296 solver.cpp:397]     Test net output #1: loss = 2.15542 (* 1 = 2.15542 loss)
I1211 11:37:27.971165 15296 solver.cpp:218] Iteration 45000 (12.56 iter/s, 7.9618s/100 iters), loss = 1.82983
I1211 11:37:27.971165 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:37:27.971165 15296 solver.cpp:237]     Train net output #1: loss = 1.82983 (* 1 = 1.82983 loss)
I1211 11:37:27.971165 15296 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1211 11:37:34.305631 15296 solver.cpp:218] Iteration 45100 (15.7872 iter/s, 6.33425s/100 iters), loss = 1.58681
I1211 11:37:34.305631 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:37:34.305631 15296 solver.cpp:237]     Train net output #1: loss = 1.58681 (* 1 = 1.58681 loss)
I1211 11:37:34.305631 15296 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1211 11:37:40.670624 15296 solver.cpp:218] Iteration 45200 (15.7127 iter/s, 6.3643s/100 iters), loss = 1.35244
I1211 11:37:40.670624 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:37:40.670624 15296 solver.cpp:237]     Train net output #1: loss = 1.35244 (* 1 = 1.35244 loss)
I1211 11:37:40.670624 15296 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1211 11:37:47.044644 15296 solver.cpp:218] Iteration 45300 (15.6885 iter/s, 6.37408s/100 iters), loss = 1.66171
I1211 11:37:47.044644 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:37:47.044644 15296 solver.cpp:237]     Train net output #1: loss = 1.66171 (* 1 = 1.66171 loss)
I1211 11:37:47.044644 15296 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1211 11:37:53.534368 15296 solver.cpp:218] Iteration 45400 (15.4092 iter/s, 6.48962s/100 iters), loss = 1.77316
I1211 11:37:53.534368 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:37:53.534368 15296 solver.cpp:237]     Train net output #1: loss = 1.77316 (* 1 = 1.77316 loss)
I1211 11:37:53.534368 15296 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1211 11:37:59.763593 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:38:00.022629 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45500.caffemodel
I1211 11:38:00.037631 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45500.solverstate
I1211 11:38:00.042631 15296 solver.cpp:330] Iteration 45500, Testing net (#0)
I1211 11:38:00.042631 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:38:01.606847  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:38:01.668349 15296 solver.cpp:397]     Test net output #0: accuracy = 0.4577
I1211 11:38:01.668349 15296 solver.cpp:397]     Test net output #1: loss = 2.04165 (* 1 = 2.04165 loss)
I1211 11:38:01.730851 15296 solver.cpp:218] Iteration 45500 (12.2024 iter/s, 8.19511s/100 iters), loss = 1.58371
I1211 11:38:01.730851 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 11:38:01.730851 15296 solver.cpp:237]     Train net output #1: loss = 1.58371 (* 1 = 1.58371 loss)
I1211 11:38:01.730851 15296 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1211 11:38:08.279498 15296 solver.cpp:218] Iteration 45600 (15.2718 iter/s, 6.548s/100 iters), loss = 1.64235
I1211 11:38:08.279498 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:38:08.279498 15296 solver.cpp:237]     Train net output #1: loss = 1.64235 (* 1 = 1.64235 loss)
I1211 11:38:08.279498 15296 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1211 11:38:14.907625 15296 solver.cpp:218] Iteration 45700 (15.0883 iter/s, 6.62766s/100 iters), loss = 1.27724
I1211 11:38:14.907625 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:38:14.907625 15296 solver.cpp:237]     Train net output #1: loss = 1.27724 (* 1 = 1.27724 loss)
I1211 11:38:14.907625 15296 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1211 11:38:21.475529 15296 solver.cpp:218] Iteration 45800 (15.2265 iter/s, 6.56751s/100 iters), loss = 1.63983
I1211 11:38:21.475529 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:38:21.475529 15296 solver.cpp:237]     Train net output #1: loss = 1.63983 (* 1 = 1.63983 loss)
I1211 11:38:21.475529 15296 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1211 11:38:27.881486 15296 solver.cpp:218] Iteration 45900 (15.6112 iter/s, 6.40565s/100 iters), loss = 1.74259
I1211 11:38:27.881486 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:38:27.881486 15296 solver.cpp:237]     Train net output #1: loss = 1.74259 (* 1 = 1.74259 loss)
I1211 11:38:27.881486 15296 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1211 11:38:33.984725 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:38:34.235747 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46000.caffemodel
I1211 11:38:34.250747 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46000.solverstate
I1211 11:38:34.255746 15296 solver.cpp:330] Iteration 46000, Testing net (#0)
I1211 11:38:34.255746 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:38:35.791903  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:38:35.854918 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3973
I1211 11:38:35.854918 15296 solver.cpp:397]     Test net output #1: loss = 2.36162 (* 1 = 2.36162 loss)
I1211 11:38:35.918416 15296 solver.cpp:218] Iteration 46000 (12.4433 iter/s, 8.03648s/100 iters), loss = 1.75959
I1211 11:38:35.918416 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:38:35.918416 15296 solver.cpp:237]     Train net output #1: loss = 1.75959 (* 1 = 1.75959 loss)
I1211 11:38:35.918416 15296 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1211 11:38:42.294558 15296 solver.cpp:218] Iteration 46100 (15.6857 iter/s, 6.37523s/100 iters), loss = 1.76922
I1211 11:38:42.294558 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:38:42.294558 15296 solver.cpp:237]     Train net output #1: loss = 1.76922 (* 1 = 1.76922 loss)
I1211 11:38:42.294558 15296 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1211 11:38:48.754359 15296 solver.cpp:218] Iteration 46200 (15.4802 iter/s, 6.45986s/100 iters), loss = 1.21498
I1211 11:38:48.754359 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:38:48.754359 15296 solver.cpp:237]     Train net output #1: loss = 1.21498 (* 1 = 1.21498 loss)
I1211 11:38:48.754359 15296 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1211 11:38:55.146154 15296 solver.cpp:218] Iteration 46300 (15.6463 iter/s, 6.39129s/100 iters), loss = 1.78473
I1211 11:38:55.146154 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:38:55.146154 15296 solver.cpp:237]     Train net output #1: loss = 1.78473 (* 1 = 1.78473 loss)
I1211 11:38:55.146154 15296 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1211 11:39:01.621829 15296 solver.cpp:218] Iteration 46400 (15.4446 iter/s, 6.47475s/100 iters), loss = 1.66342
I1211 11:39:01.621829 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:39:01.621829 15296 solver.cpp:237]     Train net output #1: loss = 1.66342 (* 1 = 1.66342 loss)
I1211 11:39:01.621829 15296 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1211 11:39:07.705387 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:39:07.960901 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46500.caffemodel
I1211 11:39:07.976405 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46500.solverstate
I1211 11:39:07.980406 15296 solver.cpp:330] Iteration 46500, Testing net (#0)
I1211 11:39:07.980406 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:39:09.511497  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:39:09.572501 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3467
I1211 11:39:09.572501 15296 solver.cpp:397]     Test net output #1: loss = 2.72594 (* 1 = 2.72594 loss)
I1211 11:39:09.631505 15296 solver.cpp:218] Iteration 46500 (12.4844 iter/s, 8.01s/100 iters), loss = 1.81407
I1211 11:39:09.631505 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:39:09.631505 15296 solver.cpp:237]     Train net output #1: loss = 1.81407 (* 1 = 1.81407 loss)
I1211 11:39:09.631505 15296 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1211 11:39:16.003093 15296 solver.cpp:218] Iteration 46600 (15.6959 iter/s, 6.3711s/100 iters), loss = 1.64359
I1211 11:39:16.003093 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:39:16.003093 15296 solver.cpp:237]     Train net output #1: loss = 1.64359 (* 1 = 1.64359 loss)
I1211 11:39:16.003093 15296 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1211 11:39:22.422318 15296 solver.cpp:218] Iteration 46700 (15.5802 iter/s, 6.41841s/100 iters), loss = 1.4557
I1211 11:39:22.422318 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:39:22.422318 15296 solver.cpp:237]     Train net output #1: loss = 1.4557 (* 1 = 1.4557 loss)
I1211 11:39:22.422318 15296 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1211 11:39:28.859850 15296 solver.cpp:218] Iteration 46800 (15.536 iter/s, 6.43665s/100 iters), loss = 1.59464
I1211 11:39:28.859850 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:39:28.859850 15296 solver.cpp:237]     Train net output #1: loss = 1.59464 (* 1 = 1.59464 loss)
I1211 11:39:28.859850 15296 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1211 11:39:35.295394 15296 solver.cpp:218] Iteration 46900 (15.5395 iter/s, 6.43519s/100 iters), loss = 1.63648
I1211 11:39:35.295394 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 11:39:35.295394 15296 solver.cpp:237]     Train net output #1: loss = 1.63648 (* 1 = 1.63648 loss)
I1211 11:39:35.295394 15296 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1211 11:39:41.410816 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:39:41.663841 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47000.caffemodel
I1211 11:39:41.683864 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47000.solverstate
I1211 11:39:41.688845 15296 solver.cpp:330] Iteration 47000, Testing net (#0)
I1211 11:39:41.688845 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:39:43.225281  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:39:43.285284 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2628
I1211 11:39:43.285284 15296 solver.cpp:397]     Test net output #1: loss = 3.44681 (* 1 = 3.44681 loss)
I1211 11:39:43.347285 15296 solver.cpp:218] Iteration 47000 (12.4203 iter/s, 8.05132s/100 iters), loss = 1.80255
I1211 11:39:43.347285 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:39:43.347285 15296 solver.cpp:237]     Train net output #1: loss = 1.80255 (* 1 = 1.80255 loss)
I1211 11:39:43.347285 15296 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1211 11:39:49.770768 15296 solver.cpp:218] Iteration 47100 (15.5685 iter/s, 6.42321s/100 iters), loss = 1.54677
I1211 11:39:49.771270 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:39:49.771270 15296 solver.cpp:237]     Train net output #1: loss = 1.54677 (* 1 = 1.54677 loss)
I1211 11:39:49.771270 15296 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1211 11:39:56.155185 15296 solver.cpp:218] Iteration 47200 (15.6651 iter/s, 6.38364s/100 iters), loss = 1.31448
I1211 11:39:56.155185 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:39:56.155185 15296 solver.cpp:237]     Train net output #1: loss = 1.31448 (* 1 = 1.31448 loss)
I1211 11:39:56.155185 15296 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1211 11:40:02.592828 15296 solver.cpp:218] Iteration 47300 (15.5341 iter/s, 6.43746s/100 iters), loss = 1.79983
I1211 11:40:02.592828 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:40:02.592828 15296 solver.cpp:237]     Train net output #1: loss = 1.79983 (* 1 = 1.79983 loss)
I1211 11:40:02.592828 15296 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1211 11:40:09.012465 15296 solver.cpp:218] Iteration 47400 (15.5794 iter/s, 6.41875s/100 iters), loss = 1.7914
I1211 11:40:09.012465 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:40:09.012465 15296 solver.cpp:237]     Train net output #1: loss = 1.7914 (* 1 = 1.7914 loss)
I1211 11:40:09.012465 15296 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1211 11:40:15.198973 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:40:15.456984 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47500.caffemodel
I1211 11:40:15.472990 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47500.solverstate
I1211 11:40:15.477489 15296 solver.cpp:330] Iteration 47500, Testing net (#0)
I1211 11:40:15.477489 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:40:17.032145  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:40:17.095165 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3713
I1211 11:40:17.095165 15296 solver.cpp:397]     Test net output #1: loss = 2.5212 (* 1 = 2.5212 loss)
I1211 11:40:17.158164 15296 solver.cpp:218] Iteration 47500 (12.2769 iter/s, 8.14537s/100 iters), loss = 1.90161
I1211 11:40:17.158164 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:40:17.158164 15296 solver.cpp:237]     Train net output #1: loss = 1.90161 (* 1 = 1.90161 loss)
I1211 11:40:17.158164 15296 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1211 11:40:23.638698 15296 solver.cpp:218] Iteration 47600 (15.4324 iter/s, 6.47986s/100 iters), loss = 1.68276
I1211 11:40:23.638698 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:40:23.638698 15296 solver.cpp:237]     Train net output #1: loss = 1.68276 (* 1 = 1.68276 loss)
I1211 11:40:23.638698 15296 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1211 11:40:30.118728 15296 solver.cpp:218] Iteration 47700 (15.432 iter/s, 6.48003s/100 iters), loss = 1.35932
I1211 11:40:30.118728 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:40:30.118728 15296 solver.cpp:237]     Train net output #1: loss = 1.35932 (* 1 = 1.35932 loss)
I1211 11:40:30.118728 15296 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1211 11:40:36.532831 15296 solver.cpp:218] Iteration 47800 (15.5921 iter/s, 6.4135s/100 iters), loss = 1.7116
I1211 11:40:36.532831 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:40:36.532831 15296 solver.cpp:237]     Train net output #1: loss = 1.7116 (* 1 = 1.7116 loss)
I1211 11:40:36.532831 15296 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1211 11:40:42.975772 15296 solver.cpp:218] Iteration 47900 (15.5218 iter/s, 6.44255s/100 iters), loss = 1.82129
I1211 11:40:42.975772 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 11:40:42.975772 15296 solver.cpp:237]     Train net output #1: loss = 1.82129 (* 1 = 1.82129 loss)
I1211 11:40:42.975772 15296 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1211 11:40:49.119791 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:40:49.368803 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48000.caffemodel
I1211 11:40:49.384814 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48000.solverstate
I1211 11:40:49.389804 15296 solver.cpp:330] Iteration 48000, Testing net (#0)
I1211 11:40:49.389804 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:40:50.939924  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:40:51.000929 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3289
I1211 11:40:51.000929 15296 solver.cpp:397]     Test net output #1: loss = 2.74003 (* 1 = 2.74003 loss)
I1211 11:40:51.061928 15296 solver.cpp:218] Iteration 48000 (12.3682 iter/s, 8.08525s/100 iters), loss = 1.80934
I1211 11:40:51.061928 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:40:51.061928 15296 solver.cpp:237]     Train net output #1: loss = 1.80934 (* 1 = 1.80934 loss)
I1211 11:40:51.061928 15296 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1211 11:40:57.573446 15296 solver.cpp:218] Iteration 48100 (15.3593 iter/s, 6.51073s/100 iters), loss = 1.50161
I1211 11:40:57.573446 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 11:40:57.573446 15296 solver.cpp:237]     Train net output #1: loss = 1.50161 (* 1 = 1.50161 loss)
I1211 11:40:57.573446 15296 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1211 11:41:04.026908 15296 solver.cpp:218] Iteration 48200 (15.4949 iter/s, 6.45373s/100 iters), loss = 1.33617
I1211 11:41:04.026908 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:41:04.026908 15296 solver.cpp:237]     Train net output #1: loss = 1.33617 (* 1 = 1.33617 loss)
I1211 11:41:04.026908 15296 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1211 11:41:10.434362 15296 solver.cpp:218] Iteration 48300 (15.6088 iter/s, 6.40663s/100 iters), loss = 1.77457
I1211 11:41:10.434362 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:41:10.434362 15296 solver.cpp:237]     Train net output #1: loss = 1.77457 (* 1 = 1.77457 loss)
I1211 11:41:10.434362 15296 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1211 11:41:16.842844 15296 solver.cpp:218] Iteration 48400 (15.6071 iter/s, 6.40733s/100 iters), loss = 1.63829
I1211 11:41:16.842844 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:41:16.842844 15296 solver.cpp:237]     Train net output #1: loss = 1.63829 (* 1 = 1.63829 loss)
I1211 11:41:16.842844 15296 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1211 11:41:22.963989 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:41:23.223074 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48500.caffemodel
I1211 11:41:23.240072 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48500.solverstate
I1211 11:41:23.244072 15296 solver.cpp:330] Iteration 48500, Testing net (#0)
I1211 11:41:23.244072 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:41:24.794420  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:41:24.854418 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3417
I1211 11:41:24.854418 15296 solver.cpp:397]     Test net output #1: loss = 2.71624 (* 1 = 2.71624 loss)
I1211 11:41:24.915094 15296 solver.cpp:218] Iteration 48500 (12.3876 iter/s, 8.07257s/100 iters), loss = 1.69411
I1211 11:41:24.915094 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:41:24.915094 15296 solver.cpp:237]     Train net output #1: loss = 1.69411 (* 1 = 1.69411 loss)
I1211 11:41:24.915094 15296 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1211 11:41:31.355197 15296 solver.cpp:218] Iteration 48600 (15.5303 iter/s, 6.43903s/100 iters), loss = 1.45202
I1211 11:41:31.355197 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:41:31.355197 15296 solver.cpp:237]     Train net output #1: loss = 1.45202 (* 1 = 1.45202 loss)
I1211 11:41:31.355197 15296 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1211 11:41:37.715831 15296 solver.cpp:218] Iteration 48700 (15.7226 iter/s, 6.36028s/100 iters), loss = 1.29689
I1211 11:41:37.715831 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:41:37.715831 15296 solver.cpp:237]     Train net output #1: loss = 1.29689 (* 1 = 1.29689 loss)
I1211 11:41:37.715831 15296 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1211 11:41:44.036931 15296 solver.cpp:218] Iteration 48800 (15.8195 iter/s, 6.3213s/100 iters), loss = 1.78651
I1211 11:41:44.037932 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 11:41:44.037932 15296 solver.cpp:237]     Train net output #1: loss = 1.78651 (* 1 = 1.78651 loss)
I1211 11:41:44.037932 15296 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1211 11:41:50.360384 15296 solver.cpp:218] Iteration 48900 (15.8176 iter/s, 6.32206s/100 iters), loss = 1.91521
I1211 11:41:50.360384 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:41:50.360384 15296 solver.cpp:237]     Train net output #1: loss = 1.91521 (* 1 = 1.91521 loss)
I1211 11:41:50.360384 15296 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1211 11:41:56.377837 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:41:56.629847 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49000.caffemodel
I1211 11:41:56.645350 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49000.solverstate
I1211 11:41:56.650352 15296 solver.cpp:330] Iteration 49000, Testing net (#0)
I1211 11:41:56.650352 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:41:58.169975  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:41:58.229979 15296 solver.cpp:397]     Test net output #0: accuracy = 0.2093
I1211 11:41:58.229979 15296 solver.cpp:397]     Test net output #1: loss = 3.9355 (* 1 = 3.9355 loss)
I1211 11:41:58.290982 15296 solver.cpp:218] Iteration 49000 (12.6102 iter/s, 7.9301s/100 iters), loss = 1.70425
I1211 11:41:58.290982 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 11:41:58.290982 15296 solver.cpp:237]     Train net output #1: loss = 1.70425 (* 1 = 1.70425 loss)
I1211 11:41:58.290982 15296 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1211 11:42:04.635422 15296 solver.cpp:218] Iteration 49100 (15.7628 iter/s, 6.34405s/100 iters), loss = 1.63229
I1211 11:42:04.635422 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 11:42:04.635422 15296 solver.cpp:237]     Train net output #1: loss = 1.63229 (* 1 = 1.63229 loss)
I1211 11:42:04.635422 15296 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1211 11:42:10.975852 15296 solver.cpp:218] Iteration 49200 (15.7736 iter/s, 6.3397s/100 iters), loss = 1.24791
I1211 11:42:10.975852 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 11:42:10.975852 15296 solver.cpp:237]     Train net output #1: loss = 1.24791 (* 1 = 1.24791 loss)
I1211 11:42:10.975852 15296 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1211 11:42:17.313349 15296 solver.cpp:218] Iteration 49300 (15.7785 iter/s, 6.33775s/100 iters), loss = 1.65663
I1211 11:42:17.313349 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 11:42:17.313349 15296 solver.cpp:237]     Train net output #1: loss = 1.65663 (* 1 = 1.65663 loss)
I1211 11:42:17.313349 15296 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1211 11:42:23.647830 15296 solver.cpp:218] Iteration 49400 (15.7888 iter/s, 6.33359s/100 iters), loss = 1.67617
I1211 11:42:23.647830 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:42:23.647830 15296 solver.cpp:237]     Train net output #1: loss = 1.67617 (* 1 = 1.67617 loss)
I1211 11:42:23.647830 15296 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1211 11:42:29.672376 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:42:29.922390 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49500.caffemodel
I1211 11:42:29.937894 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49500.solverstate
I1211 11:42:29.942394 15296 solver.cpp:330] Iteration 49500, Testing net (#0)
I1211 11:42:29.942394 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:42:31.462735  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:42:31.522734 15296 solver.cpp:397]     Test net output #0: accuracy = 0.336
I1211 11:42:31.522734 15296 solver.cpp:397]     Test net output #1: loss = 2.74616 (* 1 = 2.74616 loss)
I1211 11:42:31.582738 15296 solver.cpp:218] Iteration 49500 (12.6022 iter/s, 7.93512s/100 iters), loss = 1.75052
I1211 11:42:31.582738 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:42:31.582738 15296 solver.cpp:237]     Train net output #1: loss = 1.75052 (* 1 = 1.75052 loss)
I1211 11:42:31.583739 15296 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1211 11:42:37.909251 15296 solver.cpp:218] Iteration 49600 (15.8087 iter/s, 6.32565s/100 iters), loss = 1.47587
I1211 11:42:37.909251 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:42:37.909251 15296 solver.cpp:237]     Train net output #1: loss = 1.47587 (* 1 = 1.47587 loss)
I1211 11:42:37.909251 15296 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1211 11:42:44.238739 15296 solver.cpp:218] Iteration 49700 (15.8008 iter/s, 6.32881s/100 iters), loss = 1.25705
I1211 11:42:44.238739 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:42:44.238739 15296 solver.cpp:237]     Train net output #1: loss = 1.25705 (* 1 = 1.25705 loss)
I1211 11:42:44.238739 15296 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1211 11:42:50.568275 15296 solver.cpp:218] Iteration 49800 (15.8007 iter/s, 6.32884s/100 iters), loss = 1.6657
I1211 11:42:50.568275 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:42:50.568275 15296 solver.cpp:237]     Train net output #1: loss = 1.6657 (* 1 = 1.6657 loss)
I1211 11:42:50.568275 15296 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1211 11:42:56.898690 15296 solver.cpp:218] Iteration 49900 (15.7962 iter/s, 6.33066s/100 iters), loss = 1.72276
I1211 11:42:56.898690 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 11:42:56.898690 15296 solver.cpp:237]     Train net output #1: loss = 1.72276 (* 1 = 1.72276 loss)
I1211 11:42:56.898690 15296 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1211 11:43:02.915079 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:43:03.166105 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50000.caffemodel
I1211 11:43:03.180104 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50000.solverstate
I1211 11:43:03.185106 15296 solver.cpp:330] Iteration 50000, Testing net (#0)
I1211 11:43:03.185106 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:43:04.705238  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:43:04.765247 15296 solver.cpp:397]     Test net output #0: accuracy = 0.3325
I1211 11:43:04.765247 15296 solver.cpp:397]     Test net output #1: loss = 2.78487 (* 1 = 2.78487 loss)
I1211 11:43:04.826248 15296 solver.cpp:218] Iteration 50000 (12.6154 iter/s, 7.9268s/100 iters), loss = 1.72869
I1211 11:43:04.826248 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 11:43:04.826248 15296 solver.cpp:237]     Train net output #1: loss = 1.72869 (* 1 = 1.72869 loss)
I1211 11:43:04.826750 15296 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1211 11:43:04.826750 15296 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1211 11:43:11.216769 15296 solver.cpp:218] Iteration 50100 (15.6497 iter/s, 6.38991s/100 iters), loss = 1.2227
I1211 11:43:11.216769 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 11:43:11.216769 15296 solver.cpp:237]     Train net output #1: loss = 1.2227 (* 1 = 1.2227 loss)
I1211 11:43:11.216769 15296 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1211 11:43:17.689065 15296 solver.cpp:218] Iteration 50200 (15.4509 iter/s, 6.4721s/100 iters), loss = 0.937772
I1211 11:43:17.689065 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 11:43:17.689065 15296 solver.cpp:237]     Train net output #1: loss = 0.937772 (* 1 = 0.937772 loss)
I1211 11:43:17.689065 15296 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1211 11:43:24.181617 15296 solver.cpp:218] Iteration 50300 (15.4046 iter/s, 6.49159s/100 iters), loss = 1.23525
I1211 11:43:24.181617 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 11:43:24.181617 15296 solver.cpp:237]     Train net output #1: loss = 1.23525 (* 1 = 1.23525 loss)
I1211 11:43:24.181617 15296 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1211 11:43:30.617082 15296 solver.cpp:218] Iteration 50400 (15.5405 iter/s, 6.43479s/100 iters), loss = 1.17542
I1211 11:43:30.617082 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:43:30.617082 15296 solver.cpp:237]     Train net output #1: loss = 1.17542 (* 1 = 1.17542 loss)
I1211 11:43:30.617082 15296 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1211 11:43:36.756685 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:43:37.008702 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50500.caffemodel
I1211 11:43:37.023706 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50500.solverstate
I1211 11:43:37.028206 15296 solver.cpp:330] Iteration 50500, Testing net (#0)
I1211 11:43:37.028206 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:43:38.556843  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:43:38.618841 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6333
I1211 11:43:38.618841 15296 solver.cpp:397]     Test net output #1: loss = 1.27146 (* 1 = 1.27146 loss)
I1211 11:43:38.681850 15296 solver.cpp:218] Iteration 50500 (12.4004 iter/s, 8.06423s/100 iters), loss = 1.21127
I1211 11:43:38.681850 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 11:43:38.681850 15296 solver.cpp:237]     Train net output #1: loss = 1.21127 (* 1 = 1.21127 loss)
I1211 11:43:38.681850 15296 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1211 11:43:45.167603 15296 solver.cpp:218] Iteration 50600 (15.4187 iter/s, 6.48565s/100 iters), loss = 1.13391
I1211 11:43:45.167603 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:43:45.167603 15296 solver.cpp:237]     Train net output #1: loss = 1.13391 (* 1 = 1.13391 loss)
I1211 11:43:45.167603 15296 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1211 11:43:51.618338 15296 solver.cpp:218] Iteration 50700 (15.5032 iter/s, 6.45026s/100 iters), loss = 0.865766
I1211 11:43:51.618338 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:43:51.618338 15296 solver.cpp:237]     Train net output #1: loss = 0.865766 (* 1 = 0.865766 loss)
I1211 11:43:51.618338 15296 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1211 11:43:58.029208 15296 solver.cpp:218] Iteration 50800 (15.6005 iter/s, 6.41006s/100 iters), loss = 1.14176
I1211 11:43:58.029208 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:43:58.029208 15296 solver.cpp:237]     Train net output #1: loss = 1.14176 (* 1 = 1.14176 loss)
I1211 11:43:58.029208 15296 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1211 11:44:04.446249 15296 solver.cpp:218] Iteration 50900 (15.5845 iter/s, 6.41663s/100 iters), loss = 1.20801
I1211 11:44:04.446249 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:44:04.446249 15296 solver.cpp:237]     Train net output #1: loss = 1.20801 (* 1 = 1.20801 loss)
I1211 11:44:04.446249 15296 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1211 11:44:10.587719 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:44:10.844741 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51000.caffemodel
I1211 11:44:10.860741 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51000.solverstate
I1211 11:44:10.865742 15296 solver.cpp:330] Iteration 51000, Testing net (#0)
I1211 11:44:10.865742 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:44:12.421855  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:44:12.483862 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6361
I1211 11:44:12.483862 15296 solver.cpp:397]     Test net output #1: loss = 1.26916 (* 1 = 1.26916 loss)
I1211 11:44:12.545864 15296 solver.cpp:218] Iteration 51000 (12.3459 iter/s, 8.09987s/100 iters), loss = 1.05575
I1211 11:44:12.545864 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:44:12.545864 15296 solver.cpp:237]     Train net output #1: loss = 1.05575 (* 1 = 1.05575 loss)
I1211 11:44:12.545864 15296 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1211 11:44:18.972653 15296 solver.cpp:218] Iteration 51100 (15.5613 iter/s, 6.4262s/100 iters), loss = 1.01178
I1211 11:44:18.973655 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:44:18.973655 15296 solver.cpp:237]     Train net output #1: loss = 1.01178 (* 1 = 1.01178 loss)
I1211 11:44:18.973655 15296 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1211 11:44:25.468199 15296 solver.cpp:218] Iteration 51200 (15.3983 iter/s, 6.49421s/100 iters), loss = 0.772757
I1211 11:44:25.468199 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:44:25.468199 15296 solver.cpp:237]     Train net output #1: loss = 0.772757 (* 1 = 0.772757 loss)
I1211 11:44:25.468199 15296 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1211 11:44:31.965802 15296 solver.cpp:218] Iteration 51300 (15.3904 iter/s, 6.49757s/100 iters), loss = 1.04823
I1211 11:44:31.965802 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 11:44:31.965802 15296 solver.cpp:237]     Train net output #1: loss = 1.04823 (* 1 = 1.04823 loss)
I1211 11:44:31.965802 15296 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1211 11:44:38.386281 15296 solver.cpp:218] Iteration 51400 (15.5754 iter/s, 6.42037s/100 iters), loss = 1.10698
I1211 11:44:38.387281 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:44:38.387281 15296 solver.cpp:237]     Train net output #1: loss = 1.10698 (* 1 = 1.10698 loss)
I1211 11:44:38.387281 15296 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1211 11:44:44.534283 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:44:44.784797 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51500.caffemodel
I1211 11:44:44.800797 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51500.solverstate
I1211 11:44:44.804797 15296 solver.cpp:330] Iteration 51500, Testing net (#0)
I1211 11:44:44.804797 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:44:46.361915  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:44:46.422916 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6411
I1211 11:44:46.422916 15296 solver.cpp:397]     Test net output #1: loss = 1.22949 (* 1 = 1.22949 loss)
I1211 11:44:46.484922 15296 solver.cpp:218] Iteration 51500 (12.3496 iter/s, 8.09742s/100 iters), loss = 1.0683
I1211 11:44:46.484922 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:44:46.484922 15296 solver.cpp:237]     Train net output #1: loss = 1.0683 (* 1 = 1.0683 loss)
I1211 11:44:46.484922 15296 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1211 11:44:52.954522 15296 solver.cpp:218] Iteration 51600 (15.4567 iter/s, 6.46968s/100 iters), loss = 1.02475
I1211 11:44:52.954522 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 11:44:52.954522 15296 solver.cpp:237]     Train net output #1: loss = 1.02475 (* 1 = 1.02475 loss)
I1211 11:44:52.954522 15296 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1211 11:44:59.381983 15296 solver.cpp:218] Iteration 51700 (15.5613 iter/s, 6.42622s/100 iters), loss = 0.70685
I1211 11:44:59.381983 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:44:59.381983 15296 solver.cpp:237]     Train net output #1: loss = 0.70685 (* 1 = 0.70685 loss)
I1211 11:44:59.381983 15296 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1211 11:45:05.787940 15296 solver.cpp:218] Iteration 51800 (15.6105 iter/s, 6.40595s/100 iters), loss = 1.1043
I1211 11:45:05.787940 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:45:05.787940 15296 solver.cpp:237]     Train net output #1: loss = 1.1043 (* 1 = 1.1043 loss)
I1211 11:45:05.787940 15296 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1211 11:45:12.246579 15296 solver.cpp:218] Iteration 51900 (15.484 iter/s, 6.45826s/100 iters), loss = 1.07813
I1211 11:45:12.246579 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:45:12.246579 15296 solver.cpp:237]     Train net output #1: loss = 1.07813 (* 1 = 1.07813 loss)
I1211 11:45:12.246579 15296 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1211 11:45:18.334403 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:45:18.585420 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52000.caffemodel
I1211 11:45:18.601420 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52000.solverstate
I1211 11:45:18.605420 15296 solver.cpp:330] Iteration 52000, Testing net (#0)
I1211 11:45:18.605420 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:45:20.140586  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:45:20.200594 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6442
I1211 11:45:20.200594 15296 solver.cpp:397]     Test net output #1: loss = 1.24509 (* 1 = 1.24509 loss)
I1211 11:45:20.262097 15296 solver.cpp:218] Iteration 52000 (12.477 iter/s, 8.01473s/100 iters), loss = 0.975871
I1211 11:45:20.262097 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:45:20.262097 15296 solver.cpp:237]     Train net output #1: loss = 0.975871 (* 1 = 0.975871 loss)
I1211 11:45:20.262097 15296 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1211 11:45:26.759112 15296 solver.cpp:218] Iteration 52100 (15.3929 iter/s, 6.49649s/100 iters), loss = 0.985221
I1211 11:45:26.759112 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:45:26.759112 15296 solver.cpp:237]     Train net output #1: loss = 0.985221 (* 1 = 0.985221 loss)
I1211 11:45:26.759112 15296 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1211 11:45:33.211078 15296 solver.cpp:218] Iteration 52200 (15.4992 iter/s, 6.45196s/100 iters), loss = 0.735199
I1211 11:45:33.211078 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 11:45:33.211078 15296 solver.cpp:237]     Train net output #1: loss = 0.735199 (* 1 = 0.735199 loss)
I1211 11:45:33.211078 15296 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1211 11:45:39.701519 15296 solver.cpp:218] Iteration 52300 (15.4104 iter/s, 6.48911s/100 iters), loss = 1.09521
I1211 11:45:39.701519 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:45:39.701519 15296 solver.cpp:237]     Train net output #1: loss = 1.09521 (* 1 = 1.09521 loss)
I1211 11:45:39.701519 15296 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1211 11:45:46.206044 15296 solver.cpp:218] Iteration 52400 (15.375 iter/s, 6.50408s/100 iters), loss = 1.04837
I1211 11:45:46.206044 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 11:45:46.206044 15296 solver.cpp:237]     Train net output #1: loss = 1.04837 (* 1 = 1.04837 loss)
I1211 11:45:46.206044 15296 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1211 11:45:52.341758 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:45:52.592782 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52500.caffemodel
I1211 11:45:52.607781 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52500.solverstate
I1211 11:45:52.612782 15296 solver.cpp:330] Iteration 52500, Testing net (#0)
I1211 11:45:52.612782 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:45:54.146945  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:45:54.207965 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6427
I1211 11:45:54.207965 15296 solver.cpp:397]     Test net output #1: loss = 1.24902 (* 1 = 1.24902 loss)
I1211 11:45:54.269968 15296 solver.cpp:218] Iteration 52500 (12.4018 iter/s, 8.06337s/100 iters), loss = 0.962892
I1211 11:45:54.269968 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:45:54.269968 15296 solver.cpp:237]     Train net output #1: loss = 0.962892 (* 1 = 0.962892 loss)
I1211 11:45:54.269968 15296 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1211 11:46:00.707479 15296 solver.cpp:218] Iteration 52600 (15.5329 iter/s, 6.43794s/100 iters), loss = 1.00466
I1211 11:46:00.708480 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:46:00.708480 15296 solver.cpp:237]     Train net output #1: loss = 1.00466 (* 1 = 1.00466 loss)
I1211 11:46:00.708480 15296 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1211 11:46:07.173910 15296 solver.cpp:218] Iteration 52700 (15.4677 iter/s, 6.46509s/100 iters), loss = 0.706924
I1211 11:46:07.173910 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 11:46:07.173910 15296 solver.cpp:237]     Train net output #1: loss = 0.706924 (* 1 = 0.706924 loss)
I1211 11:46:07.173910 15296 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1211 11:46:13.652443 15296 solver.cpp:218] Iteration 52800 (15.4368 iter/s, 6.47801s/100 iters), loss = 1.03255
I1211 11:46:13.652443 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:46:13.652443 15296 solver.cpp:237]     Train net output #1: loss = 1.03255 (* 1 = 1.03255 loss)
I1211 11:46:13.652443 15296 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1211 11:46:20.062629 15296 solver.cpp:218] Iteration 52900 (15.6014 iter/s, 6.40966s/100 iters), loss = 1.00423
I1211 11:46:20.062629 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:46:20.062629 15296 solver.cpp:237]     Train net output #1: loss = 1.00423 (* 1 = 1.00423 loss)
I1211 11:46:20.062629 15296 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1211 11:46:26.110604 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:46:26.360625 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53000.caffemodel
I1211 11:46:26.375128 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53000.solverstate
I1211 11:46:26.379634 15296 solver.cpp:330] Iteration 53000, Testing net (#0)
I1211 11:46:26.379634 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:46:27.899746  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:46:27.960747 15296 solver.cpp:397]     Test net output #0: accuracy = 0.648
I1211 11:46:27.960747 15296 solver.cpp:397]     Test net output #1: loss = 1.23755 (* 1 = 1.23755 loss)
I1211 11:46:28.020754 15296 solver.cpp:218] Iteration 53000 (12.5665 iter/s, 7.95766s/100 iters), loss = 1.03111
I1211 11:46:28.020754 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:46:28.020754 15296 solver.cpp:237]     Train net output #1: loss = 1.03111 (* 1 = 1.03111 loss)
I1211 11:46:28.020754 15296 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1211 11:46:34.448941 15296 solver.cpp:218] Iteration 53100 (15.557 iter/s, 6.42799s/100 iters), loss = 0.890707
I1211 11:46:34.448941 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:46:34.448941 15296 solver.cpp:237]     Train net output #1: loss = 0.890707 (* 1 = 0.890707 loss)
I1211 11:46:34.448941 15296 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1211 11:46:40.798172 15296 solver.cpp:218] Iteration 53200 (15.7509 iter/s, 6.34884s/100 iters), loss = 0.813019
I1211 11:46:40.798172 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 11:46:40.798172 15296 solver.cpp:237]     Train net output #1: loss = 0.813019 (* 1 = 0.813019 loss)
I1211 11:46:40.798172 15296 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1211 11:46:47.137859 15296 solver.cpp:218] Iteration 53300 (15.775 iter/s, 6.33913s/100 iters), loss = 0.961495
I1211 11:46:47.137859 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:46:47.137859 15296 solver.cpp:237]     Train net output #1: loss = 0.961495 (* 1 = 0.961495 loss)
I1211 11:46:47.137859 15296 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1211 11:46:53.684494 15296 solver.cpp:218] Iteration 53400 (15.2769 iter/s, 6.54583s/100 iters), loss = 0.974613
I1211 11:46:53.684494 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:46:53.684986 15296 solver.cpp:237]     Train net output #1: loss = 0.974613 (* 1 = 0.974613 loss)
I1211 11:46:53.684986 15296 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1211 11:46:59.933231 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:47:00.194279 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53500.caffemodel
I1211 11:47:00.211278 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53500.solverstate
I1211 11:47:00.216281 15296 solver.cpp:330] Iteration 53500, Testing net (#0)
I1211 11:47:00.217279 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:47:01.788271  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:47:01.849781 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6541
I1211 11:47:01.849781 15296 solver.cpp:397]     Test net output #1: loss = 1.21354 (* 1 = 1.21354 loss)
I1211 11:47:01.910792 15296 solver.cpp:218] Iteration 53500 (12.1569 iter/s, 8.22577s/100 iters), loss = 0.972587
I1211 11:47:01.910792 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:47:01.910792 15296 solver.cpp:237]     Train net output #1: loss = 0.972587 (* 1 = 0.972587 loss)
I1211 11:47:01.910792 15296 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1211 11:47:08.486902 15296 solver.cpp:218] Iteration 53600 (15.2085 iter/s, 6.57527s/100 iters), loss = 0.861878
I1211 11:47:08.486902 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:47:08.486902 15296 solver.cpp:237]     Train net output #1: loss = 0.861878 (* 1 = 0.861878 loss)
I1211 11:47:08.486902 15296 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1211 11:47:15.058462 15296 solver.cpp:218] Iteration 53700 (15.2167 iter/s, 6.57173s/100 iters), loss = 0.77146
I1211 11:47:15.058462 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:47:15.058462 15296 solver.cpp:237]     Train net output #1: loss = 0.77146 (* 1 = 0.77146 loss)
I1211 11:47:15.058462 15296 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1211 11:47:21.522752 15296 solver.cpp:218] Iteration 53800 (15.4712 iter/s, 6.46362s/100 iters), loss = 0.942915
I1211 11:47:21.522752 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:47:21.522752 15296 solver.cpp:237]     Train net output #1: loss = 0.942915 (* 1 = 0.942915 loss)
I1211 11:47:21.522752 15296 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1211 11:47:27.881233 15296 solver.cpp:218] Iteration 53900 (15.728 iter/s, 6.35808s/100 iters), loss = 1.05813
I1211 11:47:27.881233 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 11:47:27.881233 15296 solver.cpp:237]     Train net output #1: loss = 1.05813 (* 1 = 1.05813 loss)
I1211 11:47:27.881233 15296 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1211 11:47:33.914875 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:47:34.165892 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54000.caffemodel
I1211 11:47:34.185894 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54000.solverstate
I1211 11:47:34.190901 15296 solver.cpp:330] Iteration 54000, Testing net (#0)
I1211 11:47:34.190901 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:47:35.722273  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:47:35.783273 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6447
I1211 11:47:35.783273 15296 solver.cpp:397]     Test net output #1: loss = 1.25347 (* 1 = 1.25347 loss)
I1211 11:47:35.844281 15296 solver.cpp:218] Iteration 54000 (12.5596 iter/s, 7.96201s/100 iters), loss = 1.00132
I1211 11:47:35.844281 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:47:35.844281 15296 solver.cpp:237]     Train net output #1: loss = 1.00132 (* 1 = 1.00132 loss)
I1211 11:47:35.844281 15296 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1211 11:47:42.202692 15296 solver.cpp:218] Iteration 54100 (15.7276 iter/s, 6.35824s/100 iters), loss = 0.842487
I1211 11:47:42.202692 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:47:42.202692 15296 solver.cpp:237]     Train net output #1: loss = 0.842487 (* 1 = 0.842487 loss)
I1211 11:47:42.202692 15296 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1211 11:47:48.557792 15296 solver.cpp:218] Iteration 54200 (15.7371 iter/s, 6.35441s/100 iters), loss = 0.729981
I1211 11:47:48.557792 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:47:48.557792 15296 solver.cpp:237]     Train net output #1: loss = 0.729981 (* 1 = 0.729981 loss)
I1211 11:47:48.557792 15296 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1211 11:47:54.915318 15296 solver.cpp:218] Iteration 54300 (15.7291 iter/s, 6.35766s/100 iters), loss = 1.01734
I1211 11:47:54.915318 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:47:54.915318 15296 solver.cpp:237]     Train net output #1: loss = 1.01734 (* 1 = 1.01734 loss)
I1211 11:47:54.915318 15296 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1211 11:48:01.290287 15296 solver.cpp:218] Iteration 54400 (15.689 iter/s, 6.37389s/100 iters), loss = 0.923959
I1211 11:48:01.290287 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:48:01.290287 15296 solver.cpp:237]     Train net output #1: loss = 0.923959 (* 1 = 0.923959 loss)
I1211 11:48:01.290287 15296 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1211 11:48:07.334866 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:48:07.585927 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54500.caffemodel
I1211 11:48:07.601909 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54500.solverstate
I1211 11:48:07.606427 15296 solver.cpp:330] Iteration 54500, Testing net (#0)
I1211 11:48:07.606427 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:48:09.131449  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:48:09.191462 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6432
I1211 11:48:09.191462 15296 solver.cpp:397]     Test net output #1: loss = 1.25847 (* 1 = 1.25847 loss)
I1211 11:48:09.252116 15296 solver.cpp:218] Iteration 54500 (12.5602 iter/s, 7.96164s/100 iters), loss = 0.863251
I1211 11:48:09.252116 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 11:48:09.252116 15296 solver.cpp:237]     Train net output #1: loss = 0.863251 (* 1 = 0.863251 loss)
I1211 11:48:09.252116 15296 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1211 11:48:15.606086 15296 solver.cpp:218] Iteration 54600 (15.739 iter/s, 6.35366s/100 iters), loss = 0.855652
I1211 11:48:15.606586 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:48:15.606586 15296 solver.cpp:237]     Train net output #1: loss = 0.855652 (* 1 = 0.855652 loss)
I1211 11:48:15.606586 15296 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1211 11:48:21.948540 15296 solver.cpp:218] Iteration 54700 (15.7672 iter/s, 6.34227s/100 iters), loss = 0.668375
I1211 11:48:21.948540 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:48:21.948540 15296 solver.cpp:237]     Train net output #1: loss = 0.668375 (* 1 = 0.668375 loss)
I1211 11:48:21.948540 15296 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1211 11:48:28.297350 15296 solver.cpp:218] Iteration 54800 (15.7524 iter/s, 6.34824s/100 iters), loss = 0.955083
I1211 11:48:28.297350 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:48:28.297350 15296 solver.cpp:237]     Train net output #1: loss = 0.955083 (* 1 = 0.955083 loss)
I1211 11:48:28.297350 15296 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1211 11:48:34.648243 15296 solver.cpp:218] Iteration 54900 (15.7484 iter/s, 6.34984s/100 iters), loss = 0.94126
I1211 11:48:34.648243 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:48:34.648243 15296 solver.cpp:237]     Train net output #1: loss = 0.94126 (* 1 = 0.94126 loss)
I1211 11:48:34.648243 15296 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1211 11:48:40.690768 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:48:40.941783 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55000.caffemodel
I1211 11:48:40.956784 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55000.solverstate
I1211 11:48:40.961784 15296 solver.cpp:330] Iteration 55000, Testing net (#0)
I1211 11:48:40.961784 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:48:42.485927  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:48:42.545920 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6387
I1211 11:48:42.545920 15296 solver.cpp:397]     Test net output #1: loss = 1.28626 (* 1 = 1.28626 loss)
I1211 11:48:42.606920 15296 solver.cpp:218] Iteration 55000 (12.565 iter/s, 7.9586s/100 iters), loss = 0.83701
I1211 11:48:42.606920 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:48:42.606920 15296 solver.cpp:237]     Train net output #1: loss = 0.83701 (* 1 = 0.83701 loss)
I1211 11:48:42.606920 15296 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1211 11:48:48.943423 15296 solver.cpp:218] Iteration 55100 (15.7832 iter/s, 6.33587s/100 iters), loss = 0.900778
I1211 11:48:48.943423 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:48:48.943423 15296 solver.cpp:237]     Train net output #1: loss = 0.900778 (* 1 = 0.900778 loss)
I1211 11:48:48.943423 15296 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1211 11:48:55.306169 15296 solver.cpp:218] Iteration 55200 (15.7181 iter/s, 6.36209s/100 iters), loss = 0.645748
I1211 11:48:55.306169 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:48:55.306169 15296 solver.cpp:237]     Train net output #1: loss = 0.645748 (* 1 = 0.645748 loss)
I1211 11:48:55.306169 15296 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1211 11:49:01.653693 15296 solver.cpp:218] Iteration 55300 (15.7549 iter/s, 6.34722s/100 iters), loss = 0.991222
I1211 11:49:01.653693 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:49:01.653693 15296 solver.cpp:237]     Train net output #1: loss = 0.991222 (* 1 = 0.991222 loss)
I1211 11:49:01.653693 15296 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1211 11:49:08.039294 15296 solver.cpp:218] Iteration 55400 (15.6602 iter/s, 6.3856s/100 iters), loss = 0.907566
I1211 11:49:08.039294 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 11:49:08.039294 15296 solver.cpp:237]     Train net output #1: loss = 0.907566 (* 1 = 0.907566 loss)
I1211 11:49:08.039294 15296 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1211 11:49:14.086603 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:49:14.337173 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55500.caffemodel
I1211 11:49:14.353173 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55500.solverstate
I1211 11:49:14.358176 15296 solver.cpp:330] Iteration 55500, Testing net (#0)
I1211 11:49:14.358176 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:49:15.879221  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:49:15.939769 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6419
I1211 11:49:15.939769 15296 solver.cpp:397]     Test net output #1: loss = 1.27557 (* 1 = 1.27557 loss)
I1211 11:49:16.001768 15296 solver.cpp:218] Iteration 55500 (12.5607 iter/s, 7.96132s/100 iters), loss = 0.913288
I1211 11:49:16.001768 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:49:16.001768 15296 solver.cpp:237]     Train net output #1: loss = 0.913288 (* 1 = 0.913288 loss)
I1211 11:49:16.001768 15296 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1211 11:49:22.341454 15296 solver.cpp:218] Iteration 55600 (15.7735 iter/s, 6.33976s/100 iters), loss = 0.865436
I1211 11:49:22.341454 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:49:22.341454 15296 solver.cpp:237]     Train net output #1: loss = 0.865436 (* 1 = 0.865436 loss)
I1211 11:49:22.341454 15296 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1211 11:49:28.708817 15296 solver.cpp:218] Iteration 55700 (15.7075 iter/s, 6.36637s/100 iters), loss = 0.59186
I1211 11:49:28.708817 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 11:49:28.708817 15296 solver.cpp:237]     Train net output #1: loss = 0.59186 (* 1 = 0.59186 loss)
I1211 11:49:28.708817 15296 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1211 11:49:35.081360 15296 solver.cpp:218] Iteration 55800 (15.6932 iter/s, 6.37217s/100 iters), loss = 0.941797
I1211 11:49:35.081360 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:49:35.081360 15296 solver.cpp:237]     Train net output #1: loss = 0.941797 (* 1 = 0.941797 loss)
I1211 11:49:35.081360 15296 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1211 11:49:41.432435 15296 solver.cpp:218] Iteration 55900 (15.7471 iter/s, 6.35036s/100 iters), loss = 0.873427
I1211 11:49:41.432435 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 11:49:41.432435 15296 solver.cpp:237]     Train net output #1: loss = 0.873427 (* 1 = 0.873427 loss)
I1211 11:49:41.432435 15296 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1211 11:49:47.470399 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:49:47.721410 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56000.caffemodel
I1211 11:49:47.736913 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56000.solverstate
I1211 11:49:47.741417 15296 solver.cpp:330] Iteration 56000, Testing net (#0)
I1211 11:49:47.741417 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:49:49.269551  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:49:49.330554 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6314
I1211 11:49:49.330554 15296 solver.cpp:397]     Test net output #1: loss = 1.31949 (* 1 = 1.31949 loss)
I1211 11:49:49.391556 15296 solver.cpp:218] Iteration 56000 (12.564 iter/s, 7.95923s/100 iters), loss = 0.89007
I1211 11:49:49.391556 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:49:49.391556 15296 solver.cpp:237]     Train net output #1: loss = 0.89007 (* 1 = 0.89007 loss)
I1211 11:49:49.391556 15296 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1211 11:49:55.739176 15296 solver.cpp:218] Iteration 56100 (15.7566 iter/s, 6.34655s/100 iters), loss = 0.888633
I1211 11:49:55.739176 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:49:55.739176 15296 solver.cpp:237]     Train net output #1: loss = 0.888633 (* 1 = 0.888633 loss)
I1211 11:49:55.739176 15296 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1211 11:50:02.152293 15296 solver.cpp:218] Iteration 56200 (15.5942 iter/s, 6.41266s/100 iters), loss = 0.610933
I1211 11:50:02.152293 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 11:50:02.152293 15296 solver.cpp:237]     Train net output #1: loss = 0.610933 (* 1 = 0.610933 loss)
I1211 11:50:02.152293 15296 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1211 11:50:08.554630 15296 solver.cpp:218] Iteration 56300 (15.6194 iter/s, 6.4023s/100 iters), loss = 0.866223
I1211 11:50:08.554630 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:50:08.554630 15296 solver.cpp:237]     Train net output #1: loss = 0.866223 (* 1 = 0.866223 loss)
I1211 11:50:08.554630 15296 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1211 11:50:14.930316 15296 solver.cpp:218] Iteration 56400 (15.6858 iter/s, 6.3752s/100 iters), loss = 0.904512
I1211 11:50:14.930316 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:50:14.930316 15296 solver.cpp:237]     Train net output #1: loss = 0.904512 (* 1 = 0.904512 loss)
I1211 11:50:14.930316 15296 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1211 11:50:20.990151 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:50:21.241276 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56500.caffemodel
I1211 11:50:21.257289 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56500.solverstate
I1211 11:50:21.262284 15296 solver.cpp:330] Iteration 56500, Testing net (#0)
I1211 11:50:21.262284 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:50:22.786658  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:50:22.847702 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6455
I1211 11:50:22.847702 15296 solver.cpp:397]     Test net output #1: loss = 1.28245 (* 1 = 1.28245 loss)
I1211 11:50:22.908355 15296 solver.cpp:218] Iteration 56500 (12.5359 iter/s, 7.97709s/100 iters), loss = 0.811404
I1211 11:50:22.908355 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:50:22.908355 15296 solver.cpp:237]     Train net output #1: loss = 0.811404 (* 1 = 0.811404 loss)
I1211 11:50:22.908355 15296 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1211 11:50:29.294314 15296 solver.cpp:218] Iteration 56600 (15.6587 iter/s, 6.38621s/100 iters), loss = 0.849187
I1211 11:50:29.294314 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:50:29.294314 15296 solver.cpp:237]     Train net output #1: loss = 0.849187 (* 1 = 0.849187 loss)
I1211 11:50:29.294314 15296 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1211 11:50:35.674222 15296 solver.cpp:218] Iteration 56700 (15.6751 iter/s, 6.37956s/100 iters), loss = 0.642846
I1211 11:50:35.674222 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:50:35.674222 15296 solver.cpp:237]     Train net output #1: loss = 0.642846 (* 1 = 0.642846 loss)
I1211 11:50:35.675223 15296 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1211 11:50:42.044033 15296 solver.cpp:218] Iteration 56800 (15.7012 iter/s, 6.36893s/100 iters), loss = 0.906269
I1211 11:50:42.044033 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:50:42.044033 15296 solver.cpp:237]     Train net output #1: loss = 0.906269 (* 1 = 0.906269 loss)
I1211 11:50:42.044033 15296 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1211 11:50:48.450769 15296 solver.cpp:218] Iteration 56900 (15.6097 iter/s, 6.40625s/100 iters), loss = 0.894091
I1211 11:50:48.451270 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:50:48.451270 15296 solver.cpp:237]     Train net output #1: loss = 0.894091 (* 1 = 0.894091 loss)
I1211 11:50:48.451270 15296 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1211 11:50:54.514286 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:50:54.764297 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57000.caffemodel
I1211 11:50:54.779300 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57000.solverstate
I1211 11:50:54.784301 15296 solver.cpp:330] Iteration 57000, Testing net (#0)
I1211 11:50:54.784301 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:50:56.310430  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:50:56.371444 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6431
I1211 11:50:56.371444 15296 solver.cpp:397]     Test net output #1: loss = 1.27245 (* 1 = 1.27245 loss)
I1211 11:50:56.432435 15296 solver.cpp:218] Iteration 57000 (12.5289 iter/s, 7.98153s/100 iters), loss = 0.875073
I1211 11:50:56.432435 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:50:56.432435 15296 solver.cpp:237]     Train net output #1: loss = 0.875073 (* 1 = 0.875073 loss)
I1211 11:50:56.432435 15296 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1211 11:51:02.810851 15296 solver.cpp:218] Iteration 57100 (15.6803 iter/s, 6.37743s/100 iters), loss = 0.850502
I1211 11:51:02.810851 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:51:02.810851 15296 solver.cpp:237]     Train net output #1: loss = 0.850502 (* 1 = 0.850502 loss)
I1211 11:51:02.810851 15296 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1211 11:51:09.196849 15296 solver.cpp:218] Iteration 57200 (15.6598 iter/s, 6.38576s/100 iters), loss = 0.713744
I1211 11:51:09.196849 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 11:51:09.196849 15296 solver.cpp:237]     Train net output #1: loss = 0.713744 (* 1 = 0.713744 loss)
I1211 11:51:09.196849 15296 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1211 11:51:15.598139 15296 solver.cpp:218] Iteration 57300 (15.6237 iter/s, 6.40052s/100 iters), loss = 0.960912
I1211 11:51:15.598139 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:51:15.598139 15296 solver.cpp:237]     Train net output #1: loss = 0.960912 (* 1 = 0.960912 loss)
I1211 11:51:15.598139 15296 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1211 11:51:22.023614 15296 solver.cpp:218] Iteration 57400 (15.5646 iter/s, 6.42482s/100 iters), loss = 1.03949
I1211 11:51:22.023614 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:51:22.023614 15296 solver.cpp:237]     Train net output #1: loss = 1.03949 (* 1 = 1.03949 loss)
I1211 11:51:22.023614 15296 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1211 11:51:28.110087 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:51:28.359097 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57500.caffemodel
I1211 11:51:28.375102 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57500.solverstate
I1211 11:51:28.380101 15296 solver.cpp:330] Iteration 57500, Testing net (#0)
I1211 11:51:28.380101 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:51:29.926241  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:51:29.987243 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6381
I1211 11:51:29.987243 15296 solver.cpp:397]     Test net output #1: loss = 1.30331 (* 1 = 1.30331 loss)
I1211 11:51:30.048256 15296 solver.cpp:218] Iteration 57500 (12.4623 iter/s, 8.02419s/100 iters), loss = 0.753301
I1211 11:51:30.048256 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:51:30.048256 15296 solver.cpp:237]     Train net output #1: loss = 0.753301 (* 1 = 0.753301 loss)
I1211 11:51:30.048256 15296 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1211 11:51:36.488931 15296 solver.cpp:218] Iteration 57600 (15.5274 iter/s, 6.44024s/100 iters), loss = 0.803666
I1211 11:51:36.488931 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:51:36.488931 15296 solver.cpp:237]     Train net output #1: loss = 0.803666 (* 1 = 0.803666 loss)
I1211 11:51:36.488931 15296 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1211 11:51:42.859455 15296 solver.cpp:218] Iteration 57700 (15.6982 iter/s, 6.37014s/100 iters), loss = 0.652265
I1211 11:51:42.859455 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 11:51:42.859455 15296 solver.cpp:237]     Train net output #1: loss = 0.652265 (* 1 = 0.652265 loss)
I1211 11:51:42.859455 15296 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1211 11:51:49.208780 15296 solver.cpp:218] Iteration 57800 (15.7505 iter/s, 6.34901s/100 iters), loss = 0.949893
I1211 11:51:49.208780 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:51:49.208780 15296 solver.cpp:237]     Train net output #1: loss = 0.949893 (* 1 = 0.949893 loss)
I1211 11:51:49.208780 15296 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1211 11:51:55.567802 15296 solver.cpp:218] Iteration 57900 (15.7281 iter/s, 6.35806s/100 iters), loss = 0.90295
I1211 11:51:55.567802 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:51:55.567802 15296 solver.cpp:237]     Train net output #1: loss = 0.90295 (* 1 = 0.90295 loss)
I1211 11:51:55.567802 15296 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1211 11:52:01.600134 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:52:01.850673 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58000.caffemodel
I1211 11:52:01.865674 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58000.solverstate
I1211 11:52:01.869674 15296 solver.cpp:330] Iteration 58000, Testing net (#0)
I1211 11:52:01.869674 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:52:03.390975  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:52:03.451750 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6384
I1211 11:52:03.451750 15296 solver.cpp:397]     Test net output #1: loss = 1.29028 (* 1 = 1.29028 loss)
I1211 11:52:03.512284 15296 solver.cpp:218] Iteration 58000 (12.587 iter/s, 7.94472s/100 iters), loss = 0.900733
I1211 11:52:03.512284 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:52:03.512284 15296 solver.cpp:237]     Train net output #1: loss = 0.900733 (* 1 = 0.900733 loss)
I1211 11:52:03.512284 15296 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1211 11:52:09.860599 15296 solver.cpp:218] Iteration 58100 (15.7548 iter/s, 6.34726s/100 iters), loss = 0.796835
I1211 11:52:09.860599 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:52:09.860599 15296 solver.cpp:237]     Train net output #1: loss = 0.796835 (* 1 = 0.796835 loss)
I1211 11:52:09.860599 15296 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1211 11:52:16.238296 15296 solver.cpp:218] Iteration 58200 (15.6797 iter/s, 6.37767s/100 iters), loss = 0.685369
I1211 11:52:16.238296 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 11:52:16.238296 15296 solver.cpp:237]     Train net output #1: loss = 0.685369 (* 1 = 0.685369 loss)
I1211 11:52:16.238296 15296 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1211 11:52:22.580914 15296 solver.cpp:218] Iteration 58300 (15.7683 iter/s, 6.34184s/100 iters), loss = 0.865579
I1211 11:52:22.580914 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:52:22.580914 15296 solver.cpp:237]     Train net output #1: loss = 0.865579 (* 1 = 0.865579 loss)
I1211 11:52:22.580914 15296 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1211 11:52:28.938452 15296 solver.cpp:218] Iteration 58400 (15.7295 iter/s, 6.35746s/100 iters), loss = 0.88474
I1211 11:52:28.938452 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:52:28.938452 15296 solver.cpp:237]     Train net output #1: loss = 0.88474 (* 1 = 0.88474 loss)
I1211 11:52:28.938452 15296 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1211 11:52:34.981003 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:52:35.231026 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58500.caffemodel
I1211 11:52:35.246026 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58500.solverstate
I1211 11:52:35.251026 15296 solver.cpp:330] Iteration 58500, Testing net (#0)
I1211 11:52:35.251026 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:52:36.805253  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:52:36.868250 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6211
I1211 11:52:36.868250 15296 solver.cpp:397]     Test net output #1: loss = 1.38543 (* 1 = 1.38543 loss)
I1211 11:52:36.931259 15296 solver.cpp:218] Iteration 58500 (12.5119 iter/s, 7.9924s/100 iters), loss = 0.790053
I1211 11:52:36.931259 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:52:36.931259 15296 solver.cpp:237]     Train net output #1: loss = 0.790053 (* 1 = 0.790053 loss)
I1211 11:52:36.931259 15296 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1211 11:52:43.412866 15296 solver.cpp:218] Iteration 58600 (15.429 iter/s, 6.48128s/100 iters), loss = 0.807896
I1211 11:52:43.413867 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:52:43.413867 15296 solver.cpp:237]     Train net output #1: loss = 0.807896 (* 1 = 0.807896 loss)
I1211 11:52:43.413867 15296 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1211 11:52:49.858314 15296 solver.cpp:218] Iteration 58700 (15.5173 iter/s, 6.44444s/100 iters), loss = 0.617485
I1211 11:52:49.858314 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 11:52:49.858314 15296 solver.cpp:237]     Train net output #1: loss = 0.617485 (* 1 = 0.617485 loss)
I1211 11:52:49.858314 15296 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1211 11:52:56.340080 15296 solver.cpp:218] Iteration 58800 (15.4289 iter/s, 6.48134s/100 iters), loss = 0.826669
I1211 11:52:56.340080 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:52:56.340080 15296 solver.cpp:237]     Train net output #1: loss = 0.826669 (* 1 = 0.826669 loss)
I1211 11:52:56.340080 15296 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1211 11:53:02.811574 15296 solver.cpp:218] Iteration 58900 (15.4533 iter/s, 6.4711s/100 iters), loss = 0.878572
I1211 11:53:02.811574 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:53:02.811574 15296 solver.cpp:237]     Train net output #1: loss = 0.878572 (* 1 = 0.878572 loss)
I1211 11:53:02.811574 15296 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1211 11:53:08.972071 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:53:09.230093 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59000.caffemodel
I1211 11:53:09.247092 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59000.solverstate
I1211 11:53:09.252094 15296 solver.cpp:330] Iteration 59000, Testing net (#0)
I1211 11:53:09.252094 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:53:10.808230  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:53:10.869230 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6091
I1211 11:53:10.869230 15296 solver.cpp:397]     Test net output #1: loss = 1.43363 (* 1 = 1.43363 loss)
I1211 11:53:10.931237 15296 solver.cpp:218] Iteration 59000 (12.3171 iter/s, 8.11879s/100 iters), loss = 0.762908
I1211 11:53:10.931237 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 11:53:10.931237 15296 solver.cpp:237]     Train net output #1: loss = 0.762908 (* 1 = 0.762908 loss)
I1211 11:53:10.931237 15296 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1211 11:53:17.415824 15296 solver.cpp:218] Iteration 59100 (15.4216 iter/s, 6.48441s/100 iters), loss = 0.749395
I1211 11:53:17.415824 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:53:17.415824 15296 solver.cpp:237]     Train net output #1: loss = 0.749395 (* 1 = 0.749395 loss)
I1211 11:53:17.415824 15296 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1211 11:53:23.867347 15296 solver.cpp:218] Iteration 59200 (15.5013 iter/s, 6.45106s/100 iters), loss = 0.734657
I1211 11:53:23.867347 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:53:23.867347 15296 solver.cpp:237]     Train net output #1: loss = 0.734657 (* 1 = 0.734657 loss)
I1211 11:53:23.867347 15296 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1211 11:53:30.338853 15296 solver.cpp:218] Iteration 59300 (15.4534 iter/s, 6.47108s/100 iters), loss = 0.916655
I1211 11:53:30.338853 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:53:30.338853 15296 solver.cpp:237]     Train net output #1: loss = 0.916655 (* 1 = 0.916655 loss)
I1211 11:53:30.338853 15296 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1211 11:53:36.800370 15296 solver.cpp:218] Iteration 59400 (15.4788 iter/s, 6.46045s/100 iters), loss = 0.936721
I1211 11:53:36.800370 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:53:36.800370 15296 solver.cpp:237]     Train net output #1: loss = 0.936721 (* 1 = 0.936721 loss)
I1211 11:53:36.800370 15296 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1211 11:53:42.936324 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:53:43.195577 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59500.caffemodel
I1211 11:53:43.212638 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59500.solverstate
I1211 11:53:43.217638 15296 solver.cpp:330] Iteration 59500, Testing net (#0)
I1211 11:53:43.217638 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:53:44.760164  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:53:44.820188 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6065
I1211 11:53:44.820188 15296 solver.cpp:397]     Test net output #1: loss = 1.42973 (* 1 = 1.42973 loss)
I1211 11:53:44.881203 15296 solver.cpp:218] Iteration 59500 (12.3754 iter/s, 8.08053s/100 iters), loss = 0.732237
I1211 11:53:44.881203 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:53:44.881203 15296 solver.cpp:237]     Train net output #1: loss = 0.732237 (* 1 = 0.732237 loss)
I1211 11:53:44.881203 15296 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1211 11:53:51.338150 15296 solver.cpp:218] Iteration 59600 (15.4893 iter/s, 6.45605s/100 iters), loss = 0.852082
I1211 11:53:51.338150 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:53:51.338150 15296 solver.cpp:237]     Train net output #1: loss = 0.852082 (* 1 = 0.852082 loss)
I1211 11:53:51.338150 15296 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1211 11:53:57.789690 15296 solver.cpp:218] Iteration 59700 (15.5007 iter/s, 6.45131s/100 iters), loss = 0.617857
I1211 11:53:57.789690 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 11:53:57.789690 15296 solver.cpp:237]     Train net output #1: loss = 0.617857 (* 1 = 0.617857 loss)
I1211 11:53:57.789690 15296 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1211 11:54:04.228467 15296 solver.cpp:218] Iteration 59800 (15.533 iter/s, 6.43791s/100 iters), loss = 0.898147
I1211 11:54:04.228467 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:54:04.228467 15296 solver.cpp:237]     Train net output #1: loss = 0.898147 (* 1 = 0.898147 loss)
I1211 11:54:04.228467 15296 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1211 11:54:10.686275 15296 solver.cpp:218] Iteration 59900 (15.4859 iter/s, 6.45747s/100 iters), loss = 0.822197
I1211 11:54:10.686275 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:54:10.686275 15296 solver.cpp:237]     Train net output #1: loss = 0.822197 (* 1 = 0.822197 loss)
I1211 11:54:10.686275 15296 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1211 11:54:16.843792 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:54:17.101812 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60000.caffemodel
I1211 11:54:17.119814 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60000.solverstate
I1211 11:54:17.125816 15296 solver.cpp:330] Iteration 60000, Testing net (#0)
I1211 11:54:17.125816 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:54:18.673935  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:54:18.735939 15296 solver.cpp:397]     Test net output #0: accuracy = 0.628
I1211 11:54:18.735939 15296 solver.cpp:397]     Test net output #1: loss = 1.36101 (* 1 = 1.36101 loss)
I1211 11:54:18.797938 15296 solver.cpp:218] Iteration 60000 (12.3283 iter/s, 8.11144s/100 iters), loss = 0.877353
I1211 11:54:18.797938 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 11:54:18.797938 15296 solver.cpp:237]     Train net output #1: loss = 0.877353 (* 1 = 0.877353 loss)
I1211 11:54:18.797938 15296 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1211 11:54:25.258805 15296 solver.cpp:218] Iteration 60100 (15.4778 iter/s, 6.46085s/100 iters), loss = 0.840339
I1211 11:54:25.258805 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:54:25.258805 15296 solver.cpp:237]     Train net output #1: loss = 0.840339 (* 1 = 0.840339 loss)
I1211 11:54:25.258805 15296 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1211 11:54:31.663617 15296 solver.cpp:218] Iteration 60200 (15.6152 iter/s, 6.40401s/100 iters), loss = 0.690654
I1211 11:54:31.663617 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 11:54:31.663617 15296 solver.cpp:237]     Train net output #1: loss = 0.690654 (* 1 = 0.690654 loss)
I1211 11:54:31.663617 15296 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1211 11:54:38.072526 15296 solver.cpp:218] Iteration 60300 (15.6046 iter/s, 6.40836s/100 iters), loss = 0.931848
I1211 11:54:38.072526 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:54:38.072526 15296 solver.cpp:237]     Train net output #1: loss = 0.931848 (* 1 = 0.931848 loss)
I1211 11:54:38.072526 15296 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1211 11:54:44.470098 15296 solver.cpp:218] Iteration 60400 (15.6314 iter/s, 6.39738s/100 iters), loss = 0.763495
I1211 11:54:44.470098 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:54:44.470098 15296 solver.cpp:237]     Train net output #1: loss = 0.763495 (* 1 = 0.763495 loss)
I1211 11:54:44.470098 15296 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1211 11:54:50.554723 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:54:50.803745 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60500.caffemodel
I1211 11:54:50.819743 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60500.solverstate
I1211 11:54:50.825744 15296 solver.cpp:330] Iteration 60500, Testing net (#0)
I1211 11:54:50.825744 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:54:52.359887  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:54:52.419890 15296 solver.cpp:397]     Test net output #0: accuracy = 0.609
I1211 11:54:52.419890 15296 solver.cpp:397]     Test net output #1: loss = 1.41334 (* 1 = 1.41334 loss)
I1211 11:54:52.481778 15296 solver.cpp:218] Iteration 60500 (12.4828 iter/s, 8.01101s/100 iters), loss = 0.779799
I1211 11:54:52.481778 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:54:52.481778 15296 solver.cpp:237]     Train net output #1: loss = 0.779799 (* 1 = 0.779799 loss)
I1211 11:54:52.481778 15296 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1211 11:54:58.858248 15296 solver.cpp:218] Iteration 60600 (15.6847 iter/s, 6.37566s/100 iters), loss = 0.812472
I1211 11:54:58.858248 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:54:58.858248 15296 solver.cpp:237]     Train net output #1: loss = 0.812472 (* 1 = 0.812472 loss)
I1211 11:54:58.858248 15296 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1211 11:55:05.283852 15296 solver.cpp:218] Iteration 60700 (15.563 iter/s, 6.42551s/100 iters), loss = 0.633212
I1211 11:55:05.283852 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 11:55:05.283852 15296 solver.cpp:237]     Train net output #1: loss = 0.633212 (* 1 = 0.633212 loss)
I1211 11:55:05.283852 15296 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1211 11:55:11.661422 15296 solver.cpp:218] Iteration 60800 (15.6825 iter/s, 6.37653s/100 iters), loss = 0.997126
I1211 11:55:11.661422 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 11:55:11.661422 15296 solver.cpp:237]     Train net output #1: loss = 0.997126 (* 1 = 0.997126 loss)
I1211 11:55:11.661422 15296 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1211 11:55:18.129066 15296 solver.cpp:218] Iteration 60900 (15.4609 iter/s, 6.46792s/100 iters), loss = 0.876247
I1211 11:55:18.130066 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:55:18.130066 15296 solver.cpp:237]     Train net output #1: loss = 0.876247 (* 1 = 0.876247 loss)
I1211 11:55:18.130066 15296 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1211 11:55:24.208039 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:55:24.464546 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61000.caffemodel
I1211 11:55:24.480546 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61000.solverstate
I1211 11:55:24.485548 15296 solver.cpp:330] Iteration 61000, Testing net (#0)
I1211 11:55:24.485548 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:55:26.012676  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:55:26.072680 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5945
I1211 11:55:26.072680 15296 solver.cpp:397]     Test net output #1: loss = 1.51355 (* 1 = 1.51355 loss)
I1211 11:55:26.133575 15296 solver.cpp:218] Iteration 61000 (12.4953 iter/s, 8.00304s/100 iters), loss = 0.815706
I1211 11:55:26.133575 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:55:26.133575 15296 solver.cpp:237]     Train net output #1: loss = 0.815706 (* 1 = 0.815706 loss)
I1211 11:55:26.133575 15296 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1211 11:55:32.523138 15296 solver.cpp:218] Iteration 61100 (15.6494 iter/s, 6.39004s/100 iters), loss = 0.81283
I1211 11:55:32.524138 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:55:32.524138 15296 solver.cpp:237]     Train net output #1: loss = 0.81283 (* 1 = 0.81283 loss)
I1211 11:55:32.524138 15296 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1211 11:55:38.882665 15296 solver.cpp:218] Iteration 61200 (15.7277 iter/s, 6.35823s/100 iters), loss = 0.590752
I1211 11:55:38.882665 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 11:55:38.882665 15296 solver.cpp:237]     Train net output #1: loss = 0.590752 (* 1 = 0.590752 loss)
I1211 11:55:38.882665 15296 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1211 11:55:45.211632 15296 solver.cpp:218] Iteration 61300 (15.8018 iter/s, 6.3284s/100 iters), loss = 0.932048
I1211 11:55:45.211632 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:55:45.211632 15296 solver.cpp:237]     Train net output #1: loss = 0.932048 (* 1 = 0.932048 loss)
I1211 11:55:45.211632 15296 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1211 11:55:51.546587 15296 solver.cpp:218] Iteration 61400 (15.7842 iter/s, 6.33546s/100 iters), loss = 0.935825
I1211 11:55:51.547588 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:55:51.547588 15296 solver.cpp:237]     Train net output #1: loss = 0.935825 (* 1 = 0.935825 loss)
I1211 11:55:51.547588 15296 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1211 11:55:57.607148 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:55:57.856158 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61500.caffemodel
I1211 11:55:57.871157 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61500.solverstate
I1211 11:55:57.877159 15296 solver.cpp:330] Iteration 61500, Testing net (#0)
I1211 11:55:57.877159 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:55:59.421283  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:55:59.483281 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6116
I1211 11:55:59.483281 15296 solver.cpp:397]     Test net output #1: loss = 1.43971 (* 1 = 1.43971 loss)
I1211 11:55:59.546290 15296 solver.cpp:218] Iteration 61500 (12.5019 iter/s, 7.99879s/100 iters), loss = 0.75438
I1211 11:55:59.546290 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 11:55:59.546290 15296 solver.cpp:237]     Train net output #1: loss = 0.75438 (* 1 = 0.75438 loss)
I1211 11:55:59.546290 15296 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1211 11:56:05.952829 15296 solver.cpp:218] Iteration 61600 (15.6098 iter/s, 6.40622s/100 iters), loss = 0.817189
I1211 11:56:05.952829 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:56:05.952829 15296 solver.cpp:237]     Train net output #1: loss = 0.817189 (* 1 = 0.817189 loss)
I1211 11:56:05.952829 15296 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1211 11:56:12.452622 15296 solver.cpp:218] Iteration 61700 (15.3864 iter/s, 6.49925s/100 iters), loss = 0.632149
I1211 11:56:12.452622 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:56:12.452622 15296 solver.cpp:237]     Train net output #1: loss = 0.632149 (* 1 = 0.632149 loss)
I1211 11:56:12.452622 15296 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1211 11:56:18.788120 15296 solver.cpp:218] Iteration 61800 (15.7844 iter/s, 6.33537s/100 iters), loss = 0.787258
I1211 11:56:18.788120 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:56:18.789121 15296 solver.cpp:237]     Train net output #1: loss = 0.787258 (* 1 = 0.787258 loss)
I1211 11:56:18.789121 15296 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1211 11:56:25.134944 15296 solver.cpp:218] Iteration 61900 (15.7593 iter/s, 6.34544s/100 iters), loss = 0.828813
I1211 11:56:25.134944 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 11:56:25.134944 15296 solver.cpp:237]     Train net output #1: loss = 0.828813 (* 1 = 0.828813 loss)
I1211 11:56:25.134944 15296 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1211 11:56:31.171427 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:56:31.422443 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62000.caffemodel
I1211 11:56:31.438450 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62000.solverstate
I1211 11:56:31.443459 15296 solver.cpp:330] Iteration 62000, Testing net (#0)
I1211 11:56:31.444452 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:56:32.964568  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:56:33.025573 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6137
I1211 11:56:33.025573 15296 solver.cpp:397]     Test net output #1: loss = 1.42694 (* 1 = 1.42694 loss)
I1211 11:56:33.087574 15296 solver.cpp:218] Iteration 62000 (12.5753 iter/s, 7.95211s/100 iters), loss = 0.722671
I1211 11:56:33.087574 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:56:33.087574 15296 solver.cpp:237]     Train net output #1: loss = 0.722671 (* 1 = 0.722671 loss)
I1211 11:56:33.087574 15296 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1211 11:56:39.441416 15296 solver.cpp:218] Iteration 62100 (15.7378 iter/s, 6.35415s/100 iters), loss = 0.801392
I1211 11:56:39.441416 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:56:39.441416 15296 solver.cpp:237]     Train net output #1: loss = 0.801392 (* 1 = 0.801392 loss)
I1211 11:56:39.441416 15296 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1211 11:56:45.779486 15296 solver.cpp:218] Iteration 62200 (15.7804 iter/s, 6.33697s/100 iters), loss = 0.643203
I1211 11:56:45.779486 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 11:56:45.779486 15296 solver.cpp:237]     Train net output #1: loss = 0.643203 (* 1 = 0.643203 loss)
I1211 11:56:45.779486 15296 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1211 11:56:52.129555 15296 solver.cpp:218] Iteration 62300 (15.7486 iter/s, 6.34977s/100 iters), loss = 0.805286
I1211 11:56:52.130054 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 11:56:52.130054 15296 solver.cpp:237]     Train net output #1: loss = 0.805286 (* 1 = 0.805286 loss)
I1211 11:56:52.130054 15296 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1211 11:56:58.469178 15296 solver.cpp:218] Iteration 62400 (15.7752 iter/s, 6.33908s/100 iters), loss = 0.815609
I1211 11:56:58.469178 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:56:58.469178 15296 solver.cpp:237]     Train net output #1: loss = 0.815609 (* 1 = 0.815609 loss)
I1211 11:56:58.469178 15296 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1211 11:57:04.518422 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:57:04.765992 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62500.caffemodel
I1211 11:57:04.780992 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62500.solverstate
I1211 11:57:04.785992 15296 solver.cpp:330] Iteration 62500, Testing net (#0)
I1211 11:57:04.785992 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:57:06.333037  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:57:06.393497 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5902
I1211 11:57:06.393497 15296 solver.cpp:397]     Test net output #1: loss = 1.52196 (* 1 = 1.52196 loss)
I1211 11:57:06.454100 15296 solver.cpp:218] Iteration 62500 (12.525 iter/s, 7.98406s/100 iters), loss = 0.658473
I1211 11:57:06.454100 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 11:57:06.454100 15296 solver.cpp:237]     Train net output #1: loss = 0.658473 (* 1 = 0.658473 loss)
I1211 11:57:06.454100 15296 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1211 11:57:12.949815 15296 solver.cpp:218] Iteration 62600 (15.3943 iter/s, 6.4959s/100 iters), loss = 0.786224
I1211 11:57:12.949815 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:57:12.949815 15296 solver.cpp:237]     Train net output #1: loss = 0.786224 (* 1 = 0.786224 loss)
I1211 11:57:12.949815 15296 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1211 11:57:19.341784 15296 solver.cpp:218] Iteration 62700 (15.6474 iter/s, 6.39083s/100 iters), loss = 0.495291
I1211 11:57:19.341784 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 11:57:19.341784 15296 solver.cpp:237]     Train net output #1: loss = 0.495291 (* 1 = 0.495291 loss)
I1211 11:57:19.341784 15296 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1211 11:57:25.731976 15296 solver.cpp:218] Iteration 62800 (15.65 iter/s, 6.38979s/100 iters), loss = 0.862977
I1211 11:57:25.731976 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:57:25.731976 15296 solver.cpp:237]     Train net output #1: loss = 0.862977 (* 1 = 0.862977 loss)
I1211 11:57:25.731976 15296 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1211 11:57:32.119858 15296 solver.cpp:218] Iteration 62900 (15.6559 iter/s, 6.38739s/100 iters), loss = 0.796332
I1211 11:57:32.119858 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 11:57:32.119858 15296 solver.cpp:237]     Train net output #1: loss = 0.796332 (* 1 = 0.796332 loss)
I1211 11:57:32.119858 15296 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1211 11:57:38.198364 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:57:38.447911 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63000.caffemodel
I1211 11:57:38.462448 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63000.solverstate
I1211 11:57:38.467450 15296 solver.cpp:330] Iteration 63000, Testing net (#0)
I1211 11:57:38.467450 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:57:40.001189  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:57:40.060724 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5991
I1211 11:57:40.060724 15296 solver.cpp:397]     Test net output #1: loss = 1.50664 (* 1 = 1.50664 loss)
I1211 11:57:40.122738 15296 solver.cpp:218] Iteration 63000 (12.4964 iter/s, 8.00231s/100 iters), loss = 0.889095
I1211 11:57:40.122738 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:57:40.122738 15296 solver.cpp:237]     Train net output #1: loss = 0.889095 (* 1 = 0.889095 loss)
I1211 11:57:40.122738 15296 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1211 11:57:46.475082 15296 solver.cpp:218] Iteration 63100 (15.7429 iter/s, 6.35209s/100 iters), loss = 0.783564
I1211 11:57:46.475082 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 11:57:46.475082 15296 solver.cpp:237]     Train net output #1: loss = 0.783564 (* 1 = 0.783564 loss)
I1211 11:57:46.475082 15296 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1211 11:57:52.805521 15296 solver.cpp:218] Iteration 63200 (15.7973 iter/s, 6.33021s/100 iters), loss = 0.630618
I1211 11:57:52.805521 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 11:57:52.805521 15296 solver.cpp:237]     Train net output #1: loss = 0.630618 (* 1 = 0.630618 loss)
I1211 11:57:52.805521 15296 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1211 11:57:59.138200 15296 solver.cpp:218] Iteration 63300 (15.7913 iter/s, 6.33261s/100 iters), loss = 0.884414
I1211 11:57:59.138200 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:57:59.138200 15296 solver.cpp:237]     Train net output #1: loss = 0.884414 (* 1 = 0.884414 loss)
I1211 11:57:59.138200 15296 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1211 11:58:05.468663 15296 solver.cpp:218] Iteration 63400 (15.7976 iter/s, 6.33009s/100 iters), loss = 0.931438
I1211 11:58:05.469665 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 11:58:05.469665 15296 solver.cpp:237]     Train net output #1: loss = 0.931438 (* 1 = 0.931438 loss)
I1211 11:58:05.469665 15296 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1211 11:58:11.484635 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:58:11.731189 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63500.caffemodel
I1211 11:58:11.746685 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63500.solverstate
I1211 11:58:11.751684 15296 solver.cpp:330] Iteration 63500, Testing net (#0)
I1211 11:58:11.751684 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:58:13.268195  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:58:13.328203 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6035
I1211 11:58:13.328203 15296 solver.cpp:397]     Test net output #1: loss = 1.48062 (* 1 = 1.48062 loss)
I1211 11:58:13.389196 15296 solver.cpp:218] Iteration 63500 (12.6272 iter/s, 7.91941s/100 iters), loss = 0.757708
I1211 11:58:13.389196 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:58:13.389196 15296 solver.cpp:237]     Train net output #1: loss = 0.757708 (* 1 = 0.757708 loss)
I1211 11:58:13.389196 15296 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1211 11:58:19.725139 15296 solver.cpp:218] Iteration 63600 (15.7847 iter/s, 6.33525s/100 iters), loss = 0.728862
I1211 11:58:19.725139 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:58:19.725139 15296 solver.cpp:237]     Train net output #1: loss = 0.728862 (* 1 = 0.728862 loss)
I1211 11:58:19.725139 15296 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1211 11:58:26.046866 15296 solver.cpp:218] Iteration 63700 (15.8189 iter/s, 6.32155s/100 iters), loss = 0.63486
I1211 11:58:26.046866 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:58:26.046866 15296 solver.cpp:237]     Train net output #1: loss = 0.63486 (* 1 = 0.63486 loss)
I1211 11:58:26.046866 15296 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1211 11:58:32.373302 15296 solver.cpp:218] Iteration 63800 (15.8078 iter/s, 6.326s/100 iters), loss = 0.697743
I1211 11:58:32.373302 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:58:32.373302 15296 solver.cpp:237]     Train net output #1: loss = 0.697743 (* 1 = 0.697743 loss)
I1211 11:58:32.373302 15296 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1211 11:58:38.702422 15296 solver.cpp:218] Iteration 63900 (15.7998 iter/s, 6.32918s/100 iters), loss = 1.00176
I1211 11:58:38.702422 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 11:58:38.702422 15296 solver.cpp:237]     Train net output #1: loss = 1.00176 (* 1 = 1.00176 loss)
I1211 11:58:38.702422 15296 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1211 11:58:44.722882 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:58:44.972908 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64000.caffemodel
I1211 11:58:44.988415 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64000.solverstate
I1211 11:58:44.992915 15296 solver.cpp:330] Iteration 64000, Testing net (#0)
I1211 11:58:44.992915 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:58:46.513926  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:58:46.573927 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6173
I1211 11:58:46.573927 15296 solver.cpp:397]     Test net output #1: loss = 1.44999 (* 1 = 1.44999 loss)
I1211 11:58:46.634933 15296 solver.cpp:218] Iteration 64000 (12.6071 iter/s, 7.93202s/100 iters), loss = 0.718652
I1211 11:58:46.634933 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:58:46.634933 15296 solver.cpp:237]     Train net output #1: loss = 0.718652 (* 1 = 0.718652 loss)
I1211 11:58:46.634933 15296 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1211 11:58:52.972412 15296 solver.cpp:218] Iteration 64100 (15.7819 iter/s, 6.33639s/100 iters), loss = 0.825104
I1211 11:58:52.972412 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 11:58:52.972412 15296 solver.cpp:237]     Train net output #1: loss = 0.825104 (* 1 = 0.825104 loss)
I1211 11:58:52.972412 15296 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1211 11:58:59.303838 15296 solver.cpp:218] Iteration 64200 (15.7951 iter/s, 6.33107s/100 iters), loss = 0.697614
I1211 11:58:59.303838 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 11:58:59.303838 15296 solver.cpp:237]     Train net output #1: loss = 0.697614 (* 1 = 0.697614 loss)
I1211 11:58:59.303838 15296 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1211 11:59:05.638491 15296 solver.cpp:218] Iteration 64300 (15.7875 iter/s, 6.33414s/100 iters), loss = 0.976348
I1211 11:59:05.638491 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:59:05.638491 15296 solver.cpp:237]     Train net output #1: loss = 0.976348 (* 1 = 0.976348 loss)
I1211 11:59:05.638491 15296 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1211 11:59:11.968989 15296 solver.cpp:218] Iteration 64400 (15.7968 iter/s, 6.3304s/100 iters), loss = 0.859026
I1211 11:59:11.968989 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:59:11.968989 15296 solver.cpp:237]     Train net output #1: loss = 0.859026 (* 1 = 0.859026 loss)
I1211 11:59:11.968989 15296 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1211 11:59:17.988448 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:59:18.236467 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64500.caffemodel
I1211 11:59:18.251467 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64500.solverstate
I1211 11:59:18.256469 15296 solver.cpp:330] Iteration 64500, Testing net (#0)
I1211 11:59:18.256469 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:59:19.775578  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:59:19.835582 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5916
I1211 11:59:19.835582 15296 solver.cpp:397]     Test net output #1: loss = 1.51913 (* 1 = 1.51913 loss)
I1211 11:59:19.896584 15296 solver.cpp:218] Iteration 64500 (12.6147 iter/s, 7.92724s/100 iters), loss = 0.837266
I1211 11:59:19.896584 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 11:59:19.896584 15296 solver.cpp:237]     Train net output #1: loss = 0.837266 (* 1 = 0.837266 loss)
I1211 11:59:19.896584 15296 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1211 11:59:26.234094 15296 solver.cpp:218] Iteration 64600 (15.7805 iter/s, 6.33695s/100 iters), loss = 0.743917
I1211 11:59:26.234094 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 11:59:26.234094 15296 solver.cpp:237]     Train net output #1: loss = 0.743917 (* 1 = 0.743917 loss)
I1211 11:59:26.234094 15296 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1211 11:59:32.568531 15296 solver.cpp:218] Iteration 64700 (15.7868 iter/s, 6.33439s/100 iters), loss = 0.749375
I1211 11:59:32.568531 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 11:59:32.568531 15296 solver.cpp:237]     Train net output #1: loss = 0.749375 (* 1 = 0.749375 loss)
I1211 11:59:32.568531 15296 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1211 11:59:38.906013 15296 solver.cpp:218] Iteration 64800 (15.7815 iter/s, 6.33654s/100 iters), loss = 0.920387
I1211 11:59:38.906013 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 11:59:38.906013 15296 solver.cpp:237]     Train net output #1: loss = 0.920387 (* 1 = 0.920387 loss)
I1211 11:59:38.906013 15296 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1211 11:59:45.242529 15296 solver.cpp:218] Iteration 64900 (15.7824 iter/s, 6.33619s/100 iters), loss = 0.861983
I1211 11:59:45.242529 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 11:59:45.242529 15296 solver.cpp:237]     Train net output #1: loss = 0.861983 (* 1 = 0.861983 loss)
I1211 11:59:45.242529 15296 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1211 11:59:51.267065 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:59:51.517096 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65000.caffemodel
I1211 11:59:51.532097 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65000.solverstate
I1211 11:59:51.537096 15296 solver.cpp:330] Iteration 65000, Testing net (#0)
I1211 11:59:51.537096 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 11:59:53.056223  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 11:59:53.116232 15296 solver.cpp:397]     Test net output #0: accuracy = 0.59
I1211 11:59:53.116232 15296 solver.cpp:397]     Test net output #1: loss = 1.53986 (* 1 = 1.53986 loss)
I1211 11:59:53.177232 15296 solver.cpp:218] Iteration 65000 (12.6034 iter/s, 7.93436s/100 iters), loss = 0.751005
I1211 11:59:53.177232 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 11:59:53.177232 15296 solver.cpp:237]     Train net output #1: loss = 0.751005 (* 1 = 0.751005 loss)
I1211 11:59:53.177232 15296 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1211 11:59:59.501749 15296 solver.cpp:218] Iteration 65100 (15.814 iter/s, 6.3235s/100 iters), loss = 0.990124
I1211 11:59:59.501749 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 11:59:59.501749 15296 solver.cpp:237]     Train net output #1: loss = 0.990124 (* 1 = 0.990124 loss)
I1211 11:59:59.501749 15296 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1211 12:00:05.868257 15296 solver.cpp:218] Iteration 65200 (15.7073 iter/s, 6.36649s/100 iters), loss = 0.636788
I1211 12:00:05.868257 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:00:05.868257 15296 solver.cpp:237]     Train net output #1: loss = 0.636788 (* 1 = 0.636788 loss)
I1211 12:00:05.868257 15296 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1211 12:00:12.201733 15296 solver.cpp:218] Iteration 65300 (15.7898 iter/s, 6.3332s/100 iters), loss = 0.832219
I1211 12:00:12.201733 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 12:00:12.201733 15296 solver.cpp:237]     Train net output #1: loss = 0.832219 (* 1 = 0.832219 loss)
I1211 12:00:12.201733 15296 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1211 12:00:18.535243 15296 solver.cpp:218] Iteration 65400 (15.79 iter/s, 6.33313s/100 iters), loss = 0.856239
I1211 12:00:18.535243 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:00:18.535243 15296 solver.cpp:237]     Train net output #1: loss = 0.856239 (* 1 = 0.856239 loss)
I1211 12:00:18.535243 15296 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1211 12:00:24.549789 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:00:24.798800 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65500.caffemodel
I1211 12:00:24.813804 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65500.solverstate
I1211 12:00:24.818804 15296 solver.cpp:330] Iteration 65500, Testing net (#0)
I1211 12:00:24.818804 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:00:26.337898  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:00:26.398403 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5512
I1211 12:00:26.398403 15296 solver.cpp:397]     Test net output #1: loss = 1.73173 (* 1 = 1.73173 loss)
I1211 12:00:26.458906 15296 solver.cpp:218] Iteration 65500 (12.6215 iter/s, 7.92296s/100 iters), loss = 0.873048
I1211 12:00:26.458906 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:00:26.458906 15296 solver.cpp:237]     Train net output #1: loss = 0.873048 (* 1 = 0.873048 loss)
I1211 12:00:26.458906 15296 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1211 12:00:32.804029 15296 solver.cpp:218] Iteration 65600 (15.7618 iter/s, 6.34444s/100 iters), loss = 0.856625
I1211 12:00:32.804029 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:00:32.804029 15296 solver.cpp:237]     Train net output #1: loss = 0.856625 (* 1 = 0.856625 loss)
I1211 12:00:32.804029 15296 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1211 12:00:39.148972 15296 solver.cpp:218] Iteration 65700 (15.7612 iter/s, 6.34471s/100 iters), loss = 0.563677
I1211 12:00:39.148972 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:00:39.148972 15296 solver.cpp:237]     Train net output #1: loss = 0.563677 (* 1 = 0.563677 loss)
I1211 12:00:39.148972 15296 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1211 12:00:45.501977 15296 solver.cpp:218] Iteration 65800 (15.7423 iter/s, 6.35233s/100 iters), loss = 0.834765
I1211 12:00:45.501977 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:00:45.501977 15296 solver.cpp:237]     Train net output #1: loss = 0.834765 (* 1 = 0.834765 loss)
I1211 12:00:45.501977 15296 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1211 12:00:51.841284 15296 solver.cpp:218] Iteration 65900 (15.7755 iter/s, 6.33894s/100 iters), loss = 1.06917
I1211 12:00:51.841284 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 12:00:51.841284 15296 solver.cpp:237]     Train net output #1: loss = 1.06917 (* 1 = 1.06917 loss)
I1211 12:00:51.841284 15296 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1211 12:00:57.863687 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:00:58.112704 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66000.caffemodel
I1211 12:00:58.128705 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66000.solverstate
I1211 12:00:58.133705 15296 solver.cpp:330] Iteration 66000, Testing net (#0)
I1211 12:00:58.133705 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:00:59.651849  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:00:59.711905 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5987
I1211 12:00:59.711905 15296 solver.cpp:397]     Test net output #1: loss = 1.50728 (* 1 = 1.50728 loss)
I1211 12:00:59.772889 15296 solver.cpp:218] Iteration 66000 (12.6088 iter/s, 7.93096s/100 iters), loss = 0.786087
I1211 12:00:59.772889 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:00:59.772889 15296 solver.cpp:237]     Train net output #1: loss = 0.786087 (* 1 = 0.786087 loss)
I1211 12:00:59.772889 15296 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1211 12:01:06.102859 15296 solver.cpp:218] Iteration 66100 (15.7992 iter/s, 6.32943s/100 iters), loss = 0.793074
I1211 12:01:06.102859 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:01:06.102859 15296 solver.cpp:237]     Train net output #1: loss = 0.793074 (* 1 = 0.793074 loss)
I1211 12:01:06.102859 15296 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1211 12:01:12.429797 15296 solver.cpp:218] Iteration 66200 (15.805 iter/s, 6.3271s/100 iters), loss = 0.602897
I1211 12:01:12.429797 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:01:12.429797 15296 solver.cpp:237]     Train net output #1: loss = 0.602897 (* 1 = 0.602897 loss)
I1211 12:01:12.429797 15296 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1211 12:01:18.761245 15296 solver.cpp:218] Iteration 66300 (15.7972 iter/s, 6.33024s/100 iters), loss = 0.820191
I1211 12:01:18.761245 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:01:18.761245 15296 solver.cpp:237]     Train net output #1: loss = 0.820191 (* 1 = 0.820191 loss)
I1211 12:01:18.761245 15296 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1211 12:01:25.090700 15296 solver.cpp:218] Iteration 66400 (15.8004 iter/s, 6.32894s/100 iters), loss = 1.02107
I1211 12:01:25.090700 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 12:01:25.090700 15296 solver.cpp:237]     Train net output #1: loss = 1.02107 (* 1 = 1.02107 loss)
I1211 12:01:25.090700 15296 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1211 12:01:31.104611 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:01:31.351846 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66500.caffemodel
I1211 12:01:31.366845 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66500.solverstate
I1211 12:01:31.371845 15296 solver.cpp:330] Iteration 66500, Testing net (#0)
I1211 12:01:31.371845 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:01:32.890024  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:01:32.951035 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6047
I1211 12:01:32.951035 15296 solver.cpp:397]     Test net output #1: loss = 1.45489 (* 1 = 1.45489 loss)
I1211 12:01:33.012539 15296 solver.cpp:218] Iteration 66500 (12.6238 iter/s, 7.92156s/100 iters), loss = 0.893141
I1211 12:01:33.012539 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:01:33.012539 15296 solver.cpp:237]     Train net output #1: loss = 0.893141 (* 1 = 0.893141 loss)
I1211 12:01:33.012539 15296 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1211 12:01:39.355921 15296 solver.cpp:218] Iteration 66600 (15.7655 iter/s, 6.34297s/100 iters), loss = 0.821104
I1211 12:01:39.355921 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:01:39.355921 15296 solver.cpp:237]     Train net output #1: loss = 0.821104 (* 1 = 0.821104 loss)
I1211 12:01:39.355921 15296 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1211 12:01:45.693735 15296 solver.cpp:218] Iteration 66700 (15.7798 iter/s, 6.33723s/100 iters), loss = 0.627343
I1211 12:01:45.693735 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:01:45.693735 15296 solver.cpp:237]     Train net output #1: loss = 0.627343 (* 1 = 0.627343 loss)
I1211 12:01:45.693735 15296 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1211 12:01:52.035605 15296 solver.cpp:218] Iteration 66800 (15.7683 iter/s, 6.34186s/100 iters), loss = 0.821073
I1211 12:01:52.035605 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:01:52.035605 15296 solver.cpp:237]     Train net output #1: loss = 0.821073 (* 1 = 0.821073 loss)
I1211 12:01:52.035605 15296 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1211 12:01:58.381168 15296 solver.cpp:218] Iteration 66900 (15.7592 iter/s, 6.3455s/100 iters), loss = 0.910601
I1211 12:01:58.381168 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 12:01:58.381168 15296 solver.cpp:237]     Train net output #1: loss = 0.910601 (* 1 = 0.910601 loss)
I1211 12:01:58.381168 15296 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1211 12:02:04.406893 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:02:04.657918 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67000.caffemodel
I1211 12:02:04.672921 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67000.solverstate
I1211 12:02:04.677920 15296 solver.cpp:330] Iteration 67000, Testing net (#0)
I1211 12:02:04.677920 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:02:06.198227  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:02:06.258235 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6056
I1211 12:02:06.258235 15296 solver.cpp:397]     Test net output #1: loss = 1.46277 (* 1 = 1.46277 loss)
I1211 12:02:06.318238 15296 solver.cpp:218] Iteration 67000 (12.5997 iter/s, 7.93667s/100 iters), loss = 0.732663
I1211 12:02:06.318238 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:02:06.318238 15296 solver.cpp:237]     Train net output #1: loss = 0.732663 (* 1 = 0.732663 loss)
I1211 12:02:06.319241 15296 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1211 12:02:12.652025 15296 solver.cpp:218] Iteration 67100 (15.7908 iter/s, 6.3328s/100 iters), loss = 0.711425
I1211 12:02:12.652025 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:02:12.652025 15296 solver.cpp:237]     Train net output #1: loss = 0.711425 (* 1 = 0.711425 loss)
I1211 12:02:12.652025 15296 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1211 12:02:18.990757 15296 solver.cpp:218] Iteration 67200 (15.7757 iter/s, 6.33887s/100 iters), loss = 0.646223
I1211 12:02:18.991758 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:02:18.991758 15296 solver.cpp:237]     Train net output #1: loss = 0.646223 (* 1 = 0.646223 loss)
I1211 12:02:18.991758 15296 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1211 12:02:25.330556 15296 solver.cpp:218] Iteration 67300 (15.7763 iter/s, 6.33862s/100 iters), loss = 0.953997
I1211 12:02:25.330556 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:02:25.330556 15296 solver.cpp:237]     Train net output #1: loss = 0.953997 (* 1 = 0.953997 loss)
I1211 12:02:25.330556 15296 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1211 12:02:31.667548 15296 solver.cpp:218] Iteration 67400 (15.7818 iter/s, 6.33643s/100 iters), loss = 0.813005
I1211 12:02:31.667548 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:02:31.667548 15296 solver.cpp:237]     Train net output #1: loss = 0.813005 (* 1 = 0.813005 loss)
I1211 12:02:31.667548 15296 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1211 12:02:37.685192 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:02:37.934211 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67500.caffemodel
I1211 12:02:37.949211 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67500.solverstate
I1211 12:02:37.954212 15296 solver.cpp:330] Iteration 67500, Testing net (#0)
I1211 12:02:37.954212 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:02:39.472427  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:02:39.532429 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5806
I1211 12:02:39.532429 15296 solver.cpp:397]     Test net output #1: loss = 1.56358 (* 1 = 1.56358 loss)
I1211 12:02:39.593451 15296 solver.cpp:218] Iteration 67500 (12.617 iter/s, 7.9258s/100 iters), loss = 0.733494
I1211 12:02:39.593451 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:02:39.593451 15296 solver.cpp:237]     Train net output #1: loss = 0.733494 (* 1 = 0.733494 loss)
I1211 12:02:39.593451 15296 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1211 12:02:45.932224 15296 solver.cpp:218] Iteration 67600 (15.7779 iter/s, 6.33797s/100 iters), loss = 0.829434
I1211 12:02:45.932224 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:02:45.932224 15296 solver.cpp:237]     Train net output #1: loss = 0.829434 (* 1 = 0.829434 loss)
I1211 12:02:45.932224 15296 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1211 12:02:52.257949 15296 solver.cpp:218] Iteration 67700 (15.8073 iter/s, 6.32621s/100 iters), loss = 0.5667
I1211 12:02:52.258950 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:02:52.258950 15296 solver.cpp:237]     Train net output #1: loss = 0.5667 (* 1 = 0.5667 loss)
I1211 12:02:52.258950 15296 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1211 12:02:58.598865 15296 solver.cpp:218] Iteration 67800 (15.7738 iter/s, 6.33961s/100 iters), loss = 0.847853
I1211 12:02:58.598865 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:02:58.598865 15296 solver.cpp:237]     Train net output #1: loss = 0.847853 (* 1 = 0.847853 loss)
I1211 12:02:58.598865 15296 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1211 12:03:04.940136 15296 solver.cpp:218] Iteration 67900 (15.7691 iter/s, 6.3415s/100 iters), loss = 0.874423
I1211 12:03:04.940136 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:03:04.940136 15296 solver.cpp:237]     Train net output #1: loss = 0.874423 (* 1 = 0.874423 loss)
I1211 12:03:04.940136 15296 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1211 12:03:10.950871 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:03:11.199900 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68000.caffemodel
I1211 12:03:11.214901 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68000.solverstate
I1211 12:03:11.218900 15296 solver.cpp:330] Iteration 68000, Testing net (#0)
I1211 12:03:11.218900 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:03:12.740160  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:03:12.800168 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5976
I1211 12:03:12.800168 15296 solver.cpp:397]     Test net output #1: loss = 1.50543 (* 1 = 1.50543 loss)
I1211 12:03:12.861167 15296 solver.cpp:218] Iteration 68000 (12.6253 iter/s, 7.92057s/100 iters), loss = 0.77472
I1211 12:03:12.861167 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:03:12.861167 15296 solver.cpp:237]     Train net output #1: loss = 0.77472 (* 1 = 0.77472 loss)
I1211 12:03:12.861167 15296 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1211 12:03:19.192942 15296 solver.cpp:218] Iteration 68100 (15.7966 iter/s, 6.33047s/100 iters), loss = 0.801483
I1211 12:03:19.192942 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:03:19.192942 15296 solver.cpp:237]     Train net output #1: loss = 0.801483 (* 1 = 0.801483 loss)
I1211 12:03:19.192942 15296 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1211 12:03:25.515549 15296 solver.cpp:218] Iteration 68200 (15.8152 iter/s, 6.32303s/100 iters), loss = 0.642723
I1211 12:03:25.515549 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:03:25.516549 15296 solver.cpp:237]     Train net output #1: loss = 0.642723 (* 1 = 0.642723 loss)
I1211 12:03:25.516549 15296 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1211 12:03:31.842406 15296 solver.cpp:218] Iteration 68300 (15.8075 iter/s, 6.32609s/100 iters), loss = 0.761954
I1211 12:03:31.842406 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:03:31.842406 15296 solver.cpp:237]     Train net output #1: loss = 0.761954 (* 1 = 0.761954 loss)
I1211 12:03:31.842406 15296 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1211 12:03:38.172152 15296 solver.cpp:218] Iteration 68400 (15.7997 iter/s, 6.32923s/100 iters), loss = 0.914707
I1211 12:03:38.172152 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:03:38.172152 15296 solver.cpp:237]     Train net output #1: loss = 0.914707 (* 1 = 0.914707 loss)
I1211 12:03:38.172152 15296 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1211 12:03:44.188822 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:03:44.440845 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68500.caffemodel
I1211 12:03:44.455849 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68500.solverstate
I1211 12:03:44.459849 15296 solver.cpp:330] Iteration 68500, Testing net (#0)
I1211 12:03:44.459849 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:03:45.977035  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:03:46.037529 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5876
I1211 12:03:46.037529 15296 solver.cpp:397]     Test net output #1: loss = 1.57345 (* 1 = 1.57345 loss)
I1211 12:03:46.098033 15296 solver.cpp:218] Iteration 68500 (12.618 iter/s, 7.9252s/100 iters), loss = 0.710473
I1211 12:03:46.098033 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:03:46.098033 15296 solver.cpp:237]     Train net output #1: loss = 0.710473 (* 1 = 0.710473 loss)
I1211 12:03:46.098033 15296 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1211 12:03:52.432829 15296 solver.cpp:218] Iteration 68600 (15.7881 iter/s, 6.33387s/100 iters), loss = 0.705793
I1211 12:03:52.432829 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:03:52.432829 15296 solver.cpp:237]     Train net output #1: loss = 0.705793 (* 1 = 0.705793 loss)
I1211 12:03:52.432829 15296 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1211 12:03:58.764546 15296 solver.cpp:218] Iteration 68700 (15.7924 iter/s, 6.33216s/100 iters), loss = 0.579037
I1211 12:03:58.764546 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:03:58.765547 15296 solver.cpp:237]     Train net output #1: loss = 0.579037 (* 1 = 0.579037 loss)
I1211 12:03:58.765547 15296 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1211 12:04:05.111343 15296 solver.cpp:218] Iteration 68800 (15.7585 iter/s, 6.34579s/100 iters), loss = 0.758603
I1211 12:04:05.111343 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:04:05.111343 15296 solver.cpp:237]     Train net output #1: loss = 0.758603 (* 1 = 0.758603 loss)
I1211 12:04:05.111343 15296 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1211 12:04:11.452093 15296 solver.cpp:218] Iteration 68900 (15.7721 iter/s, 6.34031s/100 iters), loss = 0.813181
I1211 12:04:11.452093 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:04:11.452093 15296 solver.cpp:237]     Train net output #1: loss = 0.813181 (* 1 = 0.813181 loss)
I1211 12:04:11.452093 15296 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1211 12:04:17.489799 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:04:17.738823 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69000.caffemodel
I1211 12:04:17.754829 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69000.solverstate
I1211 12:04:17.758828 15296 solver.cpp:330] Iteration 69000, Testing net (#0)
I1211 12:04:17.758828 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:04:19.277007  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:04:19.338013 15296 solver.cpp:397]     Test net output #0: accuracy = 0.598
I1211 12:04:19.338013 15296 solver.cpp:397]     Test net output #1: loss = 1.51533 (* 1 = 1.51533 loss)
I1211 12:04:19.399014 15296 solver.cpp:218] Iteration 69000 (12.584 iter/s, 7.94662s/100 iters), loss = 0.724847
I1211 12:04:19.399014 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:04:19.399014 15296 solver.cpp:237]     Train net output #1: loss = 0.724847 (* 1 = 0.724847 loss)
I1211 12:04:19.399014 15296 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1211 12:04:25.727077 15296 solver.cpp:218] Iteration 69100 (15.8044 iter/s, 6.32737s/100 iters), loss = 0.795175
I1211 12:04:25.727077 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 12:04:25.727077 15296 solver.cpp:237]     Train net output #1: loss = 0.795175 (* 1 = 0.795175 loss)
I1211 12:04:25.727077 15296 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1211 12:04:32.060706 15296 solver.cpp:218] Iteration 69200 (15.7889 iter/s, 6.33358s/100 iters), loss = 0.624747
I1211 12:04:32.060706 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:04:32.060706 15296 solver.cpp:237]     Train net output #1: loss = 0.624747 (* 1 = 0.624747 loss)
I1211 12:04:32.060706 15296 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1211 12:04:38.392658 15296 solver.cpp:218] Iteration 69300 (15.7955 iter/s, 6.3309s/100 iters), loss = 0.914463
I1211 12:04:38.392658 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 12:04:38.392658 15296 solver.cpp:237]     Train net output #1: loss = 0.914463 (* 1 = 0.914463 loss)
I1211 12:04:38.392658 15296 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1211 12:04:44.732372 15296 solver.cpp:218] Iteration 69400 (15.7724 iter/s, 6.34021s/100 iters), loss = 0.829453
I1211 12:04:44.732372 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 12:04:44.732372 15296 solver.cpp:237]     Train net output #1: loss = 0.829453 (* 1 = 0.829453 loss)
I1211 12:04:44.733372 15296 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1211 12:04:50.755185 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:04:51.004217 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69500.caffemodel
I1211 12:04:51.019217 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69500.solverstate
I1211 12:04:51.023216 15296 solver.cpp:330] Iteration 69500, Testing net (#0)
I1211 12:04:51.023216 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:04:52.541461  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:04:52.601487 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6081
I1211 12:04:52.601487 15296 solver.cpp:397]     Test net output #1: loss = 1.49836 (* 1 = 1.49836 loss)
I1211 12:04:52.662487 15296 solver.cpp:218] Iteration 69500 (12.6117 iter/s, 7.92917s/100 iters), loss = 0.75462
I1211 12:04:52.662487 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:04:52.662487 15296 solver.cpp:237]     Train net output #1: loss = 0.75462 (* 1 = 0.75462 loss)
I1211 12:04:52.662487 15296 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1211 12:04:58.994262 15296 solver.cpp:218] Iteration 69600 (15.7953 iter/s, 6.33099s/100 iters), loss = 0.841011
I1211 12:04:58.994262 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:04:58.994262 15296 solver.cpp:237]     Train net output #1: loss = 0.841011 (* 1 = 0.841011 loss)
I1211 12:04:58.994262 15296 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1211 12:05:05.329965 15296 solver.cpp:218] Iteration 69700 (15.783 iter/s, 6.33593s/100 iters), loss = 0.69242
I1211 12:05:05.329965 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:05:05.329965 15296 solver.cpp:237]     Train net output #1: loss = 0.69242 (* 1 = 0.69242 loss)
I1211 12:05:05.329965 15296 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1211 12:05:11.664717 15296 solver.cpp:218] Iteration 69800 (15.7875 iter/s, 6.33413s/100 iters), loss = 0.776591
I1211 12:05:11.664717 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:05:11.664717 15296 solver.cpp:237]     Train net output #1: loss = 0.776591 (* 1 = 0.776591 loss)
I1211 12:05:11.664717 15296 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1211 12:05:17.989449 15296 solver.cpp:218] Iteration 69900 (15.8125 iter/s, 6.32412s/100 iters), loss = 0.856713
I1211 12:05:17.989449 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:05:17.989449 15296 solver.cpp:237]     Train net output #1: loss = 0.856713 (* 1 = 0.856713 loss)
I1211 12:05:17.989951 15296 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1211 12:05:24.004251 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:05:24.255282 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70000.caffemodel
I1211 12:05:24.271281 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70000.solverstate
I1211 12:05:24.276283 15296 solver.cpp:330] Iteration 70000, Testing net (#0)
I1211 12:05:24.276283 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:05:25.796531  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:05:25.856539 15296 solver.cpp:397]     Test net output #0: accuracy = 0.599
I1211 12:05:25.856539 15296 solver.cpp:397]     Test net output #1: loss = 1.48685 (* 1 = 1.48685 loss)
I1211 12:05:25.917538 15296 solver.cpp:218] Iteration 70000 (12.6143 iter/s, 7.92751s/100 iters), loss = 0.777951
I1211 12:05:25.917538 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:05:25.917538 15296 solver.cpp:237]     Train net output #1: loss = 0.777951 (* 1 = 0.777951 loss)
I1211 12:05:25.917538 15296 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1211 12:05:32.236171 15296 solver.cpp:218] Iteration 70100 (15.8272 iter/s, 6.31825s/100 iters), loss = 0.830687
I1211 12:05:32.236171 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:05:32.236171 15296 solver.cpp:237]     Train net output #1: loss = 0.830687 (* 1 = 0.830687 loss)
I1211 12:05:32.236171 15296 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1211 12:05:38.572787 15296 solver.cpp:218] Iteration 70200 (15.7821 iter/s, 6.3363s/100 iters), loss = 0.593073
I1211 12:05:38.572787 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:05:38.572787 15296 solver.cpp:237]     Train net output #1: loss = 0.593073 (* 1 = 0.593073 loss)
I1211 12:05:38.572787 15296 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1211 12:05:44.903409 15296 solver.cpp:218] Iteration 70300 (15.7985 iter/s, 6.3297s/100 iters), loss = 0.704199
I1211 12:05:44.903409 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:05:44.903409 15296 solver.cpp:237]     Train net output #1: loss = 0.704199 (* 1 = 0.704199 loss)
I1211 12:05:44.903409 15296 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1211 12:05:51.237869 15296 solver.cpp:218] Iteration 70400 (15.7861 iter/s, 6.3347s/100 iters), loss = 0.789611
I1211 12:05:51.237869 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:05:51.237869 15296 solver.cpp:237]     Train net output #1: loss = 0.789611 (* 1 = 0.789611 loss)
I1211 12:05:51.237869 15296 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1211 12:05:57.258358 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:05:57.509371 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70500.caffemodel
I1211 12:05:57.554424 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70500.solverstate
I1211 12:05:57.567427 15296 solver.cpp:330] Iteration 70500, Testing net (#0)
I1211 12:05:57.568426 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:05:59.093521  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:05:59.153535 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6175
I1211 12:05:59.153535 15296 solver.cpp:397]     Test net output #1: loss = 1.43401 (* 1 = 1.43401 loss)
I1211 12:05:59.214534 15296 solver.cpp:218] Iteration 70500 (12.538 iter/s, 7.97577s/100 iters), loss = 0.756577
I1211 12:05:59.214534 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:05:59.214534 15296 solver.cpp:237]     Train net output #1: loss = 0.756577 (* 1 = 0.756577 loss)
I1211 12:05:59.214534 15296 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1211 12:06:05.556021 15296 solver.cpp:218] Iteration 70600 (15.7696 iter/s, 6.34133s/100 iters), loss = 0.671076
I1211 12:06:05.556021 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:06:05.556021 15296 solver.cpp:237]     Train net output #1: loss = 0.671076 (* 1 = 0.671076 loss)
I1211 12:06:05.556021 15296 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1211 12:06:11.898478 15296 solver.cpp:218] Iteration 70700 (15.7676 iter/s, 6.34212s/100 iters), loss = 0.600682
I1211 12:06:11.898478 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:06:11.898478 15296 solver.cpp:237]     Train net output #1: loss = 0.600682 (* 1 = 0.600682 loss)
I1211 12:06:11.898478 15296 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1211 12:06:18.239425 15296 solver.cpp:218] Iteration 70800 (15.7724 iter/s, 6.34021s/100 iters), loss = 0.883623
I1211 12:06:18.239425 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 12:06:18.239425 15296 solver.cpp:237]     Train net output #1: loss = 0.883623 (* 1 = 0.883623 loss)
I1211 12:06:18.239425 15296 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1211 12:06:24.576387 15296 solver.cpp:218] Iteration 70900 (15.7818 iter/s, 6.33641s/100 iters), loss = 0.877644
I1211 12:06:24.576387 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 12:06:24.576387 15296 solver.cpp:237]     Train net output #1: loss = 0.877644 (* 1 = 0.877644 loss)
I1211 12:06:24.576387 15296 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1211 12:06:30.608831 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:06:30.858850 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71000.caffemodel
I1211 12:06:30.873850 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71000.solverstate
I1211 12:06:30.878851 15296 solver.cpp:330] Iteration 71000, Testing net (#0)
I1211 12:06:30.878851 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:06:32.398962  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:06:32.458971 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5771
I1211 12:06:32.458971 15296 solver.cpp:397]     Test net output #1: loss = 1.6022 (* 1 = 1.6022 loss)
I1211 12:06:32.518966 15296 solver.cpp:218] Iteration 71000 (12.5901 iter/s, 7.94277s/100 iters), loss = 0.676399
I1211 12:06:32.518966 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:06:32.519968 15296 solver.cpp:237]     Train net output #1: loss = 0.676399 (* 1 = 0.676399 loss)
I1211 12:06:32.519968 15296 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1211 12:06:38.854394 15296 solver.cpp:218] Iteration 71100 (15.7858 iter/s, 6.33481s/100 iters), loss = 0.771557
I1211 12:06:38.854394 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:06:38.854394 15296 solver.cpp:237]     Train net output #1: loss = 0.771557 (* 1 = 0.771557 loss)
I1211 12:06:38.854394 15296 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1211 12:06:45.198879 15296 solver.cpp:218] Iteration 71200 (15.7642 iter/s, 6.34348s/100 iters), loss = 0.673953
I1211 12:06:45.198879 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:06:45.198879 15296 solver.cpp:237]     Train net output #1: loss = 0.673953 (* 1 = 0.673953 loss)
I1211 12:06:45.198879 15296 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1211 12:06:51.528421 15296 solver.cpp:218] Iteration 71300 (15.8005 iter/s, 6.32893s/100 iters), loss = 0.878007
I1211 12:06:51.528421 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:06:51.528421 15296 solver.cpp:237]     Train net output #1: loss = 0.878007 (* 1 = 0.878007 loss)
I1211 12:06:51.528421 15296 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1211 12:06:57.865099 15296 solver.cpp:218] Iteration 71400 (15.7807 iter/s, 6.33687s/100 iters), loss = 0.871176
I1211 12:06:57.865099 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:06:57.865099 15296 solver.cpp:237]     Train net output #1: loss = 0.871176 (* 1 = 0.871176 loss)
I1211 12:06:57.865099 15296 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1211 12:07:03.894515 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:07:04.146039 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71500.caffemodel
I1211 12:07:04.162542 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71500.solverstate
I1211 12:07:04.166543 15296 solver.cpp:330] Iteration 71500, Testing net (#0)
I1211 12:07:04.166543 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:07:05.689326  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:07:05.749325 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5689
I1211 12:07:05.749325 15296 solver.cpp:397]     Test net output #1: loss = 1.67873 (* 1 = 1.67873 loss)
I1211 12:07:05.810823 15296 solver.cpp:218] Iteration 71500 (12.587 iter/s, 7.94469s/100 iters), loss = 0.803401
I1211 12:07:05.810823 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:07:05.810823 15296 solver.cpp:237]     Train net output #1: loss = 0.803401 (* 1 = 0.803401 loss)
I1211 12:07:05.810823 15296 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1211 12:07:12.145167 15296 solver.cpp:218] Iteration 71600 (15.7865 iter/s, 6.33451s/100 iters), loss = 0.707706
I1211 12:07:12.145167 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:07:12.145167 15296 solver.cpp:237]     Train net output #1: loss = 0.707706 (* 1 = 0.707706 loss)
I1211 12:07:12.145167 15296 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1211 12:07:18.468566 15296 solver.cpp:218] Iteration 71700 (15.8169 iter/s, 6.32236s/100 iters), loss = 0.636108
I1211 12:07:18.468566 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:07:18.468566 15296 solver.cpp:237]     Train net output #1: loss = 0.636108 (* 1 = 0.636108 loss)
I1211 12:07:18.468566 15296 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1211 12:07:24.805061 15296 solver.cpp:218] Iteration 71800 (15.7826 iter/s, 6.33608s/100 iters), loss = 0.760177
I1211 12:07:24.805061 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:07:24.805061 15296 solver.cpp:237]     Train net output #1: loss = 0.760177 (* 1 = 0.760177 loss)
I1211 12:07:24.805061 15296 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1211 12:07:31.131052 15296 solver.cpp:218] Iteration 71900 (15.8093 iter/s, 6.32538s/100 iters), loss = 0.923666
I1211 12:07:31.131052 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 12:07:31.131052 15296 solver.cpp:237]     Train net output #1: loss = 0.923666 (* 1 = 0.923666 loss)
I1211 12:07:31.131052 15296 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1211 12:07:37.159020 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:07:37.408032 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72000.caffemodel
I1211 12:07:37.425035 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72000.solverstate
I1211 12:07:37.430035 15296 solver.cpp:330] Iteration 72000, Testing net (#0)
I1211 12:07:37.430035 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:07:38.946693  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:07:39.007200 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5442
I1211 12:07:39.007200 15296 solver.cpp:397]     Test net output #1: loss = 1.83424 (* 1 = 1.83424 loss)
I1211 12:07:39.067198 15296 solver.cpp:218] Iteration 72000 (12.6007 iter/s, 7.93605s/100 iters), loss = 0.805419
I1211 12:07:39.067198 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:07:39.067198 15296 solver.cpp:237]     Train net output #1: loss = 0.805419 (* 1 = 0.805419 loss)
I1211 12:07:39.067198 15296 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1211 12:07:45.404799 15296 solver.cpp:218] Iteration 72100 (15.7805 iter/s, 6.33692s/100 iters), loss = 0.877991
I1211 12:07:45.404799 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:07:45.404799 15296 solver.cpp:237]     Train net output #1: loss = 0.877991 (* 1 = 0.877991 loss)
I1211 12:07:45.404799 15296 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1211 12:07:51.744071 15296 solver.cpp:218] Iteration 72200 (15.7742 iter/s, 6.33947s/100 iters), loss = 0.622554
I1211 12:07:51.744071 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:07:51.744071 15296 solver.cpp:237]     Train net output #1: loss = 0.622554 (* 1 = 0.622554 loss)
I1211 12:07:51.744071 15296 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1211 12:07:58.075877 15296 solver.cpp:218] Iteration 72300 (15.7961 iter/s, 6.33069s/100 iters), loss = 0.888902
I1211 12:07:58.075877 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:07:58.075877 15296 solver.cpp:237]     Train net output #1: loss = 0.888902 (* 1 = 0.888902 loss)
I1211 12:07:58.075877 15296 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1211 12:08:04.417860 15296 solver.cpp:218] Iteration 72400 (15.7674 iter/s, 6.34221s/100 iters), loss = 0.863197
I1211 12:08:04.417860 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:08:04.417860 15296 solver.cpp:237]     Train net output #1: loss = 0.863197 (* 1 = 0.863197 loss)
I1211 12:08:04.417860 15296 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1211 12:08:10.445374 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:08:10.694397 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72500.caffemodel
I1211 12:08:10.709403 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72500.solverstate
I1211 12:08:10.713403 15296 solver.cpp:330] Iteration 72500, Testing net (#0)
I1211 12:08:10.713403 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:08:12.232844  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:08:12.293846 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6124
I1211 12:08:12.293846 15296 solver.cpp:397]     Test net output #1: loss = 1.43792 (* 1 = 1.43792 loss)
I1211 12:08:12.353848 15296 solver.cpp:218] Iteration 72500 (12.6022 iter/s, 7.93511s/100 iters), loss = 0.707475
I1211 12:08:12.353848 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:08:12.353848 15296 solver.cpp:237]     Train net output #1: loss = 0.707475 (* 1 = 0.707475 loss)
I1211 12:08:12.353848 15296 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1211 12:08:18.678315 15296 solver.cpp:218] Iteration 72600 (15.813 iter/s, 6.32393s/100 iters), loss = 0.805265
I1211 12:08:18.678315 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:08:18.678315 15296 solver.cpp:237]     Train net output #1: loss = 0.805265 (* 1 = 0.805265 loss)
I1211 12:08:18.678315 15296 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1211 12:08:25.004829 15296 solver.cpp:218] Iteration 72700 (15.8084 iter/s, 6.32577s/100 iters), loss = 0.590075
I1211 12:08:25.004829 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:08:25.004829 15296 solver.cpp:237]     Train net output #1: loss = 0.590075 (* 1 = 0.590075 loss)
I1211 12:08:25.004829 15296 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1211 12:08:31.335351 15296 solver.cpp:218] Iteration 72800 (15.7963 iter/s, 6.33058s/100 iters), loss = 0.87008
I1211 12:08:31.335351 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:08:31.335351 15296 solver.cpp:237]     Train net output #1: loss = 0.87008 (* 1 = 0.87008 loss)
I1211 12:08:31.335351 15296 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1211 12:08:37.675134 15296 solver.cpp:218] Iteration 72900 (15.7756 iter/s, 6.33889s/100 iters), loss = 0.808176
I1211 12:08:37.675134 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:08:37.675134 15296 solver.cpp:237]     Train net output #1: loss = 0.808176 (* 1 = 0.808176 loss)
I1211 12:08:37.675134 15296 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1211 12:08:43.689712 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:08:43.938730 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73000.caffemodel
I1211 12:08:43.953725 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73000.solverstate
I1211 12:08:43.957726 15296 solver.cpp:330] Iteration 73000, Testing net (#0)
I1211 12:08:43.957726 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:08:45.477979  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:08:45.537984 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5914
I1211 12:08:45.537984 15296 solver.cpp:397]     Test net output #1: loss = 1.53498 (* 1 = 1.53498 loss)
I1211 12:08:45.598985 15296 solver.cpp:218] Iteration 73000 (12.6207 iter/s, 7.92348s/100 iters), loss = 0.71439
I1211 12:08:45.598985 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:08:45.598985 15296 solver.cpp:237]     Train net output #1: loss = 0.71439 (* 1 = 0.71439 loss)
I1211 12:08:45.598985 15296 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1211 12:08:51.940490 15296 solver.cpp:218] Iteration 73100 (15.7702 iter/s, 6.34108s/100 iters), loss = 0.756673
I1211 12:08:51.940490 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:08:51.940490 15296 solver.cpp:237]     Train net output #1: loss = 0.756673 (* 1 = 0.756673 loss)
I1211 12:08:51.940490 15296 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1211 12:08:58.286000 15296 solver.cpp:218] Iteration 73200 (15.7588 iter/s, 6.34565s/100 iters), loss = 0.673984
I1211 12:08:58.286000 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:08:58.286000 15296 solver.cpp:237]     Train net output #1: loss = 0.673984 (* 1 = 0.673984 loss)
I1211 12:08:58.286000 15296 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1211 12:09:04.628533 15296 solver.cpp:218] Iteration 73300 (15.7693 iter/s, 6.34142s/100 iters), loss = 0.834433
I1211 12:09:04.628533 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:09:04.628533 15296 solver.cpp:237]     Train net output #1: loss = 0.834433 (* 1 = 0.834433 loss)
I1211 12:09:04.628533 15296 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1211 12:09:10.973991 15296 solver.cpp:218] Iteration 73400 (15.76 iter/s, 6.34518s/100 iters), loss = 0.783606
I1211 12:09:10.973991 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:09:10.973991 15296 solver.cpp:237]     Train net output #1: loss = 0.783606 (* 1 = 0.783606 loss)
I1211 12:09:10.973991 15296 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1211 12:09:17.012466 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:09:17.262480 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73500.caffemodel
I1211 12:09:17.277480 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73500.solverstate
I1211 12:09:17.281481 15296 solver.cpp:330] Iteration 73500, Testing net (#0)
I1211 12:09:17.281481 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:09:18.799803  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:09:18.859812 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5888
I1211 12:09:18.860805 15296 solver.cpp:397]     Test net output #1: loss = 1.57893 (* 1 = 1.57893 loss)
I1211 12:09:18.919808 15296 solver.cpp:218] Iteration 73500 (12.5851 iter/s, 7.94592s/100 iters), loss = 0.710802
I1211 12:09:18.919808 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:09:18.919808 15296 solver.cpp:237]     Train net output #1: loss = 0.710802 (* 1 = 0.710802 loss)
I1211 12:09:18.919808 15296 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1211 12:09:25.250255 15296 solver.cpp:218] Iteration 73600 (15.7995 iter/s, 6.32933s/100 iters), loss = 0.691762
I1211 12:09:25.250255 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:09:25.250255 15296 solver.cpp:237]     Train net output #1: loss = 0.691762 (* 1 = 0.691762 loss)
I1211 12:09:25.250255 15296 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1211 12:09:31.578713 15296 solver.cpp:218] Iteration 73700 (15.8009 iter/s, 6.32874s/100 iters), loss = 0.660409
I1211 12:09:31.578713 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:09:31.578713 15296 solver.cpp:237]     Train net output #1: loss = 0.660409 (* 1 = 0.660409 loss)
I1211 12:09:31.578713 15296 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1211 12:09:37.903681 15296 solver.cpp:218] Iteration 73800 (15.8134 iter/s, 6.32377s/100 iters), loss = 0.759946
I1211 12:09:37.903681 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:09:37.903681 15296 solver.cpp:237]     Train net output #1: loss = 0.759946 (* 1 = 0.759946 loss)
I1211 12:09:37.903681 15296 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1211 12:09:44.230628 15296 solver.cpp:218] Iteration 73900 (15.8051 iter/s, 6.32707s/100 iters), loss = 0.915458
I1211 12:09:44.230628 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:09:44.230628 15296 solver.cpp:237]     Train net output #1: loss = 0.915458 (* 1 = 0.915458 loss)
I1211 12:09:44.230628 15296 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1211 12:09:50.250972 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:09:50.501485 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74000.caffemodel
I1211 12:09:50.515990 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74000.solverstate
I1211 12:09:50.520990 15296 solver.cpp:330] Iteration 74000, Testing net (#0)
I1211 12:09:50.520990 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:09:52.039094  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:09:52.100121 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6156
I1211 12:09:52.100121 15296 solver.cpp:397]     Test net output #1: loss = 1.48904 (* 1 = 1.48904 loss)
I1211 12:09:52.161118 15296 solver.cpp:218] Iteration 74000 (12.6102 iter/s, 7.93009s/100 iters), loss = 0.847083
I1211 12:09:52.161118 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:09:52.161118 15296 solver.cpp:237]     Train net output #1: loss = 0.847083 (* 1 = 0.847083 loss)
I1211 12:09:52.161118 15296 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1211 12:09:58.498667 15296 solver.cpp:218] Iteration 74100 (15.781 iter/s, 6.33671s/100 iters), loss = 0.735715
I1211 12:09:58.498667 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:09:58.498667 15296 solver.cpp:237]     Train net output #1: loss = 0.735715 (* 1 = 0.735715 loss)
I1211 12:09:58.498667 15296 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1211 12:10:04.875119 15296 solver.cpp:218] Iteration 74200 (15.6825 iter/s, 6.37653s/100 iters), loss = 0.685406
I1211 12:10:04.875119 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:10:04.875119 15296 solver.cpp:237]     Train net output #1: loss = 0.685406 (* 1 = 0.685406 loss)
I1211 12:10:04.875119 15296 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1211 12:10:11.208562 15296 solver.cpp:218] Iteration 74300 (15.7911 iter/s, 6.33269s/100 iters), loss = 0.713419
I1211 12:10:11.208562 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:10:11.208562 15296 solver.cpp:237]     Train net output #1: loss = 0.713419 (* 1 = 0.713419 loss)
I1211 12:10:11.208562 15296 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1211 12:10:17.549944 15296 solver.cpp:218] Iteration 74400 (15.7713 iter/s, 6.34063s/100 iters), loss = 0.913889
I1211 12:10:17.549944 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:10:17.549944 15296 solver.cpp:237]     Train net output #1: loss = 0.913889 (* 1 = 0.913889 loss)
I1211 12:10:17.549944 15296 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1211 12:10:23.566385 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:10:23.814399 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74500.caffemodel
I1211 12:10:23.830397 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74500.solverstate
I1211 12:10:23.834398 15296 solver.cpp:330] Iteration 74500, Testing net (#0)
I1211 12:10:23.834398 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:10:25.356500  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:10:25.415498 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5826
I1211 12:10:25.416501 15296 solver.cpp:397]     Test net output #1: loss = 1.60225 (* 1 = 1.60225 loss)
I1211 12:10:25.476513 15296 solver.cpp:218] Iteration 74500 (12.6152 iter/s, 7.92694s/100 iters), loss = 0.717842
I1211 12:10:25.476513 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:10:25.477514 15296 solver.cpp:237]     Train net output #1: loss = 0.717842 (* 1 = 0.717842 loss)
I1211 12:10:25.477514 15296 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1211 12:10:31.803982 15296 solver.cpp:218] Iteration 74600 (15.8056 iter/s, 6.32689s/100 iters), loss = 0.66462
I1211 12:10:31.803982 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:10:31.803982 15296 solver.cpp:237]     Train net output #1: loss = 0.66462 (* 1 = 0.66462 loss)
I1211 12:10:31.803982 15296 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1211 12:10:38.134459 15296 solver.cpp:218] Iteration 74700 (15.7995 iter/s, 6.32932s/100 iters), loss = 0.652098
I1211 12:10:38.134459 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:10:38.134459 15296 solver.cpp:237]     Train net output #1: loss = 0.652098 (* 1 = 0.652098 loss)
I1211 12:10:38.134459 15296 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1211 12:10:44.480015 15296 solver.cpp:218] Iteration 74800 (15.7588 iter/s, 6.34566s/100 iters), loss = 0.716914
I1211 12:10:44.480015 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:10:44.480015 15296 solver.cpp:237]     Train net output #1: loss = 0.716914 (* 1 = 0.716914 loss)
I1211 12:10:44.480015 15296 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1211 12:10:50.811530 15296 solver.cpp:218] Iteration 74900 (15.7949 iter/s, 6.33117s/100 iters), loss = 0.722217
I1211 12:10:50.811530 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:10:50.811530 15296 solver.cpp:237]     Train net output #1: loss = 0.722217 (* 1 = 0.722217 loss)
I1211 12:10:50.811530 15296 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1211 12:10:56.833969 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:10:57.082989 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75000.caffemodel
I1211 12:10:57.097990 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75000.solverstate
I1211 12:10:57.103991 15296 solver.cpp:330] Iteration 75000, Testing net (#0)
I1211 12:10:57.103991 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:10:58.622318  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:10:58.682323 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5817
I1211 12:10:58.682323 15296 solver.cpp:397]     Test net output #1: loss = 1.60229 (* 1 = 1.60229 loss)
I1211 12:10:58.742825 15296 solver.cpp:218] Iteration 75000 (12.6102 iter/s, 7.93008s/100 iters), loss = 0.755081
I1211 12:10:58.742825 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:10:58.742825 15296 solver.cpp:237]     Train net output #1: loss = 0.755081 (* 1 = 0.755081 loss)
I1211 12:10:58.742825 15296 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1211 12:11:05.072795 15296 solver.cpp:218] Iteration 75100 (15.7982 iter/s, 6.32985s/100 iters), loss = 0.810298
I1211 12:11:05.072795 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:11:05.072795 15296 solver.cpp:237]     Train net output #1: loss = 0.810298 (* 1 = 0.810298 loss)
I1211 12:11:05.072795 15296 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1211 12:11:11.407229 15296 solver.cpp:218] Iteration 75200 (15.7887 iter/s, 6.33365s/100 iters), loss = 0.706984
I1211 12:11:11.407229 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:11:11.407229 15296 solver.cpp:237]     Train net output #1: loss = 0.706984 (* 1 = 0.706984 loss)
I1211 12:11:11.407229 15296 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1211 12:11:17.727726 15296 solver.cpp:218] Iteration 75300 (15.8226 iter/s, 6.32006s/100 iters), loss = 0.832898
I1211 12:11:17.727726 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:11:17.727726 15296 solver.cpp:237]     Train net output #1: loss = 0.832898 (* 1 = 0.832898 loss)
I1211 12:11:17.727726 15296 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1211 12:11:24.054147 15296 solver.cpp:218] Iteration 75400 (15.8073 iter/s, 6.32621s/100 iters), loss = 0.813623
I1211 12:11:24.054147 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:11:24.054147 15296 solver.cpp:237]     Train net output #1: loss = 0.813623 (* 1 = 0.813623 loss)
I1211 12:11:24.054147 15296 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1211 12:11:30.078657 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:11:30.329669 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75500.caffemodel
I1211 12:11:30.345674 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75500.solverstate
I1211 12:11:30.350173 15296 solver.cpp:330] Iteration 75500, Testing net (#0)
I1211 12:11:30.350173 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:11:31.867784  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:11:31.928783 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5903
I1211 12:11:31.928783 15296 solver.cpp:397]     Test net output #1: loss = 1.58012 (* 1 = 1.58012 loss)
I1211 12:11:31.988786 15296 solver.cpp:218] Iteration 75500 (12.6035 iter/s, 7.93431s/100 iters), loss = 0.738686
I1211 12:11:31.988786 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:11:31.988786 15296 solver.cpp:237]     Train net output #1: loss = 0.738686 (* 1 = 0.738686 loss)
I1211 12:11:31.988786 15296 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1211 12:11:38.317296 15296 solver.cpp:218] Iteration 75600 (15.8032 iter/s, 6.32782s/100 iters), loss = 0.710751
I1211 12:11:38.317296 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:11:38.317296 15296 solver.cpp:237]     Train net output #1: loss = 0.710751 (* 1 = 0.710751 loss)
I1211 12:11:38.317296 15296 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1211 12:11:44.647760 15296 solver.cpp:218] Iteration 75700 (15.7978 iter/s, 6.33001s/100 iters), loss = 0.582489
I1211 12:11:44.647760 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:11:44.647760 15296 solver.cpp:237]     Train net output #1: loss = 0.582489 (* 1 = 0.582489 loss)
I1211 12:11:44.647760 15296 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1211 12:11:50.981266 15296 solver.cpp:218] Iteration 75800 (15.7883 iter/s, 6.3338s/100 iters), loss = 0.968249
I1211 12:11:50.981266 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 12:11:50.981266 15296 solver.cpp:237]     Train net output #1: loss = 0.968249 (* 1 = 0.968249 loss)
I1211 12:11:50.981266 15296 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1211 12:11:57.322726 15296 solver.cpp:218] Iteration 75900 (15.7717 iter/s, 6.34047s/100 iters), loss = 0.717815
I1211 12:11:57.322726 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:11:57.322726 15296 solver.cpp:237]     Train net output #1: loss = 0.717815 (* 1 = 0.717815 loss)
I1211 12:11:57.322726 15296 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1211 12:12:03.345203 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:12:03.594218 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76000.caffemodel
I1211 12:12:03.609217 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76000.solverstate
I1211 12:12:03.614218 15296 solver.cpp:330] Iteration 76000, Testing net (#0)
I1211 12:12:03.614218 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:12:05.133322  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:12:05.193325 15296 solver.cpp:397]     Test net output #0: accuracy = 0.555
I1211 12:12:05.193325 15296 solver.cpp:397]     Test net output #1: loss = 1.75155 (* 1 = 1.75155 loss)
I1211 12:12:05.254328 15296 solver.cpp:218] Iteration 76000 (12.6084 iter/s, 7.93124s/100 iters), loss = 0.649884
I1211 12:12:05.254328 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:12:05.254829 15296 solver.cpp:237]     Train net output #1: loss = 0.649884 (* 1 = 0.649884 loss)
I1211 12:12:05.254829 15296 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1211 12:12:11.655268 15296 solver.cpp:218] Iteration 76100 (15.6244 iter/s, 6.40025s/100 iters), loss = 0.694789
I1211 12:12:11.655268 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:12:11.655268 15296 solver.cpp:237]     Train net output #1: loss = 0.694789 (* 1 = 0.694789 loss)
I1211 12:12:11.655268 15296 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1211 12:12:17.999076 15296 solver.cpp:218] Iteration 76200 (15.7635 iter/s, 6.34375s/100 iters), loss = 0.601374
I1211 12:12:17.999076 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:12:17.999076 15296 solver.cpp:237]     Train net output #1: loss = 0.601374 (* 1 = 0.601374 loss)
I1211 12:12:17.999076 15296 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1211 12:12:24.324043 15296 solver.cpp:218] Iteration 76300 (15.8104 iter/s, 6.32495s/100 iters), loss = 0.776338
I1211 12:12:24.325044 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:12:24.325044 15296 solver.cpp:237]     Train net output #1: loss = 0.776338 (* 1 = 0.776338 loss)
I1211 12:12:24.325044 15296 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1211 12:12:30.642493 15296 solver.cpp:218] Iteration 76400 (15.8288 iter/s, 6.31761s/100 iters), loss = 0.70825
I1211 12:12:30.642493 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:12:30.642493 15296 solver.cpp:237]     Train net output #1: loss = 0.70825 (* 1 = 0.70825 loss)
I1211 12:12:30.642493 15296 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1211 12:12:36.650490 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:12:36.899015 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76500.caffemodel
I1211 12:12:36.914016 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76500.solverstate
I1211 12:12:36.919018 15296 solver.cpp:330] Iteration 76500, Testing net (#0)
I1211 12:12:36.919018 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:12:38.434128  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:12:38.494145 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5883
I1211 12:12:38.494145 15296 solver.cpp:397]     Test net output #1: loss = 1.58956 (* 1 = 1.58956 loss)
I1211 12:12:38.554144 15296 solver.cpp:218] Iteration 76500 (12.64 iter/s, 7.91137s/100 iters), loss = 0.675737
I1211 12:12:38.554144 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:12:38.554144 15296 solver.cpp:237]     Train net output #1: loss = 0.675737 (* 1 = 0.675737 loss)
I1211 12:12:38.554144 15296 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1211 12:12:44.879647 15296 solver.cpp:218] Iteration 76600 (15.8115 iter/s, 6.3245s/100 iters), loss = 0.822328
I1211 12:12:44.879647 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:12:44.879647 15296 solver.cpp:237]     Train net output #1: loss = 0.822328 (* 1 = 0.822328 loss)
I1211 12:12:44.879647 15296 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1211 12:12:51.200073 15296 solver.cpp:218] Iteration 76700 (15.8227 iter/s, 6.32005s/100 iters), loss = 0.638731
I1211 12:12:51.200073 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:12:51.200073 15296 solver.cpp:237]     Train net output #1: loss = 0.638731 (* 1 = 0.638731 loss)
I1211 12:12:51.200073 15296 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1211 12:12:57.516474 15296 solver.cpp:218] Iteration 76800 (15.8316 iter/s, 6.31647s/100 iters), loss = 0.876606
I1211 12:12:57.516474 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:12:57.516474 15296 solver.cpp:237]     Train net output #1: loss = 0.876606 (* 1 = 0.876606 loss)
I1211 12:12:57.516474 15296 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1211 12:13:03.839921 15296 solver.cpp:218] Iteration 76900 (15.8151 iter/s, 6.32306s/100 iters), loss = 0.899657
I1211 12:13:03.839921 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:13:03.839921 15296 solver.cpp:237]     Train net output #1: loss = 0.899657 (* 1 = 0.899657 loss)
I1211 12:13:03.839921 15296 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1211 12:13:09.851858 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:13:10.102383 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77000.caffemodel
I1211 12:13:10.118394 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77000.solverstate
I1211 12:13:10.122393 15296 solver.cpp:330] Iteration 77000, Testing net (#0)
I1211 12:13:10.122393 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:13:11.637567  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:13:11.697584 15296 solver.cpp:397]     Test net output #0: accuracy = 0.586
I1211 12:13:11.697584 15296 solver.cpp:397]     Test net output #1: loss = 1.6408 (* 1 = 1.6408 loss)
I1211 12:13:11.758097 15296 solver.cpp:218] Iteration 77000 (12.6308 iter/s, 7.91716s/100 iters), loss = 0.655401
I1211 12:13:11.758097 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:13:11.758097 15296 solver.cpp:237]     Train net output #1: loss = 0.655401 (* 1 = 0.655401 loss)
I1211 12:13:11.758097 15296 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1211 12:13:18.071089 15296 solver.cpp:218] Iteration 77100 (15.84 iter/s, 6.31312s/100 iters), loss = 0.759895
I1211 12:13:18.071089 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:13:18.071089 15296 solver.cpp:237]     Train net output #1: loss = 0.759895 (* 1 = 0.759895 loss)
I1211 12:13:18.071089 15296 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1211 12:13:24.379848 15296 solver.cpp:218] Iteration 77200 (15.8523 iter/s, 6.30823s/100 iters), loss = 0.612983
I1211 12:13:24.379848 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:13:24.379848 15296 solver.cpp:237]     Train net output #1: loss = 0.612983 (* 1 = 0.612983 loss)
I1211 12:13:24.379848 15296 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1211 12:13:30.695209 15296 solver.cpp:218] Iteration 77300 (15.8358 iter/s, 6.31481s/100 iters), loss = 0.800285
I1211 12:13:30.695209 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:13:30.695209 15296 solver.cpp:237]     Train net output #1: loss = 0.800285 (* 1 = 0.800285 loss)
I1211 12:13:30.695209 15296 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1211 12:13:37.009742 15296 solver.cpp:218] Iteration 77400 (15.8377 iter/s, 6.31403s/100 iters), loss = 0.981062
I1211 12:13:37.009742 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:13:37.009742 15296 solver.cpp:237]     Train net output #1: loss = 0.981062 (* 1 = 0.981062 loss)
I1211 12:13:37.009742 15296 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1211 12:13:43.014245 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:13:43.265758 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77500.caffemodel
I1211 12:13:43.281261 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77500.solverstate
I1211 12:13:43.286262 15296 solver.cpp:330] Iteration 77500, Testing net (#0)
I1211 12:13:43.286262 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:13:44.798400  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:13:44.857903 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5587
I1211 12:13:44.857903 15296 solver.cpp:397]     Test net output #1: loss = 1.77248 (* 1 = 1.77248 loss)
I1211 12:13:44.918404 15296 solver.cpp:218] Iteration 77500 (12.646 iter/s, 7.90766s/100 iters), loss = 0.629818
I1211 12:13:44.918404 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:13:44.918404 15296 solver.cpp:237]     Train net output #1: loss = 0.629818 (* 1 = 0.629818 loss)
I1211 12:13:44.918404 15296 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1211 12:13:51.238881 15296 solver.cpp:218] Iteration 77600 (15.8225 iter/s, 6.3201s/100 iters), loss = 0.740096
I1211 12:13:51.238881 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:13:51.238881 15296 solver.cpp:237]     Train net output #1: loss = 0.740096 (* 1 = 0.740096 loss)
I1211 12:13:51.238881 15296 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1211 12:13:57.549351 15296 solver.cpp:218] Iteration 77700 (15.8464 iter/s, 6.31059s/100 iters), loss = 0.721644
I1211 12:13:57.549351 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:13:57.549351 15296 solver.cpp:237]     Train net output #1: loss = 0.721644 (* 1 = 0.721644 loss)
I1211 12:13:57.549351 15296 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1211 12:14:03.862293 15296 solver.cpp:218] Iteration 77800 (15.8428 iter/s, 6.31202s/100 iters), loss = 0.780039
I1211 12:14:03.862293 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:14:03.862293 15296 solver.cpp:237]     Train net output #1: loss = 0.780039 (* 1 = 0.780039 loss)
I1211 12:14:03.862293 15296 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1211 12:14:10.179230 15296 solver.cpp:218] Iteration 77900 (15.8296 iter/s, 6.31726s/100 iters), loss = 0.876333
I1211 12:14:10.180232 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 12:14:10.180232 15296 solver.cpp:237]     Train net output #1: loss = 0.876333 (* 1 = 0.876333 loss)
I1211 12:14:10.180232 15296 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1211 12:14:16.187641 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:14:16.437655 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78000.caffemodel
I1211 12:14:16.451656 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78000.solverstate
I1211 12:14:16.456657 15296 solver.cpp:330] Iteration 78000, Testing net (#0)
I1211 12:14:16.456657 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:14:17.969350  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:14:18.028852 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5948
I1211 12:14:18.028852 15296 solver.cpp:397]     Test net output #1: loss = 1.5529 (* 1 = 1.5529 loss)
I1211 12:14:18.089857 15296 solver.cpp:218] Iteration 78000 (12.6429 iter/s, 7.90957s/100 iters), loss = 0.656956
I1211 12:14:18.089857 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:14:18.089857 15296 solver.cpp:237]     Train net output #1: loss = 0.656956 (* 1 = 0.656956 loss)
I1211 12:14:18.089857 15296 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1211 12:14:24.400372 15296 solver.cpp:218] Iteration 78100 (15.8481 iter/s, 6.30992s/100 iters), loss = 0.782181
I1211 12:14:24.400372 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:14:24.400372 15296 solver.cpp:237]     Train net output #1: loss = 0.782181 (* 1 = 0.782181 loss)
I1211 12:14:24.400372 15296 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1211 12:14:30.708778 15296 solver.cpp:218] Iteration 78200 (15.8534 iter/s, 6.30781s/100 iters), loss = 0.587594
I1211 12:14:30.708778 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:14:30.708778 15296 solver.cpp:237]     Train net output #1: loss = 0.587594 (* 1 = 0.587594 loss)
I1211 12:14:30.708778 15296 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1211 12:14:37.023350 15296 solver.cpp:218] Iteration 78300 (15.836 iter/s, 6.31474s/100 iters), loss = 0.842471
I1211 12:14:37.023350 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:14:37.023350 15296 solver.cpp:237]     Train net output #1: loss = 0.842471 (* 1 = 0.842471 loss)
I1211 12:14:37.023350 15296 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1211 12:14:43.331879 15296 solver.cpp:218] Iteration 78400 (15.8521 iter/s, 6.30831s/100 iters), loss = 0.89485
I1211 12:14:43.331879 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:14:43.331879 15296 solver.cpp:237]     Train net output #1: loss = 0.89485 (* 1 = 0.89485 loss)
I1211 12:14:43.331879 15296 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1211 12:14:49.338326 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:14:49.588340 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78500.caffemodel
I1211 12:14:49.604341 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78500.solverstate
I1211 12:14:49.608340 15296 solver.cpp:330] Iteration 78500, Testing net (#0)
I1211 12:14:49.608340 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:14:51.123474  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:14:51.183480 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5827
I1211 12:14:51.183480 15296 solver.cpp:397]     Test net output #1: loss = 1.63069 (* 1 = 1.63069 loss)
I1211 12:14:51.243479 15296 solver.cpp:218] Iteration 78500 (12.6405 iter/s, 7.91105s/100 iters), loss = 0.747
I1211 12:14:51.243479 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:14:51.243479 15296 solver.cpp:237]     Train net output #1: loss = 0.747 (* 1 = 0.747 loss)
I1211 12:14:51.243479 15296 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1211 12:14:57.890555 15296 solver.cpp:218] Iteration 78600 (15.0463 iter/s, 6.64616s/100 iters), loss = 0.736607
I1211 12:14:57.890555 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:14:57.890555 15296 solver.cpp:237]     Train net output #1: loss = 0.736607 (* 1 = 0.736607 loss)
I1211 12:14:57.890555 15296 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1211 12:15:04.219573 15296 solver.cpp:218] Iteration 78700 (15.8009 iter/s, 6.32877s/100 iters), loss = 0.647578
I1211 12:15:04.219573 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:15:04.219573 15296 solver.cpp:237]     Train net output #1: loss = 0.647578 (* 1 = 0.647578 loss)
I1211 12:15:04.219573 15296 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1211 12:15:10.590147 15296 solver.cpp:218] Iteration 78800 (15.6988 iter/s, 6.36991s/100 iters), loss = 0.873325
I1211 12:15:10.590147 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:15:10.590147 15296 solver.cpp:237]     Train net output #1: loss = 0.873325 (* 1 = 0.873325 loss)
I1211 12:15:10.590147 15296 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1211 12:15:16.999709 15296 solver.cpp:218] Iteration 78900 (15.6017 iter/s, 6.40955s/100 iters), loss = 0.716854
I1211 12:15:16.999709 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:15:16.999709 15296 solver.cpp:237]     Train net output #1: loss = 0.716854 (* 1 = 0.716854 loss)
I1211 12:15:16.999709 15296 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1211 12:15:23.055177 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:15:23.310222 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79000.caffemodel
I1211 12:15:23.327221 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79000.solverstate
I1211 12:15:23.331221 15296 solver.cpp:330] Iteration 79000, Testing net (#0)
I1211 12:15:23.331221 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:15:24.884853  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:15:24.945359 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5588
I1211 12:15:24.945359 15296 solver.cpp:397]     Test net output #1: loss = 1.81412 (* 1 = 1.81412 loss)
I1211 12:15:25.007364 15296 solver.cpp:218] Iteration 79000 (12.4897 iter/s, 8.00659s/100 iters), loss = 0.867587
I1211 12:15:25.007364 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:15:25.007364 15296 solver.cpp:237]     Train net output #1: loss = 0.867587 (* 1 = 0.867587 loss)
I1211 12:15:25.007364 15296 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1211 12:15:31.407397 15296 solver.cpp:218] Iteration 79100 (15.6252 iter/s, 6.3999s/100 iters), loss = 0.668937
I1211 12:15:31.407397 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:15:31.407898 15296 solver.cpp:237]     Train net output #1: loss = 0.668937 (* 1 = 0.668937 loss)
I1211 12:15:31.407898 15296 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1211 12:15:37.758258 15296 solver.cpp:218] Iteration 79200 (15.7458 iter/s, 6.35089s/100 iters), loss = 0.577666
I1211 12:15:37.758258 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:15:37.759259 15296 solver.cpp:237]     Train net output #1: loss = 0.577666 (* 1 = 0.577666 loss)
I1211 12:15:37.759259 15296 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1211 12:15:44.097759 15296 solver.cpp:218] Iteration 79300 (15.7773 iter/s, 6.33822s/100 iters), loss = 0.720685
I1211 12:15:44.097759 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:15:44.097759 15296 solver.cpp:237]     Train net output #1: loss = 0.720685 (* 1 = 0.720685 loss)
I1211 12:15:44.097759 15296 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1211 12:15:50.461294 15296 solver.cpp:218] Iteration 79400 (15.7141 iter/s, 6.36373s/100 iters), loss = 0.894631
I1211 12:15:50.461294 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:15:50.461294 15296 solver.cpp:237]     Train net output #1: loss = 0.894631 (* 1 = 0.894631 loss)
I1211 12:15:50.461294 15296 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1211 12:15:56.533967 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:15:56.783990 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79500.caffemodel
I1211 12:15:56.798986 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79500.solverstate
I1211 12:15:56.802989 15296 solver.cpp:330] Iteration 79500, Testing net (#0)
I1211 12:15:56.802989 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:15:58.333120  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:15:58.393120 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5076
I1211 12:15:58.393120 15296 solver.cpp:397]     Test net output #1: loss = 2.09573 (* 1 = 2.09573 loss)
I1211 12:15:58.454119 15296 solver.cpp:218] Iteration 79500 (12.5124 iter/s, 7.99209s/100 iters), loss = 0.766737
I1211 12:15:58.454119 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:15:58.454119 15296 solver.cpp:237]     Train net output #1: loss = 0.766737 (* 1 = 0.766737 loss)
I1211 12:15:58.454119 15296 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1211 12:16:04.806587 15296 solver.cpp:218] Iteration 79600 (15.7429 iter/s, 6.35209s/100 iters), loss = 0.740713
I1211 12:16:04.806587 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:16:04.806587 15296 solver.cpp:237]     Train net output #1: loss = 0.740713 (* 1 = 0.740713 loss)
I1211 12:16:04.806587 15296 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1211 12:16:11.163132 15296 solver.cpp:218] Iteration 79700 (15.7325 iter/s, 6.35627s/100 iters), loss = 0.615334
I1211 12:16:11.163132 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:16:11.163132 15296 solver.cpp:237]     Train net output #1: loss = 0.615334 (* 1 = 0.615334 loss)
I1211 12:16:11.163132 15296 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1211 12:16:17.506582 15296 solver.cpp:218] Iteration 79800 (15.7652 iter/s, 6.34308s/100 iters), loss = 0.815855
I1211 12:16:17.507582 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:16:17.507582 15296 solver.cpp:237]     Train net output #1: loss = 0.815855 (* 1 = 0.815855 loss)
I1211 12:16:17.507582 15296 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1211 12:16:23.857079 15296 solver.cpp:218] Iteration 79900 (15.7491 iter/s, 6.34958s/100 iters), loss = 0.921389
I1211 12:16:23.857079 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 12:16:23.857079 15296 solver.cpp:237]     Train net output #1: loss = 0.921389 (* 1 = 0.921389 loss)
I1211 12:16:23.857079 15296 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1211 12:16:29.892524 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:16:30.141543 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80000.caffemodel
I1211 12:16:30.156550 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80000.solverstate
I1211 12:16:30.161550 15296 solver.cpp:330] Iteration 80000, Testing net (#0)
I1211 12:16:30.161550 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:16:31.681674  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:16:31.743175 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5938
I1211 12:16:31.743175 15296 solver.cpp:397]     Test net output #1: loss = 1.55493 (* 1 = 1.55493 loss)
I1211 12:16:31.803678 15296 solver.cpp:218] Iteration 80000 (12.5853 iter/s, 7.94578s/100 iters), loss = 0.803886
I1211 12:16:31.803678 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:16:31.803678 15296 solver.cpp:237]     Train net output #1: loss = 0.803886 (* 1 = 0.803886 loss)
I1211 12:16:31.803678 15296 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1211 12:16:38.175228 15296 solver.cpp:218] Iteration 80100 (15.6952 iter/s, 6.37139s/100 iters), loss = 0.623903
I1211 12:16:38.175228 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:16:38.175228 15296 solver.cpp:237]     Train net output #1: loss = 0.623903 (* 1 = 0.623903 loss)
I1211 12:16:38.175228 15296 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1211 12:16:44.524767 15296 solver.cpp:218] Iteration 80200 (15.7502 iter/s, 6.34911s/100 iters), loss = 0.679869
I1211 12:16:44.524767 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:16:44.524767 15296 solver.cpp:237]     Train net output #1: loss = 0.679869 (* 1 = 0.679869 loss)
I1211 12:16:44.524767 15296 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1211 12:16:50.862278 15296 solver.cpp:218] Iteration 80300 (15.7815 iter/s, 6.33655s/100 iters), loss = 0.782669
I1211 12:16:50.862278 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:16:50.862278 15296 solver.cpp:237]     Train net output #1: loss = 0.782669 (* 1 = 0.782669 loss)
I1211 12:16:50.862278 15296 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1211 12:16:57.213841 15296 solver.cpp:218] Iteration 80400 (15.7435 iter/s, 6.35182s/100 iters), loss = 0.928655
I1211 12:16:57.213841 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 12:16:57.213841 15296 solver.cpp:237]     Train net output #1: loss = 0.928655 (* 1 = 0.928655 loss)
I1211 12:16:57.213841 15296 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1211 12:17:03.247856 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:17:03.496384 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80500.caffemodel
I1211 12:17:03.512382 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80500.solverstate
I1211 12:17:03.517382 15296 solver.cpp:330] Iteration 80500, Testing net (#0)
I1211 12:17:03.517382 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:17:05.042021  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:17:05.101528 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5699
I1211 12:17:05.101528 15296 solver.cpp:397]     Test net output #1: loss = 1.7056 (* 1 = 1.7056 loss)
I1211 12:17:05.162531 15296 solver.cpp:218] Iteration 80500 (12.5819 iter/s, 7.94793s/100 iters), loss = 0.74827
I1211 12:17:05.162531 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:17:05.162531 15296 solver.cpp:237]     Train net output #1: loss = 0.74827 (* 1 = 0.74827 loss)
I1211 12:17:05.162531 15296 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1211 12:17:11.502003 15296 solver.cpp:218] Iteration 80600 (15.7762 iter/s, 6.33868s/100 iters), loss = 0.652176
I1211 12:17:11.502003 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:17:11.502003 15296 solver.cpp:237]     Train net output #1: loss = 0.652176 (* 1 = 0.652176 loss)
I1211 12:17:11.502003 15296 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1211 12:17:17.841914 15296 solver.cpp:218] Iteration 80700 (15.7744 iter/s, 6.33937s/100 iters), loss = 0.609216
I1211 12:17:17.841914 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:17:17.841914 15296 solver.cpp:237]     Train net output #1: loss = 0.609216 (* 1 = 0.609216 loss)
I1211 12:17:17.841914 15296 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1211 12:17:24.172421 15296 solver.cpp:218] Iteration 80800 (15.7962 iter/s, 6.33066s/100 iters), loss = 0.80485
I1211 12:17:24.172421 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:17:24.172421 15296 solver.cpp:237]     Train net output #1: loss = 0.80485 (* 1 = 0.80485 loss)
I1211 12:17:24.172421 15296 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1211 12:17:30.508908 15296 solver.cpp:218] Iteration 80900 (15.7841 iter/s, 6.33549s/100 iters), loss = 0.814302
I1211 12:17:30.508908 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:17:30.508908 15296 solver.cpp:237]     Train net output #1: loss = 0.814302 (* 1 = 0.814302 loss)
I1211 12:17:30.508908 15296 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1211 12:17:36.538344 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:17:36.788365 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81000.caffemodel
I1211 12:17:36.802366 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81000.solverstate
I1211 12:17:36.807366 15296 solver.cpp:330] Iteration 81000, Testing net (#0)
I1211 12:17:36.807366 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:17:38.332479  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:17:38.392488 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6118
I1211 12:17:38.392488 15296 solver.cpp:397]     Test net output #1: loss = 1.46862 (* 1 = 1.46862 loss)
I1211 12:17:38.453490 15296 solver.cpp:218] Iteration 81000 (12.5878 iter/s, 7.9442s/100 iters), loss = 0.650646
I1211 12:17:38.453490 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:17:38.453490 15296 solver.cpp:237]     Train net output #1: loss = 0.650646 (* 1 = 0.650646 loss)
I1211 12:17:38.453490 15296 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1211 12:17:44.801045 15296 solver.cpp:218] Iteration 81100 (15.7547 iter/s, 6.34733s/100 iters), loss = 0.721533
I1211 12:17:44.801045 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:17:44.801045 15296 solver.cpp:237]     Train net output #1: loss = 0.721533 (* 1 = 0.721533 loss)
I1211 12:17:44.801045 15296 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1211 12:17:51.143507 15296 solver.cpp:218] Iteration 81200 (15.7667 iter/s, 6.3425s/100 iters), loss = 0.724215
I1211 12:17:51.143507 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:17:51.143507 15296 solver.cpp:237]     Train net output #1: loss = 0.724215 (* 1 = 0.724215 loss)
I1211 12:17:51.144508 15296 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1211 12:17:57.491089 15296 solver.cpp:218] Iteration 81300 (15.7573 iter/s, 6.34625s/100 iters), loss = 0.747187
I1211 12:17:57.491089 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:17:57.491089 15296 solver.cpp:237]     Train net output #1: loss = 0.747187 (* 1 = 0.747187 loss)
I1211 12:17:57.491089 15296 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1211 12:18:03.841873 15296 solver.cpp:218] Iteration 81400 (15.745 iter/s, 6.35124s/100 iters), loss = 0.819338
I1211 12:18:03.842874 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 12:18:03.842874 15296 solver.cpp:237]     Train net output #1: loss = 0.819338 (* 1 = 0.819338 loss)
I1211 12:18:03.842874 15296 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1211 12:18:09.876278 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:18:10.125291 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81500.caffemodel
I1211 12:18:10.141291 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81500.solverstate
I1211 12:18:10.146291 15296 solver.cpp:330] Iteration 81500, Testing net (#0)
I1211 12:18:10.146291 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:18:11.669564  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:18:11.730563 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5697
I1211 12:18:11.730563 15296 solver.cpp:397]     Test net output #1: loss = 1.673 (* 1 = 1.673 loss)
I1211 12:18:11.791568 15296 solver.cpp:218] Iteration 81500 (12.5799 iter/s, 7.94919s/100 iters), loss = 0.592595
I1211 12:18:11.792569 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:18:11.792569 15296 solver.cpp:237]     Train net output #1: loss = 0.592595 (* 1 = 0.592595 loss)
I1211 12:18:11.792569 15296 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1211 12:18:18.135016 15296 solver.cpp:218] Iteration 81600 (15.7658 iter/s, 6.34283s/100 iters), loss = 0.726207
I1211 12:18:18.135016 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:18:18.135016 15296 solver.cpp:237]     Train net output #1: loss = 0.726207 (* 1 = 0.726207 loss)
I1211 12:18:18.135016 15296 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1211 12:18:24.536801 15296 solver.cpp:218] Iteration 81700 (15.6224 iter/s, 6.40107s/100 iters), loss = 0.592065
I1211 12:18:24.536801 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:18:24.536801 15296 solver.cpp:237]     Train net output #1: loss = 0.592065 (* 1 = 0.592065 loss)
I1211 12:18:24.536801 15296 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1211 12:18:30.947312 15296 solver.cpp:218] Iteration 81800 (15.6012 iter/s, 6.40977s/100 iters), loss = 0.748181
I1211 12:18:30.947312 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:18:30.947312 15296 solver.cpp:237]     Train net output #1: loss = 0.748181 (* 1 = 0.748181 loss)
I1211 12:18:30.947312 15296 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1211 12:18:37.373376 15296 solver.cpp:218] Iteration 81900 (15.5627 iter/s, 6.42562s/100 iters), loss = 0.772944
I1211 12:18:37.373376 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:18:37.373376 15296 solver.cpp:237]     Train net output #1: loss = 0.772944 (* 1 = 0.772944 loss)
I1211 12:18:37.373376 15296 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1211 12:18:43.564715 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:18:43.814589 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82000.caffemodel
I1211 12:18:43.830590 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82000.solverstate
I1211 12:18:43.834589 15296 solver.cpp:330] Iteration 82000, Testing net (#0)
I1211 12:18:43.834589 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:18:45.355389  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:18:45.415922 15296 solver.cpp:397]     Test net output #0: accuracy = 0.603
I1211 12:18:45.415922 15296 solver.cpp:397]     Test net output #1: loss = 1.54714 (* 1 = 1.54714 loss)
I1211 12:18:45.476936 15296 solver.cpp:218] Iteration 82000 (12.3416 iter/s, 8.10265s/100 iters), loss = 0.696984
I1211 12:18:45.476936 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:18:45.476936 15296 solver.cpp:237]     Train net output #1: loss = 0.696984 (* 1 = 0.696984 loss)
I1211 12:18:45.476936 15296 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1211 12:18:51.830783 15296 solver.cpp:218] Iteration 82100 (15.7394 iter/s, 6.35349s/100 iters), loss = 0.661088
I1211 12:18:51.830783 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:18:51.830783 15296 solver.cpp:237]     Train net output #1: loss = 0.661088 (* 1 = 0.661088 loss)
I1211 12:18:51.830783 15296 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1211 12:18:58.223301 15296 solver.cpp:218] Iteration 82200 (15.6438 iter/s, 6.3923s/100 iters), loss = 0.689173
I1211 12:18:58.223301 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:18:58.223301 15296 solver.cpp:237]     Train net output #1: loss = 0.689173 (* 1 = 0.689173 loss)
I1211 12:18:58.223301 15296 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1211 12:19:04.569713 15296 solver.cpp:218] Iteration 82300 (15.758 iter/s, 6.34599s/100 iters), loss = 0.763134
I1211 12:19:04.569713 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:19:04.569713 15296 solver.cpp:237]     Train net output #1: loss = 0.763134 (* 1 = 0.763134 loss)
I1211 12:19:04.569713 15296 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1211 12:19:10.898164 15296 solver.cpp:218] Iteration 82400 (15.8024 iter/s, 6.32815s/100 iters), loss = 0.824463
I1211 12:19:10.898164 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:19:10.898164 15296 solver.cpp:237]     Train net output #1: loss = 0.824463 (* 1 = 0.824463 loss)
I1211 12:19:10.898164 15296 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1211 12:19:16.933568 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:19:17.182595 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82500.caffemodel
I1211 12:19:17.196594 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82500.solverstate
I1211 12:19:17.201596 15296 solver.cpp:330] Iteration 82500, Testing net (#0)
I1211 12:19:17.201596 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:19:18.757786  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:19:18.821794 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5887
I1211 12:19:18.821794 15296 solver.cpp:397]     Test net output #1: loss = 1.65935 (* 1 = 1.65935 loss)
I1211 12:19:18.886804 15296 solver.cpp:218] Iteration 82500 (12.5183 iter/s, 7.9883s/100 iters), loss = 0.602692
I1211 12:19:18.886804 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:19:18.886804 15296 solver.cpp:237]     Train net output #1: loss = 0.602692 (* 1 = 0.602692 loss)
I1211 12:19:18.886804 15296 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1211 12:19:25.251219 15296 solver.cpp:218] Iteration 82600 (15.715 iter/s, 6.36335s/100 iters), loss = 0.614399
I1211 12:19:25.251219 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:19:25.251219 15296 solver.cpp:237]     Train net output #1: loss = 0.614399 (* 1 = 0.614399 loss)
I1211 12:19:25.251219 15296 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1211 12:19:31.579648 15296 solver.cpp:218] Iteration 82700 (15.802 iter/s, 6.32832s/100 iters), loss = 0.63762
I1211 12:19:31.579648 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:19:31.579648 15296 solver.cpp:237]     Train net output #1: loss = 0.63762 (* 1 = 0.63762 loss)
I1211 12:19:31.579648 15296 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1211 12:19:37.921098 15296 solver.cpp:218] Iteration 82800 (15.77 iter/s, 6.34116s/100 iters), loss = 0.759108
I1211 12:19:37.921098 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:19:37.921098 15296 solver.cpp:237]     Train net output #1: loss = 0.759108 (* 1 = 0.759108 loss)
I1211 12:19:37.921098 15296 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1211 12:19:44.244545 15296 solver.cpp:218] Iteration 82900 (15.8141 iter/s, 6.32348s/100 iters), loss = 0.717857
I1211 12:19:44.244545 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:19:44.245546 15296 solver.cpp:237]     Train net output #1: loss = 0.717857 (* 1 = 0.717857 loss)
I1211 12:19:44.245546 15296 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1211 12:19:50.341091 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:19:50.596115 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83000.caffemodel
I1211 12:19:50.611116 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83000.solverstate
I1211 12:19:50.616134 15296 solver.cpp:330] Iteration 83000, Testing net (#0)
I1211 12:19:50.616134 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:19:52.166749  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:19:52.229256 15296 solver.cpp:397]     Test net output #0: accuracy = 0.596
I1211 12:19:52.229256 15296 solver.cpp:397]     Test net output #1: loss = 1.57042 (* 1 = 1.57042 loss)
I1211 12:19:52.291260 15296 solver.cpp:218] Iteration 83000 (12.4296 iter/s, 8.04533s/100 iters), loss = 0.704381
I1211 12:19:52.291260 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:19:52.291260 15296 solver.cpp:237]     Train net output #1: loss = 0.704381 (* 1 = 0.704381 loss)
I1211 12:19:52.291260 15296 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1211 12:19:58.725769 15296 solver.cpp:218] Iteration 83100 (15.5413 iter/s, 6.43448s/100 iters), loss = 0.767056
I1211 12:19:58.725769 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:19:58.725769 15296 solver.cpp:237]     Train net output #1: loss = 0.767056 (* 1 = 0.767056 loss)
I1211 12:19:58.725769 15296 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1211 12:20:05.149919 15296 solver.cpp:218] Iteration 83200 (15.5672 iter/s, 6.42378s/100 iters), loss = 0.649418
I1211 12:20:05.149919 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:20:05.149919 15296 solver.cpp:237]     Train net output #1: loss = 0.649418 (* 1 = 0.649418 loss)
I1211 12:20:05.149919 15296 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1211 12:20:11.637153 15296 solver.cpp:218] Iteration 83300 (15.4165 iter/s, 6.48657s/100 iters), loss = 0.836667
I1211 12:20:11.637153 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:20:11.637153 15296 solver.cpp:237]     Train net output #1: loss = 0.836667 (* 1 = 0.836667 loss)
I1211 12:20:11.637153 15296 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1211 12:20:18.033200 15296 solver.cpp:218] Iteration 83400 (15.6353 iter/s, 6.39578s/100 iters), loss = 0.689073
I1211 12:20:18.033200 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:20:18.033200 15296 solver.cpp:237]     Train net output #1: loss = 0.689073 (* 1 = 0.689073 loss)
I1211 12:20:18.033200 15296 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1211 12:20:24.117894 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:20:24.369393 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83500.caffemodel
I1211 12:20:24.385392 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83500.solverstate
I1211 12:20:24.390398 15296 solver.cpp:330] Iteration 83500, Testing net (#0)
I1211 12:20:24.390398 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:20:25.928185  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:20:25.989692 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5906
I1211 12:20:25.989692 15296 solver.cpp:397]     Test net output #1: loss = 1.56393 (* 1 = 1.56393 loss)
I1211 12:20:26.051298 15296 solver.cpp:218] Iteration 83500 (12.4736 iter/s, 8.01696s/100 iters), loss = 0.58969
I1211 12:20:26.051298 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:20:26.051298 15296 solver.cpp:237]     Train net output #1: loss = 0.58969 (* 1 = 0.58969 loss)
I1211 12:20:26.051298 15296 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1211 12:20:32.470544 15296 solver.cpp:218] Iteration 83600 (15.5793 iter/s, 6.41877s/100 iters), loss = 0.729048
I1211 12:20:32.470544 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:20:32.470544 15296 solver.cpp:237]     Train net output #1: loss = 0.729048 (* 1 = 0.729048 loss)
I1211 12:20:32.470544 15296 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1211 12:20:38.919816 15296 solver.cpp:218] Iteration 83700 (15.5067 iter/s, 6.44883s/100 iters), loss = 0.620574
I1211 12:20:38.919816 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:20:38.919816 15296 solver.cpp:237]     Train net output #1: loss = 0.620574 (* 1 = 0.620574 loss)
I1211 12:20:38.919816 15296 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1211 12:20:45.432613 15296 solver.cpp:218] Iteration 83800 (15.3544 iter/s, 6.51279s/100 iters), loss = 0.837896
I1211 12:20:45.432613 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:20:45.432613 15296 solver.cpp:237]     Train net output #1: loss = 0.837896 (* 1 = 0.837896 loss)
I1211 12:20:45.432613 15296 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1211 12:20:51.765453 15296 solver.cpp:218] Iteration 83900 (15.791 iter/s, 6.33271s/100 iters), loss = 0.850571
I1211 12:20:51.766461 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:20:51.766461 15296 solver.cpp:237]     Train net output #1: loss = 0.850571 (* 1 = 0.850571 loss)
I1211 12:20:51.766461 15296 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1211 12:20:57.783134 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:20:58.045191 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84000.caffemodel
I1211 12:20:58.060190 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84000.solverstate
I1211 12:20:58.065191 15296 solver.cpp:330] Iteration 84000, Testing net (#0)
I1211 12:20:58.065191 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:20:59.583006  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:20:59.644040 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5914
I1211 12:20:59.644040 15296 solver.cpp:397]     Test net output #1: loss = 1.54242 (* 1 = 1.54242 loss)
I1211 12:20:59.706084 15296 solver.cpp:218] Iteration 84000 (12.5955 iter/s, 7.93934s/100 iters), loss = 0.572377
I1211 12:20:59.706084 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:20:59.706084 15296 solver.cpp:237]     Train net output #1: loss = 0.572377 (* 1 = 0.572377 loss)
I1211 12:20:59.706084 15296 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1211 12:21:06.038183 15296 solver.cpp:218] Iteration 84100 (15.792 iter/s, 6.3323s/100 iters), loss = 0.811816
I1211 12:21:06.038183 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:21:06.038183 15296 solver.cpp:237]     Train net output #1: loss = 0.811816 (* 1 = 0.811816 loss)
I1211 12:21:06.038183 15296 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1211 12:21:12.443626 15296 solver.cpp:218] Iteration 84200 (15.6134 iter/s, 6.40475s/100 iters), loss = 0.534806
I1211 12:21:12.443626 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:21:12.443626 15296 solver.cpp:237]     Train net output #1: loss = 0.534806 (* 1 = 0.534806 loss)
I1211 12:21:12.443626 15296 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1211 12:21:18.881041 15296 solver.cpp:218] Iteration 84300 (15.5365 iter/s, 6.43647s/100 iters), loss = 0.760806
I1211 12:21:18.881041 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:21:18.881041 15296 solver.cpp:237]     Train net output #1: loss = 0.760806 (* 1 = 0.760806 loss)
I1211 12:21:18.881041 15296 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1211 12:21:25.235565 15296 solver.cpp:218] Iteration 84400 (15.7358 iter/s, 6.35494s/100 iters), loss = 0.743267
I1211 12:21:25.235565 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:21:25.235565 15296 solver.cpp:237]     Train net output #1: loss = 0.743267 (* 1 = 0.743267 loss)
I1211 12:21:25.236572 15296 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1211 12:21:31.581115 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:21:31.830127 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84500.caffemodel
I1211 12:21:31.846128 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84500.solverstate
I1211 12:21:31.850127 15296 solver.cpp:330] Iteration 84500, Testing net (#0)
I1211 12:21:31.850127 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:21:33.372239  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:21:33.432253 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5871
I1211 12:21:33.432253 15296 solver.cpp:397]     Test net output #1: loss = 1.61709 (* 1 = 1.61709 loss)
I1211 12:21:33.494247 15296 solver.cpp:218] Iteration 84500 (12.1104 iter/s, 8.25734s/100 iters), loss = 0.590526
I1211 12:21:33.494247 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:21:33.494247 15296 solver.cpp:237]     Train net output #1: loss = 0.590526 (* 1 = 0.590526 loss)
I1211 12:21:33.494247 15296 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1211 12:21:39.834723 15296 solver.cpp:218] Iteration 84600 (15.7723 iter/s, 6.34023s/100 iters), loss = 0.720761
I1211 12:21:39.834723 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:21:39.834723 15296 solver.cpp:237]     Train net output #1: loss = 0.720761 (* 1 = 0.720761 loss)
I1211 12:21:39.834723 15296 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1211 12:21:46.181187 15296 solver.cpp:218] Iteration 84700 (15.7581 iter/s, 6.34593s/100 iters), loss = 0.622545
I1211 12:21:46.181187 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:21:46.181187 15296 solver.cpp:237]     Train net output #1: loss = 0.622545 (* 1 = 0.622545 loss)
I1211 12:21:46.181187 15296 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1211 12:21:52.625861 15296 solver.cpp:218] Iteration 84800 (15.5167 iter/s, 6.44468s/100 iters), loss = 0.680742
I1211 12:21:52.625861 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:21:52.625861 15296 solver.cpp:237]     Train net output #1: loss = 0.680742 (* 1 = 0.680742 loss)
I1211 12:21:52.625861 15296 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1211 12:21:59.101303 15296 solver.cpp:218] Iteration 84900 (15.4448 iter/s, 6.47466s/100 iters), loss = 0.804115
I1211 12:21:59.101303 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:21:59.101303 15296 solver.cpp:237]     Train net output #1: loss = 0.804115 (* 1 = 0.804115 loss)
I1211 12:21:59.101303 15296 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1211 12:22:05.231050 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:22:05.485050 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85000.caffemodel
I1211 12:22:05.503553 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85000.solverstate
I1211 12:22:05.508049 15296 solver.cpp:330] Iteration 85000, Testing net (#0)
I1211 12:22:05.508049 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:22:07.043560  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:22:07.103592 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5686
I1211 12:22:07.103592 15296 solver.cpp:397]     Test net output #1: loss = 1.6848 (* 1 = 1.6848 loss)
I1211 12:22:07.164602 15296 solver.cpp:218] Iteration 85000 (12.402 iter/s, 8.06324s/100 iters), loss = 0.732944
I1211 12:22:07.164602 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:22:07.164602 15296 solver.cpp:237]     Train net output #1: loss = 0.732944 (* 1 = 0.732944 loss)
I1211 12:22:07.164602 15296 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1211 12:22:13.600960 15296 solver.cpp:218] Iteration 85100 (15.5384 iter/s, 6.43566s/100 iters), loss = 0.727496
I1211 12:22:13.600960 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:22:13.600960 15296 solver.cpp:237]     Train net output #1: loss = 0.727496 (* 1 = 0.727496 loss)
I1211 12:22:13.600960 15296 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1211 12:22:19.952306 15296 solver.cpp:218] Iteration 85200 (15.7463 iter/s, 6.35071s/100 iters), loss = 0.592241
I1211 12:22:19.952306 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:22:19.952306 15296 solver.cpp:237]     Train net output #1: loss = 0.592241 (* 1 = 0.592241 loss)
I1211 12:22:19.952306 15296 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1211 12:22:26.337882 15296 solver.cpp:218] Iteration 85300 (15.6615 iter/s, 6.38507s/100 iters), loss = 0.872706
I1211 12:22:26.338382 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:22:26.338382 15296 solver.cpp:237]     Train net output #1: loss = 0.872706 (* 1 = 0.872706 loss)
I1211 12:22:26.338382 15296 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1211 12:22:32.734694 15296 solver.cpp:218] Iteration 85400 (15.6349 iter/s, 6.39597s/100 iters), loss = 0.79656
I1211 12:22:32.734694 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:22:32.734694 15296 solver.cpp:237]     Train net output #1: loss = 0.79656 (* 1 = 0.79656 loss)
I1211 12:22:32.734694 15296 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1211 12:22:38.831594 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:22:39.079193 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85500.caffemodel
I1211 12:22:39.094193 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85500.solverstate
I1211 12:22:39.099196 15296 solver.cpp:330] Iteration 85500, Testing net (#0)
I1211 12:22:39.099196 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:22:40.632226  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:22:40.693727 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5868
I1211 12:22:40.693727 15296 solver.cpp:397]     Test net output #1: loss = 1.62279 (* 1 = 1.62279 loss)
I1211 12:22:40.758744 15296 solver.cpp:218] Iteration 85500 (12.4635 iter/s, 8.02346s/100 iters), loss = 0.613955
I1211 12:22:40.758744 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:22:40.758744 15296 solver.cpp:237]     Train net output #1: loss = 0.613955 (* 1 = 0.613955 loss)
I1211 12:22:40.758744 15296 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1211 12:22:47.200525 15296 solver.cpp:218] Iteration 85600 (15.5232 iter/s, 6.44197s/100 iters), loss = 0.754986
I1211 12:22:47.200525 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:22:47.200525 15296 solver.cpp:237]     Train net output #1: loss = 0.754986 (* 1 = 0.754986 loss)
I1211 12:22:47.200525 15296 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1211 12:22:53.582448 15296 solver.cpp:218] Iteration 85700 (15.6699 iter/s, 6.38165s/100 iters), loss = 0.633154
I1211 12:22:53.582448 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:22:53.582448 15296 solver.cpp:237]     Train net output #1: loss = 0.633154 (* 1 = 0.633154 loss)
I1211 12:22:53.582448 15296 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1211 12:22:59.948794 15296 solver.cpp:218] Iteration 85800 (15.7103 iter/s, 6.36525s/100 iters), loss = 0.719455
I1211 12:22:59.948794 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:22:59.948794 15296 solver.cpp:237]     Train net output #1: loss = 0.719455 (* 1 = 0.719455 loss)
I1211 12:22:59.948794 15296 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1211 12:23:06.307907 15296 solver.cpp:218] Iteration 85900 (15.7254 iter/s, 6.35914s/100 iters), loss = 0.710907
I1211 12:23:06.307907 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:23:06.307907 15296 solver.cpp:237]     Train net output #1: loss = 0.710907 (* 1 = 0.710907 loss)
I1211 12:23:06.307907 15296 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1211 12:23:12.343849 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:23:12.594365 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86000.caffemodel
I1211 12:23:12.609365 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86000.solverstate
I1211 12:23:12.613366 15296 solver.cpp:330] Iteration 86000, Testing net (#0)
I1211 12:23:12.613366 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:23:14.136529  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:23:14.197537 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5844
I1211 12:23:14.197537 15296 solver.cpp:397]     Test net output #1: loss = 1.61701 (* 1 = 1.61701 loss)
I1211 12:23:14.258536 15296 solver.cpp:218] Iteration 86000 (12.5789 iter/s, 7.94981s/100 iters), loss = 0.627502
I1211 12:23:14.258536 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:23:14.258536 15296 solver.cpp:237]     Train net output #1: loss = 0.627502 (* 1 = 0.627502 loss)
I1211 12:23:14.258536 15296 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1211 12:23:20.600018 15296 solver.cpp:218] Iteration 86100 (15.7698 iter/s, 6.34122s/100 iters), loss = 0.675227
I1211 12:23:20.600018 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:23:20.600018 15296 solver.cpp:237]     Train net output #1: loss = 0.675227 (* 1 = 0.675227 loss)
I1211 12:23:20.600018 15296 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1211 12:23:26.943586 15296 solver.cpp:218] Iteration 86200 (15.7656 iter/s, 6.34291s/100 iters), loss = 0.649952
I1211 12:23:26.943586 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:23:26.943586 15296 solver.cpp:237]     Train net output #1: loss = 0.649952 (* 1 = 0.649952 loss)
I1211 12:23:26.943586 15296 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1211 12:23:33.274091 15296 solver.cpp:218] Iteration 86300 (15.7984 iter/s, 6.32977s/100 iters), loss = 0.834685
I1211 12:23:33.274091 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:23:33.274091 15296 solver.cpp:237]     Train net output #1: loss = 0.834685 (* 1 = 0.834685 loss)
I1211 12:23:33.274091 15296 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1211 12:23:39.607570 15296 solver.cpp:218] Iteration 86400 (15.7888 iter/s, 6.33359s/100 iters), loss = 0.777527
I1211 12:23:39.607570 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:23:39.607570 15296 solver.cpp:237]     Train net output #1: loss = 0.777527 (* 1 = 0.777527 loss)
I1211 12:23:39.607570 15296 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1211 12:23:45.663024 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:23:45.916035 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86500.caffemodel
I1211 12:23:45.932035 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86500.solverstate
I1211 12:23:45.936035 15296 solver.cpp:330] Iteration 86500, Testing net (#0)
I1211 12:23:45.936035 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:23:47.486203  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:23:47.547207 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5866
I1211 12:23:47.547207 15296 solver.cpp:397]     Test net output #1: loss = 1.61402 (* 1 = 1.61402 loss)
I1211 12:23:47.608208 15296 solver.cpp:218] Iteration 86500 (12.5007 iter/s, 7.99957s/100 iters), loss = 0.692911
I1211 12:23:47.608208 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:23:47.608208 15296 solver.cpp:237]     Train net output #1: loss = 0.692911 (* 1 = 0.692911 loss)
I1211 12:23:47.608208 15296 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1211 12:23:53.974670 15296 solver.cpp:218] Iteration 86600 (15.7066 iter/s, 6.36674s/100 iters), loss = 0.757809
I1211 12:23:53.974670 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:23:53.974670 15296 solver.cpp:237]     Train net output #1: loss = 0.757809 (* 1 = 0.757809 loss)
I1211 12:23:53.974670 15296 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1211 12:24:00.372167 15296 solver.cpp:218] Iteration 86700 (15.6338 iter/s, 6.39641s/100 iters), loss = 0.572476
I1211 12:24:00.372167 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:24:00.372167 15296 solver.cpp:237]     Train net output #1: loss = 0.572476 (* 1 = 0.572476 loss)
I1211 12:24:00.372167 15296 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1211 12:24:06.731679 15296 solver.cpp:218] Iteration 86800 (15.7236 iter/s, 6.35989s/100 iters), loss = 0.858511
I1211 12:24:06.732681 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 12:24:06.732681 15296 solver.cpp:237]     Train net output #1: loss = 0.858511 (* 1 = 0.858511 loss)
I1211 12:24:06.732681 15296 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1211 12:24:13.103116 15296 solver.cpp:218] Iteration 86900 (15.6975 iter/s, 6.37045s/100 iters), loss = 0.801422
I1211 12:24:13.103116 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:24:13.103116 15296 solver.cpp:237]     Train net output #1: loss = 0.801422 (* 1 = 0.801422 loss)
I1211 12:24:13.103116 15296 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1211 12:24:19.184576 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:24:19.436584 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87000.caffemodel
I1211 12:24:19.452090 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87000.solverstate
I1211 12:24:19.457096 15296 solver.cpp:330] Iteration 87000, Testing net (#0)
I1211 12:24:19.457096 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:24:20.986693  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:24:21.048197 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6136
I1211 12:24:21.048197 15296 solver.cpp:397]     Test net output #1: loss = 1.46751 (* 1 = 1.46751 loss)
I1211 12:24:21.108700 15296 solver.cpp:218] Iteration 87000 (12.4914 iter/s, 8.00554s/100 iters), loss = 0.60021
I1211 12:24:21.108700 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:24:21.108700 15296 solver.cpp:237]     Train net output #1: loss = 0.60021 (* 1 = 0.60021 loss)
I1211 12:24:21.108700 15296 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1211 12:24:27.564074 15296 solver.cpp:218] Iteration 87100 (15.494 iter/s, 6.45412s/100 iters), loss = 0.709021
I1211 12:24:27.564074 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:24:27.564074 15296 solver.cpp:237]     Train net output #1: loss = 0.709021 (* 1 = 0.709021 loss)
I1211 12:24:27.564074 15296 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1211 12:24:33.956121 15296 solver.cpp:218] Iteration 87200 (15.6452 iter/s, 6.39175s/100 iters), loss = 0.654541
I1211 12:24:33.956121 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:24:33.956121 15296 solver.cpp:237]     Train net output #1: loss = 0.654541 (* 1 = 0.654541 loss)
I1211 12:24:33.956121 15296 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1211 12:24:40.305115 15296 solver.cpp:218] Iteration 87300 (15.7523 iter/s, 6.3483s/100 iters), loss = 0.822934
I1211 12:24:40.305115 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:24:40.305115 15296 solver.cpp:237]     Train net output #1: loss = 0.822934 (* 1 = 0.822934 loss)
I1211 12:24:40.305115 15296 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1211 12:24:46.634536 15296 solver.cpp:218] Iteration 87400 (15.8002 iter/s, 6.32904s/100 iters), loss = 0.746776
I1211 12:24:46.634536 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:24:46.634536 15296 solver.cpp:237]     Train net output #1: loss = 0.746776 (* 1 = 0.746776 loss)
I1211 12:24:46.634536 15296 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1211 12:24:52.657446 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:24:52.904960 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87500.caffemodel
I1211 12:24:52.919960 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87500.solverstate
I1211 12:24:52.924962 15296 solver.cpp:330] Iteration 87500, Testing net (#0)
I1211 12:24:52.924962 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:24:54.446624  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:24:54.507127 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5751
I1211 12:24:54.507127 15296 solver.cpp:397]     Test net output #1: loss = 1.66414 (* 1 = 1.66414 loss)
I1211 12:24:54.568169 15296 solver.cpp:218] Iteration 87500 (12.6046 iter/s, 7.9336s/100 iters), loss = 0.68955
I1211 12:24:54.568169 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:24:54.568169 15296 solver.cpp:237]     Train net output #1: loss = 0.68955 (* 1 = 0.68955 loss)
I1211 12:24:54.568169 15296 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1211 12:25:00.913663 15296 solver.cpp:218] Iteration 87600 (15.7598 iter/s, 6.34526s/100 iters), loss = 0.667483
I1211 12:25:00.913663 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:25:00.913663 15296 solver.cpp:237]     Train net output #1: loss = 0.667483 (* 1 = 0.667483 loss)
I1211 12:25:00.913663 15296 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1211 12:25:07.256718 15296 solver.cpp:218] Iteration 87700 (15.7676 iter/s, 6.3421s/100 iters), loss = 0.625697
I1211 12:25:07.256718 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:25:07.256718 15296 solver.cpp:237]     Train net output #1: loss = 0.625697 (* 1 = 0.625697 loss)
I1211 12:25:07.256718 15296 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1211 12:25:13.597712 15296 solver.cpp:218] Iteration 87800 (15.7722 iter/s, 6.34025s/100 iters), loss = 0.839619
I1211 12:25:13.597712 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:25:13.597712 15296 solver.cpp:237]     Train net output #1: loss = 0.839619 (* 1 = 0.839619 loss)
I1211 12:25:13.597712 15296 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1211 12:25:19.939198 15296 solver.cpp:218] Iteration 87900 (15.7693 iter/s, 6.34144s/100 iters), loss = 0.719705
I1211 12:25:19.939198 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:25:19.939198 15296 solver.cpp:237]     Train net output #1: loss = 0.719705 (* 1 = 0.719705 loss)
I1211 12:25:19.939198 15296 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1211 12:25:25.959903 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:25:26.207962 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88000.caffemodel
I1211 12:25:26.222961 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88000.solverstate
I1211 12:25:26.227977 15296 solver.cpp:330] Iteration 88000, Testing net (#0)
I1211 12:25:26.227977 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:25:27.749073  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:25:27.809594 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6002
I1211 12:25:27.809594 15296 solver.cpp:397]     Test net output #1: loss = 1.49607 (* 1 = 1.49607 loss)
I1211 12:25:27.870611 15296 solver.cpp:218] Iteration 88000 (12.6094 iter/s, 7.93057s/100 iters), loss = 0.662918
I1211 12:25:27.870611 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:25:27.870611 15296 solver.cpp:237]     Train net output #1: loss = 0.662918 (* 1 = 0.662918 loss)
I1211 12:25:27.870611 15296 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1211 12:25:34.209437 15296 solver.cpp:218] Iteration 88100 (15.7766 iter/s, 6.33851s/100 iters), loss = 0.717209
I1211 12:25:34.209437 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:25:34.209437 15296 solver.cpp:237]     Train net output #1: loss = 0.717209 (* 1 = 0.717209 loss)
I1211 12:25:34.209437 15296 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1211 12:25:40.537811 15296 solver.cpp:218] Iteration 88200 (15.8031 iter/s, 6.32788s/100 iters), loss = 0.613412
I1211 12:25:40.537811 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:25:40.537811 15296 solver.cpp:237]     Train net output #1: loss = 0.613412 (* 1 = 0.613412 loss)
I1211 12:25:40.537811 15296 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1211 12:25:46.874756 15296 solver.cpp:218] Iteration 88300 (15.7805 iter/s, 6.33694s/100 iters), loss = 0.832597
I1211 12:25:46.874756 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:25:46.874756 15296 solver.cpp:237]     Train net output #1: loss = 0.832597 (* 1 = 0.832597 loss)
I1211 12:25:46.874756 15296 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1211 12:25:53.208225 15296 solver.cpp:218] Iteration 88400 (15.7901 iter/s, 6.33308s/100 iters), loss = 0.843062
I1211 12:25:53.208225 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 12:25:53.208225 15296 solver.cpp:237]     Train net output #1: loss = 0.843062 (* 1 = 0.843062 loss)
I1211 12:25:53.208225 15296 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1211 12:25:59.237635 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:25:59.487658 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88500.caffemodel
I1211 12:25:59.504662 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88500.solverstate
I1211 12:25:59.508661 15296 solver.cpp:330] Iteration 88500, Testing net (#0)
I1211 12:25:59.508661 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:26:01.028826  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:26:01.089826 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5752
I1211 12:26:01.089826 15296 solver.cpp:397]     Test net output #1: loss = 1.70099 (* 1 = 1.70099 loss)
I1211 12:26:01.149828 15296 solver.cpp:218] Iteration 88500 (12.5925 iter/s, 7.94126s/100 iters), loss = 0.815086
I1211 12:26:01.149828 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:26:01.149828 15296 solver.cpp:237]     Train net output #1: loss = 0.815086 (* 1 = 0.815086 loss)
I1211 12:26:01.149828 15296 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1211 12:26:07.489236 15296 solver.cpp:218] Iteration 88600 (15.7763 iter/s, 6.33863s/100 iters), loss = 0.705428
I1211 12:26:07.489737 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:26:07.489737 15296 solver.cpp:237]     Train net output #1: loss = 0.705428 (* 1 = 0.705428 loss)
I1211 12:26:07.489737 15296 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1211 12:26:13.819731 15296 solver.cpp:218] Iteration 88700 (15.7976 iter/s, 6.33008s/100 iters), loss = 0.651857
I1211 12:26:13.819731 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:26:13.819731 15296 solver.cpp:237]     Train net output #1: loss = 0.651857 (* 1 = 0.651857 loss)
I1211 12:26:13.819731 15296 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1211 12:26:20.147176 15296 solver.cpp:218] Iteration 88800 (15.8055 iter/s, 6.32692s/100 iters), loss = 0.739232
I1211 12:26:20.147176 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:26:20.147176 15296 solver.cpp:237]     Train net output #1: loss = 0.739232 (* 1 = 0.739232 loss)
I1211 12:26:20.147176 15296 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1211 12:26:26.474288 15296 solver.cpp:218] Iteration 88900 (15.8065 iter/s, 6.32652s/100 iters), loss = 0.6809
I1211 12:26:26.474288 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:26:26.474288 15296 solver.cpp:237]     Train net output #1: loss = 0.6809 (* 1 = 0.6809 loss)
I1211 12:26:26.474288 15296 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1211 12:26:32.498749 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:26:32.750758 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89000.caffemodel
I1211 12:26:32.766264 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89000.solverstate
I1211 12:26:32.770766 15296 solver.cpp:330] Iteration 89000, Testing net (#0)
I1211 12:26:32.770766 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:26:34.291275  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:26:34.351275 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5936
I1211 12:26:34.351275 15296 solver.cpp:397]     Test net output #1: loss = 1.57262 (* 1 = 1.57262 loss)
I1211 12:26:34.412281 15296 solver.cpp:218] Iteration 89000 (12.5985 iter/s, 7.93746s/100 iters), loss = 0.654608
I1211 12:26:34.412281 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:26:34.412281 15296 solver.cpp:237]     Train net output #1: loss = 0.654608 (* 1 = 0.654608 loss)
I1211 12:26:34.412281 15296 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1211 12:26:40.765236 15296 solver.cpp:218] Iteration 89100 (15.7411 iter/s, 6.35278s/100 iters), loss = 0.66801
I1211 12:26:40.765736 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:26:40.765736 15296 solver.cpp:237]     Train net output #1: loss = 0.66801 (* 1 = 0.66801 loss)
I1211 12:26:40.765736 15296 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1211 12:26:47.099195 15296 solver.cpp:218] Iteration 89200 (15.7881 iter/s, 6.33387s/100 iters), loss = 0.669128
I1211 12:26:47.099195 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:26:47.099195 15296 solver.cpp:237]     Train net output #1: loss = 0.669128 (* 1 = 0.669128 loss)
I1211 12:26:47.099195 15296 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1211 12:26:53.437633 15296 solver.cpp:218] Iteration 89300 (15.7776 iter/s, 6.33811s/100 iters), loss = 0.850145
I1211 12:26:53.437633 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:26:53.438633 15296 solver.cpp:237]     Train net output #1: loss = 0.850145 (* 1 = 0.850145 loss)
I1211 12:26:53.438633 15296 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1211 12:26:59.771592 15296 solver.cpp:218] Iteration 89400 (15.7907 iter/s, 6.33285s/100 iters), loss = 0.747537
I1211 12:26:59.771592 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:26:59.771592 15296 solver.cpp:237]     Train net output #1: loss = 0.747537 (* 1 = 0.747537 loss)
I1211 12:26:59.771592 15296 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1211 12:27:05.792531 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:27:06.043541 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89500.caffemodel
I1211 12:27:06.059541 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89500.solverstate
I1211 12:27:06.064546 15296 solver.cpp:330] Iteration 89500, Testing net (#0)
I1211 12:27:06.064546 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:27:07.585690  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:27:07.646689 15296 solver.cpp:397]     Test net output #0: accuracy = 0.591
I1211 12:27:07.646689 15296 solver.cpp:397]     Test net output #1: loss = 1.62358 (* 1 = 1.62358 loss)
I1211 12:27:07.706694 15296 solver.cpp:218] Iteration 89500 (12.6025 iter/s, 7.93492s/100 iters), loss = 0.636293
I1211 12:27:07.706694 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:27:07.706694 15296 solver.cpp:237]     Train net output #1: loss = 0.636293 (* 1 = 0.636293 loss)
I1211 12:27:07.706694 15296 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1211 12:27:14.042182 15296 solver.cpp:218] Iteration 89600 (15.785 iter/s, 6.33514s/100 iters), loss = 0.66159
I1211 12:27:14.042182 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:27:14.042182 15296 solver.cpp:237]     Train net output #1: loss = 0.66159 (* 1 = 0.66159 loss)
I1211 12:27:14.042182 15296 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1211 12:27:20.383635 15296 solver.cpp:218] Iteration 89700 (15.7708 iter/s, 6.34082s/100 iters), loss = 0.626556
I1211 12:27:20.383635 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:27:20.383635 15296 solver.cpp:237]     Train net output #1: loss = 0.626556 (* 1 = 0.626556 loss)
I1211 12:27:20.383635 15296 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1211 12:27:26.731101 15296 solver.cpp:218] Iteration 89800 (15.756 iter/s, 6.3468s/100 iters), loss = 0.823866
I1211 12:27:26.731101 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:27:26.731101 15296 solver.cpp:237]     Train net output #1: loss = 0.823866 (* 1 = 0.823866 loss)
I1211 12:27:26.731101 15296 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1211 12:27:33.067571 15296 solver.cpp:218] Iteration 89900 (15.7828 iter/s, 6.33601s/100 iters), loss = 0.781063
I1211 12:27:33.067571 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:27:33.067571 15296 solver.cpp:237]     Train net output #1: loss = 0.781063 (* 1 = 0.781063 loss)
I1211 12:27:33.067571 15296 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1211 12:27:39.083992 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:27:39.334000 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90000.caffemodel
I1211 12:27:39.349001 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90000.solverstate
I1211 12:27:39.354001 15296 solver.cpp:330] Iteration 90000, Testing net (#0)
I1211 12:27:39.354001 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:27:40.876125  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:27:40.936164 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5711
I1211 12:27:40.936164 15296 solver.cpp:397]     Test net output #1: loss = 1.67838 (* 1 = 1.67838 loss)
I1211 12:27:40.996168 15296 solver.cpp:218] Iteration 90000 (12.6123 iter/s, 7.92879s/100 iters), loss = 0.743406
I1211 12:27:40.996168 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:27:40.996168 15296 solver.cpp:237]     Train net output #1: loss = 0.743406 (* 1 = 0.743406 loss)
I1211 12:27:40.996168 15296 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1211 12:27:47.323591 15296 solver.cpp:218] Iteration 90100 (15.8057 iter/s, 6.32682s/100 iters), loss = 0.84477
I1211 12:27:47.323591 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:27:47.323591 15296 solver.cpp:237]     Train net output #1: loss = 0.84477 (* 1 = 0.84477 loss)
I1211 12:27:47.323591 15296 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1211 12:27:53.661025 15296 solver.cpp:218] Iteration 90200 (15.7794 iter/s, 6.33736s/100 iters), loss = 0.602152
I1211 12:27:53.662025 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:27:53.662025 15296 solver.cpp:237]     Train net output #1: loss = 0.602152 (* 1 = 0.602152 loss)
I1211 12:27:53.662025 15296 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1211 12:27:59.989506 15296 solver.cpp:218] Iteration 90300 (15.8049 iter/s, 6.32715s/100 iters), loss = 0.891719
I1211 12:27:59.989506 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:27:59.989506 15296 solver.cpp:237]     Train net output #1: loss = 0.891719 (* 1 = 0.891719 loss)
I1211 12:27:59.989506 15296 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1211 12:28:06.320988 15296 solver.cpp:218] Iteration 90400 (15.7946 iter/s, 6.33129s/100 iters), loss = 0.815109
I1211 12:28:06.320988 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:28:06.320988 15296 solver.cpp:237]     Train net output #1: loss = 0.815109 (* 1 = 0.815109 loss)
I1211 12:28:06.320988 15296 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1211 12:28:12.344419 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:28:12.592435 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90500.caffemodel
I1211 12:28:12.607436 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90500.solverstate
I1211 12:28:12.611435 15296 solver.cpp:330] Iteration 90500, Testing net (#0)
I1211 12:28:12.611435 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:28:14.133585  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:28:14.194595 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5844
I1211 12:28:14.194595 15296 solver.cpp:397]     Test net output #1: loss = 1.6336 (* 1 = 1.6336 loss)
I1211 12:28:14.255599 15296 solver.cpp:218] Iteration 90500 (12.6038 iter/s, 7.93411s/100 iters), loss = 0.671126
I1211 12:28:14.255599 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:28:14.255599 15296 solver.cpp:237]     Train net output #1: loss = 0.671126 (* 1 = 0.671126 loss)
I1211 12:28:14.255599 15296 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1211 12:28:20.589099 15296 solver.cpp:218] Iteration 90600 (15.7897 iter/s, 6.33325s/100 iters), loss = 0.682994
I1211 12:28:20.589099 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:28:20.589099 15296 solver.cpp:237]     Train net output #1: loss = 0.682994 (* 1 = 0.682994 loss)
I1211 12:28:20.589099 15296 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1211 12:28:26.916568 15296 solver.cpp:218] Iteration 90700 (15.806 iter/s, 6.3267s/100 iters), loss = 0.570998
I1211 12:28:26.916568 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:28:26.916568 15296 solver.cpp:237]     Train net output #1: loss = 0.570998 (* 1 = 0.570998 loss)
I1211 12:28:26.916568 15296 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1211 12:28:33.251477 15296 solver.cpp:218] Iteration 90800 (15.7861 iter/s, 6.33468s/100 iters), loss = 0.717705
I1211 12:28:33.251477 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:28:33.251477 15296 solver.cpp:237]     Train net output #1: loss = 0.717705 (* 1 = 0.717705 loss)
I1211 12:28:33.251477 15296 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1211 12:28:39.580435 15296 solver.cpp:218] Iteration 90900 (15.8009 iter/s, 6.32874s/100 iters), loss = 0.738809
I1211 12:28:39.580435 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:28:39.580435 15296 solver.cpp:237]     Train net output #1: loss = 0.738809 (* 1 = 0.738809 loss)
I1211 12:28:39.580435 15296 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1211 12:28:45.595824 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:28:45.845818 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91000.caffemodel
I1211 12:28:45.861340 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91000.solverstate
I1211 12:28:45.865844 15296 solver.cpp:330] Iteration 91000, Testing net (#0)
I1211 12:28:45.865844 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:28:47.385606  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:28:47.446604 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5637
I1211 12:28:47.446604 15296 solver.cpp:397]     Test net output #1: loss = 1.74033 (* 1 = 1.74033 loss)
I1211 12:28:47.508117 15296 solver.cpp:218] Iteration 91000 (12.6157 iter/s, 7.9266s/100 iters), loss = 0.699717
I1211 12:28:47.508117 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:28:47.508117 15296 solver.cpp:237]     Train net output #1: loss = 0.699717 (* 1 = 0.699717 loss)
I1211 12:28:47.508117 15296 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1211 12:28:53.859055 15296 solver.cpp:218] Iteration 91100 (15.7467 iter/s, 6.35054s/100 iters), loss = 0.711686
I1211 12:28:53.859055 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:28:53.859055 15296 solver.cpp:237]     Train net output #1: loss = 0.711686 (* 1 = 0.711686 loss)
I1211 12:28:53.859055 15296 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1211 12:29:00.200562 15296 solver.cpp:218] Iteration 91200 (15.7696 iter/s, 6.34132s/100 iters), loss = 0.585685
I1211 12:29:00.200562 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:29:00.200562 15296 solver.cpp:237]     Train net output #1: loss = 0.585685 (* 1 = 0.585685 loss)
I1211 12:29:00.200562 15296 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1211 12:29:06.534052 15296 solver.cpp:218] Iteration 91300 (15.7907 iter/s, 6.33284s/100 iters), loss = 0.793031
I1211 12:29:06.534052 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 12:29:06.534052 15296 solver.cpp:237]     Train net output #1: loss = 0.793031 (* 1 = 0.793031 loss)
I1211 12:29:06.534052 15296 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1211 12:29:12.870757 15296 solver.cpp:218] Iteration 91400 (15.7825 iter/s, 6.33614s/100 iters), loss = 0.727624
I1211 12:29:12.870757 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:29:12.870757 15296 solver.cpp:237]     Train net output #1: loss = 0.727624 (* 1 = 0.727624 loss)
I1211 12:29:12.870757 15296 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1211 12:29:18.906759 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:29:19.158274 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91500.caffemodel
I1211 12:29:19.172777 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91500.solverstate
I1211 12:29:19.176777 15296 solver.cpp:330] Iteration 91500, Testing net (#0)
I1211 12:29:19.177778 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:29:20.696902  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:29:20.757905 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5793
I1211 12:29:20.758406 15296 solver.cpp:397]     Test net output #1: loss = 1.64221 (* 1 = 1.64221 loss)
I1211 12:29:20.818907 15296 solver.cpp:218] Iteration 91500 (12.5816 iter/s, 7.94815s/100 iters), loss = 0.645614
I1211 12:29:20.818907 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:29:20.818907 15296 solver.cpp:237]     Train net output #1: loss = 0.645614 (* 1 = 0.645614 loss)
I1211 12:29:20.818907 15296 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1211 12:29:27.154361 15296 solver.cpp:218] Iteration 91600 (15.7857 iter/s, 6.33486s/100 iters), loss = 0.744654
I1211 12:29:27.154361 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:29:27.154361 15296 solver.cpp:237]     Train net output #1: loss = 0.744654 (* 1 = 0.744654 loss)
I1211 12:29:27.154361 15296 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1211 12:29:33.484822 15296 solver.cpp:218] Iteration 91700 (15.7967 iter/s, 6.33043s/100 iters), loss = 0.601276
I1211 12:29:33.484822 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:29:33.484822 15296 solver.cpp:237]     Train net output #1: loss = 0.601276 (* 1 = 0.601276 loss)
I1211 12:29:33.484822 15296 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1211 12:29:39.819217 15296 solver.cpp:218] Iteration 91800 (15.7893 iter/s, 6.3334s/100 iters), loss = 0.666892
I1211 12:29:39.819217 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:29:39.819217 15296 solver.cpp:237]     Train net output #1: loss = 0.666892 (* 1 = 0.666892 loss)
I1211 12:29:39.819217 15296 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1211 12:29:46.147689 15296 solver.cpp:218] Iteration 91900 (15.8017 iter/s, 6.32844s/100 iters), loss = 0.668416
I1211 12:29:46.147689 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:29:46.147689 15296 solver.cpp:237]     Train net output #1: loss = 0.668416 (* 1 = 0.668416 loss)
I1211 12:29:46.147689 15296 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1211 12:29:52.168114 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:29:52.418123 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92000.caffemodel
I1211 12:29:52.433626 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92000.solverstate
I1211 12:29:52.438627 15296 solver.cpp:330] Iteration 92000, Testing net (#0)
I1211 12:29:52.438627 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:29:53.959250  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:29:54.020248 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5638
I1211 12:29:54.020248 15296 solver.cpp:397]     Test net output #1: loss = 1.72751 (* 1 = 1.72751 loss)
I1211 12:29:54.081254 15296 solver.cpp:218] Iteration 92000 (12.6058 iter/s, 7.93284s/100 iters), loss = 0.699247
I1211 12:29:54.081254 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:29:54.081254 15296 solver.cpp:237]     Train net output #1: loss = 0.699247 (* 1 = 0.699247 loss)
I1211 12:29:54.081254 15296 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1211 12:30:00.429759 15296 solver.cpp:218] Iteration 92100 (15.7537 iter/s, 6.34773s/100 iters), loss = 0.708238
I1211 12:30:00.429759 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 12:30:00.429759 15296 solver.cpp:237]     Train net output #1: loss = 0.708238 (* 1 = 0.708238 loss)
I1211 12:30:00.429759 15296 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1211 12:30:06.784323 15296 solver.cpp:218] Iteration 92200 (15.7373 iter/s, 6.35432s/100 iters), loss = 0.780171
I1211 12:30:06.784323 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:30:06.784323 15296 solver.cpp:237]     Train net output #1: loss = 0.780171 (* 1 = 0.780171 loss)
I1211 12:30:06.784323 15296 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1211 12:30:13.104799 15296 solver.cpp:218] Iteration 92300 (15.8223 iter/s, 6.3202s/100 iters), loss = 0.694504
I1211 12:30:13.104799 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:30:13.104799 15296 solver.cpp:237]     Train net output #1: loss = 0.694504 (* 1 = 0.694504 loss)
I1211 12:30:13.104799 15296 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1211 12:30:19.435533 15296 solver.cpp:218] Iteration 92400 (15.7968 iter/s, 6.3304s/100 iters), loss = 0.888823
I1211 12:30:19.435533 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:30:19.435533 15296 solver.cpp:237]     Train net output #1: loss = 0.888823 (* 1 = 0.888823 loss)
I1211 12:30:19.435533 15296 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1211 12:30:25.455560 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:30:25.705073 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92500.caffemodel
I1211 12:30:25.720073 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92500.solverstate
I1211 12:30:25.725075 15296 solver.cpp:330] Iteration 92500, Testing net (#0)
I1211 12:30:25.725075 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:30:27.245215  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:30:27.304850 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5875
I1211 12:30:27.304850 15296 solver.cpp:397]     Test net output #1: loss = 1.61846 (* 1 = 1.61846 loss)
I1211 12:30:27.366348 15296 solver.cpp:218] Iteration 92500 (12.6102 iter/s, 7.93006s/100 iters), loss = 0.666088
I1211 12:30:27.366348 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:30:27.366348 15296 solver.cpp:237]     Train net output #1: loss = 0.666088 (* 1 = 0.666088 loss)
I1211 12:30:27.366348 15296 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1211 12:30:33.713801 15296 solver.cpp:218] Iteration 92600 (15.7563 iter/s, 6.34668s/100 iters), loss = 0.673515
I1211 12:30:33.713801 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:30:33.713801 15296 solver.cpp:237]     Train net output #1: loss = 0.673515 (* 1 = 0.673515 loss)
I1211 12:30:33.713801 15296 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1211 12:30:40.057772 15296 solver.cpp:218] Iteration 92700 (15.7639 iter/s, 6.34359s/100 iters), loss = 0.676126
I1211 12:30:40.057772 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:30:40.057772 15296 solver.cpp:237]     Train net output #1: loss = 0.676126 (* 1 = 0.676126 loss)
I1211 12:30:40.057772 15296 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1211 12:30:46.394745 15296 solver.cpp:218] Iteration 92800 (15.7804 iter/s, 6.33698s/100 iters), loss = 0.84458
I1211 12:30:46.394745 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:30:46.394745 15296 solver.cpp:237]     Train net output #1: loss = 0.84458 (* 1 = 0.84458 loss)
I1211 12:30:46.394745 15296 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1211 12:30:52.731237 15296 solver.cpp:218] Iteration 92900 (15.7835 iter/s, 6.33573s/100 iters), loss = 0.764623
I1211 12:30:52.731237 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:30:52.731237 15296 solver.cpp:237]     Train net output #1: loss = 0.764623 (* 1 = 0.764623 loss)
I1211 12:30:52.731237 15296 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1211 12:30:58.765723 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:30:59.017733 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93000.caffemodel
I1211 12:30:59.032732 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93000.solverstate
I1211 12:30:59.037732 15296 solver.cpp:330] Iteration 93000, Testing net (#0)
I1211 12:30:59.037732 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:31:00.559901  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:31:00.619904 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5755
I1211 12:31:00.619904 15296 solver.cpp:397]     Test net output #1: loss = 1.7435 (* 1 = 1.7435 loss)
I1211 12:31:00.679910 15296 solver.cpp:218] Iteration 93000 (12.5806 iter/s, 7.94872s/100 iters), loss = 0.662601
I1211 12:31:00.679910 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:31:00.679910 15296 solver.cpp:237]     Train net output #1: loss = 0.662601 (* 1 = 0.662601 loss)
I1211 12:31:00.679910 15296 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1211 12:31:07.019376 15296 solver.cpp:218] Iteration 93100 (15.7769 iter/s, 6.33839s/100 iters), loss = 0.678123
I1211 12:31:07.019376 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:31:07.019376 15296 solver.cpp:237]     Train net output #1: loss = 0.678123 (* 1 = 0.678123 loss)
I1211 12:31:07.019376 15296 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1211 12:31:13.350855 15296 solver.cpp:218] Iteration 93200 (15.7955 iter/s, 6.33094s/100 iters), loss = 0.644758
I1211 12:31:13.350855 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:31:13.350855 15296 solver.cpp:237]     Train net output #1: loss = 0.644758 (* 1 = 0.644758 loss)
I1211 12:31:13.350855 15296 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1211 12:31:19.694319 15296 solver.cpp:218] Iteration 93300 (15.7636 iter/s, 6.34372s/100 iters), loss = 0.773943
I1211 12:31:19.694319 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:31:19.694319 15296 solver.cpp:237]     Train net output #1: loss = 0.773943 (* 1 = 0.773943 loss)
I1211 12:31:19.694319 15296 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1211 12:31:26.023818 15296 solver.cpp:218] Iteration 93400 (15.8014 iter/s, 6.32857s/100 iters), loss = 0.776384
I1211 12:31:26.023818 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 12:31:26.023818 15296 solver.cpp:237]     Train net output #1: loss = 0.776384 (* 1 = 0.776384 loss)
I1211 12:31:26.023818 15296 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1211 12:31:32.047226 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:31:32.296260 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93500.caffemodel
I1211 12:31:32.311260 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93500.solverstate
I1211 12:31:32.315260 15296 solver.cpp:330] Iteration 93500, Testing net (#0)
I1211 12:31:32.315260 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:31:33.833360  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:31:33.894364 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5713
I1211 12:31:33.894364 15296 solver.cpp:397]     Test net output #1: loss = 1.7215 (* 1 = 1.7215 loss)
I1211 12:31:33.955866 15296 solver.cpp:218] Iteration 93500 (12.6083 iter/s, 7.93131s/100 iters), loss = 0.621816
I1211 12:31:33.955866 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:31:33.955866 15296 solver.cpp:237]     Train net output #1: loss = 0.621816 (* 1 = 0.621816 loss)
I1211 12:31:33.955866 15296 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1211 12:31:40.296838 15296 solver.cpp:218] Iteration 93600 (15.7713 iter/s, 6.34063s/100 iters), loss = 0.725466
I1211 12:31:40.296838 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 12:31:40.296838 15296 solver.cpp:237]     Train net output #1: loss = 0.725466 (* 1 = 0.725466 loss)
I1211 12:31:40.296838 15296 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1211 12:31:46.633327 15296 solver.cpp:218] Iteration 93700 (15.7813 iter/s, 6.33661s/100 iters), loss = 0.584961
I1211 12:31:46.633327 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:31:46.633327 15296 solver.cpp:237]     Train net output #1: loss = 0.584961 (* 1 = 0.584961 loss)
I1211 12:31:46.633327 15296 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1211 12:31:52.976759 15296 solver.cpp:218] Iteration 93800 (15.7673 iter/s, 6.34222s/100 iters), loss = 0.710877
I1211 12:31:52.976759 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 12:31:52.976759 15296 solver.cpp:237]     Train net output #1: loss = 0.710877 (* 1 = 0.710877 loss)
I1211 12:31:52.976759 15296 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1211 12:31:59.307179 15296 solver.cpp:218] Iteration 93900 (15.7966 iter/s, 6.33047s/100 iters), loss = 0.736635
I1211 12:31:59.307179 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:31:59.307179 15296 solver.cpp:237]     Train net output #1: loss = 0.736635 (* 1 = 0.736635 loss)
I1211 12:31:59.307179 15296 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1211 12:32:05.325603 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:32:05.574615 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94000.caffemodel
I1211 12:32:05.589618 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94000.solverstate
I1211 12:32:05.594619 15296 solver.cpp:330] Iteration 94000, Testing net (#0)
I1211 12:32:05.594619 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:32:07.115734  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:32:07.176743 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5797
I1211 12:32:07.176743 15296 solver.cpp:397]     Test net output #1: loss = 1.6718 (* 1 = 1.6718 loss)
I1211 12:32:07.237738 15296 solver.cpp:218] Iteration 94000 (12.6097 iter/s, 7.93042s/100 iters), loss = 0.796388
I1211 12:32:07.237738 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:32:07.237738 15296 solver.cpp:237]     Train net output #1: loss = 0.796388 (* 1 = 0.796388 loss)
I1211 12:32:07.237738 15296 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1211 12:32:13.572209 15296 solver.cpp:218] Iteration 94100 (15.7887 iter/s, 6.33366s/100 iters), loss = 0.689364
I1211 12:32:13.572209 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:32:13.572209 15296 solver.cpp:237]     Train net output #1: loss = 0.689364 (* 1 = 0.689364 loss)
I1211 12:32:13.572209 15296 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1211 12:32:19.897097 15296 solver.cpp:218] Iteration 94200 (15.812 iter/s, 6.3243s/100 iters), loss = 0.709404
I1211 12:32:19.897097 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:32:19.897097 15296 solver.cpp:237]     Train net output #1: loss = 0.709404 (* 1 = 0.709404 loss)
I1211 12:32:19.897097 15296 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1211 12:32:26.224041 15296 solver.cpp:218] Iteration 94300 (15.8072 iter/s, 6.32623s/100 iters), loss = 0.688383
I1211 12:32:26.224041 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 12:32:26.224041 15296 solver.cpp:237]     Train net output #1: loss = 0.688383 (* 1 = 0.688383 loss)
I1211 12:32:26.224041 15296 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1211 12:32:32.554514 15296 solver.cpp:218] Iteration 94400 (15.7975 iter/s, 6.3301s/100 iters), loss = 0.795771
I1211 12:32:32.554514 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 12:32:32.554514 15296 solver.cpp:237]     Train net output #1: loss = 0.795771 (* 1 = 0.795771 loss)
I1211 12:32:32.554514 15296 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1211 12:32:38.571990 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:32:38.822015 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94500.caffemodel
I1211 12:32:38.838016 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94500.solverstate
I1211 12:32:38.843015 15296 solver.cpp:330] Iteration 94500, Testing net (#0)
I1211 12:32:38.843015 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:32:40.365142  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:32:40.426154 15296 solver.cpp:397]     Test net output #0: accuracy = 0.5834
I1211 12:32:40.426154 15296 solver.cpp:397]     Test net output #1: loss = 1.59052 (* 1 = 1.59052 loss)
I1211 12:32:40.487146 15296 solver.cpp:218] Iteration 94500 (12.6058 iter/s, 7.93284s/100 iters), loss = 0.787043
I1211 12:32:40.487146 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:32:40.487146 15296 solver.cpp:237]     Train net output #1: loss = 0.787043 (* 1 = 0.787043 loss)
I1211 12:32:40.487146 15296 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1211 12:32:46.827955 15296 solver.cpp:218] Iteration 94600 (15.7716 iter/s, 6.3405s/100 iters), loss = 0.743388
I1211 12:32:46.827955 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:32:46.827955 15296 solver.cpp:237]     Train net output #1: loss = 0.743388 (* 1 = 0.743388 loss)
I1211 12:32:46.827955 15296 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1211 12:32:53.170442 15296 solver.cpp:218] Iteration 94700 (15.7698 iter/s, 6.34124s/100 iters), loss = 0.657254
I1211 12:32:53.170442 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:32:53.170442 15296 solver.cpp:237]     Train net output #1: loss = 0.657254 (* 1 = 0.657254 loss)
I1211 12:32:53.170442 15296 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1211 12:32:59.513926 15296 solver.cpp:218] Iteration 94800 (15.7651 iter/s, 6.34313s/100 iters), loss = 0.743768
I1211 12:32:59.513926 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 12:32:59.513926 15296 solver.cpp:237]     Train net output #1: loss = 0.743768 (* 1 = 0.743768 loss)
I1211 12:32:59.513926 15296 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1211 12:33:05.851399 15296 solver.cpp:218] Iteration 94900 (15.779 iter/s, 6.33756s/100 iters), loss = 0.9139
I1211 12:33:05.851399 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 12:33:05.851399 15296 solver.cpp:237]     Train net output #1: loss = 0.9139 (* 1 = 0.9139 loss)
I1211 12:33:05.851399 15296 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1211 12:33:11.882946 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:33:12.132963 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95000.caffemodel
I1211 12:33:12.147963 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95000.solverstate
I1211 12:33:12.152964 15296 solver.cpp:330] Iteration 95000, Testing net (#0)
I1211 12:33:12.152964 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:33:13.673076  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:33:13.733080 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6095
I1211 12:33:13.733080 15296 solver.cpp:397]     Test net output #1: loss = 1.46133 (* 1 = 1.46133 loss)
I1211 12:33:13.794080 15296 solver.cpp:218] Iteration 95000 (12.5919 iter/s, 7.94159s/100 iters), loss = 0.78467
I1211 12:33:13.794080 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:33:13.794080 15296 solver.cpp:237]     Train net output #1: loss = 0.78467 (* 1 = 0.78467 loss)
I1211 12:33:13.794080 15296 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1211 12:33:13.794080 15296 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1211 12:33:20.137993 15296 solver.cpp:218] Iteration 95100 (15.7639 iter/s, 6.34363s/100 iters), loss = 0.629692
I1211 12:33:20.137993 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 12:33:20.137993 15296 solver.cpp:237]     Train net output #1: loss = 0.629692 (* 1 = 0.629692 loss)
I1211 12:33:20.137993 15296 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1211 12:33:26.466449 15296 solver.cpp:218] Iteration 95200 (15.8027 iter/s, 6.32804s/100 iters), loss = 0.542516
I1211 12:33:26.466449 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:33:26.466449 15296 solver.cpp:237]     Train net output #1: loss = 0.542516 (* 1 = 0.542516 loss)
I1211 12:33:26.466449 15296 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1211 12:33:32.806385 15296 solver.cpp:218] Iteration 95300 (15.7749 iter/s, 6.3392s/100 iters), loss = 0.621122
I1211 12:33:32.806385 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:33:32.806385 15296 solver.cpp:237]     Train net output #1: loss = 0.621122 (* 1 = 0.621122 loss)
I1211 12:33:32.806385 15296 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1211 12:33:39.136878 15296 solver.cpp:218] Iteration 95400 (15.7966 iter/s, 6.33049s/100 iters), loss = 0.489359
I1211 12:33:39.136878 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:33:39.136878 15296 solver.cpp:237]     Train net output #1: loss = 0.489359 (* 1 = 0.489359 loss)
I1211 12:33:39.136878 15296 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1211 12:33:45.156297 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:33:45.405342 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95500.caffemodel
I1211 12:33:45.421341 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95500.solverstate
I1211 12:33:45.426342 15296 solver.cpp:330] Iteration 95500, Testing net (#0)
I1211 12:33:45.426342 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:33:46.945426  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:33:47.005430 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6761
I1211 12:33:47.005430 15296 solver.cpp:397]     Test net output #1: loss = 1.1872 (* 1 = 1.1872 loss)
I1211 12:33:47.067433 15296 solver.cpp:218] Iteration 95500 (12.6107 iter/s, 7.9298s/100 iters), loss = 0.539732
I1211 12:33:47.067433 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:33:47.067433 15296 solver.cpp:237]     Train net output #1: loss = 0.539732 (* 1 = 0.539732 loss)
I1211 12:33:47.067433 15296 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1211 12:33:53.399150 15296 solver.cpp:218] Iteration 95600 (15.7933 iter/s, 6.33181s/100 iters), loss = 0.580286
I1211 12:33:53.399150 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:33:53.399150 15296 solver.cpp:237]     Train net output #1: loss = 0.580286 (* 1 = 0.580286 loss)
I1211 12:33:53.399150 15296 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1211 12:33:59.725591 15296 solver.cpp:218] Iteration 95700 (15.8079 iter/s, 6.32597s/100 iters), loss = 0.419212
I1211 12:33:59.725591 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:33:59.725591 15296 solver.cpp:237]     Train net output #1: loss = 0.419212 (* 1 = 0.419212 loss)
I1211 12:33:59.725591 15296 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1211 12:34:06.064606 15296 solver.cpp:218] Iteration 95800 (15.7774 iter/s, 6.33817s/100 iters), loss = 0.480155
I1211 12:34:06.064606 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:34:06.064606 15296 solver.cpp:237]     Train net output #1: loss = 0.480155 (* 1 = 0.480155 loss)
I1211 12:34:06.064606 15296 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1211 12:34:12.397558 15296 solver.cpp:218] Iteration 95900 (15.7925 iter/s, 6.33212s/100 iters), loss = 0.508471
I1211 12:34:12.397558 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:34:12.397558 15296 solver.cpp:237]     Train net output #1: loss = 0.508471 (* 1 = 0.508471 loss)
I1211 12:34:12.397558 15296 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1211 12:34:18.411005 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:34:18.661020 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96000.caffemodel
I1211 12:34:18.675019 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96000.solverstate
I1211 12:34:18.680023 15296 solver.cpp:330] Iteration 96000, Testing net (#0)
I1211 12:34:18.680023 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:34:20.201153  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:34:20.262154 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6797
I1211 12:34:20.262154 15296 solver.cpp:397]     Test net output #1: loss = 1.18348 (* 1 = 1.18348 loss)
I1211 12:34:20.323155 15296 solver.cpp:218] Iteration 96000 (12.617 iter/s, 7.92581s/100 iters), loss = 0.541216
I1211 12:34:20.323155 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:34:20.323155 15296 solver.cpp:237]     Train net output #1: loss = 0.541216 (* 1 = 0.541216 loss)
I1211 12:34:20.323155 15296 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1211 12:34:26.674631 15296 solver.cpp:218] Iteration 96100 (15.7466 iter/s, 6.35057s/100 iters), loss = 0.51956
I1211 12:34:26.674631 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:34:26.674631 15296 solver.cpp:237]     Train net output #1: loss = 0.51956 (* 1 = 0.51956 loss)
I1211 12:34:26.674631 15296 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1211 12:34:33.008106 15296 solver.cpp:218] Iteration 96200 (15.791 iter/s, 6.33272s/100 iters), loss = 0.446253
I1211 12:34:33.008106 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:34:33.008106 15296 solver.cpp:237]     Train net output #1: loss = 0.446253 (* 1 = 0.446253 loss)
I1211 12:34:33.008106 15296 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1211 12:34:39.334520 15296 solver.cpp:218] Iteration 96300 (15.8062 iter/s, 6.32665s/100 iters), loss = 0.591212
I1211 12:34:39.334520 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:34:39.334520 15296 solver.cpp:237]     Train net output #1: loss = 0.591212 (* 1 = 0.591212 loss)
I1211 12:34:39.334520 15296 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1211 12:34:45.677960 15296 solver.cpp:218] Iteration 96400 (15.766 iter/s, 6.34276s/100 iters), loss = 0.448749
I1211 12:34:45.677960 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:34:45.677960 15296 solver.cpp:237]     Train net output #1: loss = 0.448749 (* 1 = 0.448749 loss)
I1211 12:34:45.677960 15296 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1211 12:34:51.698420 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:34:51.946430 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96500.caffemodel
I1211 12:34:51.961936 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96500.solverstate
I1211 12:34:51.966436 15296 solver.cpp:330] Iteration 96500, Testing net (#0)
I1211 12:34:51.966436 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:34:53.484452  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:34:53.545451 15296 solver.cpp:397]     Test net output #0: accuracy = 0.681
I1211 12:34:53.545451 15296 solver.cpp:397]     Test net output #1: loss = 1.17925 (* 1 = 1.17925 loss)
I1211 12:34:53.606456 15296 solver.cpp:218] Iteration 96500 (12.6136 iter/s, 7.92794s/100 iters), loss = 0.504954
I1211 12:34:53.606456 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:34:53.606456 15296 solver.cpp:237]     Train net output #1: loss = 0.504954 (* 1 = 0.504954 loss)
I1211 12:34:53.606456 15296 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1211 12:34:59.936883 15296 solver.cpp:218] Iteration 96600 (15.7981 iter/s, 6.32989s/100 iters), loss = 0.537388
I1211 12:34:59.936883 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:34:59.936883 15296 solver.cpp:237]     Train net output #1: loss = 0.537388 (* 1 = 0.537388 loss)
I1211 12:34:59.936883 15296 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1211 12:35:06.265836 15296 solver.cpp:218] Iteration 96700 (15.8015 iter/s, 6.32852s/100 iters), loss = 0.380253
I1211 12:35:06.265836 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:35:06.265836 15296 solver.cpp:237]     Train net output #1: loss = 0.380253 (* 1 = 0.380253 loss)
I1211 12:35:06.265836 15296 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1211 12:35:12.589874 15296 solver.cpp:218] Iteration 96800 (15.8134 iter/s, 6.32375s/100 iters), loss = 0.482607
I1211 12:35:12.589874 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:35:12.589874 15296 solver.cpp:237]     Train net output #1: loss = 0.482607 (* 1 = 0.482607 loss)
I1211 12:35:12.589874 15296 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1211 12:35:18.920408 15296 solver.cpp:218] Iteration 96900 (15.7975 iter/s, 6.33013s/100 iters), loss = 0.432032
I1211 12:35:18.920408 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:35:18.920408 15296 solver.cpp:237]     Train net output #1: loss = 0.432032 (* 1 = 0.432032 loss)
I1211 12:35:18.920408 15296 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1211 12:35:24.932873 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:35:25.182888 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97000.caffemodel
I1211 12:35:25.198886 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97000.solverstate
I1211 12:35:25.202886 15296 solver.cpp:330] Iteration 97000, Testing net (#0)
I1211 12:35:25.202886 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:35:26.723008  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:35:26.783016 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6818
I1211 12:35:26.783016 15296 solver.cpp:397]     Test net output #1: loss = 1.17682 (* 1 = 1.17682 loss)
I1211 12:35:26.844012 15296 solver.cpp:218] Iteration 97000 (12.621 iter/s, 7.92331s/100 iters), loss = 0.494316
I1211 12:35:26.844012 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:35:26.844012 15296 solver.cpp:237]     Train net output #1: loss = 0.494316 (* 1 = 0.494316 loss)
I1211 12:35:26.844012 15296 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1211 12:35:33.183534 15296 solver.cpp:218] Iteration 97100 (15.7772 iter/s, 6.33828s/100 iters), loss = 0.522111
I1211 12:35:33.183534 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 12:35:33.183534 15296 solver.cpp:237]     Train net output #1: loss = 0.522111 (* 1 = 0.522111 loss)
I1211 12:35:33.183534 15296 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1211 12:35:39.510998 15296 solver.cpp:218] Iteration 97200 (15.8056 iter/s, 6.32686s/100 iters), loss = 0.462736
I1211 12:35:39.510998 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:35:39.510998 15296 solver.cpp:237]     Train net output #1: loss = 0.462736 (* 1 = 0.462736 loss)
I1211 12:35:39.510998 15296 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1211 12:35:45.841457 15296 solver.cpp:218] Iteration 97300 (15.7962 iter/s, 6.33062s/100 iters), loss = 0.589097
I1211 12:35:45.841457 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:35:45.841457 15296 solver.cpp:237]     Train net output #1: loss = 0.589097 (* 1 = 0.589097 loss)
I1211 12:35:45.841457 15296 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1211 12:35:52.173444 15296 solver.cpp:218] Iteration 97400 (15.7945 iter/s, 6.33132s/100 iters), loss = 0.441311
I1211 12:35:52.173444 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:35:52.173444 15296 solver.cpp:237]     Train net output #1: loss = 0.441311 (* 1 = 0.441311 loss)
I1211 12:35:52.173943 15296 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1211 12:35:58.186385 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:35:58.437397 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97500.caffemodel
I1211 12:35:58.452397 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97500.solverstate
I1211 12:35:58.456398 15296 solver.cpp:330] Iteration 97500, Testing net (#0)
I1211 12:35:58.456398 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:35:59.975644  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:36:00.036648 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6799
I1211 12:36:00.036648 15296 solver.cpp:397]     Test net output #1: loss = 1.18907 (* 1 = 1.18907 loss)
I1211 12:36:00.096654 15296 solver.cpp:218] Iteration 97500 (12.6217 iter/s, 7.92288s/100 iters), loss = 0.423122
I1211 12:36:00.096654 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:36:00.096654 15296 solver.cpp:237]     Train net output #1: loss = 0.423122 (* 1 = 0.423122 loss)
I1211 12:36:00.096654 15296 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1211 12:36:06.427135 15296 solver.cpp:218] Iteration 97600 (15.7977 iter/s, 6.33003s/100 iters), loss = 0.447901
I1211 12:36:06.427135 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:36:06.427135 15296 solver.cpp:237]     Train net output #1: loss = 0.447901 (* 1 = 0.447901 loss)
I1211 12:36:06.427135 15296 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1211 12:36:12.758159 15296 solver.cpp:218] Iteration 97700 (15.797 iter/s, 6.33034s/100 iters), loss = 0.425061
I1211 12:36:12.758159 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:36:12.758159 15296 solver.cpp:237]     Train net output #1: loss = 0.425061 (* 1 = 0.425061 loss)
I1211 12:36:12.758159 15296 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1211 12:36:19.079910 15296 solver.cpp:218] Iteration 97800 (15.8195 iter/s, 6.32131s/100 iters), loss = 0.463292
I1211 12:36:19.079910 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:36:19.079910 15296 solver.cpp:237]     Train net output #1: loss = 0.463292 (* 1 = 0.463292 loss)
I1211 12:36:19.079910 15296 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1211 12:36:25.402271 15296 solver.cpp:218] Iteration 97900 (15.8187 iter/s, 6.32163s/100 iters), loss = 0.438571
I1211 12:36:25.402271 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:36:25.402271 15296 solver.cpp:237]     Train net output #1: loss = 0.438571 (* 1 = 0.438571 loss)
I1211 12:36:25.402271 15296 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1211 12:36:31.407752 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:36:31.656846 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98000.caffemodel
I1211 12:36:31.670861 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98000.solverstate
I1211 12:36:31.675866 15296 solver.cpp:330] Iteration 98000, Testing net (#0)
I1211 12:36:31.675866 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:36:33.196283  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:36:33.255800 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6817
I1211 12:36:33.255800 15296 solver.cpp:397]     Test net output #1: loss = 1.18538 (* 1 = 1.18538 loss)
I1211 12:36:33.316596 15296 solver.cpp:218] Iteration 98000 (12.6347 iter/s, 7.91469s/100 iters), loss = 0.400752
I1211 12:36:33.316596 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:36:33.316596 15296 solver.cpp:237]     Train net output #1: loss = 0.400752 (* 1 = 0.400752 loss)
I1211 12:36:33.316596 15296 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1211 12:36:39.652618 15296 solver.cpp:218] Iteration 98100 (15.7857 iter/s, 6.33484s/100 iters), loss = 0.478415
I1211 12:36:39.652618 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:36:39.652618 15296 solver.cpp:237]     Train net output #1: loss = 0.478415 (* 1 = 0.478415 loss)
I1211 12:36:39.652618 15296 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1211 12:36:45.990538 15296 solver.cpp:218] Iteration 98200 (15.7793 iter/s, 6.33743s/100 iters), loss = 0.416179
I1211 12:36:45.990538 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:36:45.990538 15296 solver.cpp:237]     Train net output #1: loss = 0.416179 (* 1 = 0.416179 loss)
I1211 12:36:45.990538 15296 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1211 12:36:52.319787 15296 solver.cpp:218] Iteration 98300 (15.8012 iter/s, 6.32862s/100 iters), loss = 0.503607
I1211 12:36:52.319787 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:36:52.319787 15296 solver.cpp:237]     Train net output #1: loss = 0.503607 (* 1 = 0.503607 loss)
I1211 12:36:52.319787 15296 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1211 12:36:58.658813 15296 solver.cpp:218] Iteration 98400 (15.7747 iter/s, 6.33925s/100 iters), loss = 0.404283
I1211 12:36:58.658813 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:36:58.658813 15296 solver.cpp:237]     Train net output #1: loss = 0.404283 (* 1 = 0.404283 loss)
I1211 12:36:58.658813 15296 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1211 12:37:04.686059 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:37:04.936193 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98500.caffemodel
I1211 12:37:04.951195 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98500.solverstate
I1211 12:37:04.956193 15296 solver.cpp:330] Iteration 98500, Testing net (#0)
I1211 12:37:04.956193 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:37:06.474009  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:37:06.535022 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6809
I1211 12:37:06.536021 15296 solver.cpp:397]     Test net output #1: loss = 1.19014 (* 1 = 1.19014 loss)
I1211 12:37:06.596526 15296 solver.cpp:218] Iteration 98500 (12.5993 iter/s, 7.93697s/100 iters), loss = 0.343315
I1211 12:37:06.596526 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:37:06.596526 15296 solver.cpp:237]     Train net output #1: loss = 0.343315 (* 1 = 0.343315 loss)
I1211 12:37:06.596526 15296 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1211 12:37:12.930419 15296 solver.cpp:218] Iteration 98600 (15.788 iter/s, 6.33394s/100 iters), loss = 0.495938
I1211 12:37:12.930419 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:37:12.930419 15296 solver.cpp:237]     Train net output #1: loss = 0.495938 (* 1 = 0.495938 loss)
I1211 12:37:12.930419 15296 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1211 12:37:19.256883 15296 solver.cpp:218] Iteration 98700 (15.8075 iter/s, 6.3261s/100 iters), loss = 0.373184
I1211 12:37:19.256883 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:37:19.256883 15296 solver.cpp:237]     Train net output #1: loss = 0.373184 (* 1 = 0.373184 loss)
I1211 12:37:19.257884 15296 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1211 12:37:25.590344 15296 solver.cpp:218] Iteration 98800 (15.7921 iter/s, 6.3323s/100 iters), loss = 0.437011
I1211 12:37:25.590344 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:37:25.590344 15296 solver.cpp:237]     Train net output #1: loss = 0.437011 (* 1 = 0.437011 loss)
I1211 12:37:25.590344 15296 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1211 12:37:31.924067 15296 solver.cpp:218] Iteration 98900 (15.7883 iter/s, 6.3338s/100 iters), loss = 0.419749
I1211 12:37:31.924067 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:37:31.924067 15296 solver.cpp:237]     Train net output #1: loss = 0.419749 (* 1 = 0.419749 loss)
I1211 12:37:31.924067 15296 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1211 12:37:37.959519 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:37:38.208534 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99000.caffemodel
I1211 12:37:38.224038 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99000.solverstate
I1211 12:37:38.228543 15296 solver.cpp:330] Iteration 99000, Testing net (#0)
I1211 12:37:38.228543 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:37:39.747660  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:37:39.808660 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6773
I1211 12:37:39.808660 15296 solver.cpp:397]     Test net output #1: loss = 1.19162 (* 1 = 1.19162 loss)
I1211 12:37:39.869676 15296 solver.cpp:218] Iteration 99000 (12.5861 iter/s, 7.94526s/100 iters), loss = 0.410587
I1211 12:37:39.869676 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:37:39.869676 15296 solver.cpp:237]     Train net output #1: loss = 0.410587 (* 1 = 0.410587 loss)
I1211 12:37:39.869676 15296 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1211 12:37:46.201189 15296 solver.cpp:218] Iteration 99100 (15.7967 iter/s, 6.33042s/100 iters), loss = 0.546768
I1211 12:37:46.201189 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:37:46.201189 15296 solver.cpp:237]     Train net output #1: loss = 0.546768 (* 1 = 0.546768 loss)
I1211 12:37:46.201189 15296 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1211 12:37:52.517594 15296 solver.cpp:218] Iteration 99200 (15.833 iter/s, 6.31593s/100 iters), loss = 0.362215
I1211 12:37:52.517594 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:37:52.517594 15296 solver.cpp:237]     Train net output #1: loss = 0.362215 (* 1 = 0.362215 loss)
I1211 12:37:52.517594 15296 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1211 12:37:58.844038 15296 solver.cpp:218] Iteration 99300 (15.8077 iter/s, 6.32602s/100 iters), loss = 0.557821
I1211 12:37:58.844038 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 12:37:58.844038 15296 solver.cpp:237]     Train net output #1: loss = 0.557821 (* 1 = 0.557821 loss)
I1211 12:37:58.844038 15296 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1211 12:38:05.168505 15296 solver.cpp:218] Iteration 99400 (15.8122 iter/s, 6.32422s/100 iters), loss = 0.489115
I1211 12:38:05.168505 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:38:05.168505 15296 solver.cpp:237]     Train net output #1: loss = 0.489115 (* 1 = 0.489115 loss)
I1211 12:38:05.168505 15296 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1211 12:38:11.197935 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:38:11.446952 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99500.caffemodel
I1211 12:38:11.461952 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99500.solverstate
I1211 12:38:11.465952 15296 solver.cpp:330] Iteration 99500, Testing net (#0)
I1211 12:38:11.465952 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:38:12.992087  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:38:13.051091 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6801
I1211 12:38:13.051091 15296 solver.cpp:397]     Test net output #1: loss = 1.19335 (* 1 = 1.19335 loss)
I1211 12:38:13.112601 15296 solver.cpp:218] Iteration 99500 (12.5889 iter/s, 7.9435s/100 iters), loss = 0.427683
I1211 12:38:13.112601 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:38:13.112601 15296 solver.cpp:237]     Train net output #1: loss = 0.427683 (* 1 = 0.427683 loss)
I1211 12:38:13.112601 15296 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1211 12:38:19.459522 15296 solver.cpp:218] Iteration 99600 (15.7556 iter/s, 6.34695s/100 iters), loss = 0.384493
I1211 12:38:19.459522 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:38:19.459522 15296 solver.cpp:237]     Train net output #1: loss = 0.384493 (* 1 = 0.384493 loss)
I1211 12:38:19.459522 15296 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1211 12:38:25.787997 15296 solver.cpp:218] Iteration 99700 (15.803 iter/s, 6.32793s/100 iters), loss = 0.357309
I1211 12:38:25.787997 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:38:25.787997 15296 solver.cpp:237]     Train net output #1: loss = 0.357309 (* 1 = 0.357309 loss)
I1211 12:38:25.787997 15296 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1211 12:38:32.129529 15296 solver.cpp:218] Iteration 99800 (15.7711 iter/s, 6.34069s/100 iters), loss = 0.502978
I1211 12:38:32.129529 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:38:32.129529 15296 solver.cpp:237]     Train net output #1: loss = 0.502978 (* 1 = 0.502978 loss)
I1211 12:38:32.129529 15296 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1211 12:38:38.466071 15296 solver.cpp:218] Iteration 99900 (15.7822 iter/s, 6.33624s/100 iters), loss = 0.454683
I1211 12:38:38.466071 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:38:38.466071 15296 solver.cpp:237]     Train net output #1: loss = 0.454683 (* 1 = 0.454683 loss)
I1211 12:38:38.466071 15296 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1211 12:38:44.488540 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:38:44.738570 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100000.caffemodel
I1211 12:38:44.753571 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100000.solverstate
I1211 12:38:44.758571 15296 solver.cpp:330] Iteration 100000, Testing net (#0)
I1211 12:38:44.758571 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:38:46.279700  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:38:46.340706 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6778
I1211 12:38:46.340706 15296 solver.cpp:397]     Test net output #1: loss = 1.20048 (* 1 = 1.20048 loss)
I1211 12:38:46.400705 15296 solver.cpp:218] Iteration 100000 (12.6037 iter/s, 7.93415s/100 iters), loss = 0.43158
I1211 12:38:46.400705 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:38:46.400705 15296 solver.cpp:237]     Train net output #1: loss = 0.43158 (* 1 = 0.43158 loss)
I1211 12:38:46.400705 15296 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1211 12:38:52.744184 15296 solver.cpp:218] Iteration 100100 (15.7652 iter/s, 6.34308s/100 iters), loss = 0.406517
I1211 12:38:52.744184 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:38:52.744184 15296 solver.cpp:237]     Train net output #1: loss = 0.406517 (* 1 = 0.406517 loss)
I1211 12:38:52.744184 15296 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1211 12:38:59.084830 15296 solver.cpp:218] Iteration 100200 (15.7711 iter/s, 6.34071s/100 iters), loss = 0.377684
I1211 12:38:59.084830 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:38:59.084830 15296 solver.cpp:237]     Train net output #1: loss = 0.377684 (* 1 = 0.377684 loss)
I1211 12:38:59.084830 15296 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1211 12:39:05.425608 15296 solver.cpp:218] Iteration 100300 (15.7741 iter/s, 6.3395s/100 iters), loss = 0.487364
I1211 12:39:05.425608 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:39:05.425608 15296 solver.cpp:237]     Train net output #1: loss = 0.487364 (* 1 = 0.487364 loss)
I1211 12:39:05.425608 15296 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1211 12:39:11.764710 15296 solver.cpp:218] Iteration 100400 (15.775 iter/s, 6.33915s/100 iters), loss = 0.433328
I1211 12:39:11.764710 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:39:11.764710 15296 solver.cpp:237]     Train net output #1: loss = 0.433328 (* 1 = 0.433328 loss)
I1211 12:39:11.764710 15296 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1211 12:39:17.786623 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:39:18.037647 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100500.caffemodel
I1211 12:39:18.052186 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100500.solverstate
I1211 12:39:18.056669 15296 solver.cpp:330] Iteration 100500, Testing net (#0)
I1211 12:39:18.056669 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:39:19.576201  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:39:19.636211 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6788
I1211 12:39:19.636211 15296 solver.cpp:397]     Test net output #1: loss = 1.20262 (* 1 = 1.20262 loss)
I1211 12:39:19.698225 15296 solver.cpp:218] Iteration 100500 (12.6063 iter/s, 7.93255s/100 iters), loss = 0.346375
I1211 12:39:19.698225 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:39:19.698225 15296 solver.cpp:237]     Train net output #1: loss = 0.346375 (* 1 = 0.346375 loss)
I1211 12:39:19.698225 15296 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1211 12:39:26.017364 15296 solver.cpp:218] Iteration 100600 (15.8253 iter/s, 6.31898s/100 iters), loss = 0.418752
I1211 12:39:26.017364 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:39:26.017364 15296 solver.cpp:237]     Train net output #1: loss = 0.418752 (* 1 = 0.418752 loss)
I1211 12:39:26.017364 15296 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1211 12:39:32.406725 15296 solver.cpp:218] Iteration 100700 (15.6518 iter/s, 6.38905s/100 iters), loss = 0.3486
I1211 12:39:32.406725 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 12:39:32.406725 15296 solver.cpp:237]     Train net output #1: loss = 0.3486 (* 1 = 0.3486 loss)
I1211 12:39:32.406725 15296 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1211 12:39:38.721705 15296 solver.cpp:218] Iteration 100800 (15.8356 iter/s, 6.31488s/100 iters), loss = 0.463572
I1211 12:39:38.721705 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 12:39:38.721705 15296 solver.cpp:237]     Train net output #1: loss = 0.463572 (* 1 = 0.463572 loss)
I1211 12:39:38.722705 15296 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1211 12:39:45.035923 15296 solver.cpp:218] Iteration 100900 (15.8392 iter/s, 6.31344s/100 iters), loss = 0.36326
I1211 12:39:45.035923 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:39:45.035923 15296 solver.cpp:237]     Train net output #1: loss = 0.36326 (* 1 = 0.36326 loss)
I1211 12:39:45.035923 15296 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1211 12:39:51.044330 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:39:51.292361 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101000.caffemodel
I1211 12:39:51.307361 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101000.solverstate
I1211 12:39:51.312362 15296 solver.cpp:330] Iteration 101000, Testing net (#0)
I1211 12:39:51.312362 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:39:52.828490  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:39:52.888499 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6808
I1211 12:39:52.888499 15296 solver.cpp:397]     Test net output #1: loss = 1.20281 (* 1 = 1.20281 loss)
I1211 12:39:52.950498 15296 solver.cpp:218] Iteration 101000 (12.6362 iter/s, 7.91375s/100 iters), loss = 0.406917
I1211 12:39:52.950498 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:39:52.950498 15296 solver.cpp:237]     Train net output #1: loss = 0.406917 (* 1 = 0.406917 loss)
I1211 12:39:52.950498 15296 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1211 12:39:59.273471 15296 solver.cpp:218] Iteration 101100 (15.8165 iter/s, 6.32251s/100 iters), loss = 0.396853
I1211 12:39:59.273471 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:39:59.273471 15296 solver.cpp:237]     Train net output #1: loss = 0.396853 (* 1 = 0.396853 loss)
I1211 12:39:59.273471 15296 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1211 12:40:05.590431 15296 solver.cpp:218] Iteration 101200 (15.8306 iter/s, 6.31687s/100 iters), loss = 0.346845
I1211 12:40:05.590431 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 12:40:05.590431 15296 solver.cpp:237]     Train net output #1: loss = 0.346845 (* 1 = 0.346845 loss)
I1211 12:40:05.590431 15296 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1211 12:40:11.904878 15296 solver.cpp:218] Iteration 101300 (15.8376 iter/s, 6.31408s/100 iters), loss = 0.461866
I1211 12:40:11.904878 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:40:11.904878 15296 solver.cpp:237]     Train net output #1: loss = 0.461866 (* 1 = 0.461866 loss)
I1211 12:40:11.904878 15296 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1211 12:40:18.222342 15296 solver.cpp:218] Iteration 101400 (15.8299 iter/s, 6.31717s/100 iters), loss = 0.421601
I1211 12:40:18.222342 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:40:18.222342 15296 solver.cpp:237]     Train net output #1: loss = 0.421601 (* 1 = 0.421601 loss)
I1211 12:40:18.222342 15296 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1211 12:40:24.238781 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:40:24.486812 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101500.caffemodel
I1211 12:40:24.501813 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101500.solverstate
I1211 12:40:24.506814 15296 solver.cpp:330] Iteration 101500, Testing net (#0)
I1211 12:40:24.506814 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:40:26.022984  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:40:26.083998 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6799
I1211 12:40:26.083998 15296 solver.cpp:397]     Test net output #1: loss = 1.20467 (* 1 = 1.20467 loss)
I1211 12:40:26.143986 15296 solver.cpp:218] Iteration 101500 (12.6249 iter/s, 7.92085s/100 iters), loss = 0.350339
I1211 12:40:26.143986 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:40:26.143986 15296 solver.cpp:237]     Train net output #1: loss = 0.350339 (* 1 = 0.350339 loss)
I1211 12:40:26.143986 15296 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1211 12:40:32.463441 15296 solver.cpp:218] Iteration 101600 (15.8252 iter/s, 6.31903s/100 iters), loss = 0.425671
I1211 12:40:32.463441 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:40:32.463441 15296 solver.cpp:237]     Train net output #1: loss = 0.425671 (* 1 = 0.425671 loss)
I1211 12:40:32.463441 15296 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1211 12:40:38.776899 15296 solver.cpp:218] Iteration 101700 (15.8411 iter/s, 6.31269s/100 iters), loss = 0.379463
I1211 12:40:38.776899 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:40:38.776899 15296 solver.cpp:237]     Train net output #1: loss = 0.379463 (* 1 = 0.379463 loss)
I1211 12:40:38.776899 15296 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1211 12:40:45.093364 15296 solver.cpp:218] Iteration 101800 (15.8328 iter/s, 6.316s/100 iters), loss = 0.389798
I1211 12:40:45.093364 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:40:45.093364 15296 solver.cpp:237]     Train net output #1: loss = 0.389798 (* 1 = 0.389798 loss)
I1211 12:40:45.093364 15296 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1211 12:40:51.404837 15296 solver.cpp:218] Iteration 101900 (15.8447 iter/s, 6.31127s/100 iters), loss = 0.3886
I1211 12:40:51.404837 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:40:51.404837 15296 solver.cpp:237]     Train net output #1: loss = 0.388601 (* 1 = 0.388601 loss)
I1211 12:40:51.404837 15296 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1211 12:40:57.408274 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:40:57.656285 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102000.caffemodel
I1211 12:40:57.671283 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102000.solverstate
I1211 12:40:57.676285 15296 solver.cpp:330] Iteration 102000, Testing net (#0)
I1211 12:40:57.676285 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:40:59.189894  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:40:59.249397 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6792
I1211 12:40:59.249397 15296 solver.cpp:397]     Test net output #1: loss = 1.208 (* 1 = 1.208 loss)
I1211 12:40:59.310405 15296 solver.cpp:218] Iteration 102000 (12.6503 iter/s, 7.90496s/100 iters), loss = 0.394425
I1211 12:40:59.310405 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:40:59.310405 15296 solver.cpp:237]     Train net output #1: loss = 0.394425 (* 1 = 0.394425 loss)
I1211 12:40:59.310405 15296 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1211 12:41:05.627924 15296 solver.cpp:218] Iteration 102100 (15.8283 iter/s, 6.31779s/100 iters), loss = 0.493504
I1211 12:41:05.627924 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:41:05.627924 15296 solver.cpp:237]     Train net output #1: loss = 0.493504 (* 1 = 0.493504 loss)
I1211 12:41:05.627924 15296 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1211 12:41:11.940381 15296 solver.cpp:218] Iteration 102200 (15.8446 iter/s, 6.31132s/100 iters), loss = 0.382105
I1211 12:41:11.940381 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:41:11.940381 15296 solver.cpp:237]     Train net output #1: loss = 0.382105 (* 1 = 0.382105 loss)
I1211 12:41:11.940381 15296 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1211 12:41:18.253937 15296 solver.cpp:218] Iteration 102300 (15.838 iter/s, 6.31392s/100 iters), loss = 0.485215
I1211 12:41:18.253937 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:41:18.253937 15296 solver.cpp:237]     Train net output #1: loss = 0.485215 (* 1 = 0.485215 loss)
I1211 12:41:18.253937 15296 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1211 12:41:24.565629 15296 solver.cpp:218] Iteration 102400 (15.8467 iter/s, 6.31048s/100 iters), loss = 0.402577
I1211 12:41:24.565629 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:41:24.565629 15296 solver.cpp:237]     Train net output #1: loss = 0.402578 (* 1 = 0.402578 loss)
I1211 12:41:24.565629 15296 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1211 12:41:30.563045 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:41:30.812054 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102500.caffemodel
I1211 12:41:30.826056 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102500.solverstate
I1211 12:41:30.830054 15296 solver.cpp:330] Iteration 102500, Testing net (#0)
I1211 12:41:30.830054 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:41:32.347280  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:41:32.406287 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1211 12:41:32.406287 15296 solver.cpp:397]     Test net output #1: loss = 1.21671 (* 1 = 1.21671 loss)
I1211 12:41:32.467286 15296 solver.cpp:218] Iteration 102500 (12.6557 iter/s, 7.90156s/100 iters), loss = 0.396196
I1211 12:41:32.467286 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:41:32.467286 15296 solver.cpp:237]     Train net output #1: loss = 0.396196 (* 1 = 0.396196 loss)
I1211 12:41:32.467286 15296 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1211 12:41:38.792775 15296 solver.cpp:218] Iteration 102600 (15.8108 iter/s, 6.32479s/100 iters), loss = 0.422046
I1211 12:41:38.792775 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:41:38.792775 15296 solver.cpp:237]     Train net output #1: loss = 0.422046 (* 1 = 0.422046 loss)
I1211 12:41:38.792775 15296 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1211 12:41:45.115193 15296 solver.cpp:218] Iteration 102700 (15.818 iter/s, 6.32191s/100 iters), loss = 0.325773
I1211 12:41:45.115193 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:41:45.115193 15296 solver.cpp:237]     Train net output #1: loss = 0.325773 (* 1 = 0.325773 loss)
I1211 12:41:45.115193 15296 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1211 12:41:51.432605 15296 solver.cpp:218] Iteration 102800 (15.8295 iter/s, 6.31731s/100 iters), loss = 0.442931
I1211 12:41:51.432605 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:41:51.432605 15296 solver.cpp:237]     Train net output #1: loss = 0.442931 (* 1 = 0.442931 loss)
I1211 12:41:51.432605 15296 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1211 12:41:57.745055 15296 solver.cpp:218] Iteration 102900 (15.8437 iter/s, 6.31164s/100 iters), loss = 0.367598
I1211 12:41:57.745055 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:41:57.745055 15296 solver.cpp:237]     Train net output #1: loss = 0.367599 (* 1 = 0.367599 loss)
I1211 12:41:57.745055 15296 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1211 12:42:03.747498 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:42:03.996512 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103000.caffemodel
I1211 12:42:04.011512 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103000.solverstate
I1211 12:42:04.016512 15296 solver.cpp:330] Iteration 103000, Testing net (#0)
I1211 12:42:04.016512 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:42:05.530247  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:42:05.590752 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1211 12:42:05.590752 15296 solver.cpp:397]     Test net output #1: loss = 1.22401 (* 1 = 1.22401 loss)
I1211 12:42:05.651266 15296 solver.cpp:218] Iteration 103000 (12.6487 iter/s, 7.90592s/100 iters), loss = 0.39607
I1211 12:42:05.651266 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 12:42:05.651266 15296 solver.cpp:237]     Train net output #1: loss = 0.39607 (* 1 = 0.39607 loss)
I1211 12:42:05.651266 15296 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1211 12:42:11.981222 15296 solver.cpp:218] Iteration 103100 (15.7985 iter/s, 6.32972s/100 iters), loss = 0.441806
I1211 12:42:11.981222 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:42:11.981222 15296 solver.cpp:237]     Train net output #1: loss = 0.441806 (* 1 = 0.441806 loss)
I1211 12:42:11.981222 15296 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1211 12:42:18.299685 15296 solver.cpp:218] Iteration 103200 (15.8275 iter/s, 6.3181s/100 iters), loss = 0.275094
I1211 12:42:18.299685 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 12:42:18.299685 15296 solver.cpp:237]     Train net output #1: loss = 0.275094 (* 1 = 0.275094 loss)
I1211 12:42:18.299685 15296 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1211 12:42:24.627774 15296 solver.cpp:218] Iteration 103300 (15.8042 iter/s, 6.32742s/100 iters), loss = 0.457633
I1211 12:42:24.627774 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:42:24.627774 15296 solver.cpp:237]     Train net output #1: loss = 0.457633 (* 1 = 0.457633 loss)
I1211 12:42:24.627774 15296 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1211 12:42:30.950098 15296 solver.cpp:218] Iteration 103400 (15.8171 iter/s, 6.32229s/100 iters), loss = 0.423133
I1211 12:42:30.950098 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:42:30.950098 15296 solver.cpp:237]     Train net output #1: loss = 0.423133 (* 1 = 0.423133 loss)
I1211 12:42:30.950098 15296 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1211 12:42:36.964745 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:42:37.212757 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103500.caffemodel
I1211 12:42:37.228260 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103500.solverstate
I1211 12:42:37.232761 15296 solver.cpp:330] Iteration 103500, Testing net (#0)
I1211 12:42:37.232761 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:42:38.749610  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:42:38.809612 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6824
I1211 12:42:38.809612 15296 solver.cpp:397]     Test net output #1: loss = 1.22043 (* 1 = 1.22043 loss)
I1211 12:42:38.870117 15296 solver.cpp:218] Iteration 103500 (12.6267 iter/s, 7.91975s/100 iters), loss = 0.421019
I1211 12:42:38.870117 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:42:38.870117 15296 solver.cpp:237]     Train net output #1: loss = 0.421019 (* 1 = 0.421019 loss)
I1211 12:42:38.870117 15296 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1211 12:42:45.187577 15296 solver.cpp:218] Iteration 103600 (15.8316 iter/s, 6.3165s/100 iters), loss = 0.400297
I1211 12:42:45.187577 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:42:45.187577 15296 solver.cpp:237]     Train net output #1: loss = 0.400297 (* 1 = 0.400297 loss)
I1211 12:42:45.187577 15296 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1211 12:42:51.502040 15296 solver.cpp:218] Iteration 103700 (15.8377 iter/s, 6.31405s/100 iters), loss = 0.291166
I1211 12:42:51.502040 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 12:42:51.502040 15296 solver.cpp:237]     Train net output #1: loss = 0.291166 (* 1 = 0.291166 loss)
I1211 12:42:51.502040 15296 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1211 12:42:57.815552 15296 solver.cpp:218] Iteration 103800 (15.8395 iter/s, 6.31333s/100 iters), loss = 0.361218
I1211 12:42:57.815552 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:42:57.815552 15296 solver.cpp:237]     Train net output #1: loss = 0.361218 (* 1 = 0.361218 loss)
I1211 12:42:57.815552 15296 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1211 12:43:04.137014 15296 solver.cpp:218] Iteration 103900 (15.8209 iter/s, 6.32077s/100 iters), loss = 0.356371
I1211 12:43:04.137014 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:43:04.137014 15296 solver.cpp:237]     Train net output #1: loss = 0.356371 (* 1 = 0.356371 loss)
I1211 12:43:04.137014 15296 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1211 12:43:10.139436 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:43:10.388455 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104000.caffemodel
I1211 12:43:10.403455 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104000.solverstate
I1211 12:43:10.408457 15296 solver.cpp:330] Iteration 104000, Testing net (#0)
I1211 12:43:10.408457 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:43:11.921602  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:43:11.980609 15296 solver.cpp:397]     Test net output #0: accuracy = 0.679
I1211 12:43:11.980609 15296 solver.cpp:397]     Test net output #1: loss = 1.2214 (* 1 = 1.2214 loss)
I1211 12:43:12.041613 15296 solver.cpp:218] Iteration 104000 (12.6521 iter/s, 7.90383s/100 iters), loss = 0.356573
I1211 12:43:12.041613 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:43:12.041613 15296 solver.cpp:237]     Train net output #1: loss = 0.356574 (* 1 = 0.356574 loss)
I1211 12:43:12.041613 15296 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1211 12:43:18.366097 15296 solver.cpp:218] Iteration 104100 (15.8104 iter/s, 6.32493s/100 iters), loss = 0.387323
I1211 12:43:18.366097 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 12:43:18.366097 15296 solver.cpp:237]     Train net output #1: loss = 0.387323 (* 1 = 0.387323 loss)
I1211 12:43:18.366097 15296 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1211 12:43:24.681572 15296 solver.cpp:218] Iteration 104200 (15.8358 iter/s, 6.31479s/100 iters), loss = 0.299739
I1211 12:43:24.681572 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:43:24.681572 15296 solver.cpp:237]     Train net output #1: loss = 0.299739 (* 1 = 0.299739 loss)
I1211 12:43:24.681572 15296 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1211 12:43:30.991173 15296 solver.cpp:218] Iteration 104300 (15.851 iter/s, 6.30876s/100 iters), loss = 0.4083
I1211 12:43:30.991173 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:43:30.991173 15296 solver.cpp:237]     Train net output #1: loss = 0.4083 (* 1 = 0.4083 loss)
I1211 12:43:30.991173 15296 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1211 12:43:37.297688 15296 solver.cpp:218] Iteration 104400 (15.8563 iter/s, 6.30666s/100 iters), loss = 0.41963
I1211 12:43:37.297688 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:43:37.297688 15296 solver.cpp:237]     Train net output #1: loss = 0.41963 (* 1 = 0.41963 loss)
I1211 12:43:37.297688 15296 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1211 12:43:43.297770 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:43:43.547291 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104500.caffemodel
I1211 12:43:43.562794 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104500.solverstate
I1211 12:43:43.566794 15296 solver.cpp:330] Iteration 104500, Testing net (#0)
I1211 12:43:43.566794 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:43:45.081898  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:43:45.141907 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6793
I1211 12:43:45.141907 15296 solver.cpp:397]     Test net output #1: loss = 1.21973 (* 1 = 1.21973 loss)
I1211 12:43:45.202906 15296 solver.cpp:218] Iteration 104500 (12.6517 iter/s, 7.90407s/100 iters), loss = 0.36932
I1211 12:43:45.202906 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:43:45.202906 15296 solver.cpp:237]     Train net output #1: loss = 0.369321 (* 1 = 0.369321 loss)
I1211 12:43:45.202906 15296 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1211 12:43:51.517375 15296 solver.cpp:218] Iteration 104600 (15.8377 iter/s, 6.31404s/100 iters), loss = 0.461585
I1211 12:43:51.517375 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:43:51.517375 15296 solver.cpp:237]     Train net output #1: loss = 0.461585 (* 1 = 0.461585 loss)
I1211 12:43:51.517375 15296 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1211 12:43:57.821725 15296 solver.cpp:218] Iteration 104700 (15.8633 iter/s, 6.30387s/100 iters), loss = 0.32715
I1211 12:43:57.821725 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 12:43:57.821725 15296 solver.cpp:237]     Train net output #1: loss = 0.32715 (* 1 = 0.32715 loss)
I1211 12:43:57.821725 15296 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1211 12:44:04.142242 15296 solver.cpp:218] Iteration 104800 (15.823 iter/s, 6.3199s/100 iters), loss = 0.398871
I1211 12:44:04.142242 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:44:04.142242 15296 solver.cpp:237]     Train net output #1: loss = 0.398871 (* 1 = 0.398871 loss)
I1211 12:44:04.142242 15296 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1211 12:44:10.458295 15296 solver.cpp:218] Iteration 104900 (15.8333 iter/s, 6.31579s/100 iters), loss = 0.26933
I1211 12:44:10.458295 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 12:44:10.458295 15296 solver.cpp:237]     Train net output #1: loss = 0.269331 (* 1 = 0.269331 loss)
I1211 12:44:10.458796 15296 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1211 12:44:16.474216 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:44:16.724227 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105000.caffemodel
I1211 12:44:16.739228 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105000.solverstate
I1211 12:44:16.743227 15296 solver.cpp:330] Iteration 105000, Testing net (#0)
I1211 12:44:16.743227 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:44:18.258342  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:44:18.318367 15296 solver.cpp:397]     Test net output #0: accuracy = 0.679
I1211 12:44:18.318367 15296 solver.cpp:397]     Test net output #1: loss = 1.2267 (* 1 = 1.2267 loss)
I1211 12:44:18.378350 15296 solver.cpp:218] Iteration 105000 (12.6274 iter/s, 7.91928s/100 iters), loss = 0.350769
I1211 12:44:18.378350 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:44:18.378350 15296 solver.cpp:237]     Train net output #1: loss = 0.350769 (* 1 = 0.350769 loss)
I1211 12:44:18.378350 15296 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1211 12:44:24.696812 15296 solver.cpp:218] Iteration 105100 (15.8263 iter/s, 6.31862s/100 iters), loss = 0.319929
I1211 12:44:24.696812 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 12:44:24.696812 15296 solver.cpp:237]     Train net output #1: loss = 0.31993 (* 1 = 0.31993 loss)
I1211 12:44:24.696812 15296 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1211 12:44:31.016355 15296 solver.cpp:218] Iteration 105200 (15.8247 iter/s, 6.31923s/100 iters), loss = 0.287486
I1211 12:44:31.016355 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 12:44:31.016355 15296 solver.cpp:237]     Train net output #1: loss = 0.287486 (* 1 = 0.287486 loss)
I1211 12:44:31.016355 15296 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1211 12:44:37.335785 15296 solver.cpp:218] Iteration 105300 (15.8274 iter/s, 6.31816s/100 iters), loss = 0.483555
I1211 12:44:37.335785 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:44:37.335785 15296 solver.cpp:237]     Train net output #1: loss = 0.483555 (* 1 = 0.483555 loss)
I1211 12:44:37.335785 15296 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1211 12:44:43.649557 15296 solver.cpp:218] Iteration 105400 (15.8386 iter/s, 6.31367s/100 iters), loss = 0.411214
I1211 12:44:43.649557 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:44:43.649557 15296 solver.cpp:237]     Train net output #1: loss = 0.411214 (* 1 = 0.411214 loss)
I1211 12:44:43.649557 15296 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1211 12:44:49.654001 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:44:49.903038 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105500.caffemodel
I1211 12:44:49.917038 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105500.solverstate
I1211 12:44:49.922039 15296 solver.cpp:330] Iteration 105500, Testing net (#0)
I1211 12:44:49.922039 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:44:51.433527  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:44:51.493531 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6779
I1211 12:44:51.493531 15296 solver.cpp:397]     Test net output #1: loss = 1.23012 (* 1 = 1.23012 loss)
I1211 12:44:51.554533 15296 solver.cpp:218] Iteration 105500 (12.6514 iter/s, 7.90427s/100 iters), loss = 0.356605
I1211 12:44:51.554533 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:44:51.554533 15296 solver.cpp:237]     Train net output #1: loss = 0.356605 (* 1 = 0.356605 loss)
I1211 12:44:51.554533 15296 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1211 12:44:57.876977 15296 solver.cpp:218] Iteration 105600 (15.8184 iter/s, 6.32176s/100 iters), loss = 0.319586
I1211 12:44:57.876977 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 12:44:57.876977 15296 solver.cpp:237]     Train net output #1: loss = 0.319587 (* 1 = 0.319587 loss)
I1211 12:44:57.876977 15296 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1211 12:45:04.191418 15296 solver.cpp:218] Iteration 105700 (15.8368 iter/s, 6.3144s/100 iters), loss = 0.353599
I1211 12:45:04.191418 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:45:04.191418 15296 solver.cpp:237]     Train net output #1: loss = 0.353599 (* 1 = 0.353599 loss)
I1211 12:45:04.191418 15296 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1211 12:45:10.498930 15296 solver.cpp:218] Iteration 105800 (15.8564 iter/s, 6.30662s/100 iters), loss = 0.425909
I1211 12:45:10.498930 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:45:10.498930 15296 solver.cpp:237]     Train net output #1: loss = 0.425909 (* 1 = 0.425909 loss)
I1211 12:45:10.498930 15296 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1211 12:45:16.812415 15296 solver.cpp:218] Iteration 105900 (15.8399 iter/s, 6.31316s/100 iters), loss = 0.459913
I1211 12:45:16.812415 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 12:45:16.812415 15296 solver.cpp:237]     Train net output #1: loss = 0.459913 (* 1 = 0.459913 loss)
I1211 12:45:16.812415 15296 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1211 12:45:22.816851 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:45:23.065364 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106000.caffemodel
I1211 12:45:23.080878 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106000.solverstate
I1211 12:45:23.085880 15296 solver.cpp:330] Iteration 106000, Testing net (#0)
I1211 12:45:23.085880 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:45:24.601238  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:45:24.661237 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6756
I1211 12:45:24.661237 15296 solver.cpp:397]     Test net output #1: loss = 1.23886 (* 1 = 1.23886 loss)
I1211 12:45:24.721246 15296 solver.cpp:218] Iteration 106000 (12.6437 iter/s, 7.90908s/100 iters), loss = 0.339322
I1211 12:45:24.721246 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:45:24.721246 15296 solver.cpp:237]     Train net output #1: loss = 0.339322 (* 1 = 0.339322 loss)
I1211 12:45:24.722246 15296 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1211 12:45:31.035732 15296 solver.cpp:218] Iteration 106100 (15.8377 iter/s, 6.31405s/100 iters), loss = 0.392839
I1211 12:45:31.035732 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:45:31.036732 15296 solver.cpp:237]     Train net output #1: loss = 0.392839 (* 1 = 0.392839 loss)
I1211 12:45:31.036732 15296 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1211 12:45:37.350167 15296 solver.cpp:218] Iteration 106200 (15.8401 iter/s, 6.31309s/100 iters), loss = 0.331394
I1211 12:45:37.350167 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:45:37.350167 15296 solver.cpp:237]     Train net output #1: loss = 0.331394 (* 1 = 0.331394 loss)
I1211 12:45:37.350167 15296 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1211 12:45:43.669643 15296 solver.cpp:218] Iteration 106300 (15.8243 iter/s, 6.31939s/100 iters), loss = 0.408009
I1211 12:45:43.669643 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:45:43.669643 15296 solver.cpp:237]     Train net output #1: loss = 0.40801 (* 1 = 0.40801 loss)
I1211 12:45:43.669643 15296 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1211 12:45:49.979310 15296 solver.cpp:218] Iteration 106400 (15.8488 iter/s, 6.30961s/100 iters), loss = 0.412181
I1211 12:45:49.979310 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:45:49.979310 15296 solver.cpp:237]     Train net output #1: loss = 0.412181 (* 1 = 0.412181 loss)
I1211 12:45:49.979310 15296 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1211 12:45:55.984437 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:45:56.234539 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106500.caffemodel
I1211 12:45:56.248633 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106500.solverstate
I1211 12:45:56.253635 15296 solver.cpp:330] Iteration 106500, Testing net (#0)
I1211 12:45:56.253635 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:45:57.763886  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:45:57.824391 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6766
I1211 12:45:57.824391 15296 solver.cpp:397]     Test net output #1: loss = 1.2321 (* 1 = 1.2321 loss)
I1211 12:45:57.884902 15296 solver.cpp:218] Iteration 106500 (12.6504 iter/s, 7.9049s/100 iters), loss = 0.430095
I1211 12:45:57.884902 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:45:57.884902 15296 solver.cpp:237]     Train net output #1: loss = 0.430095 (* 1 = 0.430095 loss)
I1211 12:45:57.884902 15296 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1211 12:46:04.199620 15296 solver.cpp:218] Iteration 106600 (15.8364 iter/s, 6.31458s/100 iters), loss = 0.379074
I1211 12:46:04.199620 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:46:04.199620 15296 solver.cpp:237]     Train net output #1: loss = 0.379074 (* 1 = 0.379074 loss)
I1211 12:46:04.199620 15296 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1211 12:46:10.505007 15296 solver.cpp:218] Iteration 106700 (15.8604 iter/s, 6.30502s/100 iters), loss = 0.305803
I1211 12:46:10.505007 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:46:10.506008 15296 solver.cpp:237]     Train net output #1: loss = 0.305803 (* 1 = 0.305803 loss)
I1211 12:46:10.506008 15296 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1211 12:46:16.815484 15296 solver.cpp:218] Iteration 106800 (15.8496 iter/s, 6.30929s/100 iters), loss = 0.452396
I1211 12:46:16.815484 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:46:16.815484 15296 solver.cpp:237]     Train net output #1: loss = 0.452396 (* 1 = 0.452396 loss)
I1211 12:46:16.815484 15296 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1211 12:46:23.127946 15296 solver.cpp:218] Iteration 106900 (15.844 iter/s, 6.31155s/100 iters), loss = 0.304728
I1211 12:46:23.127946 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 12:46:23.127946 15296 solver.cpp:237]     Train net output #1: loss = 0.304728 (* 1 = 0.304728 loss)
I1211 12:46:23.127946 15296 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1211 12:46:29.132354 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:46:29.381362 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107000.caffemodel
I1211 12:46:29.396368 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107000.solverstate
I1211 12:46:29.400367 15296 solver.cpp:330] Iteration 107000, Testing net (#0)
I1211 12:46:29.400367 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:46:30.915524  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:46:30.976533 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1211 12:46:30.976533 15296 solver.cpp:397]     Test net output #1: loss = 1.23876 (* 1 = 1.23876 loss)
I1211 12:46:31.037529 15296 solver.cpp:218] Iteration 107000 (12.6425 iter/s, 7.90983s/100 iters), loss = 0.364539
I1211 12:46:31.037529 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:46:31.037529 15296 solver.cpp:237]     Train net output #1: loss = 0.364539 (* 1 = 0.364539 loss)
I1211 12:46:31.037529 15296 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1211 12:46:37.372089 15296 solver.cpp:218] Iteration 107100 (15.7897 iter/s, 6.33323s/100 iters), loss = 0.42603
I1211 12:46:37.372089 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:46:37.372089 15296 solver.cpp:237]     Train net output #1: loss = 0.42603 (* 1 = 0.42603 loss)
I1211 12:46:37.372089 15296 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1211 12:46:43.687546 15296 solver.cpp:218] Iteration 107200 (15.8347 iter/s, 6.31523s/100 iters), loss = 0.347361
I1211 12:46:43.687546 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:46:43.687546 15296 solver.cpp:237]     Train net output #1: loss = 0.347361 (* 1 = 0.347361 loss)
I1211 12:46:43.687546 15296 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1211 12:46:50.012359 15296 solver.cpp:218] Iteration 107300 (15.8124 iter/s, 6.32415s/100 iters), loss = 0.319619
I1211 12:46:50.012359 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 12:46:50.012359 15296 solver.cpp:237]     Train net output #1: loss = 0.319619 (* 1 = 0.319619 loss)
I1211 12:46:50.012359 15296 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1211 12:46:56.329838 15296 solver.cpp:218] Iteration 107400 (15.8306 iter/s, 6.31688s/100 iters), loss = 0.361702
I1211 12:46:56.329838 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:46:56.329838 15296 solver.cpp:237]     Train net output #1: loss = 0.361702 (* 1 = 0.361702 loss)
I1211 12:46:56.329838 15296 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1211 12:47:02.340327 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:47:02.589339 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107500.caffemodel
I1211 12:47:02.604341 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107500.solverstate
I1211 12:47:02.608341 15296 solver.cpp:330] Iteration 107500, Testing net (#0)
I1211 12:47:02.609342 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:47:04.123463  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:47:04.184465 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6759
I1211 12:47:04.184465 15296 solver.cpp:397]     Test net output #1: loss = 1.23865 (* 1 = 1.23865 loss)
I1211 12:47:04.245466 15296 solver.cpp:218] Iteration 107500 (12.6341 iter/s, 7.91511s/100 iters), loss = 0.355319
I1211 12:47:04.245466 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:47:04.245466 15296 solver.cpp:237]     Train net output #1: loss = 0.355319 (* 1 = 0.355319 loss)
I1211 12:47:04.245466 15296 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1211 12:47:10.560899 15296 solver.cpp:218] Iteration 107600 (15.8344 iter/s, 6.31536s/100 iters), loss = 0.378916
I1211 12:47:10.560899 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:47:10.560899 15296 solver.cpp:237]     Train net output #1: loss = 0.378916 (* 1 = 0.378916 loss)
I1211 12:47:10.560899 15296 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1211 12:47:16.876375 15296 solver.cpp:218] Iteration 107700 (15.835 iter/s, 6.31511s/100 iters), loss = 0.322061
I1211 12:47:16.876375 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:47:16.876375 15296 solver.cpp:237]     Train net output #1: loss = 0.322061 (* 1 = 0.322061 loss)
I1211 12:47:16.876375 15296 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1211 12:47:23.194840 15296 solver.cpp:218] Iteration 107800 (15.8284 iter/s, 6.31776s/100 iters), loss = 0.363173
I1211 12:47:23.194840 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:47:23.194840 15296 solver.cpp:237]     Train net output #1: loss = 0.363173 (* 1 = 0.363173 loss)
I1211 12:47:23.194840 15296 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1211 12:47:29.515290 15296 solver.cpp:218] Iteration 107900 (15.8223 iter/s, 6.3202s/100 iters), loss = 0.341342
I1211 12:47:29.515290 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:47:29.515290 15296 solver.cpp:237]     Train net output #1: loss = 0.341343 (* 1 = 0.341343 loss)
I1211 12:47:29.515290 15296 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1211 12:47:35.516767 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:47:35.767781 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108000.caffemodel
I1211 12:47:35.783782 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108000.solverstate
I1211 12:47:35.788782 15296 solver.cpp:330] Iteration 108000, Testing net (#0)
I1211 12:47:35.788782 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:47:37.305944  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:47:37.365950 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6754
I1211 12:47:37.365950 15296 solver.cpp:397]     Test net output #1: loss = 1.24547 (* 1 = 1.24547 loss)
I1211 12:47:37.426949 15296 solver.cpp:218] Iteration 108000 (12.6408 iter/s, 7.91091s/100 iters), loss = 0.300976
I1211 12:47:37.426949 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 12:47:37.426949 15296 solver.cpp:237]     Train net output #1: loss = 0.300977 (* 1 = 0.300977 loss)
I1211 12:47:37.426949 15296 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1211 12:47:43.755631 15296 solver.cpp:218] Iteration 108100 (15.8011 iter/s, 6.32868s/100 iters), loss = 0.425608
I1211 12:47:43.755631 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:47:43.755631 15296 solver.cpp:237]     Train net output #1: loss = 0.425608 (* 1 = 0.425608 loss)
I1211 12:47:43.755631 15296 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1211 12:47:50.088075 15296 solver.cpp:218] Iteration 108200 (15.7932 iter/s, 6.33185s/100 iters), loss = 0.36915
I1211 12:47:50.088075 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:47:50.088075 15296 solver.cpp:237]     Train net output #1: loss = 0.36915 (* 1 = 0.36915 loss)
I1211 12:47:50.088075 15296 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1211 12:47:56.413539 15296 solver.cpp:218] Iteration 108300 (15.809 iter/s, 6.3255s/100 iters), loss = 0.369498
I1211 12:47:56.413539 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 12:47:56.413539 15296 solver.cpp:237]     Train net output #1: loss = 0.369498 (* 1 = 0.369498 loss)
I1211 12:47:56.413539 15296 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1211 12:48:02.734007 15296 solver.cpp:218] Iteration 108400 (15.8231 iter/s, 6.31988s/100 iters), loss = 0.402546
I1211 12:48:02.734007 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 12:48:02.734007 15296 solver.cpp:237]     Train net output #1: loss = 0.402546 (* 1 = 0.402546 loss)
I1211 12:48:02.734007 15296 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1211 12:48:08.743499 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:48:08.992511 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108500.caffemodel
I1211 12:48:09.007513 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108500.solverstate
I1211 12:48:09.011512 15296 solver.cpp:330] Iteration 108500, Testing net (#0)
I1211 12:48:09.011512 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:48:10.529647  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:48:10.589653 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1211 12:48:10.589653 15296 solver.cpp:397]     Test net output #1: loss = 1.24422 (* 1 = 1.24422 loss)
I1211 12:48:10.650153 15296 solver.cpp:218] Iteration 108500 (12.6341 iter/s, 7.91507s/100 iters), loss = 0.356186
I1211 12:48:10.650153 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:48:10.650153 15296 solver.cpp:237]     Train net output #1: loss = 0.356186 (* 1 = 0.356186 loss)
I1211 12:48:10.650153 15296 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1211 12:48:16.962102 15296 solver.cpp:218] Iteration 108600 (15.8436 iter/s, 6.3117s/100 iters), loss = 0.393461
I1211 12:48:16.962102 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:48:16.962102 15296 solver.cpp:237]     Train net output #1: loss = 0.393461 (* 1 = 0.393461 loss)
I1211 12:48:16.962102 15296 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1211 12:48:23.280596 15296 solver.cpp:218] Iteration 108700 (15.8281 iter/s, 6.31788s/100 iters), loss = 0.282338
I1211 12:48:23.280596 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 12:48:23.280596 15296 solver.cpp:237]     Train net output #1: loss = 0.282338 (* 1 = 0.282338 loss)
I1211 12:48:23.280596 15296 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1211 12:48:29.591111 15296 solver.cpp:218] Iteration 108800 (15.8466 iter/s, 6.31049s/100 iters), loss = 0.383345
I1211 12:48:29.591111 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:48:29.591111 15296 solver.cpp:237]     Train net output #1: loss = 0.383345 (* 1 = 0.383345 loss)
I1211 12:48:29.591111 15296 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1211 12:48:36.211628 15296 solver.cpp:218] Iteration 108900 (15.1048 iter/s, 6.62042s/100 iters), loss = 0.342705
I1211 12:48:36.212630 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 12:48:36.212630 15296 solver.cpp:237]     Train net output #1: loss = 0.342705 (* 1 = 0.342705 loss)
I1211 12:48:36.212630 15296 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1211 12:48:42.274366 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:48:42.526401 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109000.caffemodel
I1211 12:48:42.542414 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109000.solverstate
I1211 12:48:42.547425 15296 solver.cpp:330] Iteration 109000, Testing net (#0)
I1211 12:48:42.547425 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:48:44.079511  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:48:44.139510 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6749
I1211 12:48:44.139510 15296 solver.cpp:397]     Test net output #1: loss = 1.24533 (* 1 = 1.24533 loss)
I1211 12:48:44.202175 15296 solver.cpp:218] Iteration 109000 (12.5165 iter/s, 7.98946s/100 iters), loss = 0.346594
I1211 12:48:44.202175 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 12:48:44.202175 15296 solver.cpp:237]     Train net output #1: loss = 0.346595 (* 1 = 0.346595 loss)
I1211 12:48:44.202175 15296 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1211 12:48:50.565886 15296 solver.cpp:218] Iteration 109100 (15.716 iter/s, 6.36294s/100 iters), loss = 0.329977
I1211 12:48:50.565886 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 12:48:50.565886 15296 solver.cpp:237]     Train net output #1: loss = 0.329977 (* 1 = 0.329977 loss)
I1211 12:48:50.565886 15296 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1211 12:48:56.923995 15296 solver.cpp:218] Iteration 109200 (15.7283 iter/s, 6.35795s/100 iters), loss = 0.30305
I1211 12:48:56.923995 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 12:48:56.923995 15296 solver.cpp:237]     Train net output #1: loss = 0.30305 (* 1 = 0.30305 loss)
I1211 12:48:56.923995 15296 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1211 12:49:03.308470 15296 solver.cpp:218] Iteration 109300 (15.6639 iter/s, 6.38412s/100 iters), loss = 0.330603
I1211 12:49:03.308470 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 12:49:03.308470 15296 solver.cpp:237]     Train net output #1: loss = 0.330604 (* 1 = 0.330604 loss)
I1211 12:49:03.308470 15296 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1211 12:49:09.666301 15296 solver.cpp:218] Iteration 109400 (15.7312 iter/s, 6.3568s/100 iters), loss = 0.350333
I1211 12:49:09.666301 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 12:49:09.666301 15296 solver.cpp:237]     Train net output #1: loss = 0.350333 (* 1 = 0.350333 loss)
I1211 12:49:09.666301 15296 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1211 12:49:15.707240 11760 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:49:15.960278 15296 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109500.caffemodel
I1211 12:49:15.975281 15296 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109500.solverstate
I1211 12:49:15.979282 15296 solver.cpp:330] Iteration 109500, Testing net (#0)
I1211 12:49:15.980283 15296 net.cpp:676] Ignoring source layer accuracy_training
I1211 12:49:17.511390  3272 data_layer.cpp:73] Restarting data prefetching from start.
I1211 12:49:17.572410 15296 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1211 12:49:17.572410 15296 solver.cpp:397]     Test net output #1: loss = 1.24466 (* 1 = 1.24466 loss)
I1211 12:49:17.634412 15296 solver.cpp:218] Iteration 109500 (12.5502 iter/s, 7.96798s/100 iters), loss = 0.384967
I1211 12:49:17.634412 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 12:49:17.634412 15296 solver.cpp:237]     Train net output #1: loss = 0.384967 (* 1 = 0.384967 loss)
I1211 12:49:17.634412 15296 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1211 12:49:24.001916 15296 solver.cpp:218] Iteration 109600 (15.7044 iter/s, 6.36764s/100 iters), loss = 0.337735
I1211 12:49:24.002916 15296 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 12:49:24.002916 15296 solver.cpp:237]     Train net output #1: loss = 0.337736 (* 1 = 0.337736 loss)
I1211 12:49:24.002916 15296 sgd_