I1211 06:53:31.936991 22260 caffe.cpp:219] Using GPUs 0
I1211 06:53:32.117604 22260 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1211 06:53:32.423221 22260 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 06:53:32.442222 22260 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 198000
stepvalue: 223000
stepvalue: 270000
type: "AdaDelta"
I1211 06:53:32.443228 22260 solver.cpp:87] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 06:53:32.444222 22260 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 06:53:32.444222 22260 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_added1
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_added2
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1211 06:53:32.444222 22260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1211 06:53:32.444222 22260 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_360k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added1"
  type: "BatchNorm"
  bottom: "newconv_added1"
  top: "newconv_added1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added1"
  type: "Scale"
  bottom: "newconv_added1"
  top: "newconv_added1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added1"
  type: "ReLU"
  bottom: "newconv_added1"
  top: "newconv_added1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added2"
  type: "BatchNorm"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added2"
  type: "Scale"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added2"
  type: "ReLU"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 06:53:32.466223 22260 layer_factory.cpp:58] Creating layer cifar
I1211 06:53:32.469223 22260 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I1211 06:53:32.469223 22260 net.cpp:84] Creating Layer cifar
I1211 06:53:32.469223 22260 net.cpp:380] cifar -> data
I1211 06:53:32.469223 22260 net.cpp:380] cifar -> label
I1211 06:53:32.471221 22260 data_layer.cpp:45] output data size: 100,3,32,32
I1211 06:53:32.480227 22260 net.cpp:122] Setting up cifar
I1211 06:53:32.480732 22260 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 06:53:32.480732 22260 net.cpp:129] Top shape: 100 (100)
I1211 06:53:32.480732 22260 net.cpp:137] Memory required for data: 1229200
I1211 06:53:32.480732 22260 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 06:53:32.480732 22260 net.cpp:84] Creating Layer label_cifar_1_split
I1211 06:53:32.480732 22260 net.cpp:406] label_cifar_1_split <- label
I1211 06:53:32.480732 22260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 06:53:32.480732 22260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 06:53:32.480732 22260 net.cpp:122] Setting up label_cifar_1_split
I1211 06:53:32.480732 22260 net.cpp:129] Top shape: 100 (100)
I1211 06:53:32.480732 22260 net.cpp:129] Top shape: 100 (100)
I1211 06:53:32.480732 22260 net.cpp:137] Memory required for data: 1230000
I1211 06:53:32.480732 22260 layer_factory.cpp:58] Creating layer conv1
I1211 06:53:32.480732 22260 net.cpp:84] Creating Layer conv1
I1211 06:53:32.480732 22260 net.cpp:406] conv1 <- data
I1211 06:53:32.480732 22260 net.cpp:380] conv1 -> conv1
I1211 06:53:32.484228 10692 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 06:53:32.731752 22260 net.cpp:122] Setting up conv1
I1211 06:53:32.731752 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.731752 22260 net.cpp:137] Memory required for data: 13518000
I1211 06:53:32.731752 22260 layer_factory.cpp:58] Creating layer bn1
I1211 06:53:32.731752 22260 net.cpp:84] Creating Layer bn1
I1211 06:53:32.731752 22260 net.cpp:406] bn1 <- conv1
I1211 06:53:32.731752 22260 net.cpp:367] bn1 -> conv1 (in-place)
I1211 06:53:32.731752 22260 net.cpp:122] Setting up bn1
I1211 06:53:32.731752 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.731752 22260 net.cpp:137] Memory required for data: 25806000
I1211 06:53:32.731752 22260 layer_factory.cpp:58] Creating layer scale1
I1211 06:53:32.731752 22260 net.cpp:84] Creating Layer scale1
I1211 06:53:32.731752 22260 net.cpp:406] scale1 <- conv1
I1211 06:53:32.731752 22260 net.cpp:367] scale1 -> conv1 (in-place)
I1211 06:53:32.731752 22260 layer_factory.cpp:58] Creating layer scale1
I1211 06:53:32.731752 22260 net.cpp:122] Setting up scale1
I1211 06:53:32.731752 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.731752 22260 net.cpp:137] Memory required for data: 38094000
I1211 06:53:32.731752 22260 layer_factory.cpp:58] Creating layer relu1
I1211 06:53:32.731752 22260 net.cpp:84] Creating Layer relu1
I1211 06:53:32.731752 22260 net.cpp:406] relu1 <- conv1
I1211 06:53:32.731752 22260 net.cpp:367] relu1 -> conv1 (in-place)
I1211 06:53:32.731752 22260 net.cpp:122] Setting up relu1
I1211 06:53:32.731752 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.731752 22260 net.cpp:137] Memory required for data: 50382000
I1211 06:53:32.731752 22260 layer_factory.cpp:58] Creating layer conv1_0
I1211 06:53:32.731752 22260 net.cpp:84] Creating Layer conv1_0
I1211 06:53:32.731752 22260 net.cpp:406] conv1_0 <- conv1
I1211 06:53:32.731752 22260 net.cpp:380] conv1_0 -> conv1_0
I1211 06:53:32.733753 22260 net.cpp:122] Setting up conv1_0
I1211 06:53:32.733753 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.733753 22260 net.cpp:137] Memory required for data: 66766000
I1211 06:53:32.733753 22260 layer_factory.cpp:58] Creating layer bn1_0
I1211 06:53:32.733753 22260 net.cpp:84] Creating Layer bn1_0
I1211 06:53:32.733753 22260 net.cpp:406] bn1_0 <- conv1_0
I1211 06:53:32.733753 22260 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 06:53:32.733753 22260 net.cpp:122] Setting up bn1_0
I1211 06:53:32.733753 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.733753 22260 net.cpp:137] Memory required for data: 83150000
I1211 06:53:32.733753 22260 layer_factory.cpp:58] Creating layer scale1_0
I1211 06:53:32.733753 22260 net.cpp:84] Creating Layer scale1_0
I1211 06:53:32.733753 22260 net.cpp:406] scale1_0 <- conv1_0
I1211 06:53:32.733753 22260 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 06:53:32.733753 22260 layer_factory.cpp:58] Creating layer scale1_0
I1211 06:53:32.733753 22260 net.cpp:122] Setting up scale1_0
I1211 06:53:32.733753 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.733753 22260 net.cpp:137] Memory required for data: 99534000
I1211 06:53:32.733753 22260 layer_factory.cpp:58] Creating layer relu1_0
I1211 06:53:32.733753 22260 net.cpp:84] Creating Layer relu1_0
I1211 06:53:32.733753 22260 net.cpp:406] relu1_0 <- conv1_0
I1211 06:53:32.733753 22260 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 06:53:32.734752 22260 net.cpp:122] Setting up relu1_0
I1211 06:53:32.734752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.734752 22260 net.cpp:137] Memory required for data: 115918000
I1211 06:53:32.734752 22260 layer_factory.cpp:58] Creating layer conv2
I1211 06:53:32.734752 22260 net.cpp:84] Creating Layer conv2
I1211 06:53:32.734752 22260 net.cpp:406] conv2 <- conv1_0
I1211 06:53:32.734752 22260 net.cpp:380] conv2 -> conv2
I1211 06:53:32.735752 22260 net.cpp:122] Setting up conv2
I1211 06:53:32.735752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.735752 22260 net.cpp:137] Memory required for data: 132302000
I1211 06:53:32.735752 22260 layer_factory.cpp:58] Creating layer bn2
I1211 06:53:32.735752 22260 net.cpp:84] Creating Layer bn2
I1211 06:53:32.735752 22260 net.cpp:406] bn2 <- conv2
I1211 06:53:32.735752 22260 net.cpp:367] bn2 -> conv2 (in-place)
I1211 06:53:32.735752 22260 net.cpp:122] Setting up bn2
I1211 06:53:32.735752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.735752 22260 net.cpp:137] Memory required for data: 148686000
I1211 06:53:32.735752 22260 layer_factory.cpp:58] Creating layer scale2
I1211 06:53:32.735752 22260 net.cpp:84] Creating Layer scale2
I1211 06:53:32.735752 22260 net.cpp:406] scale2 <- conv2
I1211 06:53:32.735752 22260 net.cpp:367] scale2 -> conv2 (in-place)
I1211 06:53:32.735752 22260 layer_factory.cpp:58] Creating layer scale2
I1211 06:53:32.735752 22260 net.cpp:122] Setting up scale2
I1211 06:53:32.735752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.735752 22260 net.cpp:137] Memory required for data: 165070000
I1211 06:53:32.735752 22260 layer_factory.cpp:58] Creating layer relu2
I1211 06:53:32.735752 22260 net.cpp:84] Creating Layer relu2
I1211 06:53:32.735752 22260 net.cpp:406] relu2 <- conv2
I1211 06:53:32.735752 22260 net.cpp:367] relu2 -> conv2 (in-place)
I1211 06:53:32.735752 22260 net.cpp:122] Setting up relu2
I1211 06:53:32.735752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.735752 22260 net.cpp:137] Memory required for data: 181454000
I1211 06:53:32.735752 22260 layer_factory.cpp:58] Creating layer conv2_1
I1211 06:53:32.735752 22260 net.cpp:84] Creating Layer conv2_1
I1211 06:53:32.735752 22260 net.cpp:406] conv2_1 <- conv2
I1211 06:53:32.735752 22260 net.cpp:380] conv2_1 -> conv2_1
I1211 06:53:32.736752 22260 net.cpp:122] Setting up conv2_1
I1211 06:53:32.736752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.736752 22260 net.cpp:137] Memory required for data: 197838000
I1211 06:53:32.736752 22260 layer_factory.cpp:58] Creating layer bn2_1
I1211 06:53:32.736752 22260 net.cpp:84] Creating Layer bn2_1
I1211 06:53:32.736752 22260 net.cpp:406] bn2_1 <- conv2_1
I1211 06:53:32.736752 22260 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 06:53:32.737752 22260 net.cpp:122] Setting up bn2_1
I1211 06:53:32.737752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.737752 22260 net.cpp:137] Memory required for data: 214222000
I1211 06:53:32.737752 22260 layer_factory.cpp:58] Creating layer scale2_1
I1211 06:53:32.737752 22260 net.cpp:84] Creating Layer scale2_1
I1211 06:53:32.737752 22260 net.cpp:406] scale2_1 <- conv2_1
I1211 06:53:32.737752 22260 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 06:53:32.737752 22260 layer_factory.cpp:58] Creating layer scale2_1
I1211 06:53:32.737752 22260 net.cpp:122] Setting up scale2_1
I1211 06:53:32.737752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.737752 22260 net.cpp:137] Memory required for data: 230606000
I1211 06:53:32.737752 22260 layer_factory.cpp:58] Creating layer relu2_1
I1211 06:53:32.737752 22260 net.cpp:84] Creating Layer relu2_1
I1211 06:53:32.737752 22260 net.cpp:406] relu2_1 <- conv2_1
I1211 06:53:32.737752 22260 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 06:53:32.737752 22260 net.cpp:122] Setting up relu2_1
I1211 06:53:32.737752 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.737752 22260 net.cpp:137] Memory required for data: 246990000
I1211 06:53:32.737752 22260 layer_factory.cpp:58] Creating layer conv2_2
I1211 06:53:32.737752 22260 net.cpp:84] Creating Layer conv2_2
I1211 06:53:32.737752 22260 net.cpp:406] conv2_2 <- conv2_1
I1211 06:53:32.737752 22260 net.cpp:380] conv2_2 -> conv2_2
I1211 06:53:32.739753 22260 net.cpp:122] Setting up conv2_2
I1211 06:53:32.739753 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.739753 22260 net.cpp:137] Memory required for data: 267470000
I1211 06:53:32.739753 22260 layer_factory.cpp:58] Creating layer bn2_2
I1211 06:53:32.739753 22260 net.cpp:84] Creating Layer bn2_2
I1211 06:53:32.739753 22260 net.cpp:406] bn2_2 <- conv2_2
I1211 06:53:32.739753 22260 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 06:53:32.739753 22260 net.cpp:122] Setting up bn2_2
I1211 06:53:32.739753 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.739753 22260 net.cpp:137] Memory required for data: 287950000
I1211 06:53:32.739753 22260 layer_factory.cpp:58] Creating layer scale2_2
I1211 06:53:32.739753 22260 net.cpp:84] Creating Layer scale2_2
I1211 06:53:32.739753 22260 net.cpp:406] scale2_2 <- conv2_2
I1211 06:53:32.739753 22260 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 06:53:32.739753 22260 layer_factory.cpp:58] Creating layer scale2_2
I1211 06:53:32.739753 22260 net.cpp:122] Setting up scale2_2
I1211 06:53:32.739753 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.739753 22260 net.cpp:137] Memory required for data: 308430000
I1211 06:53:32.739753 22260 layer_factory.cpp:58] Creating layer relu2_2
I1211 06:53:32.739753 22260 net.cpp:84] Creating Layer relu2_2
I1211 06:53:32.739753 22260 net.cpp:406] relu2_2 <- conv2_2
I1211 06:53:32.739753 22260 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 06:53:32.740752 22260 net.cpp:122] Setting up relu2_2
I1211 06:53:32.740752 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.740752 22260 net.cpp:137] Memory required for data: 328910000
I1211 06:53:32.740752 22260 layer_factory.cpp:58] Creating layer newconv_added1
I1211 06:53:32.740752 22260 net.cpp:84] Creating Layer newconv_added1
I1211 06:53:32.740752 22260 net.cpp:406] newconv_added1 <- conv2_2
I1211 06:53:32.740752 22260 net.cpp:380] newconv_added1 -> newconv_added1
I1211 06:53:32.741751 22260 net.cpp:122] Setting up newconv_added1
I1211 06:53:32.741751 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.741751 22260 net.cpp:137] Memory required for data: 349390000
I1211 06:53:32.741751 22260 layer_factory.cpp:58] Creating layer bn_added1
I1211 06:53:32.741751 22260 net.cpp:84] Creating Layer bn_added1
I1211 06:53:32.741751 22260 net.cpp:406] bn_added1 <- newconv_added1
I1211 06:53:32.741751 22260 net.cpp:367] bn_added1 -> newconv_added1 (in-place)
I1211 06:53:32.741751 22260 net.cpp:122] Setting up bn_added1
I1211 06:53:32.741751 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.741751 22260 net.cpp:137] Memory required for data: 369870000
I1211 06:53:32.741751 22260 layer_factory.cpp:58] Creating layer scale_added1
I1211 06:53:32.741751 22260 net.cpp:84] Creating Layer scale_added1
I1211 06:53:32.741751 22260 net.cpp:406] scale_added1 <- newconv_added1
I1211 06:53:32.741751 22260 net.cpp:367] scale_added1 -> newconv_added1 (in-place)
I1211 06:53:32.741751 22260 layer_factory.cpp:58] Creating layer scale_added1
I1211 06:53:32.741751 22260 net.cpp:122] Setting up scale_added1
I1211 06:53:32.741751 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.741751 22260 net.cpp:137] Memory required for data: 390350000
I1211 06:53:32.741751 22260 layer_factory.cpp:58] Creating layer relu_added1
I1211 06:53:32.741751 22260 net.cpp:84] Creating Layer relu_added1
I1211 06:53:32.741751 22260 net.cpp:406] relu_added1 <- newconv_added1
I1211 06:53:32.741751 22260 net.cpp:367] relu_added1 -> newconv_added1 (in-place)
I1211 06:53:32.742753 22260 net.cpp:122] Setting up relu_added1
I1211 06:53:32.742753 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.742753 22260 net.cpp:137] Memory required for data: 410830000
I1211 06:53:32.742753 22260 layer_factory.cpp:58] Creating layer pool2_1
I1211 06:53:32.742753 22260 net.cpp:84] Creating Layer pool2_1
I1211 06:53:32.742753 22260 net.cpp:406] pool2_1 <- newconv_added1
I1211 06:53:32.742753 22260 net.cpp:380] pool2_1 -> pool2_1
I1211 06:53:32.742753 22260 net.cpp:122] Setting up pool2_1
I1211 06:53:32.742753 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.742753 22260 net.cpp:137] Memory required for data: 415950000
I1211 06:53:32.742753 22260 layer_factory.cpp:58] Creating layer conv3
I1211 06:53:32.742753 22260 net.cpp:84] Creating Layer conv3
I1211 06:53:32.742753 22260 net.cpp:406] conv3 <- pool2_1
I1211 06:53:32.742753 22260 net.cpp:380] conv3 -> conv3
I1211 06:53:32.743752 22260 net.cpp:122] Setting up conv3
I1211 06:53:32.743752 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.743752 22260 net.cpp:137] Memory required for data: 421070000
I1211 06:53:32.743752 22260 layer_factory.cpp:58] Creating layer bn3
I1211 06:53:32.743752 22260 net.cpp:84] Creating Layer bn3
I1211 06:53:32.743752 22260 net.cpp:406] bn3 <- conv3
I1211 06:53:32.743752 22260 net.cpp:367] bn3 -> conv3 (in-place)
I1211 06:53:32.743752 22260 net.cpp:122] Setting up bn3
I1211 06:53:32.743752 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.743752 22260 net.cpp:137] Memory required for data: 426190000
I1211 06:53:32.743752 22260 layer_factory.cpp:58] Creating layer scale3
I1211 06:53:32.743752 22260 net.cpp:84] Creating Layer scale3
I1211 06:53:32.743752 22260 net.cpp:406] scale3 <- conv3
I1211 06:53:32.743752 22260 net.cpp:367] scale3 -> conv3 (in-place)
I1211 06:53:32.743752 22260 layer_factory.cpp:58] Creating layer scale3
I1211 06:53:32.744752 22260 net.cpp:122] Setting up scale3
I1211 06:53:32.744752 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.744752 22260 net.cpp:137] Memory required for data: 431310000
I1211 06:53:32.744752 22260 layer_factory.cpp:58] Creating layer relu3
I1211 06:53:32.744752 22260 net.cpp:84] Creating Layer relu3
I1211 06:53:32.744752 22260 net.cpp:406] relu3 <- conv3
I1211 06:53:32.744752 22260 net.cpp:367] relu3 -> conv3 (in-place)
I1211 06:53:32.744752 22260 net.cpp:122] Setting up relu3
I1211 06:53:32.744752 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.744752 22260 net.cpp:137] Memory required for data: 436430000
I1211 06:53:32.744752 22260 layer_factory.cpp:58] Creating layer conv3_1
I1211 06:53:32.744752 22260 net.cpp:84] Creating Layer conv3_1
I1211 06:53:32.744752 22260 net.cpp:406] conv3_1 <- conv3
I1211 06:53:32.744752 22260 net.cpp:380] conv3_1 -> conv3_1
I1211 06:53:32.745753 22260 net.cpp:122] Setting up conv3_1
I1211 06:53:32.745753 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.745753 22260 net.cpp:137] Memory required for data: 441550000
I1211 06:53:32.745753 22260 layer_factory.cpp:58] Creating layer bn3_1
I1211 06:53:32.745753 22260 net.cpp:84] Creating Layer bn3_1
I1211 06:53:32.745753 22260 net.cpp:406] bn3_1 <- conv3_1
I1211 06:53:32.745753 22260 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 06:53:32.745753 22260 net.cpp:122] Setting up bn3_1
I1211 06:53:32.745753 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.745753 22260 net.cpp:137] Memory required for data: 446670000
I1211 06:53:32.745753 22260 layer_factory.cpp:58] Creating layer scale3_1
I1211 06:53:32.745753 22260 net.cpp:84] Creating Layer scale3_1
I1211 06:53:32.745753 22260 net.cpp:406] scale3_1 <- conv3_1
I1211 06:53:32.745753 22260 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 06:53:32.746752 22260 layer_factory.cpp:58] Creating layer scale3_1
I1211 06:53:32.746752 22260 net.cpp:122] Setting up scale3_1
I1211 06:53:32.746752 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.746752 22260 net.cpp:137] Memory required for data: 451790000
I1211 06:53:32.746752 22260 layer_factory.cpp:58] Creating layer relu3_1
I1211 06:53:32.746752 22260 net.cpp:84] Creating Layer relu3_1
I1211 06:53:32.746752 22260 net.cpp:406] relu3_1 <- conv3_1
I1211 06:53:32.746752 22260 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 06:53:32.746752 22260 net.cpp:122] Setting up relu3_1
I1211 06:53:32.746752 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.746752 22260 net.cpp:137] Memory required for data: 456910000
I1211 06:53:32.746752 22260 layer_factory.cpp:58] Creating layer conv4
I1211 06:53:32.746752 22260 net.cpp:84] Creating Layer conv4
I1211 06:53:32.746752 22260 net.cpp:406] conv4 <- conv3_1
I1211 06:53:32.746752 22260 net.cpp:380] conv4 -> conv4
I1211 06:53:32.748754 22260 net.cpp:122] Setting up conv4
I1211 06:53:32.748754 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.748754 22260 net.cpp:137] Memory required for data: 462030000
I1211 06:53:32.748754 22260 layer_factory.cpp:58] Creating layer bn4
I1211 06:53:32.748754 22260 net.cpp:84] Creating Layer bn4
I1211 06:53:32.748754 22260 net.cpp:406] bn4 <- conv4
I1211 06:53:32.748754 22260 net.cpp:367] bn4 -> conv4 (in-place)
I1211 06:53:32.748754 22260 net.cpp:122] Setting up bn4
I1211 06:53:32.748754 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.748754 22260 net.cpp:137] Memory required for data: 467150000
I1211 06:53:32.748754 22260 layer_factory.cpp:58] Creating layer scale4
I1211 06:53:32.748754 22260 net.cpp:84] Creating Layer scale4
I1211 06:53:32.748754 22260 net.cpp:406] scale4 <- conv4
I1211 06:53:32.748754 22260 net.cpp:367] scale4 -> conv4 (in-place)
I1211 06:53:32.748754 22260 layer_factory.cpp:58] Creating layer scale4
I1211 06:53:32.748754 22260 net.cpp:122] Setting up scale4
I1211 06:53:32.748754 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.748754 22260 net.cpp:137] Memory required for data: 472270000
I1211 06:53:32.748754 22260 layer_factory.cpp:58] Creating layer relu4
I1211 06:53:32.748754 22260 net.cpp:84] Creating Layer relu4
I1211 06:53:32.748754 22260 net.cpp:406] relu4 <- conv4
I1211 06:53:32.748754 22260 net.cpp:367] relu4 -> conv4 (in-place)
I1211 06:53:32.748754 22260 net.cpp:122] Setting up relu4
I1211 06:53:32.749754 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.749754 22260 net.cpp:137] Memory required for data: 477390000
I1211 06:53:32.749754 22260 layer_factory.cpp:58] Creating layer conv4_1
I1211 06:53:32.749754 22260 net.cpp:84] Creating Layer conv4_1
I1211 06:53:32.749754 22260 net.cpp:406] conv4_1 <- conv4
I1211 06:53:32.749754 22260 net.cpp:380] conv4_1 -> conv4_1
I1211 06:53:32.750756 22260 net.cpp:122] Setting up conv4_1
I1211 06:53:32.750756 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.750756 22260 net.cpp:137] Memory required for data: 482510000
I1211 06:53:32.750756 22260 layer_factory.cpp:58] Creating layer bn4_1
I1211 06:53:32.750756 22260 net.cpp:84] Creating Layer bn4_1
I1211 06:53:32.750756 22260 net.cpp:406] bn4_1 <- conv4_1
I1211 06:53:32.750756 22260 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 06:53:32.750756 22260 net.cpp:122] Setting up bn4_1
I1211 06:53:32.750756 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.750756 22260 net.cpp:137] Memory required for data: 487630000
I1211 06:53:32.750756 22260 layer_factory.cpp:58] Creating layer scale4_1
I1211 06:53:32.750756 22260 net.cpp:84] Creating Layer scale4_1
I1211 06:53:32.750756 22260 net.cpp:406] scale4_1 <- conv4_1
I1211 06:53:32.750756 22260 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 06:53:32.750756 22260 layer_factory.cpp:58] Creating layer scale4_1
I1211 06:53:32.751771 22260 net.cpp:122] Setting up scale4_1
I1211 06:53:32.751771 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.751771 22260 net.cpp:137] Memory required for data: 492750000
I1211 06:53:32.751771 22260 layer_factory.cpp:58] Creating layer relu4_1
I1211 06:53:32.751771 22260 net.cpp:84] Creating Layer relu4_1
I1211 06:53:32.751771 22260 net.cpp:406] relu4_1 <- conv4_1
I1211 06:53:32.751771 22260 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 06:53:32.751771 22260 net.cpp:122] Setting up relu4_1
I1211 06:53:32.751771 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.751771 22260 net.cpp:137] Memory required for data: 497870000
I1211 06:53:32.751771 22260 layer_factory.cpp:58] Creating layer conv4_2
I1211 06:53:32.751771 22260 net.cpp:84] Creating Layer conv4_2
I1211 06:53:32.751771 22260 net.cpp:406] conv4_2 <- conv4_1
I1211 06:53:32.751771 22260 net.cpp:380] conv4_2 -> conv4_2
I1211 06:53:32.752754 22260 net.cpp:122] Setting up conv4_2
I1211 06:53:32.752754 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.752754 22260 net.cpp:137] Memory required for data: 503809200
I1211 06:53:32.752754 22260 layer_factory.cpp:58] Creating layer bn4_2
I1211 06:53:32.752754 22260 net.cpp:84] Creating Layer bn4_2
I1211 06:53:32.752754 22260 net.cpp:406] bn4_2 <- conv4_2
I1211 06:53:32.752754 22260 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 06:53:32.752754 22260 net.cpp:122] Setting up bn4_2
I1211 06:53:32.752754 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.752754 22260 net.cpp:137] Memory required for data: 509748400
I1211 06:53:32.752754 22260 layer_factory.cpp:58] Creating layer scale4_2
I1211 06:53:32.752754 22260 net.cpp:84] Creating Layer scale4_2
I1211 06:53:32.752754 22260 net.cpp:406] scale4_2 <- conv4_2
I1211 06:53:32.752754 22260 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 06:53:32.752754 22260 layer_factory.cpp:58] Creating layer scale4_2
I1211 06:53:32.753770 22260 net.cpp:122] Setting up scale4_2
I1211 06:53:32.753770 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.753770 22260 net.cpp:137] Memory required for data: 515687600
I1211 06:53:32.753770 22260 layer_factory.cpp:58] Creating layer relu4_2
I1211 06:53:32.753770 22260 net.cpp:84] Creating Layer relu4_2
I1211 06:53:32.753770 22260 net.cpp:406] relu4_2 <- conv4_2
I1211 06:53:32.753770 22260 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 06:53:32.753770 22260 net.cpp:122] Setting up relu4_2
I1211 06:53:32.753770 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.753770 22260 net.cpp:137] Memory required for data: 521626800
I1211 06:53:32.753770 22260 layer_factory.cpp:58] Creating layer added_new_conv2
I1211 06:53:32.753770 22260 net.cpp:84] Creating Layer added_new_conv2
I1211 06:53:32.753770 22260 net.cpp:406] added_new_conv2 <- conv4_2
I1211 06:53:32.753770 22260 net.cpp:380] added_new_conv2 -> added_new_conv2
I1211 06:53:32.755769 22260 net.cpp:122] Setting up added_new_conv2
I1211 06:53:32.755769 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.755769 22260 net.cpp:137] Memory required for data: 527566000
I1211 06:53:32.755769 22260 layer_factory.cpp:58] Creating layer bn_added2
I1211 06:53:32.755769 22260 net.cpp:84] Creating Layer bn_added2
I1211 06:53:32.755769 22260 net.cpp:406] bn_added2 <- added_new_conv2
I1211 06:53:32.755769 22260 net.cpp:367] bn_added2 -> added_new_conv2 (in-place)
I1211 06:53:32.755769 22260 net.cpp:122] Setting up bn_added2
I1211 06:53:32.755769 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.755769 22260 net.cpp:137] Memory required for data: 533505200
I1211 06:53:32.755769 22260 layer_factory.cpp:58] Creating layer scale_added2
I1211 06:53:32.755769 22260 net.cpp:84] Creating Layer scale_added2
I1211 06:53:32.755769 22260 net.cpp:406] scale_added2 <- added_new_conv2
I1211 06:53:32.755769 22260 net.cpp:367] scale_added2 -> added_new_conv2 (in-place)
I1211 06:53:32.755769 22260 layer_factory.cpp:58] Creating layer scale_added2
I1211 06:53:32.755769 22260 net.cpp:122] Setting up scale_added2
I1211 06:53:32.755769 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.755769 22260 net.cpp:137] Memory required for data: 539444400
I1211 06:53:32.755769 22260 layer_factory.cpp:58] Creating layer relu_added2
I1211 06:53:32.755769 22260 net.cpp:84] Creating Layer relu_added2
I1211 06:53:32.755769 22260 net.cpp:406] relu_added2 <- added_new_conv2
I1211 06:53:32.755769 22260 net.cpp:367] relu_added2 -> added_new_conv2 (in-place)
I1211 06:53:32.756755 22260 net.cpp:122] Setting up relu_added2
I1211 06:53:32.756755 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.756755 22260 net.cpp:137] Memory required for data: 545383600
I1211 06:53:32.756755 22260 layer_factory.cpp:58] Creating layer pool4_2
I1211 06:53:32.756755 22260 net.cpp:84] Creating Layer pool4_2
I1211 06:53:32.756755 22260 net.cpp:406] pool4_2 <- added_new_conv2
I1211 06:53:32.756755 22260 net.cpp:380] pool4_2 -> pool4_2
I1211 06:53:32.756755 22260 net.cpp:122] Setting up pool4_2
I1211 06:53:32.756755 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.756755 22260 net.cpp:137] Memory required for data: 546868400
I1211 06:53:32.756755 22260 layer_factory.cpp:58] Creating layer conv4_0
I1211 06:53:32.756755 22260 net.cpp:84] Creating Layer conv4_0
I1211 06:53:32.756755 22260 net.cpp:406] conv4_0 <- pool4_2
I1211 06:53:32.756755 22260 net.cpp:380] conv4_0 -> conv4_0
I1211 06:53:32.757763 22260 net.cpp:122] Setting up conv4_0
I1211 06:53:32.757763 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.757763 22260 net.cpp:137] Memory required for data: 548353200
I1211 06:53:32.757763 22260 layer_factory.cpp:58] Creating layer bn4_0
I1211 06:53:32.757763 22260 net.cpp:84] Creating Layer bn4_0
I1211 06:53:32.757763 22260 net.cpp:406] bn4_0 <- conv4_0
I1211 06:53:32.757763 22260 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 06:53:32.758752 22260 net.cpp:122] Setting up bn4_0
I1211 06:53:32.758752 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.758752 22260 net.cpp:137] Memory required for data: 549838000
I1211 06:53:32.758752 22260 layer_factory.cpp:58] Creating layer scale4_0
I1211 06:53:32.758752 22260 net.cpp:84] Creating Layer scale4_0
I1211 06:53:32.758752 22260 net.cpp:406] scale4_0 <- conv4_0
I1211 06:53:32.758752 22260 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 06:53:32.758752 22260 layer_factory.cpp:58] Creating layer scale4_0
I1211 06:53:32.758752 22260 net.cpp:122] Setting up scale4_0
I1211 06:53:32.758752 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.758752 22260 net.cpp:137] Memory required for data: 551322800
I1211 06:53:32.758752 22260 layer_factory.cpp:58] Creating layer relu4_0
I1211 06:53:32.758752 22260 net.cpp:84] Creating Layer relu4_0
I1211 06:53:32.758752 22260 net.cpp:406] relu4_0 <- conv4_0
I1211 06:53:32.758752 22260 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 06:53:32.758752 22260 net.cpp:122] Setting up relu4_0
I1211 06:53:32.758752 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.758752 22260 net.cpp:137] Memory required for data: 552807600
I1211 06:53:32.758752 22260 layer_factory.cpp:58] Creating layer conv11
I1211 06:53:32.758752 22260 net.cpp:84] Creating Layer conv11
I1211 06:53:32.758752 22260 net.cpp:406] conv11 <- conv4_0
I1211 06:53:32.758752 22260 net.cpp:380] conv11 -> conv11
I1211 06:53:32.760762 22260 net.cpp:122] Setting up conv11
I1211 06:53:32.760762 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.760762 22260 net.cpp:137] Memory required for data: 554599600
I1211 06:53:32.760762 22260 layer_factory.cpp:58] Creating layer bn_conv11
I1211 06:53:32.760762 22260 net.cpp:84] Creating Layer bn_conv11
I1211 06:53:32.760762 22260 net.cpp:406] bn_conv11 <- conv11
I1211 06:53:32.760762 22260 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 06:53:32.760762 22260 net.cpp:122] Setting up bn_conv11
I1211 06:53:32.760762 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.760762 22260 net.cpp:137] Memory required for data: 556391600
I1211 06:53:32.760762 22260 layer_factory.cpp:58] Creating layer scale_conv11
I1211 06:53:32.760762 22260 net.cpp:84] Creating Layer scale_conv11
I1211 06:53:32.760762 22260 net.cpp:406] scale_conv11 <- conv11
I1211 06:53:32.760762 22260 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 06:53:32.760762 22260 layer_factory.cpp:58] Creating layer scale_conv11
I1211 06:53:32.760762 22260 net.cpp:122] Setting up scale_conv11
I1211 06:53:32.760762 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.760762 22260 net.cpp:137] Memory required for data: 558183600
I1211 06:53:32.760762 22260 layer_factory.cpp:58] Creating layer relu_conv11
I1211 06:53:32.760762 22260 net.cpp:84] Creating Layer relu_conv11
I1211 06:53:32.760762 22260 net.cpp:406] relu_conv11 <- conv11
I1211 06:53:32.760762 22260 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 06:53:32.761754 22260 net.cpp:122] Setting up relu_conv11
I1211 06:53:32.761754 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.761754 22260 net.cpp:137] Memory required for data: 559975600
I1211 06:53:32.761754 22260 layer_factory.cpp:58] Creating layer conv12
I1211 06:53:32.761754 22260 net.cpp:84] Creating Layer conv12
I1211 06:53:32.761754 22260 net.cpp:406] conv12 <- conv11
I1211 06:53:32.761754 22260 net.cpp:380] conv12 -> conv12
I1211 06:53:32.762753 22260 net.cpp:122] Setting up conv12
I1211 06:53:32.762753 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.762753 22260 net.cpp:137] Memory required for data: 562279600
I1211 06:53:32.762753 22260 layer_factory.cpp:58] Creating layer bn_conv12
I1211 06:53:32.762753 22260 net.cpp:84] Creating Layer bn_conv12
I1211 06:53:32.762753 22260 net.cpp:406] bn_conv12 <- conv12
I1211 06:53:32.762753 22260 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 06:53:32.763752 22260 net.cpp:122] Setting up bn_conv12
I1211 06:53:32.763752 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.763752 22260 net.cpp:137] Memory required for data: 564583600
I1211 06:53:32.763752 22260 layer_factory.cpp:58] Creating layer scale_conv12
I1211 06:53:32.763752 22260 net.cpp:84] Creating Layer scale_conv12
I1211 06:53:32.763752 22260 net.cpp:406] scale_conv12 <- conv12
I1211 06:53:32.763752 22260 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 06:53:32.763752 22260 layer_factory.cpp:58] Creating layer scale_conv12
I1211 06:53:32.763752 22260 net.cpp:122] Setting up scale_conv12
I1211 06:53:32.763752 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.763752 22260 net.cpp:137] Memory required for data: 566887600
I1211 06:53:32.763752 22260 layer_factory.cpp:58] Creating layer relu_conv12
I1211 06:53:32.763752 22260 net.cpp:84] Creating Layer relu_conv12
I1211 06:53:32.763752 22260 net.cpp:406] relu_conv12 <- conv12
I1211 06:53:32.763752 22260 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 06:53:32.763752 22260 net.cpp:122] Setting up relu_conv12
I1211 06:53:32.763752 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.763752 22260 net.cpp:137] Memory required for data: 569191600
I1211 06:53:32.763752 22260 layer_factory.cpp:58] Creating layer poolcp6
I1211 06:53:32.763752 22260 net.cpp:84] Creating Layer poolcp6
I1211 06:53:32.763752 22260 net.cpp:406] poolcp6 <- conv12
I1211 06:53:32.763752 22260 net.cpp:380] poolcp6 -> poolcp6
I1211 06:53:32.763752 22260 net.cpp:122] Setting up poolcp6
I1211 06:53:32.763752 22260 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 06:53:32.763752 22260 net.cpp:137] Memory required for data: 569227600
I1211 06:53:32.763752 22260 layer_factory.cpp:58] Creating layer ip1
I1211 06:53:32.763752 22260 net.cpp:84] Creating Layer ip1
I1211 06:53:32.763752 22260 net.cpp:406] ip1 <- poolcp6
I1211 06:53:32.763752 22260 net.cpp:380] ip1 -> ip1
I1211 06:53:32.764763 22260 net.cpp:122] Setting up ip1
I1211 06:53:32.764763 22260 net.cpp:129] Top shape: 100 100 (10000)
I1211 06:53:32.764763 22260 net.cpp:137] Memory required for data: 569267600
I1211 06:53:32.764763 22260 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 06:53:32.764763 22260 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 06:53:32.764763 22260 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 06:53:32.764763 22260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 06:53:32.764763 22260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 06:53:32.764763 22260 net.cpp:122] Setting up ip1_ip1_0_split
I1211 06:53:32.764763 22260 net.cpp:129] Top shape: 100 100 (10000)
I1211 06:53:32.764763 22260 net.cpp:129] Top shape: 100 100 (10000)
I1211 06:53:32.764763 22260 net.cpp:137] Memory required for data: 569347600
I1211 06:53:32.764763 22260 layer_factory.cpp:58] Creating layer accuracy_training
I1211 06:53:32.764763 22260 net.cpp:84] Creating Layer accuracy_training
I1211 06:53:32.764763 22260 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1211 06:53:32.764763 22260 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1211 06:53:32.764763 22260 net.cpp:380] accuracy_training -> accuracy_training
I1211 06:53:32.764763 22260 net.cpp:122] Setting up accuracy_training
I1211 06:53:32.764763 22260 net.cpp:129] Top shape: (1)
I1211 06:53:32.764763 22260 net.cpp:137] Memory required for data: 569347604
I1211 06:53:32.764763 22260 layer_factory.cpp:58] Creating layer loss
I1211 06:53:32.764763 22260 net.cpp:84] Creating Layer loss
I1211 06:53:32.764763 22260 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 06:53:32.764763 22260 net.cpp:406] loss <- label_cifar_1_split_1
I1211 06:53:32.764763 22260 net.cpp:380] loss -> loss
I1211 06:53:32.764763 22260 layer_factory.cpp:58] Creating layer loss
I1211 06:53:32.765754 22260 net.cpp:122] Setting up loss
I1211 06:53:32.765754 22260 net.cpp:129] Top shape: (1)
I1211 06:53:32.765754 22260 net.cpp:132]     with loss weight 1
I1211 06:53:32.765754 22260 net.cpp:137] Memory required for data: 569347608
I1211 06:53:32.765754 22260 net.cpp:198] loss needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:200] accuracy_training does not need backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] ip1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] poolcp6 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu_conv12 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale_conv12 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn_conv12 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv12 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu_conv11 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale_conv11 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn_conv11 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv11 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu4_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale4_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn4_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv4_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] pool4_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu_added2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale_added2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn_added2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] added_new_conv2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu4_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale4_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn4_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv4_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu4_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale4_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn4_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv4_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu4 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale4 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn4 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv4 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu3_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale3_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn3_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv3_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu3 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale3 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn3 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv3 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] pool2_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu_added1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale_added1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn_added1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] newconv_added1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu2_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale2_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn2_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv2_2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu2_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale2_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn2_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv2_1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv2 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu1_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale1_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn1_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv1_0 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] relu1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] scale1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] bn1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:198] conv1 needs backward computation.
I1211 06:53:32.765754 22260 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 06:53:32.765754 22260 net.cpp:200] cifar does not need backward computation.
I1211 06:53:32.765754 22260 net.cpp:242] This network produces output accuracy_training
I1211 06:53:32.765754 22260 net.cpp:242] This network produces output loss
I1211 06:53:32.765754 22260 net.cpp:255] Network initialization done.
I1211 06:53:32.766764 22260 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 06:53:32.766764 22260 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 06:53:32.766764 22260 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_added1
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_added2
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1211 06:53:32.766764 22260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1211 06:53:32.767762 22260 net.cpp:51] Initializing net from parameters: 
name: "CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_360k"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "newconv_added1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "newconv_added1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added1"
  type: "BatchNorm"
  bottom: "newconv_added1"
  top: "newconv_added1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added1"
  type: "Scale"
  bottom: "newconv_added1"
  top: "newconv_added1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added1"
  type: "ReLU"
  bottom: "newconv_added1"
  top: "newconv_added1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "newconv_added1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "added_new_conv2"
  type: "Convolution"
  bottom: "conv4_2"
  top: "added_new_conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_added2"
  type: "BatchNorm"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_added2"
  type: "Scale"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_added2"
  type: "ReLU"
  bottom: "added_new_conv2"
  top: "added_new_conv2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "added_new_conv2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1211 06:53:32.767762 22260 layer_factory.cpp:58] Creating layer cifar
I1211 06:53:32.772753 22260 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I1211 06:53:32.772753 22260 net.cpp:84] Creating Layer cifar
I1211 06:53:32.772753 22260 net.cpp:380] cifar -> data
I1211 06:53:32.772753 22260 net.cpp:380] cifar -> label
I1211 06:53:32.773752 22260 data_layer.cpp:45] output data size: 100,3,32,32
I1211 06:53:32.778769 22260 net.cpp:122] Setting up cifar
I1211 06:53:32.779258 22260 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 06:53:32.779258 22260 net.cpp:129] Top shape: 100 (100)
I1211 06:53:32.779258 22260 net.cpp:137] Memory required for data: 1229200
I1211 06:53:32.779258 22260 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 06:53:32.779258 22260 net.cpp:84] Creating Layer label_cifar_1_split
I1211 06:53:32.779258 22260 net.cpp:406] label_cifar_1_split <- label
I1211 06:53:32.779258 22260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 06:53:32.779258 22260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 06:53:32.779258 22260 net.cpp:122] Setting up label_cifar_1_split
I1211 06:53:32.779258 22260 net.cpp:129] Top shape: 100 (100)
I1211 06:53:32.779258 22260 net.cpp:129] Top shape: 100 (100)
I1211 06:53:32.779258 22260 net.cpp:137] Memory required for data: 1230000
I1211 06:53:32.779258 22260 layer_factory.cpp:58] Creating layer conv1
I1211 06:53:32.779258 22260 net.cpp:84] Creating Layer conv1
I1211 06:53:32.779258 22260 net.cpp:406] conv1 <- data
I1211 06:53:32.779258 22260 net.cpp:380] conv1 -> conv1
I1211 06:53:32.780758 14572 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 06:53:32.780758 22260 net.cpp:122] Setting up conv1
I1211 06:53:32.780758 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.780758 22260 net.cpp:137] Memory required for data: 13518000
I1211 06:53:32.780758 22260 layer_factory.cpp:58] Creating layer bn1
I1211 06:53:32.781258 22260 net.cpp:84] Creating Layer bn1
I1211 06:53:32.781258 22260 net.cpp:406] bn1 <- conv1
I1211 06:53:32.781258 22260 net.cpp:367] bn1 -> conv1 (in-place)
I1211 06:53:32.781258 22260 net.cpp:122] Setting up bn1
I1211 06:53:32.781258 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.781258 22260 net.cpp:137] Memory required for data: 25806000
I1211 06:53:32.781258 22260 layer_factory.cpp:58] Creating layer scale1
I1211 06:53:32.781258 22260 net.cpp:84] Creating Layer scale1
I1211 06:53:32.781258 22260 net.cpp:406] scale1 <- conv1
I1211 06:53:32.781258 22260 net.cpp:367] scale1 -> conv1 (in-place)
I1211 06:53:32.781258 22260 layer_factory.cpp:58] Creating layer scale1
I1211 06:53:32.781258 22260 net.cpp:122] Setting up scale1
I1211 06:53:32.781258 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.781258 22260 net.cpp:137] Memory required for data: 38094000
I1211 06:53:32.781258 22260 layer_factory.cpp:58] Creating layer relu1
I1211 06:53:32.781258 22260 net.cpp:84] Creating Layer relu1
I1211 06:53:32.781258 22260 net.cpp:406] relu1 <- conv1
I1211 06:53:32.781258 22260 net.cpp:367] relu1 -> conv1 (in-place)
I1211 06:53:32.781757 22260 net.cpp:122] Setting up relu1
I1211 06:53:32.782258 22260 net.cpp:129] Top shape: 100 30 32 32 (3072000)
I1211 06:53:32.782258 22260 net.cpp:137] Memory required for data: 50382000
I1211 06:53:32.782258 22260 layer_factory.cpp:58] Creating layer conv1_0
I1211 06:53:32.782258 22260 net.cpp:84] Creating Layer conv1_0
I1211 06:53:32.782258 22260 net.cpp:406] conv1_0 <- conv1
I1211 06:53:32.782258 22260 net.cpp:380] conv1_0 -> conv1_0
I1211 06:53:32.783259 22260 net.cpp:122] Setting up conv1_0
I1211 06:53:32.783259 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.783259 22260 net.cpp:137] Memory required for data: 66766000
I1211 06:53:32.783259 22260 layer_factory.cpp:58] Creating layer bn1_0
I1211 06:53:32.783259 22260 net.cpp:84] Creating Layer bn1_0
I1211 06:53:32.783259 22260 net.cpp:406] bn1_0 <- conv1_0
I1211 06:53:32.783259 22260 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1211 06:53:32.783758 22260 net.cpp:122] Setting up bn1_0
I1211 06:53:32.783758 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.783758 22260 net.cpp:137] Memory required for data: 83150000
I1211 06:53:32.783758 22260 layer_factory.cpp:58] Creating layer scale1_0
I1211 06:53:32.783758 22260 net.cpp:84] Creating Layer scale1_0
I1211 06:53:32.783758 22260 net.cpp:406] scale1_0 <- conv1_0
I1211 06:53:32.783758 22260 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1211 06:53:32.783758 22260 layer_factory.cpp:58] Creating layer scale1_0
I1211 06:53:32.783758 22260 net.cpp:122] Setting up scale1_0
I1211 06:53:32.783758 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.783758 22260 net.cpp:137] Memory required for data: 99534000
I1211 06:53:32.783758 22260 layer_factory.cpp:58] Creating layer relu1_0
I1211 06:53:32.783758 22260 net.cpp:84] Creating Layer relu1_0
I1211 06:53:32.783758 22260 net.cpp:406] relu1_0 <- conv1_0
I1211 06:53:32.783758 22260 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1211 06:53:32.783758 22260 net.cpp:122] Setting up relu1_0
I1211 06:53:32.784258 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.784258 22260 net.cpp:137] Memory required for data: 115918000
I1211 06:53:32.784258 22260 layer_factory.cpp:58] Creating layer conv2
I1211 06:53:32.784258 22260 net.cpp:84] Creating Layer conv2
I1211 06:53:32.784258 22260 net.cpp:406] conv2 <- conv1_0
I1211 06:53:32.784258 22260 net.cpp:380] conv2 -> conv2
I1211 06:53:32.785259 22260 net.cpp:122] Setting up conv2
I1211 06:53:32.785259 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.785259 22260 net.cpp:137] Memory required for data: 132302000
I1211 06:53:32.785259 22260 layer_factory.cpp:58] Creating layer bn2
I1211 06:53:32.785259 22260 net.cpp:84] Creating Layer bn2
I1211 06:53:32.785259 22260 net.cpp:406] bn2 <- conv2
I1211 06:53:32.785259 22260 net.cpp:367] bn2 -> conv2 (in-place)
I1211 06:53:32.785758 22260 net.cpp:122] Setting up bn2
I1211 06:53:32.785758 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.785758 22260 net.cpp:137] Memory required for data: 148686000
I1211 06:53:32.785758 22260 layer_factory.cpp:58] Creating layer scale2
I1211 06:53:32.785758 22260 net.cpp:84] Creating Layer scale2
I1211 06:53:32.785758 22260 net.cpp:406] scale2 <- conv2
I1211 06:53:32.785758 22260 net.cpp:367] scale2 -> conv2 (in-place)
I1211 06:53:32.785758 22260 layer_factory.cpp:58] Creating layer scale2
I1211 06:53:32.785758 22260 net.cpp:122] Setting up scale2
I1211 06:53:32.785758 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.785758 22260 net.cpp:137] Memory required for data: 165070000
I1211 06:53:32.785758 22260 layer_factory.cpp:58] Creating layer relu2
I1211 06:53:32.785758 22260 net.cpp:84] Creating Layer relu2
I1211 06:53:32.785758 22260 net.cpp:406] relu2 <- conv2
I1211 06:53:32.785758 22260 net.cpp:367] relu2 -> conv2 (in-place)
I1211 06:53:32.786257 22260 net.cpp:122] Setting up relu2
I1211 06:53:32.786257 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.786257 22260 net.cpp:137] Memory required for data: 181454000
I1211 06:53:32.786257 22260 layer_factory.cpp:58] Creating layer conv2_1
I1211 06:53:32.786257 22260 net.cpp:84] Creating Layer conv2_1
I1211 06:53:32.786257 22260 net.cpp:406] conv2_1 <- conv2
I1211 06:53:32.786257 22260 net.cpp:380] conv2_1 -> conv2_1
I1211 06:53:32.787757 22260 net.cpp:122] Setting up conv2_1
I1211 06:53:32.787757 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.787757 22260 net.cpp:137] Memory required for data: 197838000
I1211 06:53:32.787757 22260 layer_factory.cpp:58] Creating layer bn2_1
I1211 06:53:32.787757 22260 net.cpp:84] Creating Layer bn2_1
I1211 06:53:32.787757 22260 net.cpp:406] bn2_1 <- conv2_1
I1211 06:53:32.787757 22260 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1211 06:53:32.788259 22260 net.cpp:122] Setting up bn2_1
I1211 06:53:32.788259 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.788259 22260 net.cpp:137] Memory required for data: 214222000
I1211 06:53:32.788259 22260 layer_factory.cpp:58] Creating layer scale2_1
I1211 06:53:32.788259 22260 net.cpp:84] Creating Layer scale2_1
I1211 06:53:32.788259 22260 net.cpp:406] scale2_1 <- conv2_1
I1211 06:53:32.788259 22260 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1211 06:53:32.788259 22260 layer_factory.cpp:58] Creating layer scale2_1
I1211 06:53:32.788259 22260 net.cpp:122] Setting up scale2_1
I1211 06:53:32.788259 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.788259 22260 net.cpp:137] Memory required for data: 230606000
I1211 06:53:32.788259 22260 layer_factory.cpp:58] Creating layer relu2_1
I1211 06:53:32.788259 22260 net.cpp:84] Creating Layer relu2_1
I1211 06:53:32.788259 22260 net.cpp:406] relu2_1 <- conv2_1
I1211 06:53:32.788259 22260 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1211 06:53:32.788758 22260 net.cpp:122] Setting up relu2_1
I1211 06:53:32.788758 22260 net.cpp:129] Top shape: 100 40 32 32 (4096000)
I1211 06:53:32.788758 22260 net.cpp:137] Memory required for data: 246990000
I1211 06:53:32.788758 22260 layer_factory.cpp:58] Creating layer conv2_2
I1211 06:53:32.788758 22260 net.cpp:84] Creating Layer conv2_2
I1211 06:53:32.788758 22260 net.cpp:406] conv2_2 <- conv2_1
I1211 06:53:32.788758 22260 net.cpp:380] conv2_2 -> conv2_2
I1211 06:53:32.790258 22260 net.cpp:122] Setting up conv2_2
I1211 06:53:32.790258 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.790258 22260 net.cpp:137] Memory required for data: 267470000
I1211 06:53:32.790258 22260 layer_factory.cpp:58] Creating layer bn2_2
I1211 06:53:32.790258 22260 net.cpp:84] Creating Layer bn2_2
I1211 06:53:32.790258 22260 net.cpp:406] bn2_2 <- conv2_2
I1211 06:53:32.790258 22260 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1211 06:53:32.790258 22260 net.cpp:122] Setting up bn2_2
I1211 06:53:32.790258 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.790258 22260 net.cpp:137] Memory required for data: 287950000
I1211 06:53:32.790258 22260 layer_factory.cpp:58] Creating layer scale2_2
I1211 06:53:32.790258 22260 net.cpp:84] Creating Layer scale2_2
I1211 06:53:32.790258 22260 net.cpp:406] scale2_2 <- conv2_2
I1211 06:53:32.790258 22260 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1211 06:53:32.790258 22260 layer_factory.cpp:58] Creating layer scale2_2
I1211 06:53:32.790758 22260 net.cpp:122] Setting up scale2_2
I1211 06:53:32.790758 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.790758 22260 net.cpp:137] Memory required for data: 308430000
I1211 06:53:32.790758 22260 layer_factory.cpp:58] Creating layer relu2_2
I1211 06:53:32.790758 22260 net.cpp:84] Creating Layer relu2_2
I1211 06:53:32.790758 22260 net.cpp:406] relu2_2 <- conv2_2
I1211 06:53:32.790758 22260 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1211 06:53:32.790758 22260 net.cpp:122] Setting up relu2_2
I1211 06:53:32.790758 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.790758 22260 net.cpp:137] Memory required for data: 328910000
I1211 06:53:32.790758 22260 layer_factory.cpp:58] Creating layer newconv_added1
I1211 06:53:32.790758 22260 net.cpp:84] Creating Layer newconv_added1
I1211 06:53:32.790758 22260 net.cpp:406] newconv_added1 <- conv2_2
I1211 06:53:32.790758 22260 net.cpp:380] newconv_added1 -> newconv_added1
I1211 06:53:32.792352 22260 net.cpp:122] Setting up newconv_added1
I1211 06:53:32.792352 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.792352 22260 net.cpp:137] Memory required for data: 349390000
I1211 06:53:32.792352 22260 layer_factory.cpp:58] Creating layer bn_added1
I1211 06:53:32.792352 22260 net.cpp:84] Creating Layer bn_added1
I1211 06:53:32.792352 22260 net.cpp:406] bn_added1 <- newconv_added1
I1211 06:53:32.792352 22260 net.cpp:367] bn_added1 -> newconv_added1 (in-place)
I1211 06:53:32.792352 22260 net.cpp:122] Setting up bn_added1
I1211 06:53:32.792352 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.792352 22260 net.cpp:137] Memory required for data: 369870000
I1211 06:53:32.792352 22260 layer_factory.cpp:58] Creating layer scale_added1
I1211 06:53:32.792352 22260 net.cpp:84] Creating Layer scale_added1
I1211 06:53:32.792352 22260 net.cpp:406] scale_added1 <- newconv_added1
I1211 06:53:32.792352 22260 net.cpp:367] scale_added1 -> newconv_added1 (in-place)
I1211 06:53:32.792352 22260 layer_factory.cpp:58] Creating layer scale_added1
I1211 06:53:32.792352 22260 net.cpp:122] Setting up scale_added1
I1211 06:53:32.792352 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.792352 22260 net.cpp:137] Memory required for data: 390350000
I1211 06:53:32.792352 22260 layer_factory.cpp:58] Creating layer relu_added1
I1211 06:53:32.792352 22260 net.cpp:84] Creating Layer relu_added1
I1211 06:53:32.792352 22260 net.cpp:406] relu_added1 <- newconv_added1
I1211 06:53:32.792352 22260 net.cpp:367] relu_added1 -> newconv_added1 (in-place)
I1211 06:53:32.793352 22260 net.cpp:122] Setting up relu_added1
I1211 06:53:32.793352 22260 net.cpp:129] Top shape: 100 50 32 32 (5120000)
I1211 06:53:32.793352 22260 net.cpp:137] Memory required for data: 410830000
I1211 06:53:32.793352 22260 layer_factory.cpp:58] Creating layer pool2_1
I1211 06:53:32.793352 22260 net.cpp:84] Creating Layer pool2_1
I1211 06:53:32.793352 22260 net.cpp:406] pool2_1 <- newconv_added1
I1211 06:53:32.793352 22260 net.cpp:380] pool2_1 -> pool2_1
I1211 06:53:32.793352 22260 net.cpp:122] Setting up pool2_1
I1211 06:53:32.793352 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.793352 22260 net.cpp:137] Memory required for data: 415950000
I1211 06:53:32.793352 22260 layer_factory.cpp:58] Creating layer conv3
I1211 06:53:32.793352 22260 net.cpp:84] Creating Layer conv3
I1211 06:53:32.793352 22260 net.cpp:406] conv3 <- pool2_1
I1211 06:53:32.793352 22260 net.cpp:380] conv3 -> conv3
I1211 06:53:32.794351 22260 net.cpp:122] Setting up conv3
I1211 06:53:32.794351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.794351 22260 net.cpp:137] Memory required for data: 421070000
I1211 06:53:32.794351 22260 layer_factory.cpp:58] Creating layer bn3
I1211 06:53:32.794351 22260 net.cpp:84] Creating Layer bn3
I1211 06:53:32.794351 22260 net.cpp:406] bn3 <- conv3
I1211 06:53:32.794351 22260 net.cpp:367] bn3 -> conv3 (in-place)
I1211 06:53:32.794351 22260 net.cpp:122] Setting up bn3
I1211 06:53:32.794351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.794351 22260 net.cpp:137] Memory required for data: 426190000
I1211 06:53:32.794351 22260 layer_factory.cpp:58] Creating layer scale3
I1211 06:53:32.794351 22260 net.cpp:84] Creating Layer scale3
I1211 06:53:32.794351 22260 net.cpp:406] scale3 <- conv3
I1211 06:53:32.794351 22260 net.cpp:367] scale3 -> conv3 (in-place)
I1211 06:53:32.794351 22260 layer_factory.cpp:58] Creating layer scale3
I1211 06:53:32.794351 22260 net.cpp:122] Setting up scale3
I1211 06:53:32.794351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.794351 22260 net.cpp:137] Memory required for data: 431310000
I1211 06:53:32.794351 22260 layer_factory.cpp:58] Creating layer relu3
I1211 06:53:32.794351 22260 net.cpp:84] Creating Layer relu3
I1211 06:53:32.794351 22260 net.cpp:406] relu3 <- conv3
I1211 06:53:32.794351 22260 net.cpp:367] relu3 -> conv3 (in-place)
I1211 06:53:32.795352 22260 net.cpp:122] Setting up relu3
I1211 06:53:32.795352 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.795352 22260 net.cpp:137] Memory required for data: 436430000
I1211 06:53:32.795352 22260 layer_factory.cpp:58] Creating layer conv3_1
I1211 06:53:32.795352 22260 net.cpp:84] Creating Layer conv3_1
I1211 06:53:32.795352 22260 net.cpp:406] conv3_1 <- conv3
I1211 06:53:32.795352 22260 net.cpp:380] conv3_1 -> conv3_1
I1211 06:53:32.797353 22260 net.cpp:122] Setting up conv3_1
I1211 06:53:32.797353 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.797353 22260 net.cpp:137] Memory required for data: 441550000
I1211 06:53:32.797353 22260 layer_factory.cpp:58] Creating layer bn3_1
I1211 06:53:32.797353 22260 net.cpp:84] Creating Layer bn3_1
I1211 06:53:32.797353 22260 net.cpp:406] bn3_1 <- conv3_1
I1211 06:53:32.797353 22260 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1211 06:53:32.797353 22260 net.cpp:122] Setting up bn3_1
I1211 06:53:32.797353 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.797353 22260 net.cpp:137] Memory required for data: 446670000
I1211 06:53:32.797353 22260 layer_factory.cpp:58] Creating layer scale3_1
I1211 06:53:32.797353 22260 net.cpp:84] Creating Layer scale3_1
I1211 06:53:32.797353 22260 net.cpp:406] scale3_1 <- conv3_1
I1211 06:53:32.797353 22260 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1211 06:53:32.797353 22260 layer_factory.cpp:58] Creating layer scale3_1
I1211 06:53:32.797353 22260 net.cpp:122] Setting up scale3_1
I1211 06:53:32.797353 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.797353 22260 net.cpp:137] Memory required for data: 451790000
I1211 06:53:32.797353 22260 layer_factory.cpp:58] Creating layer relu3_1
I1211 06:53:32.797353 22260 net.cpp:84] Creating Layer relu3_1
I1211 06:53:32.797353 22260 net.cpp:406] relu3_1 <- conv3_1
I1211 06:53:32.797353 22260 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1211 06:53:32.797353 22260 net.cpp:122] Setting up relu3_1
I1211 06:53:32.797353 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.797353 22260 net.cpp:137] Memory required for data: 456910000
I1211 06:53:32.797353 22260 layer_factory.cpp:58] Creating layer conv4
I1211 06:53:32.797353 22260 net.cpp:84] Creating Layer conv4
I1211 06:53:32.797353 22260 net.cpp:406] conv4 <- conv3_1
I1211 06:53:32.797353 22260 net.cpp:380] conv4 -> conv4
I1211 06:53:32.799351 22260 net.cpp:122] Setting up conv4
I1211 06:53:32.799351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.799351 22260 net.cpp:137] Memory required for data: 462030000
I1211 06:53:32.799351 22260 layer_factory.cpp:58] Creating layer bn4
I1211 06:53:32.799351 22260 net.cpp:84] Creating Layer bn4
I1211 06:53:32.799351 22260 net.cpp:406] bn4 <- conv4
I1211 06:53:32.799351 22260 net.cpp:367] bn4 -> conv4 (in-place)
I1211 06:53:32.799351 22260 net.cpp:122] Setting up bn4
I1211 06:53:32.799351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.799351 22260 net.cpp:137] Memory required for data: 467150000
I1211 06:53:32.799351 22260 layer_factory.cpp:58] Creating layer scale4
I1211 06:53:32.799351 22260 net.cpp:84] Creating Layer scale4
I1211 06:53:32.799351 22260 net.cpp:406] scale4 <- conv4
I1211 06:53:32.799351 22260 net.cpp:367] scale4 -> conv4 (in-place)
I1211 06:53:32.799351 22260 layer_factory.cpp:58] Creating layer scale4
I1211 06:53:32.799351 22260 net.cpp:122] Setting up scale4
I1211 06:53:32.799351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.799351 22260 net.cpp:137] Memory required for data: 472270000
I1211 06:53:32.799351 22260 layer_factory.cpp:58] Creating layer relu4
I1211 06:53:32.799351 22260 net.cpp:84] Creating Layer relu4
I1211 06:53:32.799351 22260 net.cpp:406] relu4 <- conv4
I1211 06:53:32.799351 22260 net.cpp:367] relu4 -> conv4 (in-place)
I1211 06:53:32.799351 22260 net.cpp:122] Setting up relu4
I1211 06:53:32.799351 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.799351 22260 net.cpp:137] Memory required for data: 477390000
I1211 06:53:32.799351 22260 layer_factory.cpp:58] Creating layer conv4_1
I1211 06:53:32.799351 22260 net.cpp:84] Creating Layer conv4_1
I1211 06:53:32.799351 22260 net.cpp:406] conv4_1 <- conv4
I1211 06:53:32.799351 22260 net.cpp:380] conv4_1 -> conv4_1
I1211 06:53:32.801352 22260 net.cpp:122] Setting up conv4_1
I1211 06:53:32.801352 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.801352 22260 net.cpp:137] Memory required for data: 482510000
I1211 06:53:32.801352 22260 layer_factory.cpp:58] Creating layer bn4_1
I1211 06:53:32.801352 22260 net.cpp:84] Creating Layer bn4_1
I1211 06:53:32.801352 22260 net.cpp:406] bn4_1 <- conv4_1
I1211 06:53:32.801352 22260 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1211 06:53:32.801352 22260 net.cpp:122] Setting up bn4_1
I1211 06:53:32.801352 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.801352 22260 net.cpp:137] Memory required for data: 487630000
I1211 06:53:32.801352 22260 layer_factory.cpp:58] Creating layer scale4_1
I1211 06:53:32.801352 22260 net.cpp:84] Creating Layer scale4_1
I1211 06:53:32.801352 22260 net.cpp:406] scale4_1 <- conv4_1
I1211 06:53:32.801352 22260 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1211 06:53:32.801352 22260 layer_factory.cpp:58] Creating layer scale4_1
I1211 06:53:32.801352 22260 net.cpp:122] Setting up scale4_1
I1211 06:53:32.801352 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.801352 22260 net.cpp:137] Memory required for data: 492750000
I1211 06:53:32.801352 22260 layer_factory.cpp:58] Creating layer relu4_1
I1211 06:53:32.801352 22260 net.cpp:84] Creating Layer relu4_1
I1211 06:53:32.801352 22260 net.cpp:406] relu4_1 <- conv4_1
I1211 06:53:32.801352 22260 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1211 06:53:32.801352 22260 net.cpp:122] Setting up relu4_1
I1211 06:53:32.801352 22260 net.cpp:129] Top shape: 100 50 16 16 (1280000)
I1211 06:53:32.801352 22260 net.cpp:137] Memory required for data: 497870000
I1211 06:53:32.801352 22260 layer_factory.cpp:58] Creating layer conv4_2
I1211 06:53:32.801352 22260 net.cpp:84] Creating Layer conv4_2
I1211 06:53:32.801352 22260 net.cpp:406] conv4_2 <- conv4_1
I1211 06:53:32.801352 22260 net.cpp:380] conv4_2 -> conv4_2
I1211 06:53:32.803352 22260 net.cpp:122] Setting up conv4_2
I1211 06:53:32.803352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.803352 22260 net.cpp:137] Memory required for data: 503809200
I1211 06:53:32.803352 22260 layer_factory.cpp:58] Creating layer bn4_2
I1211 06:53:32.803352 22260 net.cpp:84] Creating Layer bn4_2
I1211 06:53:32.803352 22260 net.cpp:406] bn4_2 <- conv4_2
I1211 06:53:32.803352 22260 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1211 06:53:32.803352 22260 net.cpp:122] Setting up bn4_2
I1211 06:53:32.803352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.803352 22260 net.cpp:137] Memory required for data: 509748400
I1211 06:53:32.803352 22260 layer_factory.cpp:58] Creating layer scale4_2
I1211 06:53:32.803352 22260 net.cpp:84] Creating Layer scale4_2
I1211 06:53:32.803352 22260 net.cpp:406] scale4_2 <- conv4_2
I1211 06:53:32.803352 22260 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1211 06:53:32.803352 22260 layer_factory.cpp:58] Creating layer scale4_2
I1211 06:53:32.803352 22260 net.cpp:122] Setting up scale4_2
I1211 06:53:32.803352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.803352 22260 net.cpp:137] Memory required for data: 515687600
I1211 06:53:32.803352 22260 layer_factory.cpp:58] Creating layer relu4_2
I1211 06:53:32.803352 22260 net.cpp:84] Creating Layer relu4_2
I1211 06:53:32.803352 22260 net.cpp:406] relu4_2 <- conv4_2
I1211 06:53:32.803352 22260 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1211 06:53:32.804352 22260 net.cpp:122] Setting up relu4_2
I1211 06:53:32.804352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.804352 22260 net.cpp:137] Memory required for data: 521626800
I1211 06:53:32.804352 22260 layer_factory.cpp:58] Creating layer added_new_conv2
I1211 06:53:32.804352 22260 net.cpp:84] Creating Layer added_new_conv2
I1211 06:53:32.804352 22260 net.cpp:406] added_new_conv2 <- conv4_2
I1211 06:53:32.804352 22260 net.cpp:380] added_new_conv2 -> added_new_conv2
I1211 06:53:32.805352 22260 net.cpp:122] Setting up added_new_conv2
I1211 06:53:32.805352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.805352 22260 net.cpp:137] Memory required for data: 527566000
I1211 06:53:32.805352 22260 layer_factory.cpp:58] Creating layer bn_added2
I1211 06:53:32.805352 22260 net.cpp:84] Creating Layer bn_added2
I1211 06:53:32.805352 22260 net.cpp:406] bn_added2 <- added_new_conv2
I1211 06:53:32.805352 22260 net.cpp:367] bn_added2 -> added_new_conv2 (in-place)
I1211 06:53:32.805352 22260 net.cpp:122] Setting up bn_added2
I1211 06:53:32.805352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.805352 22260 net.cpp:137] Memory required for data: 533505200
I1211 06:53:32.805352 22260 layer_factory.cpp:58] Creating layer scale_added2
I1211 06:53:32.805352 22260 net.cpp:84] Creating Layer scale_added2
I1211 06:53:32.805352 22260 net.cpp:406] scale_added2 <- added_new_conv2
I1211 06:53:32.805352 22260 net.cpp:367] scale_added2 -> added_new_conv2 (in-place)
I1211 06:53:32.805352 22260 layer_factory.cpp:58] Creating layer scale_added2
I1211 06:53:32.805352 22260 net.cpp:122] Setting up scale_added2
I1211 06:53:32.805352 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.805352 22260 net.cpp:137] Memory required for data: 539444400
I1211 06:53:32.805352 22260 layer_factory.cpp:58] Creating layer relu_added2
I1211 06:53:32.805352 22260 net.cpp:84] Creating Layer relu_added2
I1211 06:53:32.805352 22260 net.cpp:406] relu_added2 <- added_new_conv2
I1211 06:53:32.805352 22260 net.cpp:367] relu_added2 -> added_new_conv2 (in-place)
I1211 06:53:32.806351 22260 net.cpp:122] Setting up relu_added2
I1211 06:53:32.806351 22260 net.cpp:129] Top shape: 100 58 16 16 (1484800)
I1211 06:53:32.806351 22260 net.cpp:137] Memory required for data: 545383600
I1211 06:53:32.806351 22260 layer_factory.cpp:58] Creating layer pool4_2
I1211 06:53:32.806351 22260 net.cpp:84] Creating Layer pool4_2
I1211 06:53:32.806351 22260 net.cpp:406] pool4_2 <- added_new_conv2
I1211 06:53:32.806351 22260 net.cpp:380] pool4_2 -> pool4_2
I1211 06:53:32.806351 22260 net.cpp:122] Setting up pool4_2
I1211 06:53:32.806351 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.806351 22260 net.cpp:137] Memory required for data: 546868400
I1211 06:53:32.806351 22260 layer_factory.cpp:58] Creating layer conv4_0
I1211 06:53:32.806351 22260 net.cpp:84] Creating Layer conv4_0
I1211 06:53:32.806351 22260 net.cpp:406] conv4_0 <- pool4_2
I1211 06:53:32.806351 22260 net.cpp:380] conv4_0 -> conv4_0
I1211 06:53:32.808351 22260 net.cpp:122] Setting up conv4_0
I1211 06:53:32.808351 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.808351 22260 net.cpp:137] Memory required for data: 548353200
I1211 06:53:32.808351 22260 layer_factory.cpp:58] Creating layer bn4_0
I1211 06:53:32.808351 22260 net.cpp:84] Creating Layer bn4_0
I1211 06:53:32.808351 22260 net.cpp:406] bn4_0 <- conv4_0
I1211 06:53:32.808351 22260 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1211 06:53:32.808351 22260 net.cpp:122] Setting up bn4_0
I1211 06:53:32.808351 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.808351 22260 net.cpp:137] Memory required for data: 549838000
I1211 06:53:32.808351 22260 layer_factory.cpp:58] Creating layer scale4_0
I1211 06:53:32.808351 22260 net.cpp:84] Creating Layer scale4_0
I1211 06:53:32.808351 22260 net.cpp:406] scale4_0 <- conv4_0
I1211 06:53:32.808351 22260 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1211 06:53:32.808351 22260 layer_factory.cpp:58] Creating layer scale4_0
I1211 06:53:32.808351 22260 net.cpp:122] Setting up scale4_0
I1211 06:53:32.808351 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.808351 22260 net.cpp:137] Memory required for data: 551322800
I1211 06:53:32.808351 22260 layer_factory.cpp:58] Creating layer relu4_0
I1211 06:53:32.808351 22260 net.cpp:84] Creating Layer relu4_0
I1211 06:53:32.808351 22260 net.cpp:406] relu4_0 <- conv4_0
I1211 06:53:32.808351 22260 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1211 06:53:32.809351 22260 net.cpp:122] Setting up relu4_0
I1211 06:53:32.809351 22260 net.cpp:129] Top shape: 100 58 8 8 (371200)
I1211 06:53:32.809351 22260 net.cpp:137] Memory required for data: 552807600
I1211 06:53:32.809351 22260 layer_factory.cpp:58] Creating layer conv11
I1211 06:53:32.809351 22260 net.cpp:84] Creating Layer conv11
I1211 06:53:32.809351 22260 net.cpp:406] conv11 <- conv4_0
I1211 06:53:32.809351 22260 net.cpp:380] conv11 -> conv11
I1211 06:53:32.810353 22260 net.cpp:122] Setting up conv11
I1211 06:53:32.810353 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.810353 22260 net.cpp:137] Memory required for data: 554599600
I1211 06:53:32.810353 22260 layer_factory.cpp:58] Creating layer bn_conv11
I1211 06:53:32.810353 22260 net.cpp:84] Creating Layer bn_conv11
I1211 06:53:32.810353 22260 net.cpp:406] bn_conv11 <- conv11
I1211 06:53:32.810353 22260 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1211 06:53:32.810353 22260 net.cpp:122] Setting up bn_conv11
I1211 06:53:32.810353 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.810353 22260 net.cpp:137] Memory required for data: 556391600
I1211 06:53:32.811352 22260 layer_factory.cpp:58] Creating layer scale_conv11
I1211 06:53:32.811352 22260 net.cpp:84] Creating Layer scale_conv11
I1211 06:53:32.811352 22260 net.cpp:406] scale_conv11 <- conv11
I1211 06:53:32.811352 22260 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1211 06:53:32.811352 22260 layer_factory.cpp:58] Creating layer scale_conv11
I1211 06:53:32.811352 22260 net.cpp:122] Setting up scale_conv11
I1211 06:53:32.811352 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.811352 22260 net.cpp:137] Memory required for data: 558183600
I1211 06:53:32.811352 22260 layer_factory.cpp:58] Creating layer relu_conv11
I1211 06:53:32.811352 22260 net.cpp:84] Creating Layer relu_conv11
I1211 06:53:32.811352 22260 net.cpp:406] relu_conv11 <- conv11
I1211 06:53:32.811352 22260 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1211 06:53:32.811352 22260 net.cpp:122] Setting up relu_conv11
I1211 06:53:32.811352 22260 net.cpp:129] Top shape: 100 70 8 8 (448000)
I1211 06:53:32.811352 22260 net.cpp:137] Memory required for data: 559975600
I1211 06:53:32.811352 22260 layer_factory.cpp:58] Creating layer conv12
I1211 06:53:32.811352 22260 net.cpp:84] Creating Layer conv12
I1211 06:53:32.811352 22260 net.cpp:406] conv12 <- conv11
I1211 06:53:32.811352 22260 net.cpp:380] conv12 -> conv12
I1211 06:53:32.813352 22260 net.cpp:122] Setting up conv12
I1211 06:53:32.813352 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.813352 22260 net.cpp:137] Memory required for data: 562279600
I1211 06:53:32.813352 22260 layer_factory.cpp:58] Creating layer bn_conv12
I1211 06:53:32.813352 22260 net.cpp:84] Creating Layer bn_conv12
I1211 06:53:32.813352 22260 net.cpp:406] bn_conv12 <- conv12
I1211 06:53:32.813352 22260 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1211 06:53:32.813352 22260 net.cpp:122] Setting up bn_conv12
I1211 06:53:32.813352 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.813352 22260 net.cpp:137] Memory required for data: 564583600
I1211 06:53:32.813352 22260 layer_factory.cpp:58] Creating layer scale_conv12
I1211 06:53:32.813352 22260 net.cpp:84] Creating Layer scale_conv12
I1211 06:53:32.813352 22260 net.cpp:406] scale_conv12 <- conv12
I1211 06:53:32.813352 22260 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1211 06:53:32.813352 22260 layer_factory.cpp:58] Creating layer scale_conv12
I1211 06:53:32.813352 22260 net.cpp:122] Setting up scale_conv12
I1211 06:53:32.813352 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.813352 22260 net.cpp:137] Memory required for data: 566887600
I1211 06:53:32.813352 22260 layer_factory.cpp:58] Creating layer relu_conv12
I1211 06:53:32.813352 22260 net.cpp:84] Creating Layer relu_conv12
I1211 06:53:32.813352 22260 net.cpp:406] relu_conv12 <- conv12
I1211 06:53:32.813352 22260 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1211 06:53:32.813352 22260 net.cpp:122] Setting up relu_conv12
I1211 06:53:32.813352 22260 net.cpp:129] Top shape: 100 90 8 8 (576000)
I1211 06:53:32.813352 22260 net.cpp:137] Memory required for data: 569191600
I1211 06:53:32.813352 22260 layer_factory.cpp:58] Creating layer poolcp6
I1211 06:53:32.813352 22260 net.cpp:84] Creating Layer poolcp6
I1211 06:53:32.813352 22260 net.cpp:406] poolcp6 <- conv12
I1211 06:53:32.813352 22260 net.cpp:380] poolcp6 -> poolcp6
I1211 06:53:32.813352 22260 net.cpp:122] Setting up poolcp6
I1211 06:53:32.813352 22260 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1211 06:53:32.814352 22260 net.cpp:137] Memory required for data: 569227600
I1211 06:53:32.814352 22260 layer_factory.cpp:58] Creating layer ip1
I1211 06:53:32.814352 22260 net.cpp:84] Creating Layer ip1
I1211 06:53:32.814352 22260 net.cpp:406] ip1 <- poolcp6
I1211 06:53:32.814352 22260 net.cpp:380] ip1 -> ip1
I1211 06:53:32.814352 22260 net.cpp:122] Setting up ip1
I1211 06:53:32.814352 22260 net.cpp:129] Top shape: 100 100 (10000)
I1211 06:53:32.814352 22260 net.cpp:137] Memory required for data: 569267600
I1211 06:53:32.814352 22260 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1211 06:53:32.814352 22260 net.cpp:84] Creating Layer ip1_ip1_0_split
I1211 06:53:32.814352 22260 net.cpp:406] ip1_ip1_0_split <- ip1
I1211 06:53:32.814352 22260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1211 06:53:32.814352 22260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1211 06:53:32.814352 22260 net.cpp:122] Setting up ip1_ip1_0_split
I1211 06:53:32.814352 22260 net.cpp:129] Top shape: 100 100 (10000)
I1211 06:53:32.814352 22260 net.cpp:129] Top shape: 100 100 (10000)
I1211 06:53:32.814352 22260 net.cpp:137] Memory required for data: 569347600
I1211 06:53:32.814352 22260 layer_factory.cpp:58] Creating layer accuracy
I1211 06:53:32.814352 22260 net.cpp:84] Creating Layer accuracy
I1211 06:53:32.814352 22260 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1211 06:53:32.814352 22260 net.cpp:406] accuracy <- label_cifar_1_split_0
I1211 06:53:32.814352 22260 net.cpp:380] accuracy -> accuracy
I1211 06:53:32.814352 22260 net.cpp:122] Setting up accuracy
I1211 06:53:32.814352 22260 net.cpp:129] Top shape: (1)
I1211 06:53:32.814352 22260 net.cpp:137] Memory required for data: 569347604
I1211 06:53:32.814352 22260 layer_factory.cpp:58] Creating layer loss
I1211 06:53:32.814352 22260 net.cpp:84] Creating Layer loss
I1211 06:53:32.814352 22260 net.cpp:406] loss <- ip1_ip1_0_split_1
I1211 06:53:32.814352 22260 net.cpp:406] loss <- label_cifar_1_split_1
I1211 06:53:32.814352 22260 net.cpp:380] loss -> loss
I1211 06:53:32.814352 22260 layer_factory.cpp:58] Creating layer loss
I1211 06:53:32.814352 22260 net.cpp:122] Setting up loss
I1211 06:53:32.814352 22260 net.cpp:129] Top shape: (1)
I1211 06:53:32.814352 22260 net.cpp:132]     with loss weight 1
I1211 06:53:32.814352 22260 net.cpp:137] Memory required for data: 569347608
I1211 06:53:32.814352 22260 net.cpp:198] loss needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:200] accuracy does not need backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] ip1 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] poolcp6 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] relu_conv12 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] scale_conv12 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] bn_conv12 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] conv12 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] relu_conv11 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] scale_conv11 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] bn_conv11 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] conv11 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] relu4_0 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] scale4_0 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] bn4_0 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] conv4_0 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] pool4_2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] relu_added2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] scale_added2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] bn_added2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] added_new_conv2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] relu4_2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] scale4_2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] bn4_2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] conv4_2 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] relu4_1 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] scale4_1 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] bn4_1 needs backward computation.
I1211 06:53:32.814352 22260 net.cpp:198] conv4_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu4 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale4 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn4 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv4 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu3_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale3_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn3_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv3_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu3 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale3 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn3 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv3 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] pool2_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu_added1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale_added1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn_added1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] newconv_added1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu2_2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale2_2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn2_2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv2_2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu2_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale2_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn2_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv2_1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv2 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu1_0 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale1_0 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn1_0 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv1_0 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] relu1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] scale1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] bn1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:198] conv1 needs backward computation.
I1211 06:53:32.815351 22260 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 06:53:32.815351 22260 net.cpp:200] cifar does not need backward computation.
I1211 06:53:32.815351 22260 net.cpp:242] This network produces output accuracy
I1211 06:53:32.815351 22260 net.cpp:242] This network produces output loss
I1211 06:53:32.815351 22260 net.cpp:255] Network initialization done.
I1211 06:53:32.815351 22260 solver.cpp:56] Solver scaffolding done.
I1211 06:53:32.819370 22260 caffe.cpp:249] Starting Optimization
I1211 06:53:32.819370 22260 solver.cpp:272] Solving CIFAR100_SimpleNet_GP_15L_Simple_NoGrpCon_NoDrp_max_360k
I1211 06:53:32.819370 22260 solver.cpp:273] Learning Rate Policy: multistep
I1211 06:53:32.822351 22260 solver.cpp:330] Iteration 0, Testing net (#0)
I1211 06:53:32.825361 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:53:34.402206 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:53:34.462209 22260 solver.cpp:397]     Test net output #0: accuracy = 0.0104
I1211 06:53:34.462209 22260 solver.cpp:397]     Test net output #1: loss = 86.4282 (* 1 = 86.4282 loss)
I1211 06:53:34.576898 22260 solver.cpp:218] Iteration 0 (0 iter/s, 1.75544s/100 iters), loss = 6.65199
I1211 06:53:34.576898 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.01
I1211 06:53:34.576898 22260 solver.cpp:237]     Train net output #1: loss = 6.65199 (* 1 = 6.65199 loss)
I1211 06:53:34.576898 22260 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1211 06:53:40.926928 22260 solver.cpp:218] Iteration 100 (15.7487 iter/s, 6.34973s/100 iters), loss = 4.59419
I1211 06:53:40.926928 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.01
I1211 06:53:40.926928 22260 solver.cpp:237]     Train net output #1: loss = 4.59419 (* 1 = 4.59419 loss)
I1211 06:53:40.926928 22260 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1211 06:53:47.237653 22260 solver.cpp:218] Iteration 200 (15.8476 iter/s, 6.3101s/100 iters), loss = 4.32222
I1211 06:53:47.237653 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1211 06:53:47.237653 22260 solver.cpp:237]     Train net output #1: loss = 4.32222 (* 1 = 4.32222 loss)
I1211 06:53:47.237653 22260 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1211 06:53:53.549170 22260 solver.cpp:218] Iteration 300 (15.8449 iter/s, 6.31119s/100 iters), loss = 4.08646
I1211 06:53:53.549170 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.06
I1211 06:53:53.549170 22260 solver.cpp:237]     Train net output #1: loss = 4.08646 (* 1 = 4.08646 loss)
I1211 06:53:53.549170 22260 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1211 06:53:59.867655 22260 solver.cpp:218] Iteration 400 (15.827 iter/s, 6.31834s/100 iters), loss = 4.05816
I1211 06:53:59.867655 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.05
I1211 06:53:59.867655 22260 solver.cpp:237]     Train net output #1: loss = 4.05816 (* 1 = 4.05816 loss)
I1211 06:53:59.867655 22260 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1211 06:54:05.904207 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:54:06.154220 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_500.caffemodel
I1211 06:54:06.176219 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_500.solverstate
I1211 06:54:06.180220 22260 solver.cpp:330] Iteration 500, Testing net (#0)
I1211 06:54:06.181221 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:54:07.710362 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:54:07.771361 22260 solver.cpp:397]     Test net output #0: accuracy = 0.0537
I1211 06:54:07.771361 22260 solver.cpp:397]     Test net output #1: loss = 4.31852 (* 1 = 4.31852 loss)
I1211 06:54:07.832366 22260 solver.cpp:218] Iteration 500 (12.5565 iter/s, 7.96403s/100 iters), loss = 3.85654
I1211 06:54:07.832366 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1211 06:54:07.832366 22260 solver.cpp:237]     Train net output #1: loss = 3.85654 (* 1 = 3.85654 loss)
I1211 06:54:07.832366 22260 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1211 06:54:14.307968 22260 solver.cpp:218] Iteration 600 (15.4443 iter/s, 6.4749s/100 iters), loss = 3.83139
I1211 06:54:14.307968 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1211 06:54:14.307968 22260 solver.cpp:237]     Train net output #1: loss = 3.83139 (* 1 = 3.83139 loss)
I1211 06:54:14.307968 22260 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1211 06:54:20.840564 22260 solver.cpp:218] Iteration 700 (15.3086 iter/s, 6.53229s/100 iters), loss = 3.59302
I1211 06:54:20.840564 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.15
I1211 06:54:20.840564 22260 solver.cpp:237]     Train net output #1: loss = 3.59302 (* 1 = 3.59302 loss)
I1211 06:54:20.840564 22260 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1211 06:54:27.373720 22260 solver.cpp:218] Iteration 800 (15.3075 iter/s, 6.53274s/100 iters), loss = 3.60249
I1211 06:54:27.373720 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1211 06:54:27.373720 22260 solver.cpp:237]     Train net output #1: loss = 3.60249 (* 1 = 3.60249 loss)
I1211 06:54:27.373720 22260 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1211 06:54:33.903743 22260 solver.cpp:218] Iteration 900 (15.3153 iter/s, 6.5294s/100 iters), loss = 3.67407
I1211 06:54:33.903743 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I1211 06:54:33.903743 22260 solver.cpp:237]     Train net output #1: loss = 3.67407 (* 1 = 3.67407 loss)
I1211 06:54:33.903743 22260 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1211 06:54:40.111560 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:54:40.368588 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1000.caffemodel
I1211 06:54:40.384589 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1000.solverstate
I1211 06:54:40.389590 22260 solver.cpp:330] Iteration 1000, Testing net (#0)
I1211 06:54:40.389590 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:54:41.945726 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:54:42.007738 22260 solver.cpp:397]     Test net output #0: accuracy = 0.0966
I1211 06:54:42.007738 22260 solver.cpp:397]     Test net output #1: loss = 3.93962 (* 1 = 3.93962 loss)
I1211 06:54:42.070729 22260 solver.cpp:218] Iteration 1000 (12.2443 iter/s, 8.16709s/100 iters), loss = 3.45459
I1211 06:54:42.070729 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.17
I1211 06:54:42.070729 22260 solver.cpp:237]     Train net output #1: loss = 3.45459 (* 1 = 3.45459 loss)
I1211 06:54:42.070729 22260 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1211 06:54:48.601502 22260 solver.cpp:218] Iteration 1100 (15.3142 iter/s, 6.5299s/100 iters), loss = 3.42903
I1211 06:54:48.601502 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.09
I1211 06:54:48.601502 22260 solver.cpp:237]     Train net output #1: loss = 3.42903 (* 1 = 3.42903 loss)
I1211 06:54:48.601502 22260 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1211 06:54:55.132050 22260 solver.cpp:218] Iteration 1200 (15.3135 iter/s, 6.53018s/100 iters), loss = 3.15033
I1211 06:54:55.132050 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 06:54:55.132050 22260 solver.cpp:237]     Train net output #1: loss = 3.15033 (* 1 = 3.15033 loss)
I1211 06:54:55.132050 22260 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1211 06:55:01.655613 22260 solver.cpp:218] Iteration 1300 (15.331 iter/s, 6.52273s/100 iters), loss = 3.2332
I1211 06:55:01.655613 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.21
I1211 06:55:01.655613 22260 solver.cpp:237]     Train net output #1: loss = 3.2332 (* 1 = 3.2332 loss)
I1211 06:55:01.655613 22260 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1211 06:55:08.186769 22260 solver.cpp:218] Iteration 1400 (15.3121 iter/s, 6.53077s/100 iters), loss = 3.29116
I1211 06:55:08.186769 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 06:55:08.186769 22260 solver.cpp:237]     Train net output #1: loss = 3.29116 (* 1 = 3.29116 loss)
I1211 06:55:08.186769 22260 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1211 06:55:14.324213 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:55:14.574496 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1500.caffemodel
I1211 06:55:14.590495 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_1500.solverstate
I1211 06:55:14.595494 22260 solver.cpp:330] Iteration 1500, Testing net (#0)
I1211 06:55:14.595494 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:55:16.128479 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:55:16.188480 22260 solver.cpp:397]     Test net output #0: accuracy = 0.0969
I1211 06:55:16.188480 22260 solver.cpp:397]     Test net output #1: loss = 4.01897 (* 1 = 4.01897 loss)
I1211 06:55:16.250097 22260 solver.cpp:218] Iteration 1500 (12.4021 iter/s, 8.06315s/100 iters), loss = 3.00041
I1211 06:55:16.250097 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 06:55:16.250097 22260 solver.cpp:237]     Train net output #1: loss = 3.00041 (* 1 = 3.00041 loss)
I1211 06:55:16.250097 22260 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1211 06:55:22.653242 22260 solver.cpp:218] Iteration 1600 (15.6193 iter/s, 6.40234s/100 iters), loss = 3.03373
I1211 06:55:22.653242 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.2
I1211 06:55:22.653242 22260 solver.cpp:237]     Train net output #1: loss = 3.03373 (* 1 = 3.03373 loss)
I1211 06:55:22.653242 22260 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1211 06:55:29.065232 22260 solver.cpp:218] Iteration 1700 (15.5974 iter/s, 6.41134s/100 iters), loss = 2.72589
I1211 06:55:29.065232 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.31
I1211 06:55:29.065232 22260 solver.cpp:237]     Train net output #1: loss = 2.72589 (* 1 = 2.72589 loss)
I1211 06:55:29.065232 22260 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1211 06:55:35.464210 22260 solver.cpp:218] Iteration 1800 (15.6292 iter/s, 6.39828s/100 iters), loss = 2.89235
I1211 06:55:35.464210 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.3
I1211 06:55:35.464210 22260 solver.cpp:237]     Train net output #1: loss = 2.89235 (* 1 = 2.89235 loss)
I1211 06:55:35.464210 22260 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1211 06:55:41.869000 22260 solver.cpp:218] Iteration 1900 (15.6129 iter/s, 6.40497s/100 iters), loss = 2.86801
I1211 06:55:41.869000 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 06:55:41.869000 22260 solver.cpp:237]     Train net output #1: loss = 2.86801 (* 1 = 2.86801 loss)
I1211 06:55:41.869000 22260 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1211 06:55:47.958478 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:55:48.210489 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2000.caffemodel
I1211 06:55:48.225996 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2000.solverstate
I1211 06:55:48.230495 22260 solver.cpp:330] Iteration 2000, Testing net (#0)
I1211 06:55:48.230495 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:55:49.763773 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:55:49.824775 22260 solver.cpp:397]     Test net output #0: accuracy = 0.182
I1211 06:55:49.824775 22260 solver.cpp:397]     Test net output #1: loss = 3.33174 (* 1 = 3.33174 loss)
I1211 06:55:49.885777 22260 solver.cpp:218] Iteration 2000 (12.4749 iter/s, 8.01611s/100 iters), loss = 2.73586
I1211 06:55:49.885777 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1211 06:55:49.885777 22260 solver.cpp:237]     Train net output #1: loss = 2.73586 (* 1 = 2.73586 loss)
I1211 06:55:49.885777 22260 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1211 06:55:56.262265 22260 solver.cpp:218] Iteration 2100 (15.6844 iter/s, 6.37575s/100 iters), loss = 2.81539
I1211 06:55:56.262265 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 06:55:56.262265 22260 solver.cpp:237]     Train net output #1: loss = 2.81539 (* 1 = 2.81539 loss)
I1211 06:55:56.262265 22260 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1211 06:56:02.599723 22260 solver.cpp:218] Iteration 2200 (15.7798 iter/s, 6.33722s/100 iters), loss = 2.50508
I1211 06:56:02.599723 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 06:56:02.599723 22260 solver.cpp:237]     Train net output #1: loss = 2.50508 (* 1 = 2.50508 loss)
I1211 06:56:02.599723 22260 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1211 06:56:08.936167 22260 solver.cpp:218] Iteration 2300 (15.7834 iter/s, 6.33577s/100 iters), loss = 2.70743
I1211 06:56:08.936167 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.29
I1211 06:56:08.936167 22260 solver.cpp:237]     Train net output #1: loss = 2.70743 (* 1 = 2.70743 loss)
I1211 06:56:08.936167 22260 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1211 06:56:15.278638 22260 solver.cpp:218] Iteration 2400 (15.7667 iter/s, 6.34248s/100 iters), loss = 2.57588
I1211 06:56:15.279639 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 06:56:15.279639 22260 solver.cpp:237]     Train net output #1: loss = 2.57588 (* 1 = 2.57588 loss)
I1211 06:56:15.279639 22260 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1211 06:56:21.303604 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:56:21.552731 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2500.caffemodel
I1211 06:56:21.567733 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_2500.solverstate
I1211 06:56:21.572733 22260 solver.cpp:330] Iteration 2500, Testing net (#0)
I1211 06:56:21.572733 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:56:23.089911 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:56:23.149983 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2196
I1211 06:56:23.149983 22260 solver.cpp:397]     Test net output #1: loss = 3.14229 (* 1 = 3.14229 loss)
I1211 06:56:23.210980 22260 solver.cpp:218] Iteration 2500 (12.608 iter/s, 7.93147s/100 iters), loss = 2.58446
I1211 06:56:23.210980 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.34
I1211 06:56:23.210980 22260 solver.cpp:237]     Train net output #1: loss = 2.58446 (* 1 = 2.58446 loss)
I1211 06:56:23.210980 22260 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1211 06:56:29.549124 22260 solver.cpp:218] Iteration 2600 (15.7796 iter/s, 6.33731s/100 iters), loss = 2.56941
I1211 06:56:29.549124 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1211 06:56:29.549124 22260 solver.cpp:237]     Train net output #1: loss = 2.56941 (* 1 = 2.56941 loss)
I1211 06:56:29.549124 22260 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1211 06:56:35.887385 22260 solver.cpp:218] Iteration 2700 (15.7779 iter/s, 6.33798s/100 iters), loss = 2.28945
I1211 06:56:35.887385 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 06:56:35.887385 22260 solver.cpp:237]     Train net output #1: loss = 2.28945 (* 1 = 2.28945 loss)
I1211 06:56:35.887385 22260 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1211 06:56:42.231274 22260 solver.cpp:218] Iteration 2800 (15.7647 iter/s, 6.34327s/100 iters), loss = 2.48457
I1211 06:56:42.231274 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 06:56:42.231274 22260 solver.cpp:237]     Train net output #1: loss = 2.48457 (* 1 = 2.48457 loss)
I1211 06:56:42.231274 22260 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1211 06:56:48.579752 22260 solver.cpp:218] Iteration 2900 (15.7534 iter/s, 6.34786s/100 iters), loss = 2.53503
I1211 06:56:48.579752 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.27
I1211 06:56:48.579752 22260 solver.cpp:237]     Train net output #1: loss = 2.53503 (* 1 = 2.53503 loss)
I1211 06:56:48.579752 22260 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1211 06:56:54.610203 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:56:54.861212 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3000.caffemodel
I1211 06:56:54.881211 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3000.solverstate
I1211 06:56:54.886212 22260 solver.cpp:330] Iteration 3000, Testing net (#0)
I1211 06:56:54.886212 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:56:56.406327 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:56:56.467329 22260 solver.cpp:397]     Test net output #0: accuracy = 0.211
I1211 06:56:56.467329 22260 solver.cpp:397]     Test net output #1: loss = 3.30754 (* 1 = 3.30754 loss)
I1211 06:56:56.528336 22260 solver.cpp:218] Iteration 3000 (12.5813 iter/s, 7.9483s/100 iters), loss = 2.40363
I1211 06:56:56.528336 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 06:56:56.528336 22260 solver.cpp:237]     Train net output #1: loss = 2.40363 (* 1 = 2.40363 loss)
I1211 06:56:56.528336 22260 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1211 06:57:02.873764 22260 solver.cpp:218] Iteration 3100 (15.7591 iter/s, 6.34552s/100 iters), loss = 2.40755
I1211 06:57:02.873764 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.32
I1211 06:57:02.873764 22260 solver.cpp:237]     Train net output #1: loss = 2.40755 (* 1 = 2.40755 loss)
I1211 06:57:02.873764 22260 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1211 06:57:09.222228 22260 solver.cpp:218] Iteration 3200 (15.7534 iter/s, 6.34782s/100 iters), loss = 2.07136
I1211 06:57:09.222228 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 06:57:09.222228 22260 solver.cpp:237]     Train net output #1: loss = 2.07136 (* 1 = 2.07136 loss)
I1211 06:57:09.222228 22260 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1211 06:57:15.574640 22260 solver.cpp:218] Iteration 3300 (15.7436 iter/s, 6.35178s/100 iters), loss = 2.4449
I1211 06:57:15.574640 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 06:57:15.574640 22260 solver.cpp:237]     Train net output #1: loss = 2.4449 (* 1 = 2.4449 loss)
I1211 06:57:15.574640 22260 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1211 06:57:21.931125 22260 solver.cpp:218] Iteration 3400 (15.732 iter/s, 6.35646s/100 iters), loss = 2.34244
I1211 06:57:21.931125 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 06:57:21.931125 22260 solver.cpp:237]     Train net output #1: loss = 2.34244 (* 1 = 2.34244 loss)
I1211 06:57:21.931125 22260 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1211 06:57:27.968560 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:57:28.218578 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3500.caffemodel
I1211 06:57:28.235579 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_3500.solverstate
I1211 06:57:28.239578 22260 solver.cpp:330] Iteration 3500, Testing net (#0)
I1211 06:57:28.239578 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:57:29.758682 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:57:29.819692 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2489
I1211 06:57:29.819692 22260 solver.cpp:397]     Test net output #1: loss = 3.0272 (* 1 = 3.0272 loss)
I1211 06:57:29.879693 22260 solver.cpp:218] Iteration 3500 (12.5817 iter/s, 7.94807s/100 iters), loss = 2.22517
I1211 06:57:29.879693 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 06:57:29.879693 22260 solver.cpp:237]     Train net output #1: loss = 2.22517 (* 1 = 2.22517 loss)
I1211 06:57:29.879693 22260 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1211 06:57:36.214174 22260 solver.cpp:218] Iteration 3600 (15.7883 iter/s, 6.33381s/100 iters), loss = 2.2761
I1211 06:57:36.214174 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.35
I1211 06:57:36.214174 22260 solver.cpp:237]     Train net output #1: loss = 2.2761 (* 1 = 2.2761 loss)
I1211 06:57:36.214174 22260 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1211 06:57:42.555634 22260 solver.cpp:218] Iteration 3700 (15.7707 iter/s, 6.34089s/100 iters), loss = 1.94355
I1211 06:57:42.555634 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 06:57:42.555634 22260 solver.cpp:237]     Train net output #1: loss = 1.94355 (* 1 = 1.94355 loss)
I1211 06:57:42.555634 22260 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1211 06:57:48.895107 22260 solver.cpp:218] Iteration 3800 (15.7748 iter/s, 6.33922s/100 iters), loss = 2.39208
I1211 06:57:48.895596 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 06:57:48.895596 22260 solver.cpp:237]     Train net output #1: loss = 2.39208 (* 1 = 2.39208 loss)
I1211 06:57:48.895596 22260 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1211 06:57:55.239219 22260 solver.cpp:218] Iteration 3900 (15.7644 iter/s, 6.34341s/100 iters), loss = 2.34332
I1211 06:57:55.239219 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 06:57:55.239219 22260 solver.cpp:237]     Train net output #1: loss = 2.34332 (* 1 = 2.34332 loss)
I1211 06:57:55.239219 22260 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1211 06:58:01.272634 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:58:01.522652 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4000.caffemodel
I1211 06:58:01.537652 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4000.solverstate
I1211 06:58:01.542652 22260 solver.cpp:330] Iteration 4000, Testing net (#0)
I1211 06:58:01.542652 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:58:03.061818 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:58:03.121824 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3156
I1211 06:58:03.121824 22260 solver.cpp:397]     Test net output #1: loss = 2.67755 (* 1 = 2.67755 loss)
I1211 06:58:03.181828 22260 solver.cpp:218] Iteration 4000 (12.5902 iter/s, 7.94266s/100 iters), loss = 2.32206
I1211 06:58:03.181828 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 06:58:03.181828 22260 solver.cpp:237]     Train net output #1: loss = 2.32206 (* 1 = 2.32206 loss)
I1211 06:58:03.181828 22260 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1211 06:58:09.530328 22260 solver.cpp:218] Iteration 4100 (15.7545 iter/s, 6.34741s/100 iters), loss = 2.18763
I1211 06:58:09.530328 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.33
I1211 06:58:09.530328 22260 solver.cpp:237]     Train net output #1: loss = 2.18763 (* 1 = 2.18763 loss)
I1211 06:58:09.530328 22260 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1211 06:58:15.869792 22260 solver.cpp:218] Iteration 4200 (15.7741 iter/s, 6.33949s/100 iters), loss = 1.93442
I1211 06:58:15.869792 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 06:58:15.869792 22260 solver.cpp:237]     Train net output #1: loss = 1.93442 (* 1 = 1.93442 loss)
I1211 06:58:15.869792 22260 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1211 06:58:22.209272 22260 solver.cpp:218] Iteration 4300 (15.7764 iter/s, 6.3386s/100 iters), loss = 2.15611
I1211 06:58:22.209272 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 06:58:22.209272 22260 solver.cpp:237]     Train net output #1: loss = 2.15611 (* 1 = 2.15611 loss)
I1211 06:58:22.209272 22260 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1211 06:58:28.546792 22260 solver.cpp:218] Iteration 4400 (15.7792 iter/s, 6.33746s/100 iters), loss = 2.31403
I1211 06:58:28.546792 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 06:58:28.546792 22260 solver.cpp:237]     Train net output #1: loss = 2.31403 (* 1 = 2.31403 loss)
I1211 06:58:28.546792 22260 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1211 06:58:34.575201 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:58:34.825217 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4500.caffemodel
I1211 06:58:34.841226 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_4500.solverstate
I1211 06:58:34.846218 22260 solver.cpp:330] Iteration 4500, Testing net (#0)
I1211 06:58:34.846218 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:58:36.363337 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:58:36.424345 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2867
I1211 06:58:36.424345 22260 solver.cpp:397]     Test net output #1: loss = 2.87269 (* 1 = 2.87269 loss)
I1211 06:58:36.485347 22260 solver.cpp:218] Iteration 4500 (12.5974 iter/s, 7.93814s/100 iters), loss = 2.19863
I1211 06:58:36.485846 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 06:58:36.485846 22260 solver.cpp:237]     Train net output #1: loss = 2.19863 (* 1 = 2.19863 loss)
I1211 06:58:36.485846 22260 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1211 06:58:42.823789 22260 solver.cpp:218] Iteration 4600 (15.7778 iter/s, 6.33804s/100 iters), loss = 2.17593
I1211 06:58:42.823789 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.37
I1211 06:58:42.823789 22260 solver.cpp:237]     Train net output #1: loss = 2.17593 (* 1 = 2.17593 loss)
I1211 06:58:42.823789 22260 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1211 06:58:49.162168 22260 solver.cpp:218] Iteration 4700 (15.7789 iter/s, 6.33757s/100 iters), loss = 1.95003
I1211 06:58:49.162168 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 06:58:49.162168 22260 solver.cpp:237]     Train net output #1: loss = 1.95003 (* 1 = 1.95003 loss)
I1211 06:58:49.162168 22260 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1211 06:58:55.499635 22260 solver.cpp:218] Iteration 4800 (15.7802 iter/s, 6.33704s/100 iters), loss = 2.22139
I1211 06:58:55.499635 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 06:58:55.499635 22260 solver.cpp:237]     Train net output #1: loss = 2.22139 (* 1 = 2.22139 loss)
I1211 06:58:55.499635 22260 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1211 06:59:01.836117 22260 solver.cpp:218] Iteration 4900 (15.7807 iter/s, 6.33684s/100 iters), loss = 2.14555
I1211 06:59:01.836117 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 06:59:01.836117 22260 solver.cpp:237]     Train net output #1: loss = 2.14555 (* 1 = 2.14555 loss)
I1211 06:59:01.836117 22260 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1211 06:59:07.857558 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:59:08.107573 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5000.caffemodel
I1211 06:59:08.122573 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5000.solverstate
I1211 06:59:08.126574 22260 solver.cpp:330] Iteration 5000, Testing net (#0)
I1211 06:59:08.126574 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:59:09.652704 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:59:09.712709 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2358
I1211 06:59:09.712709 22260 solver.cpp:397]     Test net output #1: loss = 3.37225 (* 1 = 3.37225 loss)
I1211 06:59:09.773708 22260 solver.cpp:218] Iteration 5000 (12.5997 iter/s, 7.93671s/100 iters), loss = 2.15722
I1211 06:59:09.773708 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 06:59:09.773708 22260 solver.cpp:237]     Train net output #1: loss = 2.15722 (* 1 = 2.15722 loss)
I1211 06:59:09.773708 22260 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1211 06:59:16.117120 22260 solver.cpp:218] Iteration 5100 (15.7652 iter/s, 6.34308s/100 iters), loss = 2.00566
I1211 06:59:16.117120 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.36
I1211 06:59:16.117120 22260 solver.cpp:237]     Train net output #1: loss = 2.00566 (* 1 = 2.00566 loss)
I1211 06:59:16.117120 22260 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1211 06:59:22.452580 22260 solver.cpp:218] Iteration 5200 (15.7856 iter/s, 6.33489s/100 iters), loss = 1.7653
I1211 06:59:22.452580 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 06:59:22.452580 22260 solver.cpp:237]     Train net output #1: loss = 1.7653 (* 1 = 1.7653 loss)
I1211 06:59:22.452580 22260 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1211 06:59:28.793043 22260 solver.cpp:218] Iteration 5300 (15.773 iter/s, 6.33995s/100 iters), loss = 2.17369
I1211 06:59:28.793043 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 06:59:28.793043 22260 solver.cpp:237]     Train net output #1: loss = 2.17369 (* 1 = 2.17369 loss)
I1211 06:59:28.793043 22260 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1211 06:59:35.130498 22260 solver.cpp:218] Iteration 5400 (15.7795 iter/s, 6.33732s/100 iters), loss = 2.19438
I1211 06:59:35.130498 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 06:59:35.130498 22260 solver.cpp:237]     Train net output #1: loss = 2.19438 (* 1 = 2.19438 loss)
I1211 06:59:35.130498 22260 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1211 06:59:41.160105 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:59:41.410120 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5500.caffemodel
I1211 06:59:41.425120 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_5500.solverstate
I1211 06:59:41.429121 22260 solver.cpp:330] Iteration 5500, Testing net (#0)
I1211 06:59:41.429121 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 06:59:42.949223 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 06:59:43.010038 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2366
I1211 06:59:43.010038 22260 solver.cpp:397]     Test net output #1: loss = 3.39044 (* 1 = 3.39044 loss)
I1211 06:59:43.072021 22260 solver.cpp:218] Iteration 5500 (12.5927 iter/s, 7.9411s/100 iters), loss = 2.22756
I1211 06:59:43.072021 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 06:59:43.072021 22260 solver.cpp:237]     Train net output #1: loss = 2.22756 (* 1 = 2.22756 loss)
I1211 06:59:43.072021 22260 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1211 06:59:49.418436 22260 solver.cpp:218] Iteration 5600 (15.7578 iter/s, 6.34606s/100 iters), loss = 1.98735
I1211 06:59:49.418436 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 06:59:49.418436 22260 solver.cpp:237]     Train net output #1: loss = 1.98735 (* 1 = 1.98735 loss)
I1211 06:59:49.418436 22260 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1211 06:59:55.774165 22260 solver.cpp:218] Iteration 5700 (15.7353 iter/s, 6.35514s/100 iters), loss = 1.74195
I1211 06:59:55.774165 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 06:59:55.774165 22260 solver.cpp:237]     Train net output #1: loss = 1.74195 (* 1 = 1.74195 loss)
I1211 06:59:55.774165 22260 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1211 07:00:02.143383 22260 solver.cpp:218] Iteration 5800 (15.7027 iter/s, 6.36831s/100 iters), loss = 2.12384
I1211 07:00:02.143882 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:00:02.143882 22260 solver.cpp:237]     Train net output #1: loss = 2.12384 (* 1 = 2.12384 loss)
I1211 07:00:02.143882 22260 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1211 07:00:08.498122 22260 solver.cpp:218] Iteration 5900 (15.7364 iter/s, 6.35468s/100 iters), loss = 2.10314
I1211 07:00:08.498122 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.38
I1211 07:00:08.498122 22260 solver.cpp:237]     Train net output #1: loss = 2.10314 (* 1 = 2.10314 loss)
I1211 07:00:08.498122 22260 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1211 07:00:11.366318 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:00:11.616343 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6000.caffemodel
I1211 07:00:11.631847 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6000.solverstate
I1211 07:00:11.636848 22260 solver.cpp:330] Iteration 6000, Testing net (#0)
I1211 07:00:11.636848 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:00:13.159474 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:00:13.220474 22260 solver.cpp:397]     Test net output #0: accuracy = 0.1059
I1211 07:00:13.220474 22260 solver.cpp:397]     Test net output #1: loss = 6.3615 (* 1 = 6.3615 loss)
I1211 07:00:13.281497 22260 solver.cpp:218] Iteration 6000 (12.5604 iter/s, 7.96152s/100 iters), loss = 2.24218
I1211 07:00:13.281497 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.39
I1211 07:00:13.281497 22260 solver.cpp:237]     Train net output #1: loss = 2.24218 (* 1 = 2.24218 loss)
I1211 07:00:13.281497 22260 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1211 07:00:19.641285 22260 solver.cpp:218] Iteration 6100 (15.7251 iter/s, 6.35924s/100 iters), loss = 1.89846
I1211 07:00:19.641285 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 07:00:19.641285 22260 solver.cpp:237]     Train net output #1: loss = 1.89846 (* 1 = 1.89846 loss)
I1211 07:00:19.641285 22260 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1211 07:00:26.002084 22260 solver.cpp:218] Iteration 6200 (15.723 iter/s, 6.3601s/100 iters), loss = 1.6534
I1211 07:00:26.002084 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:00:26.002084 22260 solver.cpp:237]     Train net output #1: loss = 1.6534 (* 1 = 1.6534 loss)
I1211 07:00:26.002084 22260 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1211 07:00:32.357306 22260 solver.cpp:218] Iteration 6300 (15.736 iter/s, 6.35485s/100 iters), loss = 2.14707
I1211 07:00:32.357306 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 07:00:32.357306 22260 solver.cpp:237]     Train net output #1: loss = 2.14707 (* 1 = 2.14707 loss)
I1211 07:00:32.357306 22260 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1211 07:00:38.706698 22260 solver.cpp:218] Iteration 6400 (15.7492 iter/s, 6.34952s/100 iters), loss = 2.2925
I1211 07:00:38.706698 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 07:00:38.706698 22260 solver.cpp:237]     Train net output #1: loss = 2.2925 (* 1 = 2.2925 loss)
I1211 07:00:38.706698 22260 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1211 07:00:44.751339 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:00:45.001384 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6500.caffemodel
I1211 07:00:45.018383 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_6500.solverstate
I1211 07:00:45.024385 22260 solver.cpp:330] Iteration 6500, Testing net (#0)
I1211 07:00:45.024385 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:00:46.548507 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:00:46.610520 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2808
I1211 07:00:46.610520 22260 solver.cpp:397]     Test net output #1: loss = 3.0137 (* 1 = 3.0137 loss)
I1211 07:00:46.672022 22260 solver.cpp:218] Iteration 6500 (12.5564 iter/s, 7.96408s/100 iters), loss = 2.16163
I1211 07:00:46.672022 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 07:00:46.672022 22260 solver.cpp:237]     Train net output #1: loss = 2.16163 (* 1 = 2.16163 loss)
I1211 07:00:46.672022 22260 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1211 07:00:53.026562 22260 solver.cpp:218] Iteration 6600 (15.7382 iter/s, 6.35395s/100 iters), loss = 1.83635
I1211 07:00:53.026562 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 07:00:53.026562 22260 solver.cpp:237]     Train net output #1: loss = 1.83635 (* 1 = 1.83635 loss)
I1211 07:00:53.026562 22260 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1211 07:00:59.377252 22260 solver.cpp:218] Iteration 6700 (15.7467 iter/s, 6.35054s/100 iters), loss = 1.61527
I1211 07:00:59.377252 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:00:59.377252 22260 solver.cpp:237]     Train net output #1: loss = 1.61527 (* 1 = 1.61527 loss)
I1211 07:00:59.377252 22260 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1211 07:01:05.729696 22260 solver.cpp:218] Iteration 6800 (15.7439 iter/s, 6.35166s/100 iters), loss = 2.08586
I1211 07:01:05.729696 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:01:05.729696 22260 solver.cpp:237]     Train net output #1: loss = 2.08586 (* 1 = 2.08586 loss)
I1211 07:01:05.729696 22260 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1211 07:01:12.079797 22260 solver.cpp:218] Iteration 6900 (15.7463 iter/s, 6.3507s/100 iters), loss = 2.13759
I1211 07:01:12.081003 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:01:12.081003 22260 solver.cpp:237]     Train net output #1: loss = 2.13759 (* 1 = 2.13759 loss)
I1211 07:01:12.081003 22260 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1211 07:01:18.119011 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:01:18.371542 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7000.caffemodel
I1211 07:01:18.386096 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7000.solverstate
I1211 07:01:18.391094 22260 solver.cpp:330] Iteration 7000, Testing net (#0)
I1211 07:01:18.391094 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:01:19.913142 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:01:19.974663 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2887
I1211 07:01:19.974663 22260 solver.cpp:397]     Test net output #1: loss = 2.9225 (* 1 = 2.9225 loss)
I1211 07:01:20.035697 22260 solver.cpp:218] Iteration 7000 (12.5719 iter/s, 7.95426s/100 iters), loss = 2.12338
I1211 07:01:20.035697 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:01:20.035697 22260 solver.cpp:237]     Train net output #1: loss = 2.12338 (* 1 = 2.12338 loss)
I1211 07:01:20.035697 22260 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1211 07:01:26.406289 22260 solver.cpp:218] Iteration 7100 (15.6983 iter/s, 6.3701s/100 iters), loss = 1.98713
I1211 07:01:26.406289 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 07:01:26.406289 22260 solver.cpp:237]     Train net output #1: loss = 1.98713 (* 1 = 1.98713 loss)
I1211 07:01:26.406289 22260 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1211 07:01:32.759037 22260 solver.cpp:218] Iteration 7200 (15.7421 iter/s, 6.35239s/100 iters), loss = 1.50407
I1211 07:01:32.759037 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:01:32.759037 22260 solver.cpp:237]     Train net output #1: loss = 1.50407 (* 1 = 1.50407 loss)
I1211 07:01:32.759037 22260 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1211 07:01:39.119570 22260 solver.cpp:218] Iteration 7300 (15.7229 iter/s, 6.36017s/100 iters), loss = 1.9241
I1211 07:01:39.119570 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:01:39.119570 22260 solver.cpp:237]     Train net output #1: loss = 1.9241 (* 1 = 1.9241 loss)
I1211 07:01:39.119570 22260 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1211 07:01:45.485122 22260 solver.cpp:218] Iteration 7400 (15.7092 iter/s, 6.36568s/100 iters), loss = 2.00045
I1211 07:01:45.486119 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:01:45.486119 22260 solver.cpp:237]     Train net output #1: loss = 2.00045 (* 1 = 2.00045 loss)
I1211 07:01:45.486119 22260 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1211 07:01:51.526679 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:01:51.775708 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7500.caffemodel
I1211 07:01:51.791708 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_7500.solverstate
I1211 07:01:51.796708 22260 solver.cpp:330] Iteration 7500, Testing net (#0)
I1211 07:01:51.796708 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:01:53.319840 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:01:53.380852 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2788
I1211 07:01:53.380852 22260 solver.cpp:397]     Test net output #1: loss = 3.03541 (* 1 = 3.03541 loss)
I1211 07:01:53.441355 22260 solver.cpp:218] Iteration 7500 (12.5706 iter/s, 7.95505s/100 iters), loss = 1.9909
I1211 07:01:53.441355 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:01:53.441355 22260 solver.cpp:237]     Train net output #1: loss = 1.9909 (* 1 = 1.9909 loss)
I1211 07:01:53.441355 22260 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1211 07:01:59.804319 22260 solver.cpp:218] Iteration 7600 (15.7174 iter/s, 6.36237s/100 iters), loss = 1.90306
I1211 07:01:59.804319 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 07:01:59.804319 22260 solver.cpp:237]     Train net output #1: loss = 1.90306 (* 1 = 1.90306 loss)
I1211 07:01:59.804319 22260 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1211 07:02:06.173179 22260 solver.cpp:218] Iteration 7700 (15.7006 iter/s, 6.36919s/100 iters), loss = 1.58792
I1211 07:02:06.173179 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:02:06.173179 22260 solver.cpp:237]     Train net output #1: loss = 1.58792 (* 1 = 1.58792 loss)
I1211 07:02:06.173179 22260 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1211 07:02:12.543763 22260 solver.cpp:218] Iteration 7800 (15.6996 iter/s, 6.36958s/100 iters), loss = 1.94174
I1211 07:02:12.543763 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:02:12.543763 22260 solver.cpp:237]     Train net output #1: loss = 1.94174 (* 1 = 1.94174 loss)
I1211 07:02:12.543763 22260 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1211 07:02:18.901383 22260 solver.cpp:218] Iteration 7900 (15.731 iter/s, 6.35689s/100 iters), loss = 2.03209
I1211 07:02:18.901383 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:02:18.901383 22260 solver.cpp:237]     Train net output #1: loss = 2.03209 (* 1 = 2.03209 loss)
I1211 07:02:18.901383 22260 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1211 07:02:24.943303 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:02:25.194327 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8000.caffemodel
I1211 07:02:25.215344 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8000.solverstate
I1211 07:02:25.220327 22260 solver.cpp:330] Iteration 8000, Testing net (#0)
I1211 07:02:25.220327 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:02:26.743994 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:02:26.805510 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2675
I1211 07:02:26.805510 22260 solver.cpp:397]     Test net output #1: loss = 3.40025 (* 1 = 3.40025 loss)
I1211 07:02:26.867511 22260 solver.cpp:218] Iteration 8000 (12.5538 iter/s, 7.96574s/100 iters), loss = 2.05561
I1211 07:02:26.867511 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:02:26.867511 22260 solver.cpp:237]     Train net output #1: loss = 2.05561 (* 1 = 2.05561 loss)
I1211 07:02:26.867511 22260 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1211 07:02:33.211828 22260 solver.cpp:218] Iteration 8100 (15.7621 iter/s, 6.34434s/100 iters), loss = 1.9176
I1211 07:02:33.211828 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:02:33.211828 22260 solver.cpp:237]     Train net output #1: loss = 1.9176 (* 1 = 1.9176 loss)
I1211 07:02:33.211828 22260 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1211 07:02:39.534351 22260 solver.cpp:218] Iteration 8200 (15.8189 iter/s, 6.32155s/100 iters), loss = 1.68363
I1211 07:02:39.534351 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:02:39.534351 22260 solver.cpp:237]     Train net output #1: loss = 1.68363 (* 1 = 1.68363 loss)
I1211 07:02:39.534351 22260 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1211 07:02:45.871194 22260 solver.cpp:218] Iteration 8300 (15.7814 iter/s, 6.33657s/100 iters), loss = 2.11466
I1211 07:02:45.871194 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:02:45.871194 22260 solver.cpp:237]     Train net output #1: loss = 2.11466 (* 1 = 2.11466 loss)
I1211 07:02:45.871194 22260 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1211 07:02:52.198865 22260 solver.cpp:218] Iteration 8400 (15.8051 iter/s, 6.32705s/100 iters), loss = 2.08923
I1211 07:02:52.198865 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:02:52.198865 22260 solver.cpp:237]     Train net output #1: loss = 2.08923 (* 1 = 2.08923 loss)
I1211 07:02:52.198865 22260 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1211 07:02:58.229887 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:02:58.480540 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8500.caffemodel
I1211 07:02:58.496048 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_8500.solverstate
I1211 07:02:58.501049 22260 solver.cpp:330] Iteration 8500, Testing net (#0)
I1211 07:02:58.501049 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:03:00.028295 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:03:00.088294 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3517
I1211 07:03:00.088294 22260 solver.cpp:397]     Test net output #1: loss = 2.56446 (* 1 = 2.56446 loss)
I1211 07:03:00.148304 22260 solver.cpp:218] Iteration 8500 (12.5797 iter/s, 7.94932s/100 iters), loss = 1.86359
I1211 07:03:00.148304 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:03:00.148304 22260 solver.cpp:237]     Train net output #1: loss = 1.86359 (* 1 = 1.86359 loss)
I1211 07:03:00.148304 22260 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1211 07:03:06.479429 22260 solver.cpp:218] Iteration 8600 (15.7975 iter/s, 6.33013s/100 iters), loss = 1.78055
I1211 07:03:06.479429 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:03:06.479429 22260 solver.cpp:237]     Train net output #1: loss = 1.78055 (* 1 = 1.78055 loss)
I1211 07:03:06.479429 22260 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1211 07:03:12.831859 22260 solver.cpp:218] Iteration 8700 (15.7427 iter/s, 6.35213s/100 iters), loss = 1.60611
I1211 07:03:12.831859 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:03:12.831859 22260 solver.cpp:237]     Train net output #1: loss = 1.60611 (* 1 = 1.60611 loss)
I1211 07:03:12.831859 22260 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1211 07:03:19.183694 22260 solver.cpp:218] Iteration 8800 (15.745 iter/s, 6.35122s/100 iters), loss = 1.99596
I1211 07:03:19.183694 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:03:19.183694 22260 solver.cpp:237]     Train net output #1: loss = 1.99596 (* 1 = 1.99596 loss)
I1211 07:03:19.183694 22260 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1211 07:03:25.545222 22260 solver.cpp:218] Iteration 8900 (15.7204 iter/s, 6.36116s/100 iters), loss = 2.07169
I1211 07:03:25.545222 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:03:25.545222 22260 solver.cpp:237]     Train net output #1: loss = 2.07169 (* 1 = 2.07169 loss)
I1211 07:03:25.545222 22260 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1211 07:03:31.582880 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:03:31.834906 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9000.caffemodel
I1211 07:03:31.849906 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9000.solverstate
I1211 07:03:31.854907 22260 solver.cpp:330] Iteration 9000, Testing net (#0)
I1211 07:03:31.854907 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:03:33.373020 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:03:33.433027 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2611
I1211 07:03:33.433027 22260 solver.cpp:397]     Test net output #1: loss = 3.23955 (* 1 = 3.23955 loss)
I1211 07:03:33.493026 22260 solver.cpp:218] Iteration 9000 (12.5825 iter/s, 7.94755s/100 iters), loss = 1.95241
I1211 07:03:33.493026 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:03:33.493026 22260 solver.cpp:237]     Train net output #1: loss = 1.95241 (* 1 = 1.95241 loss)
I1211 07:03:33.493026 22260 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1211 07:03:39.841455 22260 solver.cpp:218] Iteration 9100 (15.7535 iter/s, 6.34779s/100 iters), loss = 1.75098
I1211 07:03:39.841455 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:03:39.841455 22260 solver.cpp:237]     Train net output #1: loss = 1.75098 (* 1 = 1.75098 loss)
I1211 07:03:39.841455 22260 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1211 07:03:46.198957 22260 solver.cpp:218] Iteration 9200 (15.7301 iter/s, 6.35722s/100 iters), loss = 1.53287
I1211 07:03:46.198957 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:03:46.198957 22260 solver.cpp:237]     Train net output #1: loss = 1.53287 (* 1 = 1.53287 loss)
I1211 07:03:46.198957 22260 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1211 07:03:52.550429 22260 solver.cpp:218] Iteration 9300 (15.7451 iter/s, 6.35117s/100 iters), loss = 1.83673
I1211 07:03:52.550429 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:03:52.550429 22260 solver.cpp:237]     Train net output #1: loss = 1.83673 (* 1 = 1.83673 loss)
I1211 07:03:52.550429 22260 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1211 07:03:58.899965 22260 solver.cpp:218] Iteration 9400 (15.7504 iter/s, 6.34903s/100 iters), loss = 1.92666
I1211 07:03:58.899965 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:03:58.899965 22260 solver.cpp:237]     Train net output #1: loss = 1.92666 (* 1 = 1.92666 loss)
I1211 07:03:58.899965 22260 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1211 07:04:04.943397 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:04:05.193421 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9500.caffemodel
I1211 07:04:05.209421 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_9500.solverstate
I1211 07:04:05.213421 22260 solver.cpp:330] Iteration 9500, Testing net (#0)
I1211 07:04:05.213421 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:04:06.731518 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:04:06.792529 22260 solver.cpp:397]     Test net output #0: accuracy = 0.156
I1211 07:04:06.792529 22260 solver.cpp:397]     Test net output #1: loss = 5.14332 (* 1 = 5.14332 loss)
I1211 07:04:06.853528 22260 solver.cpp:218] Iteration 9500 (12.5738 iter/s, 7.95305s/100 iters), loss = 1.80486
I1211 07:04:06.853528 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:04:06.853528 22260 solver.cpp:237]     Train net output #1: loss = 1.80486 (* 1 = 1.80486 loss)
I1211 07:04:06.853528 22260 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1211 07:04:13.204964 22260 solver.cpp:218] Iteration 9600 (15.7461 iter/s, 6.35079s/100 iters), loss = 1.70788
I1211 07:04:13.204964 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:04:13.204964 22260 solver.cpp:237]     Train net output #1: loss = 1.70788 (* 1 = 1.70788 loss)
I1211 07:04:13.204964 22260 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1211 07:04:19.559366 22260 solver.cpp:218] Iteration 9700 (15.7385 iter/s, 6.35383s/100 iters), loss = 1.42632
I1211 07:04:19.559366 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:04:19.559366 22260 solver.cpp:237]     Train net output #1: loss = 1.42632 (* 1 = 1.42632 loss)
I1211 07:04:19.559366 22260 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1211 07:04:25.903846 22260 solver.cpp:218] Iteration 9800 (15.7618 iter/s, 6.34447s/100 iters), loss = 1.81892
I1211 07:04:25.903846 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:04:25.903846 22260 solver.cpp:237]     Train net output #1: loss = 1.81892 (* 1 = 1.81892 loss)
I1211 07:04:25.903846 22260 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1211 07:04:32.264345 22260 solver.cpp:218] Iteration 9900 (15.7243 iter/s, 6.35957s/100 iters), loss = 2.03463
I1211 07:04:32.264345 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:04:32.264345 22260 solver.cpp:237]     Train net output #1: loss = 2.03463 (* 1 = 2.03463 loss)
I1211 07:04:32.264345 22260 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1211 07:04:38.296772 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:04:38.546787 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10000.caffemodel
I1211 07:04:38.561786 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10000.solverstate
I1211 07:04:38.566792 22260 solver.cpp:330] Iteration 10000, Testing net (#0)
I1211 07:04:38.566792 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:04:40.084933 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:04:40.144938 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2341
I1211 07:04:40.144938 22260 solver.cpp:397]     Test net output #1: loss = 3.57235 (* 1 = 3.57235 loss)
I1211 07:04:40.205938 22260 solver.cpp:218] Iteration 10000 (12.5918 iter/s, 7.94168s/100 iters), loss = 1.92847
I1211 07:04:40.205938 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:04:40.205938 22260 solver.cpp:237]     Train net output #1: loss = 1.92847 (* 1 = 1.92847 loss)
I1211 07:04:40.205938 22260 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1211 07:04:46.546496 22260 solver.cpp:218] Iteration 10100 (15.7736 iter/s, 6.33969s/100 iters), loss = 1.85227
I1211 07:04:46.546496 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:04:46.546496 22260 solver.cpp:237]     Train net output #1: loss = 1.85227 (* 1 = 1.85227 loss)
I1211 07:04:46.546496 22260 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1211 07:04:52.892024 22260 solver.cpp:218] Iteration 10200 (15.7595 iter/s, 6.3454s/100 iters), loss = 1.48832
I1211 07:04:52.892024 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 07:04:52.892024 22260 solver.cpp:237]     Train net output #1: loss = 1.48832 (* 1 = 1.48832 loss)
I1211 07:04:52.892024 22260 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1211 07:04:59.244614 22260 solver.cpp:218] Iteration 10300 (15.7424 iter/s, 6.35227s/100 iters), loss = 1.94379
I1211 07:04:59.244614 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:04:59.244614 22260 solver.cpp:237]     Train net output #1: loss = 1.94379 (* 1 = 1.94379 loss)
I1211 07:04:59.244614 22260 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1211 07:05:05.591101 22260 solver.cpp:218] Iteration 10400 (15.7579 iter/s, 6.34601s/100 iters), loss = 2.15641
I1211 07:05:05.591101 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:05:05.591101 22260 solver.cpp:237]     Train net output #1: loss = 2.15641 (* 1 = 2.15641 loss)
I1211 07:05:05.591101 22260 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1211 07:05:11.639588 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:05:11.889607 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10500.caffemodel
I1211 07:05:11.905607 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_10500.solverstate
I1211 07:05:11.909607 22260 solver.cpp:330] Iteration 10500, Testing net (#0)
I1211 07:05:11.909607 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:05:13.426717 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:05:13.487722 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2665
I1211 07:05:13.487722 22260 solver.cpp:397]     Test net output #1: loss = 3.29785 (* 1 = 3.29785 loss)
I1211 07:05:13.548720 22260 solver.cpp:218] Iteration 10500 (12.5677 iter/s, 7.95689s/100 iters), loss = 1.91215
I1211 07:05:13.548720 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:05:13.548720 22260 solver.cpp:237]     Train net output #1: loss = 1.91215 (* 1 = 1.91215 loss)
I1211 07:05:13.548720 22260 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1211 07:05:19.905225 22260 solver.cpp:218] Iteration 10600 (15.734 iter/s, 6.35565s/100 iters), loss = 1.80495
I1211 07:05:19.905225 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:05:19.905225 22260 solver.cpp:237]     Train net output #1: loss = 1.80495 (* 1 = 1.80495 loss)
I1211 07:05:19.905225 22260 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1211 07:05:26.256753 22260 solver.cpp:218] Iteration 10700 (15.7436 iter/s, 6.35179s/100 iters), loss = 1.54686
I1211 07:05:26.256753 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:05:26.256753 22260 solver.cpp:237]     Train net output #1: loss = 1.54686 (* 1 = 1.54686 loss)
I1211 07:05:26.256753 22260 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1211 07:05:32.608217 22260 solver.cpp:218] Iteration 10800 (15.7449 iter/s, 6.35126s/100 iters), loss = 1.79341
I1211 07:05:32.609218 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:05:32.609218 22260 solver.cpp:237]     Train net output #1: loss = 1.79341 (* 1 = 1.79341 loss)
I1211 07:05:32.609218 22260 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1211 07:05:38.962692 22260 solver.cpp:218] Iteration 10900 (15.7401 iter/s, 6.35321s/100 iters), loss = 1.94044
I1211 07:05:38.962692 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:05:38.962692 22260 solver.cpp:237]     Train net output #1: loss = 1.94044 (* 1 = 1.94044 loss)
I1211 07:05:38.962692 22260 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1211 07:05:44.999192 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:05:45.250203 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11000.caffemodel
I1211 07:05:45.267204 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11000.solverstate
I1211 07:05:45.272209 22260 solver.cpp:330] Iteration 11000, Testing net (#0)
I1211 07:05:45.272209 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:05:46.789309 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:05:46.849308 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2971
I1211 07:05:46.849308 22260 solver.cpp:397]     Test net output #1: loss = 2.89668 (* 1 = 2.89668 loss)
I1211 07:05:46.910315 22260 solver.cpp:218] Iteration 11000 (12.5827 iter/s, 7.94739s/100 iters), loss = 1.98879
I1211 07:05:46.910315 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:05:46.910315 22260 solver.cpp:237]     Train net output #1: loss = 1.98879 (* 1 = 1.98879 loss)
I1211 07:05:46.910315 22260 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1211 07:05:53.255821 22260 solver.cpp:218] Iteration 11100 (15.7591 iter/s, 6.34553s/100 iters), loss = 1.76099
I1211 07:05:53.255821 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:05:53.255821 22260 solver.cpp:237]     Train net output #1: loss = 1.76099 (* 1 = 1.76099 loss)
I1211 07:05:53.255821 22260 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1211 07:05:59.599334 22260 solver.cpp:218] Iteration 11200 (15.7652 iter/s, 6.34307s/100 iters), loss = 1.65501
I1211 07:05:59.599334 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:05:59.599334 22260 solver.cpp:237]     Train net output #1: loss = 1.65501 (* 1 = 1.65501 loss)
I1211 07:05:59.599334 22260 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1211 07:06:05.946827 22260 solver.cpp:218] Iteration 11300 (15.7559 iter/s, 6.34682s/100 iters), loss = 1.99874
I1211 07:06:05.946827 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:06:05.946827 22260 solver.cpp:237]     Train net output #1: loss = 1.99874 (* 1 = 1.99874 loss)
I1211 07:06:05.946827 22260 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1211 07:06:12.287322 22260 solver.cpp:218] Iteration 11400 (15.7733 iter/s, 6.33983s/100 iters), loss = 1.97039
I1211 07:06:12.287322 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:06:12.287322 22260 solver.cpp:237]     Train net output #1: loss = 1.97039 (* 1 = 1.97039 loss)
I1211 07:06:12.287322 22260 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1211 07:06:18.313786 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:06:18.563797 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11500.caffemodel
I1211 07:06:18.578800 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_11500.solverstate
I1211 07:06:18.583299 22260 solver.cpp:330] Iteration 11500, Testing net (#0)
I1211 07:06:18.583801 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:06:20.101893 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:06:20.161895 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3059
I1211 07:06:20.161895 22260 solver.cpp:397]     Test net output #1: loss = 3.01602 (* 1 = 3.01602 loss)
I1211 07:06:20.221897 22260 solver.cpp:218] Iteration 11500 (12.6028 iter/s, 7.93476s/100 iters), loss = 1.98593
I1211 07:06:20.222898 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:06:20.222898 22260 solver.cpp:237]     Train net output #1: loss = 1.98593 (* 1 = 1.98593 loss)
I1211 07:06:20.222898 22260 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1211 07:06:26.565371 22260 solver.cpp:218] Iteration 11600 (15.7666 iter/s, 6.34253s/100 iters), loss = 1.7387
I1211 07:06:26.565371 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:06:26.565371 22260 solver.cpp:237]     Train net output #1: loss = 1.7387 (* 1 = 1.7387 loss)
I1211 07:06:26.565371 22260 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1211 07:06:32.909842 22260 solver.cpp:218] Iteration 11700 (15.7635 iter/s, 6.34377s/100 iters), loss = 1.56617
I1211 07:06:32.909842 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:06:32.909842 22260 solver.cpp:237]     Train net output #1: loss = 1.56617 (* 1 = 1.56617 loss)
I1211 07:06:32.909842 22260 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1211 07:06:39.248201 22260 solver.cpp:218] Iteration 11800 (15.7786 iter/s, 6.33768s/100 iters), loss = 1.89775
I1211 07:06:39.248201 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:06:39.248201 22260 solver.cpp:237]     Train net output #1: loss = 1.89775 (* 1 = 1.89775 loss)
I1211 07:06:39.248201 22260 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1211 07:06:45.592664 22260 solver.cpp:218] Iteration 11900 (15.7607 iter/s, 6.34491s/100 iters), loss = 1.92344
I1211 07:06:45.592664 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:06:45.592664 22260 solver.cpp:237]     Train net output #1: loss = 1.92344 (* 1 = 1.92344 loss)
I1211 07:06:45.593664 22260 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1211 07:06:51.619108 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:06:51.868127 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12000.caffemodel
I1211 07:06:51.885128 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12000.solverstate
I1211 07:06:51.889629 22260 solver.cpp:330] Iteration 12000, Testing net (#0)
I1211 07:06:51.890128 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:06:53.407253 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:06:53.468252 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2842
I1211 07:06:53.468252 22260 solver.cpp:397]     Test net output #1: loss = 3.03312 (* 1 = 3.03312 loss)
I1211 07:06:53.529258 22260 solver.cpp:218] Iteration 12000 (12.6015 iter/s, 7.93557s/100 iters), loss = 1.94176
I1211 07:06:53.529258 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:06:53.529258 22260 solver.cpp:237]     Train net output #1: loss = 1.94176 (* 1 = 1.94176 loss)
I1211 07:06:53.529258 22260 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1211 07:06:59.866732 22260 solver.cpp:218] Iteration 12100 (15.781 iter/s, 6.33672s/100 iters), loss = 1.71146
I1211 07:06:59.866732 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:06:59.866732 22260 solver.cpp:237]     Train net output #1: loss = 1.71146 (* 1 = 1.71146 loss)
I1211 07:06:59.866732 22260 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1211 07:07:06.198259 22260 solver.cpp:218] Iteration 12200 (15.7942 iter/s, 6.33145s/100 iters), loss = 1.54804
I1211 07:07:06.198259 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:07:06.198259 22260 solver.cpp:237]     Train net output #1: loss = 1.54804 (* 1 = 1.54804 loss)
I1211 07:07:06.198259 22260 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1211 07:07:12.531709 22260 solver.cpp:218] Iteration 12300 (15.7894 iter/s, 6.33337s/100 iters), loss = 1.90219
I1211 07:07:12.531709 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:07:12.531709 22260 solver.cpp:237]     Train net output #1: loss = 1.90219 (* 1 = 1.90219 loss)
I1211 07:07:12.531709 22260 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1211 07:07:18.870556 22260 solver.cpp:218] Iteration 12400 (15.7776 iter/s, 6.33812s/100 iters), loss = 1.93303
I1211 07:07:18.870556 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:07:18.870556 22260 solver.cpp:237]     Train net output #1: loss = 1.93303 (* 1 = 1.93303 loss)
I1211 07:07:18.870556 22260 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1211 07:07:24.890185 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:07:25.140202 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12500.caffemodel
I1211 07:07:25.156201 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_12500.solverstate
I1211 07:07:25.160202 22260 solver.cpp:330] Iteration 12500, Testing net (#0)
I1211 07:07:25.160202 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:07:26.676316 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:07:26.736320 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2974
I1211 07:07:26.736320 22260 solver.cpp:397]     Test net output #1: loss = 2.951 (* 1 = 2.951 loss)
I1211 07:07:26.797324 22260 solver.cpp:218] Iteration 12500 (12.6161 iter/s, 7.92639s/100 iters), loss = 2.0008
I1211 07:07:26.797324 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:07:26.797324 22260 solver.cpp:237]     Train net output #1: loss = 2.0008 (* 1 = 2.0008 loss)
I1211 07:07:26.797324 22260 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1211 07:07:33.140781 22260 solver.cpp:218] Iteration 12600 (15.7663 iter/s, 6.34264s/100 iters), loss = 1.61041
I1211 07:07:33.140781 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:07:33.140781 22260 solver.cpp:237]     Train net output #1: loss = 1.61041 (* 1 = 1.61041 loss)
I1211 07:07:33.140781 22260 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1211 07:07:39.475186 22260 solver.cpp:218] Iteration 12700 (15.7881 iter/s, 6.33388s/100 iters), loss = 1.54412
I1211 07:07:39.475186 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:07:39.475186 22260 solver.cpp:237]     Train net output #1: loss = 1.54412 (* 1 = 1.54412 loss)
I1211 07:07:39.475186 22260 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1211 07:07:45.814671 22260 solver.cpp:218] Iteration 12800 (15.7741 iter/s, 6.33952s/100 iters), loss = 1.76119
I1211 07:07:45.814671 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:07:45.814671 22260 solver.cpp:237]     Train net output #1: loss = 1.76119 (* 1 = 1.76119 loss)
I1211 07:07:45.814671 22260 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1211 07:07:52.150133 22260 solver.cpp:218] Iteration 12900 (15.7865 iter/s, 6.33454s/100 iters), loss = 1.94007
I1211 07:07:52.150133 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:07:52.150133 22260 solver.cpp:237]     Train net output #1: loss = 1.94007 (* 1 = 1.94007 loss)
I1211 07:07:52.150133 22260 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1211 07:07:58.177587 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:07:58.428614 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13000.caffemodel
I1211 07:07:58.444617 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13000.solverstate
I1211 07:07:58.449617 22260 solver.cpp:330] Iteration 13000, Testing net (#0)
I1211 07:07:58.449617 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:07:59.967720 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:08:00.027724 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2832
I1211 07:08:00.027724 22260 solver.cpp:397]     Test net output #1: loss = 3.08885 (* 1 = 3.08885 loss)
I1211 07:08:00.088225 22260 solver.cpp:218] Iteration 13000 (12.5982 iter/s, 7.93762s/100 iters), loss = 2.07575
I1211 07:08:00.088225 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:08:00.088225 22260 solver.cpp:237]     Train net output #1: loss = 2.07575 (* 1 = 2.07575 loss)
I1211 07:08:00.088225 22260 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1211 07:08:06.423179 22260 solver.cpp:218] Iteration 13100 (15.785 iter/s, 6.33512s/100 iters), loss = 1.73922
I1211 07:08:06.423179 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:08:06.423179 22260 solver.cpp:237]     Train net output #1: loss = 1.73922 (* 1 = 1.73922 loss)
I1211 07:08:06.423179 22260 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1211 07:08:12.759677 22260 solver.cpp:218] Iteration 13200 (15.7824 iter/s, 6.33616s/100 iters), loss = 1.45095
I1211 07:08:12.760679 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:08:12.760679 22260 solver.cpp:237]     Train net output #1: loss = 1.45095 (* 1 = 1.45095 loss)
I1211 07:08:12.760679 22260 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1211 07:08:19.096133 22260 solver.cpp:218] Iteration 13300 (15.7841 iter/s, 6.33548s/100 iters), loss = 1.89131
I1211 07:08:19.096133 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:08:19.096133 22260 solver.cpp:237]     Train net output #1: loss = 1.89131 (* 1 = 1.89131 loss)
I1211 07:08:19.096133 22260 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1211 07:08:25.436677 22260 solver.cpp:218] Iteration 13400 (15.7722 iter/s, 6.34025s/100 iters), loss = 1.95586
I1211 07:08:25.436677 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:08:25.436677 22260 solver.cpp:237]     Train net output #1: loss = 1.95586 (* 1 = 1.95586 loss)
I1211 07:08:25.436677 22260 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1211 07:08:31.468506 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:08:31.717521 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13500.caffemodel
I1211 07:08:31.732522 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_13500.solverstate
I1211 07:08:31.736521 22260 solver.cpp:330] Iteration 13500, Testing net (#0)
I1211 07:08:31.736521 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:08:33.254644 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:08:33.314653 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3443
I1211 07:08:33.314653 22260 solver.cpp:397]     Test net output #1: loss = 2.71269 (* 1 = 2.71269 loss)
I1211 07:08:33.375653 22260 solver.cpp:218] Iteration 13500 (12.5974 iter/s, 7.93813s/100 iters), loss = 1.82439
I1211 07:08:33.375653 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:08:33.375653 22260 solver.cpp:237]     Train net output #1: loss = 1.82439 (* 1 = 1.82439 loss)
I1211 07:08:33.375653 22260 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1211 07:08:39.713102 22260 solver.cpp:218] Iteration 13600 (15.7789 iter/s, 6.33759s/100 iters), loss = 1.72247
I1211 07:08:39.713102 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:08:39.713102 22260 solver.cpp:237]     Train net output #1: loss = 1.72247 (* 1 = 1.72247 loss)
I1211 07:08:39.713102 22260 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1211 07:08:46.045593 22260 solver.cpp:218] Iteration 13700 (15.792 iter/s, 6.33232s/100 iters), loss = 1.55165
I1211 07:08:46.046592 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:08:46.046592 22260 solver.cpp:237]     Train net output #1: loss = 1.55165 (* 1 = 1.55165 loss)
I1211 07:08:46.046592 22260 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1211 07:08:52.379998 22260 solver.cpp:218] Iteration 13800 (15.7902 iter/s, 6.33305s/100 iters), loss = 1.8636
I1211 07:08:52.379998 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:08:52.379998 22260 solver.cpp:237]     Train net output #1: loss = 1.8636 (* 1 = 1.8636 loss)
I1211 07:08:52.379998 22260 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1211 07:08:58.717388 22260 solver.cpp:218] Iteration 13900 (15.7789 iter/s, 6.33757s/100 iters), loss = 1.89074
I1211 07:08:58.717388 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:08:58.717388 22260 solver.cpp:237]     Train net output #1: loss = 1.89074 (* 1 = 1.89074 loss)
I1211 07:08:58.717388 22260 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1211 07:09:04.741029 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:09:04.990916 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14000.caffemodel
I1211 07:09:05.005933 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14000.solverstate
I1211 07:09:05.010432 22260 solver.cpp:330] Iteration 14000, Testing net (#0)
I1211 07:09:05.010432 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:09:06.525365 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:09:06.585386 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2908
I1211 07:09:06.585386 22260 solver.cpp:397]     Test net output #1: loss = 3.1594 (* 1 = 3.1594 loss)
I1211 07:09:06.646006 22260 solver.cpp:218] Iteration 14000 (12.6132 iter/s, 7.9282s/100 iters), loss = 1.78257
I1211 07:09:06.646006 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:09:06.646006 22260 solver.cpp:237]     Train net output #1: loss = 1.78257 (* 1 = 1.78257 loss)
I1211 07:09:06.646006 22260 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1211 07:09:12.982066 22260 solver.cpp:218] Iteration 14100 (15.7839 iter/s, 6.33555s/100 iters), loss = 1.81934
I1211 07:09:12.982066 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:09:12.982066 22260 solver.cpp:237]     Train net output #1: loss = 1.81934 (* 1 = 1.81934 loss)
I1211 07:09:12.982066 22260 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1211 07:09:19.315594 22260 solver.cpp:218] Iteration 14200 (15.7904 iter/s, 6.33294s/100 iters), loss = 1.44305
I1211 07:09:19.315594 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:09:19.316095 22260 solver.cpp:237]     Train net output #1: loss = 1.44305 (* 1 = 1.44305 loss)
I1211 07:09:19.316095 22260 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1211 07:09:25.648906 22260 solver.cpp:218] Iteration 14300 (15.7915 iter/s, 6.33253s/100 iters), loss = 1.83463
I1211 07:09:25.648906 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:09:25.648906 22260 solver.cpp:237]     Train net output #1: loss = 1.83463 (* 1 = 1.83463 loss)
I1211 07:09:25.648906 22260 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1211 07:09:31.986565 22260 solver.cpp:218] Iteration 14400 (15.7789 iter/s, 6.33758s/100 iters), loss = 1.83492
I1211 07:09:31.986565 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:09:31.986565 22260 solver.cpp:237]     Train net output #1: loss = 1.83492 (* 1 = 1.83492 loss)
I1211 07:09:31.986565 22260 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1211 07:09:38.018028 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:09:38.268054 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14500.caffemodel
I1211 07:09:38.284054 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_14500.solverstate
I1211 07:09:38.289057 22260 solver.cpp:330] Iteration 14500, Testing net (#0)
I1211 07:09:38.289057 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:09:39.807159 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:09:39.866173 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3386
I1211 07:09:39.867166 22260 solver.cpp:397]     Test net output #1: loss = 2.76491 (* 1 = 2.76491 loss)
I1211 07:09:39.927166 22260 solver.cpp:218] Iteration 14500 (12.5942 iter/s, 7.94019s/100 iters), loss = 1.84016
I1211 07:09:39.927166 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:09:39.927166 22260 solver.cpp:237]     Train net output #1: loss = 1.84016 (* 1 = 1.84016 loss)
I1211 07:09:39.927166 22260 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1211 07:09:46.272589 22260 solver.cpp:218] Iteration 14600 (15.7615 iter/s, 6.34459s/100 iters), loss = 1.74777
I1211 07:09:46.272589 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:09:46.272589 22260 solver.cpp:237]     Train net output #1: loss = 1.74777 (* 1 = 1.74777 loss)
I1211 07:09:46.272589 22260 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1211 07:09:52.616022 22260 solver.cpp:218] Iteration 14700 (15.7655 iter/s, 6.34298s/100 iters), loss = 1.53029
I1211 07:09:52.616022 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:09:52.616022 22260 solver.cpp:237]     Train net output #1: loss = 1.53029 (* 1 = 1.53029 loss)
I1211 07:09:52.616022 22260 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1211 07:09:58.995596 22260 solver.cpp:218] Iteration 14800 (15.676 iter/s, 6.3792s/100 iters), loss = 2.01856
I1211 07:09:58.995596 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 07:09:58.995596 22260 solver.cpp:237]     Train net output #1: loss = 2.01856 (* 1 = 2.01856 loss)
I1211 07:09:58.995596 22260 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1211 07:10:05.348019 22260 solver.cpp:218] Iteration 14900 (15.7415 iter/s, 6.35263s/100 iters), loss = 1.89178
I1211 07:10:05.348019 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:10:05.348019 22260 solver.cpp:237]     Train net output #1: loss = 1.89178 (* 1 = 1.89178 loss)
I1211 07:10:05.348019 22260 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1211 07:10:11.383479 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:10:11.634495 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15000.caffemodel
I1211 07:10:11.649494 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15000.solverstate
I1211 07:10:11.653494 22260 solver.cpp:330] Iteration 15000, Testing net (#0)
I1211 07:10:11.654495 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:10:13.171613 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:10:13.231626 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2754
I1211 07:10:13.231626 22260 solver.cpp:397]     Test net output #1: loss = 3.09343 (* 1 = 3.09343 loss)
I1211 07:10:13.292629 22260 solver.cpp:218] Iteration 15000 (12.5884 iter/s, 7.94382s/100 iters), loss = 1.77375
I1211 07:10:13.292629 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:10:13.292629 22260 solver.cpp:237]     Train net output #1: loss = 1.77375 (* 1 = 1.77375 loss)
I1211 07:10:13.292629 22260 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1211 07:10:19.664803 22260 solver.cpp:218] Iteration 15100 (15.6941 iter/s, 6.37182s/100 iters), loss = 1.62069
I1211 07:10:19.664803 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:10:19.664803 22260 solver.cpp:237]     Train net output #1: loss = 1.62069 (* 1 = 1.62069 loss)
I1211 07:10:19.664803 22260 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1211 07:10:25.998072 22260 solver.cpp:218] Iteration 15200 (15.7895 iter/s, 6.33331s/100 iters), loss = 1.61455
I1211 07:10:25.998072 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:10:25.998072 22260 solver.cpp:237]     Train net output #1: loss = 1.61455 (* 1 = 1.61455 loss)
I1211 07:10:25.999058 22260 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1211 07:10:32.321501 22260 solver.cpp:218] Iteration 15300 (15.8154 iter/s, 6.32296s/100 iters), loss = 1.79972
I1211 07:10:32.321501 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:10:32.321501 22260 solver.cpp:237]     Train net output #1: loss = 1.79972 (* 1 = 1.79972 loss)
I1211 07:10:32.321501 22260 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1211 07:10:38.647951 22260 solver.cpp:218] Iteration 15400 (15.8092 iter/s, 6.32543s/100 iters), loss = 1.80491
I1211 07:10:38.647951 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:10:38.647951 22260 solver.cpp:237]     Train net output #1: loss = 1.80491 (* 1 = 1.80491 loss)
I1211 07:10:38.647951 22260 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1211 07:10:44.662400 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:10:44.911412 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15500.caffemodel
I1211 07:10:44.928416 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_15500.solverstate
I1211 07:10:44.932917 22260 solver.cpp:330] Iteration 15500, Testing net (#0)
I1211 07:10:44.932917 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:10:46.443506 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:10:46.503506 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3362
I1211 07:10:46.503506 22260 solver.cpp:397]     Test net output #1: loss = 2.73941 (* 1 = 2.73941 loss)
I1211 07:10:46.564510 22260 solver.cpp:218] Iteration 15500 (12.6321 iter/s, 7.91632s/100 iters), loss = 1.99595
I1211 07:10:46.564510 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:10:46.564510 22260 solver.cpp:237]     Train net output #1: loss = 1.99595 (* 1 = 1.99595 loss)
I1211 07:10:46.564510 22260 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1211 07:10:52.890996 22260 solver.cpp:218] Iteration 15600 (15.8069 iter/s, 6.32637s/100 iters), loss = 1.62982
I1211 07:10:52.890996 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:10:52.890996 22260 solver.cpp:237]     Train net output #1: loss = 1.62982 (* 1 = 1.62982 loss)
I1211 07:10:52.890996 22260 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1211 07:10:59.220420 22260 solver.cpp:218] Iteration 15700 (15.8012 iter/s, 6.32865s/100 iters), loss = 1.47855
I1211 07:10:59.220420 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:10:59.220420 22260 solver.cpp:237]     Train net output #1: loss = 1.47855 (* 1 = 1.47855 loss)
I1211 07:10:59.220420 22260 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1211 07:11:05.550881 22260 solver.cpp:218] Iteration 15800 (15.7977 iter/s, 6.33005s/100 iters), loss = 1.60387
I1211 07:11:05.550881 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:11:05.550881 22260 solver.cpp:237]     Train net output #1: loss = 1.60387 (* 1 = 1.60387 loss)
I1211 07:11:05.550881 22260 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1211 07:11:11.883340 22260 solver.cpp:218] Iteration 15900 (15.7934 iter/s, 6.33175s/100 iters), loss = 2.03619
I1211 07:11:11.883340 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:11:11.883340 22260 solver.cpp:237]     Train net output #1: loss = 2.03619 (* 1 = 2.03619 loss)
I1211 07:11:11.883340 22260 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1211 07:11:17.906805 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:11:18.157831 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16000.caffemodel
I1211 07:11:18.171833 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16000.solverstate
I1211 07:11:18.176834 22260 solver.cpp:330] Iteration 16000, Testing net (#0)
I1211 07:11:18.176834 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:11:19.687940 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:11:19.747944 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3086
I1211 07:11:19.747944 22260 solver.cpp:397]     Test net output #1: loss = 2.92045 (* 1 = 2.92045 loss)
I1211 07:11:19.807945 22260 solver.cpp:218] Iteration 16000 (12.6186 iter/s, 7.92482s/100 iters), loss = 1.71198
I1211 07:11:19.807945 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:11:19.807945 22260 solver.cpp:237]     Train net output #1: loss = 1.71198 (* 1 = 1.71198 loss)
I1211 07:11:19.808945 22260 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1211 07:11:26.141865 22260 solver.cpp:218] Iteration 16100 (15.7913 iter/s, 6.3326s/100 iters), loss = 1.68629
I1211 07:11:26.141865 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:11:26.141865 22260 solver.cpp:237]     Train net output #1: loss = 1.68629 (* 1 = 1.68629 loss)
I1211 07:11:26.141865 22260 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1211 07:11:32.469774 22260 solver.cpp:218] Iteration 16200 (15.8026 iter/s, 6.32808s/100 iters), loss = 1.38391
I1211 07:11:32.469774 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:11:32.469774 22260 solver.cpp:237]     Train net output #1: loss = 1.38391 (* 1 = 1.38391 loss)
I1211 07:11:32.469774 22260 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1211 07:11:38.797199 22260 solver.cpp:218] Iteration 16300 (15.8048 iter/s, 6.3272s/100 iters), loss = 1.86242
I1211 07:11:38.797199 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:11:38.797199 22260 solver.cpp:237]     Train net output #1: loss = 1.86242 (* 1 = 1.86242 loss)
I1211 07:11:38.797199 22260 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1211 07:11:45.137622 22260 solver.cpp:218] Iteration 16400 (15.7745 iter/s, 6.33935s/100 iters), loss = 1.90969
I1211 07:11:45.137622 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:11:45.137622 22260 solver.cpp:237]     Train net output #1: loss = 1.90969 (* 1 = 1.90969 loss)
I1211 07:11:45.137622 22260 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1211 07:11:51.158032 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:11:51.408044 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16500.caffemodel
I1211 07:11:51.425549 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_16500.solverstate
I1211 07:11:51.430049 22260 solver.cpp:330] Iteration 16500, Testing net (#0)
I1211 07:11:51.430049 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:11:52.943172 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:11:53.003173 22260 solver.cpp:397]     Test net output #0: accuracy = 0.31
I1211 07:11:53.003173 22260 solver.cpp:397]     Test net output #1: loss = 2.99882 (* 1 = 2.99882 loss)
I1211 07:11:53.064178 22260 solver.cpp:218] Iteration 16500 (12.6164 iter/s, 7.92621s/100 iters), loss = 1.88939
I1211 07:11:53.064178 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:11:53.064178 22260 solver.cpp:237]     Train net output #1: loss = 1.88939 (* 1 = 1.88939 loss)
I1211 07:11:53.064178 22260 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1211 07:11:59.386658 22260 solver.cpp:218] Iteration 16600 (15.8163 iter/s, 6.32258s/100 iters), loss = 1.71204
I1211 07:11:59.386658 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:11:59.386658 22260 solver.cpp:237]     Train net output #1: loss = 1.71204 (* 1 = 1.71204 loss)
I1211 07:11:59.386658 22260 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1211 07:12:05.714094 22260 solver.cpp:218] Iteration 16700 (15.8063 iter/s, 6.32658s/100 iters), loss = 1.44165
I1211 07:12:05.714094 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:12:05.714094 22260 solver.cpp:237]     Train net output #1: loss = 1.44165 (* 1 = 1.44165 loss)
I1211 07:12:05.714094 22260 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1211 07:12:12.040614 22260 solver.cpp:218] Iteration 16800 (15.8074 iter/s, 6.32616s/100 iters), loss = 1.9307
I1211 07:12:12.040614 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:12:12.040614 22260 solver.cpp:237]     Train net output #1: loss = 1.9307 (* 1 = 1.9307 loss)
I1211 07:12:12.040614 22260 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1211 07:12:18.367020 22260 solver.cpp:218] Iteration 16900 (15.8083 iter/s, 6.32579s/100 iters), loss = 1.95257
I1211 07:12:18.367020 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:12:18.367020 22260 solver.cpp:237]     Train net output #1: loss = 1.95257 (* 1 = 1.95257 loss)
I1211 07:12:18.367020 22260 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1211 07:12:24.388695 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:12:24.638707 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17000.caffemodel
I1211 07:12:24.654711 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17000.solverstate
I1211 07:12:24.658710 22260 solver.cpp:330] Iteration 17000, Testing net (#0)
I1211 07:12:24.658710 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:12:26.172824 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:12:26.232825 22260 solver.cpp:397]     Test net output #0: accuracy = 0.319
I1211 07:12:26.232825 22260 solver.cpp:397]     Test net output #1: loss = 2.85287 (* 1 = 2.85287 loss)
I1211 07:12:26.293828 22260 solver.cpp:218] Iteration 17000 (12.6168 iter/s, 7.92593s/100 iters), loss = 1.82873
I1211 07:12:26.293828 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:12:26.293828 22260 solver.cpp:237]     Train net output #1: loss = 1.82873 (* 1 = 1.82873 loss)
I1211 07:12:26.293828 22260 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1211 07:12:32.614253 22260 solver.cpp:218] Iteration 17100 (15.8224 iter/s, 6.32017s/100 iters), loss = 1.69912
I1211 07:12:32.614253 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:12:32.614253 22260 solver.cpp:237]     Train net output #1: loss = 1.69912 (* 1 = 1.69912 loss)
I1211 07:12:32.614253 22260 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1211 07:12:38.939702 22260 solver.cpp:218] Iteration 17200 (15.8093 iter/s, 6.32538s/100 iters), loss = 1.43668
I1211 07:12:38.939702 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:12:38.939702 22260 solver.cpp:237]     Train net output #1: loss = 1.43668 (* 1 = 1.43668 loss)
I1211 07:12:38.939702 22260 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1211 07:12:45.269250 22260 solver.cpp:218] Iteration 17300 (15.8007 iter/s, 6.32883s/100 iters), loss = 1.88941
I1211 07:12:45.269250 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:12:45.269250 22260 solver.cpp:237]     Train net output #1: loss = 1.88941 (* 1 = 1.88941 loss)
I1211 07:12:45.269250 22260 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1211 07:12:51.599738 22260 solver.cpp:218] Iteration 17400 (15.7978 iter/s, 6.32998s/100 iters), loss = 1.88292
I1211 07:12:51.599738 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:12:51.599738 22260 solver.cpp:237]     Train net output #1: loss = 1.88292 (* 1 = 1.88292 loss)
I1211 07:12:51.599738 22260 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1211 07:12:57.625692 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:12:57.875214 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17500.caffemodel
I1211 07:12:57.890214 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_17500.solverstate
I1211 07:12:57.894214 22260 solver.cpp:330] Iteration 17500, Testing net (#0)
I1211 07:12:57.894214 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:12:59.413316 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:12:59.473323 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3266
I1211 07:12:59.473323 22260 solver.cpp:397]     Test net output #1: loss = 2.85086 (* 1 = 2.85086 loss)
I1211 07:12:59.534322 22260 solver.cpp:218] Iteration 17500 (12.6037 iter/s, 7.93416s/100 iters), loss = 2.00582
I1211 07:12:59.534322 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:12:59.534322 22260 solver.cpp:237]     Train net output #1: loss = 2.00582 (* 1 = 2.00582 loss)
I1211 07:12:59.534322 22260 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1211 07:13:05.861290 22260 solver.cpp:218] Iteration 17600 (15.8069 iter/s, 6.32633s/100 iters), loss = 1.68834
I1211 07:13:05.861290 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:13:05.861290 22260 solver.cpp:237]     Train net output #1: loss = 1.68834 (* 1 = 1.68834 loss)
I1211 07:13:05.861290 22260 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1211 07:13:12.190306 22260 solver.cpp:218] Iteration 17700 (15.8006 iter/s, 6.32889s/100 iters), loss = 1.51714
I1211 07:13:12.190306 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:13:12.190306 22260 solver.cpp:237]     Train net output #1: loss = 1.51714 (* 1 = 1.51714 loss)
I1211 07:13:12.190306 22260 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1211 07:13:18.515725 22260 solver.cpp:218] Iteration 17800 (15.8101 iter/s, 6.32509s/100 iters), loss = 1.92209
I1211 07:13:18.515725 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:13:18.515725 22260 solver.cpp:237]     Train net output #1: loss = 1.92209 (* 1 = 1.92209 loss)
I1211 07:13:18.515725 22260 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1211 07:13:24.840234 22260 solver.cpp:218] Iteration 17900 (15.813 iter/s, 6.32393s/100 iters), loss = 1.74687
I1211 07:13:24.840234 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:13:24.840234 22260 solver.cpp:237]     Train net output #1: loss = 1.74687 (* 1 = 1.74687 loss)
I1211 07:13:24.840234 22260 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1211 07:13:30.860711 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:13:31.110728 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18000.caffemodel
I1211 07:13:31.125727 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18000.solverstate
I1211 07:13:31.130728 22260 solver.cpp:330] Iteration 18000, Testing net (#0)
I1211 07:13:31.130728 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:13:32.642830 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:13:32.703336 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3627
I1211 07:13:32.703336 22260 solver.cpp:397]     Test net output #1: loss = 2.54052 (* 1 = 2.54052 loss)
I1211 07:13:32.763840 22260 solver.cpp:218] Iteration 18000 (12.6209 iter/s, 7.92334s/100 iters), loss = 1.84929
I1211 07:13:32.763840 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:13:32.763840 22260 solver.cpp:237]     Train net output #1: loss = 1.84929 (* 1 = 1.84929 loss)
I1211 07:13:32.763840 22260 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1211 07:13:39.100267 22260 solver.cpp:218] Iteration 18100 (15.783 iter/s, 6.33592s/100 iters), loss = 1.58004
I1211 07:13:39.100267 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:13:39.100769 22260 solver.cpp:237]     Train net output #1: loss = 1.58004 (* 1 = 1.58004 loss)
I1211 07:13:39.100769 22260 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1211 07:13:45.434687 22260 solver.cpp:218] Iteration 18200 (15.7884 iter/s, 6.33378s/100 iters), loss = 1.61908
I1211 07:13:45.434687 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:13:45.434687 22260 solver.cpp:237]     Train net output #1: loss = 1.61908 (* 1 = 1.61908 loss)
I1211 07:13:45.434687 22260 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1211 07:13:51.764113 22260 solver.cpp:218] Iteration 18300 (15.7994 iter/s, 6.32935s/100 iters), loss = 1.69216
I1211 07:13:51.764113 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:13:51.764113 22260 solver.cpp:237]     Train net output #1: loss = 1.69216 (* 1 = 1.69216 loss)
I1211 07:13:51.764113 22260 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1211 07:13:58.088929 22260 solver.cpp:218] Iteration 18400 (15.8131 iter/s, 6.32386s/100 iters), loss = 1.85513
I1211 07:13:58.088929 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:13:58.088929 22260 solver.cpp:237]     Train net output #1: loss = 1.85513 (* 1 = 1.85513 loss)
I1211 07:13:58.088929 22260 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1211 07:14:04.103843 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:14:04.353370 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18500.caffemodel
I1211 07:14:04.368371 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_18500.solverstate
I1211 07:14:04.373371 22260 solver.cpp:330] Iteration 18500, Testing net (#0)
I1211 07:14:04.373371 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:14:05.887465 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:14:05.947473 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3356
I1211 07:14:05.947473 22260 solver.cpp:397]     Test net output #1: loss = 2.69723 (* 1 = 2.69723 loss)
I1211 07:14:06.007475 22260 solver.cpp:218] Iteration 18500 (12.628 iter/s, 7.9189s/100 iters), loss = 1.7105
I1211 07:14:06.007475 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:14:06.007475 22260 solver.cpp:237]     Train net output #1: loss = 1.7105 (* 1 = 1.7105 loss)
I1211 07:14:06.007475 22260 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1211 07:14:12.326947 22260 solver.cpp:218] Iteration 18600 (15.8255 iter/s, 6.3189s/100 iters), loss = 1.69994
I1211 07:14:12.326947 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:14:12.326947 22260 solver.cpp:237]     Train net output #1: loss = 1.69994 (* 1 = 1.69994 loss)
I1211 07:14:12.326947 22260 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1211 07:14:18.644415 22260 solver.cpp:218] Iteration 18700 (15.8316 iter/s, 6.31647s/100 iters), loss = 1.42776
I1211 07:14:18.644415 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:14:18.644415 22260 solver.cpp:237]     Train net output #1: loss = 1.42776 (* 1 = 1.42776 loss)
I1211 07:14:18.644415 22260 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1211 07:14:24.962867 22260 solver.cpp:218] Iteration 18800 (15.8263 iter/s, 6.31861s/100 iters), loss = 2.03374
I1211 07:14:24.962867 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 07:14:24.962867 22260 solver.cpp:237]     Train net output #1: loss = 2.03374 (* 1 = 2.03374 loss)
I1211 07:14:24.962867 22260 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1211 07:14:31.275621 22260 solver.cpp:218] Iteration 18900 (15.8439 iter/s, 6.3116s/100 iters), loss = 1.82607
I1211 07:14:31.275621 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:14:31.275621 22260 solver.cpp:237]     Train net output #1: loss = 1.82607 (* 1 = 1.82607 loss)
I1211 07:14:31.275621 22260 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1211 07:14:37.289060 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:14:37.538082 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19000.caffemodel
I1211 07:14:37.553082 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19000.solverstate
I1211 07:14:37.557082 22260 solver.cpp:330] Iteration 19000, Testing net (#0)
I1211 07:14:37.557082 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:14:39.070168 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:14:39.130175 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3673
I1211 07:14:39.130175 22260 solver.cpp:397]     Test net output #1: loss = 2.51461 (* 1 = 2.51461 loss)
I1211 07:14:39.191171 22260 solver.cpp:218] Iteration 19000 (12.6337 iter/s, 7.91536s/100 iters), loss = 1.74304
I1211 07:14:39.191171 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:14:39.191171 22260 solver.cpp:237]     Train net output #1: loss = 1.74304 (* 1 = 1.74304 loss)
I1211 07:14:39.191171 22260 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1211 07:14:45.520628 22260 solver.cpp:218] Iteration 19100 (15.8004 iter/s, 6.32896s/100 iters), loss = 1.70904
I1211 07:14:45.520628 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:14:45.520628 22260 solver.cpp:237]     Train net output #1: loss = 1.70904 (* 1 = 1.70904 loss)
I1211 07:14:45.520628 22260 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1211 07:14:51.854188 22260 solver.cpp:218] Iteration 19200 (15.7894 iter/s, 6.33336s/100 iters), loss = 1.33823
I1211 07:14:51.854188 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:14:51.854188 22260 solver.cpp:237]     Train net output #1: loss = 1.33823 (* 1 = 1.33823 loss)
I1211 07:14:51.854188 22260 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1211 07:14:58.186681 22260 solver.cpp:218] Iteration 19300 (15.7915 iter/s, 6.33252s/100 iters), loss = 1.91363
I1211 07:14:58.186681 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:14:58.186681 22260 solver.cpp:237]     Train net output #1: loss = 1.91363 (* 1 = 1.91363 loss)
I1211 07:14:58.186681 22260 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1211 07:15:04.516151 22260 solver.cpp:218] Iteration 19400 (15.802 iter/s, 6.32832s/100 iters), loss = 1.80561
I1211 07:15:04.516151 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:15:04.516151 22260 solver.cpp:237]     Train net output #1: loss = 1.80561 (* 1 = 1.80561 loss)
I1211 07:15:04.516151 22260 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1211 07:15:10.543627 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:15:10.793650 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19500.caffemodel
I1211 07:15:10.808651 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_19500.solverstate
I1211 07:15:10.813652 22260 solver.cpp:330] Iteration 19500, Testing net (#0)
I1211 07:15:10.813652 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:15:12.324760 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:15:12.384765 22260 solver.cpp:397]     Test net output #0: accuracy = 0.249
I1211 07:15:12.384765 22260 solver.cpp:397]     Test net output #1: loss = 4.02004 (* 1 = 4.02004 loss)
I1211 07:15:12.445269 22260 solver.cpp:218] Iteration 19500 (12.6119 iter/s, 7.92899s/100 iters), loss = 1.74034
I1211 07:15:12.445768 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:15:12.445768 22260 solver.cpp:237]     Train net output #1: loss = 1.74034 (* 1 = 1.74034 loss)
I1211 07:15:12.445768 22260 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1211 07:15:18.781255 22260 solver.cpp:218] Iteration 19600 (15.7843 iter/s, 6.3354s/100 iters), loss = 1.55241
I1211 07:15:18.781255 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:15:18.781255 22260 solver.cpp:237]     Train net output #1: loss = 1.55241 (* 1 = 1.55241 loss)
I1211 07:15:18.781255 22260 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1211 07:15:25.106722 22260 solver.cpp:218] Iteration 19700 (15.8107 iter/s, 6.32483s/100 iters), loss = 1.31186
I1211 07:15:25.106722 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:15:25.106722 22260 solver.cpp:237]     Train net output #1: loss = 1.31186 (* 1 = 1.31186 loss)
I1211 07:15:25.106722 22260 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1211 07:15:31.433190 22260 solver.cpp:218] Iteration 19800 (15.8076 iter/s, 6.32608s/100 iters), loss = 1.79283
I1211 07:15:31.433190 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:15:31.433190 22260 solver.cpp:237]     Train net output #1: loss = 1.79283 (* 1 = 1.79283 loss)
I1211 07:15:31.433190 22260 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1211 07:15:37.760670 22260 solver.cpp:218] Iteration 19900 (15.8053 iter/s, 6.327s/100 iters), loss = 1.84623
I1211 07:15:37.760670 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:15:37.760670 22260 solver.cpp:237]     Train net output #1: loss = 1.84623 (* 1 = 1.84623 loss)
I1211 07:15:37.760670 22260 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1211 07:15:43.774161 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:15:44.023195 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20000.caffemodel
I1211 07:15:44.040194 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20000.solverstate
I1211 07:15:44.044193 22260 solver.cpp:330] Iteration 20000, Testing net (#0)
I1211 07:15:44.044193 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:15:45.558315 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:15:45.618320 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3456
I1211 07:15:45.618320 22260 solver.cpp:397]     Test net output #1: loss = 2.72153 (* 1 = 2.72153 loss)
I1211 07:15:45.678319 22260 solver.cpp:218] Iteration 20000 (12.6302 iter/s, 7.91752s/100 iters), loss = 1.62824
I1211 07:15:45.678319 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:15:45.678319 22260 solver.cpp:237]     Train net output #1: loss = 1.62824 (* 1 = 1.62824 loss)
I1211 07:15:45.678319 22260 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1211 07:15:52.000841 22260 solver.cpp:218] Iteration 20100 (15.8169 iter/s, 6.32234s/100 iters), loss = 1.83617
I1211 07:15:52.000841 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:15:52.000841 22260 solver.cpp:237]     Train net output #1: loss = 1.83617 (* 1 = 1.83617 loss)
I1211 07:15:52.000841 22260 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1211 07:15:58.330304 22260 solver.cpp:218] Iteration 20200 (15.8012 iter/s, 6.32863s/100 iters), loss = 1.33902
I1211 07:15:58.330304 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:15:58.330304 22260 solver.cpp:237]     Train net output #1: loss = 1.33902 (* 1 = 1.33902 loss)
I1211 07:15:58.330304 22260 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1211 07:16:04.656744 22260 solver.cpp:218] Iteration 20300 (15.8063 iter/s, 6.32658s/100 iters), loss = 1.88045
I1211 07:16:04.656744 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:16:04.656744 22260 solver.cpp:237]     Train net output #1: loss = 1.88045 (* 1 = 1.88045 loss)
I1211 07:16:04.656744 22260 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1211 07:16:10.976182 22260 solver.cpp:218] Iteration 20400 (15.8267 iter/s, 6.31843s/100 iters), loss = 1.92006
I1211 07:16:10.976182 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:16:10.976182 22260 solver.cpp:237]     Train net output #1: loss = 1.92006 (* 1 = 1.92006 loss)
I1211 07:16:10.976182 22260 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1211 07:16:16.990614 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:16:17.240628 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20500.caffemodel
I1211 07:16:17.255627 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_20500.solverstate
I1211 07:16:17.259627 22260 solver.cpp:330] Iteration 20500, Testing net (#0)
I1211 07:16:17.259627 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:16:18.771744 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:16:18.830745 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3106
I1211 07:16:18.830745 22260 solver.cpp:397]     Test net output #1: loss = 2.87902 (* 1 = 2.87902 loss)
I1211 07:16:18.891749 22260 solver.cpp:218] Iteration 20500 (12.6342 iter/s, 7.91501s/100 iters), loss = 1.81018
I1211 07:16:18.891749 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:16:18.891749 22260 solver.cpp:237]     Train net output #1: loss = 1.81018 (* 1 = 1.81018 loss)
I1211 07:16:18.891749 22260 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1211 07:16:25.221263 22260 solver.cpp:218] Iteration 20600 (15.7999 iter/s, 6.32916s/100 iters), loss = 1.73776
I1211 07:16:25.221263 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:16:25.221263 22260 solver.cpp:237]     Train net output #1: loss = 1.73776 (* 1 = 1.73776 loss)
I1211 07:16:25.221263 22260 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1211 07:16:31.541782 22260 solver.cpp:218] Iteration 20700 (15.8231 iter/s, 6.31988s/100 iters), loss = 1.49972
I1211 07:16:31.541782 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:16:31.541782 22260 solver.cpp:237]     Train net output #1: loss = 1.49972 (* 1 = 1.49972 loss)
I1211 07:16:31.541782 22260 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1211 07:16:37.877758 22260 solver.cpp:218] Iteration 20800 (15.7835 iter/s, 6.33574s/100 iters), loss = 1.83576
I1211 07:16:37.878258 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:16:37.878258 22260 solver.cpp:237]     Train net output #1: loss = 1.83576 (* 1 = 1.83576 loss)
I1211 07:16:37.878258 22260 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1211 07:16:44.201783 22260 solver.cpp:218] Iteration 20900 (15.8138 iter/s, 6.32357s/100 iters), loss = 2.20359
I1211 07:16:44.201783 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:16:44.201783 22260 solver.cpp:237]     Train net output #1: loss = 2.20359 (* 1 = 2.20359 loss)
I1211 07:16:44.201783 22260 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1211 07:16:50.214215 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:16:50.463224 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21000.caffemodel
I1211 07:16:50.479228 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21000.solverstate
I1211 07:16:50.483232 22260 solver.cpp:330] Iteration 21000, Testing net (#0)
I1211 07:16:50.483232 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:16:51.997413 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:16:52.057412 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3309
I1211 07:16:52.057412 22260 solver.cpp:397]     Test net output #1: loss = 2.72809 (* 1 = 2.72809 loss)
I1211 07:16:52.118418 22260 solver.cpp:218] Iteration 21000 (12.6321 iter/s, 7.91632s/100 iters), loss = 1.79642
I1211 07:16:52.118418 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:16:52.118418 22260 solver.cpp:237]     Train net output #1: loss = 1.79642 (* 1 = 1.79642 loss)
I1211 07:16:52.118418 22260 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1211 07:16:58.446883 22260 solver.cpp:218] Iteration 21100 (15.8038 iter/s, 6.32758s/100 iters), loss = 1.74506
I1211 07:16:58.446883 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:16:58.446883 22260 solver.cpp:237]     Train net output #1: loss = 1.74506 (* 1 = 1.74506 loss)
I1211 07:16:58.446883 22260 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1211 07:17:04.778321 22260 solver.cpp:218] Iteration 21200 (15.7946 iter/s, 6.33128s/100 iters), loss = 1.43017
I1211 07:17:04.778321 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:17:04.778321 22260 solver.cpp:237]     Train net output #1: loss = 1.43017 (* 1 = 1.43017 loss)
I1211 07:17:04.778321 22260 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1211 07:17:11.104809 22260 solver.cpp:218] Iteration 21300 (15.8079 iter/s, 6.32594s/100 iters), loss = 1.6753
I1211 07:17:11.104809 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:17:11.104809 22260 solver.cpp:237]     Train net output #1: loss = 1.6753 (* 1 = 1.6753 loss)
I1211 07:17:11.104809 22260 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1211 07:17:17.429280 22260 solver.cpp:218] Iteration 21400 (15.8114 iter/s, 6.32456s/100 iters), loss = 1.82152
I1211 07:17:17.429280 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:17:17.429280 22260 solver.cpp:237]     Train net output #1: loss = 1.82152 (* 1 = 1.82152 loss)
I1211 07:17:17.429280 22260 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1211 07:17:23.450706 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:17:23.699719 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21500.caffemodel
I1211 07:17:23.714720 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_21500.solverstate
I1211 07:17:23.718720 22260 solver.cpp:330] Iteration 21500, Testing net (#0)
I1211 07:17:23.718720 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:17:25.231856 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:17:25.291852 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3367
I1211 07:17:25.291852 22260 solver.cpp:397]     Test net output #1: loss = 2.69785 (* 1 = 2.69785 loss)
I1211 07:17:25.351851 22260 solver.cpp:218] Iteration 21500 (12.6239 iter/s, 7.92148s/100 iters), loss = 1.79064
I1211 07:17:25.351851 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:17:25.351851 22260 solver.cpp:237]     Train net output #1: loss = 1.79064 (* 1 = 1.79064 loss)
I1211 07:17:25.351851 22260 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1211 07:17:31.672813 22260 solver.cpp:218] Iteration 21600 (15.8212 iter/s, 6.32064s/100 iters), loss = 1.51423
I1211 07:17:31.672813 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:17:31.672813 22260 solver.cpp:237]     Train net output #1: loss = 1.51423 (* 1 = 1.51423 loss)
I1211 07:17:31.672813 22260 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1211 07:17:37.993831 22260 solver.cpp:218] Iteration 21700 (15.8196 iter/s, 6.32127s/100 iters), loss = 1.51807
I1211 07:17:37.994832 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:17:37.994832 22260 solver.cpp:237]     Train net output #1: loss = 1.51807 (* 1 = 1.51807 loss)
I1211 07:17:37.994832 22260 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1211 07:17:44.320325 22260 solver.cpp:218] Iteration 21800 (15.8099 iter/s, 6.32515s/100 iters), loss = 1.66904
I1211 07:17:44.320325 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:17:44.320325 22260 solver.cpp:237]     Train net output #1: loss = 1.66904 (* 1 = 1.66904 loss)
I1211 07:17:44.320325 22260 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1211 07:17:50.648821 22260 solver.cpp:218] Iteration 21900 (15.8018 iter/s, 6.32839s/100 iters), loss = 1.82954
I1211 07:17:50.648821 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:17:50.648821 22260 solver.cpp:237]     Train net output #1: loss = 1.82954 (* 1 = 1.82954 loss)
I1211 07:17:50.648821 22260 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1211 07:17:56.668246 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:17:56.917264 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22000.caffemodel
I1211 07:17:56.933265 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22000.solverstate
I1211 07:17:56.937265 22260 solver.cpp:330] Iteration 22000, Testing net (#0)
I1211 07:17:56.937265 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:17:58.449371 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:17:58.509374 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3692
I1211 07:17:58.509374 22260 solver.cpp:397]     Test net output #1: loss = 2.49562 (* 1 = 2.49562 loss)
I1211 07:17:58.571377 22260 solver.cpp:218] Iteration 22000 (12.623 iter/s, 7.92208s/100 iters), loss = 1.70705
I1211 07:17:58.571377 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:17:58.571377 22260 solver.cpp:237]     Train net output #1: loss = 1.70705 (* 1 = 1.70705 loss)
I1211 07:17:58.571377 22260 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1211 07:18:04.885841 22260 solver.cpp:218] Iteration 22100 (15.8378 iter/s, 6.31402s/100 iters), loss = 1.70113
I1211 07:18:04.885841 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:18:04.885841 22260 solver.cpp:237]     Train net output #1: loss = 1.70113 (* 1 = 1.70113 loss)
I1211 07:18:04.885841 22260 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1211 07:18:11.208354 22260 solver.cpp:218] Iteration 22200 (15.8173 iter/s, 6.3222s/100 iters), loss = 1.27715
I1211 07:18:11.208354 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 07:18:11.208354 22260 solver.cpp:237]     Train net output #1: loss = 1.27715 (* 1 = 1.27715 loss)
I1211 07:18:11.208354 22260 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1211 07:18:17.523855 22260 solver.cpp:218] Iteration 22300 (15.8351 iter/s, 6.3151s/100 iters), loss = 1.86256
I1211 07:18:17.523855 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.42
I1211 07:18:17.523855 22260 solver.cpp:237]     Train net output #1: loss = 1.86256 (* 1 = 1.86256 loss)
I1211 07:18:17.523855 22260 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1211 07:18:23.842317 22260 solver.cpp:218] Iteration 22400 (15.828 iter/s, 6.31791s/100 iters), loss = 1.89191
I1211 07:18:23.842317 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:18:23.842317 22260 solver.cpp:237]     Train net output #1: loss = 1.89191 (* 1 = 1.89191 loss)
I1211 07:18:23.842317 22260 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1211 07:18:29.853763 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:18:30.103783 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22500.caffemodel
I1211 07:18:30.118784 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_22500.solverstate
I1211 07:18:30.123786 22260 solver.cpp:330] Iteration 22500, Testing net (#0)
I1211 07:18:30.123786 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:18:31.637910 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:18:31.697912 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3437
I1211 07:18:31.697912 22260 solver.cpp:397]     Test net output #1: loss = 2.70141 (* 1 = 2.70141 loss)
I1211 07:18:31.758911 22260 solver.cpp:218] Iteration 22500 (12.6325 iter/s, 7.91609s/100 iters), loss = 1.69341
I1211 07:18:31.758911 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:18:31.758911 22260 solver.cpp:237]     Train net output #1: loss = 1.69341 (* 1 = 1.69341 loss)
I1211 07:18:31.758911 22260 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1211 07:18:38.085960 22260 solver.cpp:218] Iteration 22600 (15.8067 iter/s, 6.32645s/100 iters), loss = 1.83647
I1211 07:18:38.085960 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.4
I1211 07:18:38.085960 22260 solver.cpp:237]     Train net output #1: loss = 1.83647 (* 1 = 1.83647 loss)
I1211 07:18:38.085960 22260 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1211 07:18:44.403903 22260 solver.cpp:218] Iteration 22700 (15.8286 iter/s, 6.31767s/100 iters), loss = 1.47552
I1211 07:18:44.403903 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:18:44.403903 22260 solver.cpp:237]     Train net output #1: loss = 1.47552 (* 1 = 1.47552 loss)
I1211 07:18:44.403903 22260 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1211 07:18:50.716368 22260 solver.cpp:218] Iteration 22800 (15.8413 iter/s, 6.3126s/100 iters), loss = 1.6454
I1211 07:18:50.716368 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:18:50.716368 22260 solver.cpp:237]     Train net output #1: loss = 1.6454 (* 1 = 1.6454 loss)
I1211 07:18:50.716368 22260 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1211 07:18:57.031886 22260 solver.cpp:218] Iteration 22900 (15.8352 iter/s, 6.31506s/100 iters), loss = 1.93021
I1211 07:18:57.031886 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:18:57.031886 22260 solver.cpp:237]     Train net output #1: loss = 1.93021 (* 1 = 1.93021 loss)
I1211 07:18:57.031886 22260 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1211 07:19:03.044513 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:19:03.293537 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23000.caffemodel
I1211 07:19:03.307536 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23000.solverstate
I1211 07:19:03.312538 22260 solver.cpp:330] Iteration 23000, Testing net (#0)
I1211 07:19:03.312538 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:19:04.824671 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:19:04.884667 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3177
I1211 07:19:04.884667 22260 solver.cpp:397]     Test net output #1: loss = 2.8098 (* 1 = 2.8098 loss)
I1211 07:19:04.944669 22260 solver.cpp:218] Iteration 23000 (12.6384 iter/s, 7.91238s/100 iters), loss = 1.68933
I1211 07:19:04.944669 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:19:04.944669 22260 solver.cpp:237]     Train net output #1: loss = 1.68933 (* 1 = 1.68933 loss)
I1211 07:19:04.944669 22260 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1211 07:19:11.272171 22260 solver.cpp:218] Iteration 23100 (15.8053 iter/s, 6.32701s/100 iters), loss = 1.66147
I1211 07:19:11.272171 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:19:11.272171 22260 solver.cpp:237]     Train net output #1: loss = 1.66147 (* 1 = 1.66147 loss)
I1211 07:19:11.272171 22260 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1211 07:19:17.598598 22260 solver.cpp:218] Iteration 23200 (15.8079 iter/s, 6.32595s/100 iters), loss = 1.47903
I1211 07:19:17.598598 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:19:17.598598 22260 solver.cpp:237]     Train net output #1: loss = 1.47903 (* 1 = 1.47903 loss)
I1211 07:19:17.598598 22260 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1211 07:19:23.931128 22260 solver.cpp:218] Iteration 23300 (15.7939 iter/s, 6.33156s/100 iters), loss = 1.70462
I1211 07:19:23.931128 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:19:23.931128 22260 solver.cpp:237]     Train net output #1: loss = 1.70462 (* 1 = 1.70462 loss)
I1211 07:19:23.931128 22260 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1211 07:19:30.256599 22260 solver.cpp:218] Iteration 23400 (15.8081 iter/s, 6.32588s/100 iters), loss = 1.85869
I1211 07:19:30.257599 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:19:30.257599 22260 solver.cpp:237]     Train net output #1: loss = 1.85869 (* 1 = 1.85869 loss)
I1211 07:19:30.257599 22260 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1211 07:19:36.298974 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:19:36.549484 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23500.caffemodel
I1211 07:19:36.564988 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_23500.solverstate
I1211 07:19:36.568987 22260 solver.cpp:330] Iteration 23500, Testing net (#0)
I1211 07:19:36.568987 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:19:38.081082 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:19:38.141584 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3045
I1211 07:19:38.142084 22260 solver.cpp:397]     Test net output #1: loss = 3.02227 (* 1 = 3.02227 loss)
I1211 07:19:38.202085 22260 solver.cpp:218] Iteration 23500 (12.5869 iter/s, 7.94476s/100 iters), loss = 1.75938
I1211 07:19:38.202085 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:19:38.202085 22260 solver.cpp:237]     Train net output #1: loss = 1.75938 (* 1 = 1.75938 loss)
I1211 07:19:38.202085 22260 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1211 07:19:44.538107 22260 solver.cpp:218] Iteration 23600 (15.7848 iter/s, 6.3352s/100 iters), loss = 1.65922
I1211 07:19:44.538107 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:19:44.538107 22260 solver.cpp:237]     Train net output #1: loss = 1.65922 (* 1 = 1.65922 loss)
I1211 07:19:44.538107 22260 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1211 07:19:50.879861 22260 solver.cpp:218] Iteration 23700 (15.7694 iter/s, 6.34139s/100 iters), loss = 1.35218
I1211 07:19:50.879861 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:19:50.879861 22260 solver.cpp:237]     Train net output #1: loss = 1.35218 (* 1 = 1.35218 loss)
I1211 07:19:50.879861 22260 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1211 07:19:57.208019 22260 solver.cpp:218] Iteration 23800 (15.8031 iter/s, 6.32785s/100 iters), loss = 1.74606
I1211 07:19:57.208019 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:19:57.208019 22260 solver.cpp:237]     Train net output #1: loss = 1.74606 (* 1 = 1.74606 loss)
I1211 07:19:57.208019 22260 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1211 07:20:03.540468 22260 solver.cpp:218] Iteration 23900 (15.7933 iter/s, 6.33181s/100 iters), loss = 1.86468
I1211 07:20:03.540468 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:20:03.540468 22260 solver.cpp:237]     Train net output #1: loss = 1.86468 (* 1 = 1.86468 loss)
I1211 07:20:03.540468 22260 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1211 07:20:09.558926 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:20:09.808940 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24000.caffemodel
I1211 07:20:09.823940 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24000.solverstate
I1211 07:20:09.827939 22260 solver.cpp:330] Iteration 24000, Testing net (#0)
I1211 07:20:09.828940 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:20:11.341047 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:20:11.401059 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3774
I1211 07:20:11.401059 22260 solver.cpp:397]     Test net output #1: loss = 2.51583 (* 1 = 2.51583 loss)
I1211 07:20:11.461056 22260 solver.cpp:218] Iteration 24000 (12.6255 iter/s, 7.92047s/100 iters), loss = 1.61585
I1211 07:20:11.461056 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:20:11.461056 22260 solver.cpp:237]     Train net output #1: loss = 1.61585 (* 1 = 1.61585 loss)
I1211 07:20:11.461056 22260 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1211 07:20:17.785545 22260 solver.cpp:218] Iteration 24100 (15.8134 iter/s, 6.32377s/100 iters), loss = 1.57776
I1211 07:20:17.785545 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:20:17.785545 22260 solver.cpp:237]     Train net output #1: loss = 1.57776 (* 1 = 1.57776 loss)
I1211 07:20:17.785545 22260 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1211 07:20:24.102017 22260 solver.cpp:218] Iteration 24200 (15.8323 iter/s, 6.31621s/100 iters), loss = 1.47159
I1211 07:20:24.102017 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 07:20:24.102017 22260 solver.cpp:237]     Train net output #1: loss = 1.47159 (* 1 = 1.47159 loss)
I1211 07:20:24.102017 22260 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1211 07:20:30.424449 22260 solver.cpp:218] Iteration 24300 (15.8167 iter/s, 6.32241s/100 iters), loss = 1.73614
I1211 07:20:30.425448 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:20:30.425448 22260 solver.cpp:237]     Train net output #1: loss = 1.73614 (* 1 = 1.73614 loss)
I1211 07:20:30.425448 22260 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1211 07:20:36.746877 22260 solver.cpp:218] Iteration 24400 (15.82 iter/s, 6.3211s/100 iters), loss = 1.83594
I1211 07:20:36.746877 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:20:36.746877 22260 solver.cpp:237]     Train net output #1: loss = 1.83594 (* 1 = 1.83594 loss)
I1211 07:20:36.746877 22260 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1211 07:20:42.761329 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:20:43.010349 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24500.caffemodel
I1211 07:20:43.025348 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_24500.solverstate
I1211 07:20:43.030350 22260 solver.cpp:330] Iteration 24500, Testing net (#0)
I1211 07:20:43.030350 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:20:44.544958 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:20:44.604463 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3712
I1211 07:20:44.604463 22260 solver.cpp:397]     Test net output #1: loss = 2.49297 (* 1 = 2.49297 loss)
I1211 07:20:44.665467 22260 solver.cpp:218] Iteration 24500 (12.6292 iter/s, 7.91817s/100 iters), loss = 1.81669
I1211 07:20:44.665467 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:20:44.665467 22260 solver.cpp:237]     Train net output #1: loss = 1.81669 (* 1 = 1.81669 loss)
I1211 07:20:44.665467 22260 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1211 07:20:50.987934 22260 solver.cpp:218] Iteration 24600 (15.8178 iter/s, 6.32198s/100 iters), loss = 1.62444
I1211 07:20:50.987934 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:20:50.987934 22260 solver.cpp:237]     Train net output #1: loss = 1.62444 (* 1 = 1.62444 loss)
I1211 07:20:50.987934 22260 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1211 07:20:57.308426 22260 solver.cpp:218] Iteration 24700 (15.8208 iter/s, 6.32078s/100 iters), loss = 1.43941
I1211 07:20:57.308426 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:20:57.308426 22260 solver.cpp:237]     Train net output #1: loss = 1.43941 (* 1 = 1.43941 loss)
I1211 07:20:57.308426 22260 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1211 07:21:03.643582 22260 solver.cpp:218] Iteration 24800 (15.7876 iter/s, 6.33409s/100 iters), loss = 1.72871
I1211 07:21:03.643582 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:21:03.643582 22260 solver.cpp:237]     Train net output #1: loss = 1.72871 (* 1 = 1.72871 loss)
I1211 07:21:03.643582 22260 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1211 07:21:09.970852 22260 solver.cpp:218] Iteration 24900 (15.8047 iter/s, 6.32723s/100 iters), loss = 1.82466
I1211 07:21:09.970852 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:21:09.970852 22260 solver.cpp:237]     Train net output #1: loss = 1.82466 (* 1 = 1.82466 loss)
I1211 07:21:09.970852 22260 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1211 07:21:15.982323 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:21:16.231335 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25000.caffemodel
I1211 07:21:16.246335 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25000.solverstate
I1211 07:21:16.250335 22260 solver.cpp:330] Iteration 25000, Testing net (#0)
I1211 07:21:16.250335 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:21:17.761943 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:21:17.821445 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3688
I1211 07:21:17.821445 22260 solver.cpp:397]     Test net output #1: loss = 2.49625 (* 1 = 2.49625 loss)
I1211 07:21:17.882455 22260 solver.cpp:218] Iteration 25000 (12.6406 iter/s, 7.911s/100 iters), loss = 1.59744
I1211 07:21:17.882455 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:21:17.882455 22260 solver.cpp:237]     Train net output #1: loss = 1.59744 (* 1 = 1.59744 loss)
I1211 07:21:17.882455 22260 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1211 07:21:24.200953 22260 solver.cpp:218] Iteration 25100 (15.8267 iter/s, 6.31843s/100 iters), loss = 1.69986
I1211 07:21:24.200953 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:21:24.200953 22260 solver.cpp:237]     Train net output #1: loss = 1.69986 (* 1 = 1.69986 loss)
I1211 07:21:24.200953 22260 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1211 07:21:30.517462 22260 solver.cpp:218] Iteration 25200 (15.8335 iter/s, 6.31573s/100 iters), loss = 1.46789
I1211 07:21:30.517462 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:21:30.517462 22260 solver.cpp:237]     Train net output #1: loss = 1.46789 (* 1 = 1.46789 loss)
I1211 07:21:30.517462 22260 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1211 07:21:36.836982 22260 solver.cpp:218] Iteration 25300 (15.8257 iter/s, 6.31883s/100 iters), loss = 1.80732
I1211 07:21:36.836982 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:21:36.836982 22260 solver.cpp:237]     Train net output #1: loss = 1.80732 (* 1 = 1.80732 loss)
I1211 07:21:36.836982 22260 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1211 07:21:43.160904 22260 solver.cpp:218] Iteration 25400 (15.8139 iter/s, 6.32356s/100 iters), loss = 1.8923
I1211 07:21:43.160904 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:21:43.160904 22260 solver.cpp:237]     Train net output #1: loss = 1.8923 (* 1 = 1.8923 loss)
I1211 07:21:43.160904 22260 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1211 07:21:49.167325 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:21:49.415855 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25500.caffemodel
I1211 07:21:49.431859 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_25500.solverstate
I1211 07:21:49.436856 22260 solver.cpp:330] Iteration 25500, Testing net (#0)
I1211 07:21:49.436856 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:21:50.949965 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:21:51.009968 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3206
I1211 07:21:51.009968 22260 solver.cpp:397]     Test net output #1: loss = 3.00597 (* 1 = 3.00597 loss)
I1211 07:21:51.070971 22260 solver.cpp:218] Iteration 25500 (12.6421 iter/s, 7.91009s/100 iters), loss = 2.06671
I1211 07:21:51.070971 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:21:51.070971 22260 solver.cpp:237]     Train net output #1: loss = 2.06671 (* 1 = 2.06671 loss)
I1211 07:21:51.070971 22260 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1211 07:21:57.398473 22260 solver.cpp:218] Iteration 25600 (15.807 iter/s, 6.32632s/100 iters), loss = 1.55364
I1211 07:21:57.398473 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:21:57.398473 22260 solver.cpp:237]     Train net output #1: loss = 1.55364 (* 1 = 1.55364 loss)
I1211 07:21:57.398473 22260 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1211 07:22:03.729950 22260 solver.cpp:218] Iteration 25700 (15.7929 iter/s, 6.33197s/100 iters), loss = 1.36612
I1211 07:22:03.730952 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:22:03.730952 22260 solver.cpp:237]     Train net output #1: loss = 1.36612 (* 1 = 1.36612 loss)
I1211 07:22:03.730952 22260 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1211 07:22:10.057966 22260 solver.cpp:218] Iteration 25800 (15.8054 iter/s, 6.32694s/100 iters), loss = 1.71304
I1211 07:22:10.057966 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:22:10.057966 22260 solver.cpp:237]     Train net output #1: loss = 1.71304 (* 1 = 1.71304 loss)
I1211 07:22:10.057966 22260 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1211 07:22:16.385923 22260 solver.cpp:218] Iteration 25900 (15.803 iter/s, 6.32791s/100 iters), loss = 2.03878
I1211 07:22:16.385923 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:22:16.385923 22260 solver.cpp:237]     Train net output #1: loss = 2.03878 (* 1 = 2.03878 loss)
I1211 07:22:16.385923 22260 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1211 07:22:22.402328 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:22:22.651337 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26000.caffemodel
I1211 07:22:22.666851 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26000.solverstate
I1211 07:22:22.671351 22260 solver.cpp:330] Iteration 26000, Testing net (#0)
I1211 07:22:22.671351 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:22:24.185461 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:22:24.245460 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3638
I1211 07:22:24.245460 22260 solver.cpp:397]     Test net output #1: loss = 2.54251 (* 1 = 2.54251 loss)
I1211 07:22:24.305464 22260 solver.cpp:218] Iteration 26000 (12.6278 iter/s, 7.91903s/100 iters), loss = 1.79689
I1211 07:22:24.305464 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:22:24.305464 22260 solver.cpp:237]     Train net output #1: loss = 1.79689 (* 1 = 1.79689 loss)
I1211 07:22:24.305464 22260 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1211 07:22:30.633910 22260 solver.cpp:218] Iteration 26100 (15.8025 iter/s, 6.32812s/100 iters), loss = 1.7012
I1211 07:22:30.633910 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:22:30.633910 22260 solver.cpp:237]     Train net output #1: loss = 1.7012 (* 1 = 1.7012 loss)
I1211 07:22:30.633910 22260 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1211 07:22:36.959338 22260 solver.cpp:218] Iteration 26200 (15.8118 iter/s, 6.3244s/100 iters), loss = 1.47322
I1211 07:22:36.959338 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:22:36.959338 22260 solver.cpp:237]     Train net output #1: loss = 1.47322 (* 1 = 1.47322 loss)
I1211 07:22:36.959338 22260 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1211 07:22:43.291802 22260 solver.cpp:218] Iteration 26300 (15.7929 iter/s, 6.33196s/100 iters), loss = 1.72132
I1211 07:22:43.291802 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:22:43.291802 22260 solver.cpp:237]     Train net output #1: loss = 1.72132 (* 1 = 1.72132 loss)
I1211 07:22:43.291802 22260 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1211 07:22:49.618263 22260 solver.cpp:218] Iteration 26400 (15.8068 iter/s, 6.3264s/100 iters), loss = 1.95164
I1211 07:22:49.618263 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:22:49.618263 22260 solver.cpp:237]     Train net output #1: loss = 1.95164 (* 1 = 1.95164 loss)
I1211 07:22:49.618263 22260 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1211 07:22:55.630759 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:22:55.880780 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26500.caffemodel
I1211 07:22:55.896780 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_26500.solverstate
I1211 07:22:55.900780 22260 solver.cpp:330] Iteration 26500, Testing net (#0)
I1211 07:22:55.900780 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:22:57.411886 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:22:57.472390 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3569
I1211 07:22:57.472390 22260 solver.cpp:397]     Test net output #1: loss = 2.64647 (* 1 = 2.64647 loss)
I1211 07:22:57.532894 22260 solver.cpp:218] Iteration 26500 (12.636 iter/s, 7.91387s/100 iters), loss = 1.65191
I1211 07:22:57.532894 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:22:57.532894 22260 solver.cpp:237]     Train net output #1: loss = 1.65191 (* 1 = 1.65191 loss)
I1211 07:22:57.532894 22260 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1211 07:23:03.860373 22260 solver.cpp:218] Iteration 26600 (15.8044 iter/s, 6.32736s/100 iters), loss = 1.52531
I1211 07:23:03.860373 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:23:03.860373 22260 solver.cpp:237]     Train net output #1: loss = 1.52531 (* 1 = 1.52531 loss)
I1211 07:23:03.860373 22260 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1211 07:23:10.182932 22260 solver.cpp:218] Iteration 26700 (15.8167 iter/s, 6.32243s/100 iters), loss = 1.47066
I1211 07:23:10.182932 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:23:10.182932 22260 solver.cpp:237]     Train net output #1: loss = 1.47066 (* 1 = 1.47066 loss)
I1211 07:23:10.182932 22260 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1211 07:23:16.504431 22260 solver.cpp:218] Iteration 26800 (15.8214 iter/s, 6.32056s/100 iters), loss = 1.58028
I1211 07:23:16.504431 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:23:16.504431 22260 solver.cpp:237]     Train net output #1: loss = 1.58028 (* 1 = 1.58028 loss)
I1211 07:23:16.504431 22260 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1211 07:23:22.824914 22260 solver.cpp:218] Iteration 26900 (15.8213 iter/s, 6.3206s/100 iters), loss = 1.90841
I1211 07:23:22.824914 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:23:22.824914 22260 solver.cpp:237]     Train net output #1: loss = 1.90841 (* 1 = 1.90841 loss)
I1211 07:23:22.824914 22260 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1211 07:23:28.837357 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:23:29.089377 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27000.caffemodel
I1211 07:23:29.104377 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27000.solverstate
I1211 07:23:29.108377 22260 solver.cpp:330] Iteration 27000, Testing net (#0)
I1211 07:23:29.108377 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:23:30.620476 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:23:30.680480 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3715
I1211 07:23:30.680480 22260 solver.cpp:397]     Test net output #1: loss = 2.58098 (* 1 = 2.58098 loss)
I1211 07:23:30.740479 22260 solver.cpp:218] Iteration 27000 (12.6339 iter/s, 7.91522s/100 iters), loss = 1.71214
I1211 07:23:30.741479 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:23:30.741479 22260 solver.cpp:237]     Train net output #1: loss = 1.71214 (* 1 = 1.71214 loss)
I1211 07:23:30.741479 22260 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1211 07:23:37.059968 22260 solver.cpp:218] Iteration 27100 (15.8259 iter/s, 6.31875s/100 iters), loss = 1.68601
I1211 07:23:37.059968 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:23:37.059968 22260 solver.cpp:237]     Train net output #1: loss = 1.68601 (* 1 = 1.68601 loss)
I1211 07:23:37.059968 22260 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1211 07:23:43.385423 22260 solver.cpp:218] Iteration 27200 (15.8102 iter/s, 6.32502s/100 iters), loss = 1.49431
I1211 07:23:43.385423 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:23:43.385423 22260 solver.cpp:237]     Train net output #1: loss = 1.49431 (* 1 = 1.49431 loss)
I1211 07:23:43.385423 22260 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1211 07:23:49.712944 22260 solver.cpp:218] Iteration 27300 (15.8049 iter/s, 6.32717s/100 iters), loss = 1.79753
I1211 07:23:49.712944 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:23:49.712944 22260 solver.cpp:237]     Train net output #1: loss = 1.79753 (* 1 = 1.79753 loss)
I1211 07:23:49.712944 22260 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1211 07:23:56.034384 22260 solver.cpp:218] Iteration 27400 (15.82 iter/s, 6.3211s/100 iters), loss = 1.78958
I1211 07:23:56.034384 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:23:56.034384 22260 solver.cpp:237]     Train net output #1: loss = 1.78958 (* 1 = 1.78958 loss)
I1211 07:23:56.034384 22260 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1211 07:24:02.048830 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:24:02.298841 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27500.caffemodel
I1211 07:24:02.314842 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_27500.solverstate
I1211 07:24:02.318841 22260 solver.cpp:330] Iteration 27500, Testing net (#0)
I1211 07:24:02.319842 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:24:03.832940 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:24:03.892953 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3404
I1211 07:24:03.892953 22260 solver.cpp:397]     Test net output #1: loss = 2.69744 (* 1 = 2.69744 loss)
I1211 07:24:03.953955 22260 solver.cpp:218] Iteration 27500 (12.6281 iter/s, 7.91883s/100 iters), loss = 1.75927
I1211 07:24:03.953955 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:24:03.953955 22260 solver.cpp:237]     Train net output #1: loss = 1.75927 (* 1 = 1.75927 loss)
I1211 07:24:03.953955 22260 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1211 07:24:10.281946 22260 solver.cpp:218] Iteration 27600 (15.805 iter/s, 6.32711s/100 iters), loss = 1.68674
I1211 07:24:10.281946 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:24:10.281946 22260 solver.cpp:237]     Train net output #1: loss = 1.68674 (* 1 = 1.68674 loss)
I1211 07:24:10.281946 22260 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1211 07:24:16.610991 22260 solver.cpp:218] Iteration 27700 (15.7995 iter/s, 6.32932s/100 iters), loss = 1.51119
I1211 07:24:16.610991 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:24:16.610991 22260 solver.cpp:237]     Train net output #1: loss = 1.51119 (* 1 = 1.51119 loss)
I1211 07:24:16.610991 22260 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1211 07:24:22.938477 22260 solver.cpp:218] Iteration 27800 (15.8052 iter/s, 6.32705s/100 iters), loss = 1.77306
I1211 07:24:22.939477 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:24:22.939477 22260 solver.cpp:237]     Train net output #1: loss = 1.77306 (* 1 = 1.77306 loss)
I1211 07:24:22.939477 22260 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1211 07:24:29.269979 22260 solver.cpp:218] Iteration 27900 (15.7973 iter/s, 6.33019s/100 iters), loss = 1.91984
I1211 07:24:29.269979 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:24:29.269979 22260 solver.cpp:237]     Train net output #1: loss = 1.91984 (* 1 = 1.91984 loss)
I1211 07:24:29.269979 22260 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1211 07:24:35.284438 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:24:35.533453 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28000.caffemodel
I1211 07:24:35.548457 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28000.solverstate
I1211 07:24:35.552958 22260 solver.cpp:330] Iteration 28000, Testing net (#0)
I1211 07:24:35.552958 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:24:37.062577 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:24:37.122581 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3388
I1211 07:24:37.122581 22260 solver.cpp:397]     Test net output #1: loss = 2.65113 (* 1 = 2.65113 loss)
I1211 07:24:37.183586 22260 solver.cpp:218] Iteration 28000 (12.636 iter/s, 7.91389s/100 iters), loss = 1.69582
I1211 07:24:37.183586 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:24:37.183586 22260 solver.cpp:237]     Train net output #1: loss = 1.69582 (* 1 = 1.69582 loss)
I1211 07:24:37.183586 22260 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1211 07:24:43.516021 22260 solver.cpp:218] Iteration 28100 (15.7933 iter/s, 6.33179s/100 iters), loss = 1.72554
I1211 07:24:43.516021 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:24:43.516021 22260 solver.cpp:237]     Train net output #1: loss = 1.72554 (* 1 = 1.72554 loss)
I1211 07:24:43.516021 22260 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1211 07:24:49.845614 22260 solver.cpp:218] Iteration 28200 (15.8004 iter/s, 6.32896s/100 iters), loss = 1.36628
I1211 07:24:49.845614 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:24:49.845614 22260 solver.cpp:237]     Train net output #1: loss = 1.36628 (* 1 = 1.36628 loss)
I1211 07:24:49.845614 22260 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1211 07:24:56.185187 22260 solver.cpp:218] Iteration 28300 (15.7749 iter/s, 6.33919s/100 iters), loss = 1.65293
I1211 07:24:56.185187 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:24:56.185187 22260 solver.cpp:237]     Train net output #1: loss = 1.65293 (* 1 = 1.65293 loss)
I1211 07:24:56.185187 22260 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1211 07:25:02.524649 22260 solver.cpp:218] Iteration 28400 (15.775 iter/s, 6.33915s/100 iters), loss = 1.89228
I1211 07:25:02.524649 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:25:02.524649 22260 solver.cpp:237]     Train net output #1: loss = 1.89228 (* 1 = 1.89228 loss)
I1211 07:25:02.524649 22260 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1211 07:25:08.553148 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:25:08.803164 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28500.caffemodel
I1211 07:25:08.818162 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_28500.solverstate
I1211 07:25:08.822162 22260 solver.cpp:330] Iteration 28500, Testing net (#0)
I1211 07:25:08.822162 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:25:10.337309 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:25:10.396314 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3907
I1211 07:25:10.396314 22260 solver.cpp:397]     Test net output #1: loss = 2.38239 (* 1 = 2.38239 loss)
I1211 07:25:10.458318 22260 solver.cpp:218] Iteration 28500 (12.6061 iter/s, 7.93265s/100 iters), loss = 1.60494
I1211 07:25:10.458318 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:25:10.458318 22260 solver.cpp:237]     Train net output #1: loss = 1.60494 (* 1 = 1.60494 loss)
I1211 07:25:10.458318 22260 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1211 07:25:16.790840 22260 solver.cpp:218] Iteration 28600 (15.792 iter/s, 6.33233s/100 iters), loss = 1.66328
I1211 07:25:16.790840 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:25:16.790840 22260 solver.cpp:237]     Train net output #1: loss = 1.66328 (* 1 = 1.66328 loss)
I1211 07:25:16.790840 22260 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1211 07:25:23.128373 22260 solver.cpp:218] Iteration 28700 (15.7784 iter/s, 6.33776s/100 iters), loss = 1.38634
I1211 07:25:23.128373 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:25:23.128373 22260 solver.cpp:237]     Train net output #1: loss = 1.38634 (* 1 = 1.38634 loss)
I1211 07:25:23.128373 22260 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1211 07:25:29.462354 22260 solver.cpp:218] Iteration 28800 (15.7903 iter/s, 6.33299s/100 iters), loss = 1.6508
I1211 07:25:29.462354 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:25:29.462354 22260 solver.cpp:237]     Train net output #1: loss = 1.6508 (* 1 = 1.6508 loss)
I1211 07:25:29.462354 22260 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1211 07:25:35.796298 22260 solver.cpp:218] Iteration 28900 (15.7892 iter/s, 6.33344s/100 iters), loss = 1.7388
I1211 07:25:35.796298 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:25:35.796298 22260 solver.cpp:237]     Train net output #1: loss = 1.7388 (* 1 = 1.7388 loss)
I1211 07:25:35.796298 22260 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1211 07:25:41.819712 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:25:42.070726 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29000.caffemodel
I1211 07:25:42.085726 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29000.solverstate
I1211 07:25:42.089727 22260 solver.cpp:330] Iteration 29000, Testing net (#0)
I1211 07:25:42.089727 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:25:43.603847 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:25:43.664350 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3186
I1211 07:25:43.664350 22260 solver.cpp:397]     Test net output #1: loss = 3.03287 (* 1 = 3.03287 loss)
I1211 07:25:43.725853 22260 solver.cpp:218] Iteration 29000 (12.6115 iter/s, 7.92928s/100 iters), loss = 1.84913
I1211 07:25:43.725853 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:25:43.725853 22260 solver.cpp:237]     Train net output #1: loss = 1.84913 (* 1 = 1.84913 loss)
I1211 07:25:43.725853 22260 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1211 07:25:50.066313 22260 solver.cpp:218] Iteration 29100 (15.7731 iter/s, 6.33989s/100 iters), loss = 1.50985
I1211 07:25:50.066313 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:25:50.066313 22260 solver.cpp:237]     Train net output #1: loss = 1.50985 (* 1 = 1.50985 loss)
I1211 07:25:50.066313 22260 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1211 07:25:56.399749 22260 solver.cpp:218] Iteration 29200 (15.7906 iter/s, 6.33286s/100 iters), loss = 1.28082
I1211 07:25:56.399749 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:25:56.399749 22260 solver.cpp:237]     Train net output #1: loss = 1.28082 (* 1 = 1.28082 loss)
I1211 07:25:56.399749 22260 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1211 07:26:02.735239 22260 solver.cpp:218] Iteration 29300 (15.7848 iter/s, 6.33519s/100 iters), loss = 1.90391
I1211 07:26:02.735239 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:26:02.735239 22260 solver.cpp:237]     Train net output #1: loss = 1.90391 (* 1 = 1.90391 loss)
I1211 07:26:02.735239 22260 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1211 07:26:09.069672 22260 solver.cpp:218] Iteration 29400 (15.7869 iter/s, 6.33437s/100 iters), loss = 1.76653
I1211 07:26:09.069672 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:26:09.069672 22260 solver.cpp:237]     Train net output #1: loss = 1.76653 (* 1 = 1.76653 loss)
I1211 07:26:09.069672 22260 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1211 07:26:15.093109 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:26:15.343118 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29500.caffemodel
I1211 07:26:15.357122 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_29500.solverstate
I1211 07:26:15.361623 22260 solver.cpp:330] Iteration 29500, Testing net (#0)
I1211 07:26:15.361623 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:26:16.872253 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:26:16.933254 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3686
I1211 07:26:16.933254 22260 solver.cpp:397]     Test net output #1: loss = 2.61609 (* 1 = 2.61609 loss)
I1211 07:26:16.993258 22260 solver.cpp:218] Iteration 29500 (12.6222 iter/s, 7.92257s/100 iters), loss = 1.62404
I1211 07:26:16.993258 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:26:16.993258 22260 solver.cpp:237]     Train net output #1: loss = 1.62404 (* 1 = 1.62404 loss)
I1211 07:26:16.993258 22260 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1211 07:26:23.318718 22260 solver.cpp:218] Iteration 29600 (15.8086 iter/s, 6.32568s/100 iters), loss = 1.683
I1211 07:26:23.318718 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:26:23.318718 22260 solver.cpp:237]     Train net output #1: loss = 1.683 (* 1 = 1.683 loss)
I1211 07:26:23.318718 22260 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1211 07:26:29.658232 22260 solver.cpp:218] Iteration 29700 (15.7761 iter/s, 6.33868s/100 iters), loss = 1.42819
I1211 07:26:29.658232 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:26:29.658232 22260 solver.cpp:237]     Train net output #1: loss = 1.42819 (* 1 = 1.42819 loss)
I1211 07:26:29.658232 22260 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1211 07:26:35.992624 22260 solver.cpp:218] Iteration 29800 (15.7875 iter/s, 6.33412s/100 iters), loss = 1.81871
I1211 07:26:35.993124 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:26:35.993124 22260 solver.cpp:237]     Train net output #1: loss = 1.81871 (* 1 = 1.81871 loss)
I1211 07:26:35.993124 22260 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1211 07:26:42.335022 22260 solver.cpp:218] Iteration 29900 (15.7678 iter/s, 6.34203s/100 iters), loss = 1.84999
I1211 07:26:42.335022 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:26:42.335022 22260 solver.cpp:237]     Train net output #1: loss = 1.84999 (* 1 = 1.84999 loss)
I1211 07:26:42.335022 22260 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1211 07:26:48.345479 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:26:48.593531 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30000.caffemodel
I1211 07:26:48.609514 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30000.solverstate
I1211 07:26:48.613514 22260 solver.cpp:330] Iteration 30000, Testing net (#0)
I1211 07:26:48.613514 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:26:50.125918 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:26:50.185930 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3392
I1211 07:26:50.185930 22260 solver.cpp:397]     Test net output #1: loss = 2.72742 (* 1 = 2.72742 loss)
I1211 07:26:50.246922 22260 solver.cpp:218] Iteration 30000 (12.6408 iter/s, 7.91088s/100 iters), loss = 1.57563
I1211 07:26:50.246922 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:26:50.246922 22260 solver.cpp:237]     Train net output #1: loss = 1.57563 (* 1 = 1.57563 loss)
I1211 07:26:50.246922 22260 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1211 07:26:56.565394 22260 solver.cpp:218] Iteration 30100 (15.8254 iter/s, 6.31896s/100 iters), loss = 1.75333
I1211 07:26:56.566395 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:26:56.566395 22260 solver.cpp:237]     Train net output #1: loss = 1.75333 (* 1 = 1.75333 loss)
I1211 07:26:56.566395 22260 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1211 07:27:02.891813 22260 solver.cpp:218] Iteration 30200 (15.8084 iter/s, 6.32576s/100 iters), loss = 1.36798
I1211 07:27:02.891813 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:27:02.891813 22260 solver.cpp:237]     Train net output #1: loss = 1.36798 (* 1 = 1.36798 loss)
I1211 07:27:02.891813 22260 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1211 07:27:09.208264 22260 solver.cpp:218] Iteration 30300 (15.8343 iter/s, 6.3154s/100 iters), loss = 1.72003
I1211 07:27:09.208264 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:27:09.208264 22260 solver.cpp:237]     Train net output #1: loss = 1.72003 (* 1 = 1.72003 loss)
I1211 07:27:09.208264 22260 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1211 07:27:15.530712 22260 solver.cpp:218] Iteration 30400 (15.8174 iter/s, 6.32214s/100 iters), loss = 1.88451
I1211 07:27:15.530712 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:27:15.530712 22260 solver.cpp:237]     Train net output #1: loss = 1.88451 (* 1 = 1.88451 loss)
I1211 07:27:15.530712 22260 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1211 07:27:21.541680 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:27:21.790199 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30500.caffemodel
I1211 07:27:21.805199 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_30500.solverstate
I1211 07:27:21.809198 22260 solver.cpp:330] Iteration 30500, Testing net (#0)
I1211 07:27:21.810199 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:27:23.320292 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:27:23.380296 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3417
I1211 07:27:23.380296 22260 solver.cpp:397]     Test net output #1: loss = 2.7012 (* 1 = 2.7012 loss)
I1211 07:27:23.441798 22260 solver.cpp:218] Iteration 30500 (12.6415 iter/s, 7.91044s/100 iters), loss = 1.7466
I1211 07:27:23.441798 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:27:23.441798 22260 solver.cpp:237]     Train net output #1: loss = 1.7466 (* 1 = 1.7466 loss)
I1211 07:27:23.441798 22260 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1211 07:27:29.766786 22260 solver.cpp:218] Iteration 30600 (15.8106 iter/s, 6.32485s/100 iters), loss = 1.5464
I1211 07:27:29.766786 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:27:29.766786 22260 solver.cpp:237]     Train net output #1: loss = 1.5464 (* 1 = 1.5464 loss)
I1211 07:27:29.766786 22260 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1211 07:27:36.107201 22260 solver.cpp:218] Iteration 30700 (15.7717 iter/s, 6.34049s/100 iters), loss = 1.32578
I1211 07:27:36.107201 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 07:27:36.107201 22260 solver.cpp:237]     Train net output #1: loss = 1.32578 (* 1 = 1.32578 loss)
I1211 07:27:36.107201 22260 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1211 07:27:42.443650 22260 solver.cpp:218] Iteration 30800 (15.7844 iter/s, 6.33538s/100 iters), loss = 1.70969
I1211 07:27:42.443650 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:27:42.443650 22260 solver.cpp:237]     Train net output #1: loss = 1.70969 (* 1 = 1.70969 loss)
I1211 07:27:42.443650 22260 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1211 07:27:48.784085 22260 solver.cpp:218] Iteration 30900 (15.7728 iter/s, 6.34001s/100 iters), loss = 1.76028
I1211 07:27:48.784085 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:27:48.784085 22260 solver.cpp:237]     Train net output #1: loss = 1.76028 (* 1 = 1.76028 loss)
I1211 07:27:48.784085 22260 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1211 07:27:54.810214 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:27:55.059370 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31000.caffemodel
I1211 07:27:55.075366 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31000.solverstate
I1211 07:27:55.080376 22260 solver.cpp:330] Iteration 31000, Testing net (#0)
I1211 07:27:55.080376 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:27:56.588666 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:27:56.648690 22260 solver.cpp:397]     Test net output #0: accuracy = 0.281
I1211 07:27:56.648690 22260 solver.cpp:397]     Test net output #1: loss = 3.23606 (* 1 = 3.23606 loss)
I1211 07:27:56.708190 22260 solver.cpp:218] Iteration 31000 (12.6195 iter/s, 7.92425s/100 iters), loss = 1.71605
I1211 07:27:56.708190 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:27:56.708190 22260 solver.cpp:237]     Train net output #1: loss = 1.71605 (* 1 = 1.71605 loss)
I1211 07:27:56.708190 22260 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1211 07:28:03.039033 22260 solver.cpp:218] Iteration 31100 (15.7973 iter/s, 6.33018s/100 iters), loss = 1.68208
I1211 07:28:03.039033 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:28:03.039033 22260 solver.cpp:237]     Train net output #1: loss = 1.68208 (* 1 = 1.68208 loss)
I1211 07:28:03.039033 22260 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1211 07:28:09.371176 22260 solver.cpp:218] Iteration 31200 (15.7927 iter/s, 6.33204s/100 iters), loss = 1.51839
I1211 07:28:09.371176 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:28:09.371176 22260 solver.cpp:237]     Train net output #1: loss = 1.51839 (* 1 = 1.51839 loss)
I1211 07:28:09.372177 22260 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1211 07:28:15.703495 22260 solver.cpp:218] Iteration 31300 (15.795 iter/s, 6.33112s/100 iters), loss = 1.77312
I1211 07:28:15.703495 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:28:15.703495 22260 solver.cpp:237]     Train net output #1: loss = 1.77312 (* 1 = 1.77312 loss)
I1211 07:28:15.703495 22260 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1211 07:28:22.023857 22260 solver.cpp:218] Iteration 31400 (15.8218 iter/s, 6.3204s/100 iters), loss = 1.80375
I1211 07:28:22.023857 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:28:22.023857 22260 solver.cpp:237]     Train net output #1: loss = 1.80375 (* 1 = 1.80375 loss)
I1211 07:28:22.023857 22260 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1211 07:28:28.042296 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:28:28.292305 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31500.caffemodel
I1211 07:28:28.307811 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_31500.solverstate
I1211 07:28:28.312311 22260 solver.cpp:330] Iteration 31500, Testing net (#0)
I1211 07:28:28.312311 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:28:29.825074 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:28:29.885085 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2288
I1211 07:28:29.885085 22260 solver.cpp:397]     Test net output #1: loss = 3.56116 (* 1 = 3.56116 loss)
I1211 07:28:29.944602 22260 solver.cpp:218] Iteration 31500 (12.6255 iter/s, 7.92048s/100 iters), loss = 1.62209
I1211 07:28:29.944602 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:28:29.944602 22260 solver.cpp:237]     Train net output #1: loss = 1.62209 (* 1 = 1.62209 loss)
I1211 07:28:29.944602 22260 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1211 07:28:36.274482 22260 solver.cpp:218] Iteration 31600 (15.7996 iter/s, 6.32927s/100 iters), loss = 1.52678
I1211 07:28:36.274482 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:28:36.274482 22260 solver.cpp:237]     Train net output #1: loss = 1.52678 (* 1 = 1.52678 loss)
I1211 07:28:36.274482 22260 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1211 07:28:42.607900 22260 solver.cpp:218] Iteration 31700 (15.7909 iter/s, 6.33275s/100 iters), loss = 1.41356
I1211 07:28:42.608386 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:28:42.608386 22260 solver.cpp:237]     Train net output #1: loss = 1.41356 (* 1 = 1.41356 loss)
I1211 07:28:42.608386 22260 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1211 07:28:48.933686 22260 solver.cpp:218] Iteration 31800 (15.8105 iter/s, 6.32491s/100 iters), loss = 1.63147
I1211 07:28:48.933686 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:28:48.933686 22260 solver.cpp:237]     Train net output #1: loss = 1.63147 (* 1 = 1.63147 loss)
I1211 07:28:48.933686 22260 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1211 07:28:55.261145 22260 solver.cpp:218] Iteration 31900 (15.8042 iter/s, 6.32743s/100 iters), loss = 1.91202
I1211 07:28:55.261145 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:28:55.261145 22260 solver.cpp:237]     Train net output #1: loss = 1.91202 (* 1 = 1.91202 loss)
I1211 07:28:55.261145 22260 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1211 07:29:01.271530 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:29:01.521042 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32000.caffemodel
I1211 07:29:01.537545 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32000.solverstate
I1211 07:29:01.541546 22260 solver.cpp:330] Iteration 32000, Testing net (#0)
I1211 07:29:01.541546 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:29:03.054675 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:29:03.114679 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3462
I1211 07:29:03.114679 22260 solver.cpp:397]     Test net output #1: loss = 2.64522 (* 1 = 2.64522 loss)
I1211 07:29:03.174681 22260 solver.cpp:218] Iteration 32000 (12.637 iter/s, 7.91327s/100 iters), loss = 1.61315
I1211 07:29:03.174681 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:29:03.174681 22260 solver.cpp:237]     Train net output #1: loss = 1.61315 (* 1 = 1.61315 loss)
I1211 07:29:03.174681 22260 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1211 07:29:09.496178 22260 solver.cpp:218] Iteration 32100 (15.8212 iter/s, 6.32065s/100 iters), loss = 1.70587
I1211 07:29:09.496178 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.41
I1211 07:29:09.496178 22260 solver.cpp:237]     Train net output #1: loss = 1.70587 (* 1 = 1.70587 loss)
I1211 07:29:09.496178 22260 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1211 07:29:15.821163 22260 solver.cpp:218] Iteration 32200 (15.8107 iter/s, 6.32485s/100 iters), loss = 1.35001
I1211 07:29:15.821663 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:29:15.821663 22260 solver.cpp:237]     Train net output #1: loss = 1.35001 (* 1 = 1.35001 loss)
I1211 07:29:15.821663 22260 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1211 07:29:22.150058 22260 solver.cpp:218] Iteration 32300 (15.8027 iter/s, 6.32805s/100 iters), loss = 1.60616
I1211 07:29:22.150058 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:29:22.150058 22260 solver.cpp:237]     Train net output #1: loss = 1.60616 (* 1 = 1.60616 loss)
I1211 07:29:22.150058 22260 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1211 07:29:28.474529 22260 solver.cpp:218] Iteration 32400 (15.8125 iter/s, 6.32412s/100 iters), loss = 1.80698
I1211 07:29:28.474529 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:29:28.474529 22260 solver.cpp:237]     Train net output #1: loss = 1.80698 (* 1 = 1.80698 loss)
I1211 07:29:28.474529 22260 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1211 07:29:34.495007 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:29:34.744040 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32500.caffemodel
I1211 07:29:34.759040 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_32500.solverstate
I1211 07:29:34.763041 22260 solver.cpp:330] Iteration 32500, Testing net (#0)
I1211 07:29:34.763041 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:29:36.277088 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:29:36.336091 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3013
I1211 07:29:36.337092 22260 solver.cpp:397]     Test net output #1: loss = 2.95683 (* 1 = 2.95683 loss)
I1211 07:29:36.397091 22260 solver.cpp:218] Iteration 32500 (12.6228 iter/s, 7.92219s/100 iters), loss = 1.59463
I1211 07:29:36.397091 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:29:36.397091 22260 solver.cpp:237]     Train net output #1: loss = 1.59463 (* 1 = 1.59463 loss)
I1211 07:29:36.397091 22260 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1211 07:29:42.714035 22260 solver.cpp:218] Iteration 32600 (15.8319 iter/s, 6.31637s/100 iters), loss = 1.78377
I1211 07:29:42.714035 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:29:42.714035 22260 solver.cpp:237]     Train net output #1: loss = 1.78377 (* 1 = 1.78377 loss)
I1211 07:29:42.714035 22260 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1211 07:29:49.027930 22260 solver.cpp:218] Iteration 32700 (15.8383 iter/s, 6.3138s/100 iters), loss = 1.52546
I1211 07:29:49.027930 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:29:49.027930 22260 solver.cpp:237]     Train net output #1: loss = 1.52546 (* 1 = 1.52546 loss)
I1211 07:29:49.027930 22260 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1211 07:29:55.340385 22260 solver.cpp:218] Iteration 32800 (15.8437 iter/s, 6.31166s/100 iters), loss = 1.85183
I1211 07:29:55.340385 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:29:55.340385 22260 solver.cpp:237]     Train net output #1: loss = 1.85183 (* 1 = 1.85183 loss)
I1211 07:29:55.340385 22260 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1211 07:30:01.660840 22260 solver.cpp:218] Iteration 32900 (15.8228 iter/s, 6.31999s/100 iters), loss = 1.90585
I1211 07:30:01.660840 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:30:01.660840 22260 solver.cpp:237]     Train net output #1: loss = 1.90585 (* 1 = 1.90585 loss)
I1211 07:30:01.660840 22260 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1211 07:30:07.670253 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:30:07.919267 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33000.caffemodel
I1211 07:30:07.934270 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33000.solverstate
I1211 07:30:07.938271 22260 solver.cpp:330] Iteration 33000, Testing net (#0)
I1211 07:30:07.938271 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:30:09.450376 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:30:09.510375 22260 solver.cpp:397]     Test net output #0: accuracy = 0.4155
I1211 07:30:09.510375 22260 solver.cpp:397]     Test net output #1: loss = 2.21973 (* 1 = 2.21973 loss)
I1211 07:30:09.571382 22260 solver.cpp:218] Iteration 33000 (12.6419 iter/s, 7.9102s/100 iters), loss = 1.53142
I1211 07:30:09.571382 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:30:09.571382 22260 solver.cpp:237]     Train net output #1: loss = 1.53142 (* 1 = 1.53142 loss)
I1211 07:30:09.571382 22260 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1211 07:30:15.891846 22260 solver.cpp:218] Iteration 33100 (15.8211 iter/s, 6.32069s/100 iters), loss = 1.6014
I1211 07:30:15.891846 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:30:15.891846 22260 solver.cpp:237]     Train net output #1: loss = 1.6014 (* 1 = 1.6014 loss)
I1211 07:30:15.891846 22260 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1211 07:30:22.218355 22260 solver.cpp:218] Iteration 33200 (15.8098 iter/s, 6.3252s/100 iters), loss = 1.33058
I1211 07:30:22.218355 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:30:22.218355 22260 solver.cpp:237]     Train net output #1: loss = 1.33058 (* 1 = 1.33058 loss)
I1211 07:30:22.218355 22260 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1211 07:30:28.539921 22260 solver.cpp:218] Iteration 33300 (15.8185 iter/s, 6.32169s/100 iters), loss = 1.81631
I1211 07:30:28.539921 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:30:28.539921 22260 solver.cpp:237]     Train net output #1: loss = 1.81631 (* 1 = 1.81631 loss)
I1211 07:30:28.539921 22260 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1211 07:30:34.860414 22260 solver.cpp:218] Iteration 33400 (15.8225 iter/s, 6.3201s/100 iters), loss = 1.98294
I1211 07:30:34.860414 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:30:34.860414 22260 solver.cpp:237]     Train net output #1: loss = 1.98294 (* 1 = 1.98294 loss)
I1211 07:30:34.860414 22260 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1211 07:30:40.869904 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:30:41.119418 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33500.caffemodel
I1211 07:30:41.133922 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_33500.solverstate
I1211 07:30:41.138924 22260 solver.cpp:330] Iteration 33500, Testing net (#0)
I1211 07:30:41.138924 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:30:42.653029 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:30:42.713029 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3212
I1211 07:30:42.713029 22260 solver.cpp:397]     Test net output #1: loss = 2.78193 (* 1 = 2.78193 loss)
I1211 07:30:42.773039 22260 solver.cpp:218] Iteration 33500 (12.6391 iter/s, 7.91194s/100 iters), loss = 1.68978
I1211 07:30:42.773039 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:30:42.773039 22260 solver.cpp:237]     Train net output #1: loss = 1.68978 (* 1 = 1.68978 loss)
I1211 07:30:42.773039 22260 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1211 07:30:49.100479 22260 solver.cpp:218] Iteration 33600 (15.8062 iter/s, 6.32662s/100 iters), loss = 1.63039
I1211 07:30:49.100479 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:30:49.100479 22260 solver.cpp:237]     Train net output #1: loss = 1.63039 (* 1 = 1.63039 loss)
I1211 07:30:49.100479 22260 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1211 07:30:55.423475 22260 solver.cpp:218] Iteration 33700 (15.8163 iter/s, 6.3226s/100 iters), loss = 1.33617
I1211 07:30:55.423475 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 07:30:55.423475 22260 solver.cpp:237]     Train net output #1: loss = 1.33617 (* 1 = 1.33617 loss)
I1211 07:30:55.423475 22260 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1211 07:31:01.742496 22260 solver.cpp:218] Iteration 33800 (15.8263 iter/s, 6.3186s/100 iters), loss = 1.73228
I1211 07:31:01.742496 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:31:01.742496 22260 solver.cpp:237]     Train net output #1: loss = 1.73228 (* 1 = 1.73228 loss)
I1211 07:31:01.742496 22260 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1211 07:31:08.066992 22260 solver.cpp:218] Iteration 33900 (15.8121 iter/s, 6.32427s/100 iters), loss = 1.83458
I1211 07:31:08.066992 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:31:08.066992 22260 solver.cpp:237]     Train net output #1: loss = 1.83458 (* 1 = 1.83458 loss)
I1211 07:31:08.066992 22260 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1211 07:31:14.084367 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:31:14.332391 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34000.caffemodel
I1211 07:31:14.347403 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34000.solverstate
I1211 07:31:14.351904 22260 solver.cpp:330] Iteration 34000, Testing net (#0)
I1211 07:31:14.352404 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:31:15.864523 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:31:15.924520 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3182
I1211 07:31:15.924520 22260 solver.cpp:397]     Test net output #1: loss = 2.93254 (* 1 = 2.93254 loss)
I1211 07:31:15.985524 22260 solver.cpp:218] Iteration 34000 (12.6295 iter/s, 7.91795s/100 iters), loss = 1.6585
I1211 07:31:15.985524 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:31:15.985524 22260 solver.cpp:237]     Train net output #1: loss = 1.6585 (* 1 = 1.6585 loss)
I1211 07:31:15.985524 22260 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1211 07:31:22.319018 22260 solver.cpp:218] Iteration 34100 (15.7909 iter/s, 6.33278s/100 iters), loss = 1.59928
I1211 07:31:22.319018 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:31:22.319018 22260 solver.cpp:237]     Train net output #1: loss = 1.59928 (* 1 = 1.59928 loss)
I1211 07:31:22.319018 22260 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1211 07:31:28.648035 22260 solver.cpp:218] Iteration 34200 (15.8012 iter/s, 6.32862s/100 iters), loss = 1.43413
I1211 07:31:28.648035 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:31:28.648035 22260 solver.cpp:237]     Train net output #1: loss = 1.43413 (* 1 = 1.43413 loss)
I1211 07:31:28.648035 22260 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1211 07:31:34.973991 22260 solver.cpp:218] Iteration 34300 (15.8071 iter/s, 6.32628s/100 iters), loss = 1.70563
I1211 07:31:34.973991 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:31:34.973991 22260 solver.cpp:237]     Train net output #1: loss = 1.70563 (* 1 = 1.70563 loss)
I1211 07:31:34.973991 22260 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1211 07:31:41.291414 22260 solver.cpp:218] Iteration 34400 (15.8306 iter/s, 6.31689s/100 iters), loss = 1.69074
I1211 07:31:41.291414 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:31:41.291414 22260 solver.cpp:237]     Train net output #1: loss = 1.69074 (* 1 = 1.69074 loss)
I1211 07:31:41.291414 22260 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1211 07:31:47.297886 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:31:47.547902 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34500.caffemodel
I1211 07:31:47.562906 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_34500.solverstate
I1211 07:31:47.566905 22260 solver.cpp:330] Iteration 34500, Testing net (#0)
I1211 07:31:47.566905 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:31:49.079993 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:31:49.139991 22260 solver.cpp:397]     Test net output #0: accuracy = 0.266
I1211 07:31:49.139991 22260 solver.cpp:397]     Test net output #1: loss = 3.24521 (* 1 = 3.24521 loss)
I1211 07:31:49.199998 22260 solver.cpp:218] Iteration 34500 (12.6452 iter/s, 7.90817s/100 iters), loss = 1.55567
I1211 07:31:49.199998 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:31:49.199998 22260 solver.cpp:237]     Train net output #1: loss = 1.55567 (* 1 = 1.55567 loss)
I1211 07:31:49.199998 22260 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1211 07:31:55.522476 22260 solver.cpp:218] Iteration 34600 (15.8191 iter/s, 6.32149s/100 iters), loss = 1.53749
I1211 07:31:55.522476 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:31:55.522476 22260 solver.cpp:237]     Train net output #1: loss = 1.53749 (* 1 = 1.53749 loss)
I1211 07:31:55.522476 22260 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1211 07:32:01.837996 22260 solver.cpp:218] Iteration 34700 (15.8343 iter/s, 6.31539s/100 iters), loss = 1.38017
I1211 07:32:01.837996 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:32:01.837996 22260 solver.cpp:237]     Train net output #1: loss = 1.38017 (* 1 = 1.38017 loss)
I1211 07:32:01.837996 22260 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1211 07:32:08.150861 22260 solver.cpp:218] Iteration 34800 (15.8425 iter/s, 6.31215s/100 iters), loss = 1.70169
I1211 07:32:08.150861 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:32:08.150861 22260 solver.cpp:237]     Train net output #1: loss = 1.70169 (* 1 = 1.70169 loss)
I1211 07:32:08.150861 22260 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1211 07:32:14.465864 22260 solver.cpp:218] Iteration 34900 (15.8351 iter/s, 6.31507s/100 iters), loss = 1.83292
I1211 07:32:14.465864 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:32:14.465864 22260 solver.cpp:237]     Train net output #1: loss = 1.83292 (* 1 = 1.83292 loss)
I1211 07:32:14.465864 22260 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1211 07:32:20.469336 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:32:20.719360 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35000.caffemodel
I1211 07:32:20.734361 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35000.solverstate
I1211 07:32:20.739362 22260 solver.cpp:330] Iteration 35000, Testing net (#0)
I1211 07:32:20.739362 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:32:22.254472 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:32:22.314471 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3519
I1211 07:32:22.314471 22260 solver.cpp:397]     Test net output #1: loss = 2.69329 (* 1 = 2.69329 loss)
I1211 07:32:22.375478 22260 solver.cpp:218] Iteration 35000 (12.6444 iter/s, 7.90864s/100 iters), loss = 1.70905
I1211 07:32:22.375478 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:32:22.375478 22260 solver.cpp:237]     Train net output #1: loss = 1.70905 (* 1 = 1.70905 loss)
I1211 07:32:22.375478 22260 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1211 07:32:28.690883 22260 solver.cpp:218] Iteration 35100 (15.8337 iter/s, 6.31566s/100 iters), loss = 1.57293
I1211 07:32:28.690883 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:32:28.690883 22260 solver.cpp:237]     Train net output #1: loss = 1.57293 (* 1 = 1.57293 loss)
I1211 07:32:28.690883 22260 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1211 07:32:35.016368 22260 solver.cpp:218] Iteration 35200 (15.8117 iter/s, 6.32443s/100 iters), loss = 1.30895
I1211 07:32:35.016368 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:32:35.016368 22260 solver.cpp:237]     Train net output #1: loss = 1.30895 (* 1 = 1.30895 loss)
I1211 07:32:35.016368 22260 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1211 07:32:41.332805 22260 solver.cpp:218] Iteration 35300 (15.831 iter/s, 6.3167s/100 iters), loss = 1.80458
I1211 07:32:41.332805 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:32:41.332805 22260 solver.cpp:237]     Train net output #1: loss = 1.80458 (* 1 = 1.80458 loss)
I1211 07:32:41.332805 22260 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1211 07:32:47.659303 22260 solver.cpp:218] Iteration 35400 (15.8094 iter/s, 6.32536s/100 iters), loss = 1.83843
I1211 07:32:47.659303 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:32:47.659303 22260 solver.cpp:237]     Train net output #1: loss = 1.83843 (* 1 = 1.83843 loss)
I1211 07:32:47.659303 22260 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1211 07:32:53.668756 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:32:53.917764 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35500.caffemodel
I1211 07:32:53.932765 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_35500.solverstate
I1211 07:32:53.937770 22260 solver.cpp:330] Iteration 35500, Testing net (#0)
I1211 07:32:53.937770 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:32:55.452033 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:32:55.512038 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3306
I1211 07:32:55.512038 22260 solver.cpp:397]     Test net output #1: loss = 2.75367 (* 1 = 2.75367 loss)
I1211 07:32:55.574043 22260 solver.cpp:218] Iteration 35500 (12.6352 iter/s, 7.91439s/100 iters), loss = 1.45618
I1211 07:32:55.574043 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:32:55.574043 22260 solver.cpp:237]     Train net output #1: loss = 1.45618 (* 1 = 1.45618 loss)
I1211 07:32:55.574043 22260 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1211 07:33:01.915405 22260 solver.cpp:218] Iteration 35600 (15.7708 iter/s, 6.34085s/100 iters), loss = 1.59345
I1211 07:33:01.915405 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:33:01.915405 22260 solver.cpp:237]     Train net output #1: loss = 1.59345 (* 1 = 1.59345 loss)
I1211 07:33:01.915405 22260 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1211 07:33:08.256849 22260 solver.cpp:218] Iteration 35700 (15.7705 iter/s, 6.34095s/100 iters), loss = 1.26114
I1211 07:33:08.256849 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:33:08.256849 22260 solver.cpp:237]     Train net output #1: loss = 1.26114 (* 1 = 1.26114 loss)
I1211 07:33:08.256849 22260 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1211 07:33:14.597252 22260 solver.cpp:218] Iteration 35800 (15.7719 iter/s, 6.34041s/100 iters), loss = 1.82902
I1211 07:33:14.597252 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.43
I1211 07:33:14.597252 22260 solver.cpp:237]     Train net output #1: loss = 1.82902 (* 1 = 1.82902 loss)
I1211 07:33:14.597252 22260 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1211 07:33:20.940812 22260 solver.cpp:218] Iteration 35900 (15.7658 iter/s, 6.34283s/100 iters), loss = 1.8546
I1211 07:33:20.940812 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:33:20.940812 22260 solver.cpp:237]     Train net output #1: loss = 1.8546 (* 1 = 1.8546 loss)
I1211 07:33:20.940812 22260 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1211 07:33:26.967262 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:33:27.217273 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36000.caffemodel
I1211 07:33:27.233278 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36000.solverstate
I1211 07:33:27.238278 22260 solver.cpp:330] Iteration 36000, Testing net (#0)
I1211 07:33:27.238278 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:33:28.747397 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:33:28.807397 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2915
I1211 07:33:28.807397 22260 solver.cpp:397]     Test net output #1: loss = 3.03724 (* 1 = 3.03724 loss)
I1211 07:33:28.868402 22260 solver.cpp:218] Iteration 36000 (12.6145 iter/s, 7.92738s/100 iters), loss = 1.71132
I1211 07:33:28.868402 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:33:28.868402 22260 solver.cpp:237]     Train net output #1: loss = 1.71132 (* 1 = 1.71132 loss)
I1211 07:33:28.868402 22260 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1211 07:33:35.202839 22260 solver.cpp:218] Iteration 36100 (15.788 iter/s, 6.33394s/100 iters), loss = 1.47924
I1211 07:33:35.202839 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:33:35.202839 22260 solver.cpp:237]     Train net output #1: loss = 1.47924 (* 1 = 1.47924 loss)
I1211 07:33:35.202839 22260 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1211 07:33:41.536290 22260 solver.cpp:218] Iteration 36200 (15.7905 iter/s, 6.33291s/100 iters), loss = 1.18892
I1211 07:33:41.536290 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 07:33:41.536290 22260 solver.cpp:237]     Train net output #1: loss = 1.18892 (* 1 = 1.18892 loss)
I1211 07:33:41.536290 22260 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1211 07:33:47.869746 22260 solver.cpp:218] Iteration 36300 (15.7901 iter/s, 6.33307s/100 iters), loss = 1.74624
I1211 07:33:47.869746 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:33:47.869746 22260 solver.cpp:237]     Train net output #1: loss = 1.74624 (* 1 = 1.74624 loss)
I1211 07:33:47.869746 22260 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1211 07:33:54.196208 22260 solver.cpp:218] Iteration 36400 (15.8078 iter/s, 6.326s/100 iters), loss = 1.82913
I1211 07:33:54.196208 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:33:54.196208 22260 solver.cpp:237]     Train net output #1: loss = 1.82913 (* 1 = 1.82913 loss)
I1211 07:33:54.196208 22260 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1211 07:34:00.220690 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:34:00.468725 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36500.caffemodel
I1211 07:34:00.484725 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_36500.solverstate
I1211 07:34:00.488726 22260 solver.cpp:330] Iteration 36500, Testing net (#0)
I1211 07:34:00.488726 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:34:02.001829 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:34:02.061839 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3817
I1211 07:34:02.061839 22260 solver.cpp:397]     Test net output #1: loss = 2.46939 (* 1 = 2.46939 loss)
I1211 07:34:02.122838 22260 solver.cpp:218] Iteration 36500 (12.6167 iter/s, 7.92603s/100 iters), loss = 1.50483
I1211 07:34:02.122838 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:34:02.122838 22260 solver.cpp:237]     Train net output #1: loss = 1.50483 (* 1 = 1.50483 loss)
I1211 07:34:02.122838 22260 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1211 07:34:08.453328 22260 solver.cpp:218] Iteration 36600 (15.7969 iter/s, 6.33036s/100 iters), loss = 1.45486
I1211 07:34:08.453328 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:34:08.453328 22260 solver.cpp:237]     Train net output #1: loss = 1.45486 (* 1 = 1.45486 loss)
I1211 07:34:08.453328 22260 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1211 07:34:14.769798 22260 solver.cpp:218] Iteration 36700 (15.8322 iter/s, 6.31622s/100 iters), loss = 1.43131
I1211 07:34:14.769798 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:34:14.769798 22260 solver.cpp:237]     Train net output #1: loss = 1.43131 (* 1 = 1.43131 loss)
I1211 07:34:14.769798 22260 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1211 07:34:21.096330 22260 solver.cpp:218] Iteration 36800 (15.8083 iter/s, 6.32579s/100 iters), loss = 1.73184
I1211 07:34:21.096330 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:34:21.096330 22260 solver.cpp:237]     Train net output #1: loss = 1.73184 (* 1 = 1.73184 loss)
I1211 07:34:21.096330 22260 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1211 07:34:27.415765 22260 solver.cpp:218] Iteration 36900 (15.8254 iter/s, 6.31895s/100 iters), loss = 1.81145
I1211 07:34:27.415765 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:34:27.415765 22260 solver.cpp:237]     Train net output #1: loss = 1.81145 (* 1 = 1.81145 loss)
I1211 07:34:27.415765 22260 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1211 07:34:33.418177 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:34:33.667189 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37000.caffemodel
I1211 07:34:33.682188 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37000.solverstate
I1211 07:34:33.687695 22260 solver.cpp:330] Iteration 37000, Testing net (#0)
I1211 07:34:33.687695 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:34:35.200567 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:34:35.259569 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3508
I1211 07:34:35.260581 22260 solver.cpp:397]     Test net output #1: loss = 2.68878 (* 1 = 2.68878 loss)
I1211 07:34:35.320574 22260 solver.cpp:218] Iteration 37000 (12.6499 iter/s, 7.90522s/100 iters), loss = 1.69525
I1211 07:34:35.321573 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:34:35.321573 22260 solver.cpp:237]     Train net output #1: loss = 1.69525 (* 1 = 1.69525 loss)
I1211 07:34:35.321573 22260 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1211 07:34:41.645071 22260 solver.cpp:218] Iteration 37100 (15.8126 iter/s, 6.32406s/100 iters), loss = 1.61065
I1211 07:34:41.646071 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:34:41.646071 22260 solver.cpp:237]     Train net output #1: loss = 1.61065 (* 1 = 1.61065 loss)
I1211 07:34:41.646071 22260 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1211 07:34:47.976631 22260 solver.cpp:218] Iteration 37200 (15.7959 iter/s, 6.33075s/100 iters), loss = 1.3388
I1211 07:34:47.976631 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:34:47.976631 22260 solver.cpp:237]     Train net output #1: loss = 1.3388 (* 1 = 1.3388 loss)
I1211 07:34:47.976631 22260 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1211 07:34:54.302110 22260 solver.cpp:218] Iteration 37300 (15.8103 iter/s, 6.32499s/100 iters), loss = 1.72889
I1211 07:34:54.302110 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:34:54.302110 22260 solver.cpp:237]     Train net output #1: loss = 1.72889 (* 1 = 1.72889 loss)
I1211 07:34:54.302110 22260 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1211 07:35:00.633587 22260 solver.cpp:218] Iteration 37400 (15.7945 iter/s, 6.33133s/100 iters), loss = 1.77605
I1211 07:35:00.633587 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:35:00.633587 22260 solver.cpp:237]     Train net output #1: loss = 1.77605 (* 1 = 1.77605 loss)
I1211 07:35:00.633587 22260 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1211 07:35:06.637006 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:35:06.887519 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37500.caffemodel
I1211 07:35:06.902019 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_37500.solverstate
I1211 07:35:06.907024 22260 solver.cpp:330] Iteration 37500, Testing net (#0)
I1211 07:35:06.907024 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:35:08.417127 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:35:08.477128 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3424
I1211 07:35:08.477128 22260 solver.cpp:397]     Test net output #1: loss = 2.67864 (* 1 = 2.67864 loss)
I1211 07:35:08.537143 22260 solver.cpp:218] Iteration 37500 (12.6537 iter/s, 7.90282s/100 iters), loss = 1.74819
I1211 07:35:08.537143 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:35:08.537143 22260 solver.cpp:237]     Train net output #1: loss = 1.74819 (* 1 = 1.74819 loss)
I1211 07:35:08.537143 22260 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1211 07:35:14.883589 22260 solver.cpp:218] Iteration 37600 (15.7589 iter/s, 6.34562s/100 iters), loss = 1.6408
I1211 07:35:14.883589 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:35:14.883589 22260 solver.cpp:237]     Train net output #1: loss = 1.6408 (* 1 = 1.6408 loss)
I1211 07:35:14.883589 22260 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1211 07:35:21.220041 22260 solver.cpp:218] Iteration 37700 (15.7825 iter/s, 6.33615s/100 iters), loss = 1.56933
I1211 07:35:21.220041 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:35:21.220041 22260 solver.cpp:237]     Train net output #1: loss = 1.56933 (* 1 = 1.56933 loss)
I1211 07:35:21.220041 22260 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1211 07:35:27.556771 22260 solver.cpp:218] Iteration 37800 (15.7808 iter/s, 6.3368s/100 iters), loss = 2.0217
I1211 07:35:27.556771 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.44
I1211 07:35:27.556771 22260 solver.cpp:237]     Train net output #1: loss = 2.0217 (* 1 = 2.0217 loss)
I1211 07:35:27.556771 22260 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1211 07:35:33.896353 22260 solver.cpp:218] Iteration 37900 (15.7754 iter/s, 6.33897s/100 iters), loss = 1.80952
I1211 07:35:33.896353 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:35:33.896353 22260 solver.cpp:237]     Train net output #1: loss = 1.80952 (* 1 = 1.80952 loss)
I1211 07:35:33.896353 22260 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1211 07:35:39.922067 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:35:40.172085 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38000.caffemodel
I1211 07:35:40.187094 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38000.solverstate
I1211 07:35:40.192095 22260 solver.cpp:330] Iteration 38000, Testing net (#0)
I1211 07:35:40.192095 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:35:41.703196 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:35:41.762194 22260 solver.cpp:397]     Test net output #0: accuracy = 0.271
I1211 07:35:41.762194 22260 solver.cpp:397]     Test net output #1: loss = 3.34891 (* 1 = 3.34891 loss)
I1211 07:35:41.823202 22260 solver.cpp:218] Iteration 38000 (12.6164 iter/s, 7.92619s/100 iters), loss = 1.57603
I1211 07:35:41.823202 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:35:41.823202 22260 solver.cpp:237]     Train net output #1: loss = 1.57603 (* 1 = 1.57603 loss)
I1211 07:35:41.823202 22260 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1211 07:35:48.153710 22260 solver.cpp:218] Iteration 38100 (15.7971 iter/s, 6.33028s/100 iters), loss = 1.64659
I1211 07:35:48.153710 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:35:48.153710 22260 solver.cpp:237]     Train net output #1: loss = 1.64659 (* 1 = 1.64659 loss)
I1211 07:35:48.153710 22260 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1211 07:35:54.493144 22260 solver.cpp:218] Iteration 38200 (15.7755 iter/s, 6.33892s/100 iters), loss = 1.3065
I1211 07:35:54.493144 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:35:54.493144 22260 solver.cpp:237]     Train net output #1: loss = 1.3065 (* 1 = 1.3065 loss)
I1211 07:35:54.493144 22260 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1211 07:36:00.824642 22260 solver.cpp:218] Iteration 38300 (15.7962 iter/s, 6.33063s/100 iters), loss = 1.77545
I1211 07:36:00.824642 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:36:00.824642 22260 solver.cpp:237]     Train net output #1: loss = 1.77545 (* 1 = 1.77545 loss)
I1211 07:36:00.824642 22260 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1211 07:36:07.158159 22260 solver.cpp:218] Iteration 38400 (15.7891 iter/s, 6.3335s/100 iters), loss = 1.77124
I1211 07:36:07.158159 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:36:07.158159 22260 solver.cpp:237]     Train net output #1: loss = 1.77124 (* 1 = 1.77124 loss)
I1211 07:36:07.158159 22260 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1211 07:36:13.175140 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:36:13.423655 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38500.caffemodel
I1211 07:36:13.437655 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_38500.solverstate
I1211 07:36:13.442656 22260 solver.cpp:330] Iteration 38500, Testing net (#0)
I1211 07:36:13.442656 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:36:14.954759 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:36:15.014763 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3027
I1211 07:36:15.014763 22260 solver.cpp:397]     Test net output #1: loss = 3.02146 (* 1 = 3.02146 loss)
I1211 07:36:15.075264 22260 solver.cpp:218] Iteration 38500 (12.632 iter/s, 7.91641s/100 iters), loss = 1.73755
I1211 07:36:15.075264 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:36:15.075264 22260 solver.cpp:237]     Train net output #1: loss = 1.73755 (* 1 = 1.73755 loss)
I1211 07:36:15.075264 22260 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1211 07:36:21.405264 22260 solver.cpp:218] Iteration 38600 (15.7988 iter/s, 6.32961s/100 iters), loss = 1.59442
I1211 07:36:21.405264 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:36:21.405264 22260 solver.cpp:237]     Train net output #1: loss = 1.59442 (* 1 = 1.59442 loss)
I1211 07:36:21.405264 22260 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1211 07:36:27.738750 22260 solver.cpp:218] Iteration 38700 (15.7887 iter/s, 6.33365s/100 iters), loss = 1.42866
I1211 07:36:27.739750 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:36:27.739750 22260 solver.cpp:237]     Train net output #1: loss = 1.42866 (* 1 = 1.42866 loss)
I1211 07:36:27.739750 22260 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1211 07:36:34.075268 22260 solver.cpp:218] Iteration 38800 (15.784 iter/s, 6.33553s/100 iters), loss = 1.65176
I1211 07:36:34.075268 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:36:34.075268 22260 solver.cpp:237]     Train net output #1: loss = 1.65176 (* 1 = 1.65176 loss)
I1211 07:36:34.075268 22260 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1211 07:36:40.423645 22260 solver.cpp:218] Iteration 38900 (15.7536 iter/s, 6.34777s/100 iters), loss = 1.60498
I1211 07:36:40.423645 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:36:40.423645 22260 solver.cpp:237]     Train net output #1: loss = 1.60498 (* 1 = 1.60498 loss)
I1211 07:36:40.423645 22260 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1211 07:36:46.453088 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:36:46.702098 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39000.caffemodel
I1211 07:36:46.717099 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39000.solverstate
I1211 07:36:46.722106 22260 solver.cpp:330] Iteration 39000, Testing net (#0)
I1211 07:36:46.722106 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:36:48.234218 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:36:48.293221 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2959
I1211 07:36:48.293221 22260 solver.cpp:397]     Test net output #1: loss = 3.13218 (* 1 = 3.13218 loss)
I1211 07:36:48.353227 22260 solver.cpp:218] Iteration 39000 (12.6105 iter/s, 7.92988s/100 iters), loss = 1.5478
I1211 07:36:48.354228 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:36:48.354228 22260 solver.cpp:237]     Train net output #1: loss = 1.5478 (* 1 = 1.5478 loss)
I1211 07:36:48.354228 22260 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1211 07:36:54.682665 22260 solver.cpp:218] Iteration 39100 (15.8018 iter/s, 6.32839s/100 iters), loss = 1.57539
I1211 07:36:54.682665 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:36:54.682665 22260 solver.cpp:237]     Train net output #1: loss = 1.57539 (* 1 = 1.57539 loss)
I1211 07:36:54.682665 22260 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1211 07:37:01.022620 22260 solver.cpp:218] Iteration 39200 (15.7749 iter/s, 6.33918s/100 iters), loss = 1.29681
I1211 07:37:01.022620 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:37:01.022620 22260 solver.cpp:237]     Train net output #1: loss = 1.29681 (* 1 = 1.29681 loss)
I1211 07:37:01.022620 22260 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1211 07:37:07.352609 22260 solver.cpp:218] Iteration 39300 (15.7978 iter/s, 6.32999s/100 iters), loss = 1.67531
I1211 07:37:07.352609 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:37:07.352609 22260 solver.cpp:237]     Train net output #1: loss = 1.67531 (* 1 = 1.67531 loss)
I1211 07:37:07.352609 22260 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1211 07:37:13.691095 22260 solver.cpp:218] Iteration 39400 (15.7783 iter/s, 6.33783s/100 iters), loss = 1.81866
I1211 07:37:13.691095 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:37:13.691095 22260 solver.cpp:237]     Train net output #1: loss = 1.81866 (* 1 = 1.81866 loss)
I1211 07:37:13.691095 22260 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1211 07:37:19.716470 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:37:19.965497 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39500.caffemodel
I1211 07:37:19.980496 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_39500.solverstate
I1211 07:37:19.984498 22260 solver.cpp:330] Iteration 39500, Testing net (#0)
I1211 07:37:19.984498 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:37:21.496637 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:37:21.556641 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3367
I1211 07:37:21.556641 22260 solver.cpp:397]     Test net output #1: loss = 2.87428 (* 1 = 2.87428 loss)
I1211 07:37:21.617641 22260 solver.cpp:218] Iteration 39500 (12.6165 iter/s, 7.92616s/100 iters), loss = 1.65983
I1211 07:37:21.617641 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:37:21.617641 22260 solver.cpp:237]     Train net output #1: loss = 1.65983 (* 1 = 1.65983 loss)
I1211 07:37:21.617641 22260 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1211 07:37:27.953130 22260 solver.cpp:218] Iteration 39600 (15.7842 iter/s, 6.33544s/100 iters), loss = 1.52763
I1211 07:37:27.953130 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:37:27.953130 22260 solver.cpp:237]     Train net output #1: loss = 1.52763 (* 1 = 1.52763 loss)
I1211 07:37:27.953130 22260 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1211 07:37:34.278635 22260 solver.cpp:218] Iteration 39700 (15.8096 iter/s, 6.32525s/100 iters), loss = 1.38017
I1211 07:37:34.278635 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:37:34.278635 22260 solver.cpp:237]     Train net output #1: loss = 1.38017 (* 1 = 1.38017 loss)
I1211 07:37:34.278635 22260 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1211 07:37:40.613135 22260 solver.cpp:218] Iteration 39800 (15.789 iter/s, 6.33353s/100 iters), loss = 1.64494
I1211 07:37:40.613135 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:37:40.613135 22260 solver.cpp:237]     Train net output #1: loss = 1.64494 (* 1 = 1.64494 loss)
I1211 07:37:40.613135 22260 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1211 07:37:46.946589 22260 solver.cpp:218] Iteration 39900 (15.7906 iter/s, 6.33289s/100 iters), loss = 1.83821
I1211 07:37:46.946589 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:37:46.946589 22260 solver.cpp:237]     Train net output #1: loss = 1.83821 (* 1 = 1.83821 loss)
I1211 07:37:46.946589 22260 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1211 07:37:52.956037 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:37:53.207046 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40000.caffemodel
I1211 07:37:53.226549 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40000.solverstate
I1211 07:37:53.231048 22260 solver.cpp:330] Iteration 40000, Testing net (#0)
I1211 07:37:53.231048 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:37:54.745159 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:37:54.805157 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3504
I1211 07:37:54.805157 22260 solver.cpp:397]     Test net output #1: loss = 2.70892 (* 1 = 2.70892 loss)
I1211 07:37:54.865161 22260 solver.cpp:218] Iteration 40000 (12.6288 iter/s, 7.91842s/100 iters), loss = 1.65472
I1211 07:37:54.865161 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:37:54.865161 22260 solver.cpp:237]     Train net output #1: loss = 1.65472 (* 1 = 1.65472 loss)
I1211 07:37:54.865161 22260 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1211 07:38:01.195627 22260 solver.cpp:218] Iteration 40100 (15.7968 iter/s, 6.3304s/100 iters), loss = 1.56184
I1211 07:38:01.196627 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:38:01.196627 22260 solver.cpp:237]     Train net output #1: loss = 1.56184 (* 1 = 1.56184 loss)
I1211 07:38:01.196627 22260 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1211 07:38:07.520071 22260 solver.cpp:218] Iteration 40200 (15.8147 iter/s, 6.32324s/100 iters), loss = 1.38417
I1211 07:38:07.520071 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:38:07.520071 22260 solver.cpp:237]     Train net output #1: loss = 1.38417 (* 1 = 1.38417 loss)
I1211 07:38:07.520071 22260 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1211 07:38:13.838027 22260 solver.cpp:218] Iteration 40300 (15.8283 iter/s, 6.31778s/100 iters), loss = 1.69161
I1211 07:38:13.838027 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:38:13.838027 22260 solver.cpp:237]     Train net output #1: loss = 1.69161 (* 1 = 1.69161 loss)
I1211 07:38:13.838027 22260 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1211 07:38:20.159929 22260 solver.cpp:218] Iteration 40400 (15.8185 iter/s, 6.32169s/100 iters), loss = 1.78847
I1211 07:38:20.159929 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:38:20.159929 22260 solver.cpp:237]     Train net output #1: loss = 1.78847 (* 1 = 1.78847 loss)
I1211 07:38:20.159929 22260 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1211 07:38:26.163319 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:38:26.411326 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40500.caffemodel
I1211 07:38:26.426831 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_40500.solverstate
I1211 07:38:26.431331 22260 solver.cpp:330] Iteration 40500, Testing net (#0)
I1211 07:38:26.431831 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:38:27.944419 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:38:28.004420 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3527
I1211 07:38:28.004420 22260 solver.cpp:397]     Test net output #1: loss = 2.64411 (* 1 = 2.64411 loss)
I1211 07:38:28.064424 22260 solver.cpp:218] Iteration 40500 (12.6513 iter/s, 7.90431s/100 iters), loss = 1.51507
I1211 07:38:28.064424 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:38:28.064424 22260 solver.cpp:237]     Train net output #1: loss = 1.51507 (* 1 = 1.51507 loss)
I1211 07:38:28.064424 22260 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1211 07:38:34.388877 22260 solver.cpp:218] Iteration 40600 (15.8147 iter/s, 6.32322s/100 iters), loss = 1.69318
I1211 07:38:34.388877 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:38:34.388877 22260 solver.cpp:237]     Train net output #1: loss = 1.69318 (* 1 = 1.69318 loss)
I1211 07:38:34.388877 22260 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1211 07:38:40.712319 22260 solver.cpp:218] Iteration 40700 (15.8141 iter/s, 6.32346s/100 iters), loss = 1.46728
I1211 07:38:40.712319 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:38:40.712319 22260 solver.cpp:237]     Train net output #1: loss = 1.46728 (* 1 = 1.46728 loss)
I1211 07:38:40.712319 22260 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1211 07:38:47.040262 22260 solver.cpp:218] Iteration 40800 (15.8044 iter/s, 6.32737s/100 iters), loss = 1.73356
I1211 07:38:47.040262 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:38:47.040262 22260 solver.cpp:237]     Train net output #1: loss = 1.73356 (* 1 = 1.73356 loss)
I1211 07:38:47.040262 22260 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1211 07:38:53.363821 22260 solver.cpp:218] Iteration 40900 (15.8158 iter/s, 6.3228s/100 iters), loss = 1.77275
I1211 07:38:53.363821 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:38:53.363821 22260 solver.cpp:237]     Train net output #1: loss = 1.77275 (* 1 = 1.77275 loss)
I1211 07:38:53.363821 22260 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1211 07:38:59.385915 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:38:59.637539 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41000.caffemodel
I1211 07:38:59.652042 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41000.solverstate
I1211 07:38:59.657043 22260 solver.cpp:330] Iteration 41000, Testing net (#0)
I1211 07:38:59.657043 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:39:01.172004 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:39:01.230999 22260 solver.cpp:397]     Test net output #0: accuracy = 0.441
I1211 07:39:01.230999 22260 solver.cpp:397]     Test net output #1: loss = 2.16436 (* 1 = 2.16436 loss)
I1211 07:39:01.292039 22260 solver.cpp:218] Iteration 41000 (12.6139 iter/s, 7.92775s/100 iters), loss = 1.68779
I1211 07:39:01.292039 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:39:01.292039 22260 solver.cpp:237]     Train net output #1: loss = 1.68779 (* 1 = 1.68779 loss)
I1211 07:39:01.292039 22260 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1211 07:39:07.625351 22260 solver.cpp:218] Iteration 41100 (15.7887 iter/s, 6.33363s/100 iters), loss = 1.51513
I1211 07:39:07.625351 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:39:07.625351 22260 solver.cpp:237]     Train net output #1: loss = 1.51513 (* 1 = 1.51513 loss)
I1211 07:39:07.625351 22260 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1211 07:39:13.958395 22260 solver.cpp:218] Iteration 41200 (15.7929 iter/s, 6.33195s/100 iters), loss = 1.50831
I1211 07:39:13.958395 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:39:13.958395 22260 solver.cpp:237]     Train net output #1: loss = 1.50831 (* 1 = 1.50831 loss)
I1211 07:39:13.958395 22260 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1211 07:39:20.286860 22260 solver.cpp:218] Iteration 41300 (15.8017 iter/s, 6.32844s/100 iters), loss = 1.69484
I1211 07:39:20.286860 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:39:20.286860 22260 solver.cpp:237]     Train net output #1: loss = 1.69484 (* 1 = 1.69484 loss)
I1211 07:39:20.286860 22260 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1211 07:39:26.612429 22260 solver.cpp:218] Iteration 41400 (15.8104 iter/s, 6.32495s/100 iters), loss = 1.71882
I1211 07:39:26.612429 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:39:26.612429 22260 solver.cpp:237]     Train net output #1: loss = 1.71882 (* 1 = 1.71882 loss)
I1211 07:39:26.612429 22260 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1211 07:39:32.632863 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:39:32.883873 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41500.caffemodel
I1211 07:39:32.897873 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_41500.solverstate
I1211 07:39:32.902874 22260 solver.cpp:330] Iteration 41500, Testing net (#0)
I1211 07:39:32.902874 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:39:34.416489 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:39:34.476001 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3564
I1211 07:39:34.476001 22260 solver.cpp:397]     Test net output #1: loss = 2.54269 (* 1 = 2.54269 loss)
I1211 07:39:34.536000 22260 solver.cpp:218] Iteration 41500 (12.6203 iter/s, 7.92376s/100 iters), loss = 1.62128
I1211 07:39:34.537000 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:39:34.537000 22260 solver.cpp:237]     Train net output #1: loss = 1.62128 (* 1 = 1.62128 loss)
I1211 07:39:34.537000 22260 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1211 07:39:40.855746 22260 solver.cpp:218] Iteration 41600 (15.825 iter/s, 6.31912s/100 iters), loss = 1.59102
I1211 07:39:40.855746 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:39:40.855746 22260 solver.cpp:237]     Train net output #1: loss = 1.59102 (* 1 = 1.59102 loss)
I1211 07:39:40.855746 22260 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1211 07:39:47.173259 22260 solver.cpp:218] Iteration 41700 (15.8299 iter/s, 6.31716s/100 iters), loss = 1.3476
I1211 07:39:47.173259 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:39:47.173259 22260 solver.cpp:237]     Train net output #1: loss = 1.3476 (* 1 = 1.3476 loss)
I1211 07:39:47.173259 22260 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1211 07:39:53.498360 22260 solver.cpp:218] Iteration 41800 (15.8115 iter/s, 6.32452s/100 iters), loss = 1.81886
I1211 07:39:53.498360 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:39:53.498360 22260 solver.cpp:237]     Train net output #1: loss = 1.81886 (* 1 = 1.81886 loss)
I1211 07:39:53.498360 22260 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1211 07:39:59.823793 22260 solver.cpp:218] Iteration 41900 (15.8117 iter/s, 6.32444s/100 iters), loss = 1.72434
I1211 07:39:59.823793 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:39:59.823793 22260 solver.cpp:237]     Train net output #1: loss = 1.72434 (* 1 = 1.72434 loss)
I1211 07:39:59.823793 22260 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1211 07:40:05.834259 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:40:06.084290 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42000.caffemodel
I1211 07:40:06.099290 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42000.solverstate
I1211 07:40:06.103291 22260 solver.cpp:330] Iteration 42000, Testing net (#0)
I1211 07:40:06.103291 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:40:07.616394 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:40:07.676398 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3463
I1211 07:40:07.676398 22260 solver.cpp:397]     Test net output #1: loss = 2.74814 (* 1 = 2.74814 loss)
I1211 07:40:07.737401 22260 solver.cpp:218] Iteration 42000 (12.6363 iter/s, 7.91372s/100 iters), loss = 1.47206
I1211 07:40:07.737401 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:40:07.737401 22260 solver.cpp:237]     Train net output #1: loss = 1.47206 (* 1 = 1.47206 loss)
I1211 07:40:07.737401 22260 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1211 07:40:14.065830 22260 solver.cpp:218] Iteration 42100 (15.8036 iter/s, 6.32769s/100 iters), loss = 1.55055
I1211 07:40:14.065830 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:40:14.065830 22260 solver.cpp:237]     Train net output #1: loss = 1.55055 (* 1 = 1.55055 loss)
I1211 07:40:14.065830 22260 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1211 07:40:20.393285 22260 solver.cpp:218] Iteration 42200 (15.806 iter/s, 6.3267s/100 iters), loss = 1.4313
I1211 07:40:20.393285 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:40:20.393285 22260 solver.cpp:237]     Train net output #1: loss = 1.4313 (* 1 = 1.4313 loss)
I1211 07:40:20.393285 22260 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1211 07:40:26.724714 22260 solver.cpp:218] Iteration 42300 (15.7944 iter/s, 6.33138s/100 iters), loss = 1.65747
I1211 07:40:26.724714 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:40:26.724714 22260 solver.cpp:237]     Train net output #1: loss = 1.65747 (* 1 = 1.65747 loss)
I1211 07:40:26.724714 22260 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1211 07:40:33.053170 22260 solver.cpp:218] Iteration 42400 (15.8038 iter/s, 6.32761s/100 iters), loss = 1.67943
I1211 07:40:33.053170 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:40:33.053170 22260 solver.cpp:237]     Train net output #1: loss = 1.67943 (* 1 = 1.67943 loss)
I1211 07:40:33.053170 22260 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1211 07:40:39.064610 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:40:39.314630 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42500.caffemodel
I1211 07:40:39.329630 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_42500.solverstate
I1211 07:40:39.334630 22260 solver.cpp:330] Iteration 42500, Testing net (#0)
I1211 07:40:39.334630 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:40:40.849057 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:40:40.909062 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3583
I1211 07:40:40.909062 22260 solver.cpp:397]     Test net output #1: loss = 2.62615 (* 1 = 2.62615 loss)
I1211 07:40:40.970062 22260 solver.cpp:218] Iteration 42500 (12.6307 iter/s, 7.9172s/100 iters), loss = 1.73108
I1211 07:40:40.970062 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:40:40.970062 22260 solver.cpp:237]     Train net output #1: loss = 1.73108 (* 1 = 1.73108 loss)
I1211 07:40:40.970062 22260 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1211 07:40:47.294517 22260 solver.cpp:218] Iteration 42600 (15.8143 iter/s, 6.3234s/100 iters), loss = 1.62944
I1211 07:40:47.294517 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:40:47.294517 22260 solver.cpp:237]     Train net output #1: loss = 1.62944 (* 1 = 1.62944 loss)
I1211 07:40:47.294517 22260 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1211 07:40:53.622035 22260 solver.cpp:218] Iteration 42700 (15.8032 iter/s, 6.32782s/100 iters), loss = 1.35473
I1211 07:40:53.622035 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:40:53.622035 22260 solver.cpp:237]     Train net output #1: loss = 1.35473 (* 1 = 1.35473 loss)
I1211 07:40:53.622035 22260 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1211 07:40:59.960464 22260 solver.cpp:218] Iteration 42800 (15.7786 iter/s, 6.33768s/100 iters), loss = 1.67508
I1211 07:40:59.960464 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:40:59.960464 22260 solver.cpp:237]     Train net output #1: loss = 1.67508 (* 1 = 1.67508 loss)
I1211 07:40:59.960464 22260 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1211 07:41:06.281942 22260 solver.cpp:218] Iteration 42900 (15.8204 iter/s, 6.32095s/100 iters), loss = 1.85201
I1211 07:41:06.282444 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:41:06.282444 22260 solver.cpp:237]     Train net output #1: loss = 1.85201 (* 1 = 1.85201 loss)
I1211 07:41:06.282444 22260 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1211 07:41:12.295011 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:41:12.544772 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43000.caffemodel
I1211 07:41:12.559772 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43000.solverstate
I1211 07:41:12.564771 22260 solver.cpp:330] Iteration 43000, Testing net (#0)
I1211 07:41:12.564771 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:41:14.076118 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:41:14.136145 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3662
I1211 07:41:14.136145 22260 solver.cpp:397]     Test net output #1: loss = 2.61489 (* 1 = 2.61489 loss)
I1211 07:41:14.196178 22260 solver.cpp:218] Iteration 43000 (12.6362 iter/s, 7.91376s/100 iters), loss = 1.69783
I1211 07:41:14.196686 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:41:14.196686 22260 solver.cpp:237]     Train net output #1: loss = 1.69783 (* 1 = 1.69783 loss)
I1211 07:41:14.196686 22260 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1211 07:41:20.533282 22260 solver.cpp:218] Iteration 43100 (15.7806 iter/s, 6.33691s/100 iters), loss = 1.76414
I1211 07:41:20.533282 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:41:20.533282 22260 solver.cpp:237]     Train net output #1: loss = 1.76414 (* 1 = 1.76414 loss)
I1211 07:41:20.533282 22260 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1211 07:41:26.870724 22260 solver.cpp:218] Iteration 43200 (15.782 iter/s, 6.33634s/100 iters), loss = 1.31113
I1211 07:41:26.870724 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:41:26.870724 22260 solver.cpp:237]     Train net output #1: loss = 1.31113 (* 1 = 1.31113 loss)
I1211 07:41:26.870724 22260 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1211 07:41:33.201222 22260 solver.cpp:218] Iteration 43300 (15.7957 iter/s, 6.33085s/100 iters), loss = 1.60275
I1211 07:41:33.201222 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:41:33.201222 22260 solver.cpp:237]     Train net output #1: loss = 1.60275 (* 1 = 1.60275 loss)
I1211 07:41:33.201222 22260 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1211 07:41:39.538677 22260 solver.cpp:218] Iteration 43400 (15.7812 iter/s, 6.33664s/100 iters), loss = 1.76107
I1211 07:41:39.538677 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:41:39.538677 22260 solver.cpp:237]     Train net output #1: loss = 1.76107 (* 1 = 1.76107 loss)
I1211 07:41:39.538677 22260 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1211 07:41:45.562878 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:41:45.811897 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43500.caffemodel
I1211 07:41:45.828897 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_43500.solverstate
I1211 07:41:45.833897 22260 solver.cpp:330] Iteration 43500, Testing net (#0)
I1211 07:41:45.833897 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:41:47.347172 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:41:47.407177 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3025
I1211 07:41:47.407177 22260 solver.cpp:397]     Test net output #1: loss = 3.11473 (* 1 = 3.11473 loss)
I1211 07:41:47.467176 22260 solver.cpp:218] Iteration 43500 (12.6132 iter/s, 7.92823s/100 iters), loss = 1.46929
I1211 07:41:47.467176 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:41:47.467176 22260 solver.cpp:237]     Train net output #1: loss = 1.46929 (* 1 = 1.46929 loss)
I1211 07:41:47.467176 22260 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1211 07:41:53.798167 22260 solver.cpp:218] Iteration 43600 (15.7972 iter/s, 6.33023s/100 iters), loss = 1.46844
I1211 07:41:53.798167 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:41:53.798167 22260 solver.cpp:237]     Train net output #1: loss = 1.46844 (* 1 = 1.46844 loss)
I1211 07:41:53.798167 22260 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1211 07:42:00.125120 22260 solver.cpp:218] Iteration 43700 (15.8049 iter/s, 6.32714s/100 iters), loss = 1.42588
I1211 07:42:00.125120 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:42:00.126121 22260 solver.cpp:237]     Train net output #1: loss = 1.42588 (* 1 = 1.42588 loss)
I1211 07:42:00.126121 22260 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1211 07:42:06.455557 22260 solver.cpp:218] Iteration 43800 (15.7995 iter/s, 6.32933s/100 iters), loss = 1.67211
I1211 07:42:06.455557 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:42:06.455557 22260 solver.cpp:237]     Train net output #1: loss = 1.67211 (* 1 = 1.67211 loss)
I1211 07:42:06.455557 22260 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1211 07:42:12.783964 22260 solver.cpp:218] Iteration 43900 (15.8033 iter/s, 6.32779s/100 iters), loss = 1.88795
I1211 07:42:12.783964 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:42:12.783964 22260 solver.cpp:237]     Train net output #1: loss = 1.88795 (* 1 = 1.88795 loss)
I1211 07:42:12.783964 22260 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1211 07:42:18.809187 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:42:19.060205 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44000.caffemodel
I1211 07:42:19.075206 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44000.solverstate
I1211 07:42:19.080207 22260 solver.cpp:330] Iteration 44000, Testing net (#0)
I1211 07:42:19.080207 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:42:20.592317 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:42:20.652320 22260 solver.cpp:397]     Test net output #0: accuracy = 0.2608
I1211 07:42:20.652320 22260 solver.cpp:397]     Test net output #1: loss = 3.55297 (* 1 = 3.55297 loss)
I1211 07:42:20.712323 22260 solver.cpp:218] Iteration 44000 (12.6126 iter/s, 7.92855s/100 iters), loss = 1.70237
I1211 07:42:20.712323 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:42:20.712323 22260 solver.cpp:237]     Train net output #1: loss = 1.70237 (* 1 = 1.70237 loss)
I1211 07:42:20.712323 22260 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1211 07:42:27.049767 22260 solver.cpp:218] Iteration 44100 (15.7805 iter/s, 6.33692s/100 iters), loss = 1.73525
I1211 07:42:27.049767 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:42:27.049767 22260 solver.cpp:237]     Train net output #1: loss = 1.73525 (* 1 = 1.73525 loss)
I1211 07:42:27.049767 22260 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1211 07:42:33.375182 22260 solver.cpp:218] Iteration 44200 (15.81 iter/s, 6.3251s/100 iters), loss = 1.22153
I1211 07:42:33.375182 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:42:33.375182 22260 solver.cpp:237]     Train net output #1: loss = 1.22153 (* 1 = 1.22153 loss)
I1211 07:42:33.375182 22260 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1211 07:42:39.701606 22260 solver.cpp:218] Iteration 44300 (15.8083 iter/s, 6.32577s/100 iters), loss = 1.73511
I1211 07:42:39.702105 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:42:39.702105 22260 solver.cpp:237]     Train net output #1: loss = 1.73511 (* 1 = 1.73511 loss)
I1211 07:42:39.702105 22260 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1211 07:42:46.032050 22260 solver.cpp:218] Iteration 44400 (15.7988 iter/s, 6.32959s/100 iters), loss = 1.698
I1211 07:42:46.032050 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:42:46.032050 22260 solver.cpp:237]     Train net output #1: loss = 1.698 (* 1 = 1.698 loss)
I1211 07:42:46.032050 22260 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1211 07:42:52.054484 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:42:52.303995 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44500.caffemodel
I1211 07:42:52.319499 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_44500.solverstate
I1211 07:42:52.323500 22260 solver.cpp:330] Iteration 44500, Testing net (#0)
I1211 07:42:52.323500 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:42:53.835587 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:42:53.895587 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3924
I1211 07:42:53.895587 22260 solver.cpp:397]     Test net output #1: loss = 2.42373 (* 1 = 2.42373 loss)
I1211 07:42:53.955587 22260 solver.cpp:218] Iteration 44500 (12.6208 iter/s, 7.92344s/100 iters), loss = 1.54705
I1211 07:42:53.955587 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:42:53.955587 22260 solver.cpp:237]     Train net output #1: loss = 1.54705 (* 1 = 1.54705 loss)
I1211 07:42:53.955587 22260 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1211 07:43:00.287058 22260 solver.cpp:218] Iteration 44600 (15.7943 iter/s, 6.3314s/100 iters), loss = 1.56034
I1211 07:43:00.287058 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:43:00.287058 22260 solver.cpp:237]     Train net output #1: loss = 1.56034 (* 1 = 1.56034 loss)
I1211 07:43:00.287058 22260 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1211 07:43:06.618569 22260 solver.cpp:218] Iteration 44700 (15.7946 iter/s, 6.33127s/100 iters), loss = 1.42062
I1211 07:43:06.618569 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:43:06.618569 22260 solver.cpp:237]     Train net output #1: loss = 1.42062 (* 1 = 1.42062 loss)
I1211 07:43:06.618569 22260 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1211 07:43:12.950134 22260 solver.cpp:218] Iteration 44800 (15.7965 iter/s, 6.33051s/100 iters), loss = 1.7998
I1211 07:43:12.950134 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.54
I1211 07:43:12.950134 22260 solver.cpp:237]     Train net output #1: loss = 1.7998 (* 1 = 1.7998 loss)
I1211 07:43:12.950134 22260 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1211 07:43:19.270608 22260 solver.cpp:218] Iteration 44900 (15.8227 iter/s, 6.32003s/100 iters), loss = 1.71989
I1211 07:43:19.270608 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:43:19.270608 22260 solver.cpp:237]     Train net output #1: loss = 1.71989 (* 1 = 1.71989 loss)
I1211 07:43:19.270608 22260 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1211 07:43:25.293493 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:43:25.543020 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45000.caffemodel
I1211 07:43:25.558020 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45000.solverstate
I1211 07:43:25.562021 22260 solver.cpp:330] Iteration 45000, Testing net (#0)
I1211 07:43:25.562021 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:43:27.074107 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:43:27.133111 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3452
I1211 07:43:27.133111 22260 solver.cpp:397]     Test net output #1: loss = 2.71153 (* 1 = 2.71153 loss)
I1211 07:43:27.194617 22260 solver.cpp:218] Iteration 45000 (12.6211 iter/s, 7.92324s/100 iters), loss = 1.49306
I1211 07:43:27.194617 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:43:27.194617 22260 solver.cpp:237]     Train net output #1: loss = 1.49306 (* 1 = 1.49306 loss)
I1211 07:43:27.194617 22260 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1211 07:43:33.523540 22260 solver.cpp:218] Iteration 45100 (15.8014 iter/s, 6.32855s/100 iters), loss = 1.65991
I1211 07:43:33.523540 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:43:33.523540 22260 solver.cpp:237]     Train net output #1: loss = 1.65991 (* 1 = 1.65991 loss)
I1211 07:43:33.523540 22260 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1211 07:43:39.860980 22260 solver.cpp:218] Iteration 45200 (15.7802 iter/s, 6.33705s/100 iters), loss = 1.44158
I1211 07:43:39.860980 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:43:39.860980 22260 solver.cpp:237]     Train net output #1: loss = 1.44158 (* 1 = 1.44158 loss)
I1211 07:43:39.860980 22260 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1211 07:43:46.202935 22260 solver.cpp:218] Iteration 45300 (15.7691 iter/s, 6.34153s/100 iters), loss = 1.44606
I1211 07:43:46.202935 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:43:46.202935 22260 solver.cpp:237]     Train net output #1: loss = 1.44606 (* 1 = 1.44606 loss)
I1211 07:43:46.202935 22260 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1211 07:43:52.533887 22260 solver.cpp:218] Iteration 45400 (15.7962 iter/s, 6.33065s/100 iters), loss = 2.0011
I1211 07:43:52.533887 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:43:52.533887 22260 solver.cpp:237]     Train net output #1: loss = 2.0011 (* 1 = 2.0011 loss)
I1211 07:43:52.533887 22260 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1211 07:43:58.558398 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:43:58.808424 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45500.caffemodel
I1211 07:43:58.823428 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_45500.solverstate
I1211 07:43:58.827428 22260 solver.cpp:330] Iteration 45500, Testing net (#0)
I1211 07:43:58.827428 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:44:00.341516 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:44:00.402019 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3366
I1211 07:44:00.402019 22260 solver.cpp:397]     Test net output #1: loss = 2.85193 (* 1 = 2.85193 loss)
I1211 07:44:00.462519 22260 solver.cpp:218] Iteration 45500 (12.613 iter/s, 7.92832s/100 iters), loss = 1.52002
I1211 07:44:00.462519 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:44:00.462519 22260 solver.cpp:237]     Train net output #1: loss = 1.52002 (* 1 = 1.52002 loss)
I1211 07:44:00.462519 22260 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1211 07:44:06.774971 22260 solver.cpp:218] Iteration 45600 (15.8423 iter/s, 6.31221s/100 iters), loss = 1.64329
I1211 07:44:06.774971 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.55
I1211 07:44:06.774971 22260 solver.cpp:237]     Train net output #1: loss = 1.64329 (* 1 = 1.64329 loss)
I1211 07:44:06.774971 22260 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1211 07:44:13.098929 22260 solver.cpp:218] Iteration 45700 (15.8146 iter/s, 6.32326s/100 iters), loss = 1.28953
I1211 07:44:13.098929 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:44:13.098929 22260 solver.cpp:237]     Train net output #1: loss = 1.28953 (* 1 = 1.28953 loss)
I1211 07:44:13.098929 22260 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1211 07:44:19.423844 22260 solver.cpp:218] Iteration 45800 (15.8111 iter/s, 6.32469s/100 iters), loss = 1.77145
I1211 07:44:19.423844 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.45
I1211 07:44:19.423844 22260 solver.cpp:237]     Train net output #1: loss = 1.77145 (* 1 = 1.77145 loss)
I1211 07:44:19.423844 22260 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1211 07:44:25.748255 22260 solver.cpp:218] Iteration 45900 (15.8127 iter/s, 6.32404s/100 iters), loss = 1.85712
I1211 07:44:25.748255 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:44:25.748255 22260 solver.cpp:237]     Train net output #1: loss = 1.85712 (* 1 = 1.85712 loss)
I1211 07:44:25.748255 22260 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1211 07:44:31.755640 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:44:32.004664 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46000.caffemodel
I1211 07:44:32.019665 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46000.solverstate
I1211 07:44:32.023664 22260 solver.cpp:330] Iteration 46000, Testing net (#0)
I1211 07:44:32.023664 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:44:33.535778 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:44:33.595782 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3834
I1211 07:44:33.595782 22260 solver.cpp:397]     Test net output #1: loss = 2.50743 (* 1 = 2.50743 loss)
I1211 07:44:33.656781 22260 solver.cpp:218] Iteration 46000 (12.6462 iter/s, 7.90753s/100 iters), loss = 1.61247
I1211 07:44:33.656781 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.58
I1211 07:44:33.656781 22260 solver.cpp:237]     Train net output #1: loss = 1.61247 (* 1 = 1.61247 loss)
I1211 07:44:33.656781 22260 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1211 07:44:39.968367 22260 solver.cpp:218] Iteration 46100 (15.8432 iter/s, 6.31185s/100 iters), loss = 1.45393
I1211 07:44:39.968367 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.51
I1211 07:44:39.968367 22260 solver.cpp:237]     Train net output #1: loss = 1.45393 (* 1 = 1.45393 loss)
I1211 07:44:39.968367 22260 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1211 07:44:46.283848 22260 solver.cpp:218] Iteration 46200 (15.8361 iter/s, 6.31468s/100 iters), loss = 1.28118
I1211 07:44:46.284348 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:44:46.284348 22260 solver.cpp:237]     Train net output #1: loss = 1.28118 (* 1 = 1.28118 loss)
I1211 07:44:46.284348 22260 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1211 07:44:52.602247 22260 solver.cpp:218] Iteration 46300 (15.8267 iter/s, 6.31843s/100 iters), loss = 1.72113
I1211 07:44:52.602247 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:44:52.602247 22260 solver.cpp:237]     Train net output #1: loss = 1.72113 (* 1 = 1.72113 loss)
I1211 07:44:52.602247 22260 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1211 07:44:58.919657 22260 solver.cpp:218] Iteration 46400 (15.8311 iter/s, 6.31668s/100 iters), loss = 1.81184
I1211 07:44:58.919657 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:44:58.919657 22260 solver.cpp:237]     Train net output #1: loss = 1.81184 (* 1 = 1.81184 loss)
I1211 07:44:58.919657 22260 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1211 07:45:04.934064 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:45:05.183578 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46500.caffemodel
I1211 07:45:05.199092 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_46500.solverstate
I1211 07:45:05.203091 22260 solver.cpp:330] Iteration 46500, Testing net (#0)
I1211 07:45:05.203091 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:45:06.716190 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:45:06.776188 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3018
I1211 07:45:06.776188 22260 solver.cpp:397]     Test net output #1: loss = 2.88981 (* 1 = 2.88981 loss)
I1211 07:45:06.836206 22260 solver.cpp:218] Iteration 46500 (12.6329 iter/s, 7.91585s/100 iters), loss = 1.68811
I1211 07:45:06.836206 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.47
I1211 07:45:06.836206 22260 solver.cpp:237]     Train net output #1: loss = 1.68811 (* 1 = 1.68811 loss)
I1211 07:45:06.836206 22260 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1211 07:45:13.176664 22260 solver.cpp:218] Iteration 46600 (15.7726 iter/s, 6.34009s/100 iters), loss = 1.65339
I1211 07:45:13.176664 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 07:45:13.176664 22260 solver.cpp:237]     Train net output #1: loss = 1.65339 (* 1 = 1.65339 loss)
I1211 07:45:13.176664 22260 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1211 07:45:19.514204 22260 solver.cpp:218] Iteration 46700 (15.7792 iter/s, 6.33744s/100 iters), loss = 1.37457
I1211 07:45:19.514204 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:45:19.514204 22260 solver.cpp:237]     Train net output #1: loss = 1.37457 (* 1 = 1.37457 loss)
I1211 07:45:19.514204 22260 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1211 07:45:25.854190 22260 solver.cpp:218] Iteration 46800 (15.7753 iter/s, 6.339s/100 iters), loss = 1.87799
I1211 07:45:25.854190 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:45:25.854190 22260 solver.cpp:237]     Train net output #1: loss = 1.87799 (* 1 = 1.87799 loss)
I1211 07:45:25.854190 22260 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1211 07:45:32.198951 22260 solver.cpp:218] Iteration 46900 (15.7623 iter/s, 6.34427s/100 iters), loss = 1.86599
I1211 07:45:32.198951 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:45:32.198951 22260 solver.cpp:237]     Train net output #1: loss = 1.86599 (* 1 = 1.86599 loss)
I1211 07:45:32.198951 22260 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1211 07:45:38.235757 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:45:38.486625 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47000.caffemodel
I1211 07:45:38.502146 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47000.solverstate
I1211 07:45:38.507148 22260 solver.cpp:330] Iteration 47000, Testing net (#0)
I1211 07:45:38.507148 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:45:40.020776 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:45:40.080760 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3048
I1211 07:45:40.080760 22260 solver.cpp:397]     Test net output #1: loss = 3.04691 (* 1 = 3.04691 loss)
I1211 07:45:40.141791 22260 solver.cpp:218] Iteration 47000 (12.5907 iter/s, 7.94236s/100 iters), loss = 1.73149
I1211 07:45:40.141791 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:45:40.141791 22260 solver.cpp:237]     Train net output #1: loss = 1.73149 (* 1 = 1.73149 loss)
I1211 07:45:40.141791 22260 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1211 07:45:46.465153 22260 solver.cpp:218] Iteration 47100 (15.8147 iter/s, 6.32322s/100 iters), loss = 1.54895
I1211 07:45:46.465153 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:45:46.465153 22260 solver.cpp:237]     Train net output #1: loss = 1.54895 (* 1 = 1.54895 loss)
I1211 07:45:46.465153 22260 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1211 07:45:52.801654 22260 solver.cpp:218] Iteration 47200 (15.7837 iter/s, 6.33566s/100 iters), loss = 1.34625
I1211 07:45:52.801654 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:45:52.801654 22260 solver.cpp:237]     Train net output #1: loss = 1.34625 (* 1 = 1.34625 loss)
I1211 07:45:52.801654 22260 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1211 07:45:59.123174 22260 solver.cpp:218] Iteration 47300 (15.8192 iter/s, 6.32143s/100 iters), loss = 1.79433
I1211 07:45:59.123174 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:45:59.123174 22260 solver.cpp:237]     Train net output #1: loss = 1.79433 (* 1 = 1.79433 loss)
I1211 07:45:59.123174 22260 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1211 07:46:05.451596 22260 solver.cpp:218] Iteration 47400 (15.8025 iter/s, 6.32812s/100 iters), loss = 1.73614
I1211 07:46:05.451596 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:46:05.451596 22260 solver.cpp:237]     Train net output #1: loss = 1.73614 (* 1 = 1.73614 loss)
I1211 07:46:05.451596 22260 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1211 07:46:11.471029 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:46:11.721041 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47500.caffemodel
I1211 07:46:11.735545 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_47500.solverstate
I1211 07:46:11.740046 22260 solver.cpp:330] Iteration 47500, Testing net (#0)
I1211 07:46:11.740046 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:46:13.253168 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:46:13.313169 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3259
I1211 07:46:13.313169 22260 solver.cpp:397]     Test net output #1: loss = 3.21256 (* 1 = 3.21256 loss)
I1211 07:46:13.373175 22260 solver.cpp:218] Iteration 47500 (12.6252 iter/s, 7.92068s/100 iters), loss = 1.71969
I1211 07:46:13.373175 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:46:13.373175 22260 solver.cpp:237]     Train net output #1: loss = 1.71969 (* 1 = 1.71969 loss)
I1211 07:46:13.373175 22260 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1211 07:46:19.709615 22260 solver.cpp:218] Iteration 47600 (15.7825 iter/s, 6.33611s/100 iters), loss = 1.53556
I1211 07:46:19.709615 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:46:19.709615 22260 solver.cpp:237]     Train net output #1: loss = 1.53556 (* 1 = 1.53556 loss)
I1211 07:46:19.709615 22260 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1211 07:46:26.030067 22260 solver.cpp:218] Iteration 47700 (15.8207 iter/s, 6.32082s/100 iters), loss = 1.23536
I1211 07:46:26.030067 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 07:46:26.031069 22260 solver.cpp:237]     Train net output #1: loss = 1.23536 (* 1 = 1.23536 loss)
I1211 07:46:26.031069 22260 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1211 07:46:32.354559 22260 solver.cpp:218] Iteration 47800 (15.8142 iter/s, 6.32342s/100 iters), loss = 1.52203
I1211 07:46:32.354559 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:46:32.354559 22260 solver.cpp:237]     Train net output #1: loss = 1.52203 (* 1 = 1.52203 loss)
I1211 07:46:32.354559 22260 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1211 07:46:38.695950 22260 solver.cpp:218] Iteration 47900 (15.7702 iter/s, 6.34106s/100 iters), loss = 1.75076
I1211 07:46:38.695950 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:46:38.695950 22260 solver.cpp:237]     Train net output #1: loss = 1.75076 (* 1 = 1.75076 loss)
I1211 07:46:38.695950 22260 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1211 07:46:44.715428 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:46:44.964448 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48000.caffemodel
I1211 07:46:44.979449 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48000.solverstate
I1211 07:46:44.983448 22260 solver.cpp:330] Iteration 48000, Testing net (#0)
I1211 07:46:44.983448 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:46:46.496546 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:46:46.556550 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3681
I1211 07:46:46.556550 22260 solver.cpp:397]     Test net output #1: loss = 2.55397 (* 1 = 2.55397 loss)
I1211 07:46:46.617051 22260 solver.cpp:218] Iteration 48000 (12.6254 iter/s, 7.92057s/100 iters), loss = 1.63059
I1211 07:46:46.617051 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:46:46.617051 22260 solver.cpp:237]     Train net output #1: loss = 1.63059 (* 1 = 1.63059 loss)
I1211 07:46:46.617051 22260 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1211 07:46:52.943120 22260 solver.cpp:218] Iteration 48100 (15.8081 iter/s, 6.32588s/100 iters), loss = 1.4872
I1211 07:46:52.943120 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:46:52.943120 22260 solver.cpp:237]     Train net output #1: loss = 1.4872 (* 1 = 1.4872 loss)
I1211 07:46:52.943120 22260 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1211 07:46:59.272563 22260 solver.cpp:218] Iteration 48200 (15.8018 iter/s, 6.32839s/100 iters), loss = 1.4054
I1211 07:46:59.272563 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 07:46:59.272563 22260 solver.cpp:237]     Train net output #1: loss = 1.4054 (* 1 = 1.4054 loss)
I1211 07:46:59.272563 22260 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1211 07:47:05.604041 22260 solver.cpp:218] Iteration 48300 (15.7951 iter/s, 6.33107s/100 iters), loss = 1.64127
I1211 07:47:05.604041 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:47:05.604041 22260 solver.cpp:237]     Train net output #1: loss = 1.64127 (* 1 = 1.64127 loss)
I1211 07:47:05.604041 22260 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1211 07:47:11.931527 22260 solver.cpp:218] Iteration 48400 (15.8038 iter/s, 6.32758s/100 iters), loss = 1.6091
I1211 07:47:11.931527 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 07:47:11.931527 22260 solver.cpp:237]     Train net output #1: loss = 1.6091 (* 1 = 1.6091 loss)
I1211 07:47:11.931527 22260 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1211 07:47:17.951992 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:47:18.202015 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48500.caffemodel
I1211 07:47:18.216521 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_48500.solverstate
I1211 07:47:18.221022 22260 solver.cpp:330] Iteration 48500, Testing net (#0)
I1211 07:47:18.221022 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:47:19.733276 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:47:19.792275 22260 solver.cpp:397]     Test net output #0: accuracy = 0.4126
I1211 07:47:19.792275 22260 solver.cpp:397]     Test net output #1: loss = 2.2495 (* 1 = 2.2495 loss)
I1211 07:47:19.853281 22260 solver.cpp:218] Iteration 48500 (12.6237 iter/s, 7.92158s/100 iters), loss = 1.48551
I1211 07:47:19.853281 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 07:47:19.853281 22260 solver.cpp:237]     Train net output #1: loss = 1.48551 (* 1 = 1.48551 loss)
I1211 07:47:19.853281 22260 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1211 07:47:26.171674 22260 solver.cpp:218] Iteration 48600 (15.83 iter/s, 6.3171s/100 iters), loss = 1.55024
I1211 07:47:26.171674 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:47:26.171674 22260 solver.cpp:237]     Train net output #1: loss = 1.55024 (* 1 = 1.55024 loss)
I1211 07:47:26.171674 22260 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1211 07:47:32.489764 22260 solver.cpp:218] Iteration 48700 (15.8265 iter/s, 6.31853s/100 iters), loss = 1.25215
I1211 07:47:32.489764 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:47:32.489764 22260 solver.cpp:237]     Train net output #1: loss = 1.25215 (* 1 = 1.25215 loss)
I1211 07:47:32.489764 22260 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1211 07:47:38.811053 22260 solver.cpp:218] Iteration 48800 (15.8226 iter/s, 6.32008s/100 iters), loss = 1.50105
I1211 07:47:38.811053 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:47:38.811053 22260 solver.cpp:237]     Train net output #1: loss = 1.50105 (* 1 = 1.50105 loss)
I1211 07:47:38.811053 22260 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1211 07:47:45.139494 22260 solver.cpp:218] Iteration 48900 (15.8029 iter/s, 6.32797s/100 iters), loss = 1.7274
I1211 07:47:45.139494 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:47:45.139494 22260 solver.cpp:237]     Train net output #1: loss = 1.7274 (* 1 = 1.7274 loss)
I1211 07:47:45.139494 22260 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1211 07:47:51.147897 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:47:51.397907 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49000.caffemodel
I1211 07:47:51.411906 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49000.solverstate
I1211 07:47:51.416911 22260 solver.cpp:330] Iteration 49000, Testing net (#0)
I1211 07:47:51.416911 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:47:52.929499 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:47:52.989001 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3291
I1211 07:47:52.989001 22260 solver.cpp:397]     Test net output #1: loss = 2.70159 (* 1 = 2.70159 loss)
I1211 07:47:53.049006 22260 solver.cpp:218] Iteration 49000 (12.6425 iter/s, 7.90985s/100 iters), loss = 1.82536
I1211 07:47:53.050014 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:47:53.050014 22260 solver.cpp:237]     Train net output #1: loss = 1.82536 (* 1 = 1.82536 loss)
I1211 07:47:53.050014 22260 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1211 07:47:59.378455 22260 solver.cpp:218] Iteration 49100 (15.8008 iter/s, 6.32877s/100 iters), loss = 1.59629
I1211 07:47:59.378455 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.52
I1211 07:47:59.378455 22260 solver.cpp:237]     Train net output #1: loss = 1.59629 (* 1 = 1.59629 loss)
I1211 07:47:59.378455 22260 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1211 07:48:05.706902 22260 solver.cpp:218] Iteration 49200 (15.8026 iter/s, 6.32808s/100 iters), loss = 1.48077
I1211 07:48:05.707903 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:48:05.707903 22260 solver.cpp:237]     Train net output #1: loss = 1.48077 (* 1 = 1.48077 loss)
I1211 07:48:05.707903 22260 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1211 07:48:12.038972 22260 solver.cpp:218] Iteration 49300 (15.7944 iter/s, 6.33137s/100 iters), loss = 1.60317
I1211 07:48:12.038972 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:48:12.038972 22260 solver.cpp:237]     Train net output #1: loss = 1.60317 (* 1 = 1.60317 loss)
I1211 07:48:12.038972 22260 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1211 07:48:18.367799 22260 solver.cpp:218] Iteration 49400 (15.8029 iter/s, 6.32796s/100 iters), loss = 1.8546
I1211 07:48:18.367799 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I1211 07:48:18.367799 22260 solver.cpp:237]     Train net output #1: loss = 1.8546 (* 1 = 1.8546 loss)
I1211 07:48:18.367799 22260 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1211 07:48:24.381285 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:48:24.630295 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49500.caffemodel
I1211 07:48:24.646298 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_49500.solverstate
I1211 07:48:24.650799 22260 solver.cpp:330] Iteration 49500, Testing net (#0)
I1211 07:48:24.650799 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:48:26.162156 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:48:26.221158 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3212
I1211 07:48:26.221158 22260 solver.cpp:397]     Test net output #1: loss = 2.82531 (* 1 = 2.82531 loss)
I1211 07:48:26.282166 22260 solver.cpp:218] Iteration 49500 (12.6351 iter/s, 7.91444s/100 iters), loss = 1.59179
I1211 07:48:26.282166 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.6
I1211 07:48:26.282166 22260 solver.cpp:237]     Train net output #1: loss = 1.59179 (* 1 = 1.59179 loss)
I1211 07:48:26.282166 22260 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1211 07:48:32.612915 22260 solver.cpp:218] Iteration 49600 (15.7983 iter/s, 6.32981s/100 iters), loss = 1.46435
I1211 07:48:32.612915 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.5
I1211 07:48:32.612915 22260 solver.cpp:237]     Train net output #1: loss = 1.46435 (* 1 = 1.46435 loss)
I1211 07:48:32.612915 22260 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1211 07:48:38.949565 22260 solver.cpp:218] Iteration 49700 (15.7824 iter/s, 6.33616s/100 iters), loss = 1.50478
I1211 07:48:38.949565 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:48:38.949565 22260 solver.cpp:237]     Train net output #1: loss = 1.50478 (* 1 = 1.50478 loss)
I1211 07:48:38.949565 22260 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1211 07:48:45.283100 22260 solver.cpp:218] Iteration 49800 (15.7881 iter/s, 6.33388s/100 iters), loss = 1.8499
I1211 07:48:45.283100 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I1211 07:48:45.283100 22260 solver.cpp:237]     Train net output #1: loss = 1.8499 (* 1 = 1.8499 loss)
I1211 07:48:45.284101 22260 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1211 07:48:51.622356 22260 solver.cpp:218] Iteration 49900 (15.7771 iter/s, 6.33829s/100 iters), loss = 1.70828
I1211 07:48:51.622356 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 07:48:51.622356 22260 solver.cpp:237]     Train net output #1: loss = 1.70828 (* 1 = 1.70828 loss)
I1211 07:48:51.622356 22260 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1211 07:48:57.653098 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:48:57.904114 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50000.caffemodel
I1211 07:48:57.918113 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50000.solverstate
I1211 07:48:57.922114 22260 solver.cpp:330] Iteration 50000, Testing net (#0)
I1211 07:48:57.923115 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:48:59.438223 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:48:59.498229 22260 solver.cpp:397]     Test net output #0: accuracy = 0.3585
I1211 07:48:59.498229 22260 solver.cpp:397]     Test net output #1: loss = 2.68757 (* 1 = 2.68757 loss)
I1211 07:48:59.558228 22260 solver.cpp:218] Iteration 50000 (12.6017 iter/s, 7.93542s/100 iters), loss = 1.4129
I1211 07:48:59.558228 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.61
I1211 07:48:59.558228 22260 solver.cpp:237]     Train net output #1: loss = 1.4129 (* 1 = 1.4129 loss)
I1211 07:48:59.558228 22260 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1211 07:48:59.558228 22260 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1211 07:49:05.888167 22260 solver.cpp:218] Iteration 50100 (15.8001 iter/s, 6.32908s/100 iters), loss = 1.2553
I1211 07:49:05.888167 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.57
I1211 07:49:05.888167 22260 solver.cpp:237]     Train net output #1: loss = 1.2553 (* 1 = 1.2553 loss)
I1211 07:49:05.888167 22260 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1211 07:49:12.215220 22260 solver.cpp:218] Iteration 50200 (15.8048 iter/s, 6.32721s/100 iters), loss = 0.986723
I1211 07:49:12.215220 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 07:49:12.215220 22260 solver.cpp:237]     Train net output #1: loss = 0.986723 (* 1 = 0.986723 loss)
I1211 07:49:12.215220 22260 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1211 07:49:18.548748 22260 solver.cpp:218] Iteration 50300 (15.7902 iter/s, 6.33305s/100 iters), loss = 1.1146
I1211 07:49:18.548748 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:49:18.548748 22260 solver.cpp:237]     Train net output #1: loss = 1.1146 (* 1 = 1.1146 loss)
I1211 07:49:18.548748 22260 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1211 07:49:24.879201 22260 solver.cpp:218] Iteration 50400 (15.7986 iter/s, 6.32968s/100 iters), loss = 1.22673
I1211 07:49:24.879201 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 07:49:24.879201 22260 solver.cpp:237]     Train net output #1: loss = 1.22673 (* 1 = 1.22673 loss)
I1211 07:49:24.879201 22260 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1211 07:49:30.895678 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:49:31.144687 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50500.caffemodel
I1211 07:49:31.160687 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_50500.solverstate
I1211 07:49:31.164687 22260 solver.cpp:330] Iteration 50500, Testing net (#0)
I1211 07:49:31.164687 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:49:32.676776 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:49:32.736781 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6289
I1211 07:49:32.736781 22260 solver.cpp:397]     Test net output #1: loss = 1.28359 (* 1 = 1.28359 loss)
I1211 07:49:32.797785 22260 solver.cpp:218] Iteration 50500 (12.6294 iter/s, 7.91805s/100 iters), loss = 1.09001
I1211 07:49:32.797785 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:49:32.797785 22260 solver.cpp:237]     Train net output #1: loss = 1.09001 (* 1 = 1.09001 loss)
I1211 07:49:32.797785 22260 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1211 07:49:39.129209 22260 solver.cpp:218] Iteration 50600 (15.7937 iter/s, 6.33165s/100 iters), loss = 1.02989
I1211 07:49:39.130209 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 07:49:39.130209 22260 solver.cpp:237]     Train net output #1: loss = 1.02989 (* 1 = 1.02989 loss)
I1211 07:49:39.130209 22260 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1211 07:49:45.457660 22260 solver.cpp:218] Iteration 50700 (15.8045 iter/s, 6.32731s/100 iters), loss = 0.88492
I1211 07:49:45.457660 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 07:49:45.457660 22260 solver.cpp:237]     Train net output #1: loss = 0.88492 (* 1 = 0.88492 loss)
I1211 07:49:45.457660 22260 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1211 07:49:51.784106 22260 solver.cpp:218] Iteration 50800 (15.8078 iter/s, 6.32598s/100 iters), loss = 1.23884
I1211 07:49:51.784106 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 07:49:51.784106 22260 solver.cpp:237]     Train net output #1: loss = 1.23884 (* 1 = 1.23884 loss)
I1211 07:49:51.784106 22260 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1211 07:49:58.114565 22260 solver.cpp:218] Iteration 50900 (15.797 iter/s, 6.3303s/100 iters), loss = 1.1662
I1211 07:49:58.114565 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 07:49:58.114565 22260 solver.cpp:237]     Train net output #1: loss = 1.1662 (* 1 = 1.1662 loss)
I1211 07:49:58.114565 22260 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1211 07:50:04.134515 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:50:04.382027 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51000.caffemodel
I1211 07:50:04.397028 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51000.solverstate
I1211 07:50:04.402029 22260 solver.cpp:330] Iteration 51000, Testing net (#0)
I1211 07:50:04.402029 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:50:05.916121 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:50:05.976131 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6296
I1211 07:50:05.976131 22260 solver.cpp:397]     Test net output #1: loss = 1.28215 (* 1 = 1.28215 loss)
I1211 07:50:06.037132 22260 solver.cpp:218] Iteration 51000 (12.6235 iter/s, 7.92176s/100 iters), loss = 0.966343
I1211 07:50:06.037132 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:50:06.037132 22260 solver.cpp:237]     Train net output #1: loss = 0.966343 (* 1 = 0.966343 loss)
I1211 07:50:06.037132 22260 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1211 07:50:12.376616 22260 solver.cpp:218] Iteration 51100 (15.7742 iter/s, 6.33948s/100 iters), loss = 1.07229
I1211 07:50:12.376616 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:50:12.376616 22260 solver.cpp:237]     Train net output #1: loss = 1.07229 (* 1 = 1.07229 loss)
I1211 07:50:12.376616 22260 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1211 07:50:18.712047 22260 solver.cpp:218] Iteration 51200 (15.7865 iter/s, 6.33452s/100 iters), loss = 0.973379
I1211 07:50:18.712047 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:50:18.712047 22260 solver.cpp:237]     Train net output #1: loss = 0.973379 (* 1 = 0.973379 loss)
I1211 07:50:18.712047 22260 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1211 07:50:25.046512 22260 solver.cpp:218] Iteration 51300 (15.788 iter/s, 6.33393s/100 iters), loss = 1.10807
I1211 07:50:25.046512 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:50:25.046512 22260 solver.cpp:237]     Train net output #1: loss = 1.10807 (* 1 = 1.10807 loss)
I1211 07:50:25.046512 22260 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1211 07:50:31.383002 22260 solver.cpp:218] Iteration 51400 (15.7807 iter/s, 6.33685s/100 iters), loss = 1.13531
I1211 07:50:31.383002 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:50:31.383002 22260 solver.cpp:237]     Train net output #1: loss = 1.13531 (* 1 = 1.13531 loss)
I1211 07:50:31.383002 22260 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1211 07:50:37.407497 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:50:37.657538 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51500.caffemodel
I1211 07:50:37.672539 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_51500.solverstate
I1211 07:50:37.677539 22260 solver.cpp:330] Iteration 51500, Testing net (#0)
I1211 07:50:37.677539 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:50:39.188649 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:50:39.249155 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6335
I1211 07:50:39.249155 22260 solver.cpp:397]     Test net output #1: loss = 1.25688 (* 1 = 1.25688 loss)
I1211 07:50:39.309659 22260 solver.cpp:218] Iteration 51500 (12.618 iter/s, 7.92522s/100 iters), loss = 0.939433
I1211 07:50:39.309659 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:50:39.309659 22260 solver.cpp:237]     Train net output #1: loss = 0.939433 (* 1 = 0.939433 loss)
I1211 07:50:39.309659 22260 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1211 07:50:45.638623 22260 solver.cpp:218] Iteration 51600 (15.8012 iter/s, 6.32864s/100 iters), loss = 0.956023
I1211 07:50:45.638623 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:50:45.638623 22260 solver.cpp:237]     Train net output #1: loss = 0.956023 (* 1 = 0.956023 loss)
I1211 07:50:45.638623 22260 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1211 07:50:51.961586 22260 solver.cpp:218] Iteration 51700 (15.8157 iter/s, 6.32284s/100 iters), loss = 0.889491
I1211 07:50:51.961586 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:50:51.961586 22260 solver.cpp:237]     Train net output #1: loss = 0.889491 (* 1 = 0.889491 loss)
I1211 07:50:51.961586 22260 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1211 07:50:58.289070 22260 solver.cpp:218] Iteration 51800 (15.8041 iter/s, 6.32745s/100 iters), loss = 1.04546
I1211 07:50:58.289070 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:50:58.289070 22260 solver.cpp:237]     Train net output #1: loss = 1.04546 (* 1 = 1.04546 loss)
I1211 07:50:58.289070 22260 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1211 07:51:04.616506 22260 solver.cpp:218] Iteration 51900 (15.8067 iter/s, 6.32645s/100 iters), loss = 1.04433
I1211 07:51:04.616506 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:51:04.616506 22260 solver.cpp:237]     Train net output #1: loss = 1.04433 (* 1 = 1.04433 loss)
I1211 07:51:04.616506 22260 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1211 07:51:10.639397 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:51:10.889909 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52000.caffemodel
I1211 07:51:10.903909 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52000.solverstate
I1211 07:51:10.908910 22260 solver.cpp:330] Iteration 52000, Testing net (#0)
I1211 07:51:10.908910 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:51:12.421010 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:51:12.481019 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6406
I1211 07:51:12.481019 22260 solver.cpp:397]     Test net output #1: loss = 1.25408 (* 1 = 1.25408 loss)
I1211 07:51:12.542021 22260 solver.cpp:218] Iteration 52000 (12.6178 iter/s, 7.92529s/100 iters), loss = 0.84755
I1211 07:51:12.542521 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:51:12.542521 22260 solver.cpp:237]     Train net output #1: loss = 0.84755 (* 1 = 0.84755 loss)
I1211 07:51:12.542521 22260 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1211 07:51:18.868463 22260 solver.cpp:218] Iteration 52100 (15.8069 iter/s, 6.32635s/100 iters), loss = 1.01833
I1211 07:51:18.868463 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:51:18.868463 22260 solver.cpp:237]     Train net output #1: loss = 1.01833 (* 1 = 1.01833 loss)
I1211 07:51:18.868463 22260 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1211 07:51:25.196974 22260 solver.cpp:218] Iteration 52200 (15.8038 iter/s, 6.32761s/100 iters), loss = 0.742505
I1211 07:51:25.196974 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 07:51:25.196974 22260 solver.cpp:237]     Train net output #1: loss = 0.742505 (* 1 = 0.742505 loss)
I1211 07:51:25.196974 22260 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1211 07:51:31.520467 22260 solver.cpp:218] Iteration 52300 (15.8152 iter/s, 6.32305s/100 iters), loss = 1.02661
I1211 07:51:31.520467 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 07:51:31.520467 22260 solver.cpp:237]     Train net output #1: loss = 1.02661 (* 1 = 1.02661 loss)
I1211 07:51:31.520467 22260 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1211 07:51:37.846359 22260 solver.cpp:218] Iteration 52400 (15.8091 iter/s, 6.32549s/100 iters), loss = 0.987179
I1211 07:51:37.846359 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 07:51:37.846359 22260 solver.cpp:237]     Train net output #1: loss = 0.987179 (* 1 = 0.987179 loss)
I1211 07:51:37.846359 22260 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1211 07:51:43.867825 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:51:44.116834 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52500.caffemodel
I1211 07:51:44.133833 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_52500.solverstate
I1211 07:51:44.138834 22260 solver.cpp:330] Iteration 52500, Testing net (#0)
I1211 07:51:44.138834 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:51:45.653439 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:51:45.712940 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6411
I1211 07:51:45.712940 22260 solver.cpp:397]     Test net output #1: loss = 1.25523 (* 1 = 1.25523 loss)
I1211 07:51:45.773944 22260 solver.cpp:218] Iteration 52500 (12.6149 iter/s, 7.92712s/100 iters), loss = 0.955318
I1211 07:51:45.773944 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:51:45.773944 22260 solver.cpp:237]     Train net output #1: loss = 0.955318 (* 1 = 0.955318 loss)
I1211 07:51:45.773944 22260 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1211 07:51:52.094404 22260 solver.cpp:218] Iteration 52600 (15.8224 iter/s, 6.32017s/100 iters), loss = 0.964756
I1211 07:51:52.094404 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:51:52.094404 22260 solver.cpp:237]     Train net output #1: loss = 0.964756 (* 1 = 0.964756 loss)
I1211 07:51:52.094404 22260 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1211 07:51:58.407956 22260 solver.cpp:218] Iteration 52700 (15.8406 iter/s, 6.31289s/100 iters), loss = 0.78045
I1211 07:51:58.407956 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 07:51:58.407956 22260 solver.cpp:237]     Train net output #1: loss = 0.78045 (* 1 = 0.78045 loss)
I1211 07:51:58.407956 22260 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1211 07:52:04.725473 22260 solver.cpp:218] Iteration 52800 (15.8293 iter/s, 6.3174s/100 iters), loss = 0.987078
I1211 07:52:04.725473 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:52:04.725473 22260 solver.cpp:237]     Train net output #1: loss = 0.987078 (* 1 = 0.987078 loss)
I1211 07:52:04.725473 22260 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1211 07:52:11.053858 22260 solver.cpp:218] Iteration 52900 (15.8028 iter/s, 6.32799s/100 iters), loss = 1.08999
I1211 07:52:11.053858 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 07:52:11.053858 22260 solver.cpp:237]     Train net output #1: loss = 1.08999 (* 1 = 1.08999 loss)
I1211 07:52:11.053858 22260 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1211 07:52:17.067353 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:52:17.317365 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53000.caffemodel
I1211 07:52:17.332366 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53000.solverstate
I1211 07:52:17.337368 22260 solver.cpp:330] Iteration 53000, Testing net (#0)
I1211 07:52:17.337368 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:52:18.852463 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:52:18.912464 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6372
I1211 07:52:18.912464 22260 solver.cpp:397]     Test net output #1: loss = 1.26998 (* 1 = 1.26998 loss)
I1211 07:52:18.973469 22260 solver.cpp:218] Iteration 53000 (12.6279 iter/s, 7.91897s/100 iters), loss = 0.950796
I1211 07:52:18.973469 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:52:18.973469 22260 solver.cpp:237]     Train net output #1: loss = 0.950796 (* 1 = 0.950796 loss)
I1211 07:52:18.973469 22260 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1211 07:52:25.292915 22260 solver.cpp:218] Iteration 53100 (15.8244 iter/s, 6.31937s/100 iters), loss = 0.898784
I1211 07:52:25.292915 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:52:25.292915 22260 solver.cpp:237]     Train net output #1: loss = 0.898784 (* 1 = 0.898784 loss)
I1211 07:52:25.292915 22260 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1211 07:52:31.617352 22260 solver.cpp:218] Iteration 53200 (15.8142 iter/s, 6.32342s/100 iters), loss = 0.776181
I1211 07:52:31.617352 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 07:52:31.617352 22260 solver.cpp:237]     Train net output #1: loss = 0.776181 (* 1 = 0.776181 loss)
I1211 07:52:31.617352 22260 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1211 07:52:37.942831 22260 solver.cpp:218] Iteration 53300 (15.8099 iter/s, 6.32516s/100 iters), loss = 1.0032
I1211 07:52:37.942831 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 07:52:37.942831 22260 solver.cpp:237]     Train net output #1: loss = 1.0032 (* 1 = 1.0032 loss)
I1211 07:52:37.942831 22260 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1211 07:52:44.268738 22260 solver.cpp:218] Iteration 53400 (15.8083 iter/s, 6.32579s/100 iters), loss = 0.994805
I1211 07:52:44.268738 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 07:52:44.268738 22260 solver.cpp:237]     Train net output #1: loss = 0.994805 (* 1 = 0.994805 loss)
I1211 07:52:44.268738 22260 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1211 07:52:50.277568 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:52:50.526609 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53500.caffemodel
I1211 07:52:50.541610 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_53500.solverstate
I1211 07:52:50.545609 22260 solver.cpp:330] Iteration 53500, Testing net (#0)
I1211 07:52:50.545609 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:52:52.060767 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:52:52.120775 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6362
I1211 07:52:52.120775 22260 solver.cpp:397]     Test net output #1: loss = 1.26798 (* 1 = 1.26798 loss)
I1211 07:52:52.181776 22260 solver.cpp:218] Iteration 53500 (12.6384 iter/s, 7.91237s/100 iters), loss = 0.896979
I1211 07:52:52.181776 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 07:52:52.181776 22260 solver.cpp:237]     Train net output #1: loss = 0.896979 (* 1 = 0.896979 loss)
I1211 07:52:52.181776 22260 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1211 07:52:58.505200 22260 solver.cpp:218] Iteration 53600 (15.8154 iter/s, 6.32297s/100 iters), loss = 0.870657
I1211 07:52:58.505200 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 07:52:58.505200 22260 solver.cpp:237]     Train net output #1: loss = 0.870657 (* 1 = 0.870657 loss)
I1211 07:52:58.505200 22260 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1211 07:53:04.820334 22260 solver.cpp:218] Iteration 53700 (15.8358 iter/s, 6.31481s/100 iters), loss = 0.761926
I1211 07:53:04.820837 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 07:53:04.820837 22260 solver.cpp:237]     Train net output #1: loss = 0.761926 (* 1 = 0.761926 loss)
I1211 07:53:04.820837 22260 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1211 07:53:11.140571 22260 solver.cpp:218] Iteration 53800 (15.8241 iter/s, 6.31949s/100 iters), loss = 0.957148
I1211 07:53:11.140571 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:53:11.140571 22260 solver.cpp:237]     Train net output #1: loss = 0.957148 (* 1 = 0.957148 loss)
I1211 07:53:11.140571 22260 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1211 07:53:17.457695 22260 solver.cpp:218] Iteration 53900 (15.8299 iter/s, 6.31717s/100 iters), loss = 0.924167
I1211 07:53:17.457695 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:53:17.457695 22260 solver.cpp:237]     Train net output #1: loss = 0.924167 (* 1 = 0.924167 loss)
I1211 07:53:17.457695 22260 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1211 07:53:23.462620 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:53:23.711673 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54000.caffemodel
I1211 07:53:23.727690 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54000.solverstate
I1211 07:53:23.731300 22260 solver.cpp:330] Iteration 54000, Testing net (#0)
I1211 07:53:23.732300 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:53:25.246682 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:53:25.305697 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6378
I1211 07:53:25.305697 22260 solver.cpp:397]     Test net output #1: loss = 1.26492 (* 1 = 1.26492 loss)
I1211 07:53:25.366274 22260 solver.cpp:218] Iteration 54000 (12.645 iter/s, 7.90828s/100 iters), loss = 0.909431
I1211 07:53:25.366274 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 07:53:25.366274 22260 solver.cpp:237]     Train net output #1: loss = 0.909431 (* 1 = 0.909431 loss)
I1211 07:53:25.366274 22260 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1211 07:53:31.680459 22260 solver.cpp:218] Iteration 54100 (15.8388 iter/s, 6.31362s/100 iters), loss = 0.885774
I1211 07:53:31.680459 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 07:53:31.680459 22260 solver.cpp:237]     Train net output #1: loss = 0.885774 (* 1 = 0.885774 loss)
I1211 07:53:31.680459 22260 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1211 07:53:38.002887 22260 solver.cpp:218] Iteration 54200 (15.8177 iter/s, 6.32205s/100 iters), loss = 0.775784
I1211 07:53:38.002887 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 07:53:38.002887 22260 solver.cpp:237]     Train net output #1: loss = 0.775784 (* 1 = 0.775784 loss)
I1211 07:53:38.002887 22260 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1211 07:53:44.330901 22260 solver.cpp:218] Iteration 54300 (15.8057 iter/s, 6.32685s/100 iters), loss = 0.91508
I1211 07:53:44.330901 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:53:44.330901 22260 solver.cpp:237]     Train net output #1: loss = 0.91508 (* 1 = 0.91508 loss)
I1211 07:53:44.330901 22260 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1211 07:53:50.656834 22260 solver.cpp:218] Iteration 54400 (15.8076 iter/s, 6.32606s/100 iters), loss = 0.948654
I1211 07:53:50.656834 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 07:53:50.656834 22260 solver.cpp:237]     Train net output #1: loss = 0.948654 (* 1 = 0.948654 loss)
I1211 07:53:50.656834 22260 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1211 07:53:56.666266 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:53:56.917294 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54500.caffemodel
I1211 07:53:56.933297 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_54500.solverstate
I1211 07:53:56.937301 22260 solver.cpp:330] Iteration 54500, Testing net (#0)
I1211 07:53:56.937301 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:53:58.451406 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:53:58.511404 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6299
I1211 07:53:58.511404 22260 solver.cpp:397]     Test net output #1: loss = 1.29689 (* 1 = 1.29689 loss)
I1211 07:53:58.571408 22260 solver.cpp:218] Iteration 54500 (12.6357 iter/s, 7.91411s/100 iters), loss = 0.868601
I1211 07:53:58.571408 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 07:53:58.571408 22260 solver.cpp:237]     Train net output #1: loss = 0.868601 (* 1 = 0.868601 loss)
I1211 07:53:58.571408 22260 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1211 07:54:04.905906 22260 solver.cpp:218] Iteration 54600 (15.7874 iter/s, 6.33417s/100 iters), loss = 0.830261
I1211 07:54:04.905906 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:54:04.905906 22260 solver.cpp:237]     Train net output #1: loss = 0.830261 (* 1 = 0.830261 loss)
I1211 07:54:04.905906 22260 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1211 07:54:11.244426 22260 solver.cpp:218] Iteration 54700 (15.778 iter/s, 6.33793s/100 iters), loss = 0.786082
I1211 07:54:11.244426 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 07:54:11.244426 22260 solver.cpp:237]     Train net output #1: loss = 0.786082 (* 1 = 0.786082 loss)
I1211 07:54:11.244426 22260 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1211 07:54:17.574976 22260 solver.cpp:218] Iteration 54800 (15.7977 iter/s, 6.33003s/100 iters), loss = 0.949996
I1211 07:54:17.574976 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:54:17.574976 22260 solver.cpp:237]     Train net output #1: loss = 0.949996 (* 1 = 0.949996 loss)
I1211 07:54:17.574976 22260 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1211 07:54:23.905164 22260 solver.cpp:218] Iteration 54900 (15.7993 iter/s, 6.32938s/100 iters), loss = 0.932809
I1211 07:54:23.905164 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 07:54:23.905164 22260 solver.cpp:237]     Train net output #1: loss = 0.932809 (* 1 = 0.932809 loss)
I1211 07:54:23.905164 22260 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1211 07:54:29.925571 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:54:30.174589 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55000.caffemodel
I1211 07:54:30.188588 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55000.solverstate
I1211 07:54:30.193589 22260 solver.cpp:330] Iteration 55000, Testing net (#0)
I1211 07:54:30.193589 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:54:31.708691 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:54:31.767695 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6246
I1211 07:54:31.767695 22260 solver.cpp:397]     Test net output #1: loss = 1.33727 (* 1 = 1.33727 loss)
I1211 07:54:31.828198 22260 solver.cpp:218] Iteration 55000 (12.6217 iter/s, 7.92289s/100 iters), loss = 0.838717
I1211 07:54:31.828198 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 07:54:31.828198 22260 solver.cpp:237]     Train net output #1: loss = 0.838717 (* 1 = 0.838717 loss)
I1211 07:54:31.828198 22260 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1211 07:54:38.158198 22260 solver.cpp:218] Iteration 55100 (15.799 iter/s, 6.3295s/100 iters), loss = 0.872424
I1211 07:54:38.158198 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:54:38.158198 22260 solver.cpp:237]     Train net output #1: loss = 0.872424 (* 1 = 0.872424 loss)
I1211 07:54:38.158198 22260 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1211 07:54:44.479672 22260 solver.cpp:218] Iteration 55200 (15.8202 iter/s, 6.32101s/100 iters), loss = 0.682213
I1211 07:54:44.479672 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 07:54:44.479672 22260 solver.cpp:237]     Train net output #1: loss = 0.682213 (* 1 = 0.682213 loss)
I1211 07:54:44.479672 22260 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1211 07:54:50.808185 22260 solver.cpp:218] Iteration 55300 (15.8015 iter/s, 6.3285s/100 iters), loss = 0.932178
I1211 07:54:50.808185 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:54:50.808185 22260 solver.cpp:237]     Train net output #1: loss = 0.932178 (* 1 = 0.932178 loss)
I1211 07:54:50.808185 22260 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1211 07:54:57.132124 22260 solver.cpp:218] Iteration 55400 (15.8147 iter/s, 6.32325s/100 iters), loss = 0.987488
I1211 07:54:57.132124 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 07:54:57.132124 22260 solver.cpp:237]     Train net output #1: loss = 0.987488 (* 1 = 0.987488 loss)
I1211 07:54:57.132124 22260 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1211 07:55:03.147058 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:55:03.396072 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55500.caffemodel
I1211 07:55:03.411073 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_55500.solverstate
I1211 07:55:03.416074 22260 solver.cpp:330] Iteration 55500, Testing net (#0)
I1211 07:55:03.416074 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:55:04.929165 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:55:04.989184 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6352
I1211 07:55:04.989184 22260 solver.cpp:397]     Test net output #1: loss = 1.28728 (* 1 = 1.28728 loss)
I1211 07:55:05.049192 22260 solver.cpp:218] Iteration 55500 (12.6314 iter/s, 7.91679s/100 iters), loss = 0.702895
I1211 07:55:05.049192 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 07:55:05.049192 22260 solver.cpp:237]     Train net output #1: loss = 0.702895 (* 1 = 0.702895 loss)
I1211 07:55:05.049192 22260 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1211 07:55:11.383661 22260 solver.cpp:218] Iteration 55600 (15.7866 iter/s, 6.33447s/100 iters), loss = 0.776394
I1211 07:55:11.384661 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 07:55:11.384661 22260 solver.cpp:237]     Train net output #1: loss = 0.776394 (* 1 = 0.776394 loss)
I1211 07:55:11.384661 22260 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1211 07:55:17.727079 22260 solver.cpp:218] Iteration 55700 (15.7665 iter/s, 6.34256s/100 iters), loss = 0.773693
I1211 07:55:17.727079 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:55:17.727079 22260 solver.cpp:237]     Train net output #1: loss = 0.773693 (* 1 = 0.773693 loss)
I1211 07:55:17.727079 22260 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1211 07:55:24.060478 22260 solver.cpp:218] Iteration 55800 (15.7916 iter/s, 6.33249s/100 iters), loss = 0.924373
I1211 07:55:24.060478 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:55:24.060478 22260 solver.cpp:237]     Train net output #1: loss = 0.924373 (* 1 = 0.924373 loss)
I1211 07:55:24.060478 22260 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1211 07:55:30.400900 22260 solver.cpp:218] Iteration 55900 (15.7717 iter/s, 6.34046s/100 iters), loss = 0.859536
I1211 07:55:30.400900 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:55:30.400900 22260 solver.cpp:237]     Train net output #1: loss = 0.859536 (* 1 = 0.859536 loss)
I1211 07:55:30.400900 22260 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1211 07:55:36.425333 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:55:36.676357 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56000.caffemodel
I1211 07:55:36.692358 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56000.solverstate
I1211 07:55:36.697357 22260 solver.cpp:330] Iteration 56000, Testing net (#0)
I1211 07:55:36.697357 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:55:38.211458 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:55:38.272464 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6346
I1211 07:55:38.272464 22260 solver.cpp:397]     Test net output #1: loss = 1.29302 (* 1 = 1.29302 loss)
I1211 07:55:38.332461 22260 solver.cpp:218] Iteration 56000 (12.6093 iter/s, 7.93066s/100 iters), loss = 0.779116
I1211 07:55:38.332461 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:55:38.332461 22260 solver.cpp:237]     Train net output #1: loss = 0.779116 (* 1 = 0.779116 loss)
I1211 07:55:38.332461 22260 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1211 07:55:44.659412 22260 solver.cpp:218] Iteration 56100 (15.806 iter/s, 6.32672s/100 iters), loss = 0.83541
I1211 07:55:44.659412 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:55:44.659412 22260 solver.cpp:237]     Train net output #1: loss = 0.83541 (* 1 = 0.83541 loss)
I1211 07:55:44.659412 22260 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1211 07:55:50.981302 22260 solver.cpp:218] Iteration 56200 (15.818 iter/s, 6.32191s/100 iters), loss = 0.754099
I1211 07:55:50.981302 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 07:55:50.981302 22260 solver.cpp:237]     Train net output #1: loss = 0.754099 (* 1 = 0.754099 loss)
I1211 07:55:50.981302 22260 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1211 07:55:57.301759 22260 solver.cpp:218] Iteration 56300 (15.8245 iter/s, 6.31933s/100 iters), loss = 0.841951
I1211 07:55:57.301759 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:55:57.301759 22260 solver.cpp:237]     Train net output #1: loss = 0.841951 (* 1 = 0.841951 loss)
I1211 07:55:57.301759 22260 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1211 07:56:03.623159 22260 solver.cpp:218] Iteration 56400 (15.8186 iter/s, 6.32165s/100 iters), loss = 0.905087
I1211 07:56:03.623159 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:56:03.623159 22260 solver.cpp:237]     Train net output #1: loss = 0.905087 (* 1 = 0.905087 loss)
I1211 07:56:03.623159 22260 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1211 07:56:09.632536 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:56:09.882553 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56500.caffemodel
I1211 07:56:09.897553 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_56500.solverstate
I1211 07:56:09.902554 22260 solver.cpp:330] Iteration 56500, Testing net (#0)
I1211 07:56:09.902554 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:56:11.418673 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:56:11.478682 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6306
I1211 07:56:11.478682 22260 solver.cpp:397]     Test net output #1: loss = 1.31616 (* 1 = 1.31616 loss)
I1211 07:56:11.539674 22260 solver.cpp:218] Iteration 56500 (12.6328 iter/s, 7.91589s/100 iters), loss = 0.723549
I1211 07:56:11.539674 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 07:56:11.539674 22260 solver.cpp:237]     Train net output #1: loss = 0.723549 (* 1 = 0.723549 loss)
I1211 07:56:11.539674 22260 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1211 07:56:17.877140 22260 solver.cpp:218] Iteration 56600 (15.7791 iter/s, 6.33748s/100 iters), loss = 0.809376
I1211 07:56:17.878135 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 07:56:17.878135 22260 solver.cpp:237]     Train net output #1: loss = 0.809376 (* 1 = 0.809376 loss)
I1211 07:56:17.878135 22260 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1211 07:56:24.204627 22260 solver.cpp:218] Iteration 56700 (15.8076 iter/s, 6.32608s/100 iters), loss = 0.701191
I1211 07:56:24.204627 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:56:24.204627 22260 solver.cpp:237]     Train net output #1: loss = 0.701191 (* 1 = 0.701191 loss)
I1211 07:56:24.204627 22260 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1211 07:56:30.535071 22260 solver.cpp:218] Iteration 56800 (15.7971 iter/s, 6.33027s/100 iters), loss = 0.908019
I1211 07:56:30.535071 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 07:56:30.535071 22260 solver.cpp:237]     Train net output #1: loss = 0.908019 (* 1 = 0.908019 loss)
I1211 07:56:30.535071 22260 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1211 07:56:36.868571 22260 solver.cpp:218] Iteration 56900 (15.7905 iter/s, 6.33292s/100 iters), loss = 0.880031
I1211 07:56:36.868571 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 07:56:36.868571 22260 solver.cpp:237]     Train net output #1: loss = 0.880031 (* 1 = 0.880031 loss)
I1211 07:56:36.868571 22260 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1211 07:56:42.891981 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:56:43.141996 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57000.caffemodel
I1211 07:56:43.159996 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57000.solverstate
I1211 07:56:43.163996 22260 solver.cpp:330] Iteration 57000, Testing net (#0)
I1211 07:56:43.163996 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:56:44.678598 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:56:44.738102 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6232
I1211 07:56:44.738102 22260 solver.cpp:397]     Test net output #1: loss = 1.35287 (* 1 = 1.35287 loss)
I1211 07:56:44.799111 22260 solver.cpp:218] Iteration 57000 (12.6101 iter/s, 7.93016s/100 iters), loss = 0.832534
I1211 07:56:44.799111 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 07:56:44.799111 22260 solver.cpp:237]     Train net output #1: loss = 0.832534 (* 1 = 0.832534 loss)
I1211 07:56:44.799111 22260 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1211 07:56:51.140568 22260 solver.cpp:218] Iteration 57100 (15.769 iter/s, 6.34156s/100 iters), loss = 0.806976
I1211 07:56:51.140568 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 07:56:51.140568 22260 solver.cpp:237]     Train net output #1: loss = 0.806976 (* 1 = 0.806976 loss)
I1211 07:56:51.140568 22260 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1211 07:56:57.478986 22260 solver.cpp:218] Iteration 57200 (15.7791 iter/s, 6.3375s/100 iters), loss = 0.700126
I1211 07:56:57.478986 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 07:56:57.478986 22260 solver.cpp:237]     Train net output #1: loss = 0.700126 (* 1 = 0.700126 loss)
I1211 07:56:57.478986 22260 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1211 07:57:03.814404 22260 solver.cpp:218] Iteration 57300 (15.7838 iter/s, 6.33561s/100 iters), loss = 0.868014
I1211 07:57:03.814404 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:57:03.815404 22260 solver.cpp:237]     Train net output #1: loss = 0.868014 (* 1 = 0.868014 loss)
I1211 07:57:03.815404 22260 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1211 07:57:10.135867 22260 solver.cpp:218] Iteration 57400 (15.8205 iter/s, 6.32092s/100 iters), loss = 0.862567
I1211 07:57:10.135867 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.67
I1211 07:57:10.135867 22260 solver.cpp:237]     Train net output #1: loss = 0.862567 (* 1 = 0.862567 loss)
I1211 07:57:10.135867 22260 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1211 07:57:16.152422 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:57:16.399440 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57500.caffemodel
I1211 07:57:16.415439 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_57500.solverstate
I1211 07:57:16.419440 22260 solver.cpp:330] Iteration 57500, Testing net (#0)
I1211 07:57:16.419440 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:57:17.935531 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:57:17.995538 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6036
I1211 07:57:17.995538 22260 solver.cpp:397]     Test net output #1: loss = 1.45203 (* 1 = 1.45203 loss)
I1211 07:57:18.055536 22260 solver.cpp:218] Iteration 57500 (12.6273 iter/s, 7.91932s/100 iters), loss = 0.790832
I1211 07:57:18.056537 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 07:57:18.056537 22260 solver.cpp:237]     Train net output #1: loss = 0.790832 (* 1 = 0.790832 loss)
I1211 07:57:18.056537 22260 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1211 07:57:24.376039 22260 solver.cpp:218] Iteration 57600 (15.8237 iter/s, 6.31964s/100 iters), loss = 0.837221
I1211 07:57:24.376039 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 07:57:24.376039 22260 solver.cpp:237]     Train net output #1: loss = 0.837221 (* 1 = 0.837221 loss)
I1211 07:57:24.376039 22260 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1211 07:57:30.699587 22260 solver.cpp:218] Iteration 57700 (15.8139 iter/s, 6.32356s/100 iters), loss = 0.667193
I1211 07:57:30.700587 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 07:57:30.700587 22260 solver.cpp:237]     Train net output #1: loss = 0.667193 (* 1 = 0.667193 loss)
I1211 07:57:30.700587 22260 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1211 07:57:37.025080 22260 solver.cpp:218] Iteration 57800 (15.8117 iter/s, 6.32445s/100 iters), loss = 0.847335
I1211 07:57:37.025080 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 07:57:37.025080 22260 solver.cpp:237]     Train net output #1: loss = 0.847335 (* 1 = 0.847335 loss)
I1211 07:57:37.025080 22260 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1211 07:57:43.350499 22260 solver.cpp:218] Iteration 57900 (15.8091 iter/s, 6.32548s/100 iters), loss = 0.842212
I1211 07:57:43.350499 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I1211 07:57:43.350499 22260 solver.cpp:237]     Train net output #1: loss = 0.842212 (* 1 = 0.842212 loss)
I1211 07:57:43.350499 22260 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1211 07:57:49.363941 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:57:49.612958 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58000.caffemodel
I1211 07:57:49.628958 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58000.solverstate
I1211 07:57:49.633958 22260 solver.cpp:330] Iteration 58000, Testing net (#0)
I1211 07:57:49.633958 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:57:51.148087 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:57:51.209092 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6102
I1211 07:57:51.209092 22260 solver.cpp:397]     Test net output #1: loss = 1.42217 (* 1 = 1.42217 loss)
I1211 07:57:51.269091 22260 solver.cpp:218] Iteration 58000 (12.6296 iter/s, 7.91791s/100 iters), loss = 0.789707
I1211 07:57:51.269091 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:57:51.269091 22260 solver.cpp:237]     Train net output #1: loss = 0.789707 (* 1 = 0.789707 loss)
I1211 07:57:51.269091 22260 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1211 07:57:57.600538 22260 solver.cpp:218] Iteration 58100 (15.7963 iter/s, 6.33062s/100 iters), loss = 0.763695
I1211 07:57:57.600538 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 07:57:57.600538 22260 solver.cpp:237]     Train net output #1: loss = 0.763695 (* 1 = 0.763695 loss)
I1211 07:57:57.600538 22260 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1211 07:58:03.932040 22260 solver.cpp:218] Iteration 58200 (15.7935 iter/s, 6.33171s/100 iters), loss = 0.724019
I1211 07:58:03.932040 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 07:58:03.932040 22260 solver.cpp:237]     Train net output #1: loss = 0.724019 (* 1 = 0.724019 loss)
I1211 07:58:03.932040 22260 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1211 07:58:10.261488 22260 solver.cpp:218] Iteration 58300 (15.8011 iter/s, 6.32868s/100 iters), loss = 0.831885
I1211 07:58:10.261488 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:58:10.261488 22260 solver.cpp:237]     Train net output #1: loss = 0.831885 (* 1 = 0.831885 loss)
I1211 07:58:10.261488 22260 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1211 07:58:16.583542 22260 solver.cpp:218] Iteration 58400 (15.8193 iter/s, 6.32139s/100 iters), loss = 0.721828
I1211 07:58:16.583542 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:58:16.583542 22260 solver.cpp:237]     Train net output #1: loss = 0.721828 (* 1 = 0.721828 loss)
I1211 07:58:16.584043 22260 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1211 07:58:22.593431 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:58:22.841447 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58500.caffemodel
I1211 07:58:22.856446 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_58500.solverstate
I1211 07:58:22.860446 22260 solver.cpp:330] Iteration 58500, Testing net (#0)
I1211 07:58:22.861449 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:58:24.373541 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:58:24.433547 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6165
I1211 07:58:24.433547 22260 solver.cpp:397]     Test net output #1: loss = 1.41233 (* 1 = 1.41233 loss)
I1211 07:58:24.493546 22260 solver.cpp:218] Iteration 58500 (12.6428 iter/s, 7.90964s/100 iters), loss = 0.697486
I1211 07:58:24.493546 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 07:58:24.493546 22260 solver.cpp:237]     Train net output #1: loss = 0.697486 (* 1 = 0.697486 loss)
I1211 07:58:24.493546 22260 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1211 07:58:30.824990 22260 solver.cpp:218] Iteration 58600 (15.7966 iter/s, 6.33049s/100 iters), loss = 0.751732
I1211 07:58:30.824990 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 07:58:30.824990 22260 solver.cpp:237]     Train net output #1: loss = 0.751732 (* 1 = 0.751732 loss)
I1211 07:58:30.824990 22260 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1211 07:58:37.152498 22260 solver.cpp:218] Iteration 58700 (15.8051 iter/s, 6.32708s/100 iters), loss = 0.697176
I1211 07:58:37.152498 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 07:58:37.152498 22260 solver.cpp:237]     Train net output #1: loss = 0.697176 (* 1 = 0.697176 loss)
I1211 07:58:37.152498 22260 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1211 07:58:43.475023 22260 solver.cpp:218] Iteration 58800 (15.8171 iter/s, 6.32227s/100 iters), loss = 0.720959
I1211 07:58:43.475023 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 07:58:43.475023 22260 solver.cpp:237]     Train net output #1: loss = 0.720959 (* 1 = 0.720959 loss)
I1211 07:58:43.475023 22260 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1211 07:58:49.804527 22260 solver.cpp:218] Iteration 58900 (15.7985 iter/s, 6.32971s/100 iters), loss = 0.7622
I1211 07:58:49.804527 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 07:58:49.804527 22260 solver.cpp:237]     Train net output #1: loss = 0.7622 (* 1 = 0.7622 loss)
I1211 07:58:49.804527 22260 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1211 07:58:55.827949 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:58:56.076979 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59000.caffemodel
I1211 07:58:56.091980 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59000.solverstate
I1211 07:58:56.095980 22260 solver.cpp:330] Iteration 59000, Testing net (#0)
I1211 07:58:56.095980 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:58:57.608065 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:58:57.668078 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6192
I1211 07:58:57.668078 22260 solver.cpp:397]     Test net output #1: loss = 1.391 (* 1 = 1.391 loss)
I1211 07:58:57.728574 22260 solver.cpp:218] Iteration 59000 (12.6214 iter/s, 7.92303s/100 iters), loss = 0.738171
I1211 07:58:57.728574 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 07:58:57.728574 22260 solver.cpp:237]     Train net output #1: loss = 0.738171 (* 1 = 0.738171 loss)
I1211 07:58:57.728574 22260 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1211 07:59:04.057538 22260 solver.cpp:218] Iteration 59100 (15.7996 iter/s, 6.32926s/100 iters), loss = 0.818037
I1211 07:59:04.058539 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:59:04.058539 22260 solver.cpp:237]     Train net output #1: loss = 0.818037 (* 1 = 0.818037 loss)
I1211 07:59:04.058539 22260 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1211 07:59:10.391994 22260 solver.cpp:218] Iteration 59200 (15.7886 iter/s, 6.33369s/100 iters), loss = 0.738407
I1211 07:59:10.391994 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 07:59:10.391994 22260 solver.cpp:237]     Train net output #1: loss = 0.738407 (* 1 = 0.738407 loss)
I1211 07:59:10.391994 22260 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1211 07:59:16.730985 22260 solver.cpp:218] Iteration 59300 (15.7775 iter/s, 6.33812s/100 iters), loss = 0.868674
I1211 07:59:16.730985 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 07:59:16.730985 22260 solver.cpp:237]     Train net output #1: loss = 0.868674 (* 1 = 0.868674 loss)
I1211 07:59:16.730985 22260 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1211 07:59:23.056900 22260 solver.cpp:218] Iteration 59400 (15.8079 iter/s, 6.32593s/100 iters), loss = 0.841986
I1211 07:59:23.056900 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 07:59:23.056900 22260 solver.cpp:237]     Train net output #1: loss = 0.841986 (* 1 = 0.841986 loss)
I1211 07:59:23.056900 22260 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1211 07:59:29.076807 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:59:29.325320 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59500.caffemodel
I1211 07:59:29.339319 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_59500.solverstate
I1211 07:59:29.344321 22260 solver.cpp:330] Iteration 59500, Testing net (#0)
I1211 07:59:29.344321 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 07:59:30.857432 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 07:59:30.918437 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6071
I1211 07:59:30.918437 22260 solver.cpp:397]     Test net output #1: loss = 1.44887 (* 1 = 1.44887 loss)
I1211 07:59:30.978437 22260 solver.cpp:218] Iteration 59500 (12.6254 iter/s, 7.92055s/100 iters), loss = 0.765673
I1211 07:59:30.978437 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 07:59:30.978437 22260 solver.cpp:237]     Train net output #1: loss = 0.765673 (* 1 = 0.765673 loss)
I1211 07:59:30.978437 22260 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1211 07:59:37.308910 22260 solver.cpp:218] Iteration 59600 (15.7975 iter/s, 6.33013s/100 iters), loss = 0.775185
I1211 07:59:37.308910 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:59:37.308910 22260 solver.cpp:237]     Train net output #1: loss = 0.775185 (* 1 = 0.775185 loss)
I1211 07:59:37.308910 22260 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1211 07:59:43.642379 22260 solver.cpp:218] Iteration 59700 (15.7882 iter/s, 6.33385s/100 iters), loss = 0.680326
I1211 07:59:43.642379 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 07:59:43.642379 22260 solver.cpp:237]     Train net output #1: loss = 0.680326 (* 1 = 0.680326 loss)
I1211 07:59:43.642379 22260 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1211 07:59:49.978842 22260 solver.cpp:218] Iteration 59800 (15.7844 iter/s, 6.33538s/100 iters), loss = 0.789164
I1211 07:59:49.978842 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 07:59:49.978842 22260 solver.cpp:237]     Train net output #1: loss = 0.789164 (* 1 = 0.789164 loss)
I1211 07:59:49.978842 22260 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1211 07:59:56.313347 22260 solver.cpp:218] Iteration 59900 (15.7875 iter/s, 6.33413s/100 iters), loss = 0.812275
I1211 07:59:56.313347 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 07:59:56.313347 22260 solver.cpp:237]     Train net output #1: loss = 0.812275 (* 1 = 0.812275 loss)
I1211 07:59:56.313347 22260 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1211 08:00:02.336846 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:00:02.585358 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60000.caffemodel
I1211 08:00:02.601861 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60000.solverstate
I1211 08:00:02.605861 22260 solver.cpp:330] Iteration 60000, Testing net (#0)
I1211 08:00:02.605861 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:00:04.120965 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:00:04.180968 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6034
I1211 08:00:04.181468 22260 solver.cpp:397]     Test net output #1: loss = 1.49121 (* 1 = 1.49121 loss)
I1211 08:00:04.241969 22260 solver.cpp:218] Iteration 60000 (12.6132 iter/s, 7.92819s/100 iters), loss = 0.712526
I1211 08:00:04.241969 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:00:04.241969 22260 solver.cpp:237]     Train net output #1: loss = 0.712526 (* 1 = 0.712526 loss)
I1211 08:00:04.241969 22260 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1211 08:00:10.579936 22260 solver.cpp:218] Iteration 60100 (15.7793 iter/s, 6.33744s/100 iters), loss = 0.784059
I1211 08:00:10.579936 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:00:10.579936 22260 solver.cpp:237]     Train net output #1: loss = 0.784059 (* 1 = 0.784059 loss)
I1211 08:00:10.579936 22260 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1211 08:00:16.917901 22260 solver.cpp:218] Iteration 60200 (15.7782 iter/s, 6.33788s/100 iters), loss = 0.715251
I1211 08:00:16.917901 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:00:16.917901 22260 solver.cpp:237]     Train net output #1: loss = 0.715251 (* 1 = 0.715251 loss)
I1211 08:00:16.917901 22260 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1211 08:00:23.258401 22260 solver.cpp:218] Iteration 60300 (15.7723 iter/s, 6.34023s/100 iters), loss = 0.927067
I1211 08:00:23.258401 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 08:00:23.258401 22260 solver.cpp:237]     Train net output #1: loss = 0.927067 (* 1 = 0.927067 loss)
I1211 08:00:23.258401 22260 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1211 08:00:29.604846 22260 solver.cpp:218] Iteration 60400 (15.758 iter/s, 6.346s/100 iters), loss = 0.829603
I1211 08:00:29.604846 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:00:29.604846 22260 solver.cpp:237]     Train net output #1: loss = 0.829603 (* 1 = 0.829603 loss)
I1211 08:00:29.604846 22260 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1211 08:00:35.634282 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:00:35.883308 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60500.caffemodel
I1211 08:00:35.898313 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_60500.solverstate
I1211 08:00:35.903312 22260 solver.cpp:330] Iteration 60500, Testing net (#0)
I1211 08:00:35.903312 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:00:37.416420 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:00:37.476423 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6125
I1211 08:00:37.476423 22260 solver.cpp:397]     Test net output #1: loss = 1.45278 (* 1 = 1.45278 loss)
I1211 08:00:37.536424 22260 solver.cpp:218] Iteration 60500 (12.6085 iter/s, 7.93118s/100 iters), loss = 0.785815
I1211 08:00:37.536424 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:00:37.536424 22260 solver.cpp:237]     Train net output #1: loss = 0.785815 (* 1 = 0.785815 loss)
I1211 08:00:37.536424 22260 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1211 08:00:43.889865 22260 solver.cpp:218] Iteration 60600 (15.7415 iter/s, 6.35263s/100 iters), loss = 0.762105
I1211 08:00:43.889865 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:00:43.889865 22260 solver.cpp:237]     Train net output #1: loss = 0.762105 (* 1 = 0.762105 loss)
I1211 08:00:43.889865 22260 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1211 08:00:50.229305 22260 solver.cpp:218] Iteration 60700 (15.7747 iter/s, 6.33927s/100 iters), loss = 0.75995
I1211 08:00:50.229305 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:00:50.229305 22260 solver.cpp:237]     Train net output #1: loss = 0.75995 (* 1 = 0.75995 loss)
I1211 08:00:50.229305 22260 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1211 08:00:56.570757 22260 solver.cpp:218] Iteration 60800 (15.7705 iter/s, 6.34096s/100 iters), loss = 0.829272
I1211 08:00:56.570757 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:00:56.570757 22260 solver.cpp:237]     Train net output #1: loss = 0.829272 (* 1 = 0.829272 loss)
I1211 08:00:56.570757 22260 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1211 08:01:02.910722 22260 solver.cpp:218] Iteration 60900 (15.7746 iter/s, 6.3393s/100 iters), loss = 0.809684
I1211 08:01:02.911223 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:01:02.911223 22260 solver.cpp:237]     Train net output #1: loss = 0.809684 (* 1 = 0.809684 loss)
I1211 08:01:02.911223 22260 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1211 08:01:08.934725 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:01:09.183740 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61000.caffemodel
I1211 08:01:09.198246 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61000.solverstate
I1211 08:01:09.202745 22260 solver.cpp:330] Iteration 61000, Testing net (#0)
I1211 08:01:09.202745 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:01:10.718861 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:01:10.778861 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5951
I1211 08:01:10.778861 22260 solver.cpp:397]     Test net output #1: loss = 1.50655 (* 1 = 1.50655 loss)
I1211 08:01:10.838865 22260 solver.cpp:218] Iteration 61000 (12.6133 iter/s, 7.92812s/100 iters), loss = 0.703358
I1211 08:01:10.838865 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:01:10.838865 22260 solver.cpp:237]     Train net output #1: loss = 0.703358 (* 1 = 0.703358 loss)
I1211 08:01:10.838865 22260 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1211 08:01:17.172384 22260 solver.cpp:218] Iteration 61100 (15.7906 iter/s, 6.33288s/100 iters), loss = 0.734815
I1211 08:01:17.172384 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:01:17.172384 22260 solver.cpp:237]     Train net output #1: loss = 0.734815 (* 1 = 0.734815 loss)
I1211 08:01:17.172384 22260 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1211 08:01:23.500828 22260 solver.cpp:218] Iteration 61200 (15.8042 iter/s, 6.32742s/100 iters), loss = 0.798501
I1211 08:01:23.500828 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:01:23.500828 22260 solver.cpp:237]     Train net output #1: loss = 0.798501 (* 1 = 0.798501 loss)
I1211 08:01:23.500828 22260 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1211 08:01:29.840811 22260 solver.cpp:218] Iteration 61300 (15.7735 iter/s, 6.33974s/100 iters), loss = 0.810744
I1211 08:01:29.841312 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:01:29.841312 22260 solver.cpp:237]     Train net output #1: loss = 0.810744 (* 1 = 0.810744 loss)
I1211 08:01:29.841312 22260 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1211 08:01:36.178733 22260 solver.cpp:218] Iteration 61400 (15.7785 iter/s, 6.33772s/100 iters), loss = 0.873273
I1211 08:01:36.178733 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:01:36.178733 22260 solver.cpp:237]     Train net output #1: loss = 0.873273 (* 1 = 0.873273 loss)
I1211 08:01:36.178733 22260 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1211 08:01:42.201159 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:01:42.450170 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61500.caffemodel
I1211 08:01:42.465174 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_61500.solverstate
I1211 08:01:42.470175 22260 solver.cpp:330] Iteration 61500, Testing net (#0)
I1211 08:01:42.470175 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:01:43.984269 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:01:44.043771 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5981
I1211 08:01:44.043771 22260 solver.cpp:397]     Test net output #1: loss = 1.50916 (* 1 = 1.50916 loss)
I1211 08:01:44.104272 22260 solver.cpp:218] Iteration 61500 (12.6181 iter/s, 7.92512s/100 iters), loss = 0.726563
I1211 08:01:44.104272 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:01:44.104272 22260 solver.cpp:237]     Train net output #1: loss = 0.726563 (* 1 = 0.726563 loss)
I1211 08:01:44.104272 22260 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1211 08:01:50.432665 22260 solver.cpp:218] Iteration 61600 (15.8042 iter/s, 6.32744s/100 iters), loss = 0.721667
I1211 08:01:50.432665 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:01:50.432665 22260 solver.cpp:237]     Train net output #1: loss = 0.721667 (* 1 = 0.721667 loss)
I1211 08:01:50.432665 22260 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1211 08:01:56.764075 22260 solver.cpp:218] Iteration 61700 (15.7938 iter/s, 6.33161s/100 iters), loss = 0.759004
I1211 08:01:56.764075 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:01:56.764075 22260 solver.cpp:237]     Train net output #1: loss = 0.759004 (* 1 = 0.759004 loss)
I1211 08:01:56.764075 22260 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1211 08:02:03.091528 22260 solver.cpp:218] Iteration 61800 (15.8059 iter/s, 6.32677s/100 iters), loss = 0.739212
I1211 08:02:03.091528 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:02:03.091528 22260 solver.cpp:237]     Train net output #1: loss = 0.739212 (* 1 = 0.739212 loss)
I1211 08:02:03.091528 22260 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1211 08:02:09.412932 22260 solver.cpp:218] Iteration 61900 (15.8192 iter/s, 6.32142s/100 iters), loss = 0.772395
I1211 08:02:09.413934 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:02:09.413934 22260 solver.cpp:237]     Train net output #1: loss = 0.772395 (* 1 = 0.772395 loss)
I1211 08:02:09.413934 22260 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1211 08:02:15.424353 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:02:15.675408 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62000.caffemodel
I1211 08:02:15.691408 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62000.solverstate
I1211 08:02:15.695408 22260 solver.cpp:330] Iteration 62000, Testing net (#0)
I1211 08:02:15.695408 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:02:17.210464 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:02:17.270472 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6084
I1211 08:02:17.270472 22260 solver.cpp:397]     Test net output #1: loss = 1.472 (* 1 = 1.472 loss)
I1211 08:02:17.331471 22260 solver.cpp:218] Iteration 62000 (12.6307 iter/s, 7.91719s/100 iters), loss = 0.719716
I1211 08:02:17.331471 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:02:17.331471 22260 solver.cpp:237]     Train net output #1: loss = 0.719716 (* 1 = 0.719716 loss)
I1211 08:02:17.331471 22260 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1211 08:02:23.655403 22260 solver.cpp:218] Iteration 62100 (15.8135 iter/s, 6.3237s/100 iters), loss = 0.704091
I1211 08:02:23.655403 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:02:23.655403 22260 solver.cpp:237]     Train net output #1: loss = 0.704091 (* 1 = 0.704091 loss)
I1211 08:02:23.655403 22260 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1211 08:02:29.976337 22260 solver.cpp:218] Iteration 62200 (15.8212 iter/s, 6.32063s/100 iters), loss = 0.719877
I1211 08:02:29.976337 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:02:29.976337 22260 solver.cpp:237]     Train net output #1: loss = 0.719877 (* 1 = 0.719877 loss)
I1211 08:02:29.976337 22260 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1211 08:02:36.295789 22260 solver.cpp:218] Iteration 62300 (15.8246 iter/s, 6.31929s/100 iters), loss = 0.714727
I1211 08:02:36.295789 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:02:36.295789 22260 solver.cpp:237]     Train net output #1: loss = 0.714727 (* 1 = 0.714727 loss)
I1211 08:02:36.295789 22260 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1211 08:02:42.614241 22260 solver.cpp:218] Iteration 62400 (15.828 iter/s, 6.3179s/100 iters), loss = 0.9311
I1211 08:02:42.614241 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 08:02:42.614241 22260 solver.cpp:237]     Train net output #1: loss = 0.9311 (* 1 = 0.9311 loss)
I1211 08:02:42.614241 22260 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1211 08:02:48.627686 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:02:48.878713 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62500.caffemodel
I1211 08:02:48.893712 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_62500.solverstate
I1211 08:02:48.897712 22260 solver.cpp:330] Iteration 62500, Testing net (#0)
I1211 08:02:48.897712 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:02:50.411816 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:02:50.471825 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6021
I1211 08:02:50.471825 22260 solver.cpp:397]     Test net output #1: loss = 1.4805 (* 1 = 1.4805 loss)
I1211 08:02:50.532824 22260 solver.cpp:218] Iteration 62500 (12.6298 iter/s, 7.91777s/100 iters), loss = 0.76366
I1211 08:02:50.532824 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:02:50.532824 22260 solver.cpp:237]     Train net output #1: loss = 0.76366 (* 1 = 0.76366 loss)
I1211 08:02:50.532824 22260 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1211 08:02:56.856240 22260 solver.cpp:218] Iteration 62600 (15.8162 iter/s, 6.32265s/100 iters), loss = 0.729812
I1211 08:02:56.856240 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:02:56.856240 22260 solver.cpp:237]     Train net output #1: loss = 0.729812 (* 1 = 0.729812 loss)
I1211 08:02:56.856240 22260 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1211 08:03:03.177752 22260 solver.cpp:218] Iteration 62700 (15.8182 iter/s, 6.32183s/100 iters), loss = 0.648412
I1211 08:03:03.177752 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:03:03.177752 22260 solver.cpp:237]     Train net output #1: loss = 0.648412 (* 1 = 0.648412 loss)
I1211 08:03:03.177752 22260 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1211 08:03:09.496248 22260 solver.cpp:218] Iteration 62800 (15.8293 iter/s, 6.31739s/100 iters), loss = 0.847812
I1211 08:03:09.496248 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:03:09.496248 22260 solver.cpp:237]     Train net output #1: loss = 0.847812 (* 1 = 0.847812 loss)
I1211 08:03:09.496248 22260 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1211 08:03:15.825891 22260 solver.cpp:218] Iteration 62900 (15.799 iter/s, 6.32951s/100 iters), loss = 0.868852
I1211 08:03:15.825891 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:03:15.825891 22260 solver.cpp:237]     Train net output #1: loss = 0.868852 (* 1 = 0.868852 loss)
I1211 08:03:15.825891 22260 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1211 08:03:21.835629 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:03:22.085646 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63000.caffemodel
I1211 08:03:22.100646 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63000.solverstate
I1211 08:03:22.105648 22260 solver.cpp:330] Iteration 63000, Testing net (#0)
I1211 08:03:22.105648 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:03:23.621765 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:03:23.681764 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6097
I1211 08:03:23.681764 22260 solver.cpp:397]     Test net output #1: loss = 1.41248 (* 1 = 1.41248 loss)
I1211 08:03:23.741771 22260 solver.cpp:218] Iteration 63000 (12.6335 iter/s, 7.91549s/100 iters), loss = 0.625824
I1211 08:03:23.741771 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:03:23.741771 22260 solver.cpp:237]     Train net output #1: loss = 0.625824 (* 1 = 0.625824 loss)
I1211 08:03:23.741771 22260 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1211 08:03:30.068126 22260 solver.cpp:218] Iteration 63100 (15.8091 iter/s, 6.32548s/100 iters), loss = 0.744121
I1211 08:03:30.068126 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:03:30.068126 22260 solver.cpp:237]     Train net output #1: loss = 0.744121 (* 1 = 0.744121 loss)
I1211 08:03:30.068126 22260 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1211 08:03:36.394608 22260 solver.cpp:218] Iteration 63200 (15.8061 iter/s, 6.32668s/100 iters), loss = 0.658083
I1211 08:03:36.394608 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:03:36.394608 22260 solver.cpp:237]     Train net output #1: loss = 0.658083 (* 1 = 0.658083 loss)
I1211 08:03:36.394608 22260 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1211 08:03:42.771126 22260 solver.cpp:218] Iteration 63300 (15.6841 iter/s, 6.3759s/100 iters), loss = 0.792168
I1211 08:03:42.771126 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:03:42.771126 22260 solver.cpp:237]     Train net output #1: loss = 0.792168 (* 1 = 0.792168 loss)
I1211 08:03:42.771126 22260 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1211 08:03:49.102087 22260 solver.cpp:218] Iteration 63400 (15.7972 iter/s, 6.33024s/100 iters), loss = 0.925267
I1211 08:03:49.102087 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 08:03:49.102087 22260 solver.cpp:237]     Train net output #1: loss = 0.925267 (* 1 = 0.925267 loss)
I1211 08:03:49.102087 22260 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1211 08:03:55.123993 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:03:55.374004 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63500.caffemodel
I1211 08:03:55.388005 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_63500.solverstate
I1211 08:03:55.393005 22260 solver.cpp:330] Iteration 63500, Testing net (#0)
I1211 08:03:55.393005 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:03:56.906128 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:03:56.966121 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5951
I1211 08:03:56.966121 22260 solver.cpp:397]     Test net output #1: loss = 1.55565 (* 1 = 1.55565 loss)
I1211 08:03:57.027124 22260 solver.cpp:218] Iteration 63500 (12.619 iter/s, 7.92459s/100 iters), loss = 0.711384
I1211 08:03:57.027124 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:03:57.027124 22260 solver.cpp:237]     Train net output #1: loss = 0.711384 (* 1 = 0.711384 loss)
I1211 08:03:57.027124 22260 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1211 08:04:03.358587 22260 solver.cpp:218] Iteration 63600 (15.7938 iter/s, 6.33161s/100 iters), loss = 0.718974
I1211 08:04:03.358587 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:04:03.358587 22260 solver.cpp:237]     Train net output #1: loss = 0.718974 (* 1 = 0.718974 loss)
I1211 08:04:03.358587 22260 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1211 08:04:09.697024 22260 solver.cpp:218] Iteration 63700 (15.7792 iter/s, 6.33745s/100 iters), loss = 0.657556
I1211 08:04:09.697024 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:04:09.697024 22260 solver.cpp:237]     Train net output #1: loss = 0.657556 (* 1 = 0.657556 loss)
I1211 08:04:09.697024 22260 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1211 08:04:16.028504 22260 solver.cpp:218] Iteration 63800 (15.7933 iter/s, 6.33178s/100 iters), loss = 0.819918
I1211 08:04:16.028504 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:04:16.028504 22260 solver.cpp:237]     Train net output #1: loss = 0.819918 (* 1 = 0.819918 loss)
I1211 08:04:16.028504 22260 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1211 08:04:22.363965 22260 solver.cpp:218] Iteration 63900 (15.7872 iter/s, 6.33425s/100 iters), loss = 0.901156
I1211 08:04:22.363965 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:04:22.363965 22260 solver.cpp:237]     Train net output #1: loss = 0.901156 (* 1 = 0.901156 loss)
I1211 08:04:22.363965 22260 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1211 08:04:28.384429 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:04:28.634449 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64000.caffemodel
I1211 08:04:28.650449 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64000.solverstate
I1211 08:04:28.654450 22260 solver.cpp:330] Iteration 64000, Testing net (#0)
I1211 08:04:28.654450 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:04:30.168555 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:04:30.228564 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5878
I1211 08:04:30.228564 22260 solver.cpp:397]     Test net output #1: loss = 1.54739 (* 1 = 1.54739 loss)
I1211 08:04:30.289563 22260 solver.cpp:218] Iteration 64000 (12.6175 iter/s, 7.9255s/100 iters), loss = 0.744872
I1211 08:04:30.289563 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:04:30.289563 22260 solver.cpp:237]     Train net output #1: loss = 0.744872 (* 1 = 0.744872 loss)
I1211 08:04:30.289563 22260 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1211 08:04:36.613979 22260 solver.cpp:218] Iteration 64100 (15.8132 iter/s, 6.32385s/100 iters), loss = 0.783744
I1211 08:04:36.613979 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:04:36.613979 22260 solver.cpp:237]     Train net output #1: loss = 0.783744 (* 1 = 0.783744 loss)
I1211 08:04:36.613979 22260 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1211 08:04:42.933408 22260 solver.cpp:218] Iteration 64200 (15.8249 iter/s, 6.31918s/100 iters), loss = 0.717811
I1211 08:04:42.933408 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:04:42.933408 22260 solver.cpp:237]     Train net output #1: loss = 0.717811 (* 1 = 0.717811 loss)
I1211 08:04:42.933408 22260 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1211 08:04:49.257838 22260 solver.cpp:218] Iteration 64300 (15.8122 iter/s, 6.32421s/100 iters), loss = 0.823007
I1211 08:04:49.257838 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 08:04:49.257838 22260 solver.cpp:237]     Train net output #1: loss = 0.823007 (* 1 = 0.823007 loss)
I1211 08:04:49.257838 22260 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1211 08:04:55.570256 22260 solver.cpp:218] Iteration 64400 (15.8433 iter/s, 6.3118s/100 iters), loss = 0.732385
I1211 08:04:55.570256 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:04:55.570256 22260 solver.cpp:237]     Train net output #1: loss = 0.732385 (* 1 = 0.732385 loss)
I1211 08:04:55.570256 22260 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1211 08:05:01.580742 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:05:01.828757 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64500.caffemodel
I1211 08:05:01.843760 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_64500.solverstate
I1211 08:05:01.848762 22260 solver.cpp:330] Iteration 64500, Testing net (#0)
I1211 08:05:01.848762 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:05:03.364167 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:05:03.424167 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6014
I1211 08:05:03.424167 22260 solver.cpp:397]     Test net output #1: loss = 1.49826 (* 1 = 1.49826 loss)
I1211 08:05:03.484174 22260 solver.cpp:218] Iteration 64500 (12.6366 iter/s, 7.91353s/100 iters), loss = 0.671268
I1211 08:05:03.484174 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:05:03.484174 22260 solver.cpp:237]     Train net output #1: loss = 0.671268 (* 1 = 0.671268 loss)
I1211 08:05:03.484174 22260 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1211 08:05:09.807656 22260 solver.cpp:218] Iteration 64600 (15.8169 iter/s, 6.32233s/100 iters), loss = 0.832233
I1211 08:05:09.807656 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:05:09.807656 22260 solver.cpp:237]     Train net output #1: loss = 0.832233 (* 1 = 0.832233 loss)
I1211 08:05:09.807656 22260 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1211 08:05:16.140128 22260 solver.cpp:218] Iteration 64700 (15.7922 iter/s, 6.33225s/100 iters), loss = 0.827483
I1211 08:05:16.140128 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:05:16.140128 22260 solver.cpp:237]     Train net output #1: loss = 0.827483 (* 1 = 0.827483 loss)
I1211 08:05:16.140128 22260 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1211 08:05:22.467630 22260 solver.cpp:218] Iteration 64800 (15.8054 iter/s, 6.32696s/100 iters), loss = 0.778319
I1211 08:05:22.467630 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:05:22.467630 22260 solver.cpp:237]     Train net output #1: loss = 0.778319 (* 1 = 0.778319 loss)
I1211 08:05:22.467630 22260 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1211 08:05:28.792105 22260 solver.cpp:218] Iteration 64900 (15.8122 iter/s, 6.32422s/100 iters), loss = 0.739479
I1211 08:05:28.792105 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:05:28.792105 22260 solver.cpp:237]     Train net output #1: loss = 0.739479 (* 1 = 0.739479 loss)
I1211 08:05:28.792105 22260 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1211 08:05:34.812965 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:05:35.062618 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65000.caffemodel
I1211 08:05:35.081619 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65000.solverstate
I1211 08:05:35.086621 22260 solver.cpp:330] Iteration 65000, Testing net (#0)
I1211 08:05:35.086621 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:05:36.603623 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:05:36.663621 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5923
I1211 08:05:36.663621 22260 solver.cpp:397]     Test net output #1: loss = 1.58731 (* 1 = 1.58731 loss)
I1211 08:05:36.723668 22260 solver.cpp:218] Iteration 65000 (12.6081 iter/s, 7.93142s/100 iters), loss = 0.703887
I1211 08:05:36.723668 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:05:36.723668 22260 solver.cpp:237]     Train net output #1: loss = 0.703887 (* 1 = 0.703887 loss)
I1211 08:05:36.723668 22260 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1211 08:05:43.070500 22260 solver.cpp:218] Iteration 65100 (15.7585 iter/s, 6.3458s/100 iters), loss = 0.826638
I1211 08:05:43.070500 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:05:43.070500 22260 solver.cpp:237]     Train net output #1: loss = 0.826638 (* 1 = 0.826638 loss)
I1211 08:05:43.070500 22260 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1211 08:05:49.409890 22260 solver.cpp:218] Iteration 65200 (15.7754 iter/s, 6.339s/100 iters), loss = 0.625684
I1211 08:05:49.409890 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:05:49.409890 22260 solver.cpp:237]     Train net output #1: loss = 0.625684 (* 1 = 0.625684 loss)
I1211 08:05:49.409890 22260 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1211 08:05:55.746023 22260 solver.cpp:218] Iteration 65300 (15.7825 iter/s, 6.33615s/100 iters), loss = 0.787179
I1211 08:05:55.746023 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:05:55.746023 22260 solver.cpp:237]     Train net output #1: loss = 0.787179 (* 1 = 0.787179 loss)
I1211 08:05:55.746023 22260 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1211 08:06:02.077479 22260 solver.cpp:218] Iteration 65400 (15.7945 iter/s, 6.3313s/100 iters), loss = 0.956803
I1211 08:06:02.077479 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 08:06:02.077479 22260 solver.cpp:237]     Train net output #1: loss = 0.956803 (* 1 = 0.956803 loss)
I1211 08:06:02.077479 22260 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1211 08:06:08.099982 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:06:08.347998 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65500.caffemodel
I1211 08:06:08.362998 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_65500.solverstate
I1211 08:06:08.366998 22260 solver.cpp:330] Iteration 65500, Testing net (#0)
I1211 08:06:08.366998 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:06:09.882114 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:06:09.942121 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6018
I1211 08:06:09.942121 22260 solver.cpp:397]     Test net output #1: loss = 1.48495 (* 1 = 1.48495 loss)
I1211 08:06:10.002120 22260 solver.cpp:218] Iteration 65500 (12.6195 iter/s, 7.92426s/100 iters), loss = 0.726926
I1211 08:06:10.003120 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:06:10.003120 22260 solver.cpp:237]     Train net output #1: loss = 0.726926 (* 1 = 0.726926 loss)
I1211 08:06:10.003120 22260 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1211 08:06:16.332567 22260 solver.cpp:218] Iteration 65600 (15.7981 iter/s, 6.32986s/100 iters), loss = 0.793441
I1211 08:06:16.332567 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:06:16.332567 22260 solver.cpp:237]     Train net output #1: loss = 0.793441 (* 1 = 0.793441 loss)
I1211 08:06:16.332567 22260 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1211 08:06:22.662071 22260 solver.cpp:218] Iteration 65700 (15.8009 iter/s, 6.32876s/100 iters), loss = 0.619561
I1211 08:06:22.662071 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:06:22.662071 22260 solver.cpp:237]     Train net output #1: loss = 0.619561 (* 1 = 0.619561 loss)
I1211 08:06:22.662071 22260 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1211 08:06:28.991600 22260 solver.cpp:218] Iteration 65800 (15.8007 iter/s, 6.32882s/100 iters), loss = 0.790936
I1211 08:06:28.991600 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:06:28.991600 22260 solver.cpp:237]     Train net output #1: loss = 0.790936 (* 1 = 0.790936 loss)
I1211 08:06:28.991600 22260 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1211 08:06:35.313004 22260 solver.cpp:218] Iteration 65900 (15.8191 iter/s, 6.32146s/100 iters), loss = 0.724826
I1211 08:06:35.313004 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:06:35.313004 22260 solver.cpp:237]     Train net output #1: loss = 0.724826 (* 1 = 0.724826 loss)
I1211 08:06:35.313004 22260 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1211 08:06:41.339288 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:06:41.588299 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66000.caffemodel
I1211 08:06:41.604300 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66000.solverstate
I1211 08:06:41.609814 22260 solver.cpp:330] Iteration 66000, Testing net (#0)
I1211 08:06:41.609814 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:06:43.122900 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:06:43.182401 22260 solver.cpp:397]     Test net output #0: accuracy = 0.619
I1211 08:06:43.183403 22260 solver.cpp:397]     Test net output #1: loss = 1.40368 (* 1 = 1.40368 loss)
I1211 08:06:43.243409 22260 solver.cpp:218] Iteration 66000 (12.6104 iter/s, 7.92998s/100 iters), loss = 0.57027
I1211 08:06:43.243409 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:06:43.243409 22260 solver.cpp:237]     Train net output #1: loss = 0.57027 (* 1 = 0.57027 loss)
I1211 08:06:43.243409 22260 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1211 08:06:49.569867 22260 solver.cpp:218] Iteration 66100 (15.8092 iter/s, 6.32542s/100 iters), loss = 0.657553
I1211 08:06:49.569867 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:06:49.569867 22260 solver.cpp:237]     Train net output #1: loss = 0.657553 (* 1 = 0.657553 loss)
I1211 08:06:49.569867 22260 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1211 08:06:55.900385 22260 solver.cpp:218] Iteration 66200 (15.796 iter/s, 6.33071s/100 iters), loss = 0.670625
I1211 08:06:55.900385 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:06:55.900385 22260 solver.cpp:237]     Train net output #1: loss = 0.670625 (* 1 = 0.670625 loss)
I1211 08:06:55.900385 22260 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1211 08:07:02.225354 22260 solver.cpp:218] Iteration 66300 (15.8125 iter/s, 6.3241s/100 iters), loss = 0.924749
I1211 08:07:02.225354 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:07:02.225354 22260 solver.cpp:237]     Train net output #1: loss = 0.924749 (* 1 = 0.924749 loss)
I1211 08:07:02.225354 22260 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1211 08:07:08.550328 22260 solver.cpp:218] Iteration 66400 (15.8107 iter/s, 6.32481s/100 iters), loss = 0.887909
I1211 08:07:08.550328 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:07:08.550328 22260 solver.cpp:237]     Train net output #1: loss = 0.887909 (* 1 = 0.887909 loss)
I1211 08:07:08.550328 22260 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1211 08:07:14.562937 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:07:14.812449 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66500.caffemodel
I1211 08:07:14.826951 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_66500.solverstate
I1211 08:07:14.830955 22260 solver.cpp:330] Iteration 66500, Testing net (#0)
I1211 08:07:14.830955 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:07:16.345062 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:07:16.405061 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6066
I1211 08:07:16.405061 22260 solver.cpp:397]     Test net output #1: loss = 1.4932 (* 1 = 1.4932 loss)
I1211 08:07:16.466068 22260 solver.cpp:218] Iteration 66500 (12.6342 iter/s, 7.915s/100 iters), loss = 0.636314
I1211 08:07:16.466068 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:07:16.466068 22260 solver.cpp:237]     Train net output #1: loss = 0.636314 (* 1 = 0.636314 loss)
I1211 08:07:16.466068 22260 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1211 08:07:22.788503 22260 solver.cpp:218] Iteration 66600 (15.8166 iter/s, 6.32247s/100 iters), loss = 0.761315
I1211 08:07:22.788503 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:07:22.788503 22260 solver.cpp:237]     Train net output #1: loss = 0.761315 (* 1 = 0.761315 loss)
I1211 08:07:22.788503 22260 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1211 08:07:29.110900 22260 solver.cpp:218] Iteration 66700 (15.8187 iter/s, 6.32163s/100 iters), loss = 0.781344
I1211 08:07:29.110900 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:07:29.110900 22260 solver.cpp:237]     Train net output #1: loss = 0.781344 (* 1 = 0.781344 loss)
I1211 08:07:29.110900 22260 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1211 08:07:35.424024 22260 solver.cpp:218] Iteration 66800 (15.8421 iter/s, 6.31228s/100 iters), loss = 0.853781
I1211 08:07:35.424024 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:07:35.424024 22260 solver.cpp:237]     Train net output #1: loss = 0.853781 (* 1 = 0.853781 loss)
I1211 08:07:35.424024 22260 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1211 08:07:41.742995 22260 solver.cpp:218] Iteration 66900 (15.8252 iter/s, 6.31903s/100 iters), loss = 0.907265
I1211 08:07:41.742995 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 08:07:41.742995 22260 solver.cpp:237]     Train net output #1: loss = 0.907265 (* 1 = 0.907265 loss)
I1211 08:07:41.742995 22260 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1211 08:07:47.749385 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:07:48.000404 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67000.caffemodel
I1211 08:07:48.014405 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67000.solverstate
I1211 08:07:48.018404 22260 solver.cpp:330] Iteration 67000, Testing net (#0)
I1211 08:07:48.018404 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:07:49.531505 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:07:49.591507 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6032
I1211 08:07:49.591507 22260 solver.cpp:397]     Test net output #1: loss = 1.45737 (* 1 = 1.45737 loss)
I1211 08:07:49.651523 22260 solver.cpp:218] Iteration 67000 (12.6448 iter/s, 7.90841s/100 iters), loss = 0.716573
I1211 08:07:49.651523 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:07:49.651523 22260 solver.cpp:237]     Train net output #1: loss = 0.716573 (* 1 = 0.716573 loss)
I1211 08:07:49.652524 22260 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1211 08:07:55.983080 22260 solver.cpp:218] Iteration 67100 (15.7961 iter/s, 6.33066s/100 iters), loss = 0.783158
I1211 08:07:55.983080 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:07:55.983080 22260 solver.cpp:237]     Train net output #1: loss = 0.783158 (* 1 = 0.783158 loss)
I1211 08:07:55.983080 22260 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1211 08:08:02.304569 22260 solver.cpp:218] Iteration 67200 (15.8198 iter/s, 6.32121s/100 iters), loss = 0.581053
I1211 08:08:02.304569 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:08:02.304569 22260 solver.cpp:237]     Train net output #1: loss = 0.581053 (* 1 = 0.581053 loss)
I1211 08:08:02.304569 22260 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1211 08:08:08.631520 22260 solver.cpp:218] Iteration 67300 (15.8078 iter/s, 6.326s/100 iters), loss = 0.880422
I1211 08:08:08.631520 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:08:08.631520 22260 solver.cpp:237]     Train net output #1: loss = 0.880422 (* 1 = 0.880422 loss)
I1211 08:08:08.631520 22260 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1211 08:08:14.948501 22260 solver.cpp:218] Iteration 67400 (15.8301 iter/s, 6.31709s/100 iters), loss = 0.92484
I1211 08:08:14.948501 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:08:14.948501 22260 solver.cpp:237]     Train net output #1: loss = 0.92484 (* 1 = 0.92484 loss)
I1211 08:08:14.948501 22260 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1211 08:08:20.957314 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:08:21.205957 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67500.caffemodel
I1211 08:08:21.220957 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_67500.solverstate
I1211 08:08:21.225956 22260 solver.cpp:330] Iteration 67500, Testing net (#0)
I1211 08:08:21.225956 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:08:22.740164 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:08:22.799681 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5848
I1211 08:08:22.799681 22260 solver.cpp:397]     Test net output #1: loss = 1.55856 (* 1 = 1.55856 loss)
I1211 08:08:22.860232 22260 solver.cpp:218] Iteration 67500 (12.6399 iter/s, 7.91147s/100 iters), loss = 0.721192
I1211 08:08:22.860232 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:08:22.860232 22260 solver.cpp:237]     Train net output #1: loss = 0.721192 (* 1 = 0.721192 loss)
I1211 08:08:22.860232 22260 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1211 08:08:29.195365 22260 solver.cpp:218] Iteration 67600 (15.7867 iter/s, 6.33443s/100 iters), loss = 0.8321
I1211 08:08:29.195365 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 08:08:29.195365 22260 solver.cpp:237]     Train net output #1: loss = 0.8321 (* 1 = 0.8321 loss)
I1211 08:08:29.195365 22260 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1211 08:08:35.519323 22260 solver.cpp:218] Iteration 67700 (15.8152 iter/s, 6.32304s/100 iters), loss = 0.695483
I1211 08:08:35.519323 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:08:35.519323 22260 solver.cpp:237]     Train net output #1: loss = 0.695483 (* 1 = 0.695483 loss)
I1211 08:08:35.519323 22260 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1211 08:08:41.841199 22260 solver.cpp:218] Iteration 67800 (15.8193 iter/s, 6.32139s/100 iters), loss = 0.804048
I1211 08:08:41.841199 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:08:41.841199 22260 solver.cpp:237]     Train net output #1: loss = 0.804048 (* 1 = 0.804048 loss)
I1211 08:08:41.841199 22260 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1211 08:08:48.173692 22260 solver.cpp:218] Iteration 67900 (15.7923 iter/s, 6.33219s/100 iters), loss = 0.87303
I1211 08:08:48.173692 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I1211 08:08:48.173692 22260 solver.cpp:237]     Train net output #1: loss = 0.87303 (* 1 = 0.87303 loss)
I1211 08:08:48.173692 22260 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1211 08:08:54.186106 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:08:54.434146 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68000.caffemodel
I1211 08:08:54.449146 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68000.solverstate
I1211 08:08:54.453146 22260 solver.cpp:330] Iteration 68000, Testing net (#0)
I1211 08:08:54.453146 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:08:55.968252 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:08:56.028257 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5802
I1211 08:08:56.028257 22260 solver.cpp:397]     Test net output #1: loss = 1.60202 (* 1 = 1.60202 loss)
I1211 08:08:56.089257 22260 solver.cpp:218] Iteration 68000 (12.6343 iter/s, 7.91494s/100 iters), loss = 0.775309
I1211 08:08:56.089257 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:08:56.089257 22260 solver.cpp:237]     Train net output #1: loss = 0.775309 (* 1 = 0.775309 loss)
I1211 08:08:56.089257 22260 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1211 08:09:02.410734 22260 solver.cpp:218] Iteration 68100 (15.8195 iter/s, 6.32131s/100 iters), loss = 0.680896
I1211 08:09:02.410734 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:09:02.410734 22260 solver.cpp:237]     Train net output #1: loss = 0.680896 (* 1 = 0.680896 loss)
I1211 08:09:02.410734 22260 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1211 08:09:08.729235 22260 solver.cpp:218] Iteration 68200 (15.8281 iter/s, 6.31789s/100 iters), loss = 0.761914
I1211 08:09:08.729235 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:09:08.729235 22260 solver.cpp:237]     Train net output #1: loss = 0.761914 (* 1 = 0.761914 loss)
I1211 08:09:08.729235 22260 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1211 08:09:15.053680 22260 solver.cpp:218] Iteration 68300 (15.8125 iter/s, 6.32412s/100 iters), loss = 0.781646
I1211 08:09:15.053680 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:09:15.053680 22260 solver.cpp:237]     Train net output #1: loss = 0.781646 (* 1 = 0.781646 loss)
I1211 08:09:15.053680 22260 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1211 08:09:21.370107 22260 solver.cpp:218] Iteration 68400 (15.8308 iter/s, 6.31681s/100 iters), loss = 0.950131
I1211 08:09:21.371109 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:09:21.371109 22260 solver.cpp:237]     Train net output #1: loss = 0.950131 (* 1 = 0.950131 loss)
I1211 08:09:21.371109 22260 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1211 08:09:27.382575 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:09:27.633594 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68500.caffemodel
I1211 08:09:27.647594 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_68500.solverstate
I1211 08:09:27.651594 22260 solver.cpp:330] Iteration 68500, Testing net (#0)
I1211 08:09:27.651594 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:09:29.167716 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:09:29.227723 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5868
I1211 08:09:29.227723 22260 solver.cpp:397]     Test net output #1: loss = 1.59625 (* 1 = 1.59625 loss)
I1211 08:09:29.288724 22260 solver.cpp:218] Iteration 68500 (12.6302 iter/s, 7.91754s/100 iters), loss = 0.788315
I1211 08:09:29.288724 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:09:29.288724 22260 solver.cpp:237]     Train net output #1: loss = 0.788315 (* 1 = 0.788315 loss)
I1211 08:09:29.288724 22260 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1211 08:09:35.619685 22260 solver.cpp:218] Iteration 68600 (15.797 iter/s, 6.33031s/100 iters), loss = 0.780683
I1211 08:09:35.619685 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:09:35.619685 22260 solver.cpp:237]     Train net output #1: loss = 0.780683 (* 1 = 0.780683 loss)
I1211 08:09:35.619685 22260 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1211 08:09:41.952666 22260 solver.cpp:218] Iteration 68700 (15.7914 iter/s, 6.33257s/100 iters), loss = 0.639421
I1211 08:09:41.952666 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:09:41.952666 22260 solver.cpp:237]     Train net output #1: loss = 0.639421 (* 1 = 0.639421 loss)
I1211 08:09:41.952666 22260 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1211 08:09:48.280056 22260 solver.cpp:218] Iteration 68800 (15.8035 iter/s, 6.32772s/100 iters), loss = 0.671836
I1211 08:09:48.280056 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:09:48.280056 22260 solver.cpp:237]     Train net output #1: loss = 0.671836 (* 1 = 0.671836 loss)
I1211 08:09:48.280056 22260 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1211 08:09:54.607477 22260 solver.cpp:218] Iteration 68900 (15.8067 iter/s, 6.32642s/100 iters), loss = 0.762532
I1211 08:09:54.607477 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:09:54.607477 22260 solver.cpp:237]     Train net output #1: loss = 0.762532 (* 1 = 0.762532 loss)
I1211 08:09:54.607477 22260 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1211 08:10:00.626879 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:10:00.876893 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69000.caffemodel
I1211 08:10:00.893894 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69000.solverstate
I1211 08:10:00.897893 22260 solver.cpp:330] Iteration 69000, Testing net (#0)
I1211 08:10:00.897893 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:10:02.412983 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:10:02.471987 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5832
I1211 08:10:02.472988 22260 solver.cpp:397]     Test net output #1: loss = 1.59165 (* 1 = 1.59165 loss)
I1211 08:10:02.533990 22260 solver.cpp:218] Iteration 69000 (12.6169 iter/s, 7.92586s/100 iters), loss = 0.655017
I1211 08:10:02.533990 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:10:02.533990 22260 solver.cpp:237]     Train net output #1: loss = 0.655017 (* 1 = 0.655017 loss)
I1211 08:10:02.533990 22260 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1211 08:10:08.856431 22260 solver.cpp:218] Iteration 69100 (15.8171 iter/s, 6.32226s/100 iters), loss = 0.822435
I1211 08:10:08.856431 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:10:08.856431 22260 solver.cpp:237]     Train net output #1: loss = 0.822435 (* 1 = 0.822435 loss)
I1211 08:10:08.856431 22260 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1211 08:10:15.172839 22260 solver.cpp:218] Iteration 69200 (15.8326 iter/s, 6.31606s/100 iters), loss = 0.656227
I1211 08:10:15.172839 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:10:15.172839 22260 solver.cpp:237]     Train net output #1: loss = 0.656227 (* 1 = 0.656227 loss)
I1211 08:10:15.172839 22260 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1211 08:10:21.488284 22260 solver.cpp:218] Iteration 69300 (15.8368 iter/s, 6.31441s/100 iters), loss = 0.941952
I1211 08:10:21.488284 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:10:21.488284 22260 solver.cpp:237]     Train net output #1: loss = 0.941952 (* 1 = 0.941952 loss)
I1211 08:10:21.488284 22260 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1211 08:10:27.800726 22260 solver.cpp:218] Iteration 69400 (15.8424 iter/s, 6.31219s/100 iters), loss = 0.714265
I1211 08:10:27.800726 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:10:27.800726 22260 solver.cpp:237]     Train net output #1: loss = 0.714265 (* 1 = 0.714265 loss)
I1211 08:10:27.800726 22260 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1211 08:10:33.803143 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:10:34.054158 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69500.caffemodel
I1211 08:10:34.068158 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_69500.solverstate
I1211 08:10:34.073159 22260 solver.cpp:330] Iteration 69500, Testing net (#0)
I1211 08:10:34.073159 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:10:35.586273 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:10:35.647282 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5773
I1211 08:10:35.647282 22260 solver.cpp:397]     Test net output #1: loss = 1.65122 (* 1 = 1.65122 loss)
I1211 08:10:35.707283 22260 solver.cpp:218] Iteration 69500 (12.6487 iter/s, 7.90593s/100 iters), loss = 0.732699
I1211 08:10:35.707283 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:10:35.707283 22260 solver.cpp:237]     Train net output #1: loss = 0.732699 (* 1 = 0.732699 loss)
I1211 08:10:35.707283 22260 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1211 08:10:42.034735 22260 solver.cpp:218] Iteration 69600 (15.8049 iter/s, 6.32716s/100 iters), loss = 0.640382
I1211 08:10:42.034735 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:10:42.034735 22260 solver.cpp:237]     Train net output #1: loss = 0.640382 (* 1 = 0.640382 loss)
I1211 08:10:42.034735 22260 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1211 08:10:48.368245 22260 solver.cpp:218] Iteration 69700 (15.7892 iter/s, 6.33344s/100 iters), loss = 0.720995
I1211 08:10:48.368245 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:10:48.368245 22260 solver.cpp:237]     Train net output #1: loss = 0.720995 (* 1 = 0.720995 loss)
I1211 08:10:48.368245 22260 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1211 08:10:54.700670 22260 solver.cpp:218] Iteration 69800 (15.7936 iter/s, 6.33166s/100 iters), loss = 0.774955
I1211 08:10:54.700670 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:10:54.700670 22260 solver.cpp:237]     Train net output #1: loss = 0.774955 (* 1 = 0.774955 loss)
I1211 08:10:54.700670 22260 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1211 08:11:01.034157 22260 solver.cpp:218] Iteration 69900 (15.789 iter/s, 6.33353s/100 iters), loss = 0.727082
I1211 08:11:01.034157 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:11:01.034157 22260 solver.cpp:237]     Train net output #1: loss = 0.727082 (* 1 = 0.727082 loss)
I1211 08:11:01.034157 22260 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1211 08:11:07.050603 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:11:07.301621 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70000.caffemodel
I1211 08:11:07.317621 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70000.solverstate
I1211 08:11:07.321621 22260 solver.cpp:330] Iteration 70000, Testing net (#0)
I1211 08:11:07.321621 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:11:08.835712 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:11:08.895717 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5802
I1211 08:11:08.895717 22260 solver.cpp:397]     Test net output #1: loss = 1.62209 (* 1 = 1.62209 loss)
I1211 08:11:08.956717 22260 solver.cpp:218] Iteration 70000 (12.6238 iter/s, 7.92154s/100 iters), loss = 0.694774
I1211 08:11:08.956717 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:11:08.956717 22260 solver.cpp:237]     Train net output #1: loss = 0.694774 (* 1 = 0.694774 loss)
I1211 08:11:08.956717 22260 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1211 08:11:15.294189 22260 solver.cpp:218] Iteration 70100 (15.7784 iter/s, 6.33778s/100 iters), loss = 0.785067
I1211 08:11:15.294189 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:11:15.294189 22260 solver.cpp:237]     Train net output #1: loss = 0.785067 (* 1 = 0.785067 loss)
I1211 08:11:15.294189 22260 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1211 08:11:21.628664 22260 solver.cpp:218] Iteration 70200 (15.7888 iter/s, 6.33362s/100 iters), loss = 0.547052
I1211 08:11:21.628664 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:11:21.628664 22260 solver.cpp:237]     Train net output #1: loss = 0.547052 (* 1 = 0.547052 loss)
I1211 08:11:21.628664 22260 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1211 08:11:27.955101 22260 solver.cpp:218] Iteration 70300 (15.8071 iter/s, 6.32628s/100 iters), loss = 0.721025
I1211 08:11:27.955101 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:11:27.955101 22260 solver.cpp:237]     Train net output #1: loss = 0.721025 (* 1 = 0.721025 loss)
I1211 08:11:27.955101 22260 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1211 08:11:34.274559 22260 solver.cpp:218] Iteration 70400 (15.8266 iter/s, 6.31849s/100 iters), loss = 0.719994
I1211 08:11:34.274559 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:11:34.274559 22260 solver.cpp:237]     Train net output #1: loss = 0.719994 (* 1 = 0.719994 loss)
I1211 08:11:34.274559 22260 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1211 08:11:40.296000 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:11:40.545011 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70500.caffemodel
I1211 08:11:40.561012 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_70500.solverstate
I1211 08:11:40.565516 22260 solver.cpp:330] Iteration 70500, Testing net (#0)
I1211 08:11:40.565516 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:11:42.078127 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:11:42.138130 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5795
I1211 08:11:42.138130 22260 solver.cpp:397]     Test net output #1: loss = 1.58552 (* 1 = 1.58552 loss)
I1211 08:11:42.198137 22260 solver.cpp:218] Iteration 70500 (12.6205 iter/s, 7.9236s/100 iters), loss = 0.60391
I1211 08:11:42.198137 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:11:42.198137 22260 solver.cpp:237]     Train net output #1: loss = 0.60391 (* 1 = 0.60391 loss)
I1211 08:11:42.198137 22260 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1211 08:11:48.526676 22260 solver.cpp:218] Iteration 70600 (15.8029 iter/s, 6.32795s/100 iters), loss = 0.74531
I1211 08:11:48.526676 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:11:48.526676 22260 solver.cpp:237]     Train net output #1: loss = 0.74531 (* 1 = 0.74531 loss)
I1211 08:11:48.526676 22260 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1211 08:11:54.861109 22260 solver.cpp:218] Iteration 70700 (15.7887 iter/s, 6.33362s/100 iters), loss = 0.668341
I1211 08:11:54.861109 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:11:54.861109 22260 solver.cpp:237]     Train net output #1: loss = 0.668341 (* 1 = 0.668341 loss)
I1211 08:11:54.861109 22260 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1211 08:12:01.193538 22260 solver.cpp:218] Iteration 70800 (15.7928 iter/s, 6.33201s/100 iters), loss = 0.783464
I1211 08:12:01.193538 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:12:01.193538 22260 solver.cpp:237]     Train net output #1: loss = 0.783464 (* 1 = 0.783464 loss)
I1211 08:12:01.193538 22260 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1211 08:12:07.523924 22260 solver.cpp:218] Iteration 70900 (15.7965 iter/s, 6.3305s/100 iters), loss = 0.968144
I1211 08:12:07.523924 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:12:07.523924 22260 solver.cpp:237]     Train net output #1: loss = 0.968144 (* 1 = 0.968144 loss)
I1211 08:12:07.523924 22260 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1211 08:12:13.546337 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:12:13.795368 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71000.caffemodel
I1211 08:12:13.811369 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71000.solverstate
I1211 08:12:13.815369 22260 solver.cpp:330] Iteration 71000, Testing net (#0)
I1211 08:12:13.815369 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:12:15.328478 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:12:15.388478 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5943
I1211 08:12:15.388478 22260 solver.cpp:397]     Test net output #1: loss = 1.53404 (* 1 = 1.53404 loss)
I1211 08:12:15.448477 22260 solver.cpp:218] Iteration 71000 (12.6202 iter/s, 7.92381s/100 iters), loss = 0.695297
I1211 08:12:15.448477 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:12:15.448477 22260 solver.cpp:237]     Train net output #1: loss = 0.695297 (* 1 = 0.695297 loss)
I1211 08:12:15.448477 22260 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1211 08:12:21.785992 22260 solver.cpp:218] Iteration 71100 (15.7801 iter/s, 6.33709s/100 iters), loss = 0.681822
I1211 08:12:21.785992 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:12:21.785992 22260 solver.cpp:237]     Train net output #1: loss = 0.681822 (* 1 = 0.681822 loss)
I1211 08:12:21.785992 22260 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1211 08:12:28.122431 22260 solver.cpp:218] Iteration 71200 (15.7833 iter/s, 6.33582s/100 iters), loss = 0.586299
I1211 08:12:28.122431 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:12:28.122431 22260 solver.cpp:237]     Train net output #1: loss = 0.586299 (* 1 = 0.586299 loss)
I1211 08:12:28.122431 22260 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1211 08:12:34.454887 22260 solver.cpp:218] Iteration 71300 (15.7921 iter/s, 6.33228s/100 iters), loss = 0.72526
I1211 08:12:34.454887 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:12:34.454887 22260 solver.cpp:237]     Train net output #1: loss = 0.72526 (* 1 = 0.72526 loss)
I1211 08:12:34.454887 22260 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1211 08:12:40.793408 22260 solver.cpp:218] Iteration 71400 (15.778 iter/s, 6.33794s/100 iters), loss = 0.786799
I1211 08:12:40.793408 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:12:40.793408 22260 solver.cpp:237]     Train net output #1: loss = 0.786799 (* 1 = 0.786799 loss)
I1211 08:12:40.793408 22260 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1211 08:12:46.819349 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:12:47.068878 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71500.caffemodel
I1211 08:12:47.082878 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_71500.solverstate
I1211 08:12:47.087878 22260 solver.cpp:330] Iteration 71500, Testing net (#0)
I1211 08:12:47.087878 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:12:48.601022 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:12:48.661026 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5989
I1211 08:12:48.661026 22260 solver.cpp:397]     Test net output #1: loss = 1.5204 (* 1 = 1.5204 loss)
I1211 08:12:48.722528 22260 solver.cpp:218] Iteration 71500 (12.6123 iter/s, 7.92879s/100 iters), loss = 0.659903
I1211 08:12:48.722528 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:12:48.722528 22260 solver.cpp:237]     Train net output #1: loss = 0.659903 (* 1 = 0.659903 loss)
I1211 08:12:48.722528 22260 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1211 08:12:55.056521 22260 solver.cpp:218] Iteration 71600 (15.7894 iter/s, 6.33334s/100 iters), loss = 0.693448
I1211 08:12:55.056521 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:12:55.056521 22260 solver.cpp:237]     Train net output #1: loss = 0.693448 (* 1 = 0.693448 loss)
I1211 08:12:55.056521 22260 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1211 08:13:01.387931 22260 solver.cpp:218] Iteration 71700 (15.7939 iter/s, 6.33156s/100 iters), loss = 0.627101
I1211 08:13:01.387931 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:13:01.387931 22260 solver.cpp:237]     Train net output #1: loss = 0.627101 (* 1 = 0.627101 loss)
I1211 08:13:01.387931 22260 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1211 08:13:07.717351 22260 solver.cpp:218] Iteration 71800 (15.8016 iter/s, 6.32849s/100 iters), loss = 0.737543
I1211 08:13:07.717351 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:13:07.717351 22260 solver.cpp:237]     Train net output #1: loss = 0.737543 (* 1 = 0.737543 loss)
I1211 08:13:07.717351 22260 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1211 08:13:14.059759 22260 solver.cpp:218] Iteration 71900 (15.7677 iter/s, 6.34208s/100 iters), loss = 0.788779
I1211 08:13:14.059759 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:13:14.059759 22260 solver.cpp:237]     Train net output #1: loss = 0.788779 (* 1 = 0.788779 loss)
I1211 08:13:14.059759 22260 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1211 08:13:20.084496 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:13:20.335564 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72000.caffemodel
I1211 08:13:20.351565 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72000.solverstate
I1211 08:13:20.356566 22260 solver.cpp:330] Iteration 72000, Testing net (#0)
I1211 08:13:20.356566 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:13:21.867010 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:13:21.927624 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5964
I1211 08:13:21.927624 22260 solver.cpp:397]     Test net output #1: loss = 1.56736 (* 1 = 1.56736 loss)
I1211 08:13:21.988631 22260 solver.cpp:218] Iteration 72000 (12.6128 iter/s, 7.92846s/100 iters), loss = 0.714299
I1211 08:13:21.988631 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:13:21.988631 22260 solver.cpp:237]     Train net output #1: loss = 0.714299 (* 1 = 0.714299 loss)
I1211 08:13:21.988631 22260 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1211 08:13:28.310127 22260 solver.cpp:218] Iteration 72100 (15.819 iter/s, 6.32151s/100 iters), loss = 0.804083
I1211 08:13:28.310127 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I1211 08:13:28.310127 22260 solver.cpp:237]     Train net output #1: loss = 0.804083 (* 1 = 0.804083 loss)
I1211 08:13:28.310127 22260 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1211 08:13:34.634579 22260 solver.cpp:218] Iteration 72200 (15.8127 iter/s, 6.32402s/100 iters), loss = 0.648469
I1211 08:13:34.634579 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:13:34.634579 22260 solver.cpp:237]     Train net output #1: loss = 0.648469 (* 1 = 0.648469 loss)
I1211 08:13:34.634579 22260 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1211 08:13:40.961014 22260 solver.cpp:218] Iteration 72300 (15.8081 iter/s, 6.32589s/100 iters), loss = 0.733162
I1211 08:13:40.961014 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:13:40.961014 22260 solver.cpp:237]     Train net output #1: loss = 0.733162 (* 1 = 0.733162 loss)
I1211 08:13:40.961014 22260 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1211 08:13:47.284620 22260 solver.cpp:218] Iteration 72400 (15.8155 iter/s, 6.32292s/100 iters), loss = 0.746134
I1211 08:13:47.284620 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:13:47.284620 22260 solver.cpp:237]     Train net output #1: loss = 0.746134 (* 1 = 0.746134 loss)
I1211 08:13:47.284620 22260 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1211 08:13:53.300088 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:13:53.551113 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72500.caffemodel
I1211 08:13:53.567119 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_72500.solverstate
I1211 08:13:53.571619 22260 solver.cpp:330] Iteration 72500, Testing net (#0)
I1211 08:13:53.571619 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:13:55.085530 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:13:55.145529 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5844
I1211 08:13:55.145529 22260 solver.cpp:397]     Test net output #1: loss = 1.63853 (* 1 = 1.63853 loss)
I1211 08:13:55.205535 22260 solver.cpp:218] Iteration 72500 (12.6247 iter/s, 7.92096s/100 iters), loss = 0.60296
I1211 08:13:55.205535 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:13:55.205535 22260 solver.cpp:237]     Train net output #1: loss = 0.60296 (* 1 = 0.60296 loss)
I1211 08:13:55.206537 22260 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1211 08:14:01.525315 22260 solver.cpp:218] Iteration 72600 (15.8253 iter/s, 6.31898s/100 iters), loss = 0.752719
I1211 08:14:01.525315 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:14:01.525315 22260 solver.cpp:237]     Train net output #1: loss = 0.752719 (* 1 = 0.752719 loss)
I1211 08:14:01.525315 22260 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1211 08:14:07.839726 22260 solver.cpp:218] Iteration 72700 (15.8375 iter/s, 6.31414s/100 iters), loss = 0.618661
I1211 08:14:07.839726 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:14:07.839726 22260 solver.cpp:237]     Train net output #1: loss = 0.618661 (* 1 = 0.618661 loss)
I1211 08:14:07.839726 22260 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1211 08:14:14.153164 22260 solver.cpp:218] Iteration 72800 (15.8397 iter/s, 6.31324s/100 iters), loss = 0.728684
I1211 08:14:14.154165 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:14:14.154165 22260 solver.cpp:237]     Train net output #1: loss = 0.728684 (* 1 = 0.728684 loss)
I1211 08:14:14.154165 22260 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1211 08:14:20.467620 22260 solver.cpp:218] Iteration 72900 (15.8394 iter/s, 6.31336s/100 iters), loss = 0.794116
I1211 08:14:20.467620 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:14:20.467620 22260 solver.cpp:237]     Train net output #1: loss = 0.794116 (* 1 = 0.794116 loss)
I1211 08:14:20.467620 22260 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1211 08:14:26.475108 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:14:26.723137 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73000.caffemodel
I1211 08:14:26.739137 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73000.solverstate
I1211 08:14:26.744138 22260 solver.cpp:330] Iteration 73000, Testing net (#0)
I1211 08:14:26.744138 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:14:28.257223 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:14:28.316229 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5605
I1211 08:14:28.316229 22260 solver.cpp:397]     Test net output #1: loss = 1.74313 (* 1 = 1.74313 loss)
I1211 08:14:28.377231 22260 solver.cpp:218] Iteration 73000 (12.6425 iter/s, 7.90982s/100 iters), loss = 0.767797
I1211 08:14:28.377231 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:14:28.377231 22260 solver.cpp:237]     Train net output #1: loss = 0.767797 (* 1 = 0.767797 loss)
I1211 08:14:28.378232 22260 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1211 08:14:34.712918 22260 solver.cpp:218] Iteration 73100 (15.7858 iter/s, 6.33482s/100 iters), loss = 0.859144
I1211 08:14:34.713419 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:14:34.713419 22260 solver.cpp:237]     Train net output #1: loss = 0.859144 (* 1 = 0.859144 loss)
I1211 08:14:34.713419 22260 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1211 08:14:41.045358 22260 solver.cpp:218] Iteration 73200 (15.7938 iter/s, 6.33162s/100 iters), loss = 0.663673
I1211 08:14:41.045358 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:14:41.045358 22260 solver.cpp:237]     Train net output #1: loss = 0.663673 (* 1 = 0.663673 loss)
I1211 08:14:41.045358 22260 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1211 08:14:47.387349 22260 solver.cpp:218] Iteration 73300 (15.7673 iter/s, 6.34225s/100 iters), loss = 0.995309
I1211 08:14:47.387349 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 08:14:47.387349 22260 solver.cpp:237]     Train net output #1: loss = 0.995309 (* 1 = 0.995309 loss)
I1211 08:14:47.387349 22260 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1211 08:14:53.733024 22260 solver.cpp:218] Iteration 73400 (15.761 iter/s, 6.34476s/100 iters), loss = 0.793866
I1211 08:14:53.733024 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:14:53.733024 22260 solver.cpp:237]     Train net output #1: loss = 0.793866 (* 1 = 0.793866 loss)
I1211 08:14:53.733024 22260 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1211 08:14:59.767463 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:15:00.017557 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73500.caffemodel
I1211 08:15:00.032631 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_73500.solverstate
I1211 08:15:00.036631 22260 solver.cpp:330] Iteration 73500, Testing net (#0)
I1211 08:15:00.036631 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:15:01.549772 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:15:01.609771 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5738
I1211 08:15:01.610772 22260 solver.cpp:397]     Test net output #1: loss = 1.67296 (* 1 = 1.67296 loss)
I1211 08:15:01.670814 22260 solver.cpp:218] Iteration 73500 (12.5977 iter/s, 7.93795s/100 iters), loss = 0.669953
I1211 08:15:01.670814 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:15:01.670814 22260 solver.cpp:237]     Train net output #1: loss = 0.669953 (* 1 = 0.669953 loss)
I1211 08:15:01.670814 22260 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1211 08:15:08.017379 22260 solver.cpp:218] Iteration 73600 (15.7577 iter/s, 6.34611s/100 iters), loss = 0.79096
I1211 08:15:08.017379 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:15:08.017379 22260 solver.cpp:237]     Train net output #1: loss = 0.79096 (* 1 = 0.79096 loss)
I1211 08:15:08.017379 22260 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1211 08:15:14.350843 22260 solver.cpp:218] Iteration 73700 (15.7916 iter/s, 6.33247s/100 iters), loss = 0.683887
I1211 08:15:14.350843 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:15:14.350843 22260 solver.cpp:237]     Train net output #1: loss = 0.683887 (* 1 = 0.683887 loss)
I1211 08:15:14.350843 22260 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1211 08:15:20.682301 22260 solver.cpp:218] Iteration 73800 (15.794 iter/s, 6.33151s/100 iters), loss = 0.837028
I1211 08:15:20.682301 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:15:20.682301 22260 solver.cpp:237]     Train net output #1: loss = 0.837028 (* 1 = 0.837028 loss)
I1211 08:15:20.682301 22260 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1211 08:15:27.021770 22260 solver.cpp:218] Iteration 73900 (15.7765 iter/s, 6.33856s/100 iters), loss = 0.799642
I1211 08:15:27.021770 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:15:27.021770 22260 solver.cpp:237]     Train net output #1: loss = 0.799642 (* 1 = 0.799642 loss)
I1211 08:15:27.021770 22260 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1211 08:15:33.040186 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:15:33.289216 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74000.caffemodel
I1211 08:15:33.304215 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74000.solverstate
I1211 08:15:33.308215 22260 solver.cpp:330] Iteration 74000, Testing net (#0)
I1211 08:15:33.308215 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:15:34.819314 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:15:34.879318 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5882
I1211 08:15:34.880319 22260 solver.cpp:397]     Test net output #1: loss = 1.62683 (* 1 = 1.62683 loss)
I1211 08:15:34.940318 22260 solver.cpp:218] Iteration 74000 (12.6283 iter/s, 7.91872s/100 iters), loss = 0.726058
I1211 08:15:34.940318 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:15:34.940318 22260 solver.cpp:237]     Train net output #1: loss = 0.726058 (* 1 = 0.726058 loss)
I1211 08:15:34.940318 22260 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1211 08:15:41.272785 22260 solver.cpp:218] Iteration 74100 (15.7936 iter/s, 6.33166s/100 iters), loss = 0.719033
I1211 08:15:41.272785 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:15:41.272785 22260 solver.cpp:237]     Train net output #1: loss = 0.719033 (* 1 = 0.719033 loss)
I1211 08:15:41.272785 22260 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1211 08:15:47.600265 22260 solver.cpp:218] Iteration 74200 (15.8058 iter/s, 6.32678s/100 iters), loss = 0.683481
I1211 08:15:47.600265 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:15:47.600265 22260 solver.cpp:237]     Train net output #1: loss = 0.683481 (* 1 = 0.683481 loss)
I1211 08:15:47.600265 22260 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1211 08:15:53.932737 22260 solver.cpp:218] Iteration 74300 (15.7915 iter/s, 6.33252s/100 iters), loss = 0.690604
I1211 08:15:53.932737 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:15:53.932737 22260 solver.cpp:237]     Train net output #1: loss = 0.690604 (* 1 = 0.690604 loss)
I1211 08:15:53.932737 22260 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1211 08:16:00.249169 22260 solver.cpp:218] Iteration 74400 (15.8342 iter/s, 6.31545s/100 iters), loss = 0.841552
I1211 08:16:00.249169 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:16:00.249169 22260 solver.cpp:237]     Train net output #1: loss = 0.841552 (* 1 = 0.841552 loss)
I1211 08:16:00.249169 22260 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1211 08:16:06.263590 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:16:06.511601 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74500.caffemodel
I1211 08:16:06.526602 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_74500.solverstate
I1211 08:16:06.531602 22260 solver.cpp:330] Iteration 74500, Testing net (#0)
I1211 08:16:06.531602 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:16:08.044708 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:16:08.104717 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5879
I1211 08:16:08.104717 22260 solver.cpp:397]     Test net output #1: loss = 1.58587 (* 1 = 1.58587 loss)
I1211 08:16:08.165719 22260 solver.cpp:218] Iteration 74500 (12.6321 iter/s, 7.91632s/100 iters), loss = 0.69284
I1211 08:16:08.165719 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:16:08.165719 22260 solver.cpp:237]     Train net output #1: loss = 0.69284 (* 1 = 0.69284 loss)
I1211 08:16:08.165719 22260 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1211 08:16:14.500174 22260 solver.cpp:218] Iteration 74600 (15.7861 iter/s, 6.33468s/100 iters), loss = 0.729699
I1211 08:16:14.501174 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:16:14.501174 22260 solver.cpp:237]     Train net output #1: loss = 0.729699 (* 1 = 0.729699 loss)
I1211 08:16:14.501174 22260 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1211 08:16:20.830610 22260 solver.cpp:218] Iteration 74700 (15.7977 iter/s, 6.33005s/100 iters), loss = 0.696608
I1211 08:16:20.831609 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:16:20.831609 22260 solver.cpp:237]     Train net output #1: loss = 0.696608 (* 1 = 0.696608 loss)
I1211 08:16:20.831609 22260 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1211 08:16:27.171072 22260 solver.cpp:218] Iteration 74800 (15.7747 iter/s, 6.33928s/100 iters), loss = 0.743864
I1211 08:16:27.171072 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:16:27.171072 22260 solver.cpp:237]     Train net output #1: loss = 0.743864 (* 1 = 0.743864 loss)
I1211 08:16:27.171072 22260 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1211 08:16:33.507545 22260 solver.cpp:218] Iteration 74900 (15.7826 iter/s, 6.33609s/100 iters), loss = 0.733347
I1211 08:16:33.507545 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:16:33.507545 22260 solver.cpp:237]     Train net output #1: loss = 0.733347 (* 1 = 0.733347 loss)
I1211 08:16:33.507545 22260 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1211 08:16:39.535965 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:16:39.786464 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75000.caffemodel
I1211 08:16:39.801964 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75000.solverstate
I1211 08:16:39.806464 22260 solver.cpp:330] Iteration 75000, Testing net (#0)
I1211 08:16:39.806464 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:16:41.333163 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:16:41.393167 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6005
I1211 08:16:41.393167 22260 solver.cpp:397]     Test net output #1: loss = 1.52214 (* 1 = 1.52214 loss)
I1211 08:16:41.453670 22260 solver.cpp:218] Iteration 75000 (12.5855 iter/s, 7.94567s/100 iters), loss = 0.679978
I1211 08:16:41.453670 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:16:41.453670 22260 solver.cpp:237]     Train net output #1: loss = 0.679978 (* 1 = 0.679978 loss)
I1211 08:16:41.453670 22260 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1211 08:16:47.785670 22260 solver.cpp:218] Iteration 75100 (15.7935 iter/s, 6.3317s/100 iters), loss = 0.758079
I1211 08:16:47.785670 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:16:47.785670 22260 solver.cpp:237]     Train net output #1: loss = 0.758079 (* 1 = 0.758079 loss)
I1211 08:16:47.785670 22260 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1211 08:16:54.119076 22260 solver.cpp:218] Iteration 75200 (15.7911 iter/s, 6.33268s/100 iters), loss = 0.704499
I1211 08:16:54.119076 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:16:54.119076 22260 solver.cpp:237]     Train net output #1: loss = 0.704499 (* 1 = 0.704499 loss)
I1211 08:16:54.119076 22260 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1211 08:17:00.456589 22260 solver.cpp:218] Iteration 75300 (15.7785 iter/s, 6.33773s/100 iters), loss = 0.760545
I1211 08:17:00.456589 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:17:00.456589 22260 solver.cpp:237]     Train net output #1: loss = 0.760545 (* 1 = 0.760545 loss)
I1211 08:17:00.456589 22260 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1211 08:17:06.785995 22260 solver.cpp:218] Iteration 75400 (15.8006 iter/s, 6.32886s/100 iters), loss = 0.729974
I1211 08:17:06.785995 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:17:06.785995 22260 solver.cpp:237]     Train net output #1: loss = 0.729974 (* 1 = 0.729974 loss)
I1211 08:17:06.785995 22260 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1211 08:17:12.802464 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:17:13.052480 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75500.caffemodel
I1211 08:17:13.067481 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_75500.solverstate
I1211 08:17:13.072480 22260 solver.cpp:330] Iteration 75500, Testing net (#0)
I1211 08:17:13.072480 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:17:14.586580 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:17:14.646584 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6118
I1211 08:17:14.646584 22260 solver.cpp:397]     Test net output #1: loss = 1.45986 (* 1 = 1.45986 loss)
I1211 08:17:14.707084 22260 solver.cpp:218] Iteration 75500 (12.626 iter/s, 7.92016s/100 iters), loss = 0.762397
I1211 08:17:14.707084 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:17:14.707084 22260 solver.cpp:237]     Train net output #1: loss = 0.762397 (* 1 = 0.762397 loss)
I1211 08:17:14.707084 22260 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1211 08:17:21.028053 22260 solver.cpp:218] Iteration 75600 (15.8216 iter/s, 6.32047s/100 iters), loss = 0.737823
I1211 08:17:21.028053 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:17:21.028053 22260 solver.cpp:237]     Train net output #1: loss = 0.737823 (* 1 = 0.737823 loss)
I1211 08:17:21.028053 22260 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1211 08:17:27.355510 22260 solver.cpp:218] Iteration 75700 (15.803 iter/s, 6.32793s/100 iters), loss = 0.54977
I1211 08:17:27.356511 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:17:27.356511 22260 solver.cpp:237]     Train net output #1: loss = 0.54977 (* 1 = 0.54977 loss)
I1211 08:17:27.356511 22260 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1211 08:17:33.680011 22260 solver.cpp:218] Iteration 75800 (15.8147 iter/s, 6.32324s/100 iters), loss = 0.702826
I1211 08:17:33.680011 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:17:33.680011 22260 solver.cpp:237]     Train net output #1: loss = 0.702826 (* 1 = 0.702826 loss)
I1211 08:17:33.680011 22260 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1211 08:17:40.002501 22260 solver.cpp:218] Iteration 75900 (15.8161 iter/s, 6.32267s/100 iters), loss = 0.712555
I1211 08:17:40.002501 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:17:40.002501 22260 solver.cpp:237]     Train net output #1: loss = 0.712555 (* 1 = 0.712555 loss)
I1211 08:17:40.002501 22260 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1211 08:17:46.013022 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:17:46.261041 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76000.caffemodel
I1211 08:17:46.278041 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76000.solverstate
I1211 08:17:46.282042 22260 solver.cpp:330] Iteration 76000, Testing net (#0)
I1211 08:17:46.282042 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:17:47.796159 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:17:47.856164 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5979
I1211 08:17:47.856164 22260 solver.cpp:397]     Test net output #1: loss = 1.5782 (* 1 = 1.5782 loss)
I1211 08:17:47.916163 22260 solver.cpp:218] Iteration 76000 (12.6375 iter/s, 7.91298s/100 iters), loss = 0.727361
I1211 08:17:47.916163 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:17:47.916163 22260 solver.cpp:237]     Train net output #1: loss = 0.727361 (* 1 = 0.727361 loss)
I1211 08:17:47.916163 22260 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1211 08:17:54.250142 22260 solver.cpp:218] Iteration 76100 (15.79 iter/s, 6.33314s/100 iters), loss = 0.854755
I1211 08:17:54.250142 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:17:54.250142 22260 solver.cpp:237]     Train net output #1: loss = 0.854755 (* 1 = 0.854755 loss)
I1211 08:17:54.250142 22260 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1211 08:18:00.581063 22260 solver.cpp:218] Iteration 76200 (15.7962 iter/s, 6.33063s/100 iters), loss = 0.650302
I1211 08:18:00.581063 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:18:00.581063 22260 solver.cpp:237]     Train net output #1: loss = 0.650302 (* 1 = 0.650302 loss)
I1211 08:18:00.581063 22260 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1211 08:18:06.902495 22260 solver.cpp:218] Iteration 76300 (15.8191 iter/s, 6.32146s/100 iters), loss = 0.743311
I1211 08:18:06.902495 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:18:06.902495 22260 solver.cpp:237]     Train net output #1: loss = 0.743311 (* 1 = 0.743311 loss)
I1211 08:18:06.902495 22260 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1211 08:18:13.246942 22260 solver.cpp:218] Iteration 76400 (15.7642 iter/s, 6.3435s/100 iters), loss = 0.649874
I1211 08:18:13.246942 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:18:13.246942 22260 solver.cpp:237]     Train net output #1: loss = 0.649874 (* 1 = 0.649874 loss)
I1211 08:18:13.246942 22260 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1211 08:18:19.271349 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:18:19.520359 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76500.caffemodel
I1211 08:18:19.535360 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_76500.solverstate
I1211 08:18:19.539863 22260 solver.cpp:330] Iteration 76500, Testing net (#0)
I1211 08:18:19.539863 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:18:21.053562 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:18:21.113567 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5932
I1211 08:18:21.113567 22260 solver.cpp:397]     Test net output #1: loss = 1.57256 (* 1 = 1.57256 loss)
I1211 08:18:21.173575 22260 solver.cpp:218] Iteration 76500 (12.6153 iter/s, 7.92685s/100 iters), loss = 0.587457
I1211 08:18:21.173575 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:18:21.173575 22260 solver.cpp:237]     Train net output #1: loss = 0.587457 (* 1 = 0.587457 loss)
I1211 08:18:21.173575 22260 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1211 08:18:27.501057 22260 solver.cpp:218] Iteration 76600 (15.8066 iter/s, 6.32648s/100 iters), loss = 0.618178
I1211 08:18:27.501057 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:18:27.501057 22260 solver.cpp:237]     Train net output #1: loss = 0.618178 (* 1 = 0.618178 loss)
I1211 08:18:27.501057 22260 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1211 08:18:33.834475 22260 solver.cpp:218] Iteration 76700 (15.7904 iter/s, 6.33294s/100 iters), loss = 0.756831
I1211 08:18:33.834475 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:18:33.834475 22260 solver.cpp:237]     Train net output #1: loss = 0.756831 (* 1 = 0.756831 loss)
I1211 08:18:33.834475 22260 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1211 08:18:40.161895 22260 solver.cpp:218] Iteration 76800 (15.8057 iter/s, 6.32682s/100 iters), loss = 0.772083
I1211 08:18:40.161895 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:18:40.161895 22260 solver.cpp:237]     Train net output #1: loss = 0.772083 (* 1 = 0.772083 loss)
I1211 08:18:40.161895 22260 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1211 08:18:46.489384 22260 solver.cpp:218] Iteration 76900 (15.8037 iter/s, 6.32762s/100 iters), loss = 0.72412
I1211 08:18:46.489384 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:18:46.489384 22260 solver.cpp:237]     Train net output #1: loss = 0.72412 (* 1 = 0.72412 loss)
I1211 08:18:46.489384 22260 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1211 08:18:52.503914 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:18:52.754930 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77000.caffemodel
I1211 08:18:52.769934 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77000.solverstate
I1211 08:18:52.773934 22260 solver.cpp:330] Iteration 77000, Testing net (#0)
I1211 08:18:52.773934 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:18:54.285061 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:18:54.345065 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5778
I1211 08:18:54.345569 22260 solver.cpp:397]     Test net output #1: loss = 1.69449 (* 1 = 1.69449 loss)
I1211 08:18:54.406067 22260 solver.cpp:218] Iteration 77000 (12.6324 iter/s, 7.91616s/100 iters), loss = 0.655881
I1211 08:18:54.406067 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:18:54.406067 22260 solver.cpp:237]     Train net output #1: loss = 0.655881 (* 1 = 0.655881 loss)
I1211 08:18:54.406067 22260 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1211 08:19:00.739542 22260 solver.cpp:218] Iteration 77100 (15.7902 iter/s, 6.33303s/100 iters), loss = 0.74855
I1211 08:19:00.739542 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:19:00.739542 22260 solver.cpp:237]     Train net output #1: loss = 0.74855 (* 1 = 0.74855 loss)
I1211 08:19:00.739542 22260 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1211 08:19:07.071532 22260 solver.cpp:218] Iteration 77200 (15.794 iter/s, 6.33152s/100 iters), loss = 0.624507
I1211 08:19:07.072032 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:19:07.072032 22260 solver.cpp:237]     Train net output #1: loss = 0.624507 (* 1 = 0.624507 loss)
I1211 08:19:07.072032 22260 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1211 08:19:13.397687 22260 solver.cpp:218] Iteration 77300 (15.8085 iter/s, 6.3257s/100 iters), loss = 0.689562
I1211 08:19:13.397687 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:19:13.397687 22260 solver.cpp:237]     Train net output #1: loss = 0.689562 (* 1 = 0.689562 loss)
I1211 08:19:13.397687 22260 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1211 08:19:19.722136 22260 solver.cpp:218] Iteration 77400 (15.813 iter/s, 6.32391s/100 iters), loss = 0.838539
I1211 08:19:19.722136 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:19:19.722136 22260 solver.cpp:237]     Train net output #1: loss = 0.838539 (* 1 = 0.838539 loss)
I1211 08:19:19.722136 22260 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1211 08:19:25.738625 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:19:25.988637 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77500.caffemodel
I1211 08:19:26.002637 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_77500.solverstate
I1211 08:19:26.007638 22260 solver.cpp:330] Iteration 77500, Testing net (#0)
I1211 08:19:26.007638 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:19:27.522739 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:19:27.582741 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5653
I1211 08:19:27.582741 22260 solver.cpp:397]     Test net output #1: loss = 1.78417 (* 1 = 1.78417 loss)
I1211 08:19:27.643734 22260 solver.cpp:218] Iteration 77500 (12.6249 iter/s, 7.92084s/100 iters), loss = 0.690524
I1211 08:19:27.643734 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:19:27.643734 22260 solver.cpp:237]     Train net output #1: loss = 0.690524 (* 1 = 0.690524 loss)
I1211 08:19:27.643734 22260 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1211 08:19:33.970244 22260 solver.cpp:218] Iteration 77600 (15.8064 iter/s, 6.32653s/100 iters), loss = 0.713581
I1211 08:19:33.970244 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:19:33.970244 22260 solver.cpp:237]     Train net output #1: loss = 0.713581 (* 1 = 0.713581 loss)
I1211 08:19:33.970244 22260 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1211 08:19:40.288705 22260 solver.cpp:218] Iteration 77700 (15.8278 iter/s, 6.31801s/100 iters), loss = 0.582933
I1211 08:19:40.288705 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:19:40.288705 22260 solver.cpp:237]     Train net output #1: loss = 0.582933 (* 1 = 0.582933 loss)
I1211 08:19:40.288705 22260 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1211 08:19:46.616096 22260 solver.cpp:218] Iteration 77800 (15.8059 iter/s, 6.32674s/100 iters), loss = 0.680339
I1211 08:19:46.616096 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:19:46.616096 22260 solver.cpp:237]     Train net output #1: loss = 0.680339 (* 1 = 0.680339 loss)
I1211 08:19:46.616096 22260 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1211 08:19:52.937566 22260 solver.cpp:218] Iteration 77900 (15.8207 iter/s, 6.32083s/100 iters), loss = 0.743342
I1211 08:19:52.937566 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:19:52.937566 22260 solver.cpp:237]     Train net output #1: loss = 0.743342 (* 1 = 0.743342 loss)
I1211 08:19:52.937566 22260 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1211 08:19:58.951026 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:19:59.200040 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78000.caffemodel
I1211 08:19:59.217041 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78000.solverstate
I1211 08:19:59.221040 22260 solver.cpp:330] Iteration 78000, Testing net (#0)
I1211 08:19:59.222041 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:20:00.735157 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:20:00.795178 22260 solver.cpp:397]     Test net output #0: accuracy = 0.596
I1211 08:20:00.795178 22260 solver.cpp:397]     Test net output #1: loss = 1.54884 (* 1 = 1.54884 loss)
I1211 08:20:00.855170 22260 solver.cpp:218] Iteration 78000 (12.6303 iter/s, 7.91748s/100 iters), loss = 0.551926
I1211 08:20:00.855170 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:20:00.855674 22260 solver.cpp:237]     Train net output #1: loss = 0.551926 (* 1 = 0.551926 loss)
I1211 08:20:00.855674 22260 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1211 08:20:07.168586 22260 solver.cpp:218] Iteration 78100 (15.8414 iter/s, 6.31256s/100 iters), loss = 0.612595
I1211 08:20:07.168586 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:20:07.168586 22260 solver.cpp:237]     Train net output #1: loss = 0.612595 (* 1 = 0.612595 loss)
I1211 08:20:07.168586 22260 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1211 08:20:13.490067 22260 solver.cpp:218] Iteration 78200 (15.8196 iter/s, 6.32127s/100 iters), loss = 0.64248
I1211 08:20:13.490067 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:20:13.490067 22260 solver.cpp:237]     Train net output #1: loss = 0.64248 (* 1 = 0.64248 loss)
I1211 08:20:13.490067 22260 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1211 08:20:19.806519 22260 solver.cpp:218] Iteration 78300 (15.8325 iter/s, 6.31612s/100 iters), loss = 0.774191
I1211 08:20:19.806519 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:20:19.806519 22260 solver.cpp:237]     Train net output #1: loss = 0.774191 (* 1 = 0.774191 loss)
I1211 08:20:19.806519 22260 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1211 08:20:26.126950 22260 solver.cpp:218] Iteration 78400 (15.8215 iter/s, 6.3205s/100 iters), loss = 0.759307
I1211 08:20:26.126950 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:20:26.126950 22260 solver.cpp:237]     Train net output #1: loss = 0.759307 (* 1 = 0.759307 loss)
I1211 08:20:26.126950 22260 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1211 08:20:32.128952 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:20:32.377008 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78500.caffemodel
I1211 08:20:32.397007 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_78500.solverstate
I1211 08:20:32.402004 22260 solver.cpp:330] Iteration 78500, Testing net (#0)
I1211 08:20:32.402004 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:20:33.913604 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:20:33.974128 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5912
I1211 08:20:33.974128 22260 solver.cpp:397]     Test net output #1: loss = 1.63138 (* 1 = 1.63138 loss)
I1211 08:20:34.034236 22260 solver.cpp:218] Iteration 78500 (12.6477 iter/s, 7.90656s/100 iters), loss = 0.677234
I1211 08:20:34.034236 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:20:34.034236 22260 solver.cpp:237]     Train net output #1: loss = 0.677234 (* 1 = 0.677234 loss)
I1211 08:20:34.034236 22260 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1211 08:20:40.355500 22260 solver.cpp:218] Iteration 78600 (15.8206 iter/s, 6.32086s/100 iters), loss = 0.786722
I1211 08:20:40.355500 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:20:40.355500 22260 solver.cpp:237]     Train net output #1: loss = 0.786722 (* 1 = 0.786722 loss)
I1211 08:20:40.355500 22260 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1211 08:20:46.673148 22260 solver.cpp:218] Iteration 78700 (15.8311 iter/s, 6.31667s/100 iters), loss = 0.599115
I1211 08:20:46.673148 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:20:46.673148 22260 solver.cpp:237]     Train net output #1: loss = 0.599115 (* 1 = 0.599115 loss)
I1211 08:20:46.673148 22260 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1211 08:20:53.000121 22260 solver.cpp:218] Iteration 78800 (15.8062 iter/s, 6.32665s/100 iters), loss = 0.716681
I1211 08:20:53.000121 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:20:53.000121 22260 solver.cpp:237]     Train net output #1: loss = 0.716681 (* 1 = 0.716681 loss)
I1211 08:20:53.000121 22260 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1211 08:20:59.319533 22260 solver.cpp:218] Iteration 78900 (15.8233 iter/s, 6.31981s/100 iters), loss = 0.81176
I1211 08:20:59.320533 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:20:59.320533 22260 solver.cpp:237]     Train net output #1: loss = 0.81176 (* 1 = 0.81176 loss)
I1211 08:20:59.320533 22260 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1211 08:21:05.338973 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:21:05.588989 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79000.caffemodel
I1211 08:21:05.603989 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79000.solverstate
I1211 08:21:05.607990 22260 solver.cpp:330] Iteration 79000, Testing net (#0)
I1211 08:21:05.607990 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:21:07.123101 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:21:07.183105 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5804
I1211 08:21:07.183105 22260 solver.cpp:397]     Test net output #1: loss = 1.66421 (* 1 = 1.66421 loss)
I1211 08:21:07.244105 22260 solver.cpp:218] Iteration 79000 (12.621 iter/s, 7.92332s/100 iters), loss = 0.638114
I1211 08:21:07.244105 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:21:07.244105 22260 solver.cpp:237]     Train net output #1: loss = 0.638114 (* 1 = 0.638114 loss)
I1211 08:21:07.244105 22260 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1211 08:21:13.560565 22260 solver.cpp:218] Iteration 79100 (15.8319 iter/s, 6.31635s/100 iters), loss = 0.640129
I1211 08:21:13.560565 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:21:13.560565 22260 solver.cpp:237]     Train net output #1: loss = 0.640129 (* 1 = 0.640129 loss)
I1211 08:21:13.560565 22260 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1211 08:21:19.884070 22260 solver.cpp:218] Iteration 79200 (15.8164 iter/s, 6.32256s/100 iters), loss = 0.628983
I1211 08:21:19.884070 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:21:19.884070 22260 solver.cpp:237]     Train net output #1: loss = 0.628983 (* 1 = 0.628983 loss)
I1211 08:21:19.884070 22260 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1211 08:21:26.206533 22260 solver.cpp:218] Iteration 79300 (15.8169 iter/s, 6.32234s/100 iters), loss = 0.675679
I1211 08:21:26.206533 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:21:26.206533 22260 solver.cpp:237]     Train net output #1: loss = 0.675679 (* 1 = 0.675679 loss)
I1211 08:21:26.206533 22260 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1211 08:21:32.529990 22260 solver.cpp:218] Iteration 79400 (15.8147 iter/s, 6.32323s/100 iters), loss = 0.766805
I1211 08:21:32.529990 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:21:32.529990 22260 solver.cpp:237]     Train net output #1: loss = 0.766805 (* 1 = 0.766805 loss)
I1211 08:21:32.529990 22260 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1211 08:21:38.544457 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:21:38.793473 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79500.caffemodel
I1211 08:21:38.809473 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_79500.solverstate
I1211 08:21:38.814473 22260 solver.cpp:330] Iteration 79500, Testing net (#0)
I1211 08:21:38.814473 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:21:40.327564 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:21:40.387569 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5504
I1211 08:21:40.387569 22260 solver.cpp:397]     Test net output #1: loss = 1.85065 (* 1 = 1.85065 loss)
I1211 08:21:40.448568 22260 solver.cpp:218] Iteration 79500 (12.6295 iter/s, 7.91798s/100 iters), loss = 0.723101
I1211 08:21:40.448568 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:21:40.448568 22260 solver.cpp:237]     Train net output #1: loss = 0.723101 (* 1 = 0.723101 loss)
I1211 08:21:40.448568 22260 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1211 08:21:46.784051 22260 solver.cpp:218] Iteration 79600 (15.7847 iter/s, 6.33523s/100 iters), loss = 0.688893
I1211 08:21:46.784051 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:21:46.784051 22260 solver.cpp:237]     Train net output #1: loss = 0.688893 (* 1 = 0.688893 loss)
I1211 08:21:46.784051 22260 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1211 08:21:53.115007 22260 solver.cpp:218] Iteration 79700 (15.7975 iter/s, 6.3301s/100 iters), loss = 0.617461
I1211 08:21:53.115007 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:21:53.115007 22260 solver.cpp:237]     Train net output #1: loss = 0.617461 (* 1 = 0.617461 loss)
I1211 08:21:53.115007 22260 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1211 08:21:59.439904 22260 solver.cpp:218] Iteration 79800 (15.8112 iter/s, 6.32462s/100 iters), loss = 0.761263
I1211 08:21:59.439904 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:21:59.439904 22260 solver.cpp:237]     Train net output #1: loss = 0.761263 (* 1 = 0.761263 loss)
I1211 08:21:59.439904 22260 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1211 08:22:05.775329 22260 solver.cpp:218] Iteration 79900 (15.7843 iter/s, 6.33541s/100 iters), loss = 0.766878
I1211 08:22:05.775329 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:22:05.775329 22260 solver.cpp:237]     Train net output #1: loss = 0.766878 (* 1 = 0.766878 loss)
I1211 08:22:05.775329 22260 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1211 08:22:11.800727 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:22:12.052754 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80000.caffemodel
I1211 08:22:12.066754 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80000.solverstate
I1211 08:22:12.071753 22260 solver.cpp:330] Iteration 80000, Testing net (#0)
I1211 08:22:12.071753 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:22:13.583855 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:22:13.643859 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5887
I1211 08:22:13.643859 22260 solver.cpp:397]     Test net output #1: loss = 1.61192 (* 1 = 1.61192 loss)
I1211 08:22:13.703858 22260 solver.cpp:218] Iteration 80000 (12.6131 iter/s, 7.92826s/100 iters), loss = 0.702967
I1211 08:22:13.703858 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:22:13.703858 22260 solver.cpp:237]     Train net output #1: loss = 0.702967 (* 1 = 0.702967 loss)
I1211 08:22:13.703858 22260 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1211 08:22:20.040421 22260 solver.cpp:218] Iteration 80100 (15.7822 iter/s, 6.33627s/100 iters), loss = 0.733837
I1211 08:22:20.041421 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:22:20.041421 22260 solver.cpp:237]     Train net output #1: loss = 0.733837 (* 1 = 0.733837 loss)
I1211 08:22:20.041421 22260 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1211 08:22:26.377883 22260 solver.cpp:218] Iteration 80200 (15.7817 iter/s, 6.33645s/100 iters), loss = 0.636951
I1211 08:22:26.377883 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:22:26.377883 22260 solver.cpp:237]     Train net output #1: loss = 0.636951 (* 1 = 0.636951 loss)
I1211 08:22:26.377883 22260 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1211 08:22:32.706375 22260 solver.cpp:218] Iteration 80300 (15.8012 iter/s, 6.32862s/100 iters), loss = 0.687936
I1211 08:22:32.707375 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:22:32.707375 22260 solver.cpp:237]     Train net output #1: loss = 0.687936 (* 1 = 0.687936 loss)
I1211 08:22:32.707375 22260 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1211 08:22:39.038904 22260 solver.cpp:218] Iteration 80400 (15.7947 iter/s, 6.33126s/100 iters), loss = 0.77248
I1211 08:22:39.038904 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:22:39.038904 22260 solver.cpp:237]     Train net output #1: loss = 0.77248 (* 1 = 0.77248 loss)
I1211 08:22:39.038904 22260 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1211 08:22:45.065336 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:22:45.314362 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80500.caffemodel
I1211 08:22:45.328366 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_80500.solverstate
I1211 08:22:45.333366 22260 solver.cpp:330] Iteration 80500, Testing net (#0)
I1211 08:22:45.333366 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:22:46.845485 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:22:46.906486 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5719
I1211 08:22:46.906486 22260 solver.cpp:397]     Test net output #1: loss = 1.67831 (* 1 = 1.67831 loss)
I1211 08:22:46.966491 22260 solver.cpp:218] Iteration 80500 (12.6147 iter/s, 7.92726s/100 iters), loss = 0.620847
I1211 08:22:46.966491 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:22:46.966491 22260 solver.cpp:237]     Train net output #1: loss = 0.620847 (* 1 = 0.620847 loss)
I1211 08:22:46.966491 22260 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1211 08:22:53.289913 22260 solver.cpp:218] Iteration 80600 (15.815 iter/s, 6.32311s/100 iters), loss = 0.665376
I1211 08:22:53.289913 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:22:53.289913 22260 solver.cpp:237]     Train net output #1: loss = 0.665376 (* 1 = 0.665376 loss)
I1211 08:22:53.289913 22260 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1211 08:22:59.611351 22260 solver.cpp:218] Iteration 80700 (15.8208 iter/s, 6.32079s/100 iters), loss = 0.607975
I1211 08:22:59.611351 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:22:59.611351 22260 solver.cpp:237]     Train net output #1: loss = 0.607975 (* 1 = 0.607975 loss)
I1211 08:22:59.611351 22260 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1211 08:23:05.940757 22260 solver.cpp:218] Iteration 80800 (15.8005 iter/s, 6.32892s/100 iters), loss = 0.781868
I1211 08:23:05.940757 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:23:05.940757 22260 solver.cpp:237]     Train net output #1: loss = 0.781868 (* 1 = 0.781868 loss)
I1211 08:23:05.940757 22260 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1211 08:23:12.271237 22260 solver.cpp:218] Iteration 80900 (15.7954 iter/s, 6.33096s/100 iters), loss = 0.687113
I1211 08:23:12.272238 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:23:12.272238 22260 solver.cpp:237]     Train net output #1: loss = 0.687113 (* 1 = 0.687113 loss)
I1211 08:23:12.272238 22260 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1211 08:23:18.283720 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:23:18.532737 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81000.caffemodel
I1211 08:23:18.547736 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81000.solverstate
I1211 08:23:18.552737 22260 solver.cpp:330] Iteration 81000, Testing net (#0)
I1211 08:23:18.552737 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:23:20.064828 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:23:20.125336 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5826
I1211 08:23:20.125336 22260 solver.cpp:397]     Test net output #1: loss = 1.68482 (* 1 = 1.68482 loss)
I1211 08:23:20.186835 22260 solver.cpp:218] Iteration 81000 (12.6354 iter/s, 7.91425s/100 iters), loss = 0.721
I1211 08:23:20.186835 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:23:20.186835 22260 solver.cpp:237]     Train net output #1: loss = 0.721 (* 1 = 0.721 loss)
I1211 08:23:20.186835 22260 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1211 08:23:26.527240 22260 solver.cpp:218] Iteration 81100 (15.773 iter/s, 6.33994s/100 iters), loss = 0.714184
I1211 08:23:26.527240 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:23:26.527240 22260 solver.cpp:237]     Train net output #1: loss = 0.714184 (* 1 = 0.714184 loss)
I1211 08:23:26.527240 22260 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1211 08:23:32.866761 22260 solver.cpp:218] Iteration 81200 (15.7749 iter/s, 6.33917s/100 iters), loss = 0.731384
I1211 08:23:32.866761 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:23:32.866761 22260 solver.cpp:237]     Train net output #1: loss = 0.731384 (* 1 = 0.731384 loss)
I1211 08:23:32.866761 22260 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1211 08:23:39.205843 22260 solver.cpp:218] Iteration 81300 (15.7748 iter/s, 6.33922s/100 iters), loss = 0.805939
I1211 08:23:39.205843 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:23:39.205843 22260 solver.cpp:237]     Train net output #1: loss = 0.805939 (* 1 = 0.805939 loss)
I1211 08:23:39.205843 22260 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1211 08:23:45.551074 22260 solver.cpp:218] Iteration 81400 (15.7628 iter/s, 6.34405s/100 iters), loss = 0.778077
I1211 08:23:45.551074 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:23:45.551074 22260 solver.cpp:237]     Train net output #1: loss = 0.778077 (* 1 = 0.778077 loss)
I1211 08:23:45.551074 22260 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1211 08:23:51.566473 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:23:51.815490 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81500.caffemodel
I1211 08:23:51.829491 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_81500.solverstate
I1211 08:23:51.834491 22260 solver.cpp:330] Iteration 81500, Testing net (#0)
I1211 08:23:51.834491 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:23:53.345613 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:23:53.406116 22260 solver.cpp:397]     Test net output #0: accuracy = 0.596
I1211 08:23:53.406116 22260 solver.cpp:397]     Test net output #1: loss = 1.55272 (* 1 = 1.55272 loss)
I1211 08:23:53.466619 22260 solver.cpp:218] Iteration 81500 (12.6333 iter/s, 7.91561s/100 iters), loss = 0.625318
I1211 08:23:53.466619 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:23:53.466619 22260 solver.cpp:237]     Train net output #1: loss = 0.625318 (* 1 = 0.625318 loss)
I1211 08:23:53.466619 22260 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1211 08:23:59.802099 22260 solver.cpp:218] Iteration 81600 (15.7856 iter/s, 6.33487s/100 iters), loss = 0.627859
I1211 08:23:59.802099 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:23:59.802099 22260 solver.cpp:237]     Train net output #1: loss = 0.627859 (* 1 = 0.627859 loss)
I1211 08:23:59.802099 22260 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1211 08:24:06.134582 22260 solver.cpp:218] Iteration 81700 (15.7928 iter/s, 6.33201s/100 iters), loss = 0.695507
I1211 08:24:06.134582 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:24:06.134582 22260 solver.cpp:237]     Train net output #1: loss = 0.695507 (* 1 = 0.695507 loss)
I1211 08:24:06.134582 22260 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1211 08:24:12.461058 22260 solver.cpp:218] Iteration 81800 (15.8059 iter/s, 6.32677s/100 iters), loss = 0.707096
I1211 08:24:12.462059 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:24:12.462059 22260 solver.cpp:237]     Train net output #1: loss = 0.707096 (* 1 = 0.707096 loss)
I1211 08:24:12.462059 22260 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1211 08:24:18.797988 22260 solver.cpp:218] Iteration 81900 (15.7828 iter/s, 6.33601s/100 iters), loss = 0.711596
I1211 08:24:18.798488 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:24:18.798488 22260 solver.cpp:237]     Train net output #1: loss = 0.711596 (* 1 = 0.711596 loss)
I1211 08:24:18.798488 22260 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1211 08:24:24.816949 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:24:25.065960 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82000.caffemodel
I1211 08:24:25.080960 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82000.solverstate
I1211 08:24:25.084960 22260 solver.cpp:330] Iteration 82000, Testing net (#0)
I1211 08:24:25.084960 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:24:26.598070 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:24:26.658076 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5805
I1211 08:24:26.658076 22260 solver.cpp:397]     Test net output #1: loss = 1.63818 (* 1 = 1.63818 loss)
I1211 08:24:26.718080 22260 solver.cpp:218] Iteration 82000 (12.6268 iter/s, 7.91964s/100 iters), loss = 0.789812
I1211 08:24:26.718080 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:24:26.718080 22260 solver.cpp:237]     Train net output #1: loss = 0.789812 (* 1 = 0.789812 loss)
I1211 08:24:26.718080 22260 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1211 08:24:33.051548 22260 solver.cpp:218] Iteration 82100 (15.7916 iter/s, 6.33246s/100 iters), loss = 0.721187
I1211 08:24:33.051548 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:24:33.051548 22260 solver.cpp:237]     Train net output #1: loss = 0.721187 (* 1 = 0.721187 loss)
I1211 08:24:33.051548 22260 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1211 08:24:39.381997 22260 solver.cpp:218] Iteration 82200 (15.7973 iter/s, 6.33021s/100 iters), loss = 0.697204
I1211 08:24:39.381997 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:24:39.381997 22260 solver.cpp:237]     Train net output #1: loss = 0.697204 (* 1 = 0.697204 loss)
I1211 08:24:39.381997 22260 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1211 08:24:45.707986 22260 solver.cpp:218] Iteration 82300 (15.8087 iter/s, 6.32565s/100 iters), loss = 0.732744
I1211 08:24:45.707986 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:24:45.707986 22260 solver.cpp:237]     Train net output #1: loss = 0.732744 (* 1 = 0.732744 loss)
I1211 08:24:45.707986 22260 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1211 08:24:52.029918 22260 solver.cpp:218] Iteration 82400 (15.8185 iter/s, 6.32172s/100 iters), loss = 0.684029
I1211 08:24:52.029918 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:24:52.029918 22260 solver.cpp:237]     Train net output #1: loss = 0.684029 (* 1 = 0.684029 loss)
I1211 08:24:52.029918 22260 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1211 08:24:58.047317 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:24:58.298341 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82500.caffemodel
I1211 08:24:58.314347 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_82500.solverstate
I1211 08:24:58.318351 22260 solver.cpp:330] Iteration 82500, Testing net (#0)
I1211 08:24:58.318351 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:24:59.829468 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:24:59.889467 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5453
I1211 08:24:59.889467 22260 solver.cpp:397]     Test net output #1: loss = 1.83689 (* 1 = 1.83689 loss)
I1211 08:24:59.949471 22260 solver.cpp:218] Iteration 82500 (12.6281 iter/s, 7.91886s/100 iters), loss = 0.746731
I1211 08:24:59.949471 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:24:59.949471 22260 solver.cpp:237]     Train net output #1: loss = 0.746731 (* 1 = 0.746731 loss)
I1211 08:24:59.949471 22260 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1211 08:25:06.265806 22260 solver.cpp:218] Iteration 82600 (15.833 iter/s, 6.31592s/100 iters), loss = 0.611314
I1211 08:25:06.265806 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:25:06.265806 22260 solver.cpp:237]     Train net output #1: loss = 0.611314 (* 1 = 0.611314 loss)
I1211 08:25:06.265806 22260 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1211 08:25:12.584013 22260 solver.cpp:218] Iteration 82700 (15.8277 iter/s, 6.31804s/100 iters), loss = 0.699322
I1211 08:25:12.584013 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:25:12.584013 22260 solver.cpp:237]     Train net output #1: loss = 0.699322 (* 1 = 0.699322 loss)
I1211 08:25:12.584013 22260 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1211 08:25:18.906507 22260 solver.cpp:218] Iteration 82800 (15.8184 iter/s, 6.32174s/100 iters), loss = 0.724712
I1211 08:25:18.906507 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:25:18.906507 22260 solver.cpp:237]     Train net output #1: loss = 0.724712 (* 1 = 0.724712 loss)
I1211 08:25:18.906507 22260 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1211 08:25:25.225937 22260 solver.cpp:218] Iteration 82900 (15.8248 iter/s, 6.31921s/100 iters), loss = 0.807503
I1211 08:25:25.225937 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:25:25.225937 22260 solver.cpp:237]     Train net output #1: loss = 0.807503 (* 1 = 0.807503 loss)
I1211 08:25:25.225937 22260 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1211 08:25:31.244391 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:25:31.493402 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83000.caffemodel
I1211 08:25:31.509405 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83000.solverstate
I1211 08:25:31.513906 22260 solver.cpp:330] Iteration 83000, Testing net (#0)
I1211 08:25:31.513906 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:25:33.027544 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:25:33.087543 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5874
I1211 08:25:33.087543 22260 solver.cpp:397]     Test net output #1: loss = 1.60416 (* 1 = 1.60416 loss)
I1211 08:25:33.147548 22260 solver.cpp:218] Iteration 83000 (12.6238 iter/s, 7.92155s/100 iters), loss = 0.617013
I1211 08:25:33.147548 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:25:33.147548 22260 solver.cpp:237]     Train net output #1: loss = 0.617013 (* 1 = 0.617013 loss)
I1211 08:25:33.147548 22260 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1211 08:25:39.472954 22260 solver.cpp:218] Iteration 83100 (15.8113 iter/s, 6.32461s/100 iters), loss = 0.647233
I1211 08:25:39.472954 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:25:39.472954 22260 solver.cpp:237]     Train net output #1: loss = 0.647233 (* 1 = 0.647233 loss)
I1211 08:25:39.472954 22260 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1211 08:25:45.807420 22260 solver.cpp:218] Iteration 83200 (15.789 iter/s, 6.33351s/100 iters), loss = 0.581123
I1211 08:25:45.807420 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:25:45.807420 22260 solver.cpp:237]     Train net output #1: loss = 0.581123 (* 1 = 0.581123 loss)
I1211 08:25:45.807420 22260 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1211 08:25:52.143900 22260 solver.cpp:218] Iteration 83300 (15.7825 iter/s, 6.33615s/100 iters), loss = 0.682667
I1211 08:25:52.143900 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:25:52.143900 22260 solver.cpp:237]     Train net output #1: loss = 0.682667 (* 1 = 0.682667 loss)
I1211 08:25:52.143900 22260 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1211 08:25:58.479348 22260 solver.cpp:218] Iteration 83400 (15.7847 iter/s, 6.33525s/100 iters), loss = 0.856942
I1211 08:25:58.479348 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:25:58.479348 22260 solver.cpp:237]     Train net output #1: loss = 0.856942 (* 1 = 0.856942 loss)
I1211 08:25:58.479348 22260 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1211 08:26:04.494773 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:26:04.744812 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83500.caffemodel
I1211 08:26:04.760813 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_83500.solverstate
I1211 08:26:04.764813 22260 solver.cpp:330] Iteration 83500, Testing net (#0)
I1211 08:26:04.765815 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:26:06.277910 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:26:06.336913 22260 solver.cpp:397]     Test net output #0: accuracy = 0.606
I1211 08:26:06.336913 22260 solver.cpp:397]     Test net output #1: loss = 1.52166 (* 1 = 1.52166 loss)
I1211 08:26:06.396914 22260 solver.cpp:218] Iteration 83500 (12.6304 iter/s, 7.9174s/100 iters), loss = 0.680626
I1211 08:26:06.396914 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:26:06.396914 22260 solver.cpp:237]     Train net output #1: loss = 0.680626 (* 1 = 0.680626 loss)
I1211 08:26:06.396914 22260 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1211 08:26:12.721395 22260 solver.cpp:218] Iteration 83600 (15.814 iter/s, 6.32349s/100 iters), loss = 0.692717
I1211 08:26:12.721395 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:26:12.721395 22260 solver.cpp:237]     Train net output #1: loss = 0.692717 (* 1 = 0.692717 loss)
I1211 08:26:12.721395 22260 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1211 08:26:19.048876 22260 solver.cpp:218] Iteration 83700 (15.804 iter/s, 6.32752s/100 iters), loss = 0.585592
I1211 08:26:19.048876 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:26:19.048876 22260 solver.cpp:237]     Train net output #1: loss = 0.585592 (* 1 = 0.585592 loss)
I1211 08:26:19.048876 22260 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1211 08:26:25.370321 22260 solver.cpp:218] Iteration 83800 (15.8211 iter/s, 6.32068s/100 iters), loss = 0.919649
I1211 08:26:25.370321 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:26:25.370321 22260 solver.cpp:237]     Train net output #1: loss = 0.919649 (* 1 = 0.919649 loss)
I1211 08:26:25.370321 22260 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1211 08:26:31.694825 22260 solver.cpp:218] Iteration 83900 (15.8131 iter/s, 6.32387s/100 iters), loss = 0.846987
I1211 08:26:31.694825 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:26:31.694825 22260 solver.cpp:237]     Train net output #1: loss = 0.846987 (* 1 = 0.846987 loss)
I1211 08:26:31.694825 22260 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1211 08:26:37.698222 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:26:37.947235 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84000.caffemodel
I1211 08:26:37.963235 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84000.solverstate
I1211 08:26:37.968235 22260 solver.cpp:330] Iteration 84000, Testing net (#0)
I1211 08:26:37.968235 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:26:39.479331 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:26:39.539335 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5787
I1211 08:26:39.539335 22260 solver.cpp:397]     Test net output #1: loss = 1.63492 (* 1 = 1.63492 loss)
I1211 08:26:39.600334 22260 solver.cpp:218] Iteration 84000 (12.6489 iter/s, 7.90585s/100 iters), loss = 0.6638
I1211 08:26:39.600334 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:26:39.600334 22260 solver.cpp:237]     Train net output #1: loss = 0.6638 (* 1 = 0.6638 loss)
I1211 08:26:39.600334 22260 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1211 08:26:45.931833 22260 solver.cpp:218] Iteration 84100 (15.7962 iter/s, 6.33065s/100 iters), loss = 0.655094
I1211 08:26:45.931833 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:26:45.931833 22260 solver.cpp:237]     Train net output #1: loss = 0.655094 (* 1 = 0.655094 loss)
I1211 08:26:45.931833 22260 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1211 08:26:52.252333 22260 solver.cpp:218] Iteration 84200 (15.8233 iter/s, 6.31979s/100 iters), loss = 0.539254
I1211 08:26:52.252333 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:26:52.252333 22260 solver.cpp:237]     Train net output #1: loss = 0.539254 (* 1 = 0.539254 loss)
I1211 08:26:52.252333 22260 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1211 08:26:58.576830 22260 solver.cpp:218] Iteration 84300 (15.8112 iter/s, 6.32464s/100 iters), loss = 0.870069
I1211 08:26:58.576830 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:26:58.576830 22260 solver.cpp:237]     Train net output #1: loss = 0.870069 (* 1 = 0.870069 loss)
I1211 08:26:58.576830 22260 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1211 08:27:04.899806 22260 solver.cpp:218] Iteration 84400 (15.8176 iter/s, 6.32209s/100 iters), loss = 0.756163
I1211 08:27:04.899806 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:27:04.899806 22260 solver.cpp:237]     Train net output #1: loss = 0.756163 (* 1 = 0.756163 loss)
I1211 08:27:04.899806 22260 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1211 08:27:10.921778 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:27:11.170790 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84500.caffemodel
I1211 08:27:11.185791 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_84500.solverstate
I1211 08:27:11.189795 22260 solver.cpp:330] Iteration 84500, Testing net (#0)
I1211 08:27:11.190295 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:27:12.701406 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:27:12.760907 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5791
I1211 08:27:12.760907 22260 solver.cpp:397]     Test net output #1: loss = 1.63463 (* 1 = 1.63463 loss)
I1211 08:27:12.820914 22260 solver.cpp:218] Iteration 84500 (12.6248 iter/s, 7.92093s/100 iters), loss = 0.723452
I1211 08:27:12.820914 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:27:12.820914 22260 solver.cpp:237]     Train net output #1: loss = 0.723452 (* 1 = 0.723452 loss)
I1211 08:27:12.820914 22260 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1211 08:27:19.160351 22260 solver.cpp:218] Iteration 84600 (15.7763 iter/s, 6.33863s/100 iters), loss = 0.69221
I1211 08:27:19.160351 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:27:19.160351 22260 solver.cpp:237]     Train net output #1: loss = 0.69221 (* 1 = 0.69221 loss)
I1211 08:27:19.160351 22260 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1211 08:27:25.495774 22260 solver.cpp:218] Iteration 84700 (15.7849 iter/s, 6.33515s/100 iters), loss = 0.575955
I1211 08:27:25.495774 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:27:25.495774 22260 solver.cpp:237]     Train net output #1: loss = 0.575955 (* 1 = 0.575955 loss)
I1211 08:27:25.495774 22260 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1211 08:27:31.829217 22260 solver.cpp:218] Iteration 84800 (15.7895 iter/s, 6.33332s/100 iters), loss = 0.729868
I1211 08:27:31.829217 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:27:31.829217 22260 solver.cpp:237]     Train net output #1: loss = 0.729868 (* 1 = 0.729868 loss)
I1211 08:27:31.829217 22260 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1211 08:27:38.156682 22260 solver.cpp:218] Iteration 84900 (15.8058 iter/s, 6.32679s/100 iters), loss = 0.861716
I1211 08:27:38.156682 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:27:38.156682 22260 solver.cpp:237]     Train net output #1: loss = 0.861716 (* 1 = 0.861716 loss)
I1211 08:27:38.156682 22260 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1211 08:27:44.189641 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:27:44.440167 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85000.caffemodel
I1211 08:27:44.455168 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85000.solverstate
I1211 08:27:44.459168 22260 solver.cpp:330] Iteration 85000, Testing net (#0)
I1211 08:27:44.459168 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:27:45.971261 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:27:46.031266 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5817
I1211 08:27:46.031266 22260 solver.cpp:397]     Test net output #1: loss = 1.63105 (* 1 = 1.63105 loss)
I1211 08:27:46.091766 22260 solver.cpp:218] Iteration 85000 (12.6029 iter/s, 7.93466s/100 iters), loss = 0.660801
I1211 08:27:46.091766 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:27:46.091766 22260 solver.cpp:237]     Train net output #1: loss = 0.660801 (* 1 = 0.660801 loss)
I1211 08:27:46.091766 22260 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1211 08:27:52.422757 22260 solver.cpp:218] Iteration 85100 (15.7952 iter/s, 6.33103s/100 iters), loss = 0.793389
I1211 08:27:52.422757 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:27:52.422757 22260 solver.cpp:237]     Train net output #1: loss = 0.793389 (* 1 = 0.793389 loss)
I1211 08:27:52.422757 22260 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1211 08:27:58.747150 22260 solver.cpp:218] Iteration 85200 (15.8128 iter/s, 6.324s/100 iters), loss = 0.478181
I1211 08:27:58.747150 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:27:58.747150 22260 solver.cpp:237]     Train net output #1: loss = 0.478181 (* 1 = 0.478181 loss)
I1211 08:27:58.747150 22260 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1211 08:28:05.062615 22260 solver.cpp:218] Iteration 85300 (15.8358 iter/s, 6.31481s/100 iters), loss = 0.694411
I1211 08:28:05.062615 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:28:05.062615 22260 solver.cpp:237]     Train net output #1: loss = 0.694411 (* 1 = 0.694411 loss)
I1211 08:28:05.062615 22260 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1211 08:28:11.381054 22260 solver.cpp:218] Iteration 85400 (15.8273 iter/s, 6.31818s/100 iters), loss = 0.780668
I1211 08:28:11.381054 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:28:11.381054 22260 solver.cpp:237]     Train net output #1: loss = 0.780668 (* 1 = 0.780668 loss)
I1211 08:28:11.381054 22260 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1211 08:28:17.388504 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:28:17.636529 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85500.caffemodel
I1211 08:28:17.652529 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_85500.solverstate
I1211 08:28:17.656530 22260 solver.cpp:330] Iteration 85500, Testing net (#0)
I1211 08:28:17.656530 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:28:19.169622 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:28:19.229626 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5824
I1211 08:28:19.229626 22260 solver.cpp:397]     Test net output #1: loss = 1.66044 (* 1 = 1.66044 loss)
I1211 08:28:19.289625 22260 solver.cpp:218] Iteration 85500 (12.6457 iter/s, 7.90784s/100 iters), loss = 0.661149
I1211 08:28:19.289625 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:28:19.289625 22260 solver.cpp:237]     Train net output #1: loss = 0.661149 (* 1 = 0.661149 loss)
I1211 08:28:19.289625 22260 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1211 08:28:25.609115 22260 solver.cpp:218] Iteration 85600 (15.8254 iter/s, 6.31897s/100 iters), loss = 0.665228
I1211 08:28:25.609115 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:28:25.609115 22260 solver.cpp:237]     Train net output #1: loss = 0.665228 (* 1 = 0.665228 loss)
I1211 08:28:25.609115 22260 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1211 08:28:31.927551 22260 solver.cpp:218] Iteration 85700 (15.8276 iter/s, 6.31808s/100 iters), loss = 0.675637
I1211 08:28:31.927551 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:28:31.927551 22260 solver.cpp:237]     Train net output #1: loss = 0.675637 (* 1 = 0.675637 loss)
I1211 08:28:31.927551 22260 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1211 08:28:38.253943 22260 solver.cpp:218] Iteration 85800 (15.8068 iter/s, 6.32638s/100 iters), loss = 0.806767
I1211 08:28:38.253943 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:28:38.253943 22260 solver.cpp:237]     Train net output #1: loss = 0.806767 (* 1 = 0.806767 loss)
I1211 08:28:38.253943 22260 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1211 08:28:44.581413 22260 solver.cpp:218] Iteration 85900 (15.8056 iter/s, 6.32689s/100 iters), loss = 0.733098
I1211 08:28:44.581413 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:28:44.581413 22260 solver.cpp:237]     Train net output #1: loss = 0.733098 (* 1 = 0.733098 loss)
I1211 08:28:44.581413 22260 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1211 08:28:50.595857 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:28:50.845871 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86000.caffemodel
I1211 08:28:50.860873 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86000.solverstate
I1211 08:28:50.865872 22260 solver.cpp:330] Iteration 86000, Testing net (#0)
I1211 08:28:50.865872 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:28:52.377975 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:28:52.437984 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6012
I1211 08:28:52.437984 22260 solver.cpp:397]     Test net output #1: loss = 1.56107 (* 1 = 1.56107 loss)
I1211 08:28:52.498986 22260 solver.cpp:218] Iteration 86000 (12.6315 iter/s, 7.91672s/100 iters), loss = 0.611492
I1211 08:28:52.498986 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:28:52.498986 22260 solver.cpp:237]     Train net output #1: loss = 0.611492 (* 1 = 0.611492 loss)
I1211 08:28:52.498986 22260 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1211 08:28:58.831429 22260 solver.cpp:218] Iteration 86100 (15.793 iter/s, 6.33191s/100 iters), loss = 0.611567
I1211 08:28:58.831429 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:28:58.831429 22260 solver.cpp:237]     Train net output #1: loss = 0.611567 (* 1 = 0.611567 loss)
I1211 08:28:58.831429 22260 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1211 08:29:05.149854 22260 solver.cpp:218] Iteration 86200 (15.8275 iter/s, 6.31811s/100 iters), loss = 0.578186
I1211 08:29:05.149854 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:29:05.149854 22260 solver.cpp:237]     Train net output #1: loss = 0.578186 (* 1 = 0.578186 loss)
I1211 08:29:05.149854 22260 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1211 08:29:11.471323 22260 solver.cpp:218] Iteration 86300 (15.8197 iter/s, 6.32124s/100 iters), loss = 0.627775
I1211 08:29:11.471323 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:29:11.471323 22260 solver.cpp:237]     Train net output #1: loss = 0.627775 (* 1 = 0.627775 loss)
I1211 08:29:11.471323 22260 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1211 08:29:17.794724 22260 solver.cpp:218] Iteration 86400 (15.8161 iter/s, 6.32268s/100 iters), loss = 0.811013
I1211 08:29:17.794724 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 08:29:17.794724 22260 solver.cpp:237]     Train net output #1: loss = 0.811013 (* 1 = 0.811013 loss)
I1211 08:29:17.794724 22260 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1211 08:29:23.811154 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:29:24.060174 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86500.caffemodel
I1211 08:29:24.075176 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_86500.solverstate
I1211 08:29:24.079174 22260 solver.cpp:330] Iteration 86500, Testing net (#0)
I1211 08:29:24.079174 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:29:25.591272 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:29:25.651294 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5635
I1211 08:29:25.651294 22260 solver.cpp:397]     Test net output #1: loss = 1.71291 (* 1 = 1.71291 loss)
I1211 08:29:25.712291 22260 solver.cpp:218] Iteration 86500 (12.6311 iter/s, 7.91695s/100 iters), loss = 0.536991
I1211 08:29:25.712291 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:29:25.712291 22260 solver.cpp:237]     Train net output #1: loss = 0.536991 (* 1 = 0.536991 loss)
I1211 08:29:25.712291 22260 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1211 08:29:32.042739 22260 solver.cpp:218] Iteration 86600 (15.7956 iter/s, 6.33088s/100 iters), loss = 0.681216
I1211 08:29:32.043740 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:29:32.043740 22260 solver.cpp:237]     Train net output #1: loss = 0.681216 (* 1 = 0.681216 loss)
I1211 08:29:32.043740 22260 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1211 08:29:38.380183 22260 solver.cpp:218] Iteration 86700 (15.7823 iter/s, 6.33622s/100 iters), loss = 0.624772
I1211 08:29:38.380183 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:29:38.380183 22260 solver.cpp:237]     Train net output #1: loss = 0.624772 (* 1 = 0.624772 loss)
I1211 08:29:38.380183 22260 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1211 08:29:44.713582 22260 solver.cpp:218] Iteration 86800 (15.7905 iter/s, 6.33291s/100 iters), loss = 0.722873
I1211 08:29:44.713582 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:29:44.713582 22260 solver.cpp:237]     Train net output #1: loss = 0.722873 (* 1 = 0.722873 loss)
I1211 08:29:44.713582 22260 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1211 08:29:51.036061 22260 solver.cpp:218] Iteration 86900 (15.8174 iter/s, 6.32215s/100 iters), loss = 0.76115
I1211 08:29:51.036061 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 08:29:51.036061 22260 solver.cpp:237]     Train net output #1: loss = 0.76115 (* 1 = 0.76115 loss)
I1211 08:29:51.036061 22260 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1211 08:29:57.046514 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:29:57.295532 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87000.caffemodel
I1211 08:29:57.311540 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87000.solverstate
I1211 08:29:57.315543 22260 solver.cpp:330] Iteration 87000, Testing net (#0)
I1211 08:29:57.315543 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:29:58.827641 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:29:58.887641 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6008
I1211 08:29:58.887641 22260 solver.cpp:397]     Test net output #1: loss = 1.53334 (* 1 = 1.53334 loss)
I1211 08:29:58.947644 22260 solver.cpp:218] Iteration 87000 (12.6395 iter/s, 7.91173s/100 iters), loss = 0.763135
I1211 08:29:58.947644 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:29:58.947644 22260 solver.cpp:237]     Train net output #1: loss = 0.763135 (* 1 = 0.763135 loss)
I1211 08:29:58.947644 22260 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1211 08:30:05.276163 22260 solver.cpp:218] Iteration 87100 (15.8036 iter/s, 6.32768s/100 iters), loss = 0.719285
I1211 08:30:05.276163 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:30:05.276163 22260 solver.cpp:237]     Train net output #1: loss = 0.719285 (* 1 = 0.719285 loss)
I1211 08:30:05.276163 22260 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1211 08:30:11.604692 22260 solver.cpp:218] Iteration 87200 (15.8038 iter/s, 6.32758s/100 iters), loss = 0.605467
I1211 08:30:11.604692 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:30:11.604692 22260 solver.cpp:237]     Train net output #1: loss = 0.605467 (* 1 = 0.605467 loss)
I1211 08:30:11.604692 22260 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1211 08:30:17.926100 22260 solver.cpp:218] Iteration 87300 (15.8189 iter/s, 6.32154s/100 iters), loss = 0.776089
I1211 08:30:17.926100 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:30:17.926100 22260 solver.cpp:237]     Train net output #1: loss = 0.776089 (* 1 = 0.776089 loss)
I1211 08:30:17.926100 22260 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1211 08:30:24.254529 22260 solver.cpp:218] Iteration 87400 (15.8034 iter/s, 6.32777s/100 iters), loss = 0.927876
I1211 08:30:24.254529 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 08:30:24.254529 22260 solver.cpp:237]     Train net output #1: loss = 0.927876 (* 1 = 0.927876 loss)
I1211 08:30:24.254529 22260 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1211 08:30:30.265960 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:30:30.515975 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87500.caffemodel
I1211 08:30:30.533975 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_87500.solverstate
I1211 08:30:30.538976 22260 solver.cpp:330] Iteration 87500, Testing net (#0)
I1211 08:30:30.538976 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:30:32.051074 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:30:32.111081 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5704
I1211 08:30:32.111081 22260 solver.cpp:397]     Test net output #1: loss = 1.73545 (* 1 = 1.73545 loss)
I1211 08:30:32.171080 22260 solver.cpp:218] Iteration 87500 (12.6317 iter/s, 7.91658s/100 iters), loss = 0.680504
I1211 08:30:32.171080 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:30:32.171080 22260 solver.cpp:237]     Train net output #1: loss = 0.680504 (* 1 = 0.680504 loss)
I1211 08:30:32.172086 22260 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1211 08:30:38.489025 22260 solver.cpp:218] Iteration 87600 (15.8311 iter/s, 6.3167s/100 iters), loss = 0.603675
I1211 08:30:38.489025 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:30:38.489025 22260 solver.cpp:237]     Train net output #1: loss = 0.603675 (* 1 = 0.603675 loss)
I1211 08:30:38.489025 22260 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1211 08:30:44.803961 22260 solver.cpp:218] Iteration 87700 (15.8348 iter/s, 6.31522s/100 iters), loss = 0.53257
I1211 08:30:44.803961 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:30:44.803961 22260 solver.cpp:237]     Train net output #1: loss = 0.53257 (* 1 = 0.53257 loss)
I1211 08:30:44.803961 22260 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1211 08:30:51.122434 22260 solver.cpp:218] Iteration 87800 (15.8279 iter/s, 6.31794s/100 iters), loss = 0.780663
I1211 08:30:51.122434 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:30:51.122434 22260 solver.cpp:237]     Train net output #1: loss = 0.780663 (* 1 = 0.780663 loss)
I1211 08:30:51.122434 22260 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1211 08:30:57.445895 22260 solver.cpp:218] Iteration 87900 (15.8164 iter/s, 6.32254s/100 iters), loss = 0.721193
I1211 08:30:57.445895 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:30:57.445895 22260 solver.cpp:237]     Train net output #1: loss = 0.721193 (* 1 = 0.721193 loss)
I1211 08:30:57.445895 22260 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1211 08:31:03.461416 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:31:03.711447 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88000.caffemodel
I1211 08:31:03.727447 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88000.solverstate
I1211 08:31:03.732448 22260 solver.cpp:330] Iteration 88000, Testing net (#0)
I1211 08:31:03.732448 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:31:05.245558 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:31:05.305593 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5586
I1211 08:31:05.305593 22260 solver.cpp:397]     Test net output #1: loss = 1.80985 (* 1 = 1.80985 loss)
I1211 08:31:05.366578 22260 solver.cpp:218] Iteration 88000 (12.6252 iter/s, 7.92064s/100 iters), loss = 0.697658
I1211 08:31:05.366578 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:31:05.366578 22260 solver.cpp:237]     Train net output #1: loss = 0.697658 (* 1 = 0.697658 loss)
I1211 08:31:05.366578 22260 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1211 08:31:11.682035 22260 solver.cpp:218] Iteration 88100 (15.8363 iter/s, 6.31459s/100 iters), loss = 0.640171
I1211 08:31:11.682035 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:31:11.682035 22260 solver.cpp:237]     Train net output #1: loss = 0.640171 (* 1 = 0.640171 loss)
I1211 08:31:11.682035 22260 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1211 08:31:18.002552 22260 solver.cpp:218] Iteration 88200 (15.8229 iter/s, 6.31997s/100 iters), loss = 0.641996
I1211 08:31:18.002552 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:31:18.002552 22260 solver.cpp:237]     Train net output #1: loss = 0.641996 (* 1 = 0.641996 loss)
I1211 08:31:18.002552 22260 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1211 08:31:24.316992 22260 solver.cpp:218] Iteration 88300 (15.8358 iter/s, 6.3148s/100 iters), loss = 0.764188
I1211 08:31:24.316992 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:31:24.316992 22260 solver.cpp:237]     Train net output #1: loss = 0.764188 (* 1 = 0.764188 loss)
I1211 08:31:24.316992 22260 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1211 08:31:30.642490 22260 solver.cpp:218] Iteration 88400 (15.8119 iter/s, 6.32436s/100 iters), loss = 0.784893
I1211 08:31:30.642490 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:31:30.642490 22260 solver.cpp:237]     Train net output #1: loss = 0.784893 (* 1 = 0.784893 loss)
I1211 08:31:30.642490 22260 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1211 08:31:36.648977 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:31:36.899996 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88500.caffemodel
I1211 08:31:36.915998 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_88500.solverstate
I1211 08:31:36.919998 22260 solver.cpp:330] Iteration 88500, Testing net (#0)
I1211 08:31:36.919998 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:31:38.434090 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:31:38.494092 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5696
I1211 08:31:38.494092 22260 solver.cpp:397]     Test net output #1: loss = 1.73085 (* 1 = 1.73085 loss)
I1211 08:31:38.555094 22260 solver.cpp:218] Iteration 88500 (12.6387 iter/s, 7.91218s/100 iters), loss = 0.811377
I1211 08:31:38.555094 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:31:38.555094 22260 solver.cpp:237]     Train net output #1: loss = 0.811377 (* 1 = 0.811377 loss)
I1211 08:31:38.555094 22260 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1211 08:31:44.881525 22260 solver.cpp:218] Iteration 88600 (15.8077 iter/s, 6.32605s/100 iters), loss = 0.617366
I1211 08:31:44.881525 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:31:44.881525 22260 solver.cpp:237]     Train net output #1: loss = 0.617366 (* 1 = 0.617366 loss)
I1211 08:31:44.881525 22260 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1211 08:31:51.201966 22260 solver.cpp:218] Iteration 88700 (15.8222 iter/s, 6.32022s/100 iters), loss = 0.591173
I1211 08:31:51.201966 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:31:51.201966 22260 solver.cpp:237]     Train net output #1: loss = 0.591173 (* 1 = 0.591173 loss)
I1211 08:31:51.201966 22260 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1211 08:31:57.524408 22260 solver.cpp:218] Iteration 88800 (15.8173 iter/s, 6.32219s/100 iters), loss = 0.725015
I1211 08:31:57.524408 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:31:57.524408 22260 solver.cpp:237]     Train net output #1: loss = 0.725015 (* 1 = 0.725015 loss)
I1211 08:31:57.524408 22260 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1211 08:32:03.848961 22260 solver.cpp:218] Iteration 88900 (15.8138 iter/s, 6.3236s/100 iters), loss = 0.749992
I1211 08:32:03.848961 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:32:03.848961 22260 solver.cpp:237]     Train net output #1: loss = 0.749992 (* 1 = 0.749992 loss)
I1211 08:32:03.848961 22260 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1211 08:32:09.851418 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:32:10.101444 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89000.caffemodel
I1211 08:32:10.116448 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89000.solverstate
I1211 08:32:10.120448 22260 solver.cpp:330] Iteration 89000, Testing net (#0)
I1211 08:32:10.121449 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:32:11.633539 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:32:11.693552 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5675
I1211 08:32:11.693552 22260 solver.cpp:397]     Test net output #1: loss = 1.81707 (* 1 = 1.81707 loss)
I1211 08:32:11.754545 22260 solver.cpp:218] Iteration 89000 (12.6501 iter/s, 7.90506s/100 iters), loss = 0.70243
I1211 08:32:11.754545 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:32:11.754545 22260 solver.cpp:237]     Train net output #1: loss = 0.70243 (* 1 = 0.70243 loss)
I1211 08:32:11.754545 22260 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1211 08:32:18.082991 22260 solver.cpp:218] Iteration 89100 (15.8013 iter/s, 6.32861s/100 iters), loss = 0.594874
I1211 08:32:18.082991 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:32:18.082991 22260 solver.cpp:237]     Train net output #1: loss = 0.594874 (* 1 = 0.594874 loss)
I1211 08:32:18.082991 22260 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1211 08:32:24.407445 22260 solver.cpp:218] Iteration 89200 (15.8126 iter/s, 6.32408s/100 iters), loss = 0.589626
I1211 08:32:24.407445 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:32:24.407445 22260 solver.cpp:237]     Train net output #1: loss = 0.589626 (* 1 = 0.589626 loss)
I1211 08:32:24.407445 22260 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1211 08:32:30.731868 22260 solver.cpp:218] Iteration 89300 (15.8125 iter/s, 6.3241s/100 iters), loss = 0.710463
I1211 08:32:30.731868 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:32:30.731868 22260 solver.cpp:237]     Train net output #1: loss = 0.710463 (* 1 = 0.710463 loss)
I1211 08:32:30.731868 22260 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1211 08:32:37.054391 22260 solver.cpp:218] Iteration 89400 (15.818 iter/s, 6.32193s/100 iters), loss = 0.746473
I1211 08:32:37.054391 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:32:37.054391 22260 solver.cpp:237]     Train net output #1: loss = 0.746473 (* 1 = 0.746473 loss)
I1211 08:32:37.054391 22260 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1211 08:32:43.071830 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:32:43.319846 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89500.caffemodel
I1211 08:32:43.334846 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_89500.solverstate
I1211 08:32:43.338846 22260 solver.cpp:330] Iteration 89500, Testing net (#0)
I1211 08:32:43.338846 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:32:44.851939 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:32:44.911943 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5729
I1211 08:32:44.911943 22260 solver.cpp:397]     Test net output #1: loss = 1.76327 (* 1 = 1.76327 loss)
I1211 08:32:44.972942 22260 solver.cpp:218] Iteration 89500 (12.629 iter/s, 7.91829s/100 iters), loss = 0.59303
I1211 08:32:44.972942 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:32:44.972942 22260 solver.cpp:237]     Train net output #1: loss = 0.59303 (* 1 = 0.59303 loss)
I1211 08:32:44.972942 22260 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1211 08:32:51.313424 22260 solver.cpp:218] Iteration 89600 (15.7741 iter/s, 6.33952s/100 iters), loss = 0.635904
I1211 08:32:51.313424 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:32:51.313424 22260 solver.cpp:237]     Train net output #1: loss = 0.635904 (* 1 = 0.635904 loss)
I1211 08:32:51.313424 22260 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1211 08:32:57.643362 22260 solver.cpp:218] Iteration 89700 (15.7994 iter/s, 6.32935s/100 iters), loss = 0.63759
I1211 08:32:57.643362 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:32:57.643362 22260 solver.cpp:237]     Train net output #1: loss = 0.63759 (* 1 = 0.63759 loss)
I1211 08:32:57.643362 22260 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1211 08:33:03.970456 22260 solver.cpp:218] Iteration 89800 (15.8045 iter/s, 6.32733s/100 iters), loss = 0.751788
I1211 08:33:03.970456 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:33:03.970456 22260 solver.cpp:237]     Train net output #1: loss = 0.751788 (* 1 = 0.751788 loss)
I1211 08:33:03.970456 22260 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1211 08:33:10.301892 22260 solver.cpp:218] Iteration 89900 (15.7957 iter/s, 6.33082s/100 iters), loss = 0.739261
I1211 08:33:10.301892 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:33:10.301892 22260 solver.cpp:237]     Train net output #1: loss = 0.739261 (* 1 = 0.739261 loss)
I1211 08:33:10.301892 22260 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1211 08:33:16.329336 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:33:16.579360 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90000.caffemodel
I1211 08:33:16.594359 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90000.solverstate
I1211 08:33:16.599361 22260 solver.cpp:330] Iteration 90000, Testing net (#0)
I1211 08:33:16.599361 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:33:18.111899 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:33:18.171903 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5908
I1211 08:33:18.171903 22260 solver.cpp:397]     Test net output #1: loss = 1.61171 (* 1 = 1.61171 loss)
I1211 08:33:18.231902 22260 solver.cpp:218] Iteration 90000 (12.6108 iter/s, 7.92971s/100 iters), loss = 0.592057
I1211 08:33:18.231902 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:33:18.231902 22260 solver.cpp:237]     Train net output #1: loss = 0.592057 (* 1 = 0.592057 loss)
I1211 08:33:18.231902 22260 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1211 08:33:24.552363 22260 solver.cpp:218] Iteration 90100 (15.8224 iter/s, 6.32015s/100 iters), loss = 0.68888
I1211 08:33:24.552363 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:33:24.552363 22260 solver.cpp:237]     Train net output #1: loss = 0.68888 (* 1 = 0.68888 loss)
I1211 08:33:24.552363 22260 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1211 08:33:30.870867 22260 solver.cpp:218] Iteration 90200 (15.8284 iter/s, 6.31777s/100 iters), loss = 0.591208
I1211 08:33:30.870867 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:33:30.870867 22260 solver.cpp:237]     Train net output #1: loss = 0.591208 (* 1 = 0.591208 loss)
I1211 08:33:30.870867 22260 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1211 08:33:37.192356 22260 solver.cpp:218] Iteration 90300 (15.8209 iter/s, 6.32077s/100 iters), loss = 0.721552
I1211 08:33:37.192356 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:33:37.192356 22260 solver.cpp:237]     Train net output #1: loss = 0.721552 (* 1 = 0.721552 loss)
I1211 08:33:37.192356 22260 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1211 08:33:43.512814 22260 solver.cpp:218] Iteration 90400 (15.8223 iter/s, 6.32019s/100 iters), loss = 0.72385
I1211 08:33:43.512814 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:33:43.512814 22260 solver.cpp:237]     Train net output #1: loss = 0.72385 (* 1 = 0.72385 loss)
I1211 08:33:43.512814 22260 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1211 08:33:49.520313 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:33:49.770330 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90500.caffemodel
I1211 08:33:49.785331 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_90500.solverstate
I1211 08:33:49.789330 22260 solver.cpp:330] Iteration 90500, Testing net (#0)
I1211 08:33:49.790333 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:33:51.302443 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:33:51.362448 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5894
I1211 08:33:51.362448 22260 solver.cpp:397]     Test net output #1: loss = 1.6017 (* 1 = 1.6017 loss)
I1211 08:33:51.422447 22260 solver.cpp:218] Iteration 90500 (12.6434 iter/s, 7.90926s/100 iters), loss = 0.598981
I1211 08:33:51.422447 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:33:51.422447 22260 solver.cpp:237]     Train net output #1: loss = 0.598981 (* 1 = 0.598981 loss)
I1211 08:33:51.422447 22260 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1211 08:33:57.741924 22260 solver.cpp:218] Iteration 90600 (15.8264 iter/s, 6.31857s/100 iters), loss = 0.60096
I1211 08:33:57.741924 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:33:57.741924 22260 solver.cpp:237]     Train net output #1: loss = 0.60096 (* 1 = 0.60096 loss)
I1211 08:33:57.741924 22260 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1211 08:34:04.063402 22260 solver.cpp:218] Iteration 90700 (15.8184 iter/s, 6.32174s/100 iters), loss = 0.660036
I1211 08:34:04.063402 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:34:04.063402 22260 solver.cpp:237]     Train net output #1: loss = 0.660036 (* 1 = 0.660036 loss)
I1211 08:34:04.063402 22260 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1211 08:34:10.383726 22260 solver.cpp:218] Iteration 90800 (15.8224 iter/s, 6.32016s/100 iters), loss = 0.747374
I1211 08:34:10.384727 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:34:10.384727 22260 solver.cpp:237]     Train net output #1: loss = 0.747374 (* 1 = 0.747374 loss)
I1211 08:34:10.384727 22260 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1211 08:34:16.703186 22260 solver.cpp:218] Iteration 90900 (15.8254 iter/s, 6.31895s/100 iters), loss = 0.696431
I1211 08:34:16.703186 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:34:16.703186 22260 solver.cpp:237]     Train net output #1: loss = 0.696431 (* 1 = 0.696431 loss)
I1211 08:34:16.703186 22260 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1211 08:34:22.714660 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:34:22.963678 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91000.caffemodel
I1211 08:34:22.982678 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91000.solverstate
I1211 08:34:22.987679 22260 solver.cpp:330] Iteration 91000, Testing net (#0)
I1211 08:34:22.987679 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:34:24.499773 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:34:24.559778 22260 solver.cpp:397]     Test net output #0: accuracy = 0.583
I1211 08:34:24.559778 22260 solver.cpp:397]     Test net output #1: loss = 1.62962 (* 1 = 1.62962 loss)
I1211 08:34:24.620777 22260 solver.cpp:218] Iteration 91000 (12.6321 iter/s, 7.91633s/100 iters), loss = 0.592967
I1211 08:34:24.620777 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:34:24.620777 22260 solver.cpp:237]     Train net output #1: loss = 0.592967 (* 1 = 0.592967 loss)
I1211 08:34:24.620777 22260 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1211 08:34:30.952191 22260 solver.cpp:218] Iteration 91100 (15.7955 iter/s, 6.33093s/100 iters), loss = 0.681695
I1211 08:34:30.952191 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:34:30.952191 22260 solver.cpp:237]     Train net output #1: loss = 0.681695 (* 1 = 0.681695 loss)
I1211 08:34:30.952191 22260 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1211 08:34:37.274616 22260 solver.cpp:218] Iteration 91200 (15.8174 iter/s, 6.32215s/100 iters), loss = 0.53554
I1211 08:34:37.274616 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:34:37.274616 22260 solver.cpp:237]     Train net output #1: loss = 0.53554 (* 1 = 0.53554 loss)
I1211 08:34:37.274616 22260 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1211 08:34:43.601629 22260 solver.cpp:218] Iteration 91300 (15.8065 iter/s, 6.32651s/100 iters), loss = 0.747732
I1211 08:34:43.601629 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:34:43.601629 22260 solver.cpp:237]     Train net output #1: loss = 0.747732 (* 1 = 0.747732 loss)
I1211 08:34:43.601629 22260 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1211 08:34:49.928140 22260 solver.cpp:218] Iteration 91400 (15.807 iter/s, 6.3263s/100 iters), loss = 0.873154
I1211 08:34:49.928140 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:34:49.928140 22260 solver.cpp:237]     Train net output #1: loss = 0.873154 (* 1 = 0.873154 loss)
I1211 08:34:49.928140 22260 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1211 08:34:55.940382 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:34:56.190420 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91500.caffemodel
I1211 08:34:56.205425 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_91500.solverstate
I1211 08:34:56.209924 22260 solver.cpp:330] Iteration 91500, Testing net (#0)
I1211 08:34:56.209924 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:34:57.720150 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:34:57.780135 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5731
I1211 08:34:57.780135 22260 solver.cpp:397]     Test net output #1: loss = 1.66941 (* 1 = 1.66941 loss)
I1211 08:34:57.840171 22260 solver.cpp:218] Iteration 91500 (12.6393 iter/s, 7.91185s/100 iters), loss = 0.563483
I1211 08:34:57.840171 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:34:57.840171 22260 solver.cpp:237]     Train net output #1: loss = 0.563483 (* 1 = 0.563483 loss)
I1211 08:34:57.840171 22260 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1211 08:35:04.174120 22260 solver.cpp:218] Iteration 91600 (15.7883 iter/s, 6.33379s/100 iters), loss = 0.600241
I1211 08:35:04.175122 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:35:04.175122 22260 solver.cpp:237]     Train net output #1: loss = 0.600241 (* 1 = 0.600241 loss)
I1211 08:35:04.175122 22260 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1211 08:35:10.510567 22260 solver.cpp:218] Iteration 91700 (15.7842 iter/s, 6.33546s/100 iters), loss = 0.63001
I1211 08:35:10.510567 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:35:10.510567 22260 solver.cpp:237]     Train net output #1: loss = 0.63001 (* 1 = 0.63001 loss)
I1211 08:35:10.510567 22260 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1211 08:35:16.843037 22260 solver.cpp:218] Iteration 91800 (15.794 iter/s, 6.33154s/100 iters), loss = 0.658073
I1211 08:35:16.843037 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:35:16.843037 22260 solver.cpp:237]     Train net output #1: loss = 0.658073 (* 1 = 0.658073 loss)
I1211 08:35:16.843037 22260 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1211 08:35:23.173518 22260 solver.cpp:218] Iteration 91900 (15.7967 iter/s, 6.33043s/100 iters), loss = 0.652598
I1211 08:35:23.173518 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:35:23.174019 22260 solver.cpp:237]     Train net output #1: loss = 0.652598 (* 1 = 0.652598 loss)
I1211 08:35:23.174019 22260 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1211 08:35:29.189023 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:35:29.438038 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92000.caffemodel
I1211 08:35:29.453038 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92000.solverstate
I1211 08:35:29.457038 22260 solver.cpp:330] Iteration 92000, Testing net (#0)
I1211 08:35:29.458039 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:35:30.968637 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:35:31.028138 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6009
I1211 08:35:31.028138 22260 solver.cpp:397]     Test net output #1: loss = 1.54187 (* 1 = 1.54187 loss)
I1211 08:35:31.088142 22260 solver.cpp:218] Iteration 92000 (12.6351 iter/s, 7.91447s/100 iters), loss = 0.808587
I1211 08:35:31.088142 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:35:31.088142 22260 solver.cpp:237]     Train net output #1: loss = 0.808587 (* 1 = 0.808587 loss)
I1211 08:35:31.088142 22260 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1211 08:35:37.422693 22260 solver.cpp:218] Iteration 92100 (15.7892 iter/s, 6.33345s/100 iters), loss = 0.593525
I1211 08:35:37.422693 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:35:37.422693 22260 solver.cpp:237]     Train net output #1: loss = 0.593525 (* 1 = 0.593525 loss)
I1211 08:35:37.422693 22260 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1211 08:35:43.755141 22260 solver.cpp:218] Iteration 92200 (15.7916 iter/s, 6.33249s/100 iters), loss = 0.592289
I1211 08:35:43.755141 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:35:43.755141 22260 solver.cpp:237]     Train net output #1: loss = 0.592289 (* 1 = 0.592289 loss)
I1211 08:35:43.755141 22260 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1211 08:35:50.083569 22260 solver.cpp:218] Iteration 92300 (15.8037 iter/s, 6.32763s/100 iters), loss = 0.786439
I1211 08:35:50.083569 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:35:50.083569 22260 solver.cpp:237]     Train net output #1: loss = 0.786439 (* 1 = 0.786439 loss)
I1211 08:35:50.083569 22260 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1211 08:35:56.413231 22260 solver.cpp:218] Iteration 92400 (15.7988 iter/s, 6.32959s/100 iters), loss = 0.78242
I1211 08:35:56.413231 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:35:56.413231 22260 solver.cpp:237]     Train net output #1: loss = 0.78242 (* 1 = 0.78242 loss)
I1211 08:35:56.413231 22260 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1211 08:36:02.437638 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:36:02.687657 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92500.caffemodel
I1211 08:36:02.701658 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_92500.solverstate
I1211 08:36:02.706658 22260 solver.cpp:330] Iteration 92500, Testing net (#0)
I1211 08:36:02.706658 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:36:04.218757 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:36:04.278770 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5804
I1211 08:36:04.278770 22260 solver.cpp:397]     Test net output #1: loss = 1.68261 (* 1 = 1.68261 loss)
I1211 08:36:04.338769 22260 solver.cpp:218] Iteration 92500 (12.6185 iter/s, 7.92489s/100 iters), loss = 0.749475
I1211 08:36:04.338769 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:36:04.338769 22260 solver.cpp:237]     Train net output #1: loss = 0.749475 (* 1 = 0.749475 loss)
I1211 08:36:04.338769 22260 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1211 08:36:10.663264 22260 solver.cpp:218] Iteration 92600 (15.8132 iter/s, 6.32384s/100 iters), loss = 0.658573
I1211 08:36:10.663264 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:36:10.663264 22260 solver.cpp:237]     Train net output #1: loss = 0.658573 (* 1 = 0.658573 loss)
I1211 08:36:10.663264 22260 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1211 08:36:16.986760 22260 solver.cpp:218] Iteration 92700 (15.8151 iter/s, 6.32308s/100 iters), loss = 0.539315
I1211 08:36:16.986760 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:36:16.986760 22260 solver.cpp:237]     Train net output #1: loss = 0.539315 (* 1 = 0.539315 loss)
I1211 08:36:16.986760 22260 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1211 08:36:23.306233 22260 solver.cpp:218] Iteration 92800 (15.8233 iter/s, 6.31978s/100 iters), loss = 0.670732
I1211 08:36:23.306233 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:36:23.306233 22260 solver.cpp:237]     Train net output #1: loss = 0.670732 (* 1 = 0.670732 loss)
I1211 08:36:23.306233 22260 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1211 08:36:29.627732 22260 solver.cpp:218] Iteration 92900 (15.8203 iter/s, 6.32097s/100 iters), loss = 0.800912
I1211 08:36:29.627732 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:36:29.627732 22260 solver.cpp:237]     Train net output #1: loss = 0.800912 (* 1 = 0.800912 loss)
I1211 08:36:29.627732 22260 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1211 08:36:35.642212 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:36:35.892247 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93000.caffemodel
I1211 08:36:35.907248 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93000.solverstate
I1211 08:36:35.911248 22260 solver.cpp:330] Iteration 93000, Testing net (#0)
I1211 08:36:35.911248 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:36:37.423382 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:36:37.482388 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5735
I1211 08:36:37.482388 22260 solver.cpp:397]     Test net output #1: loss = 1.74897 (* 1 = 1.74897 loss)
I1211 08:36:37.543388 22260 solver.cpp:218] Iteration 93000 (12.6343 iter/s, 7.91499s/100 iters), loss = 0.598039
I1211 08:36:37.543388 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:36:37.543388 22260 solver.cpp:237]     Train net output #1: loss = 0.598039 (* 1 = 0.598039 loss)
I1211 08:36:37.543388 22260 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1211 08:36:43.874197 22260 solver.cpp:218] Iteration 93100 (15.7969 iter/s, 6.33036s/100 iters), loss = 0.678669
I1211 08:36:43.874197 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:36:43.874197 22260 solver.cpp:237]     Train net output #1: loss = 0.678669 (* 1 = 0.678669 loss)
I1211 08:36:43.874197 22260 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1211 08:36:50.203377 22260 solver.cpp:218] Iteration 93200 (15.8025 iter/s, 6.32813s/100 iters), loss = 0.643146
I1211 08:36:50.203377 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:36:50.203377 22260 solver.cpp:237]     Train net output #1: loss = 0.643146 (* 1 = 0.643146 loss)
I1211 08:36:50.203377 22260 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1211 08:36:56.526867 22260 solver.cpp:218] Iteration 93300 (15.8141 iter/s, 6.32347s/100 iters), loss = 0.738078
I1211 08:36:56.526867 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 08:36:56.526867 22260 solver.cpp:237]     Train net output #1: loss = 0.738078 (* 1 = 0.738078 loss)
I1211 08:36:56.526867 22260 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1211 08:37:02.854372 22260 solver.cpp:218] Iteration 93400 (15.8057 iter/s, 6.32682s/100 iters), loss = 0.64452
I1211 08:37:02.854372 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:37:02.854372 22260 solver.cpp:237]     Train net output #1: loss = 0.64452 (* 1 = 0.64452 loss)
I1211 08:37:02.854372 22260 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1211 08:37:08.875861 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:37:09.126870 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93500.caffemodel
I1211 08:37:09.142377 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_93500.solverstate
I1211 08:37:09.146879 22260 solver.cpp:330] Iteration 93500, Testing net (#0)
I1211 08:37:09.146879 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:37:10.657999 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:37:10.717998 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5473
I1211 08:37:10.717998 22260 solver.cpp:397]     Test net output #1: loss = 1.82539 (* 1 = 1.82539 loss)
I1211 08:37:10.779006 22260 solver.cpp:218] Iteration 93500 (12.6192 iter/s, 7.92444s/100 iters), loss = 0.76257
I1211 08:37:10.779006 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 08:37:10.779006 22260 solver.cpp:237]     Train net output #1: loss = 0.76257 (* 1 = 0.76257 loss)
I1211 08:37:10.779006 22260 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1211 08:37:17.100442 22260 solver.cpp:218] Iteration 93600 (15.8207 iter/s, 6.32082s/100 iters), loss = 0.67202
I1211 08:37:17.100442 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:37:17.100442 22260 solver.cpp:237]     Train net output #1: loss = 0.67202 (* 1 = 0.67202 loss)
I1211 08:37:17.100442 22260 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1211 08:37:23.427903 22260 solver.cpp:218] Iteration 93700 (15.8055 iter/s, 6.32691s/100 iters), loss = 0.563191
I1211 08:37:23.427903 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:37:23.427903 22260 solver.cpp:237]     Train net output #1: loss = 0.563191 (* 1 = 0.563191 loss)
I1211 08:37:23.427903 22260 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1211 08:37:29.746862 22260 solver.cpp:218] Iteration 93800 (15.8266 iter/s, 6.31849s/100 iters), loss = 0.769973
I1211 08:37:29.746862 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 08:37:29.746862 22260 solver.cpp:237]     Train net output #1: loss = 0.769973 (* 1 = 0.769973 loss)
I1211 08:37:29.746862 22260 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1211 08:37:36.072793 22260 solver.cpp:218] Iteration 93900 (15.8074 iter/s, 6.32615s/100 iters), loss = 0.826209
I1211 08:37:36.072793 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 08:37:36.072793 22260 solver.cpp:237]     Train net output #1: loss = 0.826209 (* 1 = 0.826209 loss)
I1211 08:37:36.072793 22260 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1211 08:37:42.075212 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:37:42.324223 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94000.caffemodel
I1211 08:37:42.339222 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94000.solverstate
I1211 08:37:42.343729 22260 solver.cpp:330] Iteration 94000, Testing net (#0)
I1211 08:37:42.343729 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:37:43.855329 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:37:43.915331 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5879
I1211 08:37:43.915331 22260 solver.cpp:397]     Test net output #1: loss = 1.62076 (* 1 = 1.62076 loss)
I1211 08:37:43.975348 22260 solver.cpp:218] Iteration 94000 (12.6546 iter/s, 7.90226s/100 iters), loss = 0.736205
I1211 08:37:43.975348 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:37:43.975348 22260 solver.cpp:237]     Train net output #1: loss = 0.736205 (* 1 = 0.736205 loss)
I1211 08:37:43.975348 22260 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1211 08:37:50.293818 22260 solver.cpp:218] Iteration 94100 (15.8287 iter/s, 6.31765s/100 iters), loss = 0.706132
I1211 08:37:50.293818 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:37:50.293818 22260 solver.cpp:237]     Train net output #1: loss = 0.706132 (* 1 = 0.706132 loss)
I1211 08:37:50.293818 22260 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1211 08:37:56.619252 22260 solver.cpp:218] Iteration 94200 (15.8105 iter/s, 6.32491s/100 iters), loss = 0.510257
I1211 08:37:56.619252 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:37:56.619252 22260 solver.cpp:237]     Train net output #1: loss = 0.510257 (* 1 = 0.510257 loss)
I1211 08:37:56.619252 22260 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1211 08:38:02.946735 22260 solver.cpp:218] Iteration 94300 (15.8057 iter/s, 6.32682s/100 iters), loss = 0.612747
I1211 08:38:02.946735 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:38:02.946735 22260 solver.cpp:237]     Train net output #1: loss = 0.612747 (* 1 = 0.612747 loss)
I1211 08:38:02.946735 22260 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1211 08:38:09.264194 22260 solver.cpp:218] Iteration 94400 (15.8302 iter/s, 6.31703s/100 iters), loss = 0.706932
I1211 08:38:09.264194 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:38:09.264194 22260 solver.cpp:237]     Train net output #1: loss = 0.706932 (* 1 = 0.706932 loss)
I1211 08:38:09.264194 22260 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1211 08:38:15.266569 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:38:15.517237 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94500.caffemodel
I1211 08:38:15.533237 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_94500.solverstate
I1211 08:38:15.537253 22260 solver.cpp:330] Iteration 94500, Testing net (#0)
I1211 08:38:15.537253 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:38:17.047554 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:38:17.107419 22260 solver.cpp:397]     Test net output #0: accuracy = 0.5777
I1211 08:38:17.107419 22260 solver.cpp:397]     Test net output #1: loss = 1.69219 (* 1 = 1.69219 loss)
I1211 08:38:17.168475 22260 solver.cpp:218] Iteration 94500 (12.6524 iter/s, 7.90364s/100 iters), loss = 0.655681
I1211 08:38:17.168475 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:38:17.168475 22260 solver.cpp:237]     Train net output #1: loss = 0.655681 (* 1 = 0.655681 loss)
I1211 08:38:17.168475 22260 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1211 08:38:23.491245 22260 solver.cpp:218] Iteration 94600 (15.816 iter/s, 6.32273s/100 iters), loss = 0.582066
I1211 08:38:23.491245 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:38:23.491245 22260 solver.cpp:237]     Train net output #1: loss = 0.582066 (* 1 = 0.582066 loss)
I1211 08:38:23.491245 22260 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1211 08:38:29.811187 22260 solver.cpp:218] Iteration 94700 (15.8239 iter/s, 6.31957s/100 iters), loss = 0.578412
I1211 08:38:29.811187 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:38:29.811187 22260 solver.cpp:237]     Train net output #1: loss = 0.578412 (* 1 = 0.578412 loss)
I1211 08:38:29.811187 22260 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1211 08:38:36.129694 22260 solver.cpp:218] Iteration 94800 (15.8281 iter/s, 6.31788s/100 iters), loss = 0.768975
I1211 08:38:36.129694 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 08:38:36.129694 22260 solver.cpp:237]     Train net output #1: loss = 0.768975 (* 1 = 0.768975 loss)
I1211 08:38:36.129694 22260 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1211 08:38:42.451226 22260 solver.cpp:218] Iteration 94900 (15.8194 iter/s, 6.32134s/100 iters), loss = 0.74129
I1211 08:38:42.451226 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 08:38:42.451226 22260 solver.cpp:237]     Train net output #1: loss = 0.74129 (* 1 = 0.74129 loss)
I1211 08:38:42.451226 22260 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1211 08:38:48.455685 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:38:48.704716 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95000.caffemodel
I1211 08:38:48.721716 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95000.solverstate
I1211 08:38:48.725716 22260 solver.cpp:330] Iteration 95000, Testing net (#0)
I1211 08:38:48.725716 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:38:50.238821 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:38:50.298830 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6015
I1211 08:38:50.298830 22260 solver.cpp:397]     Test net output #1: loss = 1.55452 (* 1 = 1.55452 loss)
I1211 08:38:50.359833 22260 solver.cpp:218] Iteration 95000 (12.6454 iter/s, 7.90801s/100 iters), loss = 0.601205
I1211 08:38:50.359833 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:38:50.359833 22260 solver.cpp:237]     Train net output #1: loss = 0.601205 (* 1 = 0.601205 loss)
I1211 08:38:50.359833 22260 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1211 08:38:50.359833 22260 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1211 08:38:56.691328 22260 solver.cpp:218] Iteration 95100 (15.795 iter/s, 6.33113s/100 iters), loss = 0.748354
I1211 08:38:56.691328 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 08:38:56.691328 22260 solver.cpp:237]     Train net output #1: loss = 0.748354 (* 1 = 0.748354 loss)
I1211 08:38:56.691328 22260 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1211 08:39:03.022830 22260 solver.cpp:218] Iteration 95200 (15.7959 iter/s, 6.33074s/100 iters), loss = 0.487222
I1211 08:39:03.022830 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:39:03.022830 22260 solver.cpp:237]     Train net output #1: loss = 0.487222 (* 1 = 0.487222 loss)
I1211 08:39:03.022830 22260 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1211 08:39:09.355227 22260 solver.cpp:218] Iteration 95300 (15.7914 iter/s, 6.33256s/100 iters), loss = 0.576389
I1211 08:39:09.355227 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:39:09.355227 22260 solver.cpp:237]     Train net output #1: loss = 0.576389 (* 1 = 0.576389 loss)
I1211 08:39:09.355227 22260 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1211 08:39:15.691759 22260 solver.cpp:218] Iteration 95400 (15.783 iter/s, 6.33595s/100 iters), loss = 0.43685
I1211 08:39:15.691759 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:39:15.691759 22260 solver.cpp:237]     Train net output #1: loss = 0.43685 (* 1 = 0.43685 loss)
I1211 08:39:15.691759 22260 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1211 08:39:21.711220 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:39:21.960235 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95500.caffemodel
I1211 08:39:21.976239 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_95500.solverstate
I1211 08:39:21.980739 22260 solver.cpp:330] Iteration 95500, Testing net (#0)
I1211 08:39:21.980739 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:39:23.493338 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:39:23.552337 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6787
I1211 08:39:23.552337 22260 solver.cpp:397]     Test net output #1: loss = 1.19174 (* 1 = 1.19174 loss)
I1211 08:39:23.613343 22260 solver.cpp:218] Iteration 95500 (12.6244 iter/s, 7.92119s/100 iters), loss = 0.492027
I1211 08:39:23.613343 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:39:23.613343 22260 solver.cpp:237]     Train net output #1: loss = 0.492027 (* 1 = 0.492027 loss)
I1211 08:39:23.613343 22260 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1211 08:39:29.934780 22260 solver.cpp:218] Iteration 95600 (15.8203 iter/s, 6.32098s/100 iters), loss = 0.556295
I1211 08:39:29.934780 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:39:29.934780 22260 solver.cpp:237]     Train net output #1: loss = 0.556295 (* 1 = 0.556295 loss)
I1211 08:39:29.934780 22260 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1211 08:39:36.251289 22260 solver.cpp:218] Iteration 95700 (15.832 iter/s, 6.31633s/100 iters), loss = 0.391363
I1211 08:39:36.251289 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:39:36.251289 22260 solver.cpp:237]     Train net output #1: loss = 0.391363 (* 1 = 0.391363 loss)
I1211 08:39:36.251289 22260 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1211 08:39:42.569694 22260 solver.cpp:218] Iteration 95800 (15.8295 iter/s, 6.31733s/100 iters), loss = 0.50101
I1211 08:39:42.569694 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:39:42.569694 22260 solver.cpp:237]     Train net output #1: loss = 0.50101 (* 1 = 0.50101 loss)
I1211 08:39:42.569694 22260 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1211 08:39:48.880153 22260 solver.cpp:218] Iteration 95900 (15.8479 iter/s, 6.30997s/100 iters), loss = 0.587096
I1211 08:39:48.880153 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 08:39:48.880153 22260 solver.cpp:237]     Train net output #1: loss = 0.587096 (* 1 = 0.587096 loss)
I1211 08:39:48.880153 22260 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1211 08:39:54.885601 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:39:55.134619 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96000.caffemodel
I1211 08:39:55.152618 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96000.solverstate
I1211 08:39:55.157618 22260 solver.cpp:330] Iteration 96000, Testing net (#0)
I1211 08:39:55.157618 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:39:56.670716 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:39:56.729722 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6774
I1211 08:39:56.730723 22260 solver.cpp:397]     Test net output #1: loss = 1.18933 (* 1 = 1.18933 loss)
I1211 08:39:56.790726 22260 solver.cpp:218] Iteration 96000 (12.6408 iter/s, 7.9109s/100 iters), loss = 0.48062
I1211 08:39:56.790726 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:39:56.790726 22260 solver.cpp:237]     Train net output #1: loss = 0.48062 (* 1 = 0.48062 loss)
I1211 08:39:56.790726 22260 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1211 08:40:03.099158 22260 solver.cpp:218] Iteration 96100 (15.8527 iter/s, 6.30806s/100 iters), loss = 0.587009
I1211 08:40:03.099158 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:40:03.099158 22260 solver.cpp:237]     Train net output #1: loss = 0.587009 (* 1 = 0.587009 loss)
I1211 08:40:03.099158 22260 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1211 08:40:09.410604 22260 solver.cpp:218] Iteration 96200 (15.8451 iter/s, 6.31111s/100 iters), loss = 0.352658
I1211 08:40:09.411604 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:40:09.411604 22260 solver.cpp:237]     Train net output #1: loss = 0.352658 (* 1 = 0.352658 loss)
I1211 08:40:09.411604 22260 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1211 08:40:15.735045 22260 solver.cpp:218] Iteration 96300 (15.8148 iter/s, 6.3232s/100 iters), loss = 0.480829
I1211 08:40:15.735045 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:40:15.735045 22260 solver.cpp:237]     Train net output #1: loss = 0.480829 (* 1 = 0.480829 loss)
I1211 08:40:15.735045 22260 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1211 08:40:22.050456 22260 solver.cpp:218] Iteration 96400 (15.8354 iter/s, 6.31497s/100 iters), loss = 0.416869
I1211 08:40:22.050456 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:40:22.050456 22260 solver.cpp:237]     Train net output #1: loss = 0.416869 (* 1 = 0.416869 loss)
I1211 08:40:22.050456 22260 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1211 08:40:28.048880 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:40:28.299913 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96500.caffemodel
I1211 08:40:28.314913 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_96500.solverstate
I1211 08:40:28.318913 22260 solver.cpp:330] Iteration 96500, Testing net (#0)
I1211 08:40:28.319914 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:40:29.830998 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:40:29.891006 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6799
I1211 08:40:29.891006 22260 solver.cpp:397]     Test net output #1: loss = 1.18738 (* 1 = 1.18738 loss)
I1211 08:40:29.951005 22260 solver.cpp:218] Iteration 96500 (12.6568 iter/s, 7.90088s/100 iters), loss = 0.415613
I1211 08:40:29.951005 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:40:29.951005 22260 solver.cpp:237]     Train net output #1: loss = 0.415613 (* 1 = 0.415613 loss)
I1211 08:40:29.951005 22260 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1211 08:40:36.287478 22260 solver.cpp:218] Iteration 96600 (15.7844 iter/s, 6.33535s/100 iters), loss = 0.557426
I1211 08:40:36.287478 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 08:40:36.287478 22260 solver.cpp:237]     Train net output #1: loss = 0.557426 (* 1 = 0.557426 loss)
I1211 08:40:36.287478 22260 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1211 08:40:42.622992 22260 solver.cpp:218] Iteration 96700 (15.7854 iter/s, 6.33497s/100 iters), loss = 0.390155
I1211 08:40:42.622992 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:40:42.622992 22260 solver.cpp:237]     Train net output #1: loss = 0.390155 (* 1 = 0.390155 loss)
I1211 08:40:42.622992 22260 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1211 08:40:48.952425 22260 solver.cpp:218] Iteration 96800 (15.7993 iter/s, 6.32941s/100 iters), loss = 0.533468
I1211 08:40:48.952425 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:40:48.952425 22260 solver.cpp:237]     Train net output #1: loss = 0.533468 (* 1 = 0.533468 loss)
I1211 08:40:48.952425 22260 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1211 08:40:55.283403 22260 solver.cpp:218] Iteration 96900 (15.7966 iter/s, 6.33048s/100 iters), loss = 0.464014
I1211 08:40:55.283903 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:40:55.283903 22260 solver.cpp:237]     Train net output #1: loss = 0.464014 (* 1 = 0.464014 loss)
I1211 08:40:55.283903 22260 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1211 08:41:01.298415 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:41:01.547518 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97000.caffemodel
I1211 08:41:01.562517 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97000.solverstate
I1211 08:41:01.567536 22260 solver.cpp:330] Iteration 97000, Testing net (#0)
I1211 08:41:01.567536 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:41:03.077765 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:41:03.136783 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6801
I1211 08:41:03.136783 22260 solver.cpp:397]     Test net output #1: loss = 1.18857 (* 1 = 1.18857 loss)
I1211 08:41:03.197787 22260 solver.cpp:218] Iteration 97000 (12.6362 iter/s, 7.91378s/100 iters), loss = 0.47992
I1211 08:41:03.197787 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:41:03.197787 22260 solver.cpp:237]     Train net output #1: loss = 0.47992 (* 1 = 0.47992 loss)
I1211 08:41:03.197787 22260 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1211 08:41:09.524348 22260 solver.cpp:218] Iteration 97100 (15.8073 iter/s, 6.32618s/100 iters), loss = 0.470837
I1211 08:41:09.524348 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:41:09.524348 22260 solver.cpp:237]     Train net output #1: loss = 0.470837 (* 1 = 0.470837 loss)
I1211 08:41:09.524348 22260 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1211 08:41:15.851842 22260 solver.cpp:218] Iteration 97200 (15.8036 iter/s, 6.32766s/100 iters), loss = 0.386571
I1211 08:41:15.852843 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:41:15.852843 22260 solver.cpp:237]     Train net output #1: loss = 0.386571 (* 1 = 0.386571 loss)
I1211 08:41:15.852843 22260 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1211 08:41:22.186286 22260 solver.cpp:218] Iteration 97300 (15.7897 iter/s, 6.33325s/100 iters), loss = 0.518574
I1211 08:41:22.186286 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:41:22.186286 22260 solver.cpp:237]     Train net output #1: loss = 0.518574 (* 1 = 0.518574 loss)
I1211 08:41:22.186286 22260 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1211 08:41:28.512794 22260 solver.cpp:218] Iteration 97400 (15.8066 iter/s, 6.32649s/100 iters), loss = 0.495923
I1211 08:41:28.512794 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:41:28.512794 22260 solver.cpp:237]     Train net output #1: loss = 0.495923 (* 1 = 0.495923 loss)
I1211 08:41:28.512794 22260 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1211 08:41:34.529243 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:41:34.778259 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97500.caffemodel
I1211 08:41:34.794762 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_97500.solverstate
I1211 08:41:34.799263 22260 solver.cpp:330] Iteration 97500, Testing net (#0)
I1211 08:41:34.799263 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:41:36.311394 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:41:36.370393 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6801
I1211 08:41:36.370393 22260 solver.cpp:397]     Test net output #1: loss = 1.19072 (* 1 = 1.19072 loss)
I1211 08:41:36.431401 22260 solver.cpp:218] Iteration 97500 (12.6293 iter/s, 7.91808s/100 iters), loss = 0.446531
I1211 08:41:36.431401 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:41:36.431401 22260 solver.cpp:237]     Train net output #1: loss = 0.446531 (* 1 = 0.446531 loss)
I1211 08:41:36.431401 22260 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1211 08:41:42.765890 22260 solver.cpp:218] Iteration 97600 (15.7888 iter/s, 6.33362s/100 iters), loss = 0.39163
I1211 08:41:42.765890 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:41:42.765890 22260 solver.cpp:237]     Train net output #1: loss = 0.39163 (* 1 = 0.39163 loss)
I1211 08:41:42.765890 22260 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1211 08:41:49.103343 22260 solver.cpp:218] Iteration 97700 (15.7799 iter/s, 6.33717s/100 iters), loss = 0.392502
I1211 08:41:49.103343 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:41:49.103343 22260 solver.cpp:237]     Train net output #1: loss = 0.392502 (* 1 = 0.392502 loss)
I1211 08:41:49.103343 22260 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1211 08:41:55.439831 22260 solver.cpp:218] Iteration 97800 (15.7821 iter/s, 6.33628s/100 iters), loss = 0.518234
I1211 08:41:55.439831 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:41:55.439831 22260 solver.cpp:237]     Train net output #1: loss = 0.518234 (* 1 = 0.518234 loss)
I1211 08:41:55.439831 22260 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1211 08:42:01.771288 22260 solver.cpp:218] Iteration 97900 (15.7957 iter/s, 6.33086s/100 iters), loss = 0.47689
I1211 08:42:01.771288 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:42:01.771288 22260 solver.cpp:237]     Train net output #1: loss = 0.47689 (* 1 = 0.47689 loss)
I1211 08:42:01.771288 22260 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1211 08:42:07.785667 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:42:08.034693 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98000.caffemodel
I1211 08:42:08.051693 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98000.solverstate
I1211 08:42:08.055692 22260 solver.cpp:330] Iteration 98000, Testing net (#0)
I1211 08:42:08.055692 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:42:09.567817 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:42:09.627822 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1211 08:42:09.627822 22260 solver.cpp:397]     Test net output #1: loss = 1.19296 (* 1 = 1.19296 loss)
I1211 08:42:09.688822 22260 solver.cpp:218] Iteration 98000 (12.6308 iter/s, 7.91718s/100 iters), loss = 0.465149
I1211 08:42:09.688822 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:42:09.688822 22260 solver.cpp:237]     Train net output #1: loss = 0.465149 (* 1 = 0.465149 loss)
I1211 08:42:09.688822 22260 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1211 08:42:16.027245 22260 solver.cpp:218] Iteration 98100 (15.7765 iter/s, 6.33855s/100 iters), loss = 0.434243
I1211 08:42:16.027245 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:42:16.027245 22260 solver.cpp:237]     Train net output #1: loss = 0.434243 (* 1 = 0.434243 loss)
I1211 08:42:16.027245 22260 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1211 08:42:22.362685 22260 solver.cpp:218] Iteration 98200 (15.7874 iter/s, 6.33417s/100 iters), loss = 0.350086
I1211 08:42:22.362685 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:42:22.362685 22260 solver.cpp:237]     Train net output #1: loss = 0.350086 (* 1 = 0.350086 loss)
I1211 08:42:22.362685 22260 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1211 08:42:28.694159 22260 solver.cpp:218] Iteration 98300 (15.7956 iter/s, 6.33089s/100 iters), loss = 0.460621
I1211 08:42:28.694159 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:42:28.694159 22260 solver.cpp:237]     Train net output #1: loss = 0.460621 (* 1 = 0.460621 loss)
I1211 08:42:28.694159 22260 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1211 08:42:35.016628 22260 solver.cpp:218] Iteration 98400 (15.8169 iter/s, 6.32236s/100 iters), loss = 0.446286
I1211 08:42:35.016628 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:42:35.016628 22260 solver.cpp:237]     Train net output #1: loss = 0.446286 (* 1 = 0.446286 loss)
I1211 08:42:35.016628 22260 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1211 08:42:41.035070 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:42:41.284080 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98500.caffemodel
I1211 08:42:41.299583 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_98500.solverstate
I1211 08:42:41.304085 22260 solver.cpp:330] Iteration 98500, Testing net (#0)
I1211 08:42:41.304085 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:42:42.815176 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:42:42.875182 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6843
I1211 08:42:42.875182 22260 solver.cpp:397]     Test net output #1: loss = 1.19447 (* 1 = 1.19447 loss)
I1211 08:42:42.936180 22260 solver.cpp:218] Iteration 98500 (12.628 iter/s, 7.9189s/100 iters), loss = 0.347819
I1211 08:42:42.936180 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:42:42.936180 22260 solver.cpp:237]     Train net output #1: loss = 0.347819 (* 1 = 0.347819 loss)
I1211 08:42:42.936180 22260 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1211 08:42:49.259635 22260 solver.cpp:218] Iteration 98600 (15.8145 iter/s, 6.32331s/100 iters), loss = 0.455866
I1211 08:42:49.259635 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:42:49.259635 22260 solver.cpp:237]     Train net output #1: loss = 0.455866 (* 1 = 0.455866 loss)
I1211 08:42:49.259635 22260 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1211 08:42:55.580113 22260 solver.cpp:218] Iteration 98700 (15.8232 iter/s, 6.31985s/100 iters), loss = 0.391422
I1211 08:42:55.580113 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:42:55.580113 22260 solver.cpp:237]     Train net output #1: loss = 0.391422 (* 1 = 0.391422 loss)
I1211 08:42:55.580113 22260 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1211 08:43:01.894552 22260 solver.cpp:218] Iteration 98800 (15.8362 iter/s, 6.31464s/100 iters), loss = 0.454148
I1211 08:43:01.894552 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:43:01.894552 22260 solver.cpp:237]     Train net output #1: loss = 0.454148 (* 1 = 0.454148 loss)
I1211 08:43:01.894552 22260 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1211 08:43:08.230042 22260 solver.cpp:218] Iteration 98900 (15.785 iter/s, 6.33511s/100 iters), loss = 0.463199
I1211 08:43:08.230042 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:43:08.230042 22260 solver.cpp:237]     Train net output #1: loss = 0.463199 (* 1 = 0.463199 loss)
I1211 08:43:08.231045 22260 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1211 08:43:14.251452 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:43:14.499969 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99000.caffemodel
I1211 08:43:14.514473 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99000.solverstate
I1211 08:43:14.519474 22260 solver.cpp:330] Iteration 99000, Testing net (#0)
I1211 08:43:14.519474 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:43:16.031575 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:43:16.090575 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6838
I1211 08:43:16.090575 22260 solver.cpp:397]     Test net output #1: loss = 1.19343 (* 1 = 1.19343 loss)
I1211 08:43:16.152581 22260 solver.cpp:218] Iteration 99000 (12.6239 iter/s, 7.92148s/100 iters), loss = 0.328458
I1211 08:43:16.152581 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:43:16.152581 22260 solver.cpp:237]     Train net output #1: loss = 0.328458 (* 1 = 0.328458 loss)
I1211 08:43:16.152581 22260 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1211 08:43:22.489027 22260 solver.cpp:218] Iteration 99100 (15.7817 iter/s, 6.33646s/100 iters), loss = 0.487139
I1211 08:43:22.489027 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:43:22.489027 22260 solver.cpp:237]     Train net output #1: loss = 0.487139 (* 1 = 0.487139 loss)
I1211 08:43:22.489027 22260 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1211 08:43:28.827477 22260 solver.cpp:218] Iteration 99200 (15.7772 iter/s, 6.33826s/100 iters), loss = 0.326647
I1211 08:43:28.828478 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:43:28.828478 22260 solver.cpp:237]     Train net output #1: loss = 0.326647 (* 1 = 0.326647 loss)
I1211 08:43:28.828478 22260 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1211 08:43:35.159968 22260 solver.cpp:218] Iteration 99300 (15.7935 iter/s, 6.33173s/100 iters), loss = 0.511454
I1211 08:43:35.159968 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 08:43:35.159968 22260 solver.cpp:237]     Train net output #1: loss = 0.511454 (* 1 = 0.511454 loss)
I1211 08:43:35.159968 22260 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1211 08:43:41.491433 22260 solver.cpp:218] Iteration 99400 (15.7949 iter/s, 6.33114s/100 iters), loss = 0.51928
I1211 08:43:41.491433 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:43:41.491433 22260 solver.cpp:237]     Train net output #1: loss = 0.51928 (* 1 = 0.51928 loss)
I1211 08:43:41.491433 22260 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1211 08:43:47.517870 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:43:47.766880 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99500.caffemodel
I1211 08:43:47.783881 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_99500.solverstate
I1211 08:43:47.788882 22260 solver.cpp:330] Iteration 99500, Testing net (#0)
I1211 08:43:47.788882 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:43:49.301465 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:43:49.360971 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6826
I1211 08:43:49.360971 22260 solver.cpp:397]     Test net output #1: loss = 1.19919 (* 1 = 1.19919 loss)
I1211 08:43:49.421977 22260 solver.cpp:218] Iteration 99500 (12.6101 iter/s, 7.93014s/100 iters), loss = 0.415939
I1211 08:43:49.421977 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:43:49.421977 22260 solver.cpp:237]     Train net output #1: loss = 0.415939 (* 1 = 0.415939 loss)
I1211 08:43:49.421977 22260 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1211 08:43:55.753384 22260 solver.cpp:218] Iteration 99600 (15.7972 iter/s, 6.33022s/100 iters), loss = 0.517404
I1211 08:43:55.753384 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:43:55.753384 22260 solver.cpp:237]     Train net output #1: loss = 0.517404 (* 1 = 0.517404 loss)
I1211 08:43:55.753384 22260 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1211 08:44:02.092234 22260 solver.cpp:218] Iteration 99700 (15.7753 iter/s, 6.33901s/100 iters), loss = 0.306216
I1211 08:44:02.092234 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:44:02.092234 22260 solver.cpp:237]     Train net output #1: loss = 0.306216 (* 1 = 0.306216 loss)
I1211 08:44:02.092234 22260 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1211 08:44:08.436892 22260 solver.cpp:218] Iteration 99800 (15.7627 iter/s, 6.34411s/100 iters), loss = 0.370047
I1211 08:44:08.436892 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:44:08.436892 22260 solver.cpp:237]     Train net output #1: loss = 0.370047 (* 1 = 0.370047 loss)
I1211 08:44:08.436892 22260 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1211 08:44:14.767401 22260 solver.cpp:218] Iteration 99900 (15.7969 iter/s, 6.33036s/100 iters), loss = 0.451957
I1211 08:44:14.767401 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:44:14.767401 22260 solver.cpp:237]     Train net output #1: loss = 0.451957 (* 1 = 0.451957 loss)
I1211 08:44:14.767401 22260 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1211 08:44:20.791813 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:44:21.040830 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100000.caffemodel
I1211 08:44:21.055830 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100000.solverstate
I1211 08:44:21.059830 22260 solver.cpp:330] Iteration 100000, Testing net (#0)
I1211 08:44:21.059830 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:44:22.573925 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:44:22.633934 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6831
I1211 08:44:22.633934 22260 solver.cpp:397]     Test net output #1: loss = 1.19999 (* 1 = 1.19999 loss)
I1211 08:44:22.694932 22260 solver.cpp:218] Iteration 100000 (12.6163 iter/s, 7.92624s/100 iters), loss = 0.378234
I1211 08:44:22.694932 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:44:22.694932 22260 solver.cpp:237]     Train net output #1: loss = 0.378234 (* 1 = 0.378234 loss)
I1211 08:44:22.694932 22260 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1211 08:44:29.019315 22260 solver.cpp:218] Iteration 100100 (15.8121 iter/s, 6.32429s/100 iters), loss = 0.385168
I1211 08:44:29.019315 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:44:29.019315 22260 solver.cpp:237]     Train net output #1: loss = 0.385168 (* 1 = 0.385168 loss)
I1211 08:44:29.019315 22260 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1211 08:44:35.343858 22260 solver.cpp:218] Iteration 100200 (15.8116 iter/s, 6.32448s/100 iters), loss = 0.375189
I1211 08:44:35.343858 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:44:35.343858 22260 solver.cpp:237]     Train net output #1: loss = 0.375189 (* 1 = 0.375189 loss)
I1211 08:44:35.343858 22260 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1211 08:44:41.661326 22260 solver.cpp:218] Iteration 100300 (15.8309 iter/s, 6.31678s/100 iters), loss = 0.421439
I1211 08:44:41.661326 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:44:41.661326 22260 solver.cpp:237]     Train net output #1: loss = 0.421439 (* 1 = 0.421439 loss)
I1211 08:44:41.661326 22260 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1211 08:44:47.987794 22260 solver.cpp:218] Iteration 100400 (15.8075 iter/s, 6.32612s/100 iters), loss = 0.474308
I1211 08:44:47.987794 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:44:47.987794 22260 solver.cpp:237]     Train net output #1: loss = 0.474308 (* 1 = 0.474308 loss)
I1211 08:44:47.987794 22260 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1211 08:44:53.998240 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:44:54.248260 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100500.caffemodel
I1211 08:44:54.263257 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_100500.solverstate
I1211 08:44:54.267257 22260 solver.cpp:330] Iteration 100500, Testing net (#0)
I1211 08:44:54.267257 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:44:55.782361 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:44:55.842365 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6818
I1211 08:44:55.842365 22260 solver.cpp:397]     Test net output #1: loss = 1.20933 (* 1 = 1.20933 loss)
I1211 08:44:55.902364 22260 solver.cpp:218] Iteration 100500 (12.6358 iter/s, 7.91403s/100 iters), loss = 0.402169
I1211 08:44:55.902364 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:44:55.902364 22260 solver.cpp:237]     Train net output #1: loss = 0.402169 (* 1 = 0.402169 loss)
I1211 08:44:55.902364 22260 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1211 08:45:02.224808 22260 solver.cpp:218] Iteration 100600 (15.8184 iter/s, 6.32177s/100 iters), loss = 0.47936
I1211 08:45:02.224808 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:45:02.224808 22260 solver.cpp:237]     Train net output #1: loss = 0.47936 (* 1 = 0.47936 loss)
I1211 08:45:02.224808 22260 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1211 08:45:08.540210 22260 solver.cpp:218] Iteration 100700 (15.8341 iter/s, 6.3155s/100 iters), loss = 0.285145
I1211 08:45:08.540210 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 08:45:08.540210 22260 solver.cpp:237]     Train net output #1: loss = 0.285145 (* 1 = 0.285145 loss)
I1211 08:45:08.540210 22260 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1211 08:45:14.866652 22260 solver.cpp:218] Iteration 100800 (15.8075 iter/s, 6.32613s/100 iters), loss = 0.431825
I1211 08:45:14.867655 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:45:14.867655 22260 solver.cpp:237]     Train net output #1: loss = 0.431825 (* 1 = 0.431825 loss)
I1211 08:45:14.867655 22260 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1211 08:45:21.188133 22260 solver.cpp:218] Iteration 100900 (15.8223 iter/s, 6.32018s/100 iters), loss = 0.406679
I1211 08:45:21.188133 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:45:21.188133 22260 solver.cpp:237]     Train net output #1: loss = 0.406679 (* 1 = 0.406679 loss)
I1211 08:45:21.188133 22260 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1211 08:45:27.199579 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:45:27.449092 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101000.caffemodel
I1211 08:45:27.464092 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101000.solverstate
I1211 08:45:27.468597 22260 solver.cpp:330] Iteration 101000, Testing net (#0)
I1211 08:45:27.468597 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:45:28.981691 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:45:29.040690 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6822
I1211 08:45:29.041692 22260 solver.cpp:397]     Test net output #1: loss = 1.21743 (* 1 = 1.21743 loss)
I1211 08:45:29.101696 22260 solver.cpp:218] Iteration 101000 (12.6368 iter/s, 7.91341s/100 iters), loss = 0.293081
I1211 08:45:29.101696 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:45:29.101696 22260 solver.cpp:237]     Train net output #1: loss = 0.293081 (* 1 = 0.293081 loss)
I1211 08:45:29.101696 22260 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1211 08:45:35.425143 22260 solver.cpp:218] Iteration 101100 (15.8155 iter/s, 6.32292s/100 iters), loss = 0.424175
I1211 08:45:35.425143 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:45:35.425143 22260 solver.cpp:237]     Train net output #1: loss = 0.424175 (* 1 = 0.424175 loss)
I1211 08:45:35.425143 22260 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1211 08:45:41.738677 22260 solver.cpp:218] Iteration 101200 (15.8401 iter/s, 6.31311s/100 iters), loss = 0.28965
I1211 08:45:41.738677 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:45:41.738677 22260 solver.cpp:237]     Train net output #1: loss = 0.28965 (* 1 = 0.28965 loss)
I1211 08:45:41.738677 22260 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1211 08:45:48.062214 22260 solver.cpp:218] Iteration 101300 (15.8153 iter/s, 6.32298s/100 iters), loss = 0.359141
I1211 08:45:48.062214 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:45:48.062214 22260 solver.cpp:237]     Train net output #1: loss = 0.359141 (* 1 = 0.359141 loss)
I1211 08:45:48.062214 22260 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1211 08:45:54.378659 22260 solver.cpp:218] Iteration 101400 (15.831 iter/s, 6.31671s/100 iters), loss = 0.450902
I1211 08:45:54.378659 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:45:54.378659 22260 solver.cpp:237]     Train net output #1: loss = 0.450902 (* 1 = 0.450902 loss)
I1211 08:45:54.378659 22260 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1211 08:46:00.392068 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:46:00.641079 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101500.caffemodel
I1211 08:46:00.656081 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_101500.solverstate
I1211 08:46:00.660583 22260 solver.cpp:330] Iteration 101500, Testing net (#0)
I1211 08:46:00.660583 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:46:02.171205 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:46:02.231204 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6826
I1211 08:46:02.231204 22260 solver.cpp:397]     Test net output #1: loss = 1.21113 (* 1 = 1.21113 loss)
I1211 08:46:02.291208 22260 solver.cpp:218] Iteration 101500 (12.6388 iter/s, 7.91213s/100 iters), loss = 0.345819
I1211 08:46:02.291208 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:46:02.291208 22260 solver.cpp:237]     Train net output #1: loss = 0.345819 (* 1 = 0.345819 loss)
I1211 08:46:02.291208 22260 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1211 08:46:08.609699 22260 solver.cpp:218] Iteration 101600 (15.8291 iter/s, 6.31748s/100 iters), loss = 0.348738
I1211 08:46:08.609699 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:46:08.609699 22260 solver.cpp:237]     Train net output #1: loss = 0.348738 (* 1 = 0.348738 loss)
I1211 08:46:08.609699 22260 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1211 08:46:14.931211 22260 solver.cpp:218] Iteration 101700 (15.8184 iter/s, 6.32176s/100 iters), loss = 0.310152
I1211 08:46:14.931211 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:46:14.931211 22260 solver.cpp:237]     Train net output #1: loss = 0.310152 (* 1 = 0.310152 loss)
I1211 08:46:14.931211 22260 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1211 08:46:21.251719 22260 solver.cpp:218] Iteration 101800 (15.8243 iter/s, 6.31938s/100 iters), loss = 0.398336
I1211 08:46:21.251719 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 08:46:21.251719 22260 solver.cpp:237]     Train net output #1: loss = 0.398336 (* 1 = 0.398336 loss)
I1211 08:46:21.251719 22260 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1211 08:46:27.562238 22260 solver.cpp:218] Iteration 101900 (15.847 iter/s, 6.31034s/100 iters), loss = 0.472142
I1211 08:46:27.562739 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 08:46:27.562739 22260 solver.cpp:237]     Train net output #1: loss = 0.472142 (* 1 = 0.472142 loss)
I1211 08:46:27.562739 22260 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1211 08:46:33.567112 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:46:33.816642 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102000.caffemodel
I1211 08:46:33.832643 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102000.solverstate
I1211 08:46:33.836642 22260 solver.cpp:330] Iteration 102000, Testing net (#0)
I1211 08:46:33.836642 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:46:35.349755 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:46:35.408761 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6826
I1211 08:46:35.408761 22260 solver.cpp:397]     Test net output #1: loss = 1.21436 (* 1 = 1.21436 loss)
I1211 08:46:35.469262 22260 solver.cpp:218] Iteration 102000 (12.6484 iter/s, 7.90611s/100 iters), loss = 0.4126
I1211 08:46:35.469262 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:46:35.469262 22260 solver.cpp:237]     Train net output #1: loss = 0.4126 (* 1 = 0.4126 loss)
I1211 08:46:35.469262 22260 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1211 08:46:41.792197 22260 solver.cpp:218] Iteration 102100 (15.8162 iter/s, 6.32263s/100 iters), loss = 0.471633
I1211 08:46:41.792197 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:46:41.792197 22260 solver.cpp:237]     Train net output #1: loss = 0.471633 (* 1 = 0.471633 loss)
I1211 08:46:41.792197 22260 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1211 08:46:48.120561 22260 solver.cpp:218] Iteration 102200 (15.8014 iter/s, 6.32856s/100 iters), loss = 0.324971
I1211 08:46:48.120561 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 08:46:48.120561 22260 solver.cpp:237]     Train net output #1: loss = 0.324971 (* 1 = 0.324971 loss)
I1211 08:46:48.120561 22260 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1211 08:46:54.440172 22260 solver.cpp:218] Iteration 102300 (15.8249 iter/s, 6.31915s/100 iters), loss = 0.493287
I1211 08:46:54.440172 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:46:54.440172 22260 solver.cpp:237]     Train net output #1: loss = 0.493287 (* 1 = 0.493287 loss)
I1211 08:46:54.440172 22260 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1211 08:47:00.764677 22260 solver.cpp:218] Iteration 102400 (15.8143 iter/s, 6.32338s/100 iters), loss = 0.391556
I1211 08:47:00.764677 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:47:00.764677 22260 solver.cpp:237]     Train net output #1: loss = 0.391556 (* 1 = 0.391556 loss)
I1211 08:47:00.764677 22260 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1211 08:47:06.781136 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:47:07.032152 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102500.caffemodel
I1211 08:47:07.048152 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_102500.solverstate
I1211 08:47:07.052153 22260 solver.cpp:330] Iteration 102500, Testing net (#0)
I1211 08:47:07.052153 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:47:08.565263 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:47:08.625267 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6832
I1211 08:47:08.625267 22260 solver.cpp:397]     Test net output #1: loss = 1.2144 (* 1 = 1.2144 loss)
I1211 08:47:08.686769 22260 solver.cpp:218] Iteration 102500 (12.6238 iter/s, 7.92153s/100 iters), loss = 0.352013
I1211 08:47:08.686769 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:47:08.686769 22260 solver.cpp:237]     Train net output #1: loss = 0.352013 (* 1 = 0.352013 loss)
I1211 08:47:08.686769 22260 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1211 08:47:15.023684 22260 solver.cpp:218] Iteration 102600 (15.7815 iter/s, 6.33654s/100 iters), loss = 0.410833
I1211 08:47:15.023684 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:47:15.023684 22260 solver.cpp:237]     Train net output #1: loss = 0.410833 (* 1 = 0.410833 loss)
I1211 08:47:15.023684 22260 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1211 08:47:21.362404 22260 solver.cpp:218] Iteration 102700 (15.777 iter/s, 6.33832s/100 iters), loss = 0.371728
I1211 08:47:21.362404 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:47:21.362404 22260 solver.cpp:237]     Train net output #1: loss = 0.371728 (* 1 = 0.371728 loss)
I1211 08:47:21.362404 22260 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1211 08:47:27.707662 22260 solver.cpp:218] Iteration 102800 (15.7598 iter/s, 6.34526s/100 iters), loss = 0.410237
I1211 08:47:27.707662 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:47:27.707662 22260 solver.cpp:237]     Train net output #1: loss = 0.410237 (* 1 = 0.410237 loss)
I1211 08:47:27.707662 22260 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1211 08:47:34.042271 22260 solver.cpp:218] Iteration 102900 (15.7878 iter/s, 6.33401s/100 iters), loss = 0.375812
I1211 08:47:34.042271 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:47:34.042271 22260 solver.cpp:237]     Train net output #1: loss = 0.375812 (* 1 = 0.375812 loss)
I1211 08:47:34.042271 22260 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1211 08:47:40.074419 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:47:40.325475 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103000.caffemodel
I1211 08:47:40.345520 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103000.solverstate
I1211 08:47:40.350514 22260 solver.cpp:330] Iteration 103000, Testing net (#0)
I1211 08:47:40.350514 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:47:41.862484 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:47:41.922463 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6806
I1211 08:47:41.922463 22260 solver.cpp:397]     Test net output #1: loss = 1.21841 (* 1 = 1.21841 loss)
I1211 08:47:41.983031 22260 solver.cpp:218] Iteration 103000 (12.5936 iter/s, 7.94054s/100 iters), loss = 0.306035
I1211 08:47:41.983031 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:47:41.983031 22260 solver.cpp:237]     Train net output #1: loss = 0.306035 (* 1 = 0.306035 loss)
I1211 08:47:41.983031 22260 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1211 08:47:48.310727 22260 solver.cpp:218] Iteration 103100 (15.8056 iter/s, 6.32688s/100 iters), loss = 0.365
I1211 08:47:48.310727 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:47:48.310727 22260 solver.cpp:237]     Train net output #1: loss = 0.365 (* 1 = 0.365 loss)
I1211 08:47:48.310727 22260 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1211 08:47:54.639264 22260 solver.cpp:218] Iteration 103200 (15.8031 iter/s, 6.32788s/100 iters), loss = 0.294913
I1211 08:47:54.639264 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:47:54.639264 22260 solver.cpp:237]     Train net output #1: loss = 0.294913 (* 1 = 0.294913 loss)
I1211 08:47:54.639264 22260 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1211 08:48:00.973341 22260 solver.cpp:218] Iteration 103300 (15.7866 iter/s, 6.33451s/100 iters), loss = 0.39408
I1211 08:48:00.973341 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:48:00.973341 22260 solver.cpp:237]     Train net output #1: loss = 0.39408 (* 1 = 0.39408 loss)
I1211 08:48:00.973341 22260 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1211 08:48:07.309818 22260 solver.cpp:218] Iteration 103400 (15.7837 iter/s, 6.33567s/100 iters), loss = 0.432088
I1211 08:48:07.309818 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:48:07.309818 22260 solver.cpp:237]     Train net output #1: loss = 0.432088 (* 1 = 0.432088 loss)
I1211 08:48:07.309818 22260 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1211 08:48:13.328294 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:48:13.578305 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103500.caffemodel
I1211 08:48:13.593304 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_103500.solverstate
I1211 08:48:13.597304 22260 solver.cpp:330] Iteration 103500, Testing net (#0)
I1211 08:48:13.597304 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:48:15.108422 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:48:15.167424 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6815
I1211 08:48:15.168424 22260 solver.cpp:397]     Test net output #1: loss = 1.22122 (* 1 = 1.22122 loss)
I1211 08:48:15.228926 22260 solver.cpp:218] Iteration 103500 (12.6286 iter/s, 7.91852s/100 iters), loss = 0.353323
I1211 08:48:15.228926 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:48:15.229427 22260 solver.cpp:237]     Train net output #1: loss = 0.353323 (* 1 = 0.353323 loss)
I1211 08:48:15.229427 22260 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1211 08:48:21.554879 22260 solver.cpp:218] Iteration 103600 (15.8086 iter/s, 6.32565s/100 iters), loss = 0.428029
I1211 08:48:21.554879 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:48:21.554879 22260 solver.cpp:237]     Train net output #1: loss = 0.428029 (* 1 = 0.428029 loss)
I1211 08:48:21.554879 22260 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1211 08:48:27.880338 22260 solver.cpp:218] Iteration 103700 (15.8094 iter/s, 6.32533s/100 iters), loss = 0.289973
I1211 08:48:27.880338 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:48:27.880338 22260 solver.cpp:237]     Train net output #1: loss = 0.289973 (* 1 = 0.289973 loss)
I1211 08:48:27.880338 22260 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1211 08:48:34.193858 22260 solver.cpp:218] Iteration 103800 (15.8404 iter/s, 6.31299s/100 iters), loss = 0.375155
I1211 08:48:34.193858 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:48:34.193858 22260 solver.cpp:237]     Train net output #1: loss = 0.375155 (* 1 = 0.375155 loss)
I1211 08:48:34.193858 22260 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1211 08:48:40.512389 22260 solver.cpp:218] Iteration 103900 (15.8283 iter/s, 6.3178s/100 iters), loss = 0.357861
I1211 08:48:40.512389 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:48:40.512389 22260 solver.cpp:237]     Train net output #1: loss = 0.357861 (* 1 = 0.357861 loss)
I1211 08:48:40.512389 22260 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1211 08:48:46.526227 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:48:46.778270 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104000.caffemodel
I1211 08:48:46.792269 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104000.solverstate
I1211 08:48:46.797271 22260 solver.cpp:330] Iteration 104000, Testing net (#0)
I1211 08:48:46.797271 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:48:48.310237 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:48:48.370242 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6829
I1211 08:48:48.370242 22260 solver.cpp:397]     Test net output #1: loss = 1.21981 (* 1 = 1.21981 loss)
I1211 08:48:48.431743 22260 solver.cpp:218] Iteration 104000 (12.6283 iter/s, 7.91873s/100 iters), loss = 0.354925
I1211 08:48:48.431743 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:48:48.431743 22260 solver.cpp:237]     Train net output #1: loss = 0.354925 (* 1 = 0.354925 loss)
I1211 08:48:48.431743 22260 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1211 08:48:54.756688 22260 solver.cpp:218] Iteration 104100 (15.8123 iter/s, 6.3242s/100 iters), loss = 0.380062
I1211 08:48:54.756688 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:48:54.756688 22260 solver.cpp:237]     Train net output #1: loss = 0.380062 (* 1 = 0.380062 loss)
I1211 08:48:54.756688 22260 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1211 08:49:01.088107 22260 solver.cpp:218] Iteration 104200 (15.7948 iter/s, 6.33118s/100 iters), loss = 0.232973
I1211 08:49:01.088107 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 08:49:01.088107 22260 solver.cpp:237]     Train net output #1: loss = 0.232973 (* 1 = 0.232973 loss)
I1211 08:49:01.088107 22260 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1211 08:49:07.410621 22260 solver.cpp:218] Iteration 104300 (15.8161 iter/s, 6.32267s/100 iters), loss = 0.387747
I1211 08:49:07.410621 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:49:07.410621 22260 solver.cpp:237]     Train net output #1: loss = 0.387747 (* 1 = 0.387747 loss)
I1211 08:49:07.410621 22260 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1211 08:49:13.724735 22260 solver.cpp:218] Iteration 104400 (15.8397 iter/s, 6.31326s/100 iters), loss = 0.409964
I1211 08:49:13.724735 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:49:13.724735 22260 solver.cpp:237]     Train net output #1: loss = 0.409964 (* 1 = 0.409964 loss)
I1211 08:49:13.724735 22260 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1211 08:49:19.746161 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:49:19.995174 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104500.caffemodel
I1211 08:49:20.010174 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_104500.solverstate
I1211 08:49:20.014175 22260 solver.cpp:330] Iteration 104500, Testing net (#0)
I1211 08:49:20.014175 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:49:21.529250 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:49:21.588263 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6832
I1211 08:49:21.588263 22260 solver.cpp:397]     Test net output #1: loss = 1.22228 (* 1 = 1.22228 loss)
I1211 08:49:21.649267 22260 solver.cpp:218] Iteration 104500 (12.6202 iter/s, 7.92381s/100 iters), loss = 0.307401
I1211 08:49:21.649267 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:49:21.649267 22260 solver.cpp:237]     Train net output #1: loss = 0.307401 (* 1 = 0.307401 loss)
I1211 08:49:21.649267 22260 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1211 08:49:27.982725 22260 solver.cpp:218] Iteration 104600 (15.7895 iter/s, 6.33333s/100 iters), loss = 0.36764
I1211 08:49:27.982725 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:49:27.982725 22260 solver.cpp:237]     Train net output #1: loss = 0.36764 (* 1 = 0.36764 loss)
I1211 08:49:27.982725 22260 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1211 08:49:34.315197 22260 solver.cpp:218] Iteration 104700 (15.7932 iter/s, 6.33183s/100 iters), loss = 0.301509
I1211 08:49:34.315197 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:49:34.315197 22260 solver.cpp:237]     Train net output #1: loss = 0.301509 (* 1 = 0.301509 loss)
I1211 08:49:34.315197 22260 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1211 08:49:40.647634 22260 solver.cpp:218] Iteration 104800 (15.7912 iter/s, 6.33262s/100 iters), loss = 0.285892
I1211 08:49:40.647634 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:49:40.647634 22260 solver.cpp:237]     Train net output #1: loss = 0.285892 (* 1 = 0.285892 loss)
I1211 08:49:40.647634 22260 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1211 08:49:46.982154 22260 solver.cpp:218] Iteration 104900 (15.7872 iter/s, 6.33424s/100 iters), loss = 0.337625
I1211 08:49:46.983155 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:49:46.983155 22260 solver.cpp:237]     Train net output #1: loss = 0.337625 (* 1 = 0.337625 loss)
I1211 08:49:46.983155 22260 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1211 08:49:52.997592 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:49:53.246665 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105000.caffemodel
I1211 08:49:53.261665 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105000.solverstate
I1211 08:49:53.265666 22260 solver.cpp:330] Iteration 105000, Testing net (#0)
I1211 08:49:53.265666 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:49:54.778185 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:49:54.838224 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6832
I1211 08:49:54.838224 22260 solver.cpp:397]     Test net output #1: loss = 1.22786 (* 1 = 1.22786 loss)
I1211 08:49:54.899235 22260 solver.cpp:218] Iteration 105000 (12.6331 iter/s, 7.91569s/100 iters), loss = 0.403946
I1211 08:49:54.899235 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:49:54.899235 22260 solver.cpp:237]     Train net output #1: loss = 0.403946 (* 1 = 0.403946 loss)
I1211 08:49:54.899235 22260 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1211 08:50:01.219794 22260 solver.cpp:218] Iteration 105100 (15.8226 iter/s, 6.32008s/100 iters), loss = 0.407469
I1211 08:50:01.219794 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:50:01.219794 22260 solver.cpp:237]     Train net output #1: loss = 0.407469 (* 1 = 0.407469 loss)
I1211 08:50:01.219794 22260 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1211 08:50:07.534142 22260 solver.cpp:218] Iteration 105200 (15.8381 iter/s, 6.31389s/100 iters), loss = 0.259086
I1211 08:50:07.534142 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:50:07.534142 22260 solver.cpp:237]     Train net output #1: loss = 0.259086 (* 1 = 0.259086 loss)
I1211 08:50:07.534142 22260 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1211 08:50:13.854841 22260 solver.cpp:218] Iteration 105300 (15.8207 iter/s, 6.32082s/100 iters), loss = 0.353978
I1211 08:50:13.854841 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:50:13.854841 22260 solver.cpp:237]     Train net output #1: loss = 0.353978 (* 1 = 0.353978 loss)
I1211 08:50:13.854841 22260 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1211 08:50:20.180738 22260 solver.cpp:218] Iteration 105400 (15.8083 iter/s, 6.32579s/100 iters), loss = 0.362709
I1211 08:50:20.180738 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:50:20.180738 22260 solver.cpp:237]     Train net output #1: loss = 0.362709 (* 1 = 0.362709 loss)
I1211 08:50:20.180738 22260 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1211 08:50:26.191805 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:50:26.440816 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105500.caffemodel
I1211 08:50:26.455819 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_105500.solverstate
I1211 08:50:26.460824 22260 solver.cpp:330] Iteration 105500, Testing net (#0)
I1211 08:50:26.460824 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:50:27.971921 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:50:28.032922 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6829
I1211 08:50:28.032922 22260 solver.cpp:397]     Test net output #1: loss = 1.23271 (* 1 = 1.23271 loss)
I1211 08:50:28.092926 22260 solver.cpp:218] Iteration 105500 (12.6401 iter/s, 7.91132s/100 iters), loss = 0.344974
I1211 08:50:28.092926 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:50:28.092926 22260 solver.cpp:237]     Train net output #1: loss = 0.344974 (* 1 = 0.344974 loss)
I1211 08:50:28.092926 22260 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1211 08:50:34.424371 22260 solver.cpp:218] Iteration 105600 (15.7953 iter/s, 6.33101s/100 iters), loss = 0.384597
I1211 08:50:34.424371 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:50:34.424371 22260 solver.cpp:237]     Train net output #1: loss = 0.384597 (* 1 = 0.384597 loss)
I1211 08:50:34.424371 22260 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1211 08:50:40.761850 22260 solver.cpp:218] Iteration 105700 (15.7799 iter/s, 6.33716s/100 iters), loss = 0.274716
I1211 08:50:40.761850 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:50:40.761850 22260 solver.cpp:237]     Train net output #1: loss = 0.274716 (* 1 = 0.274716 loss)
I1211 08:50:40.761850 22260 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1211 08:50:47.090275 22260 solver.cpp:218] Iteration 105800 (15.804 iter/s, 6.32752s/100 iters), loss = 0.365561
I1211 08:50:47.090275 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:50:47.090275 22260 solver.cpp:237]     Train net output #1: loss = 0.365561 (* 1 = 0.365561 loss)
I1211 08:50:47.090275 22260 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1211 08:50:53.414726 22260 solver.cpp:218] Iteration 105900 (15.8128 iter/s, 6.32399s/100 iters), loss = 0.387755
I1211 08:50:53.414726 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:50:53.414726 22260 solver.cpp:237]     Train net output #1: loss = 0.387755 (* 1 = 0.387755 loss)
I1211 08:50:53.414726 22260 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1211 08:50:59.423180 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:50:59.672197 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106000.caffemodel
I1211 08:50:59.687197 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106000.solverstate
I1211 08:50:59.692198 22260 solver.cpp:330] Iteration 106000, Testing net (#0)
I1211 08:50:59.692198 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:51:01.204547 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:51:01.263551 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6807
I1211 08:51:01.264552 22260 solver.cpp:397]     Test net output #1: loss = 1.22471 (* 1 = 1.22471 loss)
I1211 08:51:01.324551 22260 solver.cpp:218] Iteration 106000 (12.6422 iter/s, 7.91s/100 iters), loss = 0.348697
I1211 08:51:01.324551 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:51:01.324551 22260 solver.cpp:237]     Train net output #1: loss = 0.348697 (* 1 = 0.348697 loss)
I1211 08:51:01.325552 22260 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1211 08:51:07.664016 22260 solver.cpp:218] Iteration 106100 (15.7774 iter/s, 6.33817s/100 iters), loss = 0.376033
I1211 08:51:07.664016 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:51:07.664016 22260 solver.cpp:237]     Train net output #1: loss = 0.376033 (* 1 = 0.376033 loss)
I1211 08:51:07.664016 22260 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1211 08:51:14.000475 22260 solver.cpp:218] Iteration 106200 (15.7807 iter/s, 6.33686s/100 iters), loss = 0.321696
I1211 08:51:14.000475 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:51:14.000475 22260 solver.cpp:237]     Train net output #1: loss = 0.321696 (* 1 = 0.321696 loss)
I1211 08:51:14.000475 22260 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1211 08:51:20.333914 22260 solver.cpp:218] Iteration 106300 (15.7911 iter/s, 6.3327s/100 iters), loss = 0.377646
I1211 08:51:20.333914 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:51:20.333914 22260 solver.cpp:237]     Train net output #1: loss = 0.377646 (* 1 = 0.377646 loss)
I1211 08:51:20.333914 22260 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1211 08:51:26.672430 22260 solver.cpp:218] Iteration 106400 (15.7778 iter/s, 6.33803s/100 iters), loss = 0.336952
I1211 08:51:26.672430 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 08:51:26.672430 22260 solver.cpp:237]     Train net output #1: loss = 0.336952 (* 1 = 0.336952 loss)
I1211 08:51:26.672430 22260 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1211 08:51:32.691853 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:51:32.941864 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106500.caffemodel
I1211 08:51:32.957868 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_106500.solverstate
I1211 08:51:32.962369 22260 solver.cpp:330] Iteration 106500, Testing net (#0)
I1211 08:51:32.962369 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:51:34.472995 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:51:34.532984 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6805
I1211 08:51:34.532984 22260 solver.cpp:397]     Test net output #1: loss = 1.2423 (* 1 = 1.2423 loss)
I1211 08:51:34.594000 22260 solver.cpp:218] Iteration 106500 (12.625 iter/s, 7.92081s/100 iters), loss = 0.305031
I1211 08:51:34.594000 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:51:34.594000 22260 solver.cpp:237]     Train net output #1: loss = 0.305031 (* 1 = 0.305031 loss)
I1211 08:51:34.594000 22260 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1211 08:51:40.905464 22260 solver.cpp:218] Iteration 106600 (15.8447 iter/s, 6.31124s/100 iters), loss = 0.396103
I1211 08:51:40.905464 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:51:40.905464 22260 solver.cpp:237]     Train net output #1: loss = 0.396103 (* 1 = 0.396103 loss)
I1211 08:51:40.905464 22260 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1211 08:51:47.214967 22260 solver.cpp:218] Iteration 106700 (15.8493 iter/s, 6.30944s/100 iters), loss = 0.310815
I1211 08:51:47.214967 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:51:47.214967 22260 solver.cpp:237]     Train net output #1: loss = 0.310815 (* 1 = 0.310815 loss)
I1211 08:51:47.214967 22260 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1211 08:51:53.531416 22260 solver.cpp:218] Iteration 106800 (15.8344 iter/s, 6.31535s/100 iters), loss = 0.397403
I1211 08:51:53.531416 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:51:53.531416 22260 solver.cpp:237]     Train net output #1: loss = 0.397403 (* 1 = 0.397403 loss)
I1211 08:51:53.531416 22260 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1211 08:51:59.852953 22260 solver.cpp:218] Iteration 106900 (15.8192 iter/s, 6.32144s/100 iters), loss = 0.410017
I1211 08:51:59.852953 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:51:59.852953 22260 solver.cpp:237]     Train net output #1: loss = 0.410017 (* 1 = 0.410017 loss)
I1211 08:51:59.852953 22260 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1211 08:52:05.852890 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:52:06.101415 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107000.caffemodel
I1211 08:52:06.116415 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107000.solverstate
I1211 08:52:06.120416 22260 solver.cpp:330] Iteration 107000, Testing net (#0)
I1211 08:52:06.120416 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:52:07.631515 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:52:07.691527 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6789
I1211 08:52:07.691527 22260 solver.cpp:397]     Test net output #1: loss = 1.23853 (* 1 = 1.23853 loss)
I1211 08:52:07.752521 22260 solver.cpp:218] Iteration 107000 (12.6601 iter/s, 7.89885s/100 iters), loss = 0.412314
I1211 08:52:07.752521 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:52:07.752521 22260 solver.cpp:237]     Train net output #1: loss = 0.412314 (* 1 = 0.412314 loss)
I1211 08:52:07.752521 22260 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1211 08:52:14.085013 22260 solver.cpp:218] Iteration 107100 (15.7926 iter/s, 6.33208s/100 iters), loss = 0.321914
I1211 08:52:14.085013 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:52:14.085013 22260 solver.cpp:237]     Train net output #1: loss = 0.321914 (* 1 = 0.321914 loss)
I1211 08:52:14.085013 22260 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1211 08:52:20.405500 22260 solver.cpp:218] Iteration 107200 (15.8227 iter/s, 6.32002s/100 iters), loss = 0.237977
I1211 08:52:20.405500 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 08:52:20.405500 22260 solver.cpp:237]     Train net output #1: loss = 0.237977 (* 1 = 0.237977 loss)
I1211 08:52:20.405500 22260 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1211 08:52:26.730984 22260 solver.cpp:218] Iteration 107300 (15.8091 iter/s, 6.32547s/100 iters), loss = 0.337849
I1211 08:52:26.730984 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:52:26.730984 22260 solver.cpp:237]     Train net output #1: loss = 0.337849 (* 1 = 0.337849 loss)
I1211 08:52:26.730984 22260 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1211 08:52:33.064898 22260 solver.cpp:218] Iteration 107400 (15.7898 iter/s, 6.33319s/100 iters), loss = 0.347478
I1211 08:52:33.065398 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:52:33.065398 22260 solver.cpp:237]     Train net output #1: loss = 0.347478 (* 1 = 0.347478 loss)
I1211 08:52:33.065398 22260 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1211 08:52:39.071846 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:52:39.320858 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107500.caffemodel
I1211 08:52:39.335857 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_107500.solverstate
I1211 08:52:39.339857 22260 solver.cpp:330] Iteration 107500, Testing net (#0)
I1211 08:52:39.339857 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:52:40.851953 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:52:40.912969 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6784
I1211 08:52:40.912969 22260 solver.cpp:397]     Test net output #1: loss = 1.24472 (* 1 = 1.24472 loss)
I1211 08:52:40.972965 22260 solver.cpp:218] Iteration 107500 (12.6456 iter/s, 7.9079s/100 iters), loss = 0.377435
I1211 08:52:40.972965 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:52:40.972965 22260 solver.cpp:237]     Train net output #1: loss = 0.377435 (* 1 = 0.377435 loss)
I1211 08:52:40.972965 22260 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1211 08:52:47.300369 22260 solver.cpp:218] Iteration 107600 (15.8067 iter/s, 6.32645s/100 iters), loss = 0.339387
I1211 08:52:47.300369 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:52:47.300369 22260 solver.cpp:237]     Train net output #1: loss = 0.339388 (* 1 = 0.339388 loss)
I1211 08:52:47.300369 22260 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1211 08:52:53.623818 22260 solver.cpp:218] Iteration 107700 (15.815 iter/s, 6.32313s/100 iters), loss = 0.302362
I1211 08:52:53.623818 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:52:53.623818 22260 solver.cpp:237]     Train net output #1: loss = 0.302362 (* 1 = 0.302362 loss)
I1211 08:52:53.623818 22260 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1211 08:52:59.945276 22260 solver.cpp:218] Iteration 107800 (15.8196 iter/s, 6.32127s/100 iters), loss = 0.402559
I1211 08:52:59.945276 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:52:59.945276 22260 solver.cpp:237]     Train net output #1: loss = 0.402559 (* 1 = 0.402559 loss)
I1211 08:52:59.945276 22260 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1211 08:53:06.276618 22260 solver.cpp:218] Iteration 107900 (15.7957 iter/s, 6.33085s/100 iters), loss = 0.35945
I1211 08:53:06.276618 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:53:06.276618 22260 solver.cpp:237]     Train net output #1: loss = 0.35945 (* 1 = 0.35945 loss)
I1211 08:53:06.276618 22260 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1211 08:53:12.295022 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:53:12.546033 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108000.caffemodel
I1211 08:53:12.562036 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108000.solverstate
I1211 08:53:12.566037 22260 solver.cpp:330] Iteration 108000, Testing net (#0)
I1211 08:53:12.566037 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:53:14.078223 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:53:14.138224 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6825
I1211 08:53:14.138224 22260 solver.cpp:397]     Test net output #1: loss = 1.24439 (* 1 = 1.24439 loss)
I1211 08:53:14.198226 22260 solver.cpp:218] Iteration 108000 (12.624 iter/s, 7.92139s/100 iters), loss = 0.335522
I1211 08:53:14.198226 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:53:14.198226 22260 solver.cpp:237]     Train net output #1: loss = 0.335522 (* 1 = 0.335522 loss)
I1211 08:53:14.198226 22260 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1211 08:53:20.516785 22260 solver.cpp:218] Iteration 108100 (15.8277 iter/s, 6.31802s/100 iters), loss = 0.38027
I1211 08:53:20.516785 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:53:20.516785 22260 solver.cpp:237]     Train net output #1: loss = 0.38027 (* 1 = 0.38027 loss)
I1211 08:53:20.516785 22260 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1211 08:53:26.835319 22260 solver.cpp:218] Iteration 108200 (15.8266 iter/s, 6.31848s/100 iters), loss = 0.288981
I1211 08:53:26.835319 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:53:26.835319 22260 solver.cpp:237]     Train net output #1: loss = 0.288981 (* 1 = 0.288981 loss)
I1211 08:53:26.836320 22260 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1211 08:53:33.158354 22260 solver.cpp:218] Iteration 108300 (15.8174 iter/s, 6.32215s/100 iters), loss = 0.300445
I1211 08:53:33.158854 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:53:33.158854 22260 solver.cpp:237]     Train net output #1: loss = 0.300445 (* 1 = 0.300445 loss)
I1211 08:53:33.158854 22260 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1211 08:53:39.488330 22260 solver.cpp:218] Iteration 108400 (15.7996 iter/s, 6.32926s/100 iters), loss = 0.383407
I1211 08:53:39.488330 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:53:39.488330 22260 solver.cpp:237]     Train net output #1: loss = 0.383408 (* 1 = 0.383408 loss)
I1211 08:53:39.488330 22260 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1211 08:53:45.493719 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:53:45.741729 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108500.caffemodel
I1211 08:53:45.756731 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_108500.solverstate
I1211 08:53:45.761235 22260 solver.cpp:330] Iteration 108500, Testing net (#0)
I1211 08:53:45.761735 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:53:47.275894 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:53:47.335893 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6783
I1211 08:53:47.335893 22260 solver.cpp:397]     Test net output #1: loss = 1.24378 (* 1 = 1.24378 loss)
I1211 08:53:47.396898 22260 solver.cpp:218] Iteration 108500 (12.6449 iter/s, 7.90832s/100 iters), loss = 0.271542
I1211 08:53:47.396898 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:53:47.396898 22260 solver.cpp:237]     Train net output #1: loss = 0.271543 (* 1 = 0.271543 loss)
I1211 08:53:47.396898 22260 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1211 08:53:53.718374 22260 solver.cpp:218] Iteration 108600 (15.8198 iter/s, 6.32119s/100 iters), loss = 0.37791
I1211 08:53:53.718374 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:53:53.718374 22260 solver.cpp:237]     Train net output #1: loss = 0.37791 (* 1 = 0.37791 loss)
I1211 08:53:53.718374 22260 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1211 08:54:00.040937 22260 solver.cpp:218] Iteration 108700 (15.817 iter/s, 6.32231s/100 iters), loss = 0.240944
I1211 08:54:00.040937 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:54:00.040937 22260 solver.cpp:237]     Train net output #1: loss = 0.240944 (* 1 = 0.240944 loss)
I1211 08:54:00.040937 22260 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1211 08:54:06.363939 22260 solver.cpp:218] Iteration 108800 (15.817 iter/s, 6.32232s/100 iters), loss = 0.290413
I1211 08:54:06.363939 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:54:06.363939 22260 solver.cpp:237]     Train net output #1: loss = 0.290413 (* 1 = 0.290413 loss)
I1211 08:54:06.363939 22260 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1211 08:54:12.687927 22260 solver.cpp:218] Iteration 108900 (15.814 iter/s, 6.32351s/100 iters), loss = 0.342148
I1211 08:54:12.687927 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:54:12.687927 22260 solver.cpp:237]     Train net output #1: loss = 0.342148 (* 1 = 0.342148 loss)
I1211 08:54:12.687927 22260 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1211 08:54:18.703379 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:54:18.951387 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109000.caffemodel
I1211 08:54:18.966892 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109000.solverstate
I1211 08:54:18.971395 22260 solver.cpp:330] Iteration 109000, Testing net (#0)
I1211 08:54:18.971395 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:54:20.481537 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:54:20.540536 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6788
I1211 08:54:20.540536 22260 solver.cpp:397]     Test net output #1: loss = 1.25046 (* 1 = 1.25046 loss)
I1211 08:54:20.601544 22260 solver.cpp:218] Iteration 109000 (12.6369 iter/s, 7.91334s/100 iters), loss = 0.308995
I1211 08:54:20.601544 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:54:20.601544 22260 solver.cpp:237]     Train net output #1: loss = 0.308995 (* 1 = 0.308995 loss)
I1211 08:54:20.601544 22260 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1211 08:54:26.926955 22260 solver.cpp:218] Iteration 109100 (15.8112 iter/s, 6.32462s/100 iters), loss = 0.357026
I1211 08:54:26.926955 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:54:26.926955 22260 solver.cpp:237]     Train net output #1: loss = 0.357026 (* 1 = 0.357026 loss)
I1211 08:54:26.926955 22260 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1211 08:54:33.250422 22260 solver.cpp:218] Iteration 109200 (15.8135 iter/s, 6.32369s/100 iters), loss = 0.253097
I1211 08:54:33.250422 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 08:54:33.250422 22260 solver.cpp:237]     Train net output #1: loss = 0.253098 (* 1 = 0.253098 loss)
I1211 08:54:33.250422 22260 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1211 08:54:39.579864 22260 solver.cpp:218] Iteration 109300 (15.8013 iter/s, 6.32859s/100 iters), loss = 0.351185
I1211 08:54:39.579864 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:54:39.579864 22260 solver.cpp:237]     Train net output #1: loss = 0.351185 (* 1 = 0.351185 loss)
I1211 08:54:39.579864 22260 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1211 08:54:45.899302 22260 solver.cpp:218] Iteration 109400 (15.824 iter/s, 6.3195s/100 iters), loss = 0.393254
I1211 08:54:45.899302 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:54:45.899302 22260 solver.cpp:237]     Train net output #1: loss = 0.393254 (* 1 = 0.393254 loss)
I1211 08:54:45.899302 22260 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1211 08:54:51.911752 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:54:52.160768 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109500.caffemodel
I1211 08:54:52.176770 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_109500.solverstate
I1211 08:54:52.180770 22260 solver.cpp:330] Iteration 109500, Testing net (#0)
I1211 08:54:52.180770 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:54:53.693876 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:54:53.753379 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6782
I1211 08:54:53.753379 22260 solver.cpp:397]     Test net output #1: loss = 1.25058 (* 1 = 1.25058 loss)
I1211 08:54:53.813881 22260 solver.cpp:218] Iteration 109500 (12.6359 iter/s, 7.91394s/100 iters), loss = 0.324142
I1211 08:54:53.813881 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:54:53.813881 22260 solver.cpp:237]     Train net output #1: loss = 0.324142 (* 1 = 0.324142 loss)
I1211 08:54:53.813881 22260 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1211 08:55:00.140349 22260 solver.cpp:218] Iteration 109600 (15.808 iter/s, 6.32592s/100 iters), loss = 0.343032
I1211 08:55:00.140349 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:55:00.140349 22260 solver.cpp:237]     Train net output #1: loss = 0.343032 (* 1 = 0.343032 loss)
I1211 08:55:00.140349 22260 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1211 08:55:06.471838 22260 solver.cpp:218] Iteration 109700 (15.7941 iter/s, 6.33149s/100 iters), loss = 0.303618
I1211 08:55:06.471838 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:55:06.472839 22260 solver.cpp:237]     Train net output #1: loss = 0.303618 (* 1 = 0.303618 loss)
I1211 08:55:06.472839 22260 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1211 08:55:12.806287 22260 solver.cpp:218] Iteration 109800 (15.7886 iter/s, 6.33368s/100 iters), loss = 0.376052
I1211 08:55:12.806287 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 08:55:12.806287 22260 solver.cpp:237]     Train net output #1: loss = 0.376053 (* 1 = 0.376053 loss)
I1211 08:55:12.806287 22260 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1211 08:55:19.134745 22260 solver.cpp:218] Iteration 109900 (15.8018 iter/s, 6.32838s/100 iters), loss = 0.348309
I1211 08:55:19.134745 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:55:19.134745 22260 solver.cpp:237]     Train net output #1: loss = 0.348309 (* 1 = 0.348309 loss)
I1211 08:55:19.134745 22260 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1211 08:55:25.154202 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:55:25.403232 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_110000.caffemodel
I1211 08:55:25.418232 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_110000.solverstate
I1211 08:55:25.422232 22260 solver.cpp:330] Iteration 110000, Testing net (#0)
I1211 08:55:25.423233 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:55:26.934329 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:55:26.994348 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6821
I1211 08:55:26.994348 22260 solver.cpp:397]     Test net output #1: loss = 1.25161 (* 1 = 1.25161 loss)
I1211 08:55:27.054347 22260 solver.cpp:218] Iteration 110000 (12.6276 iter/s, 7.91916s/100 iters), loss = 0.342773
I1211 08:55:27.055347 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:55:27.055347 22260 solver.cpp:237]     Train net output #1: loss = 0.342773 (* 1 = 0.342773 loss)
I1211 08:55:27.055347 22260 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1211 08:55:33.373792 22260 solver.cpp:218] Iteration 110100 (15.8267 iter/s, 6.31843s/100 iters), loss = 0.328542
I1211 08:55:33.373792 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:55:33.373792 22260 solver.cpp:237]     Train net output #1: loss = 0.328542 (* 1 = 0.328542 loss)
I1211 08:55:33.373792 22260 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1211 08:55:39.689242 22260 solver.cpp:218] Iteration 110200 (15.8348 iter/s, 6.3152s/100 iters), loss = 0.259052
I1211 08:55:39.689242 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:55:39.689242 22260 solver.cpp:237]     Train net output #1: loss = 0.259052 (* 1 = 0.259052 loss)
I1211 08:55:39.689242 22260 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1211 08:55:46.008682 22260 solver.cpp:218] Iteration 110300 (15.8263 iter/s, 6.31858s/100 iters), loss = 0.369239
I1211 08:55:46.008682 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:55:46.008682 22260 solver.cpp:237]     Train net output #1: loss = 0.369239 (* 1 = 0.369239 loss)
I1211 08:55:46.008682 22260 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1211 08:55:52.329079 22260 solver.cpp:218] Iteration 110400 (15.821 iter/s, 6.3207s/100 iters), loss = 0.321151
I1211 08:55:52.329079 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:55:52.329079 22260 solver.cpp:237]     Train net output #1: loss = 0.321152 (* 1 = 0.321152 loss)
I1211 08:55:52.329079 22260 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1211 08:55:58.343468 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:55:58.592818 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_110500.caffemodel
I1211 08:55:58.607818 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_110500.solverstate
I1211 08:55:58.612819 22260 solver.cpp:330] Iteration 110500, Testing net (#0)
I1211 08:55:58.612819 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:56:00.125371 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:56:00.185380 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6821
I1211 08:56:00.185380 22260 solver.cpp:397]     Test net output #1: loss = 1.25069 (* 1 = 1.25069 loss)
I1211 08:56:00.245878 22260 solver.cpp:218] Iteration 110500 (12.6326 iter/s, 7.916s/100 iters), loss = 0.312243
I1211 08:56:00.246379 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:56:00.246379 22260 solver.cpp:237]     Train net output #1: loss = 0.312243 (* 1 = 0.312243 loss)
I1211 08:56:00.246379 22260 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1211 08:56:06.568446 22260 solver.cpp:218] Iteration 110600 (15.8168 iter/s, 6.32239s/100 iters), loss = 0.348795
I1211 08:56:06.568446 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:56:06.568446 22260 solver.cpp:237]     Train net output #1: loss = 0.348795 (* 1 = 0.348795 loss)
I1211 08:56:06.568446 22260 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1211 08:56:12.893857 22260 solver.cpp:218] Iteration 110700 (15.8119 iter/s, 6.32435s/100 iters), loss = 0.253288
I1211 08:56:12.893857 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:56:12.893857 22260 solver.cpp:237]     Train net output #1: loss = 0.253288 (* 1 = 0.253288 loss)
I1211 08:56:12.893857 22260 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1211 08:56:19.211318 22260 solver.cpp:218] Iteration 110800 (15.8288 iter/s, 6.31759s/100 iters), loss = 0.324451
I1211 08:56:19.211318 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:56:19.211318 22260 solver.cpp:237]     Train net output #1: loss = 0.324451 (* 1 = 0.324451 loss)
I1211 08:56:19.211318 22260 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1211 08:56:25.534705 22260 solver.cpp:218] Iteration 110900 (15.8164 iter/s, 6.32257s/100 iters), loss = 0.334356
I1211 08:56:25.534705 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:56:25.534705 22260 solver.cpp:237]     Train net output #1: loss = 0.334356 (* 1 = 0.334356 loss)
I1211 08:56:25.534705 22260 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1211 08:56:31.543123 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:56:31.792135 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_111000.caffemodel
I1211 08:56:31.807137 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_111000.solverstate
I1211 08:56:31.812134 22260 solver.cpp:330] Iteration 111000, Testing net (#0)
I1211 08:56:31.812134 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:56:33.324726 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:56:33.384228 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1211 08:56:33.384228 22260 solver.cpp:397]     Test net output #1: loss = 1.25899 (* 1 = 1.25899 loss)
I1211 08:56:33.445231 22260 solver.cpp:218] Iteration 111000 (12.6424 iter/s, 7.90987s/100 iters), loss = 0.313754
I1211 08:56:33.445231 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:56:33.445231 22260 solver.cpp:237]     Train net output #1: loss = 0.313755 (* 1 = 0.313755 loss)
I1211 08:56:33.445231 22260 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1211 08:56:39.773624 22260 solver.cpp:218] Iteration 111100 (15.8026 iter/s, 6.32807s/100 iters), loss = 0.352228
I1211 08:56:39.773624 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:56:39.773624 22260 solver.cpp:237]     Train net output #1: loss = 0.352228 (* 1 = 0.352228 loss)
I1211 08:56:39.773624 22260 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1211 08:56:46.100005 22260 solver.cpp:218] Iteration 111200 (15.8066 iter/s, 6.32647s/100 iters), loss = 0.323588
I1211 08:56:46.100005 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:56:46.100005 22260 solver.cpp:237]     Train net output #1: loss = 0.323588 (* 1 = 0.323588 loss)
I1211 08:56:46.100005 22260 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1211 08:56:52.420462 22260 solver.cpp:218] Iteration 111300 (15.8236 iter/s, 6.31969s/100 iters), loss = 0.328386
I1211 08:56:52.420462 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:56:52.420462 22260 solver.cpp:237]     Train net output #1: loss = 0.328386 (* 1 = 0.328386 loss)
I1211 08:56:52.420462 22260 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1211 08:56:58.740412 22260 solver.cpp:218] Iteration 111400 (15.8244 iter/s, 6.31936s/100 iters), loss = 0.407951
I1211 08:56:58.740412 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 08:56:58.740412 22260 solver.cpp:237]     Train net output #1: loss = 0.407951 (* 1 = 0.407951 loss)
I1211 08:56:58.740412 22260 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1211 08:57:04.753347 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:57:05.002357 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_111500.caffemodel
I1211 08:57:05.018357 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_111500.solverstate
I1211 08:57:05.023357 22260 solver.cpp:330] Iteration 111500, Testing net (#0)
I1211 08:57:05.023357 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:57:06.535454 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:57:06.595465 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6762
I1211 08:57:06.595465 22260 solver.cpp:397]     Test net output #1: loss = 1.26671 (* 1 = 1.26671 loss)
I1211 08:57:06.655460 22260 solver.cpp:218] Iteration 111500 (12.6338 iter/s, 7.91529s/100 iters), loss = 0.331209
I1211 08:57:06.655460 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:57:06.655460 22260 solver.cpp:237]     Train net output #1: loss = 0.331209 (* 1 = 0.331209 loss)
I1211 08:57:06.655460 22260 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1211 08:57:12.987944 22260 solver.cpp:218] Iteration 111600 (15.7937 iter/s, 6.33166s/100 iters), loss = 0.315446
I1211 08:57:12.987944 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:57:12.987944 22260 solver.cpp:237]     Train net output #1: loss = 0.315446 (* 1 = 0.315446 loss)
I1211 08:57:12.987944 22260 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1211 08:57:19.319449 22260 solver.cpp:218] Iteration 111700 (15.7961 iter/s, 6.33068s/100 iters), loss = 0.326727
I1211 08:57:19.319449 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:57:19.319449 22260 solver.cpp:237]     Train net output #1: loss = 0.326728 (* 1 = 0.326728 loss)
I1211 08:57:19.319449 22260 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1211 08:57:25.646960 22260 solver.cpp:218] Iteration 111800 (15.8043 iter/s, 6.32738s/100 iters), loss = 0.292146
I1211 08:57:25.646960 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:57:25.646960 22260 solver.cpp:237]     Train net output #1: loss = 0.292146 (* 1 = 0.292146 loss)
I1211 08:57:25.646960 22260 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1211 08:57:31.965502 22260 solver.cpp:218] Iteration 111900 (15.8278 iter/s, 6.31801s/100 iters), loss = 0.440215
I1211 08:57:31.965502 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:57:31.965502 22260 solver.cpp:237]     Train net output #1: loss = 0.440216 (* 1 = 0.440216 loss)
I1211 08:57:31.965502 22260 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1211 08:57:37.980998 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:57:38.229013 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_112000.caffemodel
I1211 08:57:38.244516 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_112000.solverstate
I1211 08:57:38.249020 22260 solver.cpp:330] Iteration 112000, Testing net (#0)
I1211 08:57:38.249020 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:57:39.761113 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:57:39.821108 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6775
I1211 08:57:39.821108 22260 solver.cpp:397]     Test net output #1: loss = 1.27071 (* 1 = 1.27071 loss)
I1211 08:57:39.882124 22260 solver.cpp:218] Iteration 112000 (12.6328 iter/s, 7.9159s/100 iters), loss = 0.320943
I1211 08:57:39.882124 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:57:39.882124 22260 solver.cpp:237]     Train net output #1: loss = 0.320943 (* 1 = 0.320943 loss)
I1211 08:57:39.882124 22260 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1211 08:57:46.206585 22260 solver.cpp:218] Iteration 112100 (15.8111 iter/s, 6.32469s/100 iters), loss = 0.309794
I1211 08:57:46.206585 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:57:46.206585 22260 solver.cpp:237]     Train net output #1: loss = 0.309794 (* 1 = 0.309794 loss)
I1211 08:57:46.206585 22260 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1211 08:57:52.519021 22260 solver.cpp:218] Iteration 112200 (15.8429 iter/s, 6.31198s/100 iters), loss = 0.256115
I1211 08:57:52.519021 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 08:57:52.519021 22260 solver.cpp:237]     Train net output #1: loss = 0.256115 (* 1 = 0.256115 loss)
I1211 08:57:52.519021 22260 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1211 08:57:58.834468 22260 solver.cpp:218] Iteration 112300 (15.8367 iter/s, 6.31444s/100 iters), loss = 0.395764
I1211 08:57:58.834468 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 08:57:58.834468 22260 solver.cpp:237]     Train net output #1: loss = 0.395764 (* 1 = 0.395764 loss)
I1211 08:57:58.834468 22260 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1211 08:58:05.149925 22260 solver.cpp:218] Iteration 112400 (15.8342 iter/s, 6.31544s/100 iters), loss = 0.323718
I1211 08:58:05.149925 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:58:05.149925 22260 solver.cpp:237]     Train net output #1: loss = 0.323718 (* 1 = 0.323718 loss)
I1211 08:58:05.149925 22260 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1211 08:58:11.159386 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:58:11.407397 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_112500.caffemodel
I1211 08:58:11.422396 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_112500.solverstate
I1211 08:58:11.427397 22260 solver.cpp:330] Iteration 112500, Testing net (#0)
I1211 08:58:11.427397 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:58:12.940533 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:58:13.000524 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6802
I1211 08:58:13.000524 22260 solver.cpp:397]     Test net output #1: loss = 1.26449 (* 1 = 1.26449 loss)
I1211 08:58:13.061535 22260 solver.cpp:218] Iteration 112500 (12.6408 iter/s, 7.91086s/100 iters), loss = 0.296999
I1211 08:58:13.061535 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:58:13.061535 22260 solver.cpp:237]     Train net output #1: loss = 0.296999 (* 1 = 0.296999 loss)
I1211 08:58:13.061535 22260 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1211 08:58:19.391033 22260 solver.cpp:218] Iteration 112600 (15.7999 iter/s, 6.32915s/100 iters), loss = 0.308675
I1211 08:58:19.391033 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:58:19.391033 22260 solver.cpp:237]     Train net output #1: loss = 0.308676 (* 1 = 0.308676 loss)
I1211 08:58:19.391033 22260 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1211 08:58:25.715628 22260 solver.cpp:218] Iteration 112700 (15.8125 iter/s, 6.3241s/100 iters), loss = 0.311004
I1211 08:58:25.715628 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 08:58:25.715628 22260 solver.cpp:237]     Train net output #1: loss = 0.311004 (* 1 = 0.311004 loss)
I1211 08:58:25.715628 22260 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1211 08:58:32.044602 22260 solver.cpp:218] Iteration 112800 (15.8018 iter/s, 6.32838s/100 iters), loss = 0.341386
I1211 08:58:32.044602 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 08:58:32.044602 22260 solver.cpp:237]     Train net output #1: loss = 0.341386 (* 1 = 0.341386 loss)
I1211 08:58:32.044602 22260 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1211 08:58:38.364511 22260 solver.cpp:218] Iteration 112900 (15.8233 iter/s, 6.3198s/100 iters), loss = 0.272745
I1211 08:58:38.364511 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 08:58:38.364511 22260 solver.cpp:237]     Train net output #1: loss = 0.272745 (* 1 = 0.272745 loss)
I1211 08:58:38.364511 22260 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1211 08:58:44.383934 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:58:44.632943 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_113000.caffemodel
I1211 08:58:44.647948 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_113000.solverstate
I1211 08:58:44.652448 22260 solver.cpp:330] Iteration 113000, Testing net (#0)
I1211 08:58:44.652448 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:58:46.165066 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:58:46.225065 22260 solver.cpp:397]     Test net output #0: accuracy = 0.68
I1211 08:58:46.225065 22260 solver.cpp:397]     Test net output #1: loss = 1.26552 (* 1 = 1.26552 loss)
I1211 08:58:46.286074 22260 solver.cpp:218] Iteration 113000 (12.625 iter/s, 7.92078s/100 iters), loss = 0.262111
I1211 08:58:46.286074 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:58:46.286074 22260 solver.cpp:237]     Train net output #1: loss = 0.262111 (* 1 = 0.262111 loss)
I1211 08:58:46.286074 22260 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1211 08:58:52.622489 22260 solver.cpp:218] Iteration 113100 (15.7823 iter/s, 6.33622s/100 iters), loss = 0.336703
I1211 08:58:52.622489 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:58:52.622489 22260 solver.cpp:237]     Train net output #1: loss = 0.336703 (* 1 = 0.336703 loss)
I1211 08:58:52.622489 22260 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1211 08:58:58.962945 22260 solver.cpp:218] Iteration 113200 (15.7712 iter/s, 6.34067s/100 iters), loss = 0.258495
I1211 08:58:58.962945 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:58:58.962945 22260 solver.cpp:237]     Train net output #1: loss = 0.258496 (* 1 = 0.258496 loss)
I1211 08:58:58.962945 22260 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1211 08:59:05.298408 22260 solver.cpp:218] Iteration 113300 (15.786 iter/s, 6.33472s/100 iters), loss = 0.323114
I1211 08:59:05.298408 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:59:05.298408 22260 solver.cpp:237]     Train net output #1: loss = 0.323114 (* 1 = 0.323114 loss)
I1211 08:59:05.298408 22260 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1211 08:59:11.637881 22260 solver.cpp:218] Iteration 113400 (15.7761 iter/s, 6.33872s/100 iters), loss = 0.288372
I1211 08:59:11.637881 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:59:11.637881 22260 solver.cpp:237]     Train net output #1: loss = 0.288372 (* 1 = 0.288372 loss)
I1211 08:59:11.637881 22260 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1211 08:59:17.663358 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:59:17.912382 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_113500.caffemodel
I1211 08:59:17.928382 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_113500.solverstate
I1211 08:59:17.933383 22260 solver.cpp:330] Iteration 113500, Testing net (#0)
I1211 08:59:17.933383 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:59:19.447491 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:59:19.507491 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6791
I1211 08:59:19.507491 22260 solver.cpp:397]     Test net output #1: loss = 1.26598 (* 1 = 1.26598 loss)
I1211 08:59:19.568490 22260 solver.cpp:218] Iteration 113500 (12.6105 iter/s, 7.92989s/100 iters), loss = 0.325224
I1211 08:59:19.568490 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 08:59:19.568490 22260 solver.cpp:237]     Train net output #1: loss = 0.325225 (* 1 = 0.325225 loss)
I1211 08:59:19.568490 22260 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1211 08:59:25.897941 22260 solver.cpp:218] Iteration 113600 (15.7985 iter/s, 6.32971s/100 iters), loss = 0.288545
I1211 08:59:25.897941 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:59:25.897941 22260 solver.cpp:237]     Train net output #1: loss = 0.288545 (* 1 = 0.288545 loss)
I1211 08:59:25.897941 22260 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1211 08:59:32.241399 22260 solver.cpp:218] Iteration 113700 (15.7652 iter/s, 6.34307s/100 iters), loss = 0.268458
I1211 08:59:32.241399 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 08:59:32.242400 22260 solver.cpp:237]     Train net output #1: loss = 0.268458 (* 1 = 0.268458 loss)
I1211 08:59:32.242400 22260 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1211 08:59:38.577834 22260 solver.cpp:218] Iteration 113800 (15.7851 iter/s, 6.33509s/100 iters), loss = 0.332125
I1211 08:59:38.577834 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 08:59:38.577834 22260 solver.cpp:237]     Train net output #1: loss = 0.332125 (* 1 = 0.332125 loss)
I1211 08:59:38.577834 22260 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1211 08:59:44.902365 22260 solver.cpp:218] Iteration 113900 (15.8106 iter/s, 6.32487s/100 iters), loss = 0.266556
I1211 08:59:44.902365 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:59:44.902365 22260 solver.cpp:237]     Train net output #1: loss = 0.266556 (* 1 = 0.266556 loss)
I1211 08:59:44.902365 22260 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1211 08:59:50.922811 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:59:51.173810 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_114000.caffemodel
I1211 08:59:51.188815 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_114000.solverstate
I1211 08:59:51.193316 22260 solver.cpp:330] Iteration 114000, Testing net (#0)
I1211 08:59:51.193316 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 08:59:52.706933 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 08:59:52.766933 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6808
I1211 08:59:52.767932 22260 solver.cpp:397]     Test net output #1: loss = 1.26294 (* 1 = 1.26294 loss)
I1211 08:59:52.827936 22260 solver.cpp:218] Iteration 114000 (12.619 iter/s, 7.92458s/100 iters), loss = 0.251308
I1211 08:59:52.827936 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 08:59:52.827936 22260 solver.cpp:237]     Train net output #1: loss = 0.251309 (* 1 = 0.251309 loss)
I1211 08:59:52.827936 22260 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1211 08:59:59.153399 22260 solver.cpp:218] Iteration 114100 (15.8101 iter/s, 6.32509s/100 iters), loss = 0.273114
I1211 08:59:59.153399 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 08:59:59.153399 22260 solver.cpp:237]     Train net output #1: loss = 0.273114 (* 1 = 0.273114 loss)
I1211 08:59:59.153399 22260 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1211 09:00:05.472872 22260 solver.cpp:218] Iteration 114200 (15.825 iter/s, 6.31912s/100 iters), loss = 0.26616
I1211 09:00:05.472872 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:00:05.472872 22260 solver.cpp:237]     Train net output #1: loss = 0.26616 (* 1 = 0.26616 loss)
I1211 09:00:05.472872 22260 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1211 09:00:11.801426 22260 solver.cpp:218] Iteration 114300 (15.8021 iter/s, 6.32828s/100 iters), loss = 0.320118
I1211 09:00:11.801426 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:00:11.801426 22260 solver.cpp:237]     Train net output #1: loss = 0.320118 (* 1 = 0.320118 loss)
I1211 09:00:11.801426 22260 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1211 09:00:18.122828 22260 solver.cpp:218] Iteration 114400 (15.8207 iter/s, 6.32083s/100 iters), loss = 0.384738
I1211 09:00:18.122828 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:00:18.122828 22260 solver.cpp:237]     Train net output #1: loss = 0.384739 (* 1 = 0.384739 loss)
I1211 09:00:18.122828 22260 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1211 09:00:24.133296 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:00:24.382304 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_114500.caffemodel
I1211 09:00:24.397807 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_114500.solverstate
I1211 09:00:24.402312 22260 solver.cpp:330] Iteration 114500, Testing net (#0)
I1211 09:00:24.402312 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:00:25.918423 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:00:25.978423 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1211 09:00:25.978423 22260 solver.cpp:397]     Test net output #1: loss = 1.27369 (* 1 = 1.27369 loss)
I1211 09:00:26.038439 22260 solver.cpp:218] Iteration 114500 (12.6332 iter/s, 7.91567s/100 iters), loss = 0.275903
I1211 09:00:26.038439 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:00:26.038439 22260 solver.cpp:237]     Train net output #1: loss = 0.275903 (* 1 = 0.275903 loss)
I1211 09:00:26.038439 22260 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1211 09:00:32.364836 22260 solver.cpp:218] Iteration 114600 (15.81 iter/s, 6.32513s/100 iters), loss = 0.304265
I1211 09:00:32.364836 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:00:32.364836 22260 solver.cpp:237]     Train net output #1: loss = 0.304265 (* 1 = 0.304265 loss)
I1211 09:00:32.364836 22260 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1211 09:00:38.682260 22260 solver.cpp:218] Iteration 114700 (15.8298 iter/s, 6.31719s/100 iters), loss = 0.250099
I1211 09:00:38.682260 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:00:38.682260 22260 solver.cpp:237]     Train net output #1: loss = 0.250099 (* 1 = 0.250099 loss)
I1211 09:00:38.682260 22260 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1211 09:00:44.995736 22260 solver.cpp:218] Iteration 114800 (15.8398 iter/s, 6.31321s/100 iters), loss = 0.347219
I1211 09:00:44.995736 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:00:44.995736 22260 solver.cpp:237]     Train net output #1: loss = 0.347219 (* 1 = 0.347219 loss)
I1211 09:00:44.995736 22260 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1211 09:00:51.318234 22260 solver.cpp:218] Iteration 114900 (15.8177 iter/s, 6.32204s/100 iters), loss = 0.379672
I1211 09:00:51.318234 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 09:00:51.318234 22260 solver.cpp:237]     Train net output #1: loss = 0.379672 (* 1 = 0.379672 loss)
I1211 09:00:51.318234 22260 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1211 09:00:57.325747 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:00:57.574777 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_115000.caffemodel
I1211 09:00:57.589777 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_115000.solverstate
I1211 09:00:57.594779 22260 solver.cpp:330] Iteration 115000, Testing net (#0)
I1211 09:00:57.594779 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:00:59.108885 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:00:59.168889 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6774
I1211 09:00:59.168889 22260 solver.cpp:397]     Test net output #1: loss = 1.27658 (* 1 = 1.27658 loss)
I1211 09:00:59.228889 22260 solver.cpp:218] Iteration 115000 (12.6423 iter/s, 7.90995s/100 iters), loss = 0.291355
I1211 09:00:59.228889 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:00:59.228889 22260 solver.cpp:237]     Train net output #1: loss = 0.291355 (* 1 = 0.291355 loss)
I1211 09:00:59.228889 22260 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1211 09:01:05.543339 22260 solver.cpp:218] Iteration 115100 (15.8366 iter/s, 6.31448s/100 iters), loss = 0.289544
I1211 09:01:05.543339 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:01:05.543339 22260 solver.cpp:237]     Train net output #1: loss = 0.289544 (* 1 = 0.289544 loss)
I1211 09:01:05.543339 22260 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1211 09:01:11.856822 22260 solver.cpp:218] Iteration 115200 (15.8414 iter/s, 6.31258s/100 iters), loss = 0.277413
I1211 09:01:11.856822 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:01:11.856822 22260 solver.cpp:237]     Train net output #1: loss = 0.277413 (* 1 = 0.277413 loss)
I1211 09:01:11.856822 22260 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1211 09:01:18.177249 22260 solver.cpp:218] Iteration 115300 (15.8227 iter/s, 6.32003s/100 iters), loss = 0.411338
I1211 09:01:18.177249 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:01:18.177249 22260 solver.cpp:237]     Train net output #1: loss = 0.411338 (* 1 = 0.411338 loss)
I1211 09:01:18.177249 22260 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1211 09:01:24.491734 22260 solver.cpp:218] Iteration 115400 (15.8356 iter/s, 6.31487s/100 iters), loss = 0.313779
I1211 09:01:24.492734 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:01:24.492734 22260 solver.cpp:237]     Train net output #1: loss = 0.313779 (* 1 = 0.313779 loss)
I1211 09:01:24.492734 22260 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1211 09:01:30.505939 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:01:30.755100 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_115500.caffemodel
I1211 09:01:30.770099 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_115500.solverstate
I1211 09:01:30.774101 22260 solver.cpp:330] Iteration 115500, Testing net (#0)
I1211 09:01:30.774101 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:01:32.285396 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:01:32.345916 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6774
I1211 09:01:32.345916 22260 solver.cpp:397]     Test net output #1: loss = 1.28067 (* 1 = 1.28067 loss)
I1211 09:01:32.406432 22260 solver.cpp:218] Iteration 115500 (12.6366 iter/s, 7.9135s/100 iters), loss = 0.300224
I1211 09:01:32.406432 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:01:32.406432 22260 solver.cpp:237]     Train net output #1: loss = 0.300224 (* 1 = 0.300224 loss)
I1211 09:01:32.406432 22260 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1211 09:01:38.740751 22260 solver.cpp:218] Iteration 115600 (15.7884 iter/s, 6.33377s/100 iters), loss = 0.299248
I1211 09:01:38.740751 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:01:38.740751 22260 solver.cpp:237]     Train net output #1: loss = 0.299248 (* 1 = 0.299248 loss)
I1211 09:01:38.740751 22260 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1211 09:01:45.080162 22260 solver.cpp:218] Iteration 115700 (15.7741 iter/s, 6.33952s/100 iters), loss = 0.301053
I1211 09:01:45.080162 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:01:45.080162 22260 solver.cpp:237]     Train net output #1: loss = 0.301053 (* 1 = 0.301053 loss)
I1211 09:01:45.080162 22260 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1211 09:01:51.408592 22260 solver.cpp:218] Iteration 115800 (15.8022 iter/s, 6.32824s/100 iters), loss = 0.34379
I1211 09:01:51.408592 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:01:51.408592 22260 solver.cpp:237]     Train net output #1: loss = 0.34379 (* 1 = 0.34379 loss)
I1211 09:01:51.408592 22260 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1211 09:01:57.728549 22260 solver.cpp:218] Iteration 115900 (15.8261 iter/s, 6.31867s/100 iters), loss = 0.330363
I1211 09:01:57.728549 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:01:57.728549 22260 solver.cpp:237]     Train net output #1: loss = 0.330363 (* 1 = 0.330363 loss)
I1211 09:01:57.728549 22260 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1211 09:02:03.740428 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:02:03.989450 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_116000.caffemodel
I1211 09:02:04.004452 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_116000.solverstate
I1211 09:02:04.008452 22260 solver.cpp:330] Iteration 116000, Testing net (#0)
I1211 09:02:04.008452 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:02:05.523560 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:02:05.583573 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6802
I1211 09:02:05.583573 22260 solver.cpp:397]     Test net output #1: loss = 1.28165 (* 1 = 1.28165 loss)
I1211 09:02:05.644578 22260 solver.cpp:218] Iteration 116000 (12.6332 iter/s, 7.91565s/100 iters), loss = 0.275258
I1211 09:02:05.644578 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:02:05.644578 22260 solver.cpp:237]     Train net output #1: loss = 0.275258 (* 1 = 0.275258 loss)
I1211 09:02:05.644578 22260 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1211 09:02:11.974979 22260 solver.cpp:218] Iteration 116100 (15.7962 iter/s, 6.33064s/100 iters), loss = 0.305104
I1211 09:02:11.974979 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:02:11.974979 22260 solver.cpp:237]     Train net output #1: loss = 0.305104 (* 1 = 0.305104 loss)
I1211 09:02:11.974979 22260 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1211 09:02:18.305443 22260 solver.cpp:218] Iteration 116200 (15.7979 iter/s, 6.32995s/100 iters), loss = 0.249047
I1211 09:02:18.305443 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:02:18.305443 22260 solver.cpp:237]     Train net output #1: loss = 0.249047 (* 1 = 0.249047 loss)
I1211 09:02:18.305443 22260 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1211 09:02:24.635392 22260 solver.cpp:218] Iteration 116300 (15.7997 iter/s, 6.32925s/100 iters), loss = 0.340829
I1211 09:02:24.635392 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:02:24.635392 22260 solver.cpp:237]     Train net output #1: loss = 0.340829 (* 1 = 0.340829 loss)
I1211 09:02:24.635392 22260 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1211 09:02:30.975353 22260 solver.cpp:218] Iteration 116400 (15.7743 iter/s, 6.33942s/100 iters), loss = 0.355175
I1211 09:02:30.975353 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:02:30.975353 22260 solver.cpp:237]     Train net output #1: loss = 0.355175 (* 1 = 0.355175 loss)
I1211 09:02:30.975353 22260 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1211 09:02:36.998863 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:02:37.248891 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_116500.caffemodel
I1211 09:02:37.264891 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_116500.solverstate
I1211 09:02:37.268893 22260 solver.cpp:330] Iteration 116500, Testing net (#0)
I1211 09:02:37.268893 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:02:38.780999 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:02:38.841506 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6776
I1211 09:02:38.841506 22260 solver.cpp:397]     Test net output #1: loss = 1.2832 (* 1 = 1.2832 loss)
I1211 09:02:38.902009 22260 solver.cpp:218] Iteration 116500 (12.6161 iter/s, 7.92636s/100 iters), loss = 0.271041
I1211 09:02:38.902009 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:02:38.902009 22260 solver.cpp:237]     Train net output #1: loss = 0.271041 (* 1 = 0.271041 loss)
I1211 09:02:38.902009 22260 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1211 09:02:45.218473 22260 solver.cpp:218] Iteration 116600 (15.8323 iter/s, 6.3162s/100 iters), loss = 0.224592
I1211 09:02:45.218473 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:02:45.218473 22260 solver.cpp:237]     Train net output #1: loss = 0.224592 (* 1 = 0.224592 loss)
I1211 09:02:45.218473 22260 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1211 09:02:51.542928 22260 solver.cpp:218] Iteration 116700 (15.8142 iter/s, 6.32342s/100 iters), loss = 0.233999
I1211 09:02:51.542928 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:02:51.542928 22260 solver.cpp:237]     Train net output #1: loss = 0.233999 (* 1 = 0.233999 loss)
I1211 09:02:51.542928 22260 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1211 09:02:57.866432 22260 solver.cpp:218] Iteration 116800 (15.8151 iter/s, 6.32308s/100 iters), loss = 0.306465
I1211 09:02:57.866432 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:02:57.866432 22260 solver.cpp:237]     Train net output #1: loss = 0.306466 (* 1 = 0.306466 loss)
I1211 09:02:57.866432 22260 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1211 09:03:04.187842 22260 solver.cpp:218] Iteration 116900 (15.8193 iter/s, 6.32139s/100 iters), loss = 0.283514
I1211 09:03:04.187842 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:03:04.187842 22260 solver.cpp:237]     Train net output #1: loss = 0.283514 (* 1 = 0.283514 loss)
I1211 09:03:04.187842 22260 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1211 09:03:10.195127 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:03:10.445288 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_117000.caffemodel
I1211 09:03:10.459971 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_117000.solverstate
I1211 09:03:10.464970 22260 solver.cpp:330] Iteration 117000, Testing net (#0)
I1211 09:03:10.464970 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:03:11.977485 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:03:12.037530 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6784
I1211 09:03:12.037530 22260 solver.cpp:397]     Test net output #1: loss = 1.2842 (* 1 = 1.2842 loss)
I1211 09:03:12.097798 22260 solver.cpp:218] Iteration 117000 (12.643 iter/s, 7.90954s/100 iters), loss = 0.212267
I1211 09:03:12.097798 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:03:12.097798 22260 solver.cpp:237]     Train net output #1: loss = 0.212267 (* 1 = 0.212267 loss)
I1211 09:03:12.097798 22260 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1211 09:03:18.432708 22260 solver.cpp:218] Iteration 117100 (15.7875 iter/s, 6.33412s/100 iters), loss = 0.29358
I1211 09:03:18.432708 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:03:18.432708 22260 solver.cpp:237]     Train net output #1: loss = 0.29358 (* 1 = 0.29358 loss)
I1211 09:03:18.432708 22260 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1211 09:03:24.768162 22260 solver.cpp:218] Iteration 117200 (15.7834 iter/s, 6.33576s/100 iters), loss = 0.231873
I1211 09:03:24.768162 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:03:24.769161 22260 solver.cpp:237]     Train net output #1: loss = 0.231873 (* 1 = 0.231873 loss)
I1211 09:03:24.769161 22260 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1211 09:03:31.112574 22260 solver.cpp:218] Iteration 117300 (15.7646 iter/s, 6.34331s/100 iters), loss = 0.338318
I1211 09:03:31.112574 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:03:31.112574 22260 solver.cpp:237]     Train net output #1: loss = 0.338318 (* 1 = 0.338318 loss)
I1211 09:03:31.112574 22260 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1211 09:03:37.444506 22260 solver.cpp:218] Iteration 117400 (15.7936 iter/s, 6.33168s/100 iters), loss = 0.352294
I1211 09:03:37.444506 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:03:37.444506 22260 solver.cpp:237]     Train net output #1: loss = 0.352294 (* 1 = 0.352294 loss)
I1211 09:03:37.444506 22260 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1211 09:03:43.465494 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:03:43.716506 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_117500.caffemodel
I1211 09:03:43.732506 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_117500.solverstate
I1211 09:03:43.737507 22260 solver.cpp:330] Iteration 117500, Testing net (#0)
I1211 09:03:43.737507 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:03:45.251127 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:03:45.310627 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6761
I1211 09:03:45.310627 22260 solver.cpp:397]     Test net output #1: loss = 1.28829 (* 1 = 1.28829 loss)
I1211 09:03:45.370633 22260 solver.cpp:218] Iteration 117500 (12.6164 iter/s, 7.92621s/100 iters), loss = 0.293671
I1211 09:03:45.371634 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:03:45.371634 22260 solver.cpp:237]     Train net output #1: loss = 0.293671 (* 1 = 0.293671 loss)
I1211 09:03:45.371634 22260 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1211 09:03:51.709141 22260 solver.cpp:218] Iteration 117600 (15.7778 iter/s, 6.33803s/100 iters), loss = 0.33426
I1211 09:03:51.710140 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:03:51.710140 22260 solver.cpp:237]     Train net output #1: loss = 0.33426 (* 1 = 0.33426 loss)
I1211 09:03:51.710140 22260 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1211 09:03:58.049659 22260 solver.cpp:218] Iteration 117700 (15.7748 iter/s, 6.33921s/100 iters), loss = 0.254118
I1211 09:03:58.049659 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:03:58.049659 22260 solver.cpp:237]     Train net output #1: loss = 0.254119 (* 1 = 0.254119 loss)
I1211 09:03:58.049659 22260 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1211 09:04:04.392165 22260 solver.cpp:218] Iteration 117800 (15.7666 iter/s, 6.34254s/100 iters), loss = 0.27278
I1211 09:04:04.392165 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:04:04.392165 22260 solver.cpp:237]     Train net output #1: loss = 0.27278 (* 1 = 0.27278 loss)
I1211 09:04:04.392165 22260 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1211 09:04:10.722618 22260 solver.cpp:218] Iteration 117900 (15.7971 iter/s, 6.33026s/100 iters), loss = 0.298842
I1211 09:04:10.722618 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:04:10.722618 22260 solver.cpp:237]     Train net output #1: loss = 0.298842 (* 1 = 0.298842 loss)
I1211 09:04:10.722618 22260 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1211 09:04:16.755064 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:04:17.007086 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_118000.caffemodel
I1211 09:04:17.021085 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_118000.solverstate
I1211 09:04:17.026087 22260 solver.cpp:330] Iteration 118000, Testing net (#0)
I1211 09:04:17.026087 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:04:18.538182 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:04:18.598186 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6769
I1211 09:04:18.598186 22260 solver.cpp:397]     Test net output #1: loss = 1.28102 (* 1 = 1.28102 loss)
I1211 09:04:18.658186 22260 solver.cpp:218] Iteration 118000 (12.6027 iter/s, 7.93483s/100 iters), loss = 0.224892
I1211 09:04:18.658186 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:04:18.658186 22260 solver.cpp:237]     Train net output #1: loss = 0.224892 (* 1 = 0.224892 loss)
I1211 09:04:18.658186 22260 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1211 09:04:24.991725 22260 solver.cpp:218] Iteration 118100 (15.7904 iter/s, 6.33296s/100 iters), loss = 0.341383
I1211 09:04:24.991725 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:04:24.991725 22260 solver.cpp:237]     Train net output #1: loss = 0.341383 (* 1 = 0.341383 loss)
I1211 09:04:24.991725 22260 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1211 09:04:31.323226 22260 solver.cpp:218] Iteration 118200 (15.7938 iter/s, 6.33158s/100 iters), loss = 0.24747
I1211 09:04:31.323226 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:04:31.323226 22260 solver.cpp:237]     Train net output #1: loss = 0.24747 (* 1 = 0.24747 loss)
I1211 09:04:31.323226 22260 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1211 09:04:37.650750 22260 solver.cpp:218] Iteration 118300 (15.8046 iter/s, 6.32727s/100 iters), loss = 0.305907
I1211 09:04:37.651751 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:04:37.651751 22260 solver.cpp:237]     Train net output #1: loss = 0.305907 (* 1 = 0.305907 loss)
I1211 09:04:37.651751 22260 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1211 09:04:43.987282 22260 solver.cpp:218] Iteration 118400 (15.7847 iter/s, 6.33524s/100 iters), loss = 0.373348
I1211 09:04:43.987282 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:04:43.987282 22260 solver.cpp:237]     Train net output #1: loss = 0.373348 (* 1 = 0.373348 loss)
I1211 09:04:43.987282 22260 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1211 09:04:50.002372 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:04:50.251772 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_118500.caffemodel
I1211 09:04:50.268276 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_118500.solverstate
I1211 09:04:50.272274 22260 solver.cpp:330] Iteration 118500, Testing net (#0)
I1211 09:04:50.272775 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:04:51.792824 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:04:51.852818 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6744
I1211 09:04:51.852818 22260 solver.cpp:397]     Test net output #1: loss = 1.28746 (* 1 = 1.28746 loss)
I1211 09:04:51.913830 22260 solver.cpp:218] Iteration 118500 (12.6158 iter/s, 7.92654s/100 iters), loss = 0.303533
I1211 09:04:51.913830 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:04:51.913830 22260 solver.cpp:237]     Train net output #1: loss = 0.303533 (* 1 = 0.303533 loss)
I1211 09:04:51.913830 22260 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1211 09:04:58.241673 22260 solver.cpp:218] Iteration 118600 (15.8038 iter/s, 6.32758s/100 iters), loss = 0.282335
I1211 09:04:58.241673 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:04:58.241673 22260 solver.cpp:237]     Train net output #1: loss = 0.282335 (* 1 = 0.282335 loss)
I1211 09:04:58.241673 22260 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1211 09:05:04.577997 22260 solver.cpp:218] Iteration 118700 (15.7844 iter/s, 6.33537s/100 iters), loss = 0.243243
I1211 09:05:04.577997 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:05:04.577997 22260 solver.cpp:237]     Train net output #1: loss = 0.243243 (* 1 = 0.243243 loss)
I1211 09:05:04.577997 22260 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1211 09:05:10.910775 22260 solver.cpp:218] Iteration 118800 (15.7921 iter/s, 6.3323s/100 iters), loss = 0.304141
I1211 09:05:10.910775 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:05:10.910775 22260 solver.cpp:237]     Train net output #1: loss = 0.304141 (* 1 = 0.304141 loss)
I1211 09:05:10.910775 22260 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1211 09:05:17.236999 22260 solver.cpp:218] Iteration 118900 (15.8087 iter/s, 6.32561s/100 iters), loss = 0.298035
I1211 09:05:17.236999 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:05:17.236999 22260 solver.cpp:237]     Train net output #1: loss = 0.298036 (* 1 = 0.298036 loss)
I1211 09:05:17.236999 22260 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1211 09:05:23.244168 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:05:23.493973 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_119000.caffemodel
I1211 09:05:23.509968 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_119000.solverstate
I1211 09:05:23.513968 22260 solver.cpp:330] Iteration 119000, Testing net (#0)
I1211 09:05:23.513968 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:05:25.027459 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:05:25.088021 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6737
I1211 09:05:25.088021 22260 solver.cpp:397]     Test net output #1: loss = 1.29461 (* 1 = 1.29461 loss)
I1211 09:05:25.148558 22260 solver.cpp:218] Iteration 119000 (12.6404 iter/s, 7.91113s/100 iters), loss = 0.350892
I1211 09:05:25.148558 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:05:25.148558 22260 solver.cpp:237]     Train net output #1: loss = 0.350892 (* 1 = 0.350892 loss)
I1211 09:05:25.148558 22260 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1211 09:05:31.490156 22260 solver.cpp:218] Iteration 119100 (15.7693 iter/s, 6.34142s/100 iters), loss = 0.275243
I1211 09:05:31.490156 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:05:31.490156 22260 solver.cpp:237]     Train net output #1: loss = 0.275243 (* 1 = 0.275243 loss)
I1211 09:05:31.490156 22260 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1211 09:05:37.825651 22260 solver.cpp:218] Iteration 119200 (15.7857 iter/s, 6.33487s/100 iters), loss = 0.259343
I1211 09:05:37.825651 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:05:37.825651 22260 solver.cpp:237]     Train net output #1: loss = 0.259344 (* 1 = 0.259344 loss)
I1211 09:05:37.825651 22260 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1211 09:05:44.161159 22260 solver.cpp:218] Iteration 119300 (15.7837 iter/s, 6.33566s/100 iters), loss = 0.263467
I1211 09:05:44.161159 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:05:44.161159 22260 solver.cpp:237]     Train net output #1: loss = 0.263467 (* 1 = 0.263467 loss)
I1211 09:05:44.161159 22260 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1211 09:05:50.504631 22260 solver.cpp:218] Iteration 119400 (15.7664 iter/s, 6.34259s/100 iters), loss = 0.342267
I1211 09:05:50.504631 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:05:50.504631 22260 solver.cpp:237]     Train net output #1: loss = 0.342267 (* 1 = 0.342267 loss)
I1211 09:05:50.504631 22260 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1211 09:05:56.530284 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:05:56.779299 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_119500.caffemodel
I1211 09:05:56.794301 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_119500.solverstate
I1211 09:05:56.798300 22260 solver.cpp:330] Iteration 119500, Testing net (#0)
I1211 09:05:56.798300 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:05:58.311403 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:05:58.371407 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6734
I1211 09:05:58.371407 22260 solver.cpp:397]     Test net output #1: loss = 1.29412 (* 1 = 1.29412 loss)
I1211 09:05:58.432405 22260 solver.cpp:218] Iteration 119500 (12.6147 iter/s, 7.92729s/100 iters), loss = 0.199916
I1211 09:05:58.432405 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:05:58.432405 22260 solver.cpp:237]     Train net output #1: loss = 0.199916 (* 1 = 0.199916 loss)
I1211 09:05:58.432405 22260 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1211 09:06:04.766880 22260 solver.cpp:218] Iteration 119600 (15.7863 iter/s, 6.33459s/100 iters), loss = 0.337207
I1211 09:06:04.766880 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:06:04.766880 22260 solver.cpp:237]     Train net output #1: loss = 0.337207 (* 1 = 0.337207 loss)
I1211 09:06:04.766880 22260 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1211 09:06:11.093355 22260 solver.cpp:218] Iteration 119700 (15.8087 iter/s, 6.32564s/100 iters), loss = 0.266554
I1211 09:06:11.093355 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:06:11.093355 22260 solver.cpp:237]     Train net output #1: loss = 0.266554 (* 1 = 0.266554 loss)
I1211 09:06:11.093355 22260 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1211 09:06:17.430790 22260 solver.cpp:218] Iteration 119800 (15.7793 iter/s, 6.33742s/100 iters), loss = 0.307762
I1211 09:06:17.430790 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:06:17.430790 22260 solver.cpp:237]     Train net output #1: loss = 0.307762 (* 1 = 0.307762 loss)
I1211 09:06:17.430790 22260 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1211 09:06:23.764250 22260 solver.cpp:218] Iteration 119900 (15.7912 iter/s, 6.33264s/100 iters), loss = 0.396795
I1211 09:06:23.764250 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 09:06:23.764250 22260 solver.cpp:237]     Train net output #1: loss = 0.396795 (* 1 = 0.396795 loss)
I1211 09:06:23.764250 22260 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1211 09:06:29.788664 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:06:30.037688 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_120000.caffemodel
I1211 09:06:30.053692 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_120000.solverstate
I1211 09:06:30.057696 22260 solver.cpp:330] Iteration 120000, Testing net (#0)
I1211 09:06:30.057696 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:06:31.569813 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:06:31.630812 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6754
I1211 09:06:31.630812 22260 solver.cpp:397]     Test net output #1: loss = 1.3028 (* 1 = 1.3028 loss)
I1211 09:06:31.690817 22260 solver.cpp:218] Iteration 120000 (12.616 iter/s, 7.92645s/100 iters), loss = 0.329564
I1211 09:06:31.690817 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:06:31.690817 22260 solver.cpp:237]     Train net output #1: loss = 0.329564 (* 1 = 0.329564 loss)
I1211 09:06:31.690817 22260 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1211 09:06:38.011268 22260 solver.cpp:218] Iteration 120100 (15.8243 iter/s, 6.31938s/100 iters), loss = 0.261338
I1211 09:06:38.011268 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:06:38.011268 22260 solver.cpp:237]     Train net output #1: loss = 0.261338 (* 1 = 0.261338 loss)
I1211 09:06:38.011268 22260 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1211 09:06:44.340215 22260 solver.cpp:218] Iteration 120200 (15.8011 iter/s, 6.32869s/100 iters), loss = 0.236188
I1211 09:06:44.340215 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:06:44.340215 22260 solver.cpp:237]     Train net output #1: loss = 0.236188 (* 1 = 0.236188 loss)
I1211 09:06:44.340215 22260 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1211 09:06:50.668126 22260 solver.cpp:218] Iteration 120300 (15.8042 iter/s, 6.32744s/100 iters), loss = 0.370079
I1211 09:06:50.668126 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:06:50.668126 22260 solver.cpp:237]     Train net output #1: loss = 0.370079 (* 1 = 0.370079 loss)
I1211 09:06:50.668126 22260 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1211 09:06:56.989645 22260 solver.cpp:218] Iteration 120400 (15.8195 iter/s, 6.32131s/100 iters), loss = 0.283843
I1211 09:06:56.989645 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:06:56.989645 22260 solver.cpp:237]     Train net output #1: loss = 0.283843 (* 1 = 0.283843 loss)
I1211 09:06:56.989645 22260 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1211 09:07:03.004061 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:07:03.252080 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_120500.caffemodel
I1211 09:07:03.267081 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_120500.solverstate
I1211 09:07:03.271080 22260 solver.cpp:330] Iteration 120500, Testing net (#0)
I1211 09:07:03.271080 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:07:04.784195 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:07:04.844202 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6731
I1211 09:07:04.844202 22260 solver.cpp:397]     Test net output #1: loss = 1.30999 (* 1 = 1.30999 loss)
I1211 09:07:04.904201 22260 solver.cpp:218] Iteration 120500 (12.6362 iter/s, 7.91374s/100 iters), loss = 0.23216
I1211 09:07:04.904201 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:07:04.904201 22260 solver.cpp:237]     Train net output #1: loss = 0.23216 (* 1 = 0.23216 loss)
I1211 09:07:04.904201 22260 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1211 09:07:11.223213 22260 solver.cpp:218] Iteration 120600 (15.8254 iter/s, 6.31895s/100 iters), loss = 0.245088
I1211 09:07:11.223713 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:07:11.223713 22260 solver.cpp:237]     Train net output #1: loss = 0.245089 (* 1 = 0.245089 loss)
I1211 09:07:11.223713 22260 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1211 09:07:17.550210 22260 solver.cpp:218] Iteration 120700 (15.8051 iter/s, 6.32708s/100 iters), loss = 0.228348
I1211 09:07:17.551210 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:07:17.551210 22260 solver.cpp:237]     Train net output #1: loss = 0.228348 (* 1 = 0.228348 loss)
I1211 09:07:17.551210 22260 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1211 09:07:23.883399 22260 solver.cpp:218] Iteration 120800 (15.7931 iter/s, 6.33188s/100 iters), loss = 0.319878
I1211 09:07:23.883399 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:07:23.883399 22260 solver.cpp:237]     Train net output #1: loss = 0.319878 (* 1 = 0.319878 loss)
I1211 09:07:23.883399 22260 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1211 09:07:30.209798 22260 solver.cpp:218] Iteration 120900 (15.8081 iter/s, 6.32588s/100 iters), loss = 0.347845
I1211 09:07:30.209798 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:07:30.209798 22260 solver.cpp:237]     Train net output #1: loss = 0.347845 (* 1 = 0.347845 loss)
I1211 09:07:30.209798 22260 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1211 09:07:36.225244 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:07:36.474267 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_121000.caffemodel
I1211 09:07:36.489267 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_121000.solverstate
I1211 09:07:36.493268 22260 solver.cpp:330] Iteration 121000, Testing net (#0)
I1211 09:07:36.494268 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:07:38.007369 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:07:38.067375 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6765
I1211 09:07:38.067375 22260 solver.cpp:397]     Test net output #1: loss = 1.30534 (* 1 = 1.30534 loss)
I1211 09:07:38.127877 22260 solver.cpp:218] Iteration 121000 (12.6298 iter/s, 7.91778s/100 iters), loss = 0.349864
I1211 09:07:38.127877 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:07:38.127877 22260 solver.cpp:237]     Train net output #1: loss = 0.349865 (* 1 = 0.349865 loss)
I1211 09:07:38.127877 22260 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1211 09:07:44.449887 22260 solver.cpp:218] Iteration 121100 (15.8186 iter/s, 6.32168s/100 iters), loss = 0.274862
I1211 09:07:44.449887 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:07:44.449887 22260 solver.cpp:237]     Train net output #1: loss = 0.274862 (* 1 = 0.274862 loss)
I1211 09:07:44.449887 22260 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1211 09:07:50.772337 22260 solver.cpp:218] Iteration 121200 (15.8183 iter/s, 6.32179s/100 iters), loss = 0.264144
I1211 09:07:50.772337 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:07:50.772337 22260 solver.cpp:237]     Train net output #1: loss = 0.264145 (* 1 = 0.264145 loss)
I1211 09:07:50.772337 22260 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1211 09:07:57.081768 22260 solver.cpp:218] Iteration 121300 (15.8487 iter/s, 6.30967s/100 iters), loss = 0.290302
I1211 09:07:57.081768 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:07:57.081768 22260 solver.cpp:237]     Train net output #1: loss = 0.290302 (* 1 = 0.290302 loss)
I1211 09:07:57.081768 22260 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1211 09:08:03.399354 22260 solver.cpp:218] Iteration 121400 (15.8303 iter/s, 6.31699s/100 iters), loss = 0.376265
I1211 09:08:03.399354 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 09:08:03.399354 22260 solver.cpp:237]     Train net output #1: loss = 0.376265 (* 1 = 0.376265 loss)
I1211 09:08:03.399354 22260 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1211 09:08:09.412825 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:08:09.662854 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_121500.caffemodel
I1211 09:08:09.677855 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_121500.solverstate
I1211 09:08:09.681855 22260 solver.cpp:330] Iteration 121500, Testing net (#0)
I1211 09:08:09.681855 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:08:11.195968 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:08:11.254972 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6739
I1211 09:08:11.254972 22260 solver.cpp:397]     Test net output #1: loss = 1.30627 (* 1 = 1.30627 loss)
I1211 09:08:11.315973 22260 solver.cpp:218] Iteration 121500 (12.6322 iter/s, 7.91625s/100 iters), loss = 0.258213
I1211 09:08:11.315973 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:08:11.315973 22260 solver.cpp:237]     Train net output #1: loss = 0.258213 (* 1 = 0.258213 loss)
I1211 09:08:11.315973 22260 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1211 09:08:17.647421 22260 solver.cpp:218] Iteration 121600 (15.7949 iter/s, 6.33116s/100 iters), loss = 0.261219
I1211 09:08:17.647421 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:08:17.647421 22260 solver.cpp:237]     Train net output #1: loss = 0.261219 (* 1 = 0.261219 loss)
I1211 09:08:17.647421 22260 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1211 09:08:23.981868 22260 solver.cpp:218] Iteration 121700 (15.7876 iter/s, 6.33408s/100 iters), loss = 0.223009
I1211 09:08:23.981868 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:08:23.981868 22260 solver.cpp:237]     Train net output #1: loss = 0.223009 (* 1 = 0.223009 loss)
I1211 09:08:23.981868 22260 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1211 09:08:30.320291 22260 solver.cpp:218] Iteration 121800 (15.7782 iter/s, 6.33788s/100 iters), loss = 0.230736
I1211 09:08:30.320291 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:08:30.320291 22260 solver.cpp:237]     Train net output #1: loss = 0.230736 (* 1 = 0.230736 loss)
I1211 09:08:30.320291 22260 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1211 09:08:36.651759 22260 solver.cpp:218] Iteration 121900 (15.7951 iter/s, 6.33108s/100 iters), loss = 0.262957
I1211 09:08:36.651759 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:08:36.651759 22260 solver.cpp:237]     Train net output #1: loss = 0.262957 (* 1 = 0.262957 loss)
I1211 09:08:36.651759 22260 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1211 09:08:42.677218 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:08:42.926230 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_122000.caffemodel
I1211 09:08:42.943235 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_122000.solverstate
I1211 09:08:42.947736 22260 solver.cpp:330] Iteration 122000, Testing net (#0)
I1211 09:08:42.947736 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:08:44.460362 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:08:44.519361 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6766
I1211 09:08:44.519361 22260 solver.cpp:397]     Test net output #1: loss = 1.29952 (* 1 = 1.29952 loss)
I1211 09:08:44.580368 22260 solver.cpp:218] Iteration 122000 (12.6135 iter/s, 7.92803s/100 iters), loss = 0.277443
I1211 09:08:44.580368 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:08:44.580368 22260 solver.cpp:237]     Train net output #1: loss = 0.277443 (* 1 = 0.277443 loss)
I1211 09:08:44.580368 22260 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1211 09:08:50.912889 22260 solver.cpp:218] Iteration 122100 (15.7935 iter/s, 6.33173s/100 iters), loss = 0.305958
I1211 09:08:50.912889 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:08:50.912889 22260 solver.cpp:237]     Train net output #1: loss = 0.305958 (* 1 = 0.305958 loss)
I1211 09:08:50.912889 22260 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1211 09:08:57.242425 22260 solver.cpp:218] Iteration 122200 (15.8005 iter/s, 6.32891s/100 iters), loss = 0.254847
I1211 09:08:57.242425 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:08:57.242425 22260 solver.cpp:237]     Train net output #1: loss = 0.254847 (* 1 = 0.254847 loss)
I1211 09:08:57.242425 22260 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1211 09:09:03.567873 22260 solver.cpp:218] Iteration 122300 (15.8093 iter/s, 6.32538s/100 iters), loss = 0.361935
I1211 09:09:03.567873 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:09:03.567873 22260 solver.cpp:237]     Train net output #1: loss = 0.361935 (* 1 = 0.361935 loss)
I1211 09:09:03.567873 22260 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1211 09:09:09.893270 22260 solver.cpp:218] Iteration 122400 (15.8096 iter/s, 6.32527s/100 iters), loss = 0.326883
I1211 09:09:09.893270 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:09:09.893270 22260 solver.cpp:237]     Train net output #1: loss = 0.326883 (* 1 = 0.326883 loss)
I1211 09:09:09.893270 22260 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1211 09:09:15.914710 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:09:16.163725 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_122500.caffemodel
I1211 09:09:16.178725 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_122500.solverstate
I1211 09:09:16.182725 22260 solver.cpp:330] Iteration 122500, Testing net (#0)
I1211 09:09:16.182725 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:09:17.695832 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:09:17.755834 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6752
I1211 09:09:17.755834 22260 solver.cpp:397]     Test net output #1: loss = 1.30667 (* 1 = 1.30667 loss)
I1211 09:09:17.815838 22260 solver.cpp:218] Iteration 122500 (12.6226 iter/s, 7.92231s/100 iters), loss = 0.343364
I1211 09:09:17.815838 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:09:17.815838 22260 solver.cpp:237]     Train net output #1: loss = 0.343364 (* 1 = 0.343364 loss)
I1211 09:09:17.815838 22260 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1211 09:09:24.130288 22260 solver.cpp:218] Iteration 122600 (15.8385 iter/s, 6.31374s/100 iters), loss = 0.32978
I1211 09:09:24.130288 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:09:24.130288 22260 solver.cpp:237]     Train net output #1: loss = 0.32978 (* 1 = 0.32978 loss)
I1211 09:09:24.130288 22260 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1211 09:09:30.448727 22260 solver.cpp:218] Iteration 122700 (15.8293 iter/s, 6.31739s/100 iters), loss = 0.263918
I1211 09:09:30.448727 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:09:30.448727 22260 solver.cpp:237]     Train net output #1: loss = 0.263918 (* 1 = 0.263918 loss)
I1211 09:09:30.448727 22260 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1211 09:09:36.771236 22260 solver.cpp:218] Iteration 122800 (15.8171 iter/s, 6.32225s/100 iters), loss = 0.362953
I1211 09:09:36.771236 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:09:36.771236 22260 solver.cpp:237]     Train net output #1: loss = 0.362953 (* 1 = 0.362953 loss)
I1211 09:09:36.771236 22260 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1211 09:09:43.091699 22260 solver.cpp:218] Iteration 122900 (15.8213 iter/s, 6.32061s/100 iters), loss = 0.311187
I1211 09:09:43.091699 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:09:43.091699 22260 solver.cpp:237]     Train net output #1: loss = 0.311187 (* 1 = 0.311187 loss)
I1211 09:09:43.091699 22260 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1211 09:09:49.105115 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:09:49.354136 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_123000.caffemodel
I1211 09:09:49.369137 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_123000.solverstate
I1211 09:09:49.374137 22260 solver.cpp:330] Iteration 123000, Testing net (#0)
I1211 09:09:49.374137 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:09:50.886253 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:09:50.946255 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6707
I1211 09:09:50.946255 22260 solver.cpp:397]     Test net output #1: loss = 1.31702 (* 1 = 1.31702 loss)
I1211 09:09:51.007257 22260 solver.cpp:218] Iteration 123000 (12.6345 iter/s, 7.91484s/100 iters), loss = 0.306943
I1211 09:09:51.007257 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:09:51.007257 22260 solver.cpp:237]     Train net output #1: loss = 0.306943 (* 1 = 0.306943 loss)
I1211 09:09:51.007257 22260 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1211 09:09:57.314704 22260 solver.cpp:218] Iteration 123100 (15.8544 iter/s, 6.30739s/100 iters), loss = 0.234737
I1211 09:09:57.314704 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:09:57.314704 22260 solver.cpp:237]     Train net output #1: loss = 0.234737 (* 1 = 0.234737 loss)
I1211 09:09:57.314704 22260 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1211 09:10:03.635160 22260 solver.cpp:218] Iteration 123200 (15.8231 iter/s, 6.31986s/100 iters), loss = 0.251522
I1211 09:10:03.635160 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:10:03.635160 22260 solver.cpp:237]     Train net output #1: loss = 0.251522 (* 1 = 0.251522 loss)
I1211 09:10:03.635160 22260 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1211 09:10:09.949146 22260 solver.cpp:218] Iteration 123300 (15.8395 iter/s, 6.31333s/100 iters), loss = 0.243375
I1211 09:10:09.949645 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:10:09.949645 22260 solver.cpp:237]     Train net output #1: loss = 0.243375 (* 1 = 0.243375 loss)
I1211 09:10:09.949645 22260 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1211 09:10:16.272150 22260 solver.cpp:218] Iteration 123400 (15.8157 iter/s, 6.32281s/100 iters), loss = 0.266988
I1211 09:10:16.272150 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:10:16.272150 22260 solver.cpp:237]     Train net output #1: loss = 0.266988 (* 1 = 0.266988 loss)
I1211 09:10:16.272150 22260 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1211 09:10:22.282603 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:10:22.533612 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_123500.caffemodel
I1211 09:10:22.548614 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_123500.solverstate
I1211 09:10:22.553114 22260 solver.cpp:330] Iteration 123500, Testing net (#0)
I1211 09:10:22.553114 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:10:24.063720 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:10:24.123719 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6733
I1211 09:10:24.123719 22260 solver.cpp:397]     Test net output #1: loss = 1.31538 (* 1 = 1.31538 loss)
I1211 09:10:24.184731 22260 solver.cpp:218] Iteration 123500 (12.6389 iter/s, 7.91205s/100 iters), loss = 0.298483
I1211 09:10:24.184731 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:10:24.184731 22260 solver.cpp:237]     Train net output #1: loss = 0.298483 (* 1 = 0.298483 loss)
I1211 09:10:24.184731 22260 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1211 09:10:30.526186 22260 solver.cpp:218] Iteration 123600 (15.7708 iter/s, 6.34082s/100 iters), loss = 0.251946
I1211 09:10:30.526186 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:10:30.526186 22260 solver.cpp:237]     Train net output #1: loss = 0.251946 (* 1 = 0.251946 loss)
I1211 09:10:30.526186 22260 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1211 09:10:36.867677 22260 solver.cpp:218] Iteration 123700 (15.7696 iter/s, 6.34132s/100 iters), loss = 0.245329
I1211 09:10:36.867677 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:10:36.867677 22260 solver.cpp:237]     Train net output #1: loss = 0.245329 (* 1 = 0.245329 loss)
I1211 09:10:36.867677 22260 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1211 09:10:43.197980 22260 solver.cpp:218] Iteration 123800 (15.7991 iter/s, 6.32949s/100 iters), loss = 0.261171
I1211 09:10:43.197980 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:10:43.197980 22260 solver.cpp:237]     Train net output #1: loss = 0.261171 (* 1 = 0.261171 loss)
I1211 09:10:43.197980 22260 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1211 09:10:49.527129 22260 solver.cpp:218] Iteration 123900 (15.8005 iter/s, 6.32892s/100 iters), loss = 0.344592
I1211 09:10:49.527631 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:10:49.527631 22260 solver.cpp:237]     Train net output #1: loss = 0.344592 (* 1 = 0.344592 loss)
I1211 09:10:49.527631 22260 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1211 09:10:55.552065 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:10:55.801079 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_124000.caffemodel
I1211 09:10:55.816079 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_124000.solverstate
I1211 09:10:55.820080 22260 solver.cpp:330] Iteration 124000, Testing net (#0)
I1211 09:10:55.820080 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:10:57.333214 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:10:57.393216 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6732
I1211 09:10:57.393216 22260 solver.cpp:397]     Test net output #1: loss = 1.30333 (* 1 = 1.30333 loss)
I1211 09:10:57.453225 22260 solver.cpp:218] Iteration 124000 (12.6165 iter/s, 7.92614s/100 iters), loss = 0.228549
I1211 09:10:57.454226 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:10:57.454226 22260 solver.cpp:237]     Train net output #1: loss = 0.228549 (* 1 = 0.228549 loss)
I1211 09:10:57.454226 22260 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1211 09:11:03.780699 22260 solver.cpp:218] Iteration 124100 (15.807 iter/s, 6.32632s/100 iters), loss = 0.195149
I1211 09:11:03.780699 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 09:11:03.780699 22260 solver.cpp:237]     Train net output #1: loss = 0.195149 (* 1 = 0.195149 loss)
I1211 09:11:03.780699 22260 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1211 09:11:10.105155 22260 solver.cpp:218] Iteration 124200 (15.8123 iter/s, 6.32419s/100 iters), loss = 0.21628
I1211 09:11:10.105155 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:11:10.105155 22260 solver.cpp:237]     Train net output #1: loss = 0.21628 (* 1 = 0.21628 loss)
I1211 09:11:10.105155 22260 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1211 09:11:16.441036 22260 solver.cpp:218] Iteration 124300 (15.7845 iter/s, 6.33535s/100 iters), loss = 0.309286
I1211 09:11:16.441036 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:11:16.441036 22260 solver.cpp:237]     Train net output #1: loss = 0.309286 (* 1 = 0.309286 loss)
I1211 09:11:16.441036 22260 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1211 09:11:22.770956 22260 solver.cpp:218] Iteration 124400 (15.798 iter/s, 6.32991s/100 iters), loss = 0.294849
I1211 09:11:22.770956 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:11:22.770956 22260 solver.cpp:237]     Train net output #1: loss = 0.294849 (* 1 = 0.294849 loss)
I1211 09:11:22.770956 22260 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1211 09:11:28.794391 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:11:29.043407 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_124500.caffemodel
I1211 09:11:29.059407 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_124500.solverstate
I1211 09:11:29.063407 22260 solver.cpp:330] Iteration 124500, Testing net (#0)
I1211 09:11:29.063407 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:11:30.575518 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:11:30.635510 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6751
I1211 09:11:30.635510 22260 solver.cpp:397]     Test net output #1: loss = 1.31117 (* 1 = 1.31117 loss)
I1211 09:11:30.695513 22260 solver.cpp:218] Iteration 124500 (12.62 iter/s, 7.92391s/100 iters), loss = 0.205263
I1211 09:11:30.695513 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:11:30.695513 22260 solver.cpp:237]     Train net output #1: loss = 0.205264 (* 1 = 0.205264 loss)
I1211 09:11:30.695513 22260 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1211 09:11:37.015977 22260 solver.cpp:218] Iteration 124600 (15.8237 iter/s, 6.31965s/100 iters), loss = 0.324487
I1211 09:11:37.015977 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:11:37.015977 22260 solver.cpp:237]     Train net output #1: loss = 0.324487 (* 1 = 0.324487 loss)
I1211 09:11:37.015977 22260 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1211 09:11:43.342486 22260 solver.cpp:218] Iteration 124700 (15.8069 iter/s, 6.32635s/100 iters), loss = 0.240864
I1211 09:11:43.342988 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:11:43.342988 22260 solver.cpp:237]     Train net output #1: loss = 0.240864 (* 1 = 0.240864 loss)
I1211 09:11:43.342988 22260 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1211 09:11:49.662925 22260 solver.cpp:218] Iteration 124800 (15.8238 iter/s, 6.31961s/100 iters), loss = 0.284908
I1211 09:11:49.662925 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:11:49.662925 22260 solver.cpp:237]     Train net output #1: loss = 0.284908 (* 1 = 0.284908 loss)
I1211 09:11:49.662925 22260 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1211 09:11:55.978373 22260 solver.cpp:218] Iteration 124900 (15.8352 iter/s, 6.31503s/100 iters), loss = 0.298413
I1211 09:11:55.978373 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:11:55.978373 22260 solver.cpp:237]     Train net output #1: loss = 0.298413 (* 1 = 0.298413 loss)
I1211 09:11:55.978373 22260 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1211 09:12:01.983840 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:12:02.233355 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_125000.caffemodel
I1211 09:12:02.249861 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_125000.solverstate
I1211 09:12:02.253861 22260 solver.cpp:330] Iteration 125000, Testing net (#0)
I1211 09:12:02.253861 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:12:03.765959 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:12:03.825958 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6738
I1211 09:12:03.825958 22260 solver.cpp:397]     Test net output #1: loss = 1.30422 (* 1 = 1.30422 loss)
I1211 09:12:03.886965 22260 solver.cpp:218] Iteration 125000 (12.6441 iter/s, 7.90884s/100 iters), loss = 0.267899
I1211 09:12:03.886965 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:12:03.886965 22260 solver.cpp:237]     Train net output #1: loss = 0.2679 (* 1 = 0.2679 loss)
I1211 09:12:03.886965 22260 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1211 09:12:10.214467 22260 solver.cpp:218] Iteration 125100 (15.8053 iter/s, 6.32701s/100 iters), loss = 0.244744
I1211 09:12:10.214467 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:12:10.214467 22260 solver.cpp:237]     Train net output #1: loss = 0.244744 (* 1 = 0.244744 loss)
I1211 09:12:10.214467 22260 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1211 09:12:16.545943 22260 solver.cpp:218] Iteration 125200 (15.7958 iter/s, 6.3308s/100 iters), loss = 0.282555
I1211 09:12:16.545943 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:12:16.545943 22260 solver.cpp:237]     Train net output #1: loss = 0.282555 (* 1 = 0.282555 loss)
I1211 09:12:16.545943 22260 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1211 09:12:22.879379 22260 solver.cpp:218] Iteration 125300 (15.7908 iter/s, 6.33281s/100 iters), loss = 0.307439
I1211 09:12:22.879379 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:12:22.879379 22260 solver.cpp:237]     Train net output #1: loss = 0.307439 (* 1 = 0.307439 loss)
I1211 09:12:22.879379 22260 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1211 09:12:29.207885 22260 solver.cpp:218] Iteration 125400 (15.8026 iter/s, 6.32809s/100 iters), loss = 0.241551
I1211 09:12:29.207885 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:12:29.207885 22260 solver.cpp:237]     Train net output #1: loss = 0.241551 (* 1 = 0.241551 loss)
I1211 09:12:29.207885 22260 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1211 09:12:35.227339 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:12:35.477366 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_125500.caffemodel
I1211 09:12:35.492367 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_125500.solverstate
I1211 09:12:35.497367 22260 solver.cpp:330] Iteration 125500, Testing net (#0)
I1211 09:12:35.497367 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:12:37.009455 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:12:37.069461 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6714
I1211 09:12:37.069461 22260 solver.cpp:397]     Test net output #1: loss = 1.33853 (* 1 = 1.33853 loss)
I1211 09:12:37.129463 22260 solver.cpp:218] Iteration 125500 (12.6251 iter/s, 7.92075s/100 iters), loss = 0.204043
I1211 09:12:37.129463 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:12:37.129463 22260 solver.cpp:237]     Train net output #1: loss = 0.204043 (* 1 = 0.204043 loss)
I1211 09:12:37.129463 22260 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1211 09:12:43.459933 22260 solver.cpp:218] Iteration 125600 (15.7972 iter/s, 6.33023s/100 iters), loss = 0.280458
I1211 09:12:43.459933 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:12:43.459933 22260 solver.cpp:237]     Train net output #1: loss = 0.280459 (* 1 = 0.280459 loss)
I1211 09:12:43.459933 22260 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1211 09:12:49.792455 22260 solver.cpp:218] Iteration 125700 (15.7915 iter/s, 6.33254s/100 iters), loss = 0.211945
I1211 09:12:49.792455 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:12:49.792455 22260 solver.cpp:237]     Train net output #1: loss = 0.211945 (* 1 = 0.211945 loss)
I1211 09:12:49.792455 22260 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1211 09:12:56.115959 22260 solver.cpp:218] Iteration 125800 (15.8166 iter/s, 6.32248s/100 iters), loss = 0.297085
I1211 09:12:56.115959 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:12:56.115959 22260 solver.cpp:237]     Train net output #1: loss = 0.297085 (* 1 = 0.297085 loss)
I1211 09:12:56.115959 22260 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1211 09:13:02.444427 22260 solver.cpp:218] Iteration 125900 (15.8003 iter/s, 6.329s/100 iters), loss = 0.323244
I1211 09:13:02.445427 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:13:02.445427 22260 solver.cpp:237]     Train net output #1: loss = 0.323244 (* 1 = 0.323244 loss)
I1211 09:13:02.445427 22260 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1211 09:13:08.469678 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:13:08.720760 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_126000.caffemodel
I1211 09:13:08.736776 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_126000.solverstate
I1211 09:13:08.740773 22260 solver.cpp:330] Iteration 126000, Testing net (#0)
I1211 09:13:08.740773 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:13:10.254526 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:13:10.314555 22260 solver.cpp:397]     Test net output #0: accuracy = 0.668
I1211 09:13:10.314555 22260 solver.cpp:397]     Test net output #1: loss = 1.32361 (* 1 = 1.32361 loss)
I1211 09:13:10.375603 22260 solver.cpp:218] Iteration 126000 (12.6102 iter/s, 7.9301s/100 iters), loss = 0.260686
I1211 09:13:10.375603 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:13:10.375603 22260 solver.cpp:237]     Train net output #1: loss = 0.260686 (* 1 = 0.260686 loss)
I1211 09:13:10.375603 22260 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1211 09:13:16.702378 22260 solver.cpp:218] Iteration 126100 (15.8066 iter/s, 6.32645s/100 iters), loss = 0.230448
I1211 09:13:16.702378 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:13:16.702378 22260 solver.cpp:237]     Train net output #1: loss = 0.230449 (* 1 = 0.230449 loss)
I1211 09:13:16.702378 22260 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1211 09:13:23.030813 22260 solver.cpp:218] Iteration 126200 (15.802 iter/s, 6.3283s/100 iters), loss = 0.245246
I1211 09:13:23.030813 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:13:23.030813 22260 solver.cpp:237]     Train net output #1: loss = 0.245246 (* 1 = 0.245246 loss)
I1211 09:13:23.030813 22260 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1211 09:13:29.359802 22260 solver.cpp:218] Iteration 126300 (15.8024 iter/s, 6.32815s/100 iters), loss = 0.327777
I1211 09:13:29.360303 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 09:13:29.360303 22260 solver.cpp:237]     Train net output #1: loss = 0.327777 (* 1 = 0.327777 loss)
I1211 09:13:29.360303 22260 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1211 09:13:35.686769 22260 solver.cpp:218] Iteration 126400 (15.8076 iter/s, 6.32609s/100 iters), loss = 0.26497
I1211 09:13:35.686769 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:13:35.686769 22260 solver.cpp:237]     Train net output #1: loss = 0.26497 (* 1 = 0.26497 loss)
I1211 09:13:35.686769 22260 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1211 09:13:41.703183 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:13:41.954185 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_126500.caffemodel
I1211 09:13:41.969189 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_126500.solverstate
I1211 09:13:41.973690 22260 solver.cpp:330] Iteration 126500, Testing net (#0)
I1211 09:13:41.973690 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:13:43.485340 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:13:43.545339 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6709
I1211 09:13:43.545339 22260 solver.cpp:397]     Test net output #1: loss = 1.32775 (* 1 = 1.32775 loss)
I1211 09:13:43.605342 22260 solver.cpp:218] Iteration 126500 (12.628 iter/s, 7.91894s/100 iters), loss = 0.251272
I1211 09:13:43.605342 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:13:43.605342 22260 solver.cpp:237]     Train net output #1: loss = 0.251272 (* 1 = 0.251272 loss)
I1211 09:13:43.606343 22260 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1211 09:13:49.917821 22260 solver.cpp:218] Iteration 126600 (15.8445 iter/s, 6.31132s/100 iters), loss = 0.324463
I1211 09:13:49.917821 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:13:49.917821 22260 solver.cpp:237]     Train net output #1: loss = 0.324463 (* 1 = 0.324463 loss)
I1211 09:13:49.917821 22260 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1211 09:13:56.230285 22260 solver.cpp:218] Iteration 126700 (15.8417 iter/s, 6.31246s/100 iters), loss = 0.256058
I1211 09:13:56.230285 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:13:56.230285 22260 solver.cpp:237]     Train net output #1: loss = 0.256058 (* 1 = 0.256058 loss)
I1211 09:13:56.230285 22260 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1211 09:14:02.547791 22260 solver.cpp:218] Iteration 126800 (15.8293 iter/s, 6.3174s/100 iters), loss = 0.216576
I1211 09:14:02.548791 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:14:02.548791 22260 solver.cpp:237]     Train net output #1: loss = 0.216576 (* 1 = 0.216576 loss)
I1211 09:14:02.548791 22260 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1211 09:14:08.861286 22260 solver.cpp:218] Iteration 126900 (15.8424 iter/s, 6.31217s/100 iters), loss = 0.285242
I1211 09:14:08.861286 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:14:08.861286 22260 solver.cpp:237]     Train net output #1: loss = 0.285242 (* 1 = 0.285242 loss)
I1211 09:14:08.861286 22260 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1211 09:14:14.867266 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:14:15.117780 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_127000.caffemodel
I1211 09:14:15.131781 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_127000.solverstate
I1211 09:14:15.136781 22260 solver.cpp:330] Iteration 127000, Testing net (#0)
I1211 09:14:15.136781 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:14:16.647877 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:14:16.707909 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6701
I1211 09:14:16.707909 22260 solver.cpp:397]     Test net output #1: loss = 1.32796 (* 1 = 1.32796 loss)
I1211 09:14:16.769888 22260 solver.cpp:218] Iteration 127000 (12.6455 iter/s, 7.90794s/100 iters), loss = 0.311314
I1211 09:14:16.769888 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:14:16.769888 22260 solver.cpp:237]     Train net output #1: loss = 0.311315 (* 1 = 0.311315 loss)
I1211 09:14:16.769888 22260 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1211 09:14:23.085333 22260 solver.cpp:218] Iteration 127100 (15.8344 iter/s, 6.31536s/100 iters), loss = 0.246843
I1211 09:14:23.085333 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:14:23.085333 22260 solver.cpp:237]     Train net output #1: loss = 0.246843 (* 1 = 0.246843 loss)
I1211 09:14:23.085333 22260 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1211 09:14:29.409807 22260 solver.cpp:218] Iteration 127200 (15.8126 iter/s, 6.32406s/100 iters), loss = 0.27328
I1211 09:14:29.409807 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:14:29.409807 22260 solver.cpp:237]     Train net output #1: loss = 0.27328 (* 1 = 0.27328 loss)
I1211 09:14:29.409807 22260 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1211 09:14:35.727226 22260 solver.cpp:218] Iteration 127300 (15.8293 iter/s, 6.31741s/100 iters), loss = 0.300383
I1211 09:14:35.727226 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:14:35.727226 22260 solver.cpp:237]     Train net output #1: loss = 0.300383 (* 1 = 0.300383 loss)
I1211 09:14:35.727226 22260 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1211 09:14:42.052650 22260 solver.cpp:218] Iteration 127400 (15.8101 iter/s, 6.32507s/100 iters), loss = 0.320025
I1211 09:14:42.053652 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:14:42.053652 22260 solver.cpp:237]     Train net output #1: loss = 0.320025 (* 1 = 0.320025 loss)
I1211 09:14:42.053652 22260 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1211 09:14:48.062085 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:14:48.310101 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_127500.caffemodel
I1211 09:14:48.325100 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_127500.solverstate
I1211 09:14:48.329102 22260 solver.cpp:330] Iteration 127500, Testing net (#0)
I1211 09:14:48.329102 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:14:49.840221 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:14:49.900233 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6725
I1211 09:14:49.900233 22260 solver.cpp:397]     Test net output #1: loss = 1.33607 (* 1 = 1.33607 loss)
I1211 09:14:49.960232 22260 solver.cpp:218] Iteration 127500 (12.6469 iter/s, 7.90705s/100 iters), loss = 0.276339
I1211 09:14:49.960232 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:14:49.960232 22260 solver.cpp:237]     Train net output #1: loss = 0.27634 (* 1 = 0.27634 loss)
I1211 09:14:49.960232 22260 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1211 09:14:56.283702 22260 solver.cpp:218] Iteration 127600 (15.815 iter/s, 6.3231s/100 iters), loss = 0.310994
I1211 09:14:56.284703 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:14:56.284703 22260 solver.cpp:237]     Train net output #1: loss = 0.310995 (* 1 = 0.310995 loss)
I1211 09:14:56.284703 22260 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1211 09:15:02.603118 22260 solver.cpp:218] Iteration 127700 (15.8265 iter/s, 6.31852s/100 iters), loss = 0.304941
I1211 09:15:02.603118 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:15:02.603118 22260 solver.cpp:237]     Train net output #1: loss = 0.304941 (* 1 = 0.304941 loss)
I1211 09:15:02.603118 22260 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1211 09:15:08.928683 22260 solver.cpp:218] Iteration 127800 (15.8104 iter/s, 6.32496s/100 iters), loss = 0.284845
I1211 09:15:08.928683 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:15:08.928683 22260 solver.cpp:237]     Train net output #1: loss = 0.284846 (* 1 = 0.284846 loss)
I1211 09:15:08.928683 22260 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1211 09:15:15.255177 22260 solver.cpp:218] Iteration 127900 (15.8076 iter/s, 6.32606s/100 iters), loss = 0.295712
I1211 09:15:15.255177 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:15:15.255177 22260 solver.cpp:237]     Train net output #1: loss = 0.295712 (* 1 = 0.295712 loss)
I1211 09:15:15.255177 22260 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1211 09:15:21.265606 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:15:21.515622 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_128000.caffemodel
I1211 09:15:21.531621 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_128000.solverstate
I1211 09:15:21.536623 22260 solver.cpp:330] Iteration 128000, Testing net (#0)
I1211 09:15:21.536623 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:15:23.048715 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:15:23.108719 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6715
I1211 09:15:23.108719 22260 solver.cpp:397]     Test net output #1: loss = 1.32892 (* 1 = 1.32892 loss)
I1211 09:15:23.168720 22260 solver.cpp:218] Iteration 128000 (12.6372 iter/s, 7.91312s/100 iters), loss = 0.225378
I1211 09:15:23.168720 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:15:23.168720 22260 solver.cpp:237]     Train net output #1: loss = 0.225378 (* 1 = 0.225378 loss)
I1211 09:15:23.168720 22260 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1211 09:15:29.493213 22260 solver.cpp:218] Iteration 128100 (15.8122 iter/s, 6.32424s/100 iters), loss = 0.222208
I1211 09:15:29.493213 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:15:29.493213 22260 solver.cpp:237]     Train net output #1: loss = 0.222208 (* 1 = 0.222208 loss)
I1211 09:15:29.493213 22260 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1211 09:15:35.810652 22260 solver.cpp:218] Iteration 128200 (15.8308 iter/s, 6.3168s/100 iters), loss = 0.264417
I1211 09:15:35.810652 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:15:35.810652 22260 solver.cpp:237]     Train net output #1: loss = 0.264417 (* 1 = 0.264417 loss)
I1211 09:15:35.810652 22260 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1211 09:15:42.126096 22260 solver.cpp:218] Iteration 128300 (15.8348 iter/s, 6.31521s/100 iters), loss = 0.25646
I1211 09:15:42.126096 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:15:42.126096 22260 solver.cpp:237]     Train net output #1: loss = 0.25646 (* 1 = 0.25646 loss)
I1211 09:15:42.126096 22260 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1211 09:15:48.452558 22260 solver.cpp:218] Iteration 128400 (15.8078 iter/s, 6.32599s/100 iters), loss = 0.384751
I1211 09:15:48.452558 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:15:48.452558 22260 solver.cpp:237]     Train net output #1: loss = 0.384751 (* 1 = 0.384751 loss)
I1211 09:15:48.452558 22260 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1211 09:15:54.469022 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:15:54.717068 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_128500.caffemodel
I1211 09:15:54.732069 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_128500.solverstate
I1211 09:15:54.736068 22260 solver.cpp:330] Iteration 128500, Testing net (#0)
I1211 09:15:54.736068 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:15:56.250185 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:15:56.310189 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6705
I1211 09:15:56.310189 22260 solver.cpp:397]     Test net output #1: loss = 1.33878 (* 1 = 1.33878 loss)
I1211 09:15:56.371193 22260 solver.cpp:218] Iteration 128500 (12.6292 iter/s, 7.91816s/100 iters), loss = 0.264626
I1211 09:15:56.371193 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:15:56.371193 22260 solver.cpp:237]     Train net output #1: loss = 0.264627 (* 1 = 0.264627 loss)
I1211 09:15:56.371193 22260 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1211 09:16:02.700652 22260 solver.cpp:218] Iteration 128600 (15.801 iter/s, 6.32871s/100 iters), loss = 0.280618
I1211 09:16:02.700652 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:16:02.700652 22260 solver.cpp:237]     Train net output #1: loss = 0.280618 (* 1 = 0.280618 loss)
I1211 09:16:02.700652 22260 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1211 09:16:09.026118 22260 solver.cpp:218] Iteration 128700 (15.8087 iter/s, 6.32561s/100 iters), loss = 0.257403
I1211 09:16:09.026118 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:16:09.026118 22260 solver.cpp:237]     Train net output #1: loss = 0.257403 (* 1 = 0.257403 loss)
I1211 09:16:09.026118 22260 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1211 09:16:15.352582 22260 solver.cpp:218] Iteration 128800 (15.8071 iter/s, 6.32629s/100 iters), loss = 0.343369
I1211 09:16:15.352582 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:16:15.352582 22260 solver.cpp:237]     Train net output #1: loss = 0.343369 (* 1 = 0.343369 loss)
I1211 09:16:15.352582 22260 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1211 09:16:21.673063 22260 solver.cpp:218] Iteration 128900 (15.8229 iter/s, 6.31996s/100 iters), loss = 0.314582
I1211 09:16:21.673063 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:16:21.673063 22260 solver.cpp:237]     Train net output #1: loss = 0.314582 (* 1 = 0.314582 loss)
I1211 09:16:21.673063 22260 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1211 09:16:27.696467 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:16:27.945495 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_129000.caffemodel
I1211 09:16:27.961496 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_129000.solverstate
I1211 09:16:27.965495 22260 solver.cpp:330] Iteration 129000, Testing net (#0)
I1211 09:16:27.965495 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:16:29.478580 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:16:29.538583 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6723
I1211 09:16:29.538583 22260 solver.cpp:397]     Test net output #1: loss = 1.34224 (* 1 = 1.34224 loss)
I1211 09:16:29.598584 22260 solver.cpp:218] Iteration 129000 (12.6183 iter/s, 7.92497s/100 iters), loss = 0.259609
I1211 09:16:29.598584 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:16:29.598584 22260 solver.cpp:237]     Train net output #1: loss = 0.259609 (* 1 = 0.259609 loss)
I1211 09:16:29.598584 22260 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1211 09:16:35.925014 22260 solver.cpp:218] Iteration 129100 (15.8097 iter/s, 6.32523s/100 iters), loss = 0.268181
I1211 09:16:35.925014 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:16:35.925014 22260 solver.cpp:237]     Train net output #1: loss = 0.268181 (* 1 = 0.268181 loss)
I1211 09:16:35.925014 22260 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1211 09:16:42.247481 22260 solver.cpp:218] Iteration 129200 (15.8174 iter/s, 6.32217s/100 iters), loss = 0.224762
I1211 09:16:42.247481 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:16:42.247481 22260 solver.cpp:237]     Train net output #1: loss = 0.224763 (* 1 = 0.224763 loss)
I1211 09:16:42.247481 22260 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1211 09:16:48.581496 22260 solver.cpp:218] Iteration 129300 (15.7889 iter/s, 6.33358s/100 iters), loss = 0.308725
I1211 09:16:48.581496 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:16:48.581496 22260 solver.cpp:237]     Train net output #1: loss = 0.308725 (* 1 = 0.308725 loss)
I1211 09:16:48.581496 22260 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1211 09:16:54.901495 22260 solver.cpp:218] Iteration 129400 (15.8228 iter/s, 6.31998s/100 iters), loss = 0.25398
I1211 09:16:54.901495 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:16:54.901495 22260 solver.cpp:237]     Train net output #1: loss = 0.253981 (* 1 = 0.253981 loss)
I1211 09:16:54.901495 22260 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1211 09:17:00.916932 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:17:01.165951 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_129500.caffemodel
I1211 09:17:01.181455 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_129500.solverstate
I1211 09:17:01.185956 22260 solver.cpp:330] Iteration 129500, Testing net (#0)
I1211 09:17:01.185956 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:17:02.698057 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:17:02.757056 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6716
I1211 09:17:02.757056 22260 solver.cpp:397]     Test net output #1: loss = 1.33146 (* 1 = 1.33146 loss)
I1211 09:17:02.819061 22260 solver.cpp:218] Iteration 129500 (12.6315 iter/s, 7.91671s/100 iters), loss = 0.296277
I1211 09:17:02.819061 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:17:02.819061 22260 solver.cpp:237]     Train net output #1: loss = 0.296277 (* 1 = 0.296277 loss)
I1211 09:17:02.819061 22260 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1211 09:17:09.134496 22260 solver.cpp:218] Iteration 129600 (15.8346 iter/s, 6.31528s/100 iters), loss = 0.257451
I1211 09:17:09.134496 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:17:09.134496 22260 solver.cpp:237]     Train net output #1: loss = 0.257452 (* 1 = 0.257452 loss)
I1211 09:17:09.134496 22260 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1211 09:17:15.440979 22260 solver.cpp:218] Iteration 129700 (15.8566 iter/s, 6.30651s/100 iters), loss = 0.272789
I1211 09:17:15.440979 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:17:15.440979 22260 solver.cpp:237]     Train net output #1: loss = 0.272789 (* 1 = 0.272789 loss)
I1211 09:17:15.440979 22260 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1211 09:17:21.755498 22260 solver.cpp:218] Iteration 129800 (15.8379 iter/s, 6.31399s/100 iters), loss = 0.304535
I1211 09:17:21.755498 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:17:21.755498 22260 solver.cpp:237]     Train net output #1: loss = 0.304536 (* 1 = 0.304536 loss)
I1211 09:17:21.755498 22260 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1211 09:17:28.072962 22260 solver.cpp:218] Iteration 129900 (15.831 iter/s, 6.3167s/100 iters), loss = 0.246062
I1211 09:17:28.072962 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:17:28.072962 22260 solver.cpp:237]     Train net output #1: loss = 0.246062 (* 1 = 0.246062 loss)
I1211 09:17:28.072962 22260 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1211 09:17:34.074388 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:17:34.324417 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_130000.caffemodel
I1211 09:17:34.339416 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_130000.solverstate
I1211 09:17:34.343417 22260 solver.cpp:330] Iteration 130000, Testing net (#0)
I1211 09:17:34.343417 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:17:35.856523 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:17:35.915527 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6765
I1211 09:17:35.915527 22260 solver.cpp:397]     Test net output #1: loss = 1.33492 (* 1 = 1.33492 loss)
I1211 09:17:35.977028 22260 solver.cpp:218] Iteration 130000 (12.6528 iter/s, 7.90339s/100 iters), loss = 0.314937
I1211 09:17:35.977028 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:17:35.977028 22260 solver.cpp:237]     Train net output #1: loss = 0.314937 (* 1 = 0.314937 loss)
I1211 09:17:35.977028 22260 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1211 09:17:42.301939 22260 solver.cpp:218] Iteration 130100 (15.8109 iter/s, 6.32476s/100 iters), loss = 0.262427
I1211 09:17:42.301939 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:17:42.301939 22260 solver.cpp:237]     Train net output #1: loss = 0.262427 (* 1 = 0.262427 loss)
I1211 09:17:42.301939 22260 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1211 09:17:48.620393 22260 solver.cpp:218] Iteration 130200 (15.8279 iter/s, 6.31794s/100 iters), loss = 0.220198
I1211 09:17:48.620393 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:17:48.620393 22260 solver.cpp:237]     Train net output #1: loss = 0.220198 (* 1 = 0.220198 loss)
I1211 09:17:48.620393 22260 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1211 09:17:54.944849 22260 solver.cpp:218] Iteration 130300 (15.8133 iter/s, 6.3238s/100 iters), loss = 0.300404
I1211 09:17:54.944849 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:17:54.944849 22260 solver.cpp:237]     Train net output #1: loss = 0.300404 (* 1 = 0.300404 loss)
I1211 09:17:54.944849 22260 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1211 09:18:01.277300 22260 solver.cpp:218] Iteration 130400 (15.7909 iter/s, 6.33277s/100 iters), loss = 0.314308
I1211 09:18:01.277300 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:18:01.277300 22260 solver.cpp:237]     Train net output #1: loss = 0.314308 (* 1 = 0.314308 loss)
I1211 09:18:01.277300 22260 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1211 09:18:07.291189 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:18:07.539706 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_130500.caffemodel
I1211 09:18:07.553706 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_130500.solverstate
I1211 09:18:07.558707 22260 solver.cpp:330] Iteration 130500, Testing net (#0)
I1211 09:18:07.558707 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:18:09.072818 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:18:09.132824 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6693
I1211 09:18:09.132824 22260 solver.cpp:397]     Test net output #1: loss = 1.34226 (* 1 = 1.34226 loss)
I1211 09:18:09.193828 22260 solver.cpp:218] Iteration 130500 (12.6333 iter/s, 7.91557s/100 iters), loss = 0.274998
I1211 09:18:09.193828 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:18:09.193828 22260 solver.cpp:237]     Train net output #1: loss = 0.274998 (* 1 = 0.274998 loss)
I1211 09:18:09.193828 22260 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1211 09:18:15.530280 22260 solver.cpp:218] Iteration 130600 (15.7829 iter/s, 6.33596s/100 iters), loss = 0.279528
I1211 09:18:15.530280 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:18:15.530280 22260 solver.cpp:237]     Train net output #1: loss = 0.279528 (* 1 = 0.279528 loss)
I1211 09:18:15.530280 22260 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1211 09:18:21.864720 22260 solver.cpp:218] Iteration 130700 (15.7862 iter/s, 6.33464s/100 iters), loss = 0.235306
I1211 09:18:21.865718 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:18:21.865718 22260 solver.cpp:237]     Train net output #1: loss = 0.235306 (* 1 = 0.235306 loss)
I1211 09:18:21.865718 22260 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1211 09:18:28.202178 22260 solver.cpp:218] Iteration 130800 (15.7813 iter/s, 6.33662s/100 iters), loss = 0.221682
I1211 09:18:28.202178 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:18:28.202178 22260 solver.cpp:237]     Train net output #1: loss = 0.221683 (* 1 = 0.221683 loss)
I1211 09:18:28.202178 22260 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1211 09:18:34.522699 22260 solver.cpp:218] Iteration 130900 (15.8236 iter/s, 6.31966s/100 iters), loss = 0.364267
I1211 09:18:34.522699 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:18:34.522699 22260 solver.cpp:237]     Train net output #1: loss = 0.364267 (* 1 = 0.364267 loss)
I1211 09:18:34.522699 22260 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1211 09:18:40.543161 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:18:40.792173 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_131000.caffemodel
I1211 09:18:40.807178 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_131000.solverstate
I1211 09:18:40.811178 22260 solver.cpp:330] Iteration 131000, Testing net (#0)
I1211 09:18:40.811178 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:18:42.322296 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:18:42.382799 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6723
I1211 09:18:42.382799 22260 solver.cpp:397]     Test net output #1: loss = 1.33813 (* 1 = 1.33813 loss)
I1211 09:18:42.443300 22260 solver.cpp:218] Iteration 131000 (12.6261 iter/s, 7.9201s/100 iters), loss = 0.272098
I1211 09:18:42.443300 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:18:42.443300 22260 solver.cpp:237]     Train net output #1: loss = 0.272098 (* 1 = 0.272098 loss)
I1211 09:18:42.443300 22260 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1211 09:18:48.768709 22260 solver.cpp:218] Iteration 131100 (15.8088 iter/s, 6.32557s/100 iters), loss = 0.298368
I1211 09:18:48.768709 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:18:48.768709 22260 solver.cpp:237]     Train net output #1: loss = 0.298368 (* 1 = 0.298368 loss)
I1211 09:18:48.768709 22260 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1211 09:18:55.104099 22260 solver.cpp:218] Iteration 131200 (15.7858 iter/s, 6.3348s/100 iters), loss = 0.296973
I1211 09:18:55.104099 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:18:55.104099 22260 solver.cpp:237]     Train net output #1: loss = 0.296973 (* 1 = 0.296973 loss)
I1211 09:18:55.104099 22260 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1211 09:19:01.442571 22260 solver.cpp:218] Iteration 131300 (15.7786 iter/s, 6.3377s/100 iters), loss = 0.334362
I1211 09:19:01.442571 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:19:01.442571 22260 solver.cpp:237]     Train net output #1: loss = 0.334362 (* 1 = 0.334362 loss)
I1211 09:19:01.442571 22260 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1211 09:19:07.772002 22260 solver.cpp:218] Iteration 131400 (15.7995 iter/s, 6.32933s/100 iters), loss = 0.268776
I1211 09:19:07.772002 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:19:07.772002 22260 solver.cpp:237]     Train net output #1: loss = 0.268777 (* 1 = 0.268777 loss)
I1211 09:19:07.772002 22260 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1211 09:19:13.791419 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:19:14.039433 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_131500.caffemodel
I1211 09:19:14.054433 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_131500.solverstate
I1211 09:19:14.059434 22260 solver.cpp:330] Iteration 131500, Testing net (#0)
I1211 09:19:14.059434 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:19:15.572535 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:19:15.631538 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6711
I1211 09:19:15.631538 22260 solver.cpp:397]     Test net output #1: loss = 1.34045 (* 1 = 1.34045 loss)
I1211 09:19:15.692541 22260 solver.cpp:218] Iteration 131500 (12.6265 iter/s, 7.91987s/100 iters), loss = 0.228723
I1211 09:19:15.692541 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:19:15.692541 22260 solver.cpp:237]     Train net output #1: loss = 0.228723 (* 1 = 0.228723 loss)
I1211 09:19:15.692541 22260 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1211 09:19:22.011965 22260 solver.cpp:218] Iteration 131600 (15.8236 iter/s, 6.31967s/100 iters), loss = 0.282204
I1211 09:19:22.011965 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:19:22.011965 22260 solver.cpp:237]     Train net output #1: loss = 0.282204 (* 1 = 0.282204 loss)
I1211 09:19:22.011965 22260 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1211 09:19:28.325445 22260 solver.cpp:218] Iteration 131700 (15.8402 iter/s, 6.31305s/100 iters), loss = 0.229185
I1211 09:19:28.325445 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:19:28.325445 22260 solver.cpp:237]     Train net output #1: loss = 0.229185 (* 1 = 0.229185 loss)
I1211 09:19:28.325445 22260 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1211 09:19:34.639919 22260 solver.cpp:218] Iteration 131800 (15.8377 iter/s, 6.31405s/100 iters), loss = 0.290835
I1211 09:19:34.639919 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:19:34.639919 22260 solver.cpp:237]     Train net output #1: loss = 0.290835 (* 1 = 0.290835 loss)
I1211 09:19:34.639919 22260 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1211 09:19:40.959785 22260 solver.cpp:218] Iteration 131900 (15.8253 iter/s, 6.31898s/100 iters), loss = 0.26289
I1211 09:19:40.959785 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:19:40.959785 22260 solver.cpp:237]     Train net output #1: loss = 0.26289 (* 1 = 0.26289 loss)
I1211 09:19:40.959785 22260 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1211 09:19:46.968222 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:19:47.219240 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_132000.caffemodel
I1211 09:19:47.234239 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_132000.solverstate
I1211 09:19:47.239240 22260 solver.cpp:330] Iteration 132000, Testing net (#0)
I1211 09:19:47.239240 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:19:48.750329 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:19:48.810333 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6735
I1211 09:19:48.810333 22260 solver.cpp:397]     Test net output #1: loss = 1.35353 (* 1 = 1.35353 loss)
I1211 09:19:48.871333 22260 solver.cpp:218] Iteration 132000 (12.6402 iter/s, 7.91128s/100 iters), loss = 0.274765
I1211 09:19:48.871333 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:19:48.871333 22260 solver.cpp:237]     Train net output #1: loss = 0.274766 (* 1 = 0.274766 loss)
I1211 09:19:48.871333 22260 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1211 09:19:55.201115 22260 solver.cpp:218] Iteration 132100 (15.8001 iter/s, 6.32908s/100 iters), loss = 0.278914
I1211 09:19:55.201115 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:19:55.201115 22260 solver.cpp:237]     Train net output #1: loss = 0.278914 (* 1 = 0.278914 loss)
I1211 09:19:55.201115 22260 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1211 09:20:01.520040 22260 solver.cpp:218] Iteration 132200 (15.827 iter/s, 6.3183s/100 iters), loss = 0.254371
I1211 09:20:01.520040 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:20:01.520040 22260 solver.cpp:237]     Train net output #1: loss = 0.254371 (* 1 = 0.254371 loss)
I1211 09:20:01.520040 22260 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1211 09:20:07.849499 22260 solver.cpp:218] Iteration 132300 (15.8006 iter/s, 6.32886s/100 iters), loss = 0.263121
I1211 09:20:07.849499 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:20:07.849499 22260 solver.cpp:237]     Train net output #1: loss = 0.263121 (* 1 = 0.263121 loss)
I1211 09:20:07.849499 22260 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1211 09:20:14.173918 22260 solver.cpp:218] Iteration 132400 (15.8129 iter/s, 6.32394s/100 iters), loss = 0.327987
I1211 09:20:14.173918 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:20:14.173918 22260 solver.cpp:237]     Train net output #1: loss = 0.327987 (* 1 = 0.327987 loss)
I1211 09:20:14.173918 22260 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1211 09:20:20.188810 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:20:20.437811 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_132500.caffemodel
I1211 09:20:20.452811 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_132500.solverstate
I1211 09:20:20.457312 22260 solver.cpp:330] Iteration 132500, Testing net (#0)
I1211 09:20:20.457312 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:20:21.982916 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:20:22.042418 22260 solver.cpp:397]     Test net output #0: accuracy = 0.671
I1211 09:20:22.042418 22260 solver.cpp:397]     Test net output #1: loss = 1.3429 (* 1 = 1.3429 loss)
I1211 09:20:22.103423 22260 solver.cpp:218] Iteration 132500 (12.6109 iter/s, 7.92968s/100 iters), loss = 0.243399
I1211 09:20:22.103423 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:20:22.103423 22260 solver.cpp:237]     Train net output #1: loss = 0.243399 (* 1 = 0.243399 loss)
I1211 09:20:22.103423 22260 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1211 09:20:28.430899 22260 solver.cpp:218] Iteration 132600 (15.8056 iter/s, 6.32686s/100 iters), loss = 0.25996
I1211 09:20:28.430899 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:20:28.430899 22260 solver.cpp:237]     Train net output #1: loss = 0.25996 (* 1 = 0.25996 loss)
I1211 09:20:28.430899 22260 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1211 09:20:34.764322 22260 solver.cpp:218] Iteration 132700 (15.7898 iter/s, 6.3332s/100 iters), loss = 0.224436
I1211 09:20:34.764322 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:20:34.764322 22260 solver.cpp:237]     Train net output #1: loss = 0.224436 (* 1 = 0.224436 loss)
I1211 09:20:34.764322 22260 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1211 09:20:41.086697 22260 solver.cpp:218] Iteration 132800 (15.8199 iter/s, 6.32117s/100 iters), loss = 0.21605
I1211 09:20:41.086697 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 09:20:41.086697 22260 solver.cpp:237]     Train net output #1: loss = 0.21605 (* 1 = 0.21605 loss)
I1211 09:20:41.086697 22260 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1211 09:20:47.411161 22260 solver.cpp:218] Iteration 132900 (15.8106 iter/s, 6.32487s/100 iters), loss = 0.277817
I1211 09:20:47.411161 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:20:47.411161 22260 solver.cpp:237]     Train net output #1: loss = 0.277817 (* 1 = 0.277817 loss)
I1211 09:20:47.411161 22260 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1211 09:20:53.423586 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:20:53.673597 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_133000.caffemodel
I1211 09:20:53.689102 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_133000.solverstate
I1211 09:20:53.694103 22260 solver.cpp:330] Iteration 133000, Testing net (#0)
I1211 09:20:53.694103 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:20:55.205708 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:20:55.265708 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6734
I1211 09:20:55.265708 22260 solver.cpp:397]     Test net output #1: loss = 1.3388 (* 1 = 1.3388 loss)
I1211 09:20:55.325732 22260 solver.cpp:218] Iteration 133000 (12.6357 iter/s, 7.91409s/100 iters), loss = 0.20015
I1211 09:20:55.325732 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:20:55.325732 22260 solver.cpp:237]     Train net output #1: loss = 0.20015 (* 1 = 0.20015 loss)
I1211 09:20:55.325732 22260 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1211 09:21:01.648147 22260 solver.cpp:218] Iteration 133100 (15.8182 iter/s, 6.32184s/100 iters), loss = 0.251097
I1211 09:21:01.648147 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:21:01.648147 22260 solver.cpp:237]     Train net output #1: loss = 0.251097 (* 1 = 0.251097 loss)
I1211 09:21:01.648147 22260 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1211 09:21:07.975555 22260 solver.cpp:218] Iteration 133200 (15.8052 iter/s, 6.32703s/100 iters), loss = 0.264033
I1211 09:21:07.975555 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:21:07.975555 22260 solver.cpp:237]     Train net output #1: loss = 0.264033 (* 1 = 0.264033 loss)
I1211 09:21:07.975555 22260 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1211 09:21:14.297346 22260 solver.cpp:218] Iteration 133300 (15.821 iter/s, 6.32072s/100 iters), loss = 0.358208
I1211 09:21:14.297346 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 09:21:14.297346 22260 solver.cpp:237]     Train net output #1: loss = 0.358209 (* 1 = 0.358209 loss)
I1211 09:21:14.297346 22260 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1211 09:21:20.627960 22260 solver.cpp:218] Iteration 133400 (15.7966 iter/s, 6.33047s/100 iters), loss = 0.229928
I1211 09:21:20.627960 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:21:20.627960 22260 solver.cpp:237]     Train net output #1: loss = 0.229928 (* 1 = 0.229928 loss)
I1211 09:21:20.627960 22260 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1211 09:21:26.653753 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:21:26.902796 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_133500.caffemodel
I1211 09:21:26.918385 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_133500.solverstate
I1211 09:21:26.923400 22260 solver.cpp:330] Iteration 133500, Testing net (#0)
I1211 09:21:26.923400 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:21:28.437525 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:21:28.496541 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6721
I1211 09:21:28.496541 22260 solver.cpp:397]     Test net output #1: loss = 1.36155 (* 1 = 1.36155 loss)
I1211 09:21:28.558579 22260 solver.cpp:218] Iteration 133500 (12.6107 iter/s, 7.92976s/100 iters), loss = 0.220691
I1211 09:21:28.558579 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:21:28.558579 22260 solver.cpp:237]     Train net output #1: loss = 0.220691 (* 1 = 0.220691 loss)
I1211 09:21:28.558579 22260 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1211 09:21:34.894408 22260 solver.cpp:218] Iteration 133600 (15.7842 iter/s, 6.33546s/100 iters), loss = 0.279059
I1211 09:21:34.894408 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:21:34.894408 22260 solver.cpp:237]     Train net output #1: loss = 0.279059 (* 1 = 0.279059 loss)
I1211 09:21:34.894408 22260 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1211 09:21:41.228839 22260 solver.cpp:218] Iteration 133700 (15.7876 iter/s, 6.33408s/100 iters), loss = 0.196032
I1211 09:21:41.228839 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:21:41.228839 22260 solver.cpp:237]     Train net output #1: loss = 0.196032 (* 1 = 0.196032 loss)
I1211 09:21:41.228839 22260 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1211 09:21:47.564232 22260 solver.cpp:218] Iteration 133800 (15.7851 iter/s, 6.3351s/100 iters), loss = 0.210161
I1211 09:21:47.564232 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:21:47.564232 22260 solver.cpp:237]     Train net output #1: loss = 0.210161 (* 1 = 0.210161 loss)
I1211 09:21:47.564232 22260 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1211 09:21:53.896649 22260 solver.cpp:218] Iteration 133900 (15.7935 iter/s, 6.33171s/100 iters), loss = 0.25655
I1211 09:21:53.896649 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:21:53.896649 22260 solver.cpp:237]     Train net output #1: loss = 0.256551 (* 1 = 0.256551 loss)
I1211 09:21:53.896649 22260 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1211 09:21:59.916100 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:22:00.166116 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_134000.caffemodel
I1211 09:22:00.181116 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_134000.solverstate
I1211 09:22:00.185621 22260 solver.cpp:330] Iteration 134000, Testing net (#0)
I1211 09:22:00.185621 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:22:01.698714 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:22:01.758215 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6696
I1211 09:22:01.758215 22260 solver.cpp:397]     Test net output #1: loss = 1.35757 (* 1 = 1.35757 loss)
I1211 09:22:01.819233 22260 solver.cpp:218] Iteration 134000 (12.622 iter/s, 7.92269s/100 iters), loss = 0.295072
I1211 09:22:01.819233 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:22:01.819233 22260 solver.cpp:237]     Train net output #1: loss = 0.295072 (* 1 = 0.295072 loss)
I1211 09:22:01.819233 22260 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1211 09:22:08.139670 22260 solver.cpp:218] Iteration 134100 (15.8237 iter/s, 6.31962s/100 iters), loss = 0.235366
I1211 09:22:08.139670 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:22:08.139670 22260 solver.cpp:237]     Train net output #1: loss = 0.235367 (* 1 = 0.235367 loss)
I1211 09:22:08.139670 22260 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1211 09:22:14.466128 22260 solver.cpp:218] Iteration 134200 (15.806 iter/s, 6.32671s/100 iters), loss = 0.247629
I1211 09:22:14.466128 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:22:14.466128 22260 solver.cpp:237]     Train net output #1: loss = 0.247629 (* 1 = 0.247629 loss)
I1211 09:22:14.466128 22260 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1211 09:22:20.782233 22260 solver.cpp:218] Iteration 134300 (15.8345 iter/s, 6.31532s/100 iters), loss = 0.238163
I1211 09:22:20.782233 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:22:20.782233 22260 solver.cpp:237]     Train net output #1: loss = 0.238164 (* 1 = 0.238164 loss)
I1211 09:22:20.782233 22260 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1211 09:22:27.091760 22260 solver.cpp:218] Iteration 134400 (15.8513 iter/s, 6.30862s/100 iters), loss = 0.313351
I1211 09:22:27.091760 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:22:27.091760 22260 solver.cpp:237]     Train net output #1: loss = 0.313351 (* 1 = 0.313351 loss)
I1211 09:22:27.091760 22260 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1211 09:22:33.102691 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:22:33.350208 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_134500.caffemodel
I1211 09:22:33.365208 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_134500.solverstate
I1211 09:22:33.369208 22260 solver.cpp:330] Iteration 134500, Testing net (#0)
I1211 09:22:33.369208 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:22:34.882308 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:22:34.941313 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6686
I1211 09:22:34.941313 22260 solver.cpp:397]     Test net output #1: loss = 1.36753 (* 1 = 1.36753 loss)
I1211 09:22:35.001817 22260 solver.cpp:218] Iteration 134500 (12.6427 iter/s, 7.90968s/100 iters), loss = 0.211665
I1211 09:22:35.001817 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:22:35.001817 22260 solver.cpp:237]     Train net output #1: loss = 0.211665 (* 1 = 0.211665 loss)
I1211 09:22:35.001817 22260 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1211 09:22:41.319758 22260 solver.cpp:218] Iteration 134600 (15.8276 iter/s, 6.31806s/100 iters), loss = 0.27877
I1211 09:22:41.319758 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:22:41.319758 22260 solver.cpp:237]     Train net output #1: loss = 0.27877 (* 1 = 0.27877 loss)
I1211 09:22:41.319758 22260 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1211 09:22:47.639242 22260 solver.cpp:218] Iteration 134700 (15.8262 iter/s, 6.31865s/100 iters), loss = 0.217527
I1211 09:22:47.639242 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:22:47.639242 22260 solver.cpp:237]     Train net output #1: loss = 0.217527 (* 1 = 0.217527 loss)
I1211 09:22:47.639242 22260 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1211 09:22:53.964738 22260 solver.cpp:218] Iteration 134800 (15.8085 iter/s, 6.32571s/100 iters), loss = 0.314629
I1211 09:22:53.964738 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:22:53.964738 22260 solver.cpp:237]     Train net output #1: loss = 0.314629 (* 1 = 0.314629 loss)
I1211 09:22:53.964738 22260 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1211 09:23:00.289221 22260 solver.cpp:218] Iteration 134900 (15.8148 iter/s, 6.3232s/100 iters), loss = 0.271303
I1211 09:23:00.289221 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:23:00.289221 22260 solver.cpp:237]     Train net output #1: loss = 0.271303 (* 1 = 0.271303 loss)
I1211 09:23:00.289221 22260 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1211 09:23:06.301719 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:23:06.550731 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_135000.caffemodel
I1211 09:23:06.566735 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_135000.solverstate
I1211 09:23:06.571735 22260 solver.cpp:330] Iteration 135000, Testing net (#0)
I1211 09:23:06.571735 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:23:08.083884 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:23:08.144387 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6683
I1211 09:23:08.144387 22260 solver.cpp:397]     Test net output #1: loss = 1.36201 (* 1 = 1.36201 loss)
I1211 09:23:08.203888 22260 solver.cpp:218] Iteration 135000 (12.6342 iter/s, 7.91503s/100 iters), loss = 0.224888
I1211 09:23:08.203888 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:23:08.203888 22260 solver.cpp:237]     Train net output #1: loss = 0.224888 (* 1 = 0.224888 loss)
I1211 09:23:08.204890 22260 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1211 09:23:14.530354 22260 solver.cpp:218] Iteration 135100 (15.8094 iter/s, 6.32533s/100 iters), loss = 0.28531
I1211 09:23:14.530354 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:23:14.530354 22260 solver.cpp:237]     Train net output #1: loss = 0.28531 (* 1 = 0.28531 loss)
I1211 09:23:14.530354 22260 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1211 09:23:20.857792 22260 solver.cpp:218] Iteration 135200 (15.8056 iter/s, 6.32687s/100 iters), loss = 0.189276
I1211 09:23:20.857792 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:23:20.857792 22260 solver.cpp:237]     Train net output #1: loss = 0.189276 (* 1 = 0.189276 loss)
I1211 09:23:20.857792 22260 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1211 09:23:27.184267 22260 solver.cpp:218] Iteration 135300 (15.8073 iter/s, 6.3262s/100 iters), loss = 0.325411
I1211 09:23:27.184267 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 09:23:27.184267 22260 solver.cpp:237]     Train net output #1: loss = 0.325411 (* 1 = 0.325411 loss)
I1211 09:23:27.184267 22260 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1211 09:23:33.509734 22260 solver.cpp:218] Iteration 135400 (15.8088 iter/s, 6.32558s/100 iters), loss = 0.27734
I1211 09:23:33.509734 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:23:33.509734 22260 solver.cpp:237]     Train net output #1: loss = 0.27734 (* 1 = 0.27734 loss)
I1211 09:23:33.509734 22260 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1211 09:23:39.527210 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:23:39.776231 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_135500.caffemodel
I1211 09:23:39.792230 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_135500.solverstate
I1211 09:23:39.796231 22260 solver.cpp:330] Iteration 135500, Testing net (#0)
I1211 09:23:39.796231 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:23:41.310338 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:23:41.370342 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6697
I1211 09:23:41.370342 22260 solver.cpp:397]     Test net output #1: loss = 1.35201 (* 1 = 1.35201 loss)
I1211 09:23:41.431341 22260 solver.cpp:218] Iteration 135500 (12.6253 iter/s, 7.92063s/100 iters), loss = 0.225005
I1211 09:23:41.431341 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:23:41.431341 22260 solver.cpp:237]     Train net output #1: loss = 0.225005 (* 1 = 0.225005 loss)
I1211 09:23:41.431341 22260 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1211 09:23:47.767868 22260 solver.cpp:218] Iteration 135600 (15.7808 iter/s, 6.33683s/100 iters), loss = 0.193588
I1211 09:23:47.767868 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:23:47.767868 22260 solver.cpp:237]     Train net output #1: loss = 0.193588 (* 1 = 0.193588 loss)
I1211 09:23:47.768868 22260 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1211 09:23:54.103315 22260 solver.cpp:218] Iteration 135700 (15.7858 iter/s, 6.33482s/100 iters), loss = 0.216804
I1211 09:23:54.103315 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:23:54.103315 22260 solver.cpp:237]     Train net output #1: loss = 0.216804 (* 1 = 0.216804 loss)
I1211 09:23:54.103315 22260 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1211 09:24:00.449808 22260 solver.cpp:218] Iteration 135800 (15.7587 iter/s, 6.34572s/100 iters), loss = 0.227205
I1211 09:24:00.449808 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:24:00.449808 22260 solver.cpp:237]     Train net output #1: loss = 0.227205 (* 1 = 0.227205 loss)
I1211 09:24:00.449808 22260 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1211 09:24:06.780217 22260 solver.cpp:218] Iteration 135900 (15.7966 iter/s, 6.33049s/100 iters), loss = 0.252295
I1211 09:24:06.780217 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:24:06.780217 22260 solver.cpp:237]     Train net output #1: loss = 0.252295 (* 1 = 0.252295 loss)
I1211 09:24:06.780217 22260 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1211 09:24:12.805605 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:24:13.057117 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_136000.caffemodel
I1211 09:24:13.072118 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_136000.solverstate
I1211 09:24:13.076618 22260 solver.cpp:330] Iteration 136000, Testing net (#0)
I1211 09:24:13.076618 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:24:14.590222 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:24:14.649724 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6676
I1211 09:24:14.649724 22260 solver.cpp:397]     Test net output #1: loss = 1.36564 (* 1 = 1.36564 loss)
I1211 09:24:14.709728 22260 solver.cpp:218] Iteration 136000 (12.6118 iter/s, 7.9291s/100 iters), loss = 0.244698
I1211 09:24:14.710729 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:24:14.710729 22260 solver.cpp:237]     Train net output #1: loss = 0.244698 (* 1 = 0.244698 loss)
I1211 09:24:14.710729 22260 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1211 09:24:21.036221 22260 solver.cpp:218] Iteration 136100 (15.81 iter/s, 6.32513s/100 iters), loss = 0.191911
I1211 09:24:21.036221 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:24:21.036221 22260 solver.cpp:237]     Train net output #1: loss = 0.191912 (* 1 = 0.191912 loss)
I1211 09:24:21.036221 22260 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1211 09:24:27.362692 22260 solver.cpp:218] Iteration 136200 (15.8054 iter/s, 6.32697s/100 iters), loss = 0.186963
I1211 09:24:27.363692 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:24:27.363692 22260 solver.cpp:237]     Train net output #1: loss = 0.186964 (* 1 = 0.186964 loss)
I1211 09:24:27.363692 22260 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1211 09:24:33.680155 22260 solver.cpp:218] Iteration 136300 (15.8311 iter/s, 6.31669s/100 iters), loss = 0.265844
I1211 09:24:33.680155 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:24:33.680155 22260 solver.cpp:237]     Train net output #1: loss = 0.265844 (* 1 = 0.265844 loss)
I1211 09:24:33.680155 22260 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1211 09:24:40.002651 22260 solver.cpp:218] Iteration 136400 (15.8178 iter/s, 6.32199s/100 iters), loss = 0.276241
I1211 09:24:40.002651 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:24:40.002651 22260 solver.cpp:237]     Train net output #1: loss = 0.276241 (* 1 = 0.276241 loss)
I1211 09:24:40.002651 22260 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1211 09:24:46.011101 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:24:46.260128 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_136500.caffemodel
I1211 09:24:46.275127 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_136500.solverstate
I1211 09:24:46.279127 22260 solver.cpp:330] Iteration 136500, Testing net (#0)
I1211 09:24:46.279127 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:24:47.794270 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:24:47.854271 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6718
I1211 09:24:47.854271 22260 solver.cpp:397]     Test net output #1: loss = 1.35657 (* 1 = 1.35657 loss)
I1211 09:24:47.915277 22260 solver.cpp:218] Iteration 136500 (12.6394 iter/s, 7.91174s/100 iters), loss = 0.25994
I1211 09:24:47.915277 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:24:47.915277 22260 solver.cpp:237]     Train net output #1: loss = 0.25994 (* 1 = 0.25994 loss)
I1211 09:24:47.915277 22260 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1211 09:24:54.245762 22260 solver.cpp:218] Iteration 136600 (15.7963 iter/s, 6.3306s/100 iters), loss = 0.230292
I1211 09:24:54.245762 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:24:54.245762 22260 solver.cpp:237]     Train net output #1: loss = 0.230292 (* 1 = 0.230292 loss)
I1211 09:24:54.245762 22260 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1211 09:25:00.577190 22260 solver.cpp:218] Iteration 136700 (15.7947 iter/s, 6.33125s/100 iters), loss = 0.179697
I1211 09:25:00.577190 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 09:25:00.578191 22260 solver.cpp:237]     Train net output #1: loss = 0.179697 (* 1 = 0.179697 loss)
I1211 09:25:00.578191 22260 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1211 09:25:06.908700 22260 solver.cpp:218] Iteration 136800 (15.7972 iter/s, 6.33022s/100 iters), loss = 0.295309
I1211 09:25:06.908700 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 09:25:06.908700 22260 solver.cpp:237]     Train net output #1: loss = 0.295309 (* 1 = 0.295309 loss)
I1211 09:25:06.908700 22260 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1211 09:25:13.239179 22260 solver.cpp:218] Iteration 136900 (15.7966 iter/s, 6.33046s/100 iters), loss = 0.239951
I1211 09:25:13.239179 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:25:13.239179 22260 solver.cpp:237]     Train net output #1: loss = 0.239951 (* 1 = 0.239951 loss)
I1211 09:25:13.239179 22260 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1211 09:25:19.255594 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:25:19.505609 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_137000.caffemodel
I1211 09:25:19.519609 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_137000.solverstate
I1211 09:25:19.524610 22260 solver.cpp:330] Iteration 137000, Testing net (#0)
I1211 09:25:19.524610 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:25:21.038085 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:25:21.098090 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6692
I1211 09:25:21.098090 22260 solver.cpp:397]     Test net output #1: loss = 1.37205 (* 1 = 1.37205 loss)
I1211 09:25:21.159093 22260 solver.cpp:218] Iteration 137000 (12.6271 iter/s, 7.91948s/100 iters), loss = 0.281624
I1211 09:25:21.159093 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:25:21.159093 22260 solver.cpp:237]     Train net output #1: loss = 0.281624 (* 1 = 0.281624 loss)
I1211 09:25:21.159093 22260 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1211 09:25:27.497021 22260 solver.cpp:218] Iteration 137100 (15.7806 iter/s, 6.3369s/100 iters), loss = 0.210049
I1211 09:25:27.497021 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 09:25:27.497021 22260 solver.cpp:237]     Train net output #1: loss = 0.21005 (* 1 = 0.21005 loss)
I1211 09:25:27.497021 22260 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1211 09:25:33.833016 22260 solver.cpp:218] Iteration 137200 (15.7819 iter/s, 6.33637s/100 iters), loss = 0.199963
I1211 09:25:33.833016 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:25:33.833016 22260 solver.cpp:237]     Train net output #1: loss = 0.199964 (* 1 = 0.199964 loss)
I1211 09:25:33.833016 22260 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1211 09:25:40.164497 22260 solver.cpp:218] Iteration 137300 (15.7964 iter/s, 6.33056s/100 iters), loss = 0.25301
I1211 09:25:40.164497 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:25:40.164497 22260 solver.cpp:237]     Train net output #1: loss = 0.25301 (* 1 = 0.25301 loss)
I1211 09:25:40.164497 22260 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1211 09:25:46.500949 22260 solver.cpp:218] Iteration 137400 (15.7825 iter/s, 6.33612s/100 iters), loss = 0.246416
I1211 09:25:46.500949 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:25:46.500949 22260 solver.cpp:237]     Train net output #1: loss = 0.246417 (* 1 = 0.246417 loss)
I1211 09:25:46.500949 22260 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1211 09:25:52.526424 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:25:52.774442 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_137500.caffemodel
I1211 09:25:52.789443 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_137500.solverstate
I1211 09:25:52.793442 22260 solver.cpp:330] Iteration 137500, Testing net (#0)
I1211 09:25:52.793442 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:25:54.307543 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:25:54.367552 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6702
I1211 09:25:54.367552 22260 solver.cpp:397]     Test net output #1: loss = 1.37262 (* 1 = 1.37262 loss)
I1211 09:25:54.428550 22260 solver.cpp:218] Iteration 137500 (12.6154 iter/s, 7.92681s/100 iters), loss = 0.249558
I1211 09:25:54.428550 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:25:54.428550 22260 solver.cpp:237]     Train net output #1: loss = 0.249558 (* 1 = 0.249558 loss)
I1211 09:25:54.428550 22260 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1211 09:26:00.760995 22260 solver.cpp:218] Iteration 137600 (15.7907 iter/s, 6.33285s/100 iters), loss = 0.252153
I1211 09:26:00.761996 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:26:00.761996 22260 solver.cpp:237]     Train net output #1: loss = 0.252153 (* 1 = 0.252153 loss)
I1211 09:26:00.761996 22260 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1211 09:26:07.095460 22260 solver.cpp:218] Iteration 137700 (15.7879 iter/s, 6.33398s/100 iters), loss = 0.200128
I1211 09:26:07.095460 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:26:07.095460 22260 solver.cpp:237]     Train net output #1: loss = 0.200129 (* 1 = 0.200129 loss)
I1211 09:26:07.095460 22260 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1211 09:26:13.433925 22260 solver.cpp:218] Iteration 137800 (15.7787 iter/s, 6.33764s/100 iters), loss = 0.242687
I1211 09:26:13.433925 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:26:13.433925 22260 solver.cpp:237]     Train net output #1: loss = 0.242687 (* 1 = 0.242687 loss)
I1211 09:26:13.433925 22260 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1211 09:26:19.766372 22260 solver.cpp:218] Iteration 137900 (15.7934 iter/s, 6.33174s/100 iters), loss = 0.373152
I1211 09:26:19.766372 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:26:19.766372 22260 solver.cpp:237]     Train net output #1: loss = 0.373152 (* 1 = 0.373152 loss)
I1211 09:26:19.766372 22260 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1211 09:26:25.787778 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:26:26.036803 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_138000.caffemodel
I1211 09:26:26.051806 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_138000.solverstate
I1211 09:26:26.055806 22260 solver.cpp:330] Iteration 138000, Testing net (#0)
I1211 09:26:26.055806 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:26:27.567908 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:26:27.627907 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6703
I1211 09:26:27.627907 22260 solver.cpp:397]     Test net output #1: loss = 1.37619 (* 1 = 1.37619 loss)
I1211 09:26:27.688915 22260 solver.cpp:218] Iteration 138000 (12.6227 iter/s, 7.92225s/100 iters), loss = 0.218754
I1211 09:26:27.688915 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:26:27.688915 22260 solver.cpp:237]     Train net output #1: loss = 0.218754 (* 1 = 0.218754 loss)
I1211 09:26:27.688915 22260 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1211 09:26:34.018409 22260 solver.cpp:218] Iteration 138100 (15.8002 iter/s, 6.32904s/100 iters), loss = 0.219752
I1211 09:26:34.018409 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:26:34.018409 22260 solver.cpp:237]     Train net output #1: loss = 0.219752 (* 1 = 0.219752 loss)
I1211 09:26:34.018409 22260 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1211 09:26:40.346405 22260 solver.cpp:218] Iteration 138200 (15.8036 iter/s, 6.32767s/100 iters), loss = 0.277118
I1211 09:26:40.346905 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:26:40.346905 22260 solver.cpp:237]     Train net output #1: loss = 0.277118 (* 1 = 0.277118 loss)
I1211 09:26:40.346905 22260 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1211 09:26:46.709640 22260 solver.cpp:218] Iteration 138300 (15.7176 iter/s, 6.36231s/100 iters), loss = 0.23729
I1211 09:26:46.709640 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:26:46.709640 22260 solver.cpp:237]     Train net output #1: loss = 0.23729 (* 1 = 0.23729 loss)
I1211 09:26:46.709640 22260 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1211 09:26:53.052063 22260 solver.cpp:218] Iteration 138400 (15.7679 iter/s, 6.34199s/100 iters), loss = 0.226326
I1211 09:26:53.052063 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 09:26:53.052063 22260 solver.cpp:237]     Train net output #1: loss = 0.226327 (* 1 = 0.226327 loss)
I1211 09:26:53.052063 22260 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1211 09:26:59.074492 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:26:59.323508 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_138500.caffemodel
I1211 09:26:59.338508 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_138500.solverstate
I1211 09:26:59.343508 22260 solver.cpp:330] Iteration 138500, Testing net (#0)
I1211 09:26:59.343508 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:27:00.863083 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:27:00.922586 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6698
I1211 09:27:00.922586 22260 solver.cpp:397]     Test net output #1: loss = 1.35993 (* 1 = 1.35993 loss)
I1211 09:27:00.983590 22260 solver.cpp:218] Iteration 138500 (12.6076 iter/s, 7.9317s/100 iters), loss = 0.267813
I1211 09:27:00.983590 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:27:00.983590 22260 solver.cpp:237]     Train net output #1: loss = 0.267813 (* 1 = 0.267813 loss)
I1211 09:27:00.983590 22260 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1211 09:27:07.311027 22260 solver.cpp:218] Iteration 138600 (15.8049 iter/s, 6.32717s/100 iters), loss = 0.189527
I1211 09:27:07.311027 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:27:07.311027 22260 solver.cpp:237]     Train net output #1: loss = 0.189527 (* 1 = 0.189527 loss)
I1211 09:27:07.311027 22260 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1211 09:27:13.634534 22260 solver.cpp:218] Iteration 138700 (15.8153 iter/s, 6.32299s/100 iters), loss = 0.260307
I1211 09:27:13.634534 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:27:13.634534 22260 solver.cpp:237]     Train net output #1: loss = 0.260307 (* 1 = 0.260307 loss)
I1211 09:27:13.634534 22260 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1211 09:27:19.964052 22260 solver.cpp:218] Iteration 138800 (15.8018 iter/s, 6.32841s/100 iters), loss = 0.219039
I1211 09:27:19.964052 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:27:19.964052 22260 solver.cpp:237]     Train net output #1: loss = 0.219039 (* 1 = 0.219039 loss)
I1211 09:27:19.964052 22260 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1211 09:27:26.296564 22260 solver.cpp:218] Iteration 138900 (15.7927 iter/s, 6.33202s/100 iters), loss = 0.274067
I1211 09:27:26.296564 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:27:26.296564 22260 solver.cpp:237]     Train net output #1: loss = 0.274067 (* 1 = 0.274067 loss)
I1211 09:27:26.296564 22260 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1211 09:27:32.314281 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:27:32.564294 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_139000.caffemodel
I1211 09:27:32.578297 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_139000.solverstate
I1211 09:27:32.582298 22260 solver.cpp:330] Iteration 139000, Testing net (#0)
I1211 09:27:32.583297 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:27:34.099357 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:27:34.159359 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6728
I1211 09:27:34.159359 22260 solver.cpp:397]     Test net output #1: loss = 1.36772 (* 1 = 1.36772 loss)
I1211 09:27:34.220362 22260 solver.cpp:218] Iteration 139000 (12.6208 iter/s, 7.92341s/100 iters), loss = 0.233616
I1211 09:27:34.220362 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:27:34.220362 22260 solver.cpp:237]     Train net output #1: loss = 0.233616 (* 1 = 0.233616 loss)
I1211 09:27:34.220362 22260 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1211 09:27:40.547857 22260 solver.cpp:218] Iteration 139100 (15.8044 iter/s, 6.32736s/100 iters), loss = 0.276196
I1211 09:27:40.547857 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:27:40.547857 22260 solver.cpp:237]     Train net output #1: loss = 0.276196 (* 1 = 0.276196 loss)
I1211 09:27:40.547857 22260 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1211 09:27:46.882346 22260 solver.cpp:218] Iteration 139200 (15.7873 iter/s, 6.33419s/100 iters), loss = 0.231087
I1211 09:27:46.882346 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:27:46.882346 22260 solver.cpp:237]     Train net output #1: loss = 0.231087 (* 1 = 0.231087 loss)
I1211 09:27:46.882346 22260 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1211 09:27:53.217819 22260 solver.cpp:218] Iteration 139300 (15.7857 iter/s, 6.33485s/100 iters), loss = 0.332711
I1211 09:27:53.217819 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:27:53.217819 22260 solver.cpp:237]     Train net output #1: loss = 0.332711 (* 1 = 0.332711 loss)
I1211 09:27:53.217819 22260 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1211 09:27:59.546275 22260 solver.cpp:218] Iteration 139400 (15.8017 iter/s, 6.32843s/100 iters), loss = 0.310223
I1211 09:27:59.546275 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:27:59.546275 22260 solver.cpp:237]     Train net output #1: loss = 0.310223 (* 1 = 0.310223 loss)
I1211 09:27:59.546275 22260 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1211 09:28:05.564741 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:28:05.814255 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_139500.caffemodel
I1211 09:28:05.830256 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_139500.solverstate
I1211 09:28:05.834754 22260 solver.cpp:330] Iteration 139500, Testing net (#0)
I1211 09:28:05.834754 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:28:07.344851 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:28:07.404851 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6684
I1211 09:28:07.404851 22260 solver.cpp:397]     Test net output #1: loss = 1.37383 (* 1 = 1.37383 loss)
I1211 09:28:07.466857 22260 solver.cpp:218] Iteration 139500 (12.6272 iter/s, 7.91943s/100 iters), loss = 0.199349
I1211 09:28:07.466857 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:28:07.466857 22260 solver.cpp:237]     Train net output #1: loss = 0.199349 (* 1 = 0.199349 loss)
I1211 09:28:07.466857 22260 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1211 09:28:13.803306 22260 solver.cpp:218] Iteration 139600 (15.7827 iter/s, 6.33604s/100 iters), loss = 0.240715
I1211 09:28:13.803306 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:28:13.803306 22260 solver.cpp:237]     Train net output #1: loss = 0.240716 (* 1 = 0.240716 loss)
I1211 09:28:13.803306 22260 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1211 09:28:20.132292 22260 solver.cpp:218] Iteration 139700 (15.8012 iter/s, 6.32862s/100 iters), loss = 0.203701
I1211 09:28:20.132292 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:28:20.132292 22260 solver.cpp:237]     Train net output #1: loss = 0.203702 (* 1 = 0.203702 loss)
I1211 09:28:20.132292 22260 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1211 09:28:26.460575 22260 solver.cpp:218] Iteration 139800 (15.8025 iter/s, 6.32809s/100 iters), loss = 0.290721
I1211 09:28:26.460575 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:28:26.460575 22260 solver.cpp:237]     Train net output #1: loss = 0.290721 (* 1 = 0.290721 loss)
I1211 09:28:26.460575 22260 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1211 09:28:32.780074 22260 solver.cpp:218] Iteration 139900 (15.8249 iter/s, 6.31914s/100 iters), loss = 0.273713
I1211 09:28:32.780074 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:28:32.780074 22260 solver.cpp:237]     Train net output #1: loss = 0.273713 (* 1 = 0.273713 loss)
I1211 09:28:32.780074 22260 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1211 09:28:38.807484 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:28:39.058495 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_140000.caffemodel
I1211 09:28:39.072497 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_140000.solverstate
I1211 09:28:39.077498 22260 solver.cpp:330] Iteration 140000, Testing net (#0)
I1211 09:28:39.077498 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:28:40.590600 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:28:40.650609 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6679
I1211 09:28:40.650609 22260 solver.cpp:397]     Test net output #1: loss = 1.37442 (* 1 = 1.37442 loss)
I1211 09:28:40.711109 22260 solver.cpp:218] Iteration 140000 (12.6099 iter/s, 7.93031s/100 iters), loss = 0.251452
I1211 09:28:40.711109 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:28:40.711109 22260 solver.cpp:237]     Train net output #1: loss = 0.251452 (* 1 = 0.251452 loss)
I1211 09:28:40.711109 22260 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1211 09:28:47.022109 22260 solver.cpp:218] Iteration 140100 (15.8462 iter/s, 6.31068s/100 iters), loss = 0.233498
I1211 09:28:47.022109 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:28:47.022109 22260 solver.cpp:237]     Train net output #1: loss = 0.233498 (* 1 = 0.233498 loss)
I1211 09:28:47.022109 22260 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1211 09:28:53.338593 22260 solver.cpp:218] Iteration 140200 (15.8321 iter/s, 6.31628s/100 iters), loss = 0.188648
I1211 09:28:53.338593 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:28:53.338593 22260 solver.cpp:237]     Train net output #1: loss = 0.188648 (* 1 = 0.188648 loss)
I1211 09:28:53.338593 22260 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1211 09:28:59.657058 22260 solver.cpp:218] Iteration 140300 (15.8281 iter/s, 6.31787s/100 iters), loss = 0.203141
I1211 09:28:59.657058 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:28:59.657058 22260 solver.cpp:237]     Train net output #1: loss = 0.203142 (* 1 = 0.203142 loss)
I1211 09:28:59.657058 22260 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1211 09:29:05.980463 22260 solver.cpp:218] Iteration 140400 (15.8149 iter/s, 6.32317s/100 iters), loss = 0.242423
I1211 09:29:05.980463 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:29:05.980463 22260 solver.cpp:237]     Train net output #1: loss = 0.242423 (* 1 = 0.242423 loss)
I1211 09:29:05.980463 22260 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1211 09:29:11.995882 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:29:12.243916 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_140500.caffemodel
I1211 09:29:12.259917 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_140500.solverstate
I1211 09:29:12.263916 22260 solver.cpp:330] Iteration 140500, Testing net (#0)
I1211 09:29:12.264917 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:29:13.777019 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:29:13.837028 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6707
I1211 09:29:13.837028 22260 solver.cpp:397]     Test net output #1: loss = 1.37702 (* 1 = 1.37702 loss)
I1211 09:29:13.897027 22260 solver.cpp:218] Iteration 140500 (12.6323 iter/s, 7.9162s/100 iters), loss = 0.166707
I1211 09:29:13.897027 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:29:13.897027 22260 solver.cpp:237]     Train net output #1: loss = 0.166707 (* 1 = 0.166707 loss)
I1211 09:29:13.897027 22260 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1211 09:29:20.221988 22260 solver.cpp:218] Iteration 140600 (15.8123 iter/s, 6.32419s/100 iters), loss = 0.23884
I1211 09:29:20.221988 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:29:20.222489 22260 solver.cpp:237]     Train net output #1: loss = 0.23884 (* 1 = 0.23884 loss)
I1211 09:29:20.222489 22260 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1211 09:29:26.543089 22260 solver.cpp:218] Iteration 140700 (15.8223 iter/s, 6.32018s/100 iters), loss = 0.227114
I1211 09:29:26.543089 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:29:26.543089 22260 solver.cpp:237]     Train net output #1: loss = 0.227114 (* 1 = 0.227114 loss)
I1211 09:29:26.543089 22260 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1211 09:29:32.865489 22260 solver.cpp:218] Iteration 140800 (15.8163 iter/s, 6.32258s/100 iters), loss = 0.236187
I1211 09:29:32.865489 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:29:32.865489 22260 solver.cpp:237]     Train net output #1: loss = 0.236188 (* 1 = 0.236188 loss)
I1211 09:29:32.865489 22260 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1211 09:29:39.189910 22260 solver.cpp:218] Iteration 140900 (15.8129 iter/s, 6.32396s/100 iters), loss = 0.223423
I1211 09:29:39.189910 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:29:39.189910 22260 solver.cpp:237]     Train net output #1: loss = 0.223423 (* 1 = 0.223423 loss)
I1211 09:29:39.189910 22260 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1211 09:29:45.192327 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:29:45.440362 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_141000.caffemodel
I1211 09:29:45.455363 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_141000.solverstate
I1211 09:29:45.459363 22260 solver.cpp:330] Iteration 141000, Testing net (#0)
I1211 09:29:45.459363 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:29:46.971453 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:29:47.031457 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6607
I1211 09:29:47.031457 22260 solver.cpp:397]     Test net output #1: loss = 1.40643 (* 1 = 1.40643 loss)
I1211 09:29:47.092456 22260 solver.cpp:218] Iteration 141000 (12.6556 iter/s, 7.90165s/100 iters), loss = 0.235237
I1211 09:29:47.092456 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:29:47.092456 22260 solver.cpp:237]     Train net output #1: loss = 0.235237 (* 1 = 0.235237 loss)
I1211 09:29:47.092456 22260 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1211 09:29:53.425879 22260 solver.cpp:218] Iteration 141100 (15.7897 iter/s, 6.33323s/100 iters), loss = 0.206159
I1211 09:29:53.425879 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:29:53.425879 22260 solver.cpp:237]     Train net output #1: loss = 0.206159 (* 1 = 0.206159 loss)
I1211 09:29:53.425879 22260 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1211 09:29:59.750325 22260 solver.cpp:218] Iteration 141200 (15.8122 iter/s, 6.32424s/100 iters), loss = 0.255934
I1211 09:29:59.750325 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:29:59.750325 22260 solver.cpp:237]     Train net output #1: loss = 0.255935 (* 1 = 0.255935 loss)
I1211 09:29:59.750325 22260 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1211 09:30:06.076877 22260 solver.cpp:218] Iteration 141300 (15.8067 iter/s, 6.32642s/100 iters), loss = 0.260393
I1211 09:30:06.076877 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:30:06.076877 22260 solver.cpp:237]     Train net output #1: loss = 0.260393 (* 1 = 0.260393 loss)
I1211 09:30:06.076877 22260 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1211 09:30:12.407340 22260 solver.cpp:218] Iteration 141400 (15.798 iter/s, 6.32992s/100 iters), loss = 0.233353
I1211 09:30:12.407340 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:30:12.407340 22260 solver.cpp:237]     Train net output #1: loss = 0.233354 (* 1 = 0.233354 loss)
I1211 09:30:12.407340 22260 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1211 09:30:18.433773 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:30:18.682782 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_141500.caffemodel
I1211 09:30:18.697783 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_141500.solverstate
I1211 09:30:18.702785 22260 solver.cpp:330] Iteration 141500, Testing net (#0)
I1211 09:30:18.702785 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:30:20.215399 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:30:20.274902 22260 solver.cpp:397]     Test net output #0: accuracy = 0.666
I1211 09:30:20.274902 22260 solver.cpp:397]     Test net output #1: loss = 1.37361 (* 1 = 1.37361 loss)
I1211 09:30:20.335906 22260 solver.cpp:218] Iteration 141500 (12.6132 iter/s, 7.92818s/100 iters), loss = 0.224942
I1211 09:30:20.335906 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:30:20.335906 22260 solver.cpp:237]     Train net output #1: loss = 0.224942 (* 1 = 0.224942 loss)
I1211 09:30:20.335906 22260 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1211 09:30:26.658375 22260 solver.cpp:218] Iteration 141600 (15.8189 iter/s, 6.32156s/100 iters), loss = 0.30524
I1211 09:30:26.658375 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:30:26.658375 22260 solver.cpp:237]     Train net output #1: loss = 0.30524 (* 1 = 0.30524 loss)
I1211 09:30:26.658375 22260 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1211 09:30:32.989800 22260 solver.cpp:218] Iteration 141700 (15.7939 iter/s, 6.33158s/100 iters), loss = 0.214704
I1211 09:30:32.990808 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 09:30:32.990808 22260 solver.cpp:237]     Train net output #1: loss = 0.214704 (* 1 = 0.214704 loss)
I1211 09:30:32.990808 22260 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1211 09:30:39.319696 22260 solver.cpp:218] Iteration 141800 (15.8006 iter/s, 6.32888s/100 iters), loss = 0.326444
I1211 09:30:39.319696 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 09:30:39.319696 22260 solver.cpp:237]     Train net output #1: loss = 0.326445 (* 1 = 0.326445 loss)
I1211 09:30:39.319696 22260 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1211 09:30:45.657781 22260 solver.cpp:218] Iteration 141900 (15.7797 iter/s, 6.33726s/100 iters), loss = 0.238192
I1211 09:30:45.657781 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:30:45.657781 22260 solver.cpp:237]     Train net output #1: loss = 0.238192 (* 1 = 0.238192 loss)
I1211 09:30:45.657781 22260 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1211 09:30:51.685277 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:30:51.935289 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_142000.caffemodel
I1211 09:30:51.950289 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_142000.solverstate
I1211 09:30:51.954289 22260 solver.cpp:330] Iteration 142000, Testing net (#0)
I1211 09:30:51.954289 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:30:53.466399 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:30:53.526402 22260 solver.cpp:397]     Test net output #0: accuracy = 0.666
I1211 09:30:53.526402 22260 solver.cpp:397]     Test net output #1: loss = 1.3775 (* 1 = 1.3775 loss)
I1211 09:30:53.586405 22260 solver.cpp:218] Iteration 142000 (12.6121 iter/s, 7.92889s/100 iters), loss = 0.211283
I1211 09:30:53.586405 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:30:53.586405 22260 solver.cpp:237]     Train net output #1: loss = 0.211283 (* 1 = 0.211283 loss)
I1211 09:30:53.586405 22260 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1211 09:30:59.917915 22260 solver.cpp:218] Iteration 142100 (15.795 iter/s, 6.33113s/100 iters), loss = 0.20118
I1211 09:30:59.917915 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:30:59.917915 22260 solver.cpp:237]     Train net output #1: loss = 0.20118 (* 1 = 0.20118 loss)
I1211 09:30:59.917915 22260 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1211 09:31:06.236399 22260 solver.cpp:218] Iteration 142200 (15.8281 iter/s, 6.31786s/100 iters), loss = 0.219623
I1211 09:31:06.236399 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:31:06.236399 22260 solver.cpp:237]     Train net output #1: loss = 0.219623 (* 1 = 0.219623 loss)
I1211 09:31:06.236399 22260 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1211 09:31:12.562432 22260 solver.cpp:218] Iteration 142300 (15.8098 iter/s, 6.32519s/100 iters), loss = 0.286415
I1211 09:31:12.562432 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:31:12.562432 22260 solver.cpp:237]     Train net output #1: loss = 0.286415 (* 1 = 0.286415 loss)
I1211 09:31:12.562432 22260 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1211 09:31:18.886754 22260 solver.cpp:218] Iteration 142400 (15.8113 iter/s, 6.32459s/100 iters), loss = 0.302176
I1211 09:31:18.886754 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:31:18.886754 22260 solver.cpp:237]     Train net output #1: loss = 0.302176 (* 1 = 0.302176 loss)
I1211 09:31:18.886754 22260 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1211 09:31:24.895184 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:31:25.145195 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_142500.caffemodel
I1211 09:31:25.163698 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_142500.solverstate
I1211 09:31:25.168697 22260 solver.cpp:330] Iteration 142500, Testing net (#0)
I1211 09:31:25.168697 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:31:26.680315 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:31:26.740314 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6662
I1211 09:31:26.740314 22260 solver.cpp:397]     Test net output #1: loss = 1.4036 (* 1 = 1.4036 loss)
I1211 09:31:26.801319 22260 solver.cpp:218] Iteration 142500 (12.6369 iter/s, 7.91333s/100 iters), loss = 0.378249
I1211 09:31:26.801319 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 09:31:26.801319 22260 solver.cpp:237]     Train net output #1: loss = 0.378249 (* 1 = 0.378249 loss)
I1211 09:31:26.801319 22260 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1211 09:31:33.129820 22260 solver.cpp:218] Iteration 142600 (15.8021 iter/s, 6.32827s/100 iters), loss = 0.278893
I1211 09:31:33.129820 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:31:33.129820 22260 solver.cpp:237]     Train net output #1: loss = 0.278894 (* 1 = 0.278894 loss)
I1211 09:31:33.129820 22260 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1211 09:31:39.462354 22260 solver.cpp:218] Iteration 142700 (15.7915 iter/s, 6.33252s/100 iters), loss = 0.19733
I1211 09:31:39.462354 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 09:31:39.462354 22260 solver.cpp:237]     Train net output #1: loss = 0.19733 (* 1 = 0.19733 loss)
I1211 09:31:39.462354 22260 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1211 09:31:45.792794 22260 solver.cpp:218] Iteration 142800 (15.7983 iter/s, 6.32979s/100 iters), loss = 0.227342
I1211 09:31:45.792794 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:31:45.792794 22260 solver.cpp:237]     Train net output #1: loss = 0.227342 (* 1 = 0.227342 loss)
I1211 09:31:45.792794 22260 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1211 09:31:52.124287 22260 solver.cpp:218] Iteration 142900 (15.7944 iter/s, 6.33134s/100 iters), loss = 0.328691
I1211 09:31:52.124287 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:31:52.124287 22260 solver.cpp:237]     Train net output #1: loss = 0.328692 (* 1 = 0.328692 loss)
I1211 09:31:52.124287 22260 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1211 09:31:58.144755 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:31:58.393782 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_143000.caffemodel
I1211 09:31:58.408782 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_143000.solverstate
I1211 09:31:58.413784 22260 solver.cpp:330] Iteration 143000, Testing net (#0)
I1211 09:31:58.413784 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:31:59.925915 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:31:59.985920 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6656
I1211 09:31:59.985920 22260 solver.cpp:397]     Test net output #1: loss = 1.40203 (* 1 = 1.40203 loss)
I1211 09:32:00.045918 22260 solver.cpp:218] Iteration 143000 (12.6243 iter/s, 7.92124s/100 iters), loss = 0.207438
I1211 09:32:00.045918 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:32:00.045918 22260 solver.cpp:237]     Train net output #1: loss = 0.207439 (* 1 = 0.207439 loss)
I1211 09:32:00.046922 22260 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1211 09:32:06.375965 22260 solver.cpp:218] Iteration 143100 (15.8007 iter/s, 6.32885s/100 iters), loss = 0.322617
I1211 09:32:06.375965 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 09:32:06.375965 22260 solver.cpp:237]     Train net output #1: loss = 0.322617 (* 1 = 0.322617 loss)
I1211 09:32:06.375965 22260 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1211 09:32:12.700966 22260 solver.cpp:218] Iteration 143200 (15.8103 iter/s, 6.325s/100 iters), loss = 0.2029
I1211 09:32:12.700966 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:32:12.700966 22260 solver.cpp:237]     Train net output #1: loss = 0.2029 (* 1 = 0.2029 loss)
I1211 09:32:12.700966 22260 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1211 09:32:19.031473 22260 solver.cpp:218] Iteration 143300 (15.7981 iter/s, 6.32988s/100 iters), loss = 0.242704
I1211 09:32:19.031473 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:32:19.031473 22260 solver.cpp:237]     Train net output #1: loss = 0.242704 (* 1 = 0.242704 loss)
I1211 09:32:19.031473 22260 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1211 09:32:25.361042 22260 solver.cpp:218] Iteration 143400 (15.8012 iter/s, 6.32862s/100 iters), loss = 0.267901
I1211 09:32:25.361042 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:32:25.361042 22260 solver.cpp:237]     Train net output #1: loss = 0.267902 (* 1 = 0.267902 loss)
I1211 09:32:25.361042 22260 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1211 09:32:31.374480 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:32:31.623495 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_143500.caffemodel
I1211 09:32:31.638496 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_143500.solverstate
I1211 09:32:31.642496 22260 solver.cpp:330] Iteration 143500, Testing net (#0)
I1211 09:32:31.643497 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:32:33.154588 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:32:33.214599 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6649
I1211 09:32:33.214599 22260 solver.cpp:397]     Test net output #1: loss = 1.38865 (* 1 = 1.38865 loss)
I1211 09:32:33.275600 22260 solver.cpp:218] Iteration 143500 (12.6356 iter/s, 7.91414s/100 iters), loss = 0.21257
I1211 09:32:33.275600 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 09:32:33.275600 22260 solver.cpp:237]     Train net output #1: loss = 0.21257 (* 1 = 0.21257 loss)
I1211 09:32:33.275600 22260 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1211 09:32:39.603560 22260 solver.cpp:218] Iteration 143600 (15.8042 iter/s, 6.32745s/100 iters), loss = 0.223456
I1211 09:32:39.603560 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:32:39.603560 22260 solver.cpp:237]     Train net output #1: loss = 0.223456 (* 1 = 0.223456 loss)
I1211 09:32:39.603560 22260 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1211 09:32:45.939591 22260 solver.cpp:218] Iteration 143700 (15.7835 iter/s, 6.33573s/100 iters), loss = 0.174206
I1211 09:32:45.939591 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:32:45.939591 22260 solver.cpp:237]     Train net output #1: loss = 0.174206 (* 1 = 0.174206 loss)
I1211 09:32:45.939591 22260 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1211 09:32:52.264325 22260 solver.cpp:218] Iteration 143800 (15.8109 iter/s, 6.32476s/100 iters), loss = 0.256368
I1211 09:32:52.264325 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 09:32:52.264325 22260 solver.cpp:237]     Train net output #1: loss = 0.256368 (* 1 = 0.256368 loss)
I1211 09:32:52.264325 22260 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1211 09:32:58.591770 22260 solver.cpp:218] Iteration 143900 (15.8061 iter/s, 6.32666s/100 iters), loss = 0.273416
I1211 09:32:58.591770 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:32:58.591770 22260 solver.cpp:237]     Train net output #1: loss = 0.273417 (* 1 = 0.273417 loss)
I1211 09:32:58.591770 22260 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1211 09:33:04.618163 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:33:04.867179 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_144000.caffemodel
I1211 09:33:04.882179 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_144000.solverstate
I1211 09:33:04.887179 22260 solver.cpp:330] Iteration 144000, Testing net (#0)
I1211 09:33:04.887179 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:33:06.400270 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:33:06.460274 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6654
I1211 09:33:06.460274 22260 solver.cpp:397]     Test net output #1: loss = 1.40294 (* 1 = 1.40294 loss)
I1211 09:33:06.520273 22260 solver.cpp:218] Iteration 144000 (12.6127 iter/s, 7.9285s/100 iters), loss = 0.234791
I1211 09:33:06.520273 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:33:06.520273 22260 solver.cpp:237]     Train net output #1: loss = 0.234791 (* 1 = 0.234791 loss)
I1211 09:33:06.520273 22260 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1211 09:33:12.857777 22260 solver.cpp:218] Iteration 144100 (15.7822 iter/s, 6.33626s/100 iters), loss = 0.206542
I1211 09:33:12.857777 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:33:12.857777 22260 solver.cpp:237]     Train net output #1: loss = 0.206542 (* 1 = 0.206542 loss)
I1211 09:33:12.857777 22260 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1211 09:33:19.194074 22260 solver.cpp:218] Iteration 144200 (15.7818 iter/s, 6.33642s/100 iters), loss = 0.207189
I1211 09:33:19.194074 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 09:33:19.194074 22260 solver.cpp:237]     Train net output #1: loss = 0.20719 (* 1 = 0.20719 loss)
I1211 09:33:19.194074 22260 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1211 09:33:25.526494 22260 solver.cpp:218] Iteration 144300 (15.793 iter/s, 6.33192s/100 iters), loss = 0.2526
I1211 09:33:25.526494 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:33:25.526494 22260 solver.cpp:237]     Train net output #1: loss = 0.2526 (* 1 = 0.2526 loss)
I1211 09:33:25.526494 22260 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1211 09:33:31.855425 22260 solver.cpp:218] Iteration 144400 (15.803 iter/s, 6.32792s/100 iters), loss = 0.218196
I1211 09:33:31.855425 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 09:33:31.855425 22260 solver.cpp:237]     Train net output #1: loss = 0.218196 (* 1 = 0.218196 loss)
I1211 09:33:31.855425 22260 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1211 09:33:38.216982 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:33:38.468495 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_144500.caffemodel
I1211 09:33:38.484496 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_144500.solverstate
I1211 09:33:38.488495 22260 solver.cpp:330] Iteration 144500, Testing net (#0)
I1211 09:33:38.489498 22260 net.cpp:676] Ignoring source layer accuracy_training
I1211 09:33:40.007133 14572 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:33:40.066633 22260 solver.cpp:397]     Test net output #0: accuracy = 0.6648
I1211 09:33:40.066633 22260 solver.cpp:397]     Test net output #1: loss = 1.39596 (* 1 = 1.39596 loss)
I1211 09:33:40.127638 22260 solver.cpp:218] Iteration 144500 (12.089 iter/s, 8.27198s/100 iters), loss = 0.215245
I1211 09:33:40.127638 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 09:33:40.127638 22260 solver.cpp:237]     Train net output #1: loss = 0.215246 (* 1 = 0.215246 loss)
I1211 09:33:40.127638 22260 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1211 09:33:46.505605 22260 solver.cpp:218] Iteration 144600 (15.6799 iter/s, 6.37759s/100 iters), loss = 0.208783
I1211 09:33:46.505605 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 09:33:46.505605 22260 solver.cpp:237]     Train net output #1: loss = 0.208783 (* 1 = 0.208783 loss)
I1211 09:33:46.505605 22260 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1211 09:33:52.935668 22260 solver.cpp:218] Iteration 144700 (15.553 iter/s, 6.42961s/100 iters), loss = 0.202974
I1211 09:33:52.935668 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:33:52.935668 22260 solver.cpp:237]     Train net output #1: loss = 0.202974 (* 1 = 0.202974 loss)
I1211 09:33:52.935668 22260 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1211 09:33:59.286341 22260 solver.cpp:218] Iteration 144800 (15.7473 iter/s, 6.3503s/100 iters), loss = 0.193052
I1211 09:33:59.286341 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 09:33:59.286341 22260 solver.cpp:237]     Train net output #1: loss = 0.193052 (* 1 = 0.193052 loss)
I1211 09:33:59.286341 22260 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1211 09:34:05.670871 22260 solver.cpp:218] Iteration 144900 (15.6636 iter/s, 6.38422s/100 iters), loss = 0.246011
I1211 09:34:05.670871 22260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 09:34:05.670871 22260 solver.cpp:237]     Train net output #1: loss = 0.246012 (* 1 = 0.246012 loss)
I1211 09:34:05.670871 22260 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1211 09:34:11.714880 10692 data_layer.cpp:73] Restarting data prefetching from start.
I1211 09:34:11.963397 22260 solver.cpp:447] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_145000.caffemodel
I1211 09:34:11.979396 22260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_slimnet_300k_max_L15_v2_withnonlin_iter_145000.solverstate
I1211 09:34:11.983397 22260 solver.cpp:330]