
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I1211 18:38:15.200865 20404 caffe.cpp:219] Using GPUs 0
I1211 18:38:15.392869 20404 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1211 18:38:15.699445 20404 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 18:38:15.716462 20404 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/resnet32_with3pooling"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 195000
stepvalue: 220000
stepvalue: 270000
type: "AdaDelta"
I1211 18:38:15.721482 20404 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 18:38:15.723441 20404 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 18:38:15.724445 20404 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 18:38:15.724445 20404 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1211 18:38:15.724445 20404 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1211 18:38:15.724445 20404 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy_training"
  include
I1211 18:38:15.725457 20404 layer_factory.cpp:58] Creating layer cifar
I1211 18:38:15.736454 20404 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I1211 18:38:15.765995 20404 net.cpp:84] Creating Layer cifar
I1211 18:38:15.765995 20404 net.cpp:380] cifar -> data
I1211 18:38:15.765995 20404 net.cpp:380] cifar -> label
I1211 18:38:15.765995 20404 data_layer.cpp:45] output data size: 100,3,32,32
I1211 18:38:15.772003 20404 net.cpp:122] Setting up cifar
I1211 18:38:15.772003 20404 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 18:38:15.772003 20404 net.cpp:129] Top shape: 100 (100)
I1211 18:38:15.772003 20404 net.cpp:137] Memory required for data: 1229200
I1211 18:38:15.772003 20404 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 18:38:15.772003 20404 net.cpp:84] Creating Layer label_cifar_1_split
I1211 18:38:15.772003 20404 net.cpp:406] label_cifar_1_split <- label
I1211 18:38:15.772003 20404 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 18:38:15.772003 20404 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 18:38:15.772003 20404 net.cpp:122] Setting up label_cifar_1_split
I1211 18:38:15.772003 20404 net.cpp:129] Top shape: 100 (100)
I1211 18:38:15.772003 20404 net.cpp:129] Top shape: 100 (100)
I1211 18:38:15.772003 20404 net.cpp:137] Memory required for data: 1230000
I1211 18:38:15.772003 20404 layer_factory.cpp:58] Creating layer first_conv
I1211 18:38:15.773003 20404 net.cpp:84] Creating Layer first_conv
I1211 18:38:15.773003 20404 net.cpp:406] first_conv <- data
I1211 18:38:15.773003 20404 net.cpp:380] first_conv -> first_conv
I1211 18:38:15.773984  9884 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 18:38:16.034031 20404 net.cpp:122] Setting up first_conv
I1211 18:38:16.034031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.034031 20404 net.cpp:137] Memory required for data: 7783600
I1211 18:38:16.034031 20404 layer_factory.cpp:58] Creating layer first_conv_bn
I1211 18:38:16.034031 20404 net.cpp:84] Creating Layer first_conv_bn
I1211 18:38:16.034031 20404 net.cpp:406] first_conv_bn <- first_conv
I1211 18:38:16.034031 20404 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1211 18:38:16.034031 20404 net.cpp:122] Setting up first_conv_bn
I1211 18:38:16.034031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.034031 20404 net.cpp:137] Memory required for data: 14337200
I1211 18:38:16.034031 20404 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 18:38:16.034031 20404 net.cpp:84] Creating Layer first_conv_scale
I1211 18:38:16.034031 20404 net.cpp:406] first_conv_scale <- first_conv
I1211 18:38:16.034031 20404 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1211 18:38:16.034031 20404 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 18:38:16.034031 20404 net.cpp:122] Setting up first_conv_scale
I1211 18:38:16.034031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.034031 20404 net.cpp:137] Memory required for data: 20890800
I1211 18:38:16.034031 20404 layer_factory.cpp:58] Creating layer first_conv_relu
I1211 18:38:16.034031 20404 net.cpp:84] Creating Layer first_conv_relu
I1211 18:38:16.034031 20404 net.cpp:406] first_conv_relu <- first_conv
I1211 18:38:16.034031 20404 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1211 18:38:16.035032 20404 net.cpp:122] Setting up first_conv_relu
I1211 18:38:16.035032 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.035032 20404 net.cpp:137] Memory required for data: 27444400
I1211 18:38:16.035032 20404 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1211 18:38:16.035032 20404 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1211 18:38:16.035032 20404 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1211 18:38:16.035032 20404 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1211 18:38:16.035032 20404 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1211 18:38:16.035032 20404 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1211 18:38:16.035032 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.035032 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.035032 20404 net.cpp:137] Memory required for data: 40551600
I1211 18:38:16.035032 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1211 18:38:16.035032 20404 net.cpp:84] Creating Layer group0_block0_conv0
I1211 18:38:16.035032 20404 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1211 18:38:16.035032 20404 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1211 18:38:16.036032 20404 net.cpp:122] Setting up group0_block0_conv0
I1211 18:38:16.037031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.037031 20404 net.cpp:137] Memory required for data: 47105200
I1211 18:38:16.037031 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1211 18:38:16.037031 20404 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1211 18:38:16.037031 20404 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1211 18:38:16.037031 20404 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1211 18:38:16.037031 20404 net.cpp:122] Setting up group0_block0_conv0_bn
I1211 18:38:16.037031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.037031 20404 net.cpp:137] Memory required for data: 53658800
I1211 18:38:16.037031 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 18:38:16.037031 20404 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1211 18:38:16.037031 20404 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1211 18:38:16.037031 20404 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1211 18:38:16.037031 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 18:38:16.037031 20404 net.cpp:122] Setting up group0_block0_conv0_scale
I1211 18:38:16.037031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.037031 20404 net.cpp:137] Memory required for data: 60212400
I1211 18:38:16.037031 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1211 18:38:16.037031 20404 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1211 18:38:16.037031 20404 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1211 18:38:16.037031 20404 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1211 18:38:16.037031 20404 net.cpp:122] Setting up group0_block0_conv0_relu
I1211 18:38:16.037031 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.037031 20404 net.cpp:137] Memory required for data: 66766000
I1211 18:38:16.037031 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1211 18:38:16.037031 20404 net.cpp:84] Creating Layer group0_block0_conv1
I1211 18:38:16.037031 20404 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1211 18:38:16.037031 20404 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1211 18:38:16.038045 20404 net.cpp:122] Setting up group0_block0_conv1
I1211 18:38:16.038045 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.038045 20404 net.cpp:137] Memory required for data: 73319600
I1211 18:38:16.038045 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1211 18:38:16.038045 20404 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1211 18:38:16.038045 20404 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1211 18:38:16.038045 20404 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1211 18:38:16.039046 20404 net.cpp:122] Setting up group0_block0_conv1_bn
I1211 18:38:16.039046 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.039046 20404 net.cpp:137] Memory required for data: 79873200
I1211 18:38:16.039046 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 18:38:16.039046 20404 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1211 18:38:16.039046 20404 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1211 18:38:16.039046 20404 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1211 18:38:16.039046 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 18:38:16.039046 20404 net.cpp:122] Setting up group0_block0_conv1_scale
I1211 18:38:16.039046 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.039046 20404 net.cpp:137] Memory required for data: 86426800
I1211 18:38:16.039046 20404 layer_factory.cpp:58] Creating layer group0_block0_sum
I1211 18:38:16.100119 20404 net.cpp:84] Creating Layer group0_block0_sum
I1211 18:38:16.100119 20404 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1211 18:38:16.100119 20404 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1211 18:38:16.100119 20404 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1211 18:38:16.100119 20404 net.cpp:122] Setting up group0_block0_sum
I1211 18:38:16.100119 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.100119 20404 net.cpp:137] Memory required for data: 92980400
I1211 18:38:16.100119 20404 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1211 18:38:16.100119 20404 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1211 18:38:16.100119 20404 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1211 18:38:16.100119 20404 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1211 18:38:16.100119 20404 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1211 18:38:16.100119 20404 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1211 18:38:16.100119 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.100119 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.100119 20404 net.cpp:137] Memory required for data: 106087600
I1211 18:38:16.100119 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1211 18:38:16.100119 20404 net.cpp:84] Creating Layer group0_block1_conv0
I1211 18:38:16.100119 20404 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1211 18:38:16.100119 20404 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1211 18:38:16.102087 20404 net.cpp:122] Setting up group0_block1_conv0
I1211 18:38:16.102087 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.102087 20404 net.cpp:137] Memory required for data: 112641200
I1211 18:38:16.102087 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1211 18:38:16.102087 20404 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1211 18:38:16.102087 20404 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1211 18:38:16.102087 20404 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1211 18:38:16.102087 20404 net.cpp:122] Setting up group0_block1_conv0_bn
I1211 18:38:16.102087 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.102087 20404 net.cpp:137] Memory required for data: 119194800
I1211 18:38:16.102087 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 18:38:16.102087 20404 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1211 18:38:16.102087 20404 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1211 18:38:16.102087 20404 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1211 18:38:16.102087 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 18:38:16.102087 20404 net.cpp:122] Setting up group0_block1_conv0_scale
I1211 18:38:16.102087 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.102087 20404 net.cpp:137] Memory required for data: 125748400
I1211 18:38:16.102087 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1211 18:38:16.102087 20404 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1211 18:38:16.102087 20404 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1211 18:38:16.102087 20404 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1211 18:38:16.103096 20404 net.cpp:122] Setting up group0_block1_conv0_relu
I1211 18:38:16.103096 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.103096 20404 net.cpp:137] Memory required for data: 132302000
I1211 18:38:16.103096 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1211 18:38:16.103096 20404 net.cpp:84] Creating Layer group0_block1_conv1
I1211 18:38:16.103096 20404 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1211 18:38:16.103096 20404 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1211 18:38:16.104095 20404 net.cpp:122] Setting up group0_block1_conv1
I1211 18:38:16.104095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.104095 20404 net.cpp:137] Memory required for data: 138855600
I1211 18:38:16.104095 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1211 18:38:16.104095 20404 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1211 18:38:16.104095 20404 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1211 18:38:16.104095 20404 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1211 18:38:16.104095 20404 net.cpp:122] Setting up group0_block1_conv1_bn
I1211 18:38:16.104095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.104095 20404 net.cpp:137] Memory required for data: 145409200
I1211 18:38:16.104095 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 18:38:16.104095 20404 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1211 18:38:16.104095 20404 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1211 18:38:16.104095 20404 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1211 18:38:16.104095 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 18:38:16.104095 20404 net.cpp:122] Setting up group0_block1_conv1_scale
I1211 18:38:16.104095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.104095 20404 net.cpp:137] Memory required for data: 151962800
I1211 18:38:16.104095 20404 layer_factory.cpp:58] Creating layer group0_block1_sum
I1211 18:38:16.104095 20404 net.cpp:84] Creating Layer group0_block1_sum
I1211 18:38:16.104095 20404 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1211 18:38:16.104095 20404 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1211 18:38:16.104095 20404 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1211 18:38:16.104095 20404 net.cpp:122] Setting up group0_block1_sum
I1211 18:38:16.104095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.104095 20404 net.cpp:137] Memory required for data: 158516400
I1211 18:38:16.104095 20404 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1211 18:38:16.104095 20404 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1211 18:38:16.104095 20404 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1211 18:38:16.104095 20404 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1211 18:38:16.104095 20404 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1211 18:38:16.104095 20404 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1211 18:38:16.104095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.104095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.104095 20404 net.cpp:137] Memory required for data: 171623600
I1211 18:38:16.104095 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1211 18:38:16.104095 20404 net.cpp:84] Creating Layer group0_block2_conv0
I1211 18:38:16.104095 20404 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1211 18:38:16.104095 20404 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1211 18:38:16.106094 20404 net.cpp:122] Setting up group0_block2_conv0
I1211 18:38:16.106094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.106094 20404 net.cpp:137] Memory required for data: 178177200
I1211 18:38:16.106094 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1211 18:38:16.106094 20404 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1211 18:38:16.106094 20404 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1211 18:38:16.106094 20404 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1211 18:38:16.106094 20404 net.cpp:122] Setting up group0_block2_conv0_bn
I1211 18:38:16.106094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.106094 20404 net.cpp:137] Memory required for data: 184730800
I1211 18:38:16.106094 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 18:38:16.106094 20404 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1211 18:38:16.106094 20404 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1211 18:38:16.106094 20404 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1211 18:38:16.106094 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 18:38:16.106094 20404 net.cpp:122] Setting up group0_block2_conv0_scale
I1211 18:38:16.106094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.106094 20404 net.cpp:137] Memory required for data: 191284400
I1211 18:38:16.106094 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1211 18:38:16.106094 20404 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1211 18:38:16.106094 20404 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1211 18:38:16.106094 20404 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1211 18:38:16.106094 20404 net.cpp:122] Setting up group0_block2_conv0_relu
I1211 18:38:16.106094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.106094 20404 net.cpp:137] Memory required for data: 197838000
I1211 18:38:16.106094 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1211 18:38:16.106094 20404 net.cpp:84] Creating Layer group0_block2_conv1
I1211 18:38:16.106094 20404 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1211 18:38:16.106094 20404 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1211 18:38:16.108095 20404 net.cpp:122] Setting up group0_block2_conv1
I1211 18:38:16.108095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.108095 20404 net.cpp:137] Memory required for data: 204391600
I1211 18:38:16.108095 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1211 18:38:16.108095 20404 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1211 18:38:16.108095 20404 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1211 18:38:16.108095 20404 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1211 18:38:16.108095 20404 net.cpp:122] Setting up group0_block2_conv1_bn
I1211 18:38:16.108095 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.108095 20404 net.cpp:137] Memory required for data: 210945200
I1211 18:38:16.108095 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 18:38:16.108095 20404 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1211 18:38:16.108095 20404 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1211 18:38:16.108095 20404 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1211 18:38:16.108095 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 18:38:16.109094 20404 net.cpp:122] Setting up group0_block2_conv1_scale
I1211 18:38:16.109094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.109094 20404 net.cpp:137] Memory required for data: 217498800
I1211 18:38:16.109094 20404 layer_factory.cpp:58] Creating layer group0_block2_sum
I1211 18:38:16.109094 20404 net.cpp:84] Creating Layer group0_block2_sum
I1211 18:38:16.109094 20404 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1211 18:38:16.109094 20404 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1211 18:38:16.109094 20404 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1211 18:38:16.109094 20404 net.cpp:122] Setting up group0_block2_sum
I1211 18:38:16.109094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.109094 20404 net.cpp:137] Memory required for data: 224052400
I1211 18:38:16.109094 20404 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1211 18:38:16.109094 20404 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1211 18:38:16.109094 20404 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1211 18:38:16.109094 20404 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1211 18:38:16.109094 20404 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1211 18:38:16.109094 20404 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1211 18:38:16.109094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.109094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.109094 20404 net.cpp:137] Memory required for data: 237159600
I1211 18:38:16.109094 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1211 18:38:16.109094 20404 net.cpp:84] Creating Layer group0_block3_conv0
I1211 18:38:16.109094 20404 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1211 18:38:16.109094 20404 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1211 18:38:16.110081 20404 net.cpp:122] Setting up group0_block3_conv0
I1211 18:38:16.110081 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.110081 20404 net.cpp:137] Memory required for data: 243713200
I1211 18:38:16.110081 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1211 18:38:16.110081 20404 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1211 18:38:16.110081 20404 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1211 18:38:16.110081 20404 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1211 18:38:16.110081 20404 net.cpp:122] Setting up group0_block3_conv0_bn
I1211 18:38:16.110081 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.110081 20404 net.cpp:137] Memory required for data: 250266800
I1211 18:38:16.110081 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 18:38:16.110081 20404 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1211 18:38:16.110081 20404 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1211 18:38:16.110081 20404 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1211 18:38:16.110081 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 18:38:16.110081 20404 net.cpp:122] Setting up group0_block3_conv0_scale
I1211 18:38:16.110081 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.110081 20404 net.cpp:137] Memory required for data: 256820400
I1211 18:38:16.110081 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1211 18:38:16.110081 20404 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1211 18:38:16.110081 20404 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1211 18:38:16.110081 20404 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1211 18:38:16.111099 20404 net.cpp:122] Setting up group0_block3_conv0_relu
I1211 18:38:16.111099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.111099 20404 net.cpp:137] Memory required for data: 263374000
I1211 18:38:16.111099 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1211 18:38:16.111099 20404 net.cpp:84] Creating Layer group0_block3_conv1
I1211 18:38:16.111099 20404 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1211 18:38:16.111099 20404 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1211 18:38:16.112100 20404 net.cpp:122] Setting up group0_block3_conv1
I1211 18:38:16.112100 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.112100 20404 net.cpp:137] Memory required for data: 269927600
I1211 18:38:16.112100 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1211 18:38:16.112100 20404 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1211 18:38:16.112100 20404 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1211 18:38:16.112100 20404 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1211 18:38:16.112100 20404 net.cpp:122] Setting up group0_block3_conv1_bn
I1211 18:38:16.112100 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.112100 20404 net.cpp:137] Memory required for data: 276481200
I1211 18:38:16.112100 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 18:38:16.112100 20404 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1211 18:38:16.112100 20404 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1211 18:38:16.112100 20404 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1211 18:38:16.112100 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 18:38:16.112100 20404 net.cpp:122] Setting up group0_block3_conv1_scale
I1211 18:38:16.112100 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.112100 20404 net.cpp:137] Memory required for data: 283034800
I1211 18:38:16.112100 20404 layer_factory.cpp:58] Creating layer group0_block3_sum
I1211 18:38:16.112100 20404 net.cpp:84] Creating Layer group0_block3_sum
I1211 18:38:16.112100 20404 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1211 18:38:16.112100 20404 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1211 18:38:16.112100 20404 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1211 18:38:16.112100 20404 net.cpp:122] Setting up group0_block3_sum
I1211 18:38:16.112100 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.112100 20404 net.cpp:137] Memory required for data: 289588400
I1211 18:38:16.112100 20404 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1211 18:38:16.112100 20404 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1211 18:38:16.112100 20404 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1211 18:38:16.112100 20404 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1211 18:38:16.112100 20404 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1211 18:38:16.112100 20404 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1211 18:38:16.112100 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.112100 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.112100 20404 net.cpp:137] Memory required for data: 302695600
I1211 18:38:16.112100 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1211 18:38:16.112100 20404 net.cpp:84] Creating Layer group0_block4_conv0
I1211 18:38:16.112100 20404 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1211 18:38:16.112100 20404 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1211 18:38:16.113098 20404 net.cpp:122] Setting up group0_block4_conv0
I1211 18:38:16.113098 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.113098 20404 net.cpp:137] Memory required for data: 309249200
I1211 18:38:16.114099 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1211 18:38:16.114099 20404 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1211 18:38:16.114099 20404 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1211 18:38:16.114099 20404 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1211 18:38:16.114099 20404 net.cpp:122] Setting up group0_block4_conv0_bn
I1211 18:38:16.114099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.114099 20404 net.cpp:137] Memory required for data: 315802800
I1211 18:38:16.114099 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 18:38:16.114099 20404 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1211 18:38:16.114099 20404 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1211 18:38:16.114099 20404 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1211 18:38:16.114099 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 18:38:16.114099 20404 net.cpp:122] Setting up group0_block4_conv0_scale
I1211 18:38:16.114099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.114099 20404 net.cpp:137] Memory required for data: 322356400
I1211 18:38:16.114099 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1211 18:38:16.114099 20404 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1211 18:38:16.114099 20404 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1211 18:38:16.114099 20404 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1211 18:38:16.114099 20404 net.cpp:122] Setting up group0_block4_conv0_relu
I1211 18:38:16.114099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.114099 20404 net.cpp:137] Memory required for data: 328910000
I1211 18:38:16.114099 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1211 18:38:16.114099 20404 net.cpp:84] Creating Layer group0_block4_conv1
I1211 18:38:16.114099 20404 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1211 18:38:16.114099 20404 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1211 18:38:16.115108 20404 net.cpp:122] Setting up group0_block4_conv1
I1211 18:38:16.115108 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.115108 20404 net.cpp:137] Memory required for data: 335463600
I1211 18:38:16.115108 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1211 18:38:16.115108 20404 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1211 18:38:16.115108 20404 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1211 18:38:16.115108 20404 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1211 18:38:16.115108 20404 net.cpp:122] Setting up group0_block4_conv1_bn
I1211 18:38:16.115108 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.115108 20404 net.cpp:137] Memory required for data: 342017200
I1211 18:38:16.115108 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 18:38:16.115108 20404 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1211 18:38:16.115108 20404 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1211 18:38:16.115108 20404 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1211 18:38:16.116099 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 18:38:16.116099 20404 net.cpp:122] Setting up group0_block4_conv1_scale
I1211 18:38:16.116099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.116099 20404 net.cpp:137] Memory required for data: 348570800
I1211 18:38:16.116099 20404 layer_factory.cpp:58] Creating layer group0_block4_sum
I1211 18:38:16.116099 20404 net.cpp:84] Creating Layer group0_block4_sum
I1211 18:38:16.116099 20404 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1211 18:38:16.116099 20404 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1211 18:38:16.116099 20404 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1211 18:38:16.116099 20404 net.cpp:122] Setting up group0_block4_sum
I1211 18:38:16.116099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.116099 20404 net.cpp:137] Memory required for data: 355124400
I1211 18:38:16.116099 20404 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1211 18:38:16.116099 20404 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1211 18:38:16.116099 20404 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1211 18:38:16.116099 20404 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1211 18:38:16.116099 20404 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1211 18:38:16.116099 20404 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1211 18:38:16.116099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.116099 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.116099 20404 net.cpp:137] Memory required for data: 368231600
I1211 18:38:16.116099 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1211 18:38:16.116099 20404 net.cpp:84] Creating Layer group1_block0_conv0
I1211 18:38:16.116099 20404 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1211 18:38:16.116099 20404 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1211 18:38:16.118080 20404 net.cpp:122] Setting up group1_block0_conv0
I1211 18:38:16.118080 20404 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1211 18:38:16.118080 20404 net.cpp:137] Memory required for data: 381338800
I1211 18:38:16.118080 20404 layer_factory.cpp:58] Creating layer pool1
I1211 18:38:16.118080 20404 net.cpp:84] Creating Layer pool1
I1211 18:38:16.118080 20404 net.cpp:406] pool1 <- group1_block0_conv0
I1211 18:38:16.118080 20404 net.cpp:380] pool1 -> pool1
I1211 18:38:16.118080 20404 net.cpp:122] Setting up pool1
I1211 18:38:16.118080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.118080 20404 net.cpp:137] Memory required for data: 384615600
I1211 18:38:16.118080 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1211 18:38:16.118080 20404 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1211 18:38:16.118080 20404 net.cpp:406] group1_block0_conv0_bn <- pool1
I1211 18:38:16.118080 20404 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1211 18:38:16.118080 20404 net.cpp:122] Setting up group1_block0_conv0_bn
I1211 18:38:16.118080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.118080 20404 net.cpp:137] Memory required for data: 387892400
I1211 18:38:16.118080 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 18:38:16.118080 20404 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1211 18:38:16.118080 20404 net.cpp:406] group1_block0_conv0_scale <- pool1
I1211 18:38:16.118080 20404 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1211 18:38:16.118080 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 18:38:16.118080 20404 net.cpp:122] Setting up group1_block0_conv0_scale
I1211 18:38:16.118080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.118080 20404 net.cpp:137] Memory required for data: 391169200
I1211 18:38:16.118080 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1211 18:38:16.118080 20404 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1211 18:38:16.118080 20404 net.cpp:406] group1_block0_conv0_relu <- pool1
I1211 18:38:16.118080 20404 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1211 18:38:16.118080 20404 net.cpp:122] Setting up group1_block0_conv0_relu
I1211 18:38:16.118080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.119081 20404 net.cpp:137] Memory required for data: 394446000
I1211 18:38:16.119081 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1211 18:38:16.119081 20404 net.cpp:84] Creating Layer group1_block0_conv1
I1211 18:38:16.119081 20404 net.cpp:406] group1_block0_conv1 <- pool1
I1211 18:38:16.119081 20404 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1211 18:38:16.120081 20404 net.cpp:122] Setting up group1_block0_conv1
I1211 18:38:16.120081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.120081 20404 net.cpp:137] Memory required for data: 397722800
I1211 18:38:16.120081 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1211 18:38:16.120081 20404 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1211 18:38:16.120081 20404 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1211 18:38:16.120081 20404 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1211 18:38:16.120081 20404 net.cpp:122] Setting up group1_block0_conv1_bn
I1211 18:38:16.120081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.120081 20404 net.cpp:137] Memory required for data: 400999600
I1211 18:38:16.120081 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 18:38:16.120081 20404 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1211 18:38:16.120081 20404 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1211 18:38:16.120081 20404 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1211 18:38:16.120081 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 18:38:16.120081 20404 net.cpp:122] Setting up group1_block0_conv1_scale
I1211 18:38:16.120081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.120081 20404 net.cpp:137] Memory required for data: 404276400
I1211 18:38:16.120081 20404 layer_factory.cpp:58] Creating layer group1_block0_proj
I1211 18:38:16.120081 20404 net.cpp:84] Creating Layer group1_block0_proj
I1211 18:38:16.120081 20404 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1211 18:38:16.120081 20404 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1211 18:38:16.122081 20404 net.cpp:122] Setting up group1_block0_proj
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1211 18:38:16.122081 20404 net.cpp:137] Memory required for data: 416577200
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer pool2
I1211 18:38:16.122081 20404 net.cpp:84] Creating Layer pool2
I1211 18:38:16.122081 20404 net.cpp:406] pool2 <- group1_block0_proj
I1211 18:38:16.122081 20404 net.cpp:380] pool2 -> pool2
I1211 18:38:16.122081 20404 net.cpp:122] Setting up pool2
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.122081 20404 net.cpp:137] Memory required for data: 419854000
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1211 18:38:16.122081 20404 net.cpp:84] Creating Layer group1_block0_proj_bn
I1211 18:38:16.122081 20404 net.cpp:406] group1_block0_proj_bn <- pool2
I1211 18:38:16.122081 20404 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1211 18:38:16.122081 20404 net.cpp:122] Setting up group1_block0_proj_bn
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.122081 20404 net.cpp:137] Memory required for data: 423130800
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 18:38:16.122081 20404 net.cpp:84] Creating Layer group1_block0_proj_scale
I1211 18:38:16.122081 20404 net.cpp:406] group1_block0_proj_scale <- pool2
I1211 18:38:16.122081 20404 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 18:38:16.122081 20404 net.cpp:122] Setting up group1_block0_proj_scale
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.122081 20404 net.cpp:137] Memory required for data: 426407600
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer group1_block0_sum
I1211 18:38:16.122081 20404 net.cpp:84] Creating Layer group1_block0_sum
I1211 18:38:16.122081 20404 net.cpp:406] group1_block0_sum <- pool2
I1211 18:38:16.122081 20404 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1211 18:38:16.122081 20404 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1211 18:38:16.122081 20404 net.cpp:122] Setting up group1_block0_sum
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.122081 20404 net.cpp:137] Memory required for data: 429684400
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1211 18:38:16.122081 20404 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1211 18:38:16.122081 20404 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1211 18:38:16.122081 20404 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1211 18:38:16.122081 20404 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1211 18:38:16.122081 20404 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.122081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.122081 20404 net.cpp:137] Memory required for data: 436238000
I1211 18:38:16.122081 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1211 18:38:16.122081 20404 net.cpp:84] Creating Layer group1_block1_conv0
I1211 18:38:16.122081 20404 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1211 18:38:16.122081 20404 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1211 18:38:16.124101 20404 net.cpp:122] Setting up group1_block1_conv0
I1211 18:38:16.124101 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.124101 20404 net.cpp:137] Memory required for data: 439514800
I1211 18:38:16.124101 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1211 18:38:16.124101 20404 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1211 18:38:16.124101 20404 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1211 18:38:16.124101 20404 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1211 18:38:16.124101 20404 net.cpp:122] Setting up group1_block1_conv0_bn
I1211 18:38:16.124101 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.124101 20404 net.cpp:137] Memory required for data: 442791600
I1211 18:38:16.124101 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 18:38:16.124101 20404 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1211 18:38:16.124101 20404 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1211 18:38:16.124101 20404 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1211 18:38:16.124101 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 18:38:16.124101 20404 net.cpp:122] Setting up group1_block1_conv0_scale
I1211 18:38:16.124101 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.124101 20404 net.cpp:137] Memory required for data: 446068400
I1211 18:38:16.124101 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1211 18:38:16.125082 20404 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1211 18:38:16.125082 20404 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1211 18:38:16.125082 20404 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1211 18:38:16.125082 20404 net.cpp:122] Setting up group1_block1_conv0_relu
I1211 18:38:16.125082 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.125082 20404 net.cpp:137] Memory required for data: 449345200
I1211 18:38:16.125082 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1211 18:38:16.125082 20404 net.cpp:84] Creating Layer group1_block1_conv1
I1211 18:38:16.125082 20404 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1211 18:38:16.125082 20404 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1211 18:38:16.126082 20404 net.cpp:122] Setting up group1_block1_conv1
I1211 18:38:16.127080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.127080 20404 net.cpp:137] Memory required for data: 452622000
I1211 18:38:16.127080 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1211 18:38:16.127080 20404 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1211 18:38:16.127080 20404 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1211 18:38:16.127080 20404 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1211 18:38:16.127080 20404 net.cpp:122] Setting up group1_block1_conv1_bn
I1211 18:38:16.127080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.127080 20404 net.cpp:137] Memory required for data: 455898800
I1211 18:38:16.127080 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 18:38:16.127080 20404 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1211 18:38:16.127080 20404 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1211 18:38:16.127080 20404 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1211 18:38:16.127080 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 18:38:16.127080 20404 net.cpp:122] Setting up group1_block1_conv1_scale
I1211 18:38:16.127080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.127080 20404 net.cpp:137] Memory required for data: 459175600
I1211 18:38:16.127080 20404 layer_factory.cpp:58] Creating layer group1_block1_sum
I1211 18:38:16.127080 20404 net.cpp:84] Creating Layer group1_block1_sum
I1211 18:38:16.127080 20404 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1211 18:38:16.127080 20404 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1211 18:38:16.127080 20404 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1211 18:38:16.127080 20404 net.cpp:122] Setting up group1_block1_sum
I1211 18:38:16.127080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.127080 20404 net.cpp:137] Memory required for data: 462452400
I1211 18:38:16.127080 20404 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1211 18:38:16.127080 20404 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1211 18:38:16.127080 20404 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1211 18:38:16.127080 20404 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1211 18:38:16.127080 20404 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1211 18:38:16.127080 20404 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1211 18:38:16.127080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.127080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.127080 20404 net.cpp:137] Memory required for data: 469006000
I1211 18:38:16.127080 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1211 18:38:16.127080 20404 net.cpp:84] Creating Layer group1_block2_conv0
I1211 18:38:16.127080 20404 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1211 18:38:16.127080 20404 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1211 18:38:16.129081 20404 net.cpp:122] Setting up group1_block2_conv0
I1211 18:38:16.129081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.129081 20404 net.cpp:137] Memory required for data: 472282800
I1211 18:38:16.129081 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1211 18:38:16.129081 20404 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1211 18:38:16.129081 20404 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1211 18:38:16.129081 20404 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1211 18:38:16.129081 20404 net.cpp:122] Setting up group1_block2_conv0_bn
I1211 18:38:16.129081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.129081 20404 net.cpp:137] Memory required for data: 475559600
I1211 18:38:16.129081 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 18:38:16.129081 20404 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1211 18:38:16.129081 20404 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1211 18:38:16.129081 20404 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1211 18:38:16.129081 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 18:38:16.129081 20404 net.cpp:122] Setting up group1_block2_conv0_scale
I1211 18:38:16.129081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.129081 20404 net.cpp:137] Memory required for data: 478836400
I1211 18:38:16.129081 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1211 18:38:16.129081 20404 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1211 18:38:16.129081 20404 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1211 18:38:16.129081 20404 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1211 18:38:16.129081 20404 net.cpp:122] Setting up group1_block2_conv0_relu
I1211 18:38:16.129081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.129081 20404 net.cpp:137] Memory required for data: 482113200
I1211 18:38:16.129081 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1211 18:38:16.129081 20404 net.cpp:84] Creating Layer group1_block2_conv1
I1211 18:38:16.129081 20404 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1211 18:38:16.129081 20404 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1211 18:38:16.132083 20404 net.cpp:122] Setting up group1_block2_conv1
I1211 18:38:16.132083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.132083 20404 net.cpp:137] Memory required for data: 485390000
I1211 18:38:16.132083 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1211 18:38:16.132083 20404 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1211 18:38:16.132083 20404 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1211 18:38:16.132083 20404 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1211 18:38:16.132083 20404 net.cpp:122] Setting up group1_block2_conv1_bn
I1211 18:38:16.132083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.132083 20404 net.cpp:137] Memory required for data: 488666800
I1211 18:38:16.132083 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 18:38:16.132083 20404 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1211 18:38:16.132083 20404 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1211 18:38:16.132083 20404 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1211 18:38:16.132083 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 18:38:16.132083 20404 net.cpp:122] Setting up group1_block2_conv1_scale
I1211 18:38:16.132083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.132083 20404 net.cpp:137] Memory required for data: 491943600
I1211 18:38:16.132083 20404 layer_factory.cpp:58] Creating layer group1_block2_sum
I1211 18:38:16.132083 20404 net.cpp:84] Creating Layer group1_block2_sum
I1211 18:38:16.132083 20404 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1211 18:38:16.132083 20404 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1211 18:38:16.132083 20404 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1211 18:38:16.132083 20404 net.cpp:122] Setting up group1_block2_sum
I1211 18:38:16.132083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.132083 20404 net.cpp:137] Memory required for data: 495220400
I1211 18:38:16.132083 20404 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1211 18:38:16.132083 20404 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1211 18:38:16.132083 20404 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1211 18:38:16.132083 20404 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1211 18:38:16.132083 20404 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1211 18:38:16.132083 20404 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1211 18:38:16.132083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.132083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.132083 20404 net.cpp:137] Memory required for data: 501774000
I1211 18:38:16.132083 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1211 18:38:16.132083 20404 net.cpp:84] Creating Layer group1_block3_conv0
I1211 18:38:16.132083 20404 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1211 18:38:16.132083 20404 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1211 18:38:16.134083 20404 net.cpp:122] Setting up group1_block3_conv0
I1211 18:38:16.134083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.134083 20404 net.cpp:137] Memory required for data: 505050800
I1211 18:38:16.134083 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1211 18:38:16.134083 20404 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1211 18:38:16.134083 20404 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1211 18:38:16.134083 20404 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1211 18:38:16.134083 20404 net.cpp:122] Setting up group1_block3_conv0_bn
I1211 18:38:16.134083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.134083 20404 net.cpp:137] Memory required for data: 508327600
I1211 18:38:16.134083 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 18:38:16.134083 20404 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1211 18:38:16.134083 20404 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1211 18:38:16.134083 20404 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1211 18:38:16.134083 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 18:38:16.134083 20404 net.cpp:122] Setting up group1_block3_conv0_scale
I1211 18:38:16.134083 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.134083 20404 net.cpp:137] Memory required for data: 511604400
I1211 18:38:16.134083 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1211 18:38:16.134083 20404 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1211 18:38:16.134083 20404 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1211 18:38:16.134083 20404 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1211 18:38:16.135082 20404 net.cpp:122] Setting up group1_block3_conv0_relu
I1211 18:38:16.135082 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.135082 20404 net.cpp:137] Memory required for data: 514881200
I1211 18:38:16.135082 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1211 18:38:16.135082 20404 net.cpp:84] Creating Layer group1_block3_conv1
I1211 18:38:16.135082 20404 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1211 18:38:16.135082 20404 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1211 18:38:16.136081 20404 net.cpp:122] Setting up group1_block3_conv1
I1211 18:38:16.136081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.136081 20404 net.cpp:137] Memory required for data: 518158000
I1211 18:38:16.136081 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1211 18:38:16.136081 20404 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1211 18:38:16.136081 20404 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1211 18:38:16.136081 20404 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1211 18:38:16.136081 20404 net.cpp:122] Setting up group1_block3_conv1_bn
I1211 18:38:16.136081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.136081 20404 net.cpp:137] Memory required for data: 521434800
I1211 18:38:16.136081 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 18:38:16.136081 20404 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1211 18:38:16.136081 20404 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1211 18:38:16.136081 20404 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1211 18:38:16.136081 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 18:38:16.136081 20404 net.cpp:122] Setting up group1_block3_conv1_scale
I1211 18:38:16.136081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.136081 20404 net.cpp:137] Memory required for data: 524711600
I1211 18:38:16.136081 20404 layer_factory.cpp:58] Creating layer group1_block3_sum
I1211 18:38:16.136081 20404 net.cpp:84] Creating Layer group1_block3_sum
I1211 18:38:16.136081 20404 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1211 18:38:16.136081 20404 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1211 18:38:16.136081 20404 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1211 18:38:16.136081 20404 net.cpp:122] Setting up group1_block3_sum
I1211 18:38:16.136081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.136081 20404 net.cpp:137] Memory required for data: 527988400
I1211 18:38:16.136081 20404 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1211 18:38:16.136081 20404 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1211 18:38:16.136081 20404 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1211 18:38:16.136081 20404 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1211 18:38:16.136081 20404 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1211 18:38:16.136081 20404 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1211 18:38:16.136081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.136081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.136081 20404 net.cpp:137] Memory required for data: 534542000
I1211 18:38:16.136081 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1211 18:38:16.136081 20404 net.cpp:84] Creating Layer group1_block4_conv0
I1211 18:38:16.136081 20404 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1211 18:38:16.136081 20404 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1211 18:38:16.138082 20404 net.cpp:122] Setting up group1_block4_conv0
I1211 18:38:16.138082 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.138082 20404 net.cpp:137] Memory required for data: 537818800
I1211 18:38:16.138082 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1211 18:38:16.138082 20404 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1211 18:38:16.138082 20404 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1211 18:38:16.138082 20404 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1211 18:38:16.138082 20404 net.cpp:122] Setting up group1_block4_conv0_bn
I1211 18:38:16.138082 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.138082 20404 net.cpp:137] Memory required for data: 541095600
I1211 18:38:16.138082 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 18:38:16.138082 20404 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1211 18:38:16.138082 20404 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1211 18:38:16.138082 20404 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1211 18:38:16.138082 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 18:38:16.138082 20404 net.cpp:122] Setting up group1_block4_conv0_scale
I1211 18:38:16.138082 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.138082 20404 net.cpp:137] Memory required for data: 544372400
I1211 18:38:16.138082 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1211 18:38:16.138082 20404 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1211 18:38:16.138082 20404 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1211 18:38:16.138082 20404 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1211 18:38:16.139081 20404 net.cpp:122] Setting up group1_block4_conv0_relu
I1211 18:38:16.139081 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.139081 20404 net.cpp:137] Memory required for data: 547649200
I1211 18:38:16.139081 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1211 18:38:16.139081 20404 net.cpp:84] Creating Layer group1_block4_conv1
I1211 18:38:16.139081 20404 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1211 18:38:16.139081 20404 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1211 18:38:16.140080 20404 net.cpp:122] Setting up group1_block4_conv1
I1211 18:38:16.140080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.140080 20404 net.cpp:137] Memory required for data: 550926000
I1211 18:38:16.140080 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1211 18:38:16.140080 20404 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1211 18:38:16.140080 20404 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1211 18:38:16.140080 20404 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1211 18:38:16.140080 20404 net.cpp:122] Setting up group1_block4_conv1_bn
I1211 18:38:16.140080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.140080 20404 net.cpp:137] Memory required for data: 554202800
I1211 18:38:16.140080 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 18:38:16.140080 20404 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1211 18:38:16.140080 20404 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1211 18:38:16.140080 20404 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1211 18:38:16.140080 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 18:38:16.140080 20404 net.cpp:122] Setting up group1_block4_conv1_scale
I1211 18:38:16.140080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.140080 20404 net.cpp:137] Memory required for data: 557479600
I1211 18:38:16.140080 20404 layer_factory.cpp:58] Creating layer group1_block4_sum
I1211 18:38:16.140080 20404 net.cpp:84] Creating Layer group1_block4_sum
I1211 18:38:16.140080 20404 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1211 18:38:16.140080 20404 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1211 18:38:16.140080 20404 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1211 18:38:16.140080 20404 net.cpp:122] Setting up group1_block4_sum
I1211 18:38:16.140080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.140080 20404 net.cpp:137] Memory required for data: 560756400
I1211 18:38:16.140080 20404 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1211 18:38:16.140080 20404 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1211 18:38:16.140080 20404 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1211 18:38:16.140080 20404 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1211 18:38:16.140080 20404 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1211 18:38:16.140080 20404 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1211 18:38:16.140080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.140080 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.140080 20404 net.cpp:137] Memory required for data: 567310000
I1211 18:38:16.141080 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1211 18:38:16.141080 20404 net.cpp:84] Creating Layer group2_block0_conv0
I1211 18:38:16.141080 20404 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1211 18:38:16.141080 20404 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1211 18:38:16.149081 20404 net.cpp:122] Setting up group2_block0_conv0
I1211 18:38:16.149081 20404 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1211 18:38:16.149081 20404 net.cpp:137] Memory required for data: 573863600
I1211 18:38:16.149081 20404 layer_factory.cpp:58] Creating layer pool3
I1211 18:38:16.149081 20404 net.cpp:84] Creating Layer pool3
I1211 18:38:16.149081 20404 net.cpp:406] pool3 <- group2_block0_conv0
I1211 18:38:16.149081 20404 net.cpp:380] pool3 -> pool3
I1211 18:38:16.149081 20404 net.cpp:122] Setting up pool3
I1211 18:38:16.149081 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.149081 20404 net.cpp:137] Memory required for data: 575502000
I1211 18:38:16.149081 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1211 18:38:16.149081 20404 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1211 18:38:16.149081 20404 net.cpp:406] group2_block0_conv0_bn <- pool3
I1211 18:38:16.149081 20404 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1211 18:38:16.149081 20404 net.cpp:122] Setting up group2_block0_conv0_bn
I1211 18:38:16.149081 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.149081 20404 net.cpp:137] Memory required for data: 577140400
I1211 18:38:16.149081 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 18:38:16.149081 20404 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1211 18:38:16.149081 20404 net.cpp:406] group2_block0_conv0_scale <- pool3
I1211 18:38:16.149081 20404 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1211 18:38:16.150081 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 18:38:16.150081 20404 net.cpp:122] Setting up group2_block0_conv0_scale
I1211 18:38:16.150081 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.150081 20404 net.cpp:137] Memory required for data: 578778800
I1211 18:38:16.150081 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1211 18:38:16.150081 20404 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1211 18:38:16.150081 20404 net.cpp:406] group2_block0_conv0_relu <- pool3
I1211 18:38:16.150081 20404 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1211 18:38:16.150600 20404 net.cpp:122] Setting up group2_block0_conv0_relu
I1211 18:38:16.150600 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.150600 20404 net.cpp:137] Memory required for data: 580417200
I1211 18:38:16.150600 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1211 18:38:16.150600 20404 net.cpp:84] Creating Layer group2_block0_conv1
I1211 18:38:16.150600 20404 net.cpp:406] group2_block0_conv1 <- pool3
I1211 18:38:16.150600 20404 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1211 18:38:16.152586 20404 net.cpp:122] Setting up group2_block0_conv1
I1211 18:38:16.152586 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.152586 20404 net.cpp:137] Memory required for data: 582055600
I1211 18:38:16.152586 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1211 18:38:16.152586 20404 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1211 18:38:16.152586 20404 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1211 18:38:16.152586 20404 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1211 18:38:16.152586 20404 net.cpp:122] Setting up group2_block0_conv1_bn
I1211 18:38:16.152586 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.152586 20404 net.cpp:137] Memory required for data: 583694000
I1211 18:38:16.152586 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 18:38:16.152586 20404 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1211 18:38:16.152586 20404 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1211 18:38:16.152586 20404 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1211 18:38:16.152586 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 18:38:16.153086 20404 net.cpp:122] Setting up group2_block0_conv1_scale
I1211 18:38:16.153086 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.153086 20404 net.cpp:137] Memory required for data: 585332400
I1211 18:38:16.153086 20404 layer_factory.cpp:58] Creating layer group2_block0_proj
I1211 18:38:16.153086 20404 net.cpp:84] Creating Layer group2_block0_proj
I1211 18:38:16.153086 20404 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1211 18:38:16.153086 20404 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1211 18:38:16.154086 20404 net.cpp:122] Setting up group2_block0_proj
I1211 18:38:16.154086 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.154086 20404 net.cpp:137] Memory required for data: 586970800
I1211 18:38:16.154086 20404 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1211 18:38:16.154086 20404 net.cpp:84] Creating Layer group2_block0_proj_bn
I1211 18:38:16.154086 20404 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1211 18:38:16.154086 20404 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1211 18:38:16.154587 20404 net.cpp:122] Setting up group2_block0_proj_bn
I1211 18:38:16.154587 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.154587 20404 net.cpp:137] Memory required for data: 588609200
I1211 18:38:16.154587 20404 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 18:38:16.154587 20404 net.cpp:84] Creating Layer group2_block0_proj_scale
I1211 18:38:16.154587 20404 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1211 18:38:16.154587 20404 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1211 18:38:16.154587 20404 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 18:38:16.154587 20404 net.cpp:122] Setting up group2_block0_proj_scale
I1211 18:38:16.154587 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.154587 20404 net.cpp:137] Memory required for data: 590247600
I1211 18:38:16.154587 20404 layer_factory.cpp:58] Creating layer group2_block0_sum
I1211 18:38:16.154587 20404 net.cpp:84] Creating Layer group2_block0_sum
I1211 18:38:16.154587 20404 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1211 18:38:16.154587 20404 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1211 18:38:16.154587 20404 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1211 18:38:16.154587 20404 net.cpp:122] Setting up group2_block0_sum
I1211 18:38:16.154587 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.154587 20404 net.cpp:137] Memory required for data: 591886000
I1211 18:38:16.154587 20404 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1211 18:38:16.154587 20404 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1211 18:38:16.154587 20404 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1211 18:38:16.154587 20404 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1211 18:38:16.154587 20404 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1211 18:38:16.154587 20404 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1211 18:38:16.154587 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.155086 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.155086 20404 net.cpp:137] Memory required for data: 595162800
I1211 18:38:16.155086 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1211 18:38:16.155086 20404 net.cpp:84] Creating Layer group2_block1_conv0
I1211 18:38:16.155086 20404 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1211 18:38:16.155086 20404 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1211 18:38:16.157095 20404 net.cpp:122] Setting up group2_block1_conv0
I1211 18:38:16.157586 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.157586 20404 net.cpp:137] Memory required for data: 596801200
I1211 18:38:16.157586 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1211 18:38:16.157586 20404 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1211 18:38:16.157586 20404 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1211 18:38:16.157586 20404 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1211 18:38:16.157586 20404 net.cpp:122] Setting up group2_block1_conv0_bn
I1211 18:38:16.157586 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.157586 20404 net.cpp:137] Memory required for data: 598439600
I1211 18:38:16.157586 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 18:38:16.157586 20404 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1211 18:38:16.157586 20404 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1211 18:38:16.158087 20404 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1211 18:38:16.158087 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 18:38:16.158087 20404 net.cpp:122] Setting up group2_block1_conv0_scale
I1211 18:38:16.158087 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.158087 20404 net.cpp:137] Memory required for data: 600078000
I1211 18:38:16.158087 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1211 18:38:16.158087 20404 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1211 18:38:16.158087 20404 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1211 18:38:16.158087 20404 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1211 18:38:16.159106 20404 net.cpp:122] Setting up group2_block1_conv0_relu
I1211 18:38:16.159106 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.159106 20404 net.cpp:137] Memory required for data: 601716400
I1211 18:38:16.159106 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1211 18:38:16.159106 20404 net.cpp:84] Creating Layer group2_block1_conv1
I1211 18:38:16.159106 20404 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1211 18:38:16.159106 20404 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1211 18:38:16.161090 20404 net.cpp:122] Setting up group2_block1_conv1
I1211 18:38:16.161595 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.161595 20404 net.cpp:137] Memory required for data: 603354800
I1211 18:38:16.161595 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1211 18:38:16.161595 20404 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1211 18:38:16.161595 20404 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1211 18:38:16.161595 20404 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1211 18:38:16.161595 20404 net.cpp:122] Setting up group2_block1_conv1_bn
I1211 18:38:16.161595 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.161595 20404 net.cpp:137] Memory required for data: 604993200
I1211 18:38:16.161595 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 18:38:16.161595 20404 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1211 18:38:16.161595 20404 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1211 18:38:16.161595 20404 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1211 18:38:16.161595 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 18:38:16.162088 20404 net.cpp:122] Setting up group2_block1_conv1_scale
I1211 18:38:16.162088 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.162088 20404 net.cpp:137] Memory required for data: 606631600
I1211 18:38:16.162088 20404 layer_factory.cpp:58] Creating layer group2_block1_sum
I1211 18:38:16.162088 20404 net.cpp:84] Creating Layer group2_block1_sum
I1211 18:38:16.162088 20404 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1211 18:38:16.162088 20404 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1211 18:38:16.162088 20404 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1211 18:38:16.162088 20404 net.cpp:122] Setting up group2_block1_sum
I1211 18:38:16.162088 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.162088 20404 net.cpp:137] Memory required for data: 608270000
I1211 18:38:16.162088 20404 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1211 18:38:16.162088 20404 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1211 18:38:16.162088 20404 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1211 18:38:16.162088 20404 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1211 18:38:16.162088 20404 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1211 18:38:16.162088 20404 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1211 18:38:16.162088 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.162088 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.162088 20404 net.cpp:137] Memory required for data: 611546800
I1211 18:38:16.162088 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1211 18:38:16.162088 20404 net.cpp:84] Creating Layer group2_block2_conv0
I1211 18:38:16.162088 20404 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1211 18:38:16.162088 20404 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1211 18:38:16.164089 20404 net.cpp:122] Setting up group2_block2_conv0
I1211 18:38:16.164089 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.164089 20404 net.cpp:137] Memory required for data: 613185200
I1211 18:38:16.164089 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1211 18:38:16.164089 20404 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1211 18:38:16.164089 20404 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1211 18:38:16.164089 20404 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1211 18:38:16.164089 20404 net.cpp:122] Setting up group2_block2_conv0_bn
I1211 18:38:16.164089 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.164089 20404 net.cpp:137] Memory required for data: 614823600
I1211 18:38:16.164089 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 18:38:16.164089 20404 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1211 18:38:16.164089 20404 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1211 18:38:16.164089 20404 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1211 18:38:16.164089 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 18:38:16.164587 20404 net.cpp:122] Setting up group2_block2_conv0_scale
I1211 18:38:16.164587 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.164587 20404 net.cpp:137] Memory required for data: 616462000
I1211 18:38:16.164587 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1211 18:38:16.164587 20404 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1211 18:38:16.164587 20404 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1211 18:38:16.164587 20404 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1211 18:38:16.165088 20404 net.cpp:122] Setting up group2_block2_conv0_relu
I1211 18:38:16.165088 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.165088 20404 net.cpp:137] Memory required for data: 618100400
I1211 18:38:16.165088 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1211 18:38:16.165088 20404 net.cpp:84] Creating Layer group2_block2_conv1
I1211 18:38:16.165088 20404 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1211 18:38:16.165088 20404 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1211 18:38:16.166092 20404 net.cpp:122] Setting up group2_block2_conv1
I1211 18:38:16.166092 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.166092 20404 net.cpp:137] Memory required for data: 619738800
I1211 18:38:16.166092 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1211 18:38:16.166092 20404 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1211 18:38:16.166092 20404 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1211 18:38:16.166092 20404 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1211 18:38:16.167094 20404 net.cpp:122] Setting up group2_block2_conv1_bn
I1211 18:38:16.167094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.167094 20404 net.cpp:137] Memory required for data: 621377200
I1211 18:38:16.167094 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 18:38:16.167094 20404 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1211 18:38:16.167094 20404 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1211 18:38:16.167094 20404 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1211 18:38:16.167094 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 18:38:16.167094 20404 net.cpp:122] Setting up group2_block2_conv1_scale
I1211 18:38:16.167094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.167094 20404 net.cpp:137] Memory required for data: 623015600
I1211 18:38:16.167094 20404 layer_factory.cpp:58] Creating layer group2_block2_sum
I1211 18:38:16.167094 20404 net.cpp:84] Creating Layer group2_block2_sum
I1211 18:38:16.167094 20404 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1211 18:38:16.167094 20404 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1211 18:38:16.167094 20404 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1211 18:38:16.167094 20404 net.cpp:122] Setting up group2_block2_sum
I1211 18:38:16.167094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.167094 20404 net.cpp:137] Memory required for data: 624654000
I1211 18:38:16.167094 20404 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1211 18:38:16.167094 20404 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1211 18:38:16.167094 20404 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1211 18:38:16.167094 20404 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1211 18:38:16.167094 20404 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1211 18:38:16.167094 20404 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1211 18:38:16.167094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.167094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.167094 20404 net.cpp:137] Memory required for data: 627930800
I1211 18:38:16.167094 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1211 18:38:16.167094 20404 net.cpp:84] Creating Layer group2_block3_conv0
I1211 18:38:16.167094 20404 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1211 18:38:16.167094 20404 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1211 18:38:16.170095 20404 net.cpp:122] Setting up group2_block3_conv0
I1211 18:38:16.170095 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.170095 20404 net.cpp:137] Memory required for data: 629569200
I1211 18:38:16.170095 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1211 18:38:16.170095 20404 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1211 18:38:16.170095 20404 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1211 18:38:16.170095 20404 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1211 18:38:16.170095 20404 net.cpp:122] Setting up group2_block3_conv0_bn
I1211 18:38:16.170095 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.170095 20404 net.cpp:137] Memory required for data: 631207600
I1211 18:38:16.170095 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 18:38:16.170095 20404 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1211 18:38:16.170095 20404 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1211 18:38:16.170095 20404 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1211 18:38:16.170095 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 18:38:16.170095 20404 net.cpp:122] Setting up group2_block3_conv0_scale
I1211 18:38:16.170095 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.170095 20404 net.cpp:137] Memory required for data: 632846000
I1211 18:38:16.170095 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1211 18:38:16.170095 20404 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1211 18:38:16.170095 20404 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1211 18:38:16.170095 20404 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1211 18:38:16.171094 20404 net.cpp:122] Setting up group2_block3_conv0_relu
I1211 18:38:16.171094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.171094 20404 net.cpp:137] Memory required for data: 634484400
I1211 18:38:16.171094 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1211 18:38:16.171094 20404 net.cpp:84] Creating Layer group2_block3_conv1
I1211 18:38:16.171094 20404 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1211 18:38:16.171094 20404 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1211 18:38:16.173094 20404 net.cpp:122] Setting up group2_block3_conv1
I1211 18:38:16.173094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.173094 20404 net.cpp:137] Memory required for data: 636122800
I1211 18:38:16.173094 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1211 18:38:16.173094 20404 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1211 18:38:16.173094 20404 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1211 18:38:16.173094 20404 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1211 18:38:16.173094 20404 net.cpp:122] Setting up group2_block3_conv1_bn
I1211 18:38:16.173094 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.173094 20404 net.cpp:137] Memory required for data: 637761200
I1211 18:38:16.173094 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 18:38:16.173094 20404 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1211 18:38:16.173094 20404 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1211 18:38:16.173094 20404 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1211 18:38:16.173094 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 18:38:16.174093 20404 net.cpp:122] Setting up group2_block3_conv1_scale
I1211 18:38:16.174093 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.174093 20404 net.cpp:137] Memory required for data: 639399600
I1211 18:38:16.174093 20404 layer_factory.cpp:58] Creating layer group2_block3_sum
I1211 18:38:16.174093 20404 net.cpp:84] Creating Layer group2_block3_sum
I1211 18:38:16.174093 20404 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1211 18:38:16.174093 20404 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1211 18:38:16.174093 20404 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1211 18:38:16.174093 20404 net.cpp:122] Setting up group2_block3_sum
I1211 18:38:16.174093 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.174093 20404 net.cpp:137] Memory required for data: 641038000
I1211 18:38:16.174093 20404 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1211 18:38:16.174093 20404 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1211 18:38:16.174093 20404 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1211 18:38:16.174093 20404 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1211 18:38:16.174093 20404 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1211 18:38:16.174093 20404 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1211 18:38:16.174093 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.174093 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.174093 20404 net.cpp:137] Memory required for data: 644314800
I1211 18:38:16.174093 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1211 18:38:16.174093 20404 net.cpp:84] Creating Layer group2_block4_conv0
I1211 18:38:16.174093 20404 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1211 18:38:16.174093 20404 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1211 18:38:16.176092 20404 net.cpp:122] Setting up group2_block4_conv0
I1211 18:38:16.176092 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.176092 20404 net.cpp:137] Memory required for data: 645953200
I1211 18:38:16.176092 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1211 18:38:16.176092 20404 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1211 18:38:16.176092 20404 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1211 18:38:16.176092 20404 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1211 18:38:16.176092 20404 net.cpp:122] Setting up group2_block4_conv0_bn
I1211 18:38:16.176092 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.176092 20404 net.cpp:137] Memory required for data: 647591600
I1211 18:38:16.176092 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 18:38:16.176092 20404 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1211 18:38:16.176092 20404 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1211 18:38:16.176092 20404 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1211 18:38:16.176092 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 18:38:16.177091 20404 net.cpp:122] Setting up group2_block4_conv0_scale
I1211 18:38:16.177091 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.177091 20404 net.cpp:137] Memory required for data: 649230000
I1211 18:38:16.177091 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1211 18:38:16.177091 20404 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1211 18:38:16.177091 20404 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1211 18:38:16.177091 20404 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1211 18:38:16.177091 20404 net.cpp:122] Setting up group2_block4_conv0_relu
I1211 18:38:16.177091 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.177091 20404 net.cpp:137] Memory required for data: 650868400
I1211 18:38:16.177091 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1211 18:38:16.177091 20404 net.cpp:84] Creating Layer group2_block4_conv1
I1211 18:38:16.177091 20404 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1211 18:38:16.177091 20404 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1211 18:38:16.179091 20404 net.cpp:122] Setting up group2_block4_conv1
I1211 18:38:16.179091 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.179091 20404 net.cpp:137] Memory required for data: 652506800
I1211 18:38:16.179091 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1211 18:38:16.179091 20404 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1211 18:38:16.179091 20404 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1211 18:38:16.179091 20404 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1211 18:38:16.179091 20404 net.cpp:122] Setting up group2_block4_conv1_bn
I1211 18:38:16.179091 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.179091 20404 net.cpp:137] Memory required for data: 654145200
I1211 18:38:16.179091 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 18:38:16.179091 20404 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1211 18:38:16.179091 20404 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1211 18:38:16.179091 20404 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1211 18:38:16.179091 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 18:38:16.179091 20404 net.cpp:122] Setting up group2_block4_conv1_scale
I1211 18:38:16.179091 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.179091 20404 net.cpp:137] Memory required for data: 655783600
I1211 18:38:16.179091 20404 layer_factory.cpp:58] Creating layer group2_block4_sum
I1211 18:38:16.179091 20404 net.cpp:84] Creating Layer group2_block4_sum
I1211 18:38:16.179091 20404 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1211 18:38:16.179091 20404 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1211 18:38:16.179091 20404 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1211 18:38:16.179091 20404 net.cpp:122] Setting up group2_block4_sum
I1211 18:38:16.179091 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.179091 20404 net.cpp:137] Memory required for data: 657422000
I1211 18:38:16.179091 20404 layer_factory.cpp:58] Creating layer global_avg_pool
I1211 18:38:16.179091 20404 net.cpp:84] Creating Layer global_avg_pool
I1211 18:38:16.179091 20404 net.cpp:406] global_avg_pool <- group2_block4_sum
I1211 18:38:16.179091 20404 net.cpp:380] global_avg_pool -> global_avg_pool
I1211 18:38:16.179091 20404 net.cpp:122] Setting up global_avg_pool
I1211 18:38:16.179091 20404 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1211 18:38:16.179091 20404 net.cpp:137] Memory required for data: 657447600
I1211 18:38:16.179091 20404 layer_factory.cpp:58] Creating layer fc
I1211 18:38:16.179091 20404 net.cpp:84] Creating Layer fc
I1211 18:38:16.179091 20404 net.cpp:406] fc <- global_avg_pool
I1211 18:38:16.179091 20404 net.cpp:380] fc -> fc
I1211 18:38:16.180091 20404 net.cpp:122] Setting up fc
I1211 18:38:16.180091 20404 net.cpp:129] Top shape: 100 10 (1000)
I1211 18:38:16.180091 20404 net.cpp:137] Memory required for data: 657451600
I1211 18:38:16.180091 20404 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1211 18:38:16.180091 20404 net.cpp:84] Creating Layer fc_fc_0_split
I1211 18:38:16.180091 20404 net.cpp:406] fc_fc_0_split <- fc
I1211 18:38:16.180091 20404 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1211 18:38:16.180091 20404 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1211 18:38:16.180091 20404 net.cpp:122] Setting up fc_fc_0_split
I1211 18:38:16.180091 20404 net.cpp:129] Top shape: 100 10 (1000)
I1211 18:38:16.180091 20404 net.cpp:129] Top shape: 100 10 (1000)
I1211 18:38:16.180091 20404 net.cpp:137] Memory required for data: 657459600
I1211 18:38:16.180091 20404 layer_factory.cpp:58] Creating layer accuracy_training
I1211 18:38:16.180091 20404 net.cpp:84] Creating Layer accuracy_training
I1211 18:38:16.180091 20404 net.cpp:406] accuracy_training <- fc_fc_0_split_0
I1211 18:38:16.180091 20404 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1211 18:38:16.180091 20404 net.cpp:380] accuracy_training -> accuracy_training
I1211 18:38:16.180091 20404 net.cpp:122] Setting up accuracy_training
I1211 18:38:16.180091 20404 net.cpp:129] Top shape: (1)
I1211 18:38:16.180091 20404 net.cpp:137] Memory required for data: 657459604
I1211 18:38:16.180091 20404 layer_factory.cpp:58] Creating layer loss
I1211 18:38:16.180091 20404 net.cpp:84] Creating Layer loss
I1211 18:38:16.180091 20404 net.cpp:406] loss <- fc_fc_0_split_1
I1211 18:38:16.180091 20404 net.cpp:406] loss <- label_cifar_1_split_1
I1211 18:38:16.180091 20404 net.cpp:380] loss -> loss
I1211 18:38:16.180091 20404 layer_factory.cpp:58] Creating layer loss
I1211 18:38:16.180091 20404 net.cpp:122] Setting up loss
I1211 18:38:16.180091 20404 net.cpp:129] Top shape: (1)
I1211 18:38:16.180091 20404 net.cpp:132]     with loss weight 1
I1211 18:38:16.180091 20404 net.cpp:137] Memory required for data: 657459608
I1211 18:38:16.180091 20404 net.cpp:198] loss needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:200] accuracy_training does not need backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] fc_fc_0_split needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] fc needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] global_avg_pool needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_sum needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv1 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block4_conv0 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_sum needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv1 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block3_conv0 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_sum needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv1 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block2_conv0 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_sum needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_conv1 needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1211 18:38:16.180091 20404 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block1_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_proj needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] pool3 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group2_block0_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block4_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block3_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block2_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block1_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] pool2 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_proj needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] pool1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group1_block0_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block4_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block3_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block2_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block1_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_sum needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv1 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] group0_block0_conv0 needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] first_conv_relu needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] first_conv_scale needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] first_conv_bn needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:198] first_conv needs backward computation.
I1211 18:38:16.181092 20404 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 18:38:16.181092 20404 net.cpp:200] cifar does not need backward computation.
I1211 18:38:16.181092 20404 net.cpp:242] This network produces output accuracy_training
I1211 18:38:16.181092 20404 net.cpp:242] This network produces output loss
I1211 18:38:16.181092 20404 net.cpp:255] Network initialization done.
I1211 18:38:16.183092 20404 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 18:38:16.183092 20404 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 18:38:16.183092 20404 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 18:38:16.183092 20404 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1211 18:38:16.183092 20404 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1211 18:38:16.183092 20404 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "Soft
I1211 18:38:16.184106 20404 layer_factory.cpp:58] Creating layer cifar
I1211 18:38:16.191103 20404 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I1211 18:38:16.208133 20404 net.cpp:84] Creating Layer cifar
I1211 18:38:16.208133 20404 net.cpp:380] cifar -> data
I1211 18:38:16.208133 20404 net.cpp:380] cifar -> label
I1211 18:38:16.208133 20404 data_layer.cpp:45] output data size: 100,3,32,32
I1211 18:38:16.214102 20404 net.cpp:122] Setting up cifar
I1211 18:38:16.214102 20404 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 18:38:16.214102 20404 net.cpp:129] Top shape: 100 (100)
I1211 18:38:16.214102 20404 net.cpp:137] Memory required for data: 1229200
I1211 18:38:16.214102 20404 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 18:38:16.214102 20404 net.cpp:84] Creating Layer label_cifar_1_split
I1211 18:38:16.214102 20404 net.cpp:406] label_cifar_1_split <- label
I1211 18:38:16.214102 20404 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 18:38:16.214102 20404 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 18:38:16.214102 20404 net.cpp:122] Setting up label_cifar_1_split
I1211 18:38:16.214102 20404 net.cpp:129] Top shape: 100 (100)
I1211 18:38:16.214102 20404 net.cpp:129] Top shape: 100 (100)
I1211 18:38:16.214102 20404 net.cpp:137] Memory required for data: 1230000
I1211 18:38:16.214102 20404 layer_factory.cpp:58] Creating layer first_conv
I1211 18:38:16.214102 20404 net.cpp:84] Creating Layer first_conv
I1211 18:38:16.214102 20404 net.cpp:406] first_conv <- data
I1211 18:38:16.214102 20404 net.cpp:380] first_conv -> first_conv
I1211 18:38:16.216102  6752 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 18:38:16.216102 20404 net.cpp:122] Setting up first_conv
I1211 18:38:16.216102 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.216102 20404 net.cpp:137] Memory required for data: 7783600
I1211 18:38:16.216102 20404 layer_factory.cpp:58] Creating layer first_conv_bn
I1211 18:38:16.216102 20404 net.cpp:84] Creating Layer first_conv_bn
I1211 18:38:16.216102 20404 net.cpp:406] first_conv_bn <- first_conv
I1211 18:38:16.216102 20404 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1211 18:38:16.216102 20404 net.cpp:122] Setting up first_conv_bn
I1211 18:38:16.216102 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.216102 20404 net.cpp:137] Memory required for data: 14337200
I1211 18:38:16.216102 20404 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 18:38:16.216102 20404 net.cpp:84] Creating Layer first_conv_scale
I1211 18:38:16.216102 20404 net.cpp:406] first_conv_scale <- first_conv
I1211 18:38:16.216102 20404 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1211 18:38:16.216102 20404 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 18:38:16.216102 20404 net.cpp:122] Setting up first_conv_scale
I1211 18:38:16.216102 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.216102 20404 net.cpp:137] Memory required for data: 20890800
I1211 18:38:16.216102 20404 layer_factory.cpp:58] Creating layer first_conv_relu
I1211 18:38:16.216102 20404 net.cpp:84] Creating Layer first_conv_relu
I1211 18:38:16.216102 20404 net.cpp:406] first_conv_relu <- first_conv
I1211 18:38:16.216102 20404 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1211 18:38:16.217101 20404 net.cpp:122] Setting up first_conv_relu
I1211 18:38:16.217101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.217101 20404 net.cpp:137] Memory required for data: 27444400
I1211 18:38:16.217101 20404 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1211 18:38:16.217101 20404 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1211 18:38:16.217101 20404 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1211 18:38:16.217101 20404 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1211 18:38:16.217101 20404 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1211 18:38:16.217101 20404 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1211 18:38:16.217101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.217101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.217101 20404 net.cpp:137] Memory required for data: 40551600
I1211 18:38:16.217101 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1211 18:38:16.217101 20404 net.cpp:84] Creating Layer group0_block0_conv0
I1211 18:38:16.217101 20404 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1211 18:38:16.217101 20404 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1211 18:38:16.218106 20404 net.cpp:122] Setting up group0_block0_conv0
I1211 18:38:16.218106 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.218106 20404 net.cpp:137] Memory required for data: 47105200
I1211 18:38:16.218106 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1211 18:38:16.218106 20404 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1211 18:38:16.218106 20404 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1211 18:38:16.218106 20404 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1211 18:38:16.218106 20404 net.cpp:122] Setting up group0_block0_conv0_bn
I1211 18:38:16.218106 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.218106 20404 net.cpp:137] Memory required for data: 53658800
I1211 18:38:16.218106 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 18:38:16.218106 20404 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1211 18:38:16.218106 20404 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1211 18:38:16.218106 20404 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1211 18:38:16.218106 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 18:38:16.218106 20404 net.cpp:122] Setting up group0_block0_conv0_scale
I1211 18:38:16.218106 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.218106 20404 net.cpp:137] Memory required for data: 60212400
I1211 18:38:16.218106 20404 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1211 18:38:16.218106 20404 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1211 18:38:16.218106 20404 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1211 18:38:16.218106 20404 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1211 18:38:16.219102 20404 net.cpp:122] Setting up group0_block0_conv0_relu
I1211 18:38:16.219102 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.219102 20404 net.cpp:137] Memory required for data: 66766000
I1211 18:38:16.219102 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1211 18:38:16.219102 20404 net.cpp:84] Creating Layer group0_block0_conv1
I1211 18:38:16.219102 20404 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1211 18:38:16.219102 20404 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1211 18:38:16.220101 20404 net.cpp:122] Setting up group0_block0_conv1
I1211 18:38:16.220101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.220101 20404 net.cpp:137] Memory required for data: 73319600
I1211 18:38:16.220101 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1211 18:38:16.220101 20404 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1211 18:38:16.221101 20404 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1211 18:38:16.221101 20404 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1211 18:38:16.221101 20404 net.cpp:122] Setting up group0_block0_conv1_bn
I1211 18:38:16.221101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.221101 20404 net.cpp:137] Memory required for data: 79873200
I1211 18:38:16.221101 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 18:38:16.221101 20404 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1211 18:38:16.221101 20404 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1211 18:38:16.221101 20404 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1211 18:38:16.221101 20404 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 18:38:16.221101 20404 net.cpp:122] Setting up group0_block0_conv1_scale
I1211 18:38:16.221101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.221101 20404 net.cpp:137] Memory required for data: 86426800
I1211 18:38:16.221101 20404 layer_factory.cpp:58] Creating layer group0_block0_sum
I1211 18:38:16.221101 20404 net.cpp:84] Creating Layer group0_block0_sum
I1211 18:38:16.221101 20404 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1211 18:38:16.221101 20404 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1211 18:38:16.221101 20404 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1211 18:38:16.221101 20404 net.cpp:122] Setting up group0_block0_sum
I1211 18:38:16.221101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.221101 20404 net.cpp:137] Memory required for data: 92980400
I1211 18:38:16.221101 20404 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1211 18:38:16.221101 20404 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1211 18:38:16.221101 20404 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1211 18:38:16.221101 20404 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1211 18:38:16.221101 20404 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1211 18:38:16.221101 20404 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1211 18:38:16.221101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.221101 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.221101 20404 net.cpp:137] Memory required for data: 106087600
I1211 18:38:16.221101 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1211 18:38:16.221101 20404 net.cpp:84] Creating Layer group0_block1_conv0
I1211 18:38:16.221101 20404 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1211 18:38:16.221101 20404 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1211 18:38:16.222102 20404 net.cpp:122] Setting up group0_block1_conv0
I1211 18:38:16.222102 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.222102 20404 net.cpp:137] Memory required for data: 112641200
I1211 18:38:16.222102 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1211 18:38:16.222102 20404 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1211 18:38:16.222102 20404 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1211 18:38:16.222102 20404 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1211 18:38:16.223093 20404 net.cpp:122] Setting up group0_block1_conv0_bn
I1211 18:38:16.223093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.223093 20404 net.cpp:137] Memory required for data: 119194800
I1211 18:38:16.223093 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 18:38:16.223093 20404 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1211 18:38:16.223093 20404 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1211 18:38:16.223093 20404 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1211 18:38:16.223093 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 18:38:16.223093 20404 net.cpp:122] Setting up group0_block1_conv0_scale
I1211 18:38:16.223093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.223093 20404 net.cpp:137] Memory required for data: 125748400
I1211 18:38:16.223093 20404 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1211 18:38:16.223093 20404 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1211 18:38:16.223093 20404 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1211 18:38:16.223093 20404 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1211 18:38:16.224094 20404 net.cpp:122] Setting up group0_block1_conv0_relu
I1211 18:38:16.224094 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.224094 20404 net.cpp:137] Memory required for data: 132302000
I1211 18:38:16.224094 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1211 18:38:16.224094 20404 net.cpp:84] Creating Layer group0_block1_conv1
I1211 18:38:16.224094 20404 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1211 18:38:16.224094 20404 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1211 18:38:16.225091 20404 net.cpp:122] Setting up group0_block1_conv1
I1211 18:38:16.225091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.225091 20404 net.cpp:137] Memory required for data: 138855600
I1211 18:38:16.225091 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1211 18:38:16.225091 20404 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1211 18:38:16.225091 20404 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1211 18:38:16.225091 20404 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1211 18:38:16.225091 20404 net.cpp:122] Setting up group0_block1_conv1_bn
I1211 18:38:16.225091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.225091 20404 net.cpp:137] Memory required for data: 145409200
I1211 18:38:16.225091 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 18:38:16.225091 20404 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1211 18:38:16.225091 20404 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1211 18:38:16.225091 20404 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1211 18:38:16.225091 20404 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 18:38:16.225091 20404 net.cpp:122] Setting up group0_block1_conv1_scale
I1211 18:38:16.225091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.225091 20404 net.cpp:137] Memory required for data: 151962800
I1211 18:38:16.225091 20404 layer_factory.cpp:58] Creating layer group0_block1_sum
I1211 18:38:16.225091 20404 net.cpp:84] Creating Layer group0_block1_sum
I1211 18:38:16.226091 20404 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1211 18:38:16.226091 20404 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1211 18:38:16.226091 20404 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1211 18:38:16.226091 20404 net.cpp:122] Setting up group0_block1_sum
I1211 18:38:16.226091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.226091 20404 net.cpp:137] Memory required for data: 158516400
I1211 18:38:16.226091 20404 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1211 18:38:16.226091 20404 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1211 18:38:16.226091 20404 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1211 18:38:16.226091 20404 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1211 18:38:16.226091 20404 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1211 18:38:16.226091 20404 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1211 18:38:16.226091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.226091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.226091 20404 net.cpp:137] Memory required for data: 171623600
I1211 18:38:16.226091 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1211 18:38:16.226091 20404 net.cpp:84] Creating Layer group0_block2_conv0
I1211 18:38:16.226091 20404 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1211 18:38:16.226091 20404 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1211 18:38:16.227092 20404 net.cpp:122] Setting up group0_block2_conv0
I1211 18:38:16.227092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.227092 20404 net.cpp:137] Memory required for data: 178177200
I1211 18:38:16.227092 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1211 18:38:16.227092 20404 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1211 18:38:16.227092 20404 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1211 18:38:16.227092 20404 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1211 18:38:16.227092 20404 net.cpp:122] Setting up group0_block2_conv0_bn
I1211 18:38:16.227092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.227092 20404 net.cpp:137] Memory required for data: 184730800
I1211 18:38:16.227092 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 18:38:16.227092 20404 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1211 18:38:16.227092 20404 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1211 18:38:16.227092 20404 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1211 18:38:16.227092 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 18:38:16.227092 20404 net.cpp:122] Setting up group0_block2_conv0_scale
I1211 18:38:16.227092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.227092 20404 net.cpp:137] Memory required for data: 191284400
I1211 18:38:16.227092 20404 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1211 18:38:16.227092 20404 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1211 18:38:16.227092 20404 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1211 18:38:16.227092 20404 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1211 18:38:16.228091 20404 net.cpp:122] Setting up group0_block2_conv0_relu
I1211 18:38:16.228091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.228091 20404 net.cpp:137] Memory required for data: 197838000
I1211 18:38:16.228091 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1211 18:38:16.228091 20404 net.cpp:84] Creating Layer group0_block2_conv1
I1211 18:38:16.228091 20404 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1211 18:38:16.228091 20404 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1211 18:38:16.229091 20404 net.cpp:122] Setting up group0_block2_conv1
I1211 18:38:16.229091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.229091 20404 net.cpp:137] Memory required for data: 204391600
I1211 18:38:16.229091 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1211 18:38:16.229091 20404 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1211 18:38:16.229091 20404 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1211 18:38:16.229091 20404 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1211 18:38:16.229091 20404 net.cpp:122] Setting up group0_block2_conv1_bn
I1211 18:38:16.229091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.229091 20404 net.cpp:137] Memory required for data: 210945200
I1211 18:38:16.229091 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 18:38:16.229091 20404 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1211 18:38:16.229091 20404 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1211 18:38:16.229091 20404 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1211 18:38:16.229091 20404 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 18:38:16.229091 20404 net.cpp:122] Setting up group0_block2_conv1_scale
I1211 18:38:16.229091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.229091 20404 net.cpp:137] Memory required for data: 217498800
I1211 18:38:16.229091 20404 layer_factory.cpp:58] Creating layer group0_block2_sum
I1211 18:38:16.229091 20404 net.cpp:84] Creating Layer group0_block2_sum
I1211 18:38:16.229091 20404 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1211 18:38:16.229091 20404 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1211 18:38:16.229091 20404 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1211 18:38:16.229091 20404 net.cpp:122] Setting up group0_block2_sum
I1211 18:38:16.229091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.229091 20404 net.cpp:137] Memory required for data: 224052400
I1211 18:38:16.229091 20404 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1211 18:38:16.229091 20404 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1211 18:38:16.229091 20404 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1211 18:38:16.229091 20404 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1211 18:38:16.229091 20404 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1211 18:38:16.229091 20404 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1211 18:38:16.229091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.230092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.230092 20404 net.cpp:137] Memory required for data: 237159600
I1211 18:38:16.230092 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1211 18:38:16.230092 20404 net.cpp:84] Creating Layer group0_block3_conv0
I1211 18:38:16.230092 20404 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1211 18:38:16.230092 20404 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1211 18:38:16.231091 20404 net.cpp:122] Setting up group0_block3_conv0
I1211 18:38:16.231091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.231091 20404 net.cpp:137] Memory required for data: 243713200
I1211 18:38:16.231091 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1211 18:38:16.231091 20404 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1211 18:38:16.231091 20404 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1211 18:38:16.231091 20404 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1211 18:38:16.231091 20404 net.cpp:122] Setting up group0_block3_conv0_bn
I1211 18:38:16.231091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.231091 20404 net.cpp:137] Memory required for data: 250266800
I1211 18:38:16.231091 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 18:38:16.231091 20404 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1211 18:38:16.231091 20404 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1211 18:38:16.231091 20404 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1211 18:38:16.231091 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 18:38:16.231091 20404 net.cpp:122] Setting up group0_block3_conv0_scale
I1211 18:38:16.231091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.231091 20404 net.cpp:137] Memory required for data: 256820400
I1211 18:38:16.231091 20404 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1211 18:38:16.231091 20404 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1211 18:38:16.231091 20404 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1211 18:38:16.231091 20404 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1211 18:38:16.231091 20404 net.cpp:122] Setting up group0_block3_conv0_relu
I1211 18:38:16.231091 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.231091 20404 net.cpp:137] Memory required for data: 263374000
I1211 18:38:16.231091 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1211 18:38:16.231091 20404 net.cpp:84] Creating Layer group0_block3_conv1
I1211 18:38:16.231091 20404 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1211 18:38:16.231091 20404 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1211 18:38:16.233093 20404 net.cpp:122] Setting up group0_block3_conv1
I1211 18:38:16.233093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.233093 20404 net.cpp:137] Memory required for data: 269927600
I1211 18:38:16.233093 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1211 18:38:16.233093 20404 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1211 18:38:16.233093 20404 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1211 18:38:16.233093 20404 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1211 18:38:16.233093 20404 net.cpp:122] Setting up group0_block3_conv1_bn
I1211 18:38:16.233093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.233093 20404 net.cpp:137] Memory required for data: 276481200
I1211 18:38:16.233093 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 18:38:16.233093 20404 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1211 18:38:16.233093 20404 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1211 18:38:16.233093 20404 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1211 18:38:16.233093 20404 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 18:38:16.233093 20404 net.cpp:122] Setting up group0_block3_conv1_scale
I1211 18:38:16.233093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.233093 20404 net.cpp:137] Memory required for data: 283034800
I1211 18:38:16.233093 20404 layer_factory.cpp:58] Creating layer group0_block3_sum
I1211 18:38:16.233093 20404 net.cpp:84] Creating Layer group0_block3_sum
I1211 18:38:16.233093 20404 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1211 18:38:16.233093 20404 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1211 18:38:16.233093 20404 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1211 18:38:16.233093 20404 net.cpp:122] Setting up group0_block3_sum
I1211 18:38:16.233093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.233093 20404 net.cpp:137] Memory required for data: 289588400
I1211 18:38:16.233093 20404 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1211 18:38:16.233093 20404 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1211 18:38:16.233093 20404 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1211 18:38:16.233093 20404 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1211 18:38:16.233093 20404 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1211 18:38:16.233093 20404 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1211 18:38:16.233093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.233093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.233093 20404 net.cpp:137] Memory required for data: 302695600
I1211 18:38:16.233093 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1211 18:38:16.233093 20404 net.cpp:84] Creating Layer group0_block4_conv0
I1211 18:38:16.233093 20404 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1211 18:38:16.233093 20404 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1211 18:38:16.235110 20404 net.cpp:122] Setting up group0_block4_conv0
I1211 18:38:16.235110 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.235110 20404 net.cpp:137] Memory required for data: 309249200
I1211 18:38:16.235110 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1211 18:38:16.235110 20404 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1211 18:38:16.235110 20404 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1211 18:38:16.235110 20404 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1211 18:38:16.235110 20404 net.cpp:122] Setting up group0_block4_conv0_bn
I1211 18:38:16.235110 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.235110 20404 net.cpp:137] Memory required for data: 315802800
I1211 18:38:16.235110 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 18:38:16.235110 20404 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1211 18:38:16.235110 20404 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1211 18:38:16.235110 20404 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1211 18:38:16.235110 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 18:38:16.235110 20404 net.cpp:122] Setting up group0_block4_conv0_scale
I1211 18:38:16.235110 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.235110 20404 net.cpp:137] Memory required for data: 322356400
I1211 18:38:16.235110 20404 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1211 18:38:16.235110 20404 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1211 18:38:16.235110 20404 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1211 18:38:16.235110 20404 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1211 18:38:16.236093 20404 net.cpp:122] Setting up group0_block4_conv0_relu
I1211 18:38:16.236093 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.236093 20404 net.cpp:137] Memory required for data: 328910000
I1211 18:38:16.236093 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1211 18:38:16.236093 20404 net.cpp:84] Creating Layer group0_block4_conv1
I1211 18:38:16.236093 20404 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1211 18:38:16.236093 20404 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1211 18:38:16.237092 20404 net.cpp:122] Setting up group0_block4_conv1
I1211 18:38:16.237092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.237092 20404 net.cpp:137] Memory required for data: 335463600
I1211 18:38:16.237092 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1211 18:38:16.237092 20404 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1211 18:38:16.237092 20404 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1211 18:38:16.237092 20404 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1211 18:38:16.237092 20404 net.cpp:122] Setting up group0_block4_conv1_bn
I1211 18:38:16.237092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.237092 20404 net.cpp:137] Memory required for data: 342017200
I1211 18:38:16.237092 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 18:38:16.237092 20404 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1211 18:38:16.237092 20404 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1211 18:38:16.237092 20404 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1211 18:38:16.237092 20404 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 18:38:16.237092 20404 net.cpp:122] Setting up group0_block4_conv1_scale
I1211 18:38:16.237092 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.237092 20404 net.cpp:137] Memory required for data: 348570800
I1211 18:38:16.237092 20404 layer_factory.cpp:58] Creating layer group0_block4_sum
I1211 18:38:16.237092 20404 net.cpp:84] Creating Layer group0_block4_sum
I1211 18:38:16.237092 20404 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1211 18:38:16.237092 20404 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1211 18:38:16.237092 20404 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1211 18:38:16.237092 20404 net.cpp:122] Setting up group0_block4_sum
I1211 18:38:16.238106 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.238106 20404 net.cpp:137] Memory required for data: 355124400
I1211 18:38:16.238106 20404 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1211 18:38:16.238106 20404 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1211 18:38:16.238106 20404 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1211 18:38:16.238106 20404 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1211 18:38:16.238106 20404 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1211 18:38:16.238106 20404 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1211 18:38:16.238106 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.238106 20404 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 18:38:16.238106 20404 net.cpp:137] Memory required for data: 368231600
I1211 18:38:16.238106 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1211 18:38:16.238106 20404 net.cpp:84] Creating Layer group1_block0_conv0
I1211 18:38:16.238106 20404 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1211 18:38:16.238106 20404 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1211 18:38:16.239105 20404 net.cpp:122] Setting up group1_block0_conv0
I1211 18:38:16.239105 20404 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1211 18:38:16.239105 20404 net.cpp:137] Memory required for data: 381338800
I1211 18:38:16.239105 20404 layer_factory.cpp:58] Creating layer pool1
I1211 18:38:16.239105 20404 net.cpp:84] Creating Layer pool1
I1211 18:38:16.239105 20404 net.cpp:406] pool1 <- group1_block0_conv0
I1211 18:38:16.239105 20404 net.cpp:380] pool1 -> pool1
I1211 18:38:16.240092 20404 net.cpp:122] Setting up pool1
I1211 18:38:16.240092 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.240092 20404 net.cpp:137] Memory required for data: 384615600
I1211 18:38:16.240092 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1211 18:38:16.240092 20404 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1211 18:38:16.240092 20404 net.cpp:406] group1_block0_conv0_bn <- pool1
I1211 18:38:16.240092 20404 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1211 18:38:16.240092 20404 net.cpp:122] Setting up group1_block0_conv0_bn
I1211 18:38:16.240092 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.240092 20404 net.cpp:137] Memory required for data: 387892400
I1211 18:38:16.240092 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 18:38:16.240092 20404 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1211 18:38:16.240092 20404 net.cpp:406] group1_block0_conv0_scale <- pool1
I1211 18:38:16.240092 20404 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1211 18:38:16.240092 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 18:38:16.240092 20404 net.cpp:122] Setting up group1_block0_conv0_scale
I1211 18:38:16.240092 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.240092 20404 net.cpp:137] Memory required for data: 391169200
I1211 18:38:16.240092 20404 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1211 18:38:16.240092 20404 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1211 18:38:16.240092 20404 net.cpp:406] group1_block0_conv0_relu <- pool1
I1211 18:38:16.240092 20404 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1211 18:38:16.240092 20404 net.cpp:122] Setting up group1_block0_conv0_relu
I1211 18:38:16.240092 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.240092 20404 net.cpp:137] Memory required for data: 394446000
I1211 18:38:16.240092 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1211 18:38:16.240092 20404 net.cpp:84] Creating Layer group1_block0_conv1
I1211 18:38:16.240092 20404 net.cpp:406] group1_block0_conv1 <- pool1
I1211 18:38:16.240092 20404 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1211 18:38:16.242090 20404 net.cpp:122] Setting up group1_block0_conv1
I1211 18:38:16.242090 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.242090 20404 net.cpp:137] Memory required for data: 397722800
I1211 18:38:16.242090 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1211 18:38:16.242090 20404 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1211 18:38:16.242090 20404 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1211 18:38:16.242090 20404 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1211 18:38:16.242090 20404 net.cpp:122] Setting up group1_block0_conv1_bn
I1211 18:38:16.242090 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.242090 20404 net.cpp:137] Memory required for data: 400999600
I1211 18:38:16.242090 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 18:38:16.242090 20404 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1211 18:38:16.242090 20404 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1211 18:38:16.242090 20404 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1211 18:38:16.242090 20404 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 18:38:16.242090 20404 net.cpp:122] Setting up group1_block0_conv1_scale
I1211 18:38:16.242090 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.242090 20404 net.cpp:137] Memory required for data: 404276400
I1211 18:38:16.242090 20404 layer_factory.cpp:58] Creating layer group1_block0_proj
I1211 18:38:16.242090 20404 net.cpp:84] Creating Layer group1_block0_proj
I1211 18:38:16.242090 20404 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1211 18:38:16.242090 20404 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1211 18:38:16.243091 20404 net.cpp:122] Setting up group1_block0_proj
I1211 18:38:16.243091 20404 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1211 18:38:16.243091 20404 net.cpp:137] Memory required for data: 416577200
I1211 18:38:16.243091 20404 layer_factory.cpp:58] Creating layer pool2
I1211 18:38:16.243091 20404 net.cpp:84] Creating Layer pool2
I1211 18:38:16.243091 20404 net.cpp:406] pool2 <- group1_block0_proj
I1211 18:38:16.243091 20404 net.cpp:380] pool2 -> pool2
I1211 18:38:16.243091 20404 net.cpp:122] Setting up pool2
I1211 18:38:16.243091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.243091 20404 net.cpp:137] Memory required for data: 419854000
I1211 18:38:16.243091 20404 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1211 18:38:16.243091 20404 net.cpp:84] Creating Layer group1_block0_proj_bn
I1211 18:38:16.243091 20404 net.cpp:406] group1_block0_proj_bn <- pool2
I1211 18:38:16.243091 20404 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1211 18:38:16.244091 20404 net.cpp:122] Setting up group1_block0_proj_bn
I1211 18:38:16.244091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.244091 20404 net.cpp:137] Memory required for data: 423130800
I1211 18:38:16.244091 20404 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 18:38:16.244091 20404 net.cpp:84] Creating Layer group1_block0_proj_scale
I1211 18:38:16.244091 20404 net.cpp:406] group1_block0_proj_scale <- pool2
I1211 18:38:16.244091 20404 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1211 18:38:16.244091 20404 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 18:38:16.244091 20404 net.cpp:122] Setting up group1_block0_proj_scale
I1211 18:38:16.244091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.244091 20404 net.cpp:137] Memory required for data: 426407600
I1211 18:38:16.244091 20404 layer_factory.cpp:58] Creating layer group1_block0_sum
I1211 18:38:16.244091 20404 net.cpp:84] Creating Layer group1_block0_sum
I1211 18:38:16.244091 20404 net.cpp:406] group1_block0_sum <- pool2
I1211 18:38:16.244091 20404 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1211 18:38:16.244091 20404 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1211 18:38:16.244091 20404 net.cpp:122] Setting up group1_block0_sum
I1211 18:38:16.244091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.244091 20404 net.cpp:137] Memory required for data: 429684400
I1211 18:38:16.244091 20404 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1211 18:38:16.244091 20404 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1211 18:38:16.244091 20404 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1211 18:38:16.244091 20404 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1211 18:38:16.244091 20404 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1211 18:38:16.244091 20404 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1211 18:38:16.244091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.244091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.244091 20404 net.cpp:137] Memory required for data: 436238000
I1211 18:38:16.244091 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1211 18:38:16.244091 20404 net.cpp:84] Creating Layer group1_block1_conv0
I1211 18:38:16.244091 20404 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1211 18:38:16.244091 20404 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1211 18:38:16.246091 20404 net.cpp:122] Setting up group1_block1_conv0
I1211 18:38:16.246091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.246091 20404 net.cpp:137] Memory required for data: 439514800
I1211 18:38:16.246091 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1211 18:38:16.246091 20404 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1211 18:38:16.246091 20404 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1211 18:38:16.246091 20404 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1211 18:38:16.246091 20404 net.cpp:122] Setting up group1_block1_conv0_bn
I1211 18:38:16.246091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.246091 20404 net.cpp:137] Memory required for data: 442791600
I1211 18:38:16.246091 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 18:38:16.246091 20404 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1211 18:38:16.246091 20404 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1211 18:38:16.246091 20404 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1211 18:38:16.246091 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 18:38:16.246091 20404 net.cpp:122] Setting up group1_block1_conv0_scale
I1211 18:38:16.246091 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.246091 20404 net.cpp:137] Memory required for data: 446068400
I1211 18:38:16.246091 20404 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1211 18:38:16.246091 20404 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1211 18:38:16.246091 20404 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1211 18:38:16.246091 20404 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1211 18:38:16.247090 20404 net.cpp:122] Setting up group1_block1_conv0_relu
I1211 18:38:16.247090 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.247090 20404 net.cpp:137] Memory required for data: 449345200
I1211 18:38:16.247090 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1211 18:38:16.247090 20404 net.cpp:84] Creating Layer group1_block1_conv1
I1211 18:38:16.247090 20404 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1211 18:38:16.247090 20404 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1211 18:38:16.248106 20404 net.cpp:122] Setting up group1_block1_conv1
I1211 18:38:16.248106 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.248106 20404 net.cpp:137] Memory required for data: 452622000
I1211 18:38:16.248106 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1211 18:38:16.248106 20404 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1211 18:38:16.248106 20404 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1211 18:38:16.248106 20404 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1211 18:38:16.248106 20404 net.cpp:122] Setting up group1_block1_conv1_bn
I1211 18:38:16.248106 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.248106 20404 net.cpp:137] Memory required for data: 455898800
I1211 18:38:16.248106 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 18:38:16.248106 20404 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1211 18:38:16.248106 20404 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1211 18:38:16.248106 20404 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1211 18:38:16.248106 20404 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 18:38:16.248106 20404 net.cpp:122] Setting up group1_block1_conv1_scale
I1211 18:38:16.248106 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.248106 20404 net.cpp:137] Memory required for data: 459175600
I1211 18:38:16.248106 20404 layer_factory.cpp:58] Creating layer group1_block1_sum
I1211 18:38:16.248106 20404 net.cpp:84] Creating Layer group1_block1_sum
I1211 18:38:16.248106 20404 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1211 18:38:16.248106 20404 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1211 18:38:16.248106 20404 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1211 18:38:16.248106 20404 net.cpp:122] Setting up group1_block1_sum
I1211 18:38:16.248106 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.248106 20404 net.cpp:137] Memory required for data: 462452400
I1211 18:38:16.248106 20404 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1211 18:38:16.248106 20404 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1211 18:38:16.248106 20404 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1211 18:38:16.248106 20404 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1211 18:38:16.248106 20404 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1211 18:38:16.249105 20404 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1211 18:38:16.249105 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.249105 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.249105 20404 net.cpp:137] Memory required for data: 469006000
I1211 18:38:16.249105 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1211 18:38:16.249105 20404 net.cpp:84] Creating Layer group1_block2_conv0
I1211 18:38:16.249105 20404 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1211 18:38:16.249105 20404 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1211 18:38:16.250614 20404 net.cpp:122] Setting up group1_block2_conv0
I1211 18:38:16.250614 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.250614 20404 net.cpp:137] Memory required for data: 472282800
I1211 18:38:16.250614 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1211 18:38:16.250614 20404 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1211 18:38:16.250614 20404 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1211 18:38:16.250614 20404 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1211 18:38:16.251113 20404 net.cpp:122] Setting up group1_block2_conv0_bn
I1211 18:38:16.251113 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.251113 20404 net.cpp:137] Memory required for data: 475559600
I1211 18:38:16.251113 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 18:38:16.251113 20404 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1211 18:38:16.251113 20404 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1211 18:38:16.251113 20404 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1211 18:38:16.251113 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 18:38:16.251113 20404 net.cpp:122] Setting up group1_block2_conv0_scale
I1211 18:38:16.251113 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.251113 20404 net.cpp:137] Memory required for data: 478836400
I1211 18:38:16.251113 20404 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1211 18:38:16.251113 20404 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1211 18:38:16.251113 20404 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1211 18:38:16.251113 20404 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1211 18:38:16.251612 20404 net.cpp:122] Setting up group1_block2_conv0_relu
I1211 18:38:16.251612 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.251612 20404 net.cpp:137] Memory required for data: 482113200
I1211 18:38:16.251612 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1211 18:38:16.251612 20404 net.cpp:84] Creating Layer group1_block2_conv1
I1211 18:38:16.251612 20404 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1211 18:38:16.251612 20404 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1211 18:38:16.252598 20404 net.cpp:122] Setting up group1_block2_conv1
I1211 18:38:16.252598 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.252598 20404 net.cpp:137] Memory required for data: 485390000
I1211 18:38:16.252598 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1211 18:38:16.252598 20404 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1211 18:38:16.252598 20404 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1211 18:38:16.253098 20404 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1211 18:38:16.253098 20404 net.cpp:122] Setting up group1_block2_conv1_bn
I1211 18:38:16.253098 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.253098 20404 net.cpp:137] Memory required for data: 488666800
I1211 18:38:16.253098 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 18:38:16.253098 20404 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1211 18:38:16.253098 20404 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1211 18:38:16.253098 20404 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1211 18:38:16.253098 20404 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 18:38:16.253098 20404 net.cpp:122] Setting up group1_block2_conv1_scale
I1211 18:38:16.253098 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.253098 20404 net.cpp:137] Memory required for data: 491943600
I1211 18:38:16.253098 20404 layer_factory.cpp:58] Creating layer group1_block2_sum
I1211 18:38:16.253098 20404 net.cpp:84] Creating Layer group1_block2_sum
I1211 18:38:16.253098 20404 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1211 18:38:16.253098 20404 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1211 18:38:16.253598 20404 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1211 18:38:16.253598 20404 net.cpp:122] Setting up group1_block2_sum
I1211 18:38:16.253598 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.253598 20404 net.cpp:137] Memory required for data: 495220400
I1211 18:38:16.253598 20404 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1211 18:38:16.253598 20404 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1211 18:38:16.253598 20404 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1211 18:38:16.253598 20404 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1211 18:38:16.253598 20404 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1211 18:38:16.253598 20404 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1211 18:38:16.253598 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.253598 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.253598 20404 net.cpp:137] Memory required for data: 501774000
I1211 18:38:16.253598 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1211 18:38:16.253598 20404 net.cpp:84] Creating Layer group1_block3_conv0
I1211 18:38:16.253598 20404 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1211 18:38:16.253598 20404 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1211 18:38:16.255108 20404 net.cpp:122] Setting up group1_block3_conv0
I1211 18:38:16.255108 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.255108 20404 net.cpp:137] Memory required for data: 505050800
I1211 18:38:16.255108 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1211 18:38:16.255108 20404 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1211 18:38:16.255108 20404 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1211 18:38:16.255108 20404 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1211 18:38:16.255108 20404 net.cpp:122] Setting up group1_block3_conv0_bn
I1211 18:38:16.255108 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.255108 20404 net.cpp:137] Memory required for data: 508327600
I1211 18:38:16.255108 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 18:38:16.255108 20404 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1211 18:38:16.255108 20404 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1211 18:38:16.255108 20404 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1211 18:38:16.255108 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 18:38:16.255609 20404 net.cpp:122] Setting up group1_block3_conv0_scale
I1211 18:38:16.255609 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.255609 20404 net.cpp:137] Memory required for data: 511604400
I1211 18:38:16.255609 20404 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1211 18:38:16.255609 20404 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1211 18:38:16.255609 20404 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1211 18:38:16.255609 20404 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1211 18:38:16.255609 20404 net.cpp:122] Setting up group1_block3_conv0_relu
I1211 18:38:16.255609 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.255609 20404 net.cpp:137] Memory required for data: 514881200
I1211 18:38:16.255609 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1211 18:38:16.255609 20404 net.cpp:84] Creating Layer group1_block3_conv1
I1211 18:38:16.255609 20404 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1211 18:38:16.255609 20404 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1211 18:38:16.257098 20404 net.cpp:122] Setting up group1_block3_conv1
I1211 18:38:16.257098 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.257098 20404 net.cpp:137] Memory required for data: 518158000
I1211 18:38:16.257098 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1211 18:38:16.257098 20404 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1211 18:38:16.257098 20404 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1211 18:38:16.257098 20404 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1211 18:38:16.257098 20404 net.cpp:122] Setting up group1_block3_conv1_bn
I1211 18:38:16.257098 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.257098 20404 net.cpp:137] Memory required for data: 521434800
I1211 18:38:16.257098 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 18:38:16.257098 20404 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1211 18:38:16.257098 20404 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1211 18:38:16.257098 20404 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1211 18:38:16.257597 20404 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 18:38:16.257597 20404 net.cpp:122] Setting up group1_block3_conv1_scale
I1211 18:38:16.257597 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.257597 20404 net.cpp:137] Memory required for data: 524711600
I1211 18:38:16.258100 20404 layer_factory.cpp:58] Creating layer group1_block3_sum
I1211 18:38:16.258100 20404 net.cpp:84] Creating Layer group1_block3_sum
I1211 18:38:16.258100 20404 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1211 18:38:16.258100 20404 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1211 18:38:16.258100 20404 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1211 18:38:16.258100 20404 net.cpp:122] Setting up group1_block3_sum
I1211 18:38:16.258100 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.258100 20404 net.cpp:137] Memory required for data: 527988400
I1211 18:38:16.258100 20404 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1211 18:38:16.258100 20404 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1211 18:38:16.258100 20404 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1211 18:38:16.258100 20404 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1211 18:38:16.258100 20404 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1211 18:38:16.258100 20404 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1211 18:38:16.258100 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.258100 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.258100 20404 net.cpp:137] Memory required for data: 534542000
I1211 18:38:16.258100 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1211 18:38:16.258100 20404 net.cpp:84] Creating Layer group1_block4_conv0
I1211 18:38:16.258100 20404 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1211 18:38:16.258100 20404 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1211 18:38:16.259608 20404 net.cpp:122] Setting up group1_block4_conv0
I1211 18:38:16.259608 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.259608 20404 net.cpp:137] Memory required for data: 537818800
I1211 18:38:16.259608 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1211 18:38:16.259608 20404 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1211 18:38:16.259608 20404 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1211 18:38:16.259608 20404 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1211 18:38:16.260108 20404 net.cpp:122] Setting up group1_block4_conv0_bn
I1211 18:38:16.260108 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.260108 20404 net.cpp:137] Memory required for data: 541095600
I1211 18:38:16.260108 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 18:38:16.260108 20404 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1211 18:38:16.260108 20404 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1211 18:38:16.260108 20404 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1211 18:38:16.260108 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 18:38:16.260108 20404 net.cpp:122] Setting up group1_block4_conv0_scale
I1211 18:38:16.260108 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.260108 20404 net.cpp:137] Memory required for data: 544372400
I1211 18:38:16.260108 20404 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1211 18:38:16.260108 20404 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1211 18:38:16.260108 20404 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1211 18:38:16.260608 20404 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1211 18:38:16.260608 20404 net.cpp:122] Setting up group1_block4_conv0_relu
I1211 18:38:16.260608 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.260608 20404 net.cpp:137] Memory required for data: 547649200
I1211 18:38:16.260608 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1211 18:38:16.260608 20404 net.cpp:84] Creating Layer group1_block4_conv1
I1211 18:38:16.260608 20404 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1211 18:38:16.260608 20404 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1211 18:38:16.262109 20404 net.cpp:122] Setting up group1_block4_conv1
I1211 18:38:16.262109 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.262109 20404 net.cpp:137] Memory required for data: 550926000
I1211 18:38:16.262109 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1211 18:38:16.262109 20404 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1211 18:38:16.262109 20404 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1211 18:38:16.262109 20404 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1211 18:38:16.262109 20404 net.cpp:122] Setting up group1_block4_conv1_bn
I1211 18:38:16.262109 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.262109 20404 net.cpp:137] Memory required for data: 554202800
I1211 18:38:16.262109 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 18:38:16.262109 20404 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1211 18:38:16.262109 20404 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1211 18:38:16.262109 20404 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1211 18:38:16.262109 20404 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 18:38:16.262609 20404 net.cpp:122] Setting up group1_block4_conv1_scale
I1211 18:38:16.262609 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.262609 20404 net.cpp:137] Memory required for data: 557479600
I1211 18:38:16.262609 20404 layer_factory.cpp:58] Creating layer group1_block4_sum
I1211 18:38:16.262609 20404 net.cpp:84] Creating Layer group1_block4_sum
I1211 18:38:16.262609 20404 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1211 18:38:16.262609 20404 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1211 18:38:16.262609 20404 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1211 18:38:16.262609 20404 net.cpp:122] Setting up group1_block4_sum
I1211 18:38:16.262609 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.262609 20404 net.cpp:137] Memory required for data: 560756400
I1211 18:38:16.262609 20404 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1211 18:38:16.262609 20404 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1211 18:38:16.262609 20404 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1211 18:38:16.262609 20404 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1211 18:38:16.262609 20404 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1211 18:38:16.262609 20404 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1211 18:38:16.262609 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.262609 20404 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 18:38:16.262609 20404 net.cpp:137] Memory required for data: 567310000
I1211 18:38:16.262609 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1211 18:38:16.262609 20404 net.cpp:84] Creating Layer group2_block0_conv0
I1211 18:38:16.262609 20404 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1211 18:38:16.262609 20404 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1211 18:38:16.264113 20404 net.cpp:122] Setting up group2_block0_conv0
I1211 18:38:16.264113 20404 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1211 18:38:16.264113 20404 net.cpp:137] Memory required for data: 573863600
I1211 18:38:16.264113 20404 layer_factory.cpp:58] Creating layer pool3
I1211 18:38:16.264113 20404 net.cpp:84] Creating Layer pool3
I1211 18:38:16.264113 20404 net.cpp:406] pool3 <- group2_block0_conv0
I1211 18:38:16.264113 20404 net.cpp:380] pool3 -> pool3
I1211 18:38:16.264113 20404 net.cpp:122] Setting up pool3
I1211 18:38:16.264113 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.264113 20404 net.cpp:137] Memory required for data: 575502000
I1211 18:38:16.264113 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1211 18:38:16.264113 20404 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1211 18:38:16.264113 20404 net.cpp:406] group2_block0_conv0_bn <- pool3
I1211 18:38:16.264113 20404 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1211 18:38:16.264613 20404 net.cpp:122] Setting up group2_block0_conv0_bn
I1211 18:38:16.264613 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.264613 20404 net.cpp:137] Memory required for data: 577140400
I1211 18:38:16.264613 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 18:38:16.264613 20404 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1211 18:38:16.264613 20404 net.cpp:406] group2_block0_conv0_scale <- pool3
I1211 18:38:16.264613 20404 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1211 18:38:16.264613 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 18:38:16.264613 20404 net.cpp:122] Setting up group2_block0_conv0_scale
I1211 18:38:16.264613 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.264613 20404 net.cpp:137] Memory required for data: 578778800
I1211 18:38:16.264613 20404 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1211 18:38:16.264613 20404 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1211 18:38:16.264613 20404 net.cpp:406] group2_block0_conv0_relu <- pool3
I1211 18:38:16.264613 20404 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1211 18:38:16.265112 20404 net.cpp:122] Setting up group2_block0_conv0_relu
I1211 18:38:16.265112 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.265112 20404 net.cpp:137] Memory required for data: 580417200
I1211 18:38:16.265112 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1211 18:38:16.265112 20404 net.cpp:84] Creating Layer group2_block0_conv1
I1211 18:38:16.265112 20404 net.cpp:406] group2_block0_conv1 <- pool3
I1211 18:38:16.265112 20404 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1211 18:38:16.266115 20404 net.cpp:122] Setting up group2_block0_conv1
I1211 18:38:16.266115 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.266115 20404 net.cpp:137] Memory required for data: 582055600
I1211 18:38:16.266115 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1211 18:38:16.266115 20404 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1211 18:38:16.266115 20404 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1211 18:38:16.266115 20404 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1211 18:38:16.266115 20404 net.cpp:122] Setting up group2_block0_conv1_bn
I1211 18:38:16.266115 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.266115 20404 net.cpp:137] Memory required for data: 583694000
I1211 18:38:16.266115 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 18:38:16.267127 20404 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1211 18:38:16.267127 20404 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1211 18:38:16.267127 20404 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1211 18:38:16.267127 20404 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 18:38:16.267127 20404 net.cpp:122] Setting up group2_block0_conv1_scale
I1211 18:38:16.267127 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.267127 20404 net.cpp:137] Memory required for data: 585332400
I1211 18:38:16.267127 20404 layer_factory.cpp:58] Creating layer group2_block0_proj
I1211 18:38:16.267127 20404 net.cpp:84] Creating Layer group2_block0_proj
I1211 18:38:16.267127 20404 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1211 18:38:16.267127 20404 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1211 18:38:16.268116 20404 net.cpp:122] Setting up group2_block0_proj
I1211 18:38:16.268116 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.268116 20404 net.cpp:137] Memory required for data: 586970800
I1211 18:38:16.268116 20404 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1211 18:38:16.268116 20404 net.cpp:84] Creating Layer group2_block0_proj_bn
I1211 18:38:16.268116 20404 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1211 18:38:16.268116 20404 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1211 18:38:16.268116 20404 net.cpp:122] Setting up group2_block0_proj_bn
I1211 18:38:16.268116 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.268116 20404 net.cpp:137] Memory required for data: 588609200
I1211 18:38:16.268116 20404 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 18:38:16.268116 20404 net.cpp:84] Creating Layer group2_block0_proj_scale
I1211 18:38:16.268116 20404 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1211 18:38:16.268116 20404 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1211 18:38:16.268116 20404 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 18:38:16.268116 20404 net.cpp:122] Setting up group2_block0_proj_scale
I1211 18:38:16.268116 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.268116 20404 net.cpp:137] Memory required for data: 590247600
I1211 18:38:16.268116 20404 layer_factory.cpp:58] Creating layer group2_block0_sum
I1211 18:38:16.268116 20404 net.cpp:84] Creating Layer group2_block0_sum
I1211 18:38:16.268116 20404 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1211 18:38:16.268116 20404 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1211 18:38:16.268116 20404 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1211 18:38:16.269126 20404 net.cpp:122] Setting up group2_block0_sum
I1211 18:38:16.269126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.269126 20404 net.cpp:137] Memory required for data: 591886000
I1211 18:38:16.269126 20404 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1211 18:38:16.269126 20404 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1211 18:38:16.269126 20404 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1211 18:38:16.269126 20404 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1211 18:38:16.269126 20404 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1211 18:38:16.269126 20404 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1211 18:38:16.269126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.269126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.269126 20404 net.cpp:137] Memory required for data: 595162800
I1211 18:38:16.269126 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1211 18:38:16.269126 20404 net.cpp:84] Creating Layer group2_block1_conv0
I1211 18:38:16.269126 20404 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1211 18:38:16.269126 20404 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1211 18:38:16.270117 20404 net.cpp:122] Setting up group2_block1_conv0
I1211 18:38:16.270117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.270117 20404 net.cpp:137] Memory required for data: 596801200
I1211 18:38:16.270117 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1211 18:38:16.270117 20404 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1211 18:38:16.270117 20404 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1211 18:38:16.270117 20404 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1211 18:38:16.270117 20404 net.cpp:122] Setting up group2_block1_conv0_bn
I1211 18:38:16.271127 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.271127 20404 net.cpp:137] Memory required for data: 598439600
I1211 18:38:16.271127 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 18:38:16.271127 20404 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1211 18:38:16.271127 20404 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1211 18:38:16.271127 20404 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1211 18:38:16.271127 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 18:38:16.271127 20404 net.cpp:122] Setting up group2_block1_conv0_scale
I1211 18:38:16.271127 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.271127 20404 net.cpp:137] Memory required for data: 600078000
I1211 18:38:16.271127 20404 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1211 18:38:16.271127 20404 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1211 18:38:16.271127 20404 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1211 18:38:16.271127 20404 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1211 18:38:16.271127 20404 net.cpp:122] Setting up group2_block1_conv0_relu
I1211 18:38:16.271127 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.271127 20404 net.cpp:137] Memory required for data: 601716400
I1211 18:38:16.271127 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1211 18:38:16.271127 20404 net.cpp:84] Creating Layer group2_block1_conv1
I1211 18:38:16.271127 20404 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1211 18:38:16.271127 20404 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1211 18:38:16.273126 20404 net.cpp:122] Setting up group2_block1_conv1
I1211 18:38:16.273126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.273126 20404 net.cpp:137] Memory required for data: 603354800
I1211 18:38:16.273126 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1211 18:38:16.273126 20404 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1211 18:38:16.273126 20404 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1211 18:38:16.273126 20404 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1211 18:38:16.273126 20404 net.cpp:122] Setting up group2_block1_conv1_bn
I1211 18:38:16.273126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.273126 20404 net.cpp:137] Memory required for data: 604993200
I1211 18:38:16.273126 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 18:38:16.273126 20404 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1211 18:38:16.273126 20404 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1211 18:38:16.273126 20404 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1211 18:38:16.273126 20404 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 18:38:16.273126 20404 net.cpp:122] Setting up group2_block1_conv1_scale
I1211 18:38:16.273126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.273126 20404 net.cpp:137] Memory required for data: 606631600
I1211 18:38:16.273126 20404 layer_factory.cpp:58] Creating layer group2_block1_sum
I1211 18:38:16.273126 20404 net.cpp:84] Creating Layer group2_block1_sum
I1211 18:38:16.273126 20404 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1211 18:38:16.273126 20404 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1211 18:38:16.273126 20404 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1211 18:38:16.273126 20404 net.cpp:122] Setting up group2_block1_sum
I1211 18:38:16.273126 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.273126 20404 net.cpp:137] Memory required for data: 608270000
I1211 18:38:16.273126 20404 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1211 18:38:16.273126 20404 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1211 18:38:16.273126 20404 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1211 18:38:16.273126 20404 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1211 18:38:16.273126 20404 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1211 18:38:16.274117 20404 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1211 18:38:16.274117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.274117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.274117 20404 net.cpp:137] Memory required for data: 611546800
I1211 18:38:16.274117 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1211 18:38:16.274117 20404 net.cpp:84] Creating Layer group2_block2_conv0
I1211 18:38:16.274117 20404 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1211 18:38:16.274117 20404 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1211 18:38:16.275115 20404 net.cpp:122] Setting up group2_block2_conv0
I1211 18:38:16.275115 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.275115 20404 net.cpp:137] Memory required for data: 613185200
I1211 18:38:16.275115 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1211 18:38:16.275115 20404 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1211 18:38:16.275115 20404 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1211 18:38:16.276131 20404 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1211 18:38:16.276131 20404 net.cpp:122] Setting up group2_block2_conv0_bn
I1211 18:38:16.276131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.276131 20404 net.cpp:137] Memory required for data: 614823600
I1211 18:38:16.276131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 18:38:16.276131 20404 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1211 18:38:16.276131 20404 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1211 18:38:16.276131 20404 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1211 18:38:16.276131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 18:38:16.276131 20404 net.cpp:122] Setting up group2_block2_conv0_scale
I1211 18:38:16.276131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.276131 20404 net.cpp:137] Memory required for data: 616462000
I1211 18:38:16.276131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1211 18:38:16.276131 20404 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1211 18:38:16.276131 20404 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1211 18:38:16.276131 20404 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1211 18:38:16.276131 20404 net.cpp:122] Setting up group2_block2_conv0_relu
I1211 18:38:16.276131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.276131 20404 net.cpp:137] Memory required for data: 618100400
I1211 18:38:16.276131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1211 18:38:16.276131 20404 net.cpp:84] Creating Layer group2_block2_conv1
I1211 18:38:16.276131 20404 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1211 18:38:16.276131 20404 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1211 18:38:16.279131 20404 net.cpp:122] Setting up group2_block2_conv1
I1211 18:38:16.279131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.279131 20404 net.cpp:137] Memory required for data: 619738800
I1211 18:38:16.279131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1211 18:38:16.279131 20404 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1211 18:38:16.279131 20404 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1211 18:38:16.279131 20404 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1211 18:38:16.279131 20404 net.cpp:122] Setting up group2_block2_conv1_bn
I1211 18:38:16.279131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.279131 20404 net.cpp:137] Memory required for data: 621377200
I1211 18:38:16.279131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 18:38:16.279131 20404 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1211 18:38:16.279131 20404 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1211 18:38:16.279131 20404 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1211 18:38:16.279131 20404 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 18:38:16.279131 20404 net.cpp:122] Setting up group2_block2_conv1_scale
I1211 18:38:16.279131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.279131 20404 net.cpp:137] Memory required for data: 623015600
I1211 18:38:16.279131 20404 layer_factory.cpp:58] Creating layer group2_block2_sum
I1211 18:38:16.279131 20404 net.cpp:84] Creating Layer group2_block2_sum
I1211 18:38:16.279131 20404 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1211 18:38:16.279131 20404 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1211 18:38:16.279131 20404 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1211 18:38:16.279131 20404 net.cpp:122] Setting up group2_block2_sum
I1211 18:38:16.280130 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.280130 20404 net.cpp:137] Memory required for data: 624654000
I1211 18:38:16.280130 20404 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1211 18:38:16.280130 20404 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1211 18:38:16.280130 20404 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1211 18:38:16.280130 20404 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1211 18:38:16.280130 20404 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1211 18:38:16.280130 20404 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1211 18:38:16.280130 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.280130 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.280130 20404 net.cpp:137] Memory required for data: 627930800
I1211 18:38:16.280130 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1211 18:38:16.280130 20404 net.cpp:84] Creating Layer group2_block3_conv0
I1211 18:38:16.280130 20404 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1211 18:38:16.280130 20404 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1211 18:38:16.282131 20404 net.cpp:122] Setting up group2_block3_conv0
I1211 18:38:16.282131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.282131 20404 net.cpp:137] Memory required for data: 629569200
I1211 18:38:16.282131 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1211 18:38:16.282131 20404 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1211 18:38:16.282131 20404 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1211 18:38:16.282131 20404 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1211 18:38:16.282131 20404 net.cpp:122] Setting up group2_block3_conv0_bn
I1211 18:38:16.282131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.282131 20404 net.cpp:137] Memory required for data: 631207600
I1211 18:38:16.282131 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 18:38:16.282131 20404 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1211 18:38:16.282131 20404 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1211 18:38:16.282131 20404 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1211 18:38:16.282131 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 18:38:16.282131 20404 net.cpp:122] Setting up group2_block3_conv0_scale
I1211 18:38:16.282131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.282131 20404 net.cpp:137] Memory required for data: 632846000
I1211 18:38:16.282131 20404 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1211 18:38:16.282131 20404 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1211 18:38:16.282131 20404 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1211 18:38:16.282131 20404 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1211 18:38:16.282131 20404 net.cpp:122] Setting up group2_block3_conv0_relu
I1211 18:38:16.282131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.282131 20404 net.cpp:137] Memory required for data: 634484400
I1211 18:38:16.282131 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1211 18:38:16.282131 20404 net.cpp:84] Creating Layer group2_block3_conv1
I1211 18:38:16.282131 20404 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1211 18:38:16.282131 20404 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1211 18:38:16.284117 20404 net.cpp:122] Setting up group2_block3_conv1
I1211 18:38:16.284117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.284117 20404 net.cpp:137] Memory required for data: 636122800
I1211 18:38:16.284117 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1211 18:38:16.284117 20404 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1211 18:38:16.284117 20404 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1211 18:38:16.284117 20404 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1211 18:38:16.284117 20404 net.cpp:122] Setting up group2_block3_conv1_bn
I1211 18:38:16.284117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.284117 20404 net.cpp:137] Memory required for data: 637761200
I1211 18:38:16.284117 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 18:38:16.284117 20404 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1211 18:38:16.284117 20404 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1211 18:38:16.284117 20404 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1211 18:38:16.284117 20404 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 18:38:16.285131 20404 net.cpp:122] Setting up group2_block3_conv1_scale
I1211 18:38:16.285131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.285131 20404 net.cpp:137] Memory required for data: 639399600
I1211 18:38:16.285131 20404 layer_factory.cpp:58] Creating layer group2_block3_sum
I1211 18:38:16.285131 20404 net.cpp:84] Creating Layer group2_block3_sum
I1211 18:38:16.285131 20404 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1211 18:38:16.285131 20404 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1211 18:38:16.285131 20404 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1211 18:38:16.285131 20404 net.cpp:122] Setting up group2_block3_sum
I1211 18:38:16.285131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.285131 20404 net.cpp:137] Memory required for data: 641038000
I1211 18:38:16.285131 20404 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1211 18:38:16.285131 20404 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1211 18:38:16.285131 20404 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1211 18:38:16.285131 20404 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1211 18:38:16.285131 20404 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1211 18:38:16.285131 20404 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1211 18:38:16.285131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.285131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.285131 20404 net.cpp:137] Memory required for data: 644314800
I1211 18:38:16.285131 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1211 18:38:16.285131 20404 net.cpp:84] Creating Layer group2_block4_conv0
I1211 18:38:16.285131 20404 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1211 18:38:16.285131 20404 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1211 18:38:16.287132 20404 net.cpp:122] Setting up group2_block4_conv0
I1211 18:38:16.287132 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.287132 20404 net.cpp:137] Memory required for data: 645953200
I1211 18:38:16.287132 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1211 18:38:16.287132 20404 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1211 18:38:16.287132 20404 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1211 18:38:16.287132 20404 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1211 18:38:16.287132 20404 net.cpp:122] Setting up group2_block4_conv0_bn
I1211 18:38:16.287132 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.287132 20404 net.cpp:137] Memory required for data: 647591600
I1211 18:38:16.287132 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 18:38:16.287132 20404 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1211 18:38:16.287132 20404 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1211 18:38:16.287132 20404 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1211 18:38:16.287132 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 18:38:16.287132 20404 net.cpp:122] Setting up group2_block4_conv0_scale
I1211 18:38:16.287132 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.287132 20404 net.cpp:137] Memory required for data: 649230000
I1211 18:38:16.287132 20404 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1211 18:38:16.287132 20404 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1211 18:38:16.287132 20404 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1211 18:38:16.287132 20404 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1211 18:38:16.287132 20404 net.cpp:122] Setting up group2_block4_conv0_relu
I1211 18:38:16.287132 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.287132 20404 net.cpp:137] Memory required for data: 650868400
I1211 18:38:16.287132 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1211 18:38:16.287132 20404 net.cpp:84] Creating Layer group2_block4_conv1
I1211 18:38:16.287132 20404 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1211 18:38:16.287132 20404 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1211 18:38:16.289131 20404 net.cpp:122] Setting up group2_block4_conv1
I1211 18:38:16.289131 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.289131 20404 net.cpp:137] Memory required for data: 652506800
I1211 18:38:16.289131 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1211 18:38:16.289131 20404 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1211 18:38:16.289131 20404 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1211 18:38:16.289131 20404 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1211 18:38:16.290117 20404 net.cpp:122] Setting up group2_block4_conv1_bn
I1211 18:38:16.290117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.290117 20404 net.cpp:137] Memory required for data: 654145200
I1211 18:38:16.290117 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 18:38:16.290117 20404 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1211 18:38:16.290117 20404 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1211 18:38:16.290117 20404 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1211 18:38:16.290117 20404 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 18:38:16.290117 20404 net.cpp:122] Setting up group2_block4_conv1_scale
I1211 18:38:16.290117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.290117 20404 net.cpp:137] Memory required for data: 655783600
I1211 18:38:16.290117 20404 layer_factory.cpp:58] Creating layer group2_block4_sum
I1211 18:38:16.290117 20404 net.cpp:84] Creating Layer group2_block4_sum
I1211 18:38:16.290117 20404 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1211 18:38:16.290117 20404 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1211 18:38:16.290117 20404 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1211 18:38:16.290117 20404 net.cpp:122] Setting up group2_block4_sum
I1211 18:38:16.290117 20404 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 18:38:16.290117 20404 net.cpp:137] Memory required for data: 657422000
I1211 18:38:16.290117 20404 layer_factory.cpp:58] Creating layer global_avg_pool
I1211 18:38:16.290117 20404 net.cpp:84] Creating Layer global_avg_pool
I1211 18:38:16.290117 20404 net.cpp:406] global_avg_pool <- group2_block4_sum
I1211 18:38:16.290117 20404 net.cpp:380] global_avg_pool -> global_avg_pool
I1211 18:38:16.291131 20404 net.cpp:122] Setting up global_avg_pool
I1211 18:38:16.291131 20404 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1211 18:38:16.291131 20404 net.cpp:137] Memory required for data: 657447600
I1211 18:38:16.291131 20404 layer_factory.cpp:58] Creating layer fc
I1211 18:38:16.291131 20404 net.cpp:84] Creating Layer fc
I1211 18:38:16.291131 20404 net.cpp:406] fc <- global_avg_pool
I1211 18:38:16.291131 20404 net.cpp:380] fc -> fc
I1211 18:38:16.291131 20404 net.cpp:122] Setting up fc
I1211 18:38:16.291131 20404 net.cpp:129] Top shape: 100 10 (1000)
I1211 18:38:16.291131 20404 net.cpp:137] Memory required for data: 657451600
I1211 18:38:16.291131 20404 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1211 18:38:16.291131 20404 net.cpp:84] Creating Layer fc_fc_0_split
I1211 18:38:16.291131 20404 net.cpp:406] fc_fc_0_split <- fc
I1211 18:38:16.291131 20404 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1211 18:38:16.291131 20404 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1211 18:38:16.291131 20404 net.cpp:122] Setting up fc_fc_0_split
I1211 18:38:16.291131 20404 net.cpp:129] Top shape: 100 10 (1000)
I1211 18:38:16.291131 20404 net.cpp:129] Top shape: 100 10 (1000)
I1211 18:38:16.291131 20404 net.cpp:137] Memory required for data: 657459600
I1211 18:38:16.291131 20404 layer_factory.cpp:58] Creating layer accuracy
I1211 18:38:16.291131 20404 net.cpp:84] Creating Layer accuracy
I1211 18:38:16.291131 20404 net.cpp:406] accuracy <- fc_fc_0_split_0
I1211 18:38:16.291131 20404 net.cpp:406] accuracy <- label_cifar_1_split_0
I1211 18:38:16.291131 20404 net.cpp:380] accuracy -> accuracy
I1211 18:38:16.291131 20404 net.cpp:122] Setting up accuracy
I1211 18:38:16.291131 20404 net.cpp:129] Top shape: (1)
I1211 18:38:16.291131 20404 net.cpp:137] Memory required for data: 657459604
I1211 18:38:16.291131 20404 layer_factory.cpp:58] Creating layer loss
I1211 18:38:16.291131 20404 net.cpp:84] Creating Layer loss
I1211 18:38:16.291131 20404 net.cpp:406] loss <- fc_fc_0_split_1
I1211 18:38:16.291131 20404 net.cpp:406] loss <- label_cifar_1_split_1
I1211 18:38:16.291131 20404 net.cpp:380] loss -> loss
I1211 18:38:16.291131 20404 layer_factory.cpp:58] Creating layer loss
I1211 18:38:16.291131 20404 net.cpp:122] Setting up loss
I1211 18:38:16.291131 20404 net.cpp:129] Top shape: (1)
I1211 18:38:16.291131 20404 net.cpp:132]     with loss weight 1
I1211 18:38:16.291131 20404 net.cpp:137] Memory required for data: 657459608
I1211 18:38:16.292131 20404 net.cpp:198] loss needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:200] accuracy does not need backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] fc_fc_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] fc needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] global_avg_pool needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block4_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block3_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block2_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block1_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_proj needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] pool3 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group2_block0_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block4_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block3_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block2_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block1_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] pool2 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_proj needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] pool1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group1_block0_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block4_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block3_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block2_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_sum needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv1 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block1_conv0 needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1211 18:38:16.292131 20404 net.cpp:198] group0_block0_sum needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv1 needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] group0_block0_conv0 needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] first_conv_relu needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] first_conv_scale needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] first_conv_bn needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:198] first_conv needs backward computation.
I1211 18:38:16.293134 20404 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 18:38:16.293134 20404 net.cpp:200] cifar does not need backward computation.
I1211 18:38:16.293134 20404 net.cpp:242] This network produces output accuracy
I1211 18:38:16.293134 20404 net.cpp:242] This network produces output loss
I1211 18:38:16.293134 20404 net.cpp:255] Network initialization done.
I1211 18:38:16.293134 20404 solver.cpp:56] Solver scaffolding done.
I1211 18:38:16.304131 20404 caffe.cpp:249] Starting Optimization
I1211 18:38:16.304131 20404 solver.cpp:272] Solving CIFAR10_resnet_32_with 3pooling
I1211 18:38:16.304131 20404 solver.cpp:273] Learning Rate Policy: multistep
I1211 18:38:16.308130 20404 solver.cpp:330] Iteration 0, Testing net (#0)
I1211 18:38:16.313135 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:38:16.859266 20404 blocking_queue.cpp:49] Waiting for data
I1211 18:38:20.598330  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:38:20.618335 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:38:20.618335 20404 solver.cpp:397]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I1211 18:38:20.867374 20404 solver.cpp:218] Iteration 0 (0 iter/s, 4.56139s/100 iters), loss = 2.43704
I1211 18:38:20.867374 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.13
I1211 18:38:20.867374 20404 solver.cpp:237]     Train net output #1: loss = 2.43704 (* 1 = 2.43704 loss)
I1211 18:38:20.867374 20404 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1211 18:38:45.412163 20404 solver.cpp:218] Iteration 100 (4.07425 iter/s, 24.5444s/100 iters), loss = 1.48872
I1211 18:38:45.412163 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.46
I1211 18:38:45.412163 20404 solver.cpp:237]     Train net output #1: loss = 1.48872 (* 1 = 1.48872 loss)
I1211 18:38:45.412163 20404 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1211 18:38:53.460492 20404 solver.cpp:218] Iteration 200 (12.4265 iter/s, 8.04729s/100 iters), loss = 1.44236
I1211 18:38:53.460492 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.49
I1211 18:38:53.460492 20404 solver.cpp:237]     Train net output #1: loss = 1.44236 (* 1 = 1.44236 loss)
I1211 18:38:53.460492 20404 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1211 18:39:01.706368 20404 solver.cpp:218] Iteration 300 (12.1285 iter/s, 8.24508s/100 iters), loss = 1.27777
I1211 18:39:01.706368 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.56
I1211 18:39:01.706368 20404 solver.cpp:237]     Train net output #1: loss = 1.27777 (* 1 = 1.27777 loss)
I1211 18:39:01.706368 20404 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1211 18:39:10.063827 20404 solver.cpp:218] Iteration 400 (11.9658 iter/s, 8.35713s/100 iters), loss = 1.09774
I1211 18:39:10.063827 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.59
I1211 18:39:10.063827 20404 solver.cpp:237]     Train net output #1: loss = 1.09774 (* 1 = 1.09774 loss)
I1211 18:39:10.063827 20404 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1211 18:39:18.000291  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:39:18.322893 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_500.caffemodel
I1211 18:39:18.372896 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_500.solverstate
I1211 18:39:18.380894 20404 solver.cpp:330] Iteration 500, Testing net (#0)
I1211 18:39:18.380894 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:39:20.097584  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:39:20.165772 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:39:20.165772 20404 solver.cpp:397]     Test net output #1: loss = 3.6444 (* 1 = 3.6444 loss)
I1211 18:39:20.243150 20404 solver.cpp:218] Iteration 500 (9.82458 iter/s, 10.1786s/100 iters), loss = 1.01629
I1211 18:39:20.243150 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 18:39:20.243150 20404 solver.cpp:237]     Train net output #1: loss = 1.01629 (* 1 = 1.01629 loss)
I1211 18:39:20.243150 20404 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1211 18:39:28.437830 20404 solver.cpp:218] Iteration 600 (12.2039 iter/s, 8.19413s/100 iters), loss = 1.02247
I1211 18:39:28.437830 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.62
I1211 18:39:28.437830 20404 solver.cpp:237]     Train net output #1: loss = 1.02247 (* 1 = 1.02247 loss)
I1211 18:39:28.437830 20404 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1211 18:39:36.628047 20404 solver.cpp:218] Iteration 700 (12.2101 iter/s, 8.18996s/100 iters), loss = 0.95133
I1211 18:39:36.628047 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.65
I1211 18:39:36.628047 20404 solver.cpp:237]     Train net output #1: loss = 0.95133 (* 1 = 0.95133 loss)
I1211 18:39:36.628047 20404 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1211 18:39:44.724558 20404 solver.cpp:218] Iteration 800 (12.3519 iter/s, 8.09589s/100 iters), loss = 0.990567
I1211 18:39:44.724558 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.63
I1211 18:39:44.724558 20404 solver.cpp:237]     Train net output #1: loss = 0.990567 (* 1 = 0.990567 loss)
I1211 18:39:44.724558 20404 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1211 18:39:52.825896 20404 solver.cpp:218] Iteration 900 (12.3441 iter/s, 8.10106s/100 iters), loss = 0.886724
I1211 18:39:52.825896 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.64
I1211 18:39:52.825896 20404 solver.cpp:237]     Train net output #1: loss = 0.886724 (* 1 = 0.886724 loss)
I1211 18:39:52.825896 20404 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1211 18:40:00.523573  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:40:00.846607 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_1000.caffemodel
I1211 18:40:00.874625 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_1000.solverstate
I1211 18:40:00.881606 20404 solver.cpp:330] Iteration 1000, Testing net (#0)
I1211 18:40:00.881606 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:40:02.568933  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:40:02.635949 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:40:02.635949 20404 solver.cpp:397]     Test net output #1: loss = 4.16171 (* 1 = 4.16171 loss)
I1211 18:40:02.709950 20404 solver.cpp:218] Iteration 1000 (10.1188 iter/s, 9.88262s/100 iters), loss = 0.843377
I1211 18:40:02.709950 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 18:40:02.709950 20404 solver.cpp:237]     Train net output #1: loss = 0.843377 (* 1 = 0.843377 loss)
I1211 18:40:02.709950 20404 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1211 18:40:10.643088 20404 solver.cpp:218] Iteration 1100 (12.606 iter/s, 7.93276s/100 iters), loss = 0.872392
I1211 18:40:10.643088 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 18:40:10.643088 20404 solver.cpp:237]     Train net output #1: loss = 0.872392 (* 1 = 0.872392 loss)
I1211 18:40:10.643088 20404 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1211 18:40:18.581923 20404 solver.cpp:218] Iteration 1200 (12.5969 iter/s, 7.93844s/100 iters), loss = 0.851512
I1211 18:40:18.581923 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.69
I1211 18:40:18.581923 20404 solver.cpp:237]     Train net output #1: loss = 0.851512 (* 1 = 0.851512 loss)
I1211 18:40:18.581923 20404 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1211 18:40:26.546756 20404 solver.cpp:218] Iteration 1300 (12.5558 iter/s, 7.96446s/100 iters), loss = 0.919178
I1211 18:40:26.546756 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 18:40:26.546756 20404 solver.cpp:237]     Train net output #1: loss = 0.919178 (* 1 = 0.919178 loss)
I1211 18:40:26.546756 20404 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1211 18:40:34.695253 20404 solver.cpp:218] Iteration 1400 (12.2731 iter/s, 8.14791s/100 iters), loss = 0.799266
I1211 18:40:34.695253 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 18:40:34.695253 20404 solver.cpp:237]     Train net output #1: loss = 0.799266 (* 1 = 0.799266 loss)
I1211 18:40:34.695253 20404 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1211 18:40:42.491848  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:40:42.810614 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_1500.caffemodel
I1211 18:40:42.838799 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_1500.solverstate
I1211 18:40:42.844810 20404 solver.cpp:330] Iteration 1500, Testing net (#0)
I1211 18:40:42.844810 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:40:44.551998  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:40:44.619518 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:40:44.619518 20404 solver.cpp:397]     Test net output #1: loss = 3.67297 (* 1 = 3.67297 loss)
I1211 18:40:44.695984 20404 solver.cpp:218] Iteration 1500 (10.0003 iter/s, 9.99972s/100 iters), loss = 0.707492
I1211 18:40:44.695984 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 18:40:44.695984 20404 solver.cpp:237]     Train net output #1: loss = 0.707492 (* 1 = 0.707492 loss)
I1211 18:40:44.695984 20404 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1211 18:40:52.779342 20404 solver.cpp:218] Iteration 1600 (12.3717 iter/s, 8.08293s/100 iters), loss = 0.79793
I1211 18:40:52.779342 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I1211 18:40:52.779342 20404 solver.cpp:237]     Train net output #1: loss = 0.79793 (* 1 = 0.79793 loss)
I1211 18:40:52.779342 20404 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1211 18:41:00.916074 20404 solver.cpp:218] Iteration 1700 (12.2903 iter/s, 8.13651s/100 iters), loss = 0.723319
I1211 18:41:00.916074 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 18:41:00.916074 20404 solver.cpp:237]     Train net output #1: loss = 0.723319 (* 1 = 0.723319 loss)
I1211 18:41:00.916074 20404 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1211 18:41:09.138386 20404 solver.cpp:218] Iteration 1800 (12.1622 iter/s, 8.22223s/100 iters), loss = 0.807616
I1211 18:41:09.138386 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 18:41:09.138386 20404 solver.cpp:237]     Train net output #1: loss = 0.807616 (* 1 = 0.807616 loss)
I1211 18:41:09.138386 20404 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1211 18:41:17.324734 20404 solver.cpp:218] Iteration 1900 (12.2167 iter/s, 8.18549s/100 iters), loss = 0.670645
I1211 18:41:17.324734 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 18:41:17.324734 20404 solver.cpp:237]     Train net output #1: loss = 0.670645 (* 1 = 0.670645 loss)
I1211 18:41:17.324734 20404 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1211 18:41:25.113498  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:41:25.432191 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_2000.caffemodel
I1211 18:41:25.461199 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_2000.solverstate
I1211 18:41:25.467202 20404 solver.cpp:330] Iteration 2000, Testing net (#0)
I1211 18:41:25.467202 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:41:27.190538  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:41:27.259073 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:41:27.259073 20404 solver.cpp:397]     Test net output #1: loss = 3.3358 (* 1 = 3.3358 loss)
I1211 18:41:27.334589 20404 solver.cpp:218] Iteration 2000 (9.99048 iter/s, 10.0095s/100 iters), loss = 0.597807
I1211 18:41:27.334589 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:41:27.334589 20404 solver.cpp:237]     Train net output #1: loss = 0.597807 (* 1 = 0.597807 loss)
I1211 18:41:27.334589 20404 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1211 18:41:35.431176 20404 solver.cpp:218] Iteration 2100 (12.3516 iter/s, 8.09612s/100 iters), loss = 0.59238
I1211 18:41:35.431176 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 18:41:35.431176 20404 solver.cpp:237]     Train net output #1: loss = 0.59238 (* 1 = 0.59238 loss)
I1211 18:41:35.431176 20404 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1211 18:41:43.524338 20404 solver.cpp:218] Iteration 2200 (12.3571 iter/s, 8.09253s/100 iters), loss = 0.689371
I1211 18:41:43.524338 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 18:41:43.524338 20404 solver.cpp:237]     Train net output #1: loss = 0.689371 (* 1 = 0.689371 loss)
I1211 18:41:43.524338 20404 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1211 18:41:51.474757 20404 solver.cpp:218] Iteration 2300 (12.5797 iter/s, 7.9493s/100 iters), loss = 0.752081
I1211 18:41:51.474757 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 18:41:51.474757 20404 solver.cpp:237]     Train net output #1: loss = 0.752081 (* 1 = 0.752081 loss)
I1211 18:41:51.474757 20404 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1211 18:41:59.421641 20404 solver.cpp:218] Iteration 2400 (12.5841 iter/s, 7.94655s/100 iters), loss = 0.737595
I1211 18:41:59.421641 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I1211 18:41:59.421641 20404 solver.cpp:237]     Train net output #1: loss = 0.737595 (* 1 = 0.737595 loss)
I1211 18:41:59.421641 20404 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1211 18:42:06.989523  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:42:07.305558 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_2500.caffemodel
I1211 18:42:07.334559 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_2500.solverstate
I1211 18:42:07.341562 20404 solver.cpp:330] Iteration 2500, Testing net (#0)
I1211 18:42:07.341562 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:42:09.015719  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:42:09.081723 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:42:09.081723 20404 solver.cpp:397]     Test net output #1: loss = 3.06165 (* 1 = 3.06165 loss)
I1211 18:42:09.156726 20404 solver.cpp:218] Iteration 2500 (10.2727 iter/s, 9.73458s/100 iters), loss = 0.596702
I1211 18:42:09.156726 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:42:09.156726 20404 solver.cpp:237]     Train net output #1: loss = 0.596702 (* 1 = 0.596702 loss)
I1211 18:42:09.156726 20404 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1211 18:42:17.122534 20404 solver.cpp:218] Iteration 2600 (12.5546 iter/s, 7.96524s/100 iters), loss = 0.611529
I1211 18:42:17.122534 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:42:17.122534 20404 solver.cpp:237]     Train net output #1: loss = 0.611529 (* 1 = 0.611529 loss)
I1211 18:42:17.122534 20404 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1211 18:42:25.128540 20404 solver.cpp:218] Iteration 2700 (12.4902 iter/s, 8.00629s/100 iters), loss = 0.561066
I1211 18:42:25.128540 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:42:25.128540 20404 solver.cpp:237]     Train net output #1: loss = 0.561066 (* 1 = 0.561066 loss)
I1211 18:42:25.128540 20404 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1211 18:42:33.189924 20404 solver.cpp:218] Iteration 2800 (12.4073 iter/s, 8.0598s/100 iters), loss = 0.63429
I1211 18:42:33.189924 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:42:33.189924 20404 solver.cpp:237]     Train net output #1: loss = 0.63429 (* 1 = 0.63429 loss)
I1211 18:42:33.189924 20404 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1211 18:42:41.275498 20404 solver.cpp:218] Iteration 2900 (12.3686 iter/s, 8.085s/100 iters), loss = 0.697769
I1211 18:42:41.275498 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:42:41.275498 20404 solver.cpp:237]     Train net output #1: loss = 0.697769 (* 1 = 0.697769 loss)
I1211 18:42:41.275498 20404 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1211 18:42:49.052673  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:42:49.399672 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_3000.caffemodel
I1211 18:42:49.433182 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_3000.solverstate
I1211 18:42:49.440174 20404 solver.cpp:330] Iteration 3000, Testing net (#0)
I1211 18:42:49.440174 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:42:51.206673  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:42:51.277173 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:42:51.277173 20404 solver.cpp:397]     Test net output #1: loss = 2.86475 (* 1 = 2.86475 loss)
I1211 18:42:51.354172 20404 solver.cpp:218] Iteration 3000 (9.92228 iter/s, 10.0783s/100 iters), loss = 0.602659
I1211 18:42:51.354673 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:42:51.354673 20404 solver.cpp:237]     Train net output #1: loss = 0.602659 (* 1 = 0.602659 loss)
I1211 18:42:51.354673 20404 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1211 18:42:59.563807 20404 solver.cpp:218] Iteration 3100 (12.182 iter/s, 8.20883s/100 iters), loss = 0.605206
I1211 18:42:59.563807 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:42:59.563807 20404 solver.cpp:237]     Train net output #1: loss = 0.605206 (* 1 = 0.605206 loss)
I1211 18:42:59.563807 20404 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1211 18:43:07.682366 20404 solver.cpp:218] Iteration 3200 (12.3188 iter/s, 8.1177s/100 iters), loss = 0.730797
I1211 18:43:07.682366 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I1211 18:43:07.682366 20404 solver.cpp:237]     Train net output #1: loss = 0.730797 (* 1 = 0.730797 loss)
I1211 18:43:07.682366 20404 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1211 18:43:15.793642 20404 solver.cpp:218] Iteration 3300 (12.3291 iter/s, 8.1109s/100 iters), loss = 0.70164
I1211 18:43:15.793642 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:43:15.793642 20404 solver.cpp:237]     Train net output #1: loss = 0.70164 (* 1 = 0.70164 loss)
I1211 18:43:15.793642 20404 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1211 18:43:23.913354 20404 solver.cpp:218] Iteration 3400 (12.3165 iter/s, 8.11917s/100 iters), loss = 0.773465
I1211 18:43:23.913354 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I1211 18:43:23.913354 20404 solver.cpp:237]     Train net output #1: loss = 0.773465 (* 1 = 0.773465 loss)
I1211 18:43:23.913354 20404 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1211 18:43:31.628546  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:43:31.950047 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_3500.caffemodel
I1211 18:43:31.980047 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_3500.solverstate
I1211 18:43:31.986048 20404 solver.cpp:330] Iteration 3500, Testing net (#0)
I1211 18:43:31.986048 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:43:33.690546  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:43:33.759047 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:43:33.759047 20404 solver.cpp:397]     Test net output #1: loss = 2.72105 (* 1 = 2.72105 loss)
I1211 18:43:33.834545 20404 solver.cpp:218] Iteration 3500 (10.0802 iter/s, 9.92049s/100 iters), loss = 0.577363
I1211 18:43:33.834545 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:43:33.834545 20404 solver.cpp:237]     Train net output #1: loss = 0.577363 (* 1 = 0.577363 loss)
I1211 18:43:33.834545 20404 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1211 18:43:41.953384 20404 solver.cpp:218] Iteration 3600 (12.3176 iter/s, 8.11849s/100 iters), loss = 0.484421
I1211 18:43:41.953384 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:43:41.953384 20404 solver.cpp:237]     Train net output #1: loss = 0.484421 (* 1 = 0.484421 loss)
I1211 18:43:41.953384 20404 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1211 18:43:50.068198 20404 solver.cpp:218] Iteration 3700 (12.3243 iter/s, 8.11406s/100 iters), loss = 0.595243
I1211 18:43:50.068198 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:43:50.068198 20404 solver.cpp:237]     Train net output #1: loss = 0.595243 (* 1 = 0.595243 loss)
I1211 18:43:50.068198 20404 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1211 18:43:58.179761 20404 solver.cpp:218] Iteration 3800 (12.3286 iter/s, 8.11122s/100 iters), loss = 0.652739
I1211 18:43:58.179761 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:43:58.179761 20404 solver.cpp:237]     Train net output #1: loss = 0.652739 (* 1 = 0.652739 loss)
I1211 18:43:58.179761 20404 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1211 18:44:06.295495 20404 solver.cpp:218] Iteration 3900 (12.3223 iter/s, 8.11539s/100 iters), loss = 0.56323
I1211 18:44:06.295995 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:44:06.295995 20404 solver.cpp:237]     Train net output #1: loss = 0.56323 (* 1 = 0.56323 loss)
I1211 18:44:06.295995 20404 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1211 18:44:14.032634  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:44:14.376216 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_4000.caffemodel
I1211 18:44:14.407228 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_4000.solverstate
I1211 18:44:14.413228 20404 solver.cpp:330] Iteration 4000, Testing net (#0)
I1211 18:44:14.414229 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:44:16.157117  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:44:16.224617 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:44:16.224617 20404 solver.cpp:397]     Test net output #1: loss = 2.66147 (* 1 = 2.66147 loss)
I1211 18:44:16.299618 20404 solver.cpp:218] Iteration 4000 (9.99657 iter/s, 10.0034s/100 iters), loss = 0.554179
I1211 18:44:16.299618 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:44:16.299618 20404 solver.cpp:237]     Train net output #1: loss = 0.554179 (* 1 = 0.554179 loss)
I1211 18:44:16.299618 20404 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1211 18:44:24.486137 20404 solver.cpp:218] Iteration 4100 (12.2161 iter/s, 8.1859s/100 iters), loss = 0.504592
I1211 18:44:24.486137 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:44:24.486137 20404 solver.cpp:237]     Train net output #1: loss = 0.504592 (* 1 = 0.504592 loss)
I1211 18:44:24.486137 20404 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1211 18:44:32.467737 20404 solver.cpp:218] Iteration 4200 (12.5289 iter/s, 7.98153s/100 iters), loss = 0.52824
I1211 18:44:32.467737 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:44:32.467737 20404 solver.cpp:237]     Train net output #1: loss = 0.52824 (* 1 = 0.52824 loss)
I1211 18:44:32.467737 20404 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1211 18:44:40.458989 20404 solver.cpp:218] Iteration 4300 (12.5141 iter/s, 7.99102s/100 iters), loss = 0.593816
I1211 18:44:40.458989 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:44:40.458989 20404 solver.cpp:237]     Train net output #1: loss = 0.593816 (* 1 = 0.593816 loss)
I1211 18:44:40.458989 20404 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1211 18:44:48.502737 20404 solver.cpp:218] Iteration 4400 (12.4341 iter/s, 8.04238s/100 iters), loss = 0.61127
I1211 18:44:48.502737 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 18:44:48.502737 20404 solver.cpp:237]     Train net output #1: loss = 0.61127 (* 1 = 0.61127 loss)
I1211 18:44:48.502737 20404 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1211 18:44:56.188146  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:44:56.513756 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_4500.caffemodel
I1211 18:44:56.548261 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_4500.solverstate
I1211 18:44:56.554262 20404 solver.cpp:330] Iteration 4500, Testing net (#0)
I1211 18:44:56.555263 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:44:58.236421  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:44:58.303925 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:44:58.303925 20404 solver.cpp:397]     Test net output #1: loss = 2.68239 (* 1 = 2.68239 loss)
I1211 18:44:58.378428 20404 solver.cpp:218] Iteration 4500 (10.1263 iter/s, 9.87525s/100 iters), loss = 0.51021
I1211 18:44:58.378428 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:44:58.378428 20404 solver.cpp:237]     Train net output #1: loss = 0.51021 (* 1 = 0.51021 loss)
I1211 18:44:58.378428 20404 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1211 18:45:06.498517 20404 solver.cpp:218] Iteration 4600 (12.315 iter/s, 8.12021s/100 iters), loss = 0.500005
I1211 18:45:06.498517 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:45:06.498517 20404 solver.cpp:237]     Train net output #1: loss = 0.500005 (* 1 = 0.500005 loss)
I1211 18:45:06.498517 20404 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1211 18:45:14.562280 20404 solver.cpp:218] Iteration 4700 (12.4018 iter/s, 8.06336s/100 iters), loss = 0.501016
I1211 18:45:14.562280 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 18:45:14.562280 20404 solver.cpp:237]     Train net output #1: loss = 0.501016 (* 1 = 0.501016 loss)
I1211 18:45:14.563280 20404 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1211 18:45:22.735623 20404 solver.cpp:218] Iteration 4800 (12.2361 iter/s, 8.17254s/100 iters), loss = 0.515129
I1211 18:45:22.735623 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:45:22.735623 20404 solver.cpp:237]     Train net output #1: loss = 0.515129 (* 1 = 0.515129 loss)
I1211 18:45:22.735623 20404 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1211 18:45:30.866456 20404 solver.cpp:218] Iteration 4900 (12.3005 iter/s, 8.12972s/100 iters), loss = 0.597576
I1211 18:45:30.866456 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 18:45:30.866456 20404 solver.cpp:237]     Train net output #1: loss = 0.597576 (* 1 = 0.597576 loss)
I1211 18:45:30.866456 20404 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1211 18:45:38.497736  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:45:38.811769 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_5000.caffemodel
I1211 18:45:38.840782 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_5000.solverstate
I1211 18:45:38.845783 20404 solver.cpp:330] Iteration 5000, Testing net (#0)
I1211 18:45:38.846792 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:45:40.520462  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:45:40.586966 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:45:40.586966 20404 solver.cpp:397]     Test net output #1: loss = 2.65533 (* 1 = 2.65533 loss)
I1211 18:45:40.661978 20404 solver.cpp:218] Iteration 5000 (10.2093 iter/s, 9.79502s/100 iters), loss = 0.585393
I1211 18:45:40.661978 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:45:40.661978 20404 solver.cpp:237]     Train net output #1: loss = 0.585393 (* 1 = 0.585393 loss)
I1211 18:45:40.661978 20404 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1211 18:45:48.766140 20404 solver.cpp:218] Iteration 5100 (12.3397 iter/s, 8.10389s/100 iters), loss = 0.49234
I1211 18:45:48.766140 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:45:48.766140 20404 solver.cpp:237]     Train net output #1: loss = 0.49234 (* 1 = 0.49234 loss)
I1211 18:45:48.766140 20404 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1211 18:45:56.772109 20404 solver.cpp:218] Iteration 5200 (12.492 iter/s, 8.00512s/100 iters), loss = 0.642319
I1211 18:45:56.772109 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 18:45:56.772109 20404 solver.cpp:237]     Train net output #1: loss = 0.642319 (* 1 = 0.642319 loss)
I1211 18:45:56.772109 20404 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1211 18:46:04.726342 20404 solver.cpp:218] Iteration 5300 (12.5725 iter/s, 7.95385s/100 iters), loss = 0.570589
I1211 18:46:04.726342 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:46:04.726342 20404 solver.cpp:237]     Train net output #1: loss = 0.570589 (* 1 = 0.570589 loss)
I1211 18:46:04.726342 20404 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1211 18:46:12.686969 20404 solver.cpp:218] Iteration 5400 (12.5618 iter/s, 7.96066s/100 iters), loss = 0.635948
I1211 18:46:12.686969 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:46:12.686969 20404 solver.cpp:237]     Train net output #1: loss = 0.635948 (* 1 = 0.635948 loss)
I1211 18:46:12.686969 20404 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1211 18:46:20.253579  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:46:20.567620 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_5500.caffemodel
I1211 18:46:20.594617 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_5500.solverstate
I1211 18:46:20.600618 20404 solver.cpp:330] Iteration 5500, Testing net (#0)
I1211 18:46:20.600618 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:46:22.273764  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:46:22.340766 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1095
I1211 18:46:22.340766 20404 solver.cpp:397]     Test net output #1: loss = 2.6445 (* 1 = 2.6445 loss)
I1211 18:46:22.414767 20404 solver.cpp:218] Iteration 5500 (10.2805 iter/s, 9.72718s/100 iters), loss = 0.438006
I1211 18:46:22.414767 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 18:46:22.414767 20404 solver.cpp:237]     Train net output #1: loss = 0.438006 (* 1 = 0.438006 loss)
I1211 18:46:22.414767 20404 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1211 18:46:30.365862 20404 solver.cpp:218] Iteration 5600 (12.5778 iter/s, 7.95049s/100 iters), loss = 0.429186
I1211 18:46:30.365862 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:46:30.365862 20404 solver.cpp:237]     Train net output #1: loss = 0.429186 (* 1 = 0.429186 loss)
I1211 18:46:30.365862 20404 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1211 18:46:38.367192 20404 solver.cpp:218] Iteration 5700 (12.4989 iter/s, 8.0007s/100 iters), loss = 0.621794
I1211 18:46:38.367192 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I1211 18:46:38.367192 20404 solver.cpp:237]     Train net output #1: loss = 0.621794 (* 1 = 0.621794 loss)
I1211 18:46:38.367192 20404 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1211 18:46:46.368772 20404 solver.cpp:218] Iteration 5800 (12.4985 iter/s, 8.00099s/100 iters), loss = 0.593097
I1211 18:46:46.368772 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 18:46:46.368772 20404 solver.cpp:237]     Train net output #1: loss = 0.593097 (* 1 = 0.593097 loss)
I1211 18:46:46.368772 20404 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1211 18:46:54.371273 20404 solver.cpp:218] Iteration 5900 (12.4962 iter/s, 8.00241s/100 iters), loss = 0.489053
I1211 18:46:54.371273 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:46:54.371273 20404 solver.cpp:237]     Train net output #1: loss = 0.489053 (* 1 = 0.489053 loss)
I1211 18:46:54.371273 20404 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1211 18:47:01.960170  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:47:02.275213 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_6000.caffemodel
I1211 18:47:02.307215 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_6000.solverstate
I1211 18:47:02.313215 20404 solver.cpp:330] Iteration 6000, Testing net (#0)
I1211 18:47:02.314225 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:47:03.985652  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:47:04.052155 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1
I1211 18:47:04.052155 20404 solver.cpp:397]     Test net output #1: loss = 2.66788 (* 1 = 2.66788 loss)
I1211 18:47:04.126658 20404 solver.cpp:218] Iteration 6000 (10.2515 iter/s, 9.75464s/100 iters), loss = 0.547485
I1211 18:47:04.126658 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:47:04.126658 20404 solver.cpp:237]     Train net output #1: loss = 0.547485 (* 1 = 0.547485 loss)
I1211 18:47:04.126658 20404 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1211 18:47:12.163612 20404 solver.cpp:218] Iteration 6100 (12.4438 iter/s, 8.03615s/100 iters), loss = 0.505939
I1211 18:47:12.163612 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:47:12.163612 20404 solver.cpp:237]     Train net output #1: loss = 0.505939 (* 1 = 0.505939 loss)
I1211 18:47:12.163612 20404 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1211 18:47:20.141537 20404 solver.cpp:218] Iteration 6200 (12.5353 iter/s, 7.97748s/100 iters), loss = 0.646172
I1211 18:47:20.141537 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 18:47:20.141537 20404 solver.cpp:237]     Train net output #1: loss = 0.646172 (* 1 = 0.646172 loss)
I1211 18:47:20.141537 20404 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1211 18:47:28.198964 20404 solver.cpp:218] Iteration 6300 (12.4116 iter/s, 8.05697s/100 iters), loss = 0.521746
I1211 18:47:28.198964 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:47:28.198964 20404 solver.cpp:237]     Train net output #1: loss = 0.521746 (* 1 = 0.521746 loss)
I1211 18:47:28.198964 20404 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1211 18:47:36.373072 20404 solver.cpp:218] Iteration 6400 (12.2349 iter/s, 8.17337s/100 iters), loss = 0.498738
I1211 18:47:36.373072 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:47:36.373072 20404 solver.cpp:237]     Train net output #1: loss = 0.498738 (* 1 = 0.498738 loss)
I1211 18:47:36.373072 20404 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1211 18:47:43.967911  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:47:44.280946 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_6500.caffemodel
I1211 18:47:44.307968 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_6500.solverstate
I1211 18:47:44.313977 20404 solver.cpp:330] Iteration 6500, Testing net (#0)
I1211 18:47:44.313977 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:47:45.991112  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:47:46.058109 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1048
I1211 18:47:46.058109 20404 solver.cpp:397]     Test net output #1: loss = 2.63386 (* 1 = 2.63386 loss)
I1211 18:47:46.132117 20404 solver.cpp:218] Iteration 6500 (10.2472 iter/s, 9.75876s/100 iters), loss = 0.458268
I1211 18:47:46.132117 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:47:46.132117 20404 solver.cpp:237]     Train net output #1: loss = 0.458268 (* 1 = 0.458268 loss)
I1211 18:47:46.132117 20404 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1211 18:47:54.093109 20404 solver.cpp:218] Iteration 6600 (12.5614 iter/s, 7.96092s/100 iters), loss = 0.50117
I1211 18:47:54.093109 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:47:54.093109 20404 solver.cpp:237]     Train net output #1: loss = 0.50117 (* 1 = 0.50117 loss)
I1211 18:47:54.093109 20404 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1211 18:48:02.066004 20404 solver.cpp:218] Iteration 6700 (12.5434 iter/s, 7.97235s/100 iters), loss = 0.528806
I1211 18:48:02.066004 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:48:02.066004 20404 solver.cpp:237]     Train net output #1: loss = 0.528806 (* 1 = 0.528806 loss)
I1211 18:48:02.066004 20404 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1211 18:48:10.056515 20404 solver.cpp:218] Iteration 6800 (12.5157 iter/s, 7.98997s/100 iters), loss = 0.53222
I1211 18:48:10.056515 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:48:10.056515 20404 solver.cpp:237]     Train net output #1: loss = 0.53222 (* 1 = 0.53222 loss)
I1211 18:48:10.056515 20404 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1211 18:48:18.063143 20404 solver.cpp:218] Iteration 6900 (12.4899 iter/s, 8.00644s/100 iters), loss = 0.476409
I1211 18:48:18.064144 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:48:18.064144 20404 solver.cpp:237]     Train net output #1: loss = 0.476409 (* 1 = 0.476409 loss)
I1211 18:48:18.064144 20404 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1211 18:48:25.704866  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:48:26.028084 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_7000.caffemodel
I1211 18:48:26.058105 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_7000.solverstate
I1211 18:48:26.064098 20404 solver.cpp:330] Iteration 7000, Testing net (#0)
I1211 18:48:26.064098 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:48:27.780167  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:48:27.847965 20404 solver.cpp:397]     Test net output #0: accuracy = 0.1378
I1211 18:48:27.847965 20404 solver.cpp:397]     Test net output #1: loss = 2.49499 (* 1 = 2.49499 loss)
I1211 18:48:27.924475 20404 solver.cpp:218] Iteration 7000 (10.1413 iter/s, 9.86063s/100 iters), loss = 0.462304
I1211 18:48:27.924475 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:48:27.924475 20404 solver.cpp:237]     Train net output #1: loss = 0.462304 (* 1 = 0.462304 loss)
I1211 18:48:27.924475 20404 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1211 18:48:35.995731 20404 solver.cpp:218] Iteration 7100 (12.3914 iter/s, 8.07011s/100 iters), loss = 0.3955
I1211 18:48:35.995731 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:48:35.995731 20404 solver.cpp:237]     Train net output #1: loss = 0.3955 (* 1 = 0.3955 loss)
I1211 18:48:35.995731 20404 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1211 18:48:43.956794 20404 solver.cpp:218] Iteration 7200 (12.562 iter/s, 7.96054s/100 iters), loss = 0.466232
I1211 18:48:43.956794 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:48:43.956794 20404 solver.cpp:237]     Train net output #1: loss = 0.466232 (* 1 = 0.466232 loss)
I1211 18:48:43.956794 20404 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1211 18:48:51.994958 20404 solver.cpp:218] Iteration 7300 (12.4408 iter/s, 8.03804s/100 iters), loss = 0.408489
I1211 18:48:51.994958 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 18:48:51.994958 20404 solver.cpp:237]     Train net output #1: loss = 0.408489 (* 1 = 0.408489 loss)
I1211 18:48:51.994958 20404 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1211 18:49:00.066131 20404 solver.cpp:218] Iteration 7400 (12.3902 iter/s, 8.07089s/100 iters), loss = 0.48979
I1211 18:49:00.066131 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:49:00.066131 20404 solver.cpp:237]     Train net output #1: loss = 0.48979 (* 1 = 0.48979 loss)
I1211 18:49:00.066131 20404 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1211 18:49:07.733505  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:49:08.062543 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_7500.caffemodel
I1211 18:49:08.096544 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_7500.solverstate
I1211 18:49:08.102543 20404 solver.cpp:330] Iteration 7500, Testing net (#0)
I1211 18:49:08.102543 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:49:09.817236  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:49:09.885741 20404 solver.cpp:397]     Test net output #0: accuracy = 0.2964
I1211 18:49:09.885741 20404 solver.cpp:397]     Test net output #1: loss = 1.98479 (* 1 = 1.98479 loss)
I1211 18:49:09.962761 20404 solver.cpp:218] Iteration 7500 (10.1058 iter/s, 9.89534s/100 iters), loss = 0.526507
I1211 18:49:09.962761 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:49:09.962761 20404 solver.cpp:237]     Train net output #1: loss = 0.526507 (* 1 = 0.526507 loss)
I1211 18:49:09.962761 20404 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1211 18:49:18.280051 20404 solver.cpp:218] Iteration 7600 (12.0228 iter/s, 8.31753s/100 iters), loss = 0.472893
I1211 18:49:18.280051 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 18:49:18.281051 20404 solver.cpp:237]     Train net output #1: loss = 0.472893 (* 1 = 0.472893 loss)
I1211 18:49:18.281051 20404 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1211 18:49:26.618872 20404 solver.cpp:218] Iteration 7700 (11.9934 iter/s, 8.33789s/100 iters), loss = 0.469647
I1211 18:49:26.619372 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:49:26.619372 20404 solver.cpp:237]     Train net output #1: loss = 0.469647 (* 1 = 0.469647 loss)
I1211 18:49:26.619372 20404 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1211 18:49:34.913553 20404 solver.cpp:218] Iteration 7800 (12.0563 iter/s, 8.29439s/100 iters), loss = 0.5367
I1211 18:49:34.913553 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:49:34.913553 20404 solver.cpp:237]     Train net output #1: loss = 0.5367 (* 1 = 0.5367 loss)
I1211 18:49:34.913553 20404 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1211 18:49:43.205170 20404 solver.cpp:218] Iteration 7900 (12.0611 iter/s, 8.29113s/100 iters), loss = 0.451047
I1211 18:49:43.205170 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:49:43.205170 20404 solver.cpp:237]     Train net output #1: loss = 0.451047 (* 1 = 0.451047 loss)
I1211 18:49:43.206171 20404 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1211 18:49:51.082610  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:49:51.408216 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_8000.caffemodel
I1211 18:49:51.439220 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_8000.solverstate
I1211 18:49:51.445225 20404 solver.cpp:330] Iteration 8000, Testing net (#0)
I1211 18:49:51.445225 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:49:53.163462  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:49:53.231464 20404 solver.cpp:397]     Test net output #0: accuracy = 0.437
I1211 18:49:53.231464 20404 solver.cpp:397]     Test net output #1: loss = 1.5103 (* 1 = 1.5103 loss)
I1211 18:49:53.307467 20404 solver.cpp:218] Iteration 8000 (9.89939 iter/s, 10.1016s/100 iters), loss = 0.534041
I1211 18:49:53.307467 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:49:53.307467 20404 solver.cpp:237]     Train net output #1: loss = 0.534041 (* 1 = 0.534041 loss)
I1211 18:49:53.307467 20404 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1211 18:50:01.602017 20404 solver.cpp:218] Iteration 8100 (12.0579 iter/s, 8.29332s/100 iters), loss = 0.385256
I1211 18:50:01.602017 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:50:01.602017 20404 solver.cpp:237]     Train net output #1: loss = 0.385256 (* 1 = 0.385256 loss)
I1211 18:50:01.602017 20404 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1211 18:50:09.858400 20404 solver.cpp:218] Iteration 8200 (12.1117 iter/s, 8.2565s/100 iters), loss = 0.540733
I1211 18:50:09.859405 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:50:09.859405 20404 solver.cpp:237]     Train net output #1: loss = 0.540733 (* 1 = 0.540733 loss)
I1211 18:50:09.859405 20404 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1211 18:50:18.133913 20404 solver.cpp:218] Iteration 8300 (12.0848 iter/s, 8.27484s/100 iters), loss = 0.48736
I1211 18:50:18.134901 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:50:18.134901 20404 solver.cpp:237]     Train net output #1: loss = 0.48736 (* 1 = 0.48736 loss)
I1211 18:50:18.134901 20404 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1211 18:50:26.413146 20404 solver.cpp:218] Iteration 8400 (12.0806 iter/s, 8.27776s/100 iters), loss = 0.498598
I1211 18:50:26.413146 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:50:26.413146 20404 solver.cpp:237]     Train net output #1: loss = 0.498598 (* 1 = 0.498598 loss)
I1211 18:50:26.413146 20404 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1211 18:50:34.250113  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:50:34.564034 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_8500.caffemodel
I1211 18:50:34.592034 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_8500.solverstate
I1211 18:50:34.598034 20404 solver.cpp:330] Iteration 8500, Testing net (#0)
I1211 18:50:34.598034 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:50:36.276731  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:50:36.345718 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6609
I1211 18:50:36.345718 20404 solver.cpp:397]     Test net output #1: loss = 0.954514 (* 1 = 0.954514 loss)
I1211 18:50:36.422735 20404 solver.cpp:218] Iteration 8500 (9.99043 iter/s, 10.0096s/100 iters), loss = 0.472839
I1211 18:50:36.422735 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:50:36.422735 20404 solver.cpp:237]     Train net output #1: loss = 0.472839 (* 1 = 0.472839 loss)
I1211 18:50:36.422735 20404 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1211 18:50:44.419584 20404 solver.cpp:218] Iteration 8600 (12.5059 iter/s, 7.9962s/100 iters), loss = 0.500289
I1211 18:50:44.419584 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:50:44.419584 20404 solver.cpp:237]     Train net output #1: loss = 0.500289 (* 1 = 0.500289 loss)
I1211 18:50:44.419584 20404 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1211 18:50:52.433940 20404 solver.cpp:218] Iteration 8700 (12.479 iter/s, 8.01348s/100 iters), loss = 0.549947
I1211 18:50:52.433940 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:50:52.433940 20404 solver.cpp:237]     Train net output #1: loss = 0.549947 (* 1 = 0.549947 loss)
I1211 18:50:52.433940 20404 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1211 18:51:00.598594 20404 solver.cpp:218] Iteration 8800 (12.2481 iter/s, 8.16455s/100 iters), loss = 0.481384
I1211 18:51:00.598594 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:51:00.598594 20404 solver.cpp:237]     Train net output #1: loss = 0.481384 (* 1 = 0.481384 loss)
I1211 18:51:00.598594 20404 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1211 18:51:08.684375 20404 solver.cpp:218] Iteration 8900 (12.3683 iter/s, 8.08517s/100 iters), loss = 0.417832
I1211 18:51:08.684375 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:51:08.684375 20404 solver.cpp:237]     Train net output #1: loss = 0.417832 (* 1 = 0.417832 loss)
I1211 18:51:08.684375 20404 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1211 18:51:16.552042  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:51:16.883025 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_9000.caffemodel
I1211 18:51:16.923010 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_9000.solverstate
I1211 18:51:16.930011 20404 solver.cpp:330] Iteration 9000, Testing net (#0)
I1211 18:51:16.930011 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:51:18.663863  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:51:18.733366 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7152
I1211 18:51:18.733366 20404 solver.cpp:397]     Test net output #1: loss = 0.838732 (* 1 = 0.838732 loss)
I1211 18:51:18.811381 20404 solver.cpp:218] Iteration 9000 (9.87548 iter/s, 10.1261s/100 iters), loss = 0.481027
I1211 18:51:18.811381 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:51:18.811381 20404 solver.cpp:237]     Train net output #1: loss = 0.481027 (* 1 = 0.481027 loss)
I1211 18:51:18.811381 20404 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1211 18:51:26.944469 20404 solver.cpp:218] Iteration 9100 (12.2955 iter/s, 8.13303s/100 iters), loss = 0.491398
I1211 18:51:26.945471 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:51:26.945471 20404 solver.cpp:237]     Train net output #1: loss = 0.491398 (* 1 = 0.491398 loss)
I1211 18:51:26.945471 20404 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1211 18:51:35.002431 20404 solver.cpp:218] Iteration 9200 (12.4112 iter/s, 8.05721s/100 iters), loss = 0.55732
I1211 18:51:35.002431 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:51:35.002431 20404 solver.cpp:237]     Train net output #1: loss = 0.55732 (* 1 = 0.55732 loss)
I1211 18:51:35.002431 20404 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1211 18:51:43.063388 20404 solver.cpp:218] Iteration 9300 (12.4071 iter/s, 8.05988s/100 iters), loss = 0.437026
I1211 18:51:43.063388 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:51:43.063388 20404 solver.cpp:237]     Train net output #1: loss = 0.437026 (* 1 = 0.437026 loss)
I1211 18:51:43.063388 20404 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1211 18:51:51.132716 20404 solver.cpp:218] Iteration 9400 (12.3924 iter/s, 8.06948s/100 iters), loss = 0.519915
I1211 18:51:51.132716 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:51:51.132716 20404 solver.cpp:237]     Train net output #1: loss = 0.519915 (* 1 = 0.519915 loss)
I1211 18:51:51.133716 20404 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1211 18:51:58.799772  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:51:59.118844 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_9500.caffemodel
I1211 18:51:59.151849 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_9500.solverstate
I1211 18:51:59.157853 20404 solver.cpp:330] Iteration 9500, Testing net (#0)
I1211 18:51:59.157853 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:52:00.843464  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:52:00.910966 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7187
I1211 18:52:00.910966 20404 solver.cpp:397]     Test net output #1: loss = 0.784615 (* 1 = 0.784615 loss)
I1211 18:52:00.985982 20404 solver.cpp:218] Iteration 9500 (10.1501 iter/s, 9.85215s/100 iters), loss = 0.438076
I1211 18:52:00.985982 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:52:00.985982 20404 solver.cpp:237]     Train net output #1: loss = 0.438076 (* 1 = 0.438076 loss)
I1211 18:52:00.985982 20404 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1211 18:52:09.055609 20404 solver.cpp:218] Iteration 9600 (12.3931 iter/s, 8.06901s/100 iters), loss = 0.385073
I1211 18:52:09.055609 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 18:52:09.055609 20404 solver.cpp:237]     Train net output #1: loss = 0.385073 (* 1 = 0.385073 loss)
I1211 18:52:09.055609 20404 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1211 18:52:17.108500 20404 solver.cpp:218] Iteration 9700 (12.4189 iter/s, 8.05225s/100 iters), loss = 0.499537
I1211 18:52:17.108500 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:52:17.108500 20404 solver.cpp:237]     Train net output #1: loss = 0.499537 (* 1 = 0.499537 loss)
I1211 18:52:17.108500 20404 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1211 18:52:25.159204 20404 solver.cpp:218] Iteration 9800 (12.4223 iter/s, 8.05006s/100 iters), loss = 0.496765
I1211 18:52:25.159204 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:52:25.159204 20404 solver.cpp:237]     Train net output #1: loss = 0.496765 (* 1 = 0.496765 loss)
I1211 18:52:25.159204 20404 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1211 18:52:33.236135 20404 solver.cpp:218] Iteration 9900 (12.3808 iter/s, 8.07702s/100 iters), loss = 0.470537
I1211 18:52:33.236135 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:52:33.236135 20404 solver.cpp:237]     Train net output #1: loss = 0.470537 (* 1 = 0.470537 loss)
I1211 18:52:33.236135 20404 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1211 18:52:40.985852  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:52:41.301869 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_10000.caffemodel
I1211 18:52:41.332868 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_10000.solverstate
I1211 18:52:41.339872 20404 solver.cpp:330] Iteration 10000, Testing net (#0)
I1211 18:52:41.339872 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:52:43.053021  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:52:43.121028 20404 solver.cpp:397]     Test net output #0: accuracy = 0.5924
I1211 18:52:43.121028 20404 solver.cpp:397]     Test net output #1: loss = 1.1591 (* 1 = 1.1591 loss)
I1211 18:52:43.197054 20404 solver.cpp:218] Iteration 10000 (10.0404 iter/s, 9.95981s/100 iters), loss = 0.467379
I1211 18:52:43.197054 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:52:43.197054 20404 solver.cpp:237]     Train net output #1: loss = 0.467379 (* 1 = 0.467379 loss)
I1211 18:52:43.197054 20404 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1211 18:52:51.358170 20404 solver.cpp:218] Iteration 10100 (12.2546 iter/s, 8.16022s/100 iters), loss = 0.372755
I1211 18:52:51.358170 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:52:51.358170 20404 solver.cpp:237]     Train net output #1: loss = 0.372755 (* 1 = 0.372755 loss)
I1211 18:52:51.358170 20404 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1211 18:52:59.518416 20404 solver.cpp:218] Iteration 10200 (12.2541 iter/s, 8.16055s/100 iters), loss = 0.549388
I1211 18:52:59.519417 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:52:59.519417 20404 solver.cpp:237]     Train net output #1: loss = 0.549388 (* 1 = 0.549388 loss)
I1211 18:52:59.519417 20404 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1211 18:53:07.698469 20404 solver.cpp:218] Iteration 10300 (12.2257 iter/s, 8.17949s/100 iters), loss = 0.466344
I1211 18:53:07.699470 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:53:07.699470 20404 solver.cpp:237]     Train net output #1: loss = 0.466344 (* 1 = 0.466344 loss)
I1211 18:53:07.699470 20404 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1211 18:53:15.818919 20404 solver.cpp:218] Iteration 10400 (12.3168 iter/s, 8.119s/100 iters), loss = 0.400748
I1211 18:53:15.818919 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:53:15.818919 20404 solver.cpp:237]     Train net output #1: loss = 0.400748 (* 1 = 0.400748 loss)
I1211 18:53:15.818919 20404 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1211 18:53:23.609323  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:53:23.938361 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_10500.caffemodel
I1211 18:53:23.972367 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_10500.solverstate
I1211 18:53:23.977864 20404 solver.cpp:330] Iteration 10500, Testing net (#0)
I1211 18:53:23.978364 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:53:25.691527  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:53:25.758527 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6981
I1211 18:53:25.758527 20404 solver.cpp:397]     Test net output #1: loss = 0.852702 (* 1 = 0.852702 loss)
I1211 18:53:25.833534 20404 solver.cpp:218] Iteration 10500 (9.98581 iter/s, 10.0142s/100 iters), loss = 0.531574
I1211 18:53:25.833534 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:53:25.833534 20404 solver.cpp:237]     Train net output #1: loss = 0.531574 (* 1 = 0.531574 loss)
I1211 18:53:25.833534 20404 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1211 18:53:33.931118 20404 solver.cpp:218] Iteration 10600 (12.3497 iter/s, 8.09736s/100 iters), loss = 0.516869
I1211 18:53:33.931118 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:53:33.931118 20404 solver.cpp:237]     Train net output #1: loss = 0.516869 (* 1 = 0.516869 loss)
I1211 18:53:33.931118 20404 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1211 18:53:42.100782 20404 solver.cpp:218] Iteration 10700 (12.2407 iter/s, 8.16946s/100 iters), loss = 0.519189
I1211 18:53:42.100782 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:53:42.100782 20404 solver.cpp:237]     Train net output #1: loss = 0.519189 (* 1 = 0.519189 loss)
I1211 18:53:42.100782 20404 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1211 18:53:50.198649 20404 solver.cpp:218] Iteration 10800 (12.3507 iter/s, 8.09673s/100 iters), loss = 0.509303
I1211 18:53:50.198649 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:53:50.198649 20404 solver.cpp:237]     Train net output #1: loss = 0.509303 (* 1 = 0.509303 loss)
I1211 18:53:50.198649 20404 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1211 18:53:58.357587 20404 solver.cpp:218] Iteration 10900 (12.2575 iter/s, 8.15828s/100 iters), loss = 0.43881
I1211 18:53:58.357587 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:53:58.357587 20404 solver.cpp:237]     Train net output #1: loss = 0.43881 (* 1 = 0.43881 loss)
I1211 18:53:58.357587 20404 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1211 18:54:06.139704  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:54:06.471743 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_11000.caffemodel
I1211 18:54:06.507755 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_11000.solverstate
I1211 18:54:06.514771 20404 solver.cpp:330] Iteration 11000, Testing net (#0)
I1211 18:54:06.515758 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:54:08.240973  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:54:08.308985 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7029
I1211 18:54:08.308985 20404 solver.cpp:397]     Test net output #1: loss = 0.852336 (* 1 = 0.852336 loss)
I1211 18:54:08.387990 20404 solver.cpp:218] Iteration 11000 (9.97021 iter/s, 10.0299s/100 iters), loss = 0.417226
I1211 18:54:08.387990 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:54:08.387990 20404 solver.cpp:237]     Train net output #1: loss = 0.417226 (* 1 = 0.417226 loss)
I1211 18:54:08.387990 20404 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1211 18:54:16.540707 20404 solver.cpp:218] Iteration 11100 (12.2665 iter/s, 8.15227s/100 iters), loss = 0.403164
I1211 18:54:16.540707 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 18:54:16.540707 20404 solver.cpp:237]     Train net output #1: loss = 0.403164 (* 1 = 0.403164 loss)
I1211 18:54:16.540707 20404 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1211 18:54:24.640409 20404 solver.cpp:218] Iteration 11200 (12.3471 iter/s, 8.0991s/100 iters), loss = 0.490833
I1211 18:54:24.640409 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:54:24.640409 20404 solver.cpp:237]     Train net output #1: loss = 0.490833 (* 1 = 0.490833 loss)
I1211 18:54:24.640409 20404 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1211 18:54:32.832816 20404 solver.cpp:218] Iteration 11300 (12.207 iter/s, 8.19205s/100 iters), loss = 0.498582
I1211 18:54:32.832816 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:54:32.832816 20404 solver.cpp:237]     Train net output #1: loss = 0.498582 (* 1 = 0.498582 loss)
I1211 18:54:32.832816 20404 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1211 18:54:40.967392 20404 solver.cpp:218] Iteration 11400 (12.2932 iter/s, 8.13456s/100 iters), loss = 0.396673
I1211 18:54:40.968392 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 18:54:40.968392 20404 solver.cpp:237]     Train net output #1: loss = 0.396673 (* 1 = 0.396673 loss)
I1211 18:54:40.968392 20404 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1211 18:54:48.663419  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:54:48.984254 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_11500.caffemodel
I1211 18:54:49.012256 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_11500.solverstate
I1211 18:54:49.019258 20404 solver.cpp:330] Iteration 11500, Testing net (#0)
I1211 18:54:49.019258 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:54:50.744433  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:54:50.812445 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6857
I1211 18:54:50.812445 20404 solver.cpp:397]     Test net output #1: loss = 0.880897 (* 1 = 0.880897 loss)
I1211 18:54:50.889438 20404 solver.cpp:218] Iteration 11500 (10.0794 iter/s, 9.92119s/100 iters), loss = 0.510577
I1211 18:54:50.889438 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:54:50.889438 20404 solver.cpp:237]     Train net output #1: loss = 0.510577 (* 1 = 0.510577 loss)
I1211 18:54:50.889438 20404 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1211 18:54:59.041780 20404 solver.cpp:218] Iteration 11600 (12.2671 iter/s, 8.15187s/100 iters), loss = 0.352317
I1211 18:54:59.041780 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 18:54:59.041780 20404 solver.cpp:237]     Train net output #1: loss = 0.352317 (* 1 = 0.352317 loss)
I1211 18:54:59.041780 20404 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1211 18:55:07.223592 20404 solver.cpp:218] Iteration 11700 (12.2228 iter/s, 8.1814s/100 iters), loss = 0.455877
I1211 18:55:07.223592 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:55:07.223592 20404 solver.cpp:237]     Train net output #1: loss = 0.455877 (* 1 = 0.455877 loss)
I1211 18:55:07.223592 20404 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1211 18:55:15.341138 20404 solver.cpp:218] Iteration 11800 (12.3198 iter/s, 8.117s/100 iters), loss = 0.507156
I1211 18:55:15.341138 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:55:15.341138 20404 solver.cpp:237]     Train net output #1: loss = 0.507156 (* 1 = 0.507156 loss)
I1211 18:55:15.341138 20404 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1211 18:55:23.518893 20404 solver.cpp:218] Iteration 11900 (12.2291 iter/s, 8.17724s/100 iters), loss = 0.428412
I1211 18:55:23.518893 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:55:23.518893 20404 solver.cpp:237]     Train net output #1: loss = 0.428412 (* 1 = 0.428412 loss)
I1211 18:55:23.518893 20404 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1211 18:55:31.310292  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:55:31.638833 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_12000.caffemodel
I1211 18:55:31.686945 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_12000.solverstate
I1211 18:55:31.693941 20404 solver.cpp:330] Iteration 12000, Testing net (#0)
I1211 18:55:31.693941 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:55:33.374495  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:55:33.440997 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7366
I1211 18:55:33.440997 20404 solver.cpp:397]     Test net output #1: loss = 0.742868 (* 1 = 0.742868 loss)
I1211 18:55:33.515038 20404 solver.cpp:218] Iteration 12000 (10.0045 iter/s, 9.99553s/100 iters), loss = 0.499566
I1211 18:55:33.515038 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:55:33.515038 20404 solver.cpp:237]     Train net output #1: loss = 0.499566 (* 1 = 0.499566 loss)
I1211 18:55:33.515038 20404 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1211 18:55:41.632273 20404 solver.cpp:218] Iteration 12100 (12.3204 iter/s, 8.1166s/100 iters), loss = 0.410189
I1211 18:55:41.632273 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:55:41.632273 20404 solver.cpp:237]     Train net output #1: loss = 0.410189 (* 1 = 0.410189 loss)
I1211 18:55:41.632273 20404 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1211 18:55:49.796216 20404 solver.cpp:218] Iteration 12200 (12.2497 iter/s, 8.16347s/100 iters), loss = 0.463939
I1211 18:55:49.796216 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:55:49.796216 20404 solver.cpp:237]     Train net output #1: loss = 0.463939 (* 1 = 0.463939 loss)
I1211 18:55:49.796216 20404 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1211 18:55:57.902310 20404 solver.cpp:218] Iteration 12300 (12.3372 iter/s, 8.10557s/100 iters), loss = 0.472291
I1211 18:55:57.902310 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:55:57.902310 20404 solver.cpp:237]     Train net output #1: loss = 0.472291 (* 1 = 0.472291 loss)
I1211 18:55:57.902310 20404 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1211 18:56:06.057729 20404 solver.cpp:218] Iteration 12400 (12.2631 iter/s, 8.15457s/100 iters), loss = 0.497597
I1211 18:56:06.057729 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:56:06.057729 20404 solver.cpp:237]     Train net output #1: loss = 0.497597 (* 1 = 0.497597 loss)
I1211 18:56:06.057729 20404 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1211 18:56:13.835932  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:56:14.164000 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_12500.caffemodel
I1211 18:56:14.197007 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_12500.solverstate
I1211 18:56:14.204010 20404 solver.cpp:330] Iteration 12500, Testing net (#0)
I1211 18:56:14.204010 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:56:15.926440  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:56:15.994451 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7355
I1211 18:56:15.994451 20404 solver.cpp:397]     Test net output #1: loss = 0.798083 (* 1 = 0.798083 loss)
I1211 18:56:16.071449 20404 solver.cpp:218] Iteration 12500 (9.9863 iter/s, 10.0137s/100 iters), loss = 0.415126
I1211 18:56:16.071449 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:56:16.071449 20404 solver.cpp:237]     Train net output #1: loss = 0.415126 (* 1 = 0.415126 loss)
I1211 18:56:16.071449 20404 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1211 18:56:24.170641 20404 solver.cpp:218] Iteration 12600 (12.3484 iter/s, 8.09821s/100 iters), loss = 0.429931
I1211 18:56:24.170641 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:56:24.170641 20404 solver.cpp:237]     Train net output #1: loss = 0.429931 (* 1 = 0.429931 loss)
I1211 18:56:24.170641 20404 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1211 18:56:32.316395 20404 solver.cpp:218] Iteration 12700 (12.2776 iter/s, 8.14495s/100 iters), loss = 0.504263
I1211 18:56:32.316395 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:56:32.316395 20404 solver.cpp:237]     Train net output #1: loss = 0.504263 (* 1 = 0.504263 loss)
I1211 18:56:32.316395 20404 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1211 18:56:40.377061 20404 solver.cpp:218] Iteration 12800 (12.4063 iter/s, 8.06043s/100 iters), loss = 0.439827
I1211 18:56:40.377061 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:56:40.377061 20404 solver.cpp:237]     Train net output #1: loss = 0.439827 (* 1 = 0.439827 loss)
I1211 18:56:40.377061 20404 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1211 18:56:48.423741 20404 solver.cpp:218] Iteration 12900 (12.4283 iter/s, 8.04618s/100 iters), loss = 0.45219
I1211 18:56:48.423741 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:56:48.423741 20404 solver.cpp:237]     Train net output #1: loss = 0.45219 (* 1 = 0.45219 loss)
I1211 18:56:48.423741 20404 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1211 18:56:56.078707  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:56:56.404767 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_13000.caffemodel
I1211 18:56:56.462821 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_13000.solverstate
I1211 18:56:56.468833 20404 solver.cpp:330] Iteration 13000, Testing net (#0)
I1211 18:56:56.468833 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:56:58.168581  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:56:58.236165 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6864
I1211 18:56:58.236165 20404 solver.cpp:397]     Test net output #1: loss = 0.906893 (* 1 = 0.906893 loss)
I1211 18:56:58.312667 20404 solver.cpp:218] Iteration 13000 (10.113 iter/s, 9.88829s/100 iters), loss = 0.430424
I1211 18:56:58.312667 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:56:58.312667 20404 solver.cpp:237]     Train net output #1: loss = 0.430424 (* 1 = 0.430424 loss)
I1211 18:56:58.312667 20404 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1211 18:57:06.376209 20404 solver.cpp:218] Iteration 13100 (12.4021 iter/s, 8.06312s/100 iters), loss = 0.516934
I1211 18:57:06.376209 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 18:57:06.376209 20404 solver.cpp:237]     Train net output #1: loss = 0.516934 (* 1 = 0.516934 loss)
I1211 18:57:06.376209 20404 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1211 18:57:14.443738 20404 solver.cpp:218] Iteration 13200 (12.3962 iter/s, 8.06697s/100 iters), loss = 0.491783
I1211 18:57:14.443738 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:57:14.443738 20404 solver.cpp:237]     Train net output #1: loss = 0.491783 (* 1 = 0.491783 loss)
I1211 18:57:14.443738 20404 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1211 18:57:22.503005 20404 solver.cpp:218] Iteration 13300 (12.4089 iter/s, 8.05876s/100 iters), loss = 0.540583
I1211 18:57:22.503005 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:57:22.503005 20404 solver.cpp:237]     Train net output #1: loss = 0.540583 (* 1 = 0.540583 loss)
I1211 18:57:22.503005 20404 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1211 18:57:30.569386 20404 solver.cpp:218] Iteration 13400 (12.3981 iter/s, 8.06578s/100 iters), loss = 0.543392
I1211 18:57:30.569386 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 18:57:30.569386 20404 solver.cpp:237]     Train net output #1: loss = 0.543392 (* 1 = 0.543392 loss)
I1211 18:57:30.569386 20404 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1211 18:57:38.234700  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:57:38.555272 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_13500.caffemodel
I1211 18:57:38.582499 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_13500.solverstate
I1211 18:57:38.589503 20404 solver.cpp:330] Iteration 13500, Testing net (#0)
I1211 18:57:38.589503 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:57:40.279100  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:57:40.346098 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7073
I1211 18:57:40.346098 20404 solver.cpp:397]     Test net output #1: loss = 0.903414 (* 1 = 0.903414 loss)
I1211 18:57:40.421119 20404 solver.cpp:218] Iteration 13500 (10.1515 iter/s, 9.8508s/100 iters), loss = 0.401718
I1211 18:57:40.421119 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:57:40.421119 20404 solver.cpp:237]     Train net output #1: loss = 0.401718 (* 1 = 0.401718 loss)
I1211 18:57:40.421119 20404 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1211 18:57:48.470281 20404 solver.cpp:218] Iteration 13600 (12.4243 iter/s, 8.04875s/100 iters), loss = 0.39849
I1211 18:57:48.470281 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:57:48.470281 20404 solver.cpp:237]     Train net output #1: loss = 0.39849 (* 1 = 0.39849 loss)
I1211 18:57:48.470774 20404 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1211 18:57:56.603492 20404 solver.cpp:218] Iteration 13700 (12.296 iter/s, 8.13271s/100 iters), loss = 0.538835
I1211 18:57:56.603492 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.74
I1211 18:57:56.603492 20404 solver.cpp:237]     Train net output #1: loss = 0.538835 (* 1 = 0.538835 loss)
I1211 18:57:56.603492 20404 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1211 18:58:04.933074 20404 solver.cpp:218] Iteration 13800 (12.0056 iter/s, 8.32946s/100 iters), loss = 0.527606
I1211 18:58:04.933074 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:58:04.933074 20404 solver.cpp:237]     Train net output #1: loss = 0.527606 (* 1 = 0.527606 loss)
I1211 18:58:04.933074 20404 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1211 18:58:13.128334 20404 solver.cpp:218] Iteration 13900 (12.203 iter/s, 8.19469s/100 iters), loss = 0.419862
I1211 18:58:13.128334 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:58:13.128334 20404 solver.cpp:237]     Train net output #1: loss = 0.419862 (* 1 = 0.419862 loss)
I1211 18:58:13.128334 20404 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1211 18:58:20.898200  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:58:21.223948 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_14000.caffemodel
I1211 18:58:21.288486 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_14000.solverstate
I1211 18:58:21.294610 20404 solver.cpp:330] Iteration 14000, Testing net (#0)
I1211 18:58:21.294610 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:58:23.007294  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:58:23.075279 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7753
I1211 18:58:23.075279 20404 solver.cpp:397]     Test net output #1: loss = 0.669146 (* 1 = 0.669146 loss)
I1211 18:58:23.151074 20404 solver.cpp:218] Iteration 14000 (9.97819 iter/s, 10.0219s/100 iters), loss = 0.400432
I1211 18:58:23.151074 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:58:23.151074 20404 solver.cpp:237]     Train net output #1: loss = 0.400432 (* 1 = 0.400432 loss)
I1211 18:58:23.151074 20404 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1211 18:58:31.331203 20404 solver.cpp:218] Iteration 14100 (12.2259 iter/s, 8.17936s/100 iters), loss = 0.454757
I1211 18:58:31.331203 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:58:31.331203 20404 solver.cpp:237]     Train net output #1: loss = 0.454757 (* 1 = 0.454757 loss)
I1211 18:58:31.331203 20404 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1211 18:58:39.523015 20404 solver.cpp:218] Iteration 14200 (12.2077 iter/s, 8.19156s/100 iters), loss = 0.457516
I1211 18:58:39.523015 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 18:58:39.523015 20404 solver.cpp:237]     Train net output #1: loss = 0.457516 (* 1 = 0.457516 loss)
I1211 18:58:39.523015 20404 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1211 18:58:47.761692 20404 solver.cpp:218] Iteration 14300 (12.1396 iter/s, 8.23748s/100 iters), loss = 0.602636
I1211 18:58:47.761692 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I1211 18:58:47.761692 20404 solver.cpp:237]     Train net output #1: loss = 0.602636 (* 1 = 0.602636 loss)
I1211 18:58:47.761692 20404 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1211 18:58:56.039194 20404 solver.cpp:218] Iteration 14400 (12.0813 iter/s, 8.27722s/100 iters), loss = 0.386012
I1211 18:58:56.039194 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 18:58:56.039194 20404 solver.cpp:237]     Train net output #1: loss = 0.386012 (* 1 = 0.386012 loss)
I1211 18:58:56.039194 20404 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1211 18:59:03.936779  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:59:04.268813 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_14500.caffemodel
I1211 18:59:04.299814 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_14500.solverstate
I1211 18:59:04.306813 20404 solver.cpp:330] Iteration 14500, Testing net (#0)
I1211 18:59:04.306813 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:59:06.040067  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:59:06.109064 20404 solver.cpp:397]     Test net output #0: accuracy = 0.74
I1211 18:59:06.109064 20404 solver.cpp:397]     Test net output #1: loss = 0.731312 (* 1 = 0.731312 loss)
I1211 18:59:06.187064 20404 solver.cpp:218] Iteration 14500 (9.85509 iter/s, 10.147s/100 iters), loss = 0.442239
I1211 18:59:06.187064 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 18:59:06.187064 20404 solver.cpp:237]     Train net output #1: loss = 0.442239 (* 1 = 0.442239 loss)
I1211 18:59:06.187064 20404 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1211 18:59:14.470976 20404 solver.cpp:218] Iteration 14600 (12.0715 iter/s, 8.284s/100 iters), loss = 0.317999
I1211 18:59:14.470976 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 18:59:14.470976 20404 solver.cpp:237]     Train net output #1: loss = 0.317999 (* 1 = 0.317999 loss)
I1211 18:59:14.470976 20404 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1211 18:59:22.547150 20404 solver.cpp:218] Iteration 14700 (12.3831 iter/s, 8.07553s/100 iters), loss = 0.411986
I1211 18:59:22.547150 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:59:22.547150 20404 solver.cpp:237]     Train net output #1: loss = 0.411986 (* 1 = 0.411986 loss)
I1211 18:59:22.547150 20404 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1211 18:59:30.630498 20404 solver.cpp:218] Iteration 14800 (12.3727 iter/s, 8.08234s/100 iters), loss = 0.587374
I1211 18:59:30.630498 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 18:59:30.630498 20404 solver.cpp:237]     Train net output #1: loss = 0.587374 (* 1 = 0.587374 loss)
I1211 18:59:30.630498 20404 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1211 18:59:38.808240 20404 solver.cpp:218] Iteration 14900 (12.229 iter/s, 8.17725s/100 iters), loss = 0.433509
I1211 18:59:38.808240 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 18:59:38.808240 20404 solver.cpp:237]     Train net output #1: loss = 0.433509 (* 1 = 0.433509 loss)
I1211 18:59:38.808240 20404 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1211 18:59:46.740722  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:59:47.066565 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_15000.caffemodel
I1211 18:59:47.119669 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_15000.solverstate
I1211 18:59:47.125660 20404 solver.cpp:330] Iteration 15000, Testing net (#0)
I1211 18:59:47.125660 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 18:59:48.835644  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 18:59:48.902652 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7151
I1211 18:59:48.902652 20404 solver.cpp:397]     Test net output #1: loss = 0.814625 (* 1 = 0.814625 loss)
I1211 18:59:48.979395 20404 solver.cpp:218] Iteration 15000 (9.83241 iter/s, 10.1704s/100 iters), loss = 0.38427
I1211 18:59:48.979395 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 18:59:48.979395 20404 solver.cpp:237]     Train net output #1: loss = 0.38427 (* 1 = 0.38427 loss)
I1211 18:59:48.979395 20404 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1211 18:59:57.149032 20404 solver.cpp:218] Iteration 15100 (12.2403 iter/s, 8.16971s/100 iters), loss = 0.44533
I1211 18:59:57.149032 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 18:59:57.149032 20404 solver.cpp:237]     Train net output #1: loss = 0.44533 (* 1 = 0.44533 loss)
I1211 18:59:57.149032 20404 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1211 19:00:05.295992 20404 solver.cpp:218] Iteration 15200 (12.2752 iter/s, 8.1465s/100 iters), loss = 0.455885
I1211 19:00:05.296983 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:00:05.296983 20404 solver.cpp:237]     Train net output #1: loss = 0.455885 (* 1 = 0.455885 loss)
I1211 19:00:05.296983 20404 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1211 19:00:13.365133 20404 solver.cpp:218] Iteration 15300 (12.3952 iter/s, 8.06766s/100 iters), loss = 0.441504
I1211 19:00:13.365133 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:00:13.365133 20404 solver.cpp:237]     Train net output #1: loss = 0.441504 (* 1 = 0.441504 loss)
I1211 19:00:13.365133 20404 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1211 19:00:21.434707 20404 solver.cpp:218] Iteration 15400 (12.393 iter/s, 8.06908s/100 iters), loss = 0.438016
I1211 19:00:21.434707 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:00:21.434707 20404 solver.cpp:237]     Train net output #1: loss = 0.438016 (* 1 = 0.438016 loss)
I1211 19:00:21.434707 20404 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1211 19:00:29.198621  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:00:29.524215 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_15500.caffemodel
I1211 19:00:29.553721 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_15500.solverstate
I1211 19:00:29.560722 20404 solver.cpp:330] Iteration 15500, Testing net (#0)
I1211 19:00:29.560722 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:00:31.295898  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:00:31.363924 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7641
I1211 19:00:31.364926 20404 solver.cpp:397]     Test net output #1: loss = 0.679294 (* 1 = 0.679294 loss)
I1211 19:00:31.440929 20404 solver.cpp:218] Iteration 15500 (9.99352 iter/s, 10.0065s/100 iters), loss = 0.405483
I1211 19:00:31.440929 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:00:31.441941 20404 solver.cpp:237]     Train net output #1: loss = 0.405483 (* 1 = 0.405483 loss)
I1211 19:00:31.441941 20404 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1211 19:00:39.665247 20404 solver.cpp:218] Iteration 15600 (12.1602 iter/s, 8.22354s/100 iters), loss = 0.45382
I1211 19:00:39.665247 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:00:39.665247 20404 solver.cpp:237]     Train net output #1: loss = 0.45382 (* 1 = 0.45382 loss)
I1211 19:00:39.665247 20404 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1211 19:00:47.959674 20404 solver.cpp:218] Iteration 15700 (12.0574 iter/s, 8.29363s/100 iters), loss = 0.390707
I1211 19:00:47.959674 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:00:47.959674 20404 solver.cpp:237]     Train net output #1: loss = 0.390707 (* 1 = 0.390707 loss)
I1211 19:00:47.959674 20404 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1211 19:00:56.004859 20404 solver.cpp:218] Iteration 15800 (12.4312 iter/s, 8.04428s/100 iters), loss = 0.491779
I1211 19:00:56.004859 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:00:56.004859 20404 solver.cpp:237]     Train net output #1: loss = 0.491779 (* 1 = 0.491779 loss)
I1211 19:00:56.004859 20404 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1211 19:01:04.123379 20404 solver.cpp:218] Iteration 15900 (12.3182 iter/s, 8.11804s/100 iters), loss = 0.382641
I1211 19:01:04.123379 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:01:04.123379 20404 solver.cpp:237]     Train net output #1: loss = 0.382641 (* 1 = 0.382641 loss)
I1211 19:01:04.123379 20404 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1211 19:01:11.780443  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:01:12.099474 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_16000.caffemodel
I1211 19:01:12.145476 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_16000.solverstate
I1211 19:01:12.151501 20404 solver.cpp:330] Iteration 16000, Testing net (#0)
I1211 19:01:12.151501 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:01:13.835676  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:01:13.902680 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6892
I1211 19:01:13.902680 20404 solver.cpp:397]     Test net output #1: loss = 0.997462 (* 1 = 0.997462 loss)
I1211 19:01:13.976691 20404 solver.cpp:218] Iteration 16000 (10.1487 iter/s, 9.85344s/100 iters), loss = 0.444792
I1211 19:01:13.976691 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:01:13.976691 20404 solver.cpp:237]     Train net output #1: loss = 0.444792 (* 1 = 0.444792 loss)
I1211 19:01:13.976691 20404 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1211 19:01:21.987900 20404 solver.cpp:218] Iteration 16100 (12.4839 iter/s, 8.01033s/100 iters), loss = 0.471902
I1211 19:01:21.987900 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:01:21.987900 20404 solver.cpp:237]     Train net output #1: loss = 0.471902 (* 1 = 0.471902 loss)
I1211 19:01:21.987900 20404 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1211 19:01:30.019546 20404 solver.cpp:218] Iteration 16200 (12.4511 iter/s, 8.03144s/100 iters), loss = 0.435559
I1211 19:01:30.019546 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:01:30.019546 20404 solver.cpp:237]     Train net output #1: loss = 0.435559 (* 1 = 0.435559 loss)
I1211 19:01:30.019546 20404 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1211 19:01:38.052454 20404 solver.cpp:218] Iteration 16300 (12.4505 iter/s, 8.03183s/100 iters), loss = 0.568412
I1211 19:01:38.052454 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 19:01:38.052454 20404 solver.cpp:237]     Train net output #1: loss = 0.568412 (* 1 = 0.568412 loss)
I1211 19:01:38.052454 20404 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1211 19:01:46.082207 20404 solver.cpp:218] Iteration 16400 (12.4542 iter/s, 8.02945s/100 iters), loss = 0.350698
I1211 19:01:46.082207 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:01:46.082207 20404 solver.cpp:237]     Train net output #1: loss = 0.350698 (* 1 = 0.350698 loss)
I1211 19:01:46.082207 20404 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1211 19:01:53.708678  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:01:54.028424 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_16500.caffemodel
I1211 19:01:54.060425 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_16500.solverstate
I1211 19:01:54.067435 20404 solver.cpp:330] Iteration 16500, Testing net (#0)
I1211 19:01:54.067435 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:01:55.747789  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:01:55.813714 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7741
I1211 19:01:55.813714 20404 solver.cpp:397]     Test net output #1: loss = 0.654824 (* 1 = 0.654824 loss)
I1211 19:01:55.888404 20404 solver.cpp:218] Iteration 16500 (10.1982 iter/s, 9.80567s/100 iters), loss = 0.375762
I1211 19:01:55.888404 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:01:55.888404 20404 solver.cpp:237]     Train net output #1: loss = 0.375762 (* 1 = 0.375762 loss)
I1211 19:01:55.888404 20404 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1211 19:02:03.924335 20404 solver.cpp:218] Iteration 16600 (12.4452 iter/s, 8.03524s/100 iters), loss = 0.461365
I1211 19:02:03.924335 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:02:03.924335 20404 solver.cpp:237]     Train net output #1: loss = 0.461365 (* 1 = 0.461365 loss)
I1211 19:02:03.924335 20404 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1211 19:02:12.021667 20404 solver.cpp:218] Iteration 16700 (12.3507 iter/s, 8.09674s/100 iters), loss = 0.461341
I1211 19:02:12.021667 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:02:12.021667 20404 solver.cpp:237]     Train net output #1: loss = 0.461341 (* 1 = 0.461341 loss)
I1211 19:02:12.021667 20404 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1211 19:02:20.048342 20404 solver.cpp:218] Iteration 16800 (12.4589 iter/s, 8.02639s/100 iters), loss = 0.470508
I1211 19:02:20.048342 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:02:20.048342 20404 solver.cpp:237]     Train net output #1: loss = 0.470508 (* 1 = 0.470508 loss)
I1211 19:02:20.048342 20404 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1211 19:02:28.042405 20404 solver.cpp:218] Iteration 16900 (12.5096 iter/s, 7.99386s/100 iters), loss = 0.414083
I1211 19:02:28.042405 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:02:28.043406 20404 solver.cpp:237]     Train net output #1: loss = 0.414083 (* 1 = 0.414083 loss)
I1211 19:02:28.043406 20404 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1211 19:02:35.665897  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:02:35.989408 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_17000.caffemodel
I1211 19:02:36.044432 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_17000.solverstate
I1211 19:02:36.051429 20404 solver.cpp:330] Iteration 17000, Testing net (#0)
I1211 19:02:36.051429 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:02:37.747227  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:02:37.815845 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7599
I1211 19:02:37.815845 20404 solver.cpp:397]     Test net output #1: loss = 0.713734 (* 1 = 0.713734 loss)
I1211 19:02:37.890369 20404 solver.cpp:218] Iteration 17000 (10.1557 iter/s, 9.84671s/100 iters), loss = 0.407143
I1211 19:02:37.890369 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:02:37.890369 20404 solver.cpp:237]     Train net output #1: loss = 0.407143 (* 1 = 0.407143 loss)
I1211 19:02:37.890369 20404 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1211 19:02:45.918372 20404 solver.cpp:218] Iteration 17100 (12.4564 iter/s, 8.02803s/100 iters), loss = 0.332074
I1211 19:02:45.918372 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:02:45.918372 20404 solver.cpp:237]     Train net output #1: loss = 0.332074 (* 1 = 0.332074 loss)
I1211 19:02:45.918372 20404 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1211 19:02:53.976289 20404 solver.cpp:218] Iteration 17200 (12.4114 iter/s, 8.05713s/100 iters), loss = 0.43101
I1211 19:02:53.976289 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:02:53.976289 20404 solver.cpp:237]     Train net output #1: loss = 0.43101 (* 1 = 0.43101 loss)
I1211 19:02:53.976289 20404 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1211 19:03:02.134457 20404 solver.cpp:218] Iteration 17300 (12.2588 iter/s, 8.1574s/100 iters), loss = 0.487983
I1211 19:03:02.134457 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 19:03:02.134457 20404 solver.cpp:237]     Train net output #1: loss = 0.487983 (* 1 = 0.487983 loss)
I1211 19:03:02.134457 20404 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1211 19:03:10.260866 20404 solver.cpp:218] Iteration 17400 (12.306 iter/s, 8.12614s/100 iters), loss = 0.449245
I1211 19:03:10.260866 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:03:10.260866 20404 solver.cpp:237]     Train net output #1: loss = 0.449245 (* 1 = 0.449245 loss)
I1211 19:03:10.260866 20404 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1211 19:03:17.935259  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:03:18.256278 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_17500.caffemodel
I1211 19:03:18.285279 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_17500.solverstate
I1211 19:03:18.291280 20404 solver.cpp:330] Iteration 17500, Testing net (#0)
I1211 19:03:18.291280 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:03:19.991411  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:03:20.058418 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7847
I1211 19:03:20.058418 20404 solver.cpp:397]     Test net output #1: loss = 0.637349 (* 1 = 0.637349 loss)
I1211 19:03:20.133441 20404 solver.cpp:218] Iteration 17500 (10.1296 iter/s, 9.87202s/100 iters), loss = 0.357879
I1211 19:03:20.133441 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:03:20.133441 20404 solver.cpp:237]     Train net output #1: loss = 0.357879 (* 1 = 0.357879 loss)
I1211 19:03:20.133441 20404 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1211 19:03:28.187273 20404 solver.cpp:218] Iteration 17600 (12.4173 iter/s, 8.05328s/100 iters), loss = 0.351738
I1211 19:03:28.187273 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:03:28.187273 20404 solver.cpp:237]     Train net output #1: loss = 0.351738 (* 1 = 0.351738 loss)
I1211 19:03:28.187273 20404 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1211 19:03:36.245033 20404 solver.cpp:218] Iteration 17700 (12.4118 iter/s, 8.05683s/100 iters), loss = 0.479013
I1211 19:03:36.245033 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:03:36.245033 20404 solver.cpp:237]     Train net output #1: loss = 0.479013 (* 1 = 0.479013 loss)
I1211 19:03:36.245033 20404 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1211 19:03:44.518554 20404 solver.cpp:218] Iteration 17800 (12.0875 iter/s, 8.27299s/100 iters), loss = 0.477086
I1211 19:03:44.518554 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:03:44.518554 20404 solver.cpp:237]     Train net output #1: loss = 0.477086 (* 1 = 0.477086 loss)
I1211 19:03:44.518554 20404 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1211 19:03:52.749528 20404 solver.cpp:218] Iteration 17900 (12.1492 iter/s, 8.23102s/100 iters), loss = 0.435373
I1211 19:03:52.749528 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:03:52.749528 20404 solver.cpp:237]     Train net output #1: loss = 0.435373 (* 1 = 0.435373 loss)
I1211 19:03:52.749528 20404 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1211 19:04:00.530403  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:04:00.860163 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_18000.caffemodel
I1211 19:04:00.922169 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_18000.solverstate
I1211 19:04:00.929169 20404 solver.cpp:330] Iteration 18000, Testing net (#0)
I1211 19:04:00.929169 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:04:02.657768  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:04:02.726279 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6739
I1211 19:04:02.726279 20404 solver.cpp:397]     Test net output #1: loss = 1.00162 (* 1 = 1.00162 loss)
I1211 19:04:02.805152 20404 solver.cpp:218] Iteration 18000 (9.94576 iter/s, 10.0545s/100 iters), loss = 0.38262
I1211 19:04:02.805152 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:04:02.805152 20404 solver.cpp:237]     Train net output #1: loss = 0.38262 (* 1 = 0.38262 loss)
I1211 19:04:02.805152 20404 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1211 19:04:10.949041 20404 solver.cpp:218] Iteration 18100 (12.2788 iter/s, 8.14414s/100 iters), loss = 0.340026
I1211 19:04:10.950042 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:04:10.950042 20404 solver.cpp:237]     Train net output #1: loss = 0.340026 (* 1 = 0.340026 loss)
I1211 19:04:10.950042 20404 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1211 19:04:19.015846 20404 solver.cpp:218] Iteration 18200 (12.3985 iter/s, 8.06551s/100 iters), loss = 0.496207
I1211 19:04:19.015846 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:04:19.015846 20404 solver.cpp:237]     Train net output #1: loss = 0.496207 (* 1 = 0.496207 loss)
I1211 19:04:19.015846 20404 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1211 19:04:27.105062 20404 solver.cpp:218] Iteration 18300 (12.3621 iter/s, 8.08924s/100 iters), loss = 0.4804
I1211 19:04:27.105062 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:04:27.105062 20404 solver.cpp:237]     Train net output #1: loss = 0.4804 (* 1 = 0.4804 loss)
I1211 19:04:27.105062 20404 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1211 19:04:35.151022 20404 solver.cpp:218] Iteration 18400 (12.4294 iter/s, 8.04546s/100 iters), loss = 0.426535
I1211 19:04:35.152022 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:04:35.152022 20404 solver.cpp:237]     Train net output #1: loss = 0.426535 (* 1 = 0.426535 loss)
I1211 19:04:35.152022 20404 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1211 19:04:42.803941  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:04:43.121963 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_18500.caffemodel
I1211 19:04:43.155969 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_18500.solverstate
I1211 19:04:43.162974 20404 solver.cpp:330] Iteration 18500, Testing net (#0)
I1211 19:04:43.163975 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:04:44.854153  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:04:44.920156 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7061
I1211 19:04:44.920156 20404 solver.cpp:397]     Test net output #1: loss = 0.894304 (* 1 = 0.894304 loss)
I1211 19:04:44.995162 20404 solver.cpp:218] Iteration 18500 (10.1594 iter/s, 9.8431s/100 iters), loss = 0.482596
I1211 19:04:44.995162 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:04:44.995162 20404 solver.cpp:237]     Train net output #1: loss = 0.482596 (* 1 = 0.482596 loss)
I1211 19:04:44.995162 20404 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1211 19:04:53.080528 20404 solver.cpp:218] Iteration 18600 (12.3685 iter/s, 8.08507s/100 iters), loss = 0.401439
I1211 19:04:53.080528 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:04:53.080528 20404 solver.cpp:237]     Train net output #1: loss = 0.401439 (* 1 = 0.401439 loss)
I1211 19:04:53.080528 20404 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1211 19:05:01.133414 20404 solver.cpp:218] Iteration 18700 (12.4193 iter/s, 8.05197s/100 iters), loss = 0.423212
I1211 19:05:01.133414 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:05:01.133414 20404 solver.cpp:237]     Train net output #1: loss = 0.423212 (* 1 = 0.423212 loss)
I1211 19:05:01.133414 20404 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1211 19:05:09.188597 20404 solver.cpp:218] Iteration 18800 (12.4144 iter/s, 8.05517s/100 iters), loss = 0.480197
I1211 19:05:09.188597 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:05:09.188597 20404 solver.cpp:237]     Train net output #1: loss = 0.480197 (* 1 = 0.480197 loss)
I1211 19:05:09.189599 20404 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1211 19:05:17.353440 20404 solver.cpp:218] Iteration 18900 (12.2492 iter/s, 8.16383s/100 iters), loss = 0.402557
I1211 19:05:17.353440 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:05:17.353941 20404 solver.cpp:237]     Train net output #1: loss = 0.402557 (* 1 = 0.402557 loss)
I1211 19:05:17.353941 20404 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1211 19:05:24.932808  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:05:25.247831 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_19000.caffemodel
I1211 19:05:25.276835 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_19000.solverstate
I1211 19:05:25.283836 20404 solver.cpp:330] Iteration 19000, Testing net (#0)
I1211 19:05:25.283836 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:05:26.953457  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:05:27.019959 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7619
I1211 19:05:27.019959 20404 solver.cpp:397]     Test net output #1: loss = 0.719596 (* 1 = 0.719596 loss)
I1211 19:05:27.093983 20404 solver.cpp:218] Iteration 19000 (10.2665 iter/s, 9.74039s/100 iters), loss = 0.416704
I1211 19:05:27.093983 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:05:27.093983 20404 solver.cpp:237]     Train net output #1: loss = 0.416704 (* 1 = 0.416704 loss)
I1211 19:05:27.093983 20404 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1211 19:05:35.254716 20404 solver.cpp:218] Iteration 19100 (12.2558 iter/s, 8.15943s/100 iters), loss = 0.338545
I1211 19:05:35.254716 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:05:35.254716 20404 solver.cpp:237]     Train net output #1: loss = 0.338545 (* 1 = 0.338545 loss)
I1211 19:05:35.254716 20404 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1211 19:05:43.300029 20404 solver.cpp:218] Iteration 19200 (12.4302 iter/s, 8.0449s/100 iters), loss = 0.478467
I1211 19:05:43.300029 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:05:43.300029 20404 solver.cpp:237]     Train net output #1: loss = 0.478467 (* 1 = 0.478467 loss)
I1211 19:05:43.300029 20404 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1211 19:05:51.260367 20404 solver.cpp:218] Iteration 19300 (12.5632 iter/s, 7.95976s/100 iters), loss = 0.342378
I1211 19:05:51.260367 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:05:51.260367 20404 solver.cpp:237]     Train net output #1: loss = 0.342378 (* 1 = 0.342378 loss)
I1211 19:05:51.260367 20404 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1211 19:05:59.287926 20404 solver.cpp:218] Iteration 19400 (12.4565 iter/s, 8.02792s/100 iters), loss = 0.425287
I1211 19:05:59.288926 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:05:59.288926 20404 solver.cpp:237]     Train net output #1: loss = 0.425287 (* 1 = 0.425287 loss)
I1211 19:05:59.288926 20404 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1211 19:06:06.850059  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:06:07.165132 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_19500.caffemodel
I1211 19:06:07.198161 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_19500.solverstate
I1211 19:06:07.204162 20404 solver.cpp:330] Iteration 19500, Testing net (#0)
I1211 19:06:07.204162 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:06:08.876663  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:06:08.942682 20404 solver.cpp:397]     Test net output #0: accuracy = 0.745
I1211 19:06:08.942682 20404 solver.cpp:397]     Test net output #1: loss = 0.794576 (* 1 = 0.794576 loss)
I1211 19:06:09.018200 20404 solver.cpp:218] Iteration 19500 (10.2783 iter/s, 9.72924s/100 iters), loss = 0.409242
I1211 19:06:09.018200 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:06:09.018200 20404 solver.cpp:237]     Train net output #1: loss = 0.409242 (* 1 = 0.409242 loss)
I1211 19:06:09.018200 20404 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1211 19:06:16.968626 20404 solver.cpp:218] Iteration 19600 (12.5783 iter/s, 7.95018s/100 iters), loss = 0.415812
I1211 19:06:16.968626 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:06:16.968626 20404 solver.cpp:237]     Train net output #1: loss = 0.415812 (* 1 = 0.415812 loss)
I1211 19:06:16.968626 20404 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1211 19:06:24.914533 20404 solver.cpp:218] Iteration 19700 (12.5858 iter/s, 7.94548s/100 iters), loss = 0.480131
I1211 19:06:24.914533 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:06:24.914533 20404 solver.cpp:237]     Train net output #1: loss = 0.480131 (* 1 = 0.480131 loss)
I1211 19:06:24.914533 20404 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1211 19:06:32.865412 20404 solver.cpp:218] Iteration 19800 (12.5783 iter/s, 7.95019s/100 iters), loss = 0.523491
I1211 19:06:32.865412 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:06:32.865412 20404 solver.cpp:237]     Train net output #1: loss = 0.523491 (* 1 = 0.523491 loss)
I1211 19:06:32.865412 20404 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1211 19:06:40.806933 20404 solver.cpp:218] Iteration 19900 (12.5925 iter/s, 7.94121s/100 iters), loss = 0.4148
I1211 19:06:40.806933 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:06:40.806933 20404 solver.cpp:237]     Train net output #1: loss = 0.4148 (* 1 = 0.4148 loss)
I1211 19:06:40.806933 20404 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1211 19:06:48.360054  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:06:48.675240 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_20000.caffemodel
I1211 19:06:48.721324 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_20000.solverstate
I1211 19:06:48.727324 20404 solver.cpp:330] Iteration 20000, Testing net (#0)
I1211 19:06:48.727324 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:06:50.400912  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:06:50.466923 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7053
I1211 19:06:50.466923 20404 solver.cpp:397]     Test net output #1: loss = 0.926923 (* 1 = 0.926923 loss)
I1211 19:06:50.540491 20404 solver.cpp:218] Iteration 20000 (10.2741 iter/s, 9.73321s/100 iters), loss = 0.417417
I1211 19:06:50.541492 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:06:50.541492 20404 solver.cpp:237]     Train net output #1: loss = 0.417417 (* 1 = 0.417417 loss)
I1211 19:06:50.541492 20404 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1211 19:06:58.538272 20404 solver.cpp:218] Iteration 20100 (12.5047 iter/s, 7.99702s/100 iters), loss = 0.305942
I1211 19:06:58.538272 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:06:58.538272 20404 solver.cpp:237]     Train net output #1: loss = 0.305942 (* 1 = 0.305942 loss)
I1211 19:06:58.538272 20404 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1211 19:07:06.526248 20404 solver.cpp:218] Iteration 20200 (12.5194 iter/s, 7.98763s/100 iters), loss = 0.483477
I1211 19:07:06.526248 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:07:06.526248 20404 solver.cpp:237]     Train net output #1: loss = 0.483477 (* 1 = 0.483477 loss)
I1211 19:07:06.526248 20404 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1211 19:07:14.550619 20404 solver.cpp:218] Iteration 20300 (12.463 iter/s, 8.02378s/100 iters), loss = 0.601709
I1211 19:07:14.550619 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.78
I1211 19:07:14.550619 20404 solver.cpp:237]     Train net output #1: loss = 0.601709 (* 1 = 0.601709 loss)
I1211 19:07:14.550619 20404 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1211 19:07:22.528964 20404 solver.cpp:218] Iteration 20400 (12.5358 iter/s, 7.97716s/100 iters), loss = 0.41059
I1211 19:07:22.528964 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:07:22.528964 20404 solver.cpp:237]     Train net output #1: loss = 0.41059 (* 1 = 0.41059 loss)
I1211 19:07:22.528964 20404 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1211 19:07:30.079989  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:07:30.394016 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_20500.caffemodel
I1211 19:07:30.422025 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_20500.solverstate
I1211 19:07:30.428026 20404 solver.cpp:330] Iteration 20500, Testing net (#0)
I1211 19:07:30.428026 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:07:32.101227  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:07:32.167228 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7401
I1211 19:07:32.167228 20404 solver.cpp:397]     Test net output #1: loss = 0.758133 (* 1 = 0.758133 loss)
I1211 19:07:32.242251 20404 solver.cpp:218] Iteration 20500 (10.2954 iter/s, 9.71308s/100 iters), loss = 0.451068
I1211 19:07:32.242251 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:07:32.242251 20404 solver.cpp:237]     Train net output #1: loss = 0.451068 (* 1 = 0.451068 loss)
I1211 19:07:32.242251 20404 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1211 19:07:40.188453 20404 solver.cpp:218] Iteration 20600 (12.5854 iter/s, 7.9457s/100 iters), loss = 0.333259
I1211 19:07:40.188453 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:07:40.188453 20404 solver.cpp:237]     Train net output #1: loss = 0.333259 (* 1 = 0.333259 loss)
I1211 19:07:40.188453 20404 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1211 19:07:48.123917 20404 solver.cpp:218] Iteration 20700 (12.6023 iter/s, 7.93507s/100 iters), loss = 0.480729
I1211 19:07:48.123917 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:07:48.123917 20404 solver.cpp:237]     Train net output #1: loss = 0.480729 (* 1 = 0.480729 loss)
I1211 19:07:48.123917 20404 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1211 19:07:56.076112 20404 solver.cpp:218] Iteration 20800 (12.5764 iter/s, 7.95143s/100 iters), loss = 0.475725
I1211 19:07:56.076112 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:07:56.076112 20404 solver.cpp:237]     Train net output #1: loss = 0.475725 (* 1 = 0.475725 loss)
I1211 19:07:56.076112 20404 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1211 19:08:04.016736 20404 solver.cpp:218] Iteration 20900 (12.5944 iter/s, 7.94004s/100 iters), loss = 0.325543
I1211 19:08:04.016736 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:08:04.016736 20404 solver.cpp:237]     Train net output #1: loss = 0.325543 (* 1 = 0.325543 loss)
I1211 19:08:04.016736 20404 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1211 19:08:11.574128  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:08:11.890175 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_21000.caffemodel
I1211 19:08:11.944195 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_21000.solverstate
I1211 19:08:11.950196 20404 solver.cpp:330] Iteration 21000, Testing net (#0)
I1211 19:08:11.950196 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:08:13.628815  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:08:13.695335 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7359
I1211 19:08:13.695335 20404 solver.cpp:397]     Test net output #1: loss = 0.821493 (* 1 = 0.821493 loss)
I1211 19:08:13.769364 20404 solver.cpp:218] Iteration 21000 (10.254 iter/s, 9.75227s/100 iters), loss = 0.418399
I1211 19:08:13.769364 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:08:13.769364 20404 solver.cpp:237]     Train net output #1: loss = 0.418399 (* 1 = 0.418399 loss)
I1211 19:08:13.769364 20404 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1211 19:08:21.776239 20404 solver.cpp:218] Iteration 21100 (12.4903 iter/s, 8.00618s/100 iters), loss = 0.417521
I1211 19:08:21.776239 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:08:21.776239 20404 solver.cpp:237]     Train net output #1: loss = 0.417521 (* 1 = 0.417521 loss)
I1211 19:08:21.776239 20404 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1211 19:08:29.735098 20404 solver.cpp:218] Iteration 21200 (12.5654 iter/s, 7.95838s/100 iters), loss = 0.438451
I1211 19:08:29.735098 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:08:29.735098 20404 solver.cpp:237]     Train net output #1: loss = 0.438451 (* 1 = 0.438451 loss)
I1211 19:08:29.735098 20404 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1211 19:08:37.689368 20404 solver.cpp:218] Iteration 21300 (12.5721 iter/s, 7.95409s/100 iters), loss = 0.457546
I1211 19:08:37.689368 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:08:37.689368 20404 solver.cpp:237]     Train net output #1: loss = 0.457546 (* 1 = 0.457546 loss)
I1211 19:08:37.689368 20404 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1211 19:08:45.644338 20404 solver.cpp:218] Iteration 21400 (12.571 iter/s, 7.95479s/100 iters), loss = 0.400657
I1211 19:08:45.644338 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:08:45.644338 20404 solver.cpp:237]     Train net output #1: loss = 0.400657 (* 1 = 0.400657 loss)
I1211 19:08:45.644338 20404 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1211 19:08:53.216173  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:08:53.530712 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_21500.caffemodel
I1211 19:08:53.559216 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_21500.solverstate
I1211 19:08:53.566216 20404 solver.cpp:330] Iteration 21500, Testing net (#0)
I1211 19:08:53.566216 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:08:55.237571  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:08:55.303570 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7689
I1211 19:08:55.303570 20404 solver.cpp:397]     Test net output #1: loss = 0.684613 (* 1 = 0.684613 loss)
I1211 19:08:55.378213 20404 solver.cpp:218] Iteration 21500 (10.2743 iter/s, 9.73306s/100 iters), loss = 0.364357
I1211 19:08:55.378213 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:08:55.378213 20404 solver.cpp:237]     Train net output #1: loss = 0.364357 (* 1 = 0.364357 loss)
I1211 19:08:55.378213 20404 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1211 19:09:03.336733 20404 solver.cpp:218] Iteration 21600 (12.5663 iter/s, 7.95779s/100 iters), loss = 0.404039
I1211 19:09:03.336733 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:09:03.336733 20404 solver.cpp:237]     Train net output #1: loss = 0.404039 (* 1 = 0.404039 loss)
I1211 19:09:03.336733 20404 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1211 19:09:11.293915 20404 solver.cpp:218] Iteration 21700 (12.5677 iter/s, 7.95692s/100 iters), loss = 0.536995
I1211 19:09:11.293915 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:09:11.293915 20404 solver.cpp:237]     Train net output #1: loss = 0.536995 (* 1 = 0.536995 loss)
I1211 19:09:11.293915 20404 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1211 19:09:19.260123 20404 solver.cpp:218] Iteration 21800 (12.5534 iter/s, 7.96596s/100 iters), loss = 0.486151
I1211 19:09:19.260123 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:09:19.260123 20404 solver.cpp:237]     Train net output #1: loss = 0.486151 (* 1 = 0.486151 loss)
I1211 19:09:19.260123 20404 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1211 19:09:27.239169 20404 solver.cpp:218] Iteration 21900 (12.5346 iter/s, 7.97791s/100 iters), loss = 0.349083
I1211 19:09:27.239169 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:09:27.239169 20404 solver.cpp:237]     Train net output #1: loss = 0.349083 (* 1 = 0.349083 loss)
I1211 19:09:27.239169 20404 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1211 19:09:34.801923  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:09:35.115942 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_22000.caffemodel
I1211 19:09:35.142947 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_22000.solverstate
I1211 19:09:35.149447 20404 solver.cpp:330] Iteration 22000, Testing net (#0)
I1211 19:09:35.149948 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:09:36.831125  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:09:36.897136 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7116
I1211 19:09:36.897136 20404 solver.cpp:397]     Test net output #1: loss = 0.887494 (* 1 = 0.887494 loss)
I1211 19:09:36.972163 20404 solver.cpp:218] Iteration 22000 (10.275 iter/s, 9.73232s/100 iters), loss = 0.39002
I1211 19:09:36.972163 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:09:36.972163 20404 solver.cpp:237]     Train net output #1: loss = 0.39002 (* 1 = 0.39002 loss)
I1211 19:09:36.972163 20404 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1211 19:09:44.942564 20404 solver.cpp:218] Iteration 22100 (12.5468 iter/s, 7.97014s/100 iters), loss = 0.399148
I1211 19:09:44.942564 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:09:44.942564 20404 solver.cpp:237]     Train net output #1: loss = 0.399148 (* 1 = 0.399148 loss)
I1211 19:09:44.942564 20404 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1211 19:09:52.879186 20404 solver.cpp:218] Iteration 22200 (12.6009 iter/s, 7.93595s/100 iters), loss = 0.450514
I1211 19:09:52.879186 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:09:52.879186 20404 solver.cpp:237]     Train net output #1: loss = 0.450514 (* 1 = 0.450514 loss)
I1211 19:09:52.879186 20404 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1211 19:10:00.832772 20404 solver.cpp:218] Iteration 22300 (12.5728 iter/s, 7.95367s/100 iters), loss = 0.42255
I1211 19:10:00.832772 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:10:00.832772 20404 solver.cpp:237]     Train net output #1: loss = 0.42255 (* 1 = 0.42255 loss)
I1211 19:10:00.832772 20404 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1211 19:10:08.801542 20404 solver.cpp:218] Iteration 22400 (12.5502 iter/s, 7.96799s/100 iters), loss = 0.425832
I1211 19:10:08.801542 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:10:08.801542 20404 solver.cpp:237]     Train net output #1: loss = 0.425832 (* 1 = 0.425832 loss)
I1211 19:10:08.801542 20404 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1211 19:10:16.358803  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:10:16.672829 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_22500.caffemodel
I1211 19:10:16.704867 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_22500.solverstate
I1211 19:10:16.710872 20404 solver.cpp:330] Iteration 22500, Testing net (#0)
I1211 19:10:16.710872 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:10:18.382012  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:10:18.448017 20404 solver.cpp:397]     Test net output #0: accuracy = 0.732
I1211 19:10:18.448017 20404 solver.cpp:397]     Test net output #1: loss = 0.821188 (* 1 = 0.821188 loss)
I1211 19:10:18.522027 20404 solver.cpp:218] Iteration 22500 (10.2876 iter/s, 9.7204s/100 iters), loss = 0.403114
I1211 19:10:18.522027 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:10:18.522027 20404 solver.cpp:237]     Train net output #1: loss = 0.403114 (* 1 = 0.403114 loss)
I1211 19:10:18.522027 20404 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1211 19:10:26.462661 20404 solver.cpp:218] Iteration 22600 (12.5954 iter/s, 7.93938s/100 iters), loss = 0.333277
I1211 19:10:26.462661 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:10:26.462661 20404 solver.cpp:237]     Train net output #1: loss = 0.333277 (* 1 = 0.333277 loss)
I1211 19:10:26.462661 20404 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1211 19:10:34.404989 20404 solver.cpp:218] Iteration 22700 (12.5912 iter/s, 7.94208s/100 iters), loss = 0.445188
I1211 19:10:34.404989 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:10:34.404989 20404 solver.cpp:237]     Train net output #1: loss = 0.445188 (* 1 = 0.445188 loss)
I1211 19:10:34.404989 20404 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1211 19:10:42.351399 20404 solver.cpp:218] Iteration 22800 (12.5845 iter/s, 7.94628s/100 iters), loss = 0.451171
I1211 19:10:42.351399 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:10:42.351399 20404 solver.cpp:237]     Train net output #1: loss = 0.451171 (* 1 = 0.451171 loss)
I1211 19:10:42.351399 20404 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1211 19:10:50.295120 20404 solver.cpp:218] Iteration 22900 (12.5897 iter/s, 7.94303s/100 iters), loss = 0.364806
I1211 19:10:50.295606 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:10:50.295606 20404 solver.cpp:237]     Train net output #1: loss = 0.364806 (* 1 = 0.364806 loss)
I1211 19:10:50.295606 20404 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1211 19:10:57.851538  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:10:58.165659 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_23000.caffemodel
I1211 19:10:58.218695 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_23000.solverstate
I1211 19:10:58.225698 20404 solver.cpp:330] Iteration 23000, Testing net (#0)
I1211 19:10:58.225698 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:10:59.896682  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:10:59.962715 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7158
I1211 19:10:59.962715 20404 solver.cpp:397]     Test net output #1: loss = 0.905741 (* 1 = 0.905741 loss)
I1211 19:11:00.037734 20404 solver.cpp:218] Iteration 23000 (10.2649 iter/s, 9.7419s/100 iters), loss = 0.424432
I1211 19:11:00.037734 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:11:00.037734 20404 solver.cpp:237]     Train net output #1: loss = 0.424432 (* 1 = 0.424432 loss)
I1211 19:11:00.037734 20404 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1211 19:11:08.002490 20404 solver.cpp:218] Iteration 23100 (12.5566 iter/s, 7.96394s/100 iters), loss = 0.342017
I1211 19:11:08.002490 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:11:08.002490 20404 solver.cpp:237]     Train net output #1: loss = 0.342017 (* 1 = 0.342017 loss)
I1211 19:11:08.002490 20404 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1211 19:11:15.960464 20404 solver.cpp:218] Iteration 23200 (12.5658 iter/s, 7.95813s/100 iters), loss = 0.442293
I1211 19:11:15.960464 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:11:15.960464 20404 solver.cpp:237]     Train net output #1: loss = 0.442293 (* 1 = 0.442293 loss)
I1211 19:11:15.960464 20404 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1211 19:11:23.914495 20404 solver.cpp:218] Iteration 23300 (12.5735 iter/s, 7.95325s/100 iters), loss = 0.517092
I1211 19:11:23.914495 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:11:23.914495 20404 solver.cpp:237]     Train net output #1: loss = 0.517092 (* 1 = 0.517092 loss)
I1211 19:11:23.914995 20404 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1211 19:11:31.863991 20404 solver.cpp:218] Iteration 23400 (12.5795 iter/s, 7.94942s/100 iters), loss = 0.377189
I1211 19:11:31.863991 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:11:31.863991 20404 solver.cpp:237]     Train net output #1: loss = 0.377189 (* 1 = 0.377189 loss)
I1211 19:11:31.863991 20404 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1211 19:11:39.424760  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:11:39.737643 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_23500.caffemodel
I1211 19:11:39.767663 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_23500.solverstate
I1211 19:11:39.773658 20404 solver.cpp:330] Iteration 23500, Testing net (#0)
I1211 19:11:39.773658 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:11:41.448045  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:11:41.515055 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7075
I1211 19:11:41.515055 20404 solver.cpp:397]     Test net output #1: loss = 0.88855 (* 1 = 0.88855 loss)
I1211 19:11:41.588606 20404 solver.cpp:218] Iteration 23500 (10.2841 iter/s, 9.72376s/100 iters), loss = 0.40046
I1211 19:11:41.588606 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:11:41.588606 20404 solver.cpp:237]     Train net output #1: loss = 0.40046 (* 1 = 0.40046 loss)
I1211 19:11:41.588606 20404 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1211 19:11:49.536032 20404 solver.cpp:218] Iteration 23600 (12.584 iter/s, 7.94659s/100 iters), loss = 0.357068
I1211 19:11:49.536032 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:11:49.536032 20404 solver.cpp:237]     Train net output #1: loss = 0.357068 (* 1 = 0.357068 loss)
I1211 19:11:49.536032 20404 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1211 19:11:57.497568 20404 solver.cpp:218] Iteration 23700 (12.5601 iter/s, 7.96172s/100 iters), loss = 0.415749
I1211 19:11:57.497568 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:11:57.497568 20404 solver.cpp:237]     Train net output #1: loss = 0.415749 (* 1 = 0.415749 loss)
I1211 19:11:57.497568 20404 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1211 19:12:05.532302 20404 solver.cpp:218] Iteration 23800 (12.448 iter/s, 8.03339s/100 iters), loss = 0.527032
I1211 19:12:05.532302 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:12:05.532302 20404 solver.cpp:237]     Train net output #1: loss = 0.527032 (* 1 = 0.527032 loss)
I1211 19:12:05.532302 20404 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1211 19:12:13.660869 20404 solver.cpp:218] Iteration 23900 (12.3017 iter/s, 8.12897s/100 iters), loss = 0.454914
I1211 19:12:13.661870 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:12:13.661870 20404 solver.cpp:237]     Train net output #1: loss = 0.454914 (* 1 = 0.454914 loss)
I1211 19:12:13.661870 20404 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1211 19:12:21.428912  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:12:21.763975 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_24000.caffemodel
I1211 19:12:21.809974 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_24000.solverstate
I1211 19:12:21.816977 20404 solver.cpp:330] Iteration 24000, Testing net (#0)
I1211 19:12:21.816977 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:12:23.545012  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:12:23.612013 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7873
I1211 19:12:23.612013 20404 solver.cpp:397]     Test net output #1: loss = 0.630214 (* 1 = 0.630214 loss)
I1211 19:12:23.691025 20404 solver.cpp:218] Iteration 24000 (9.97128 iter/s, 10.0288s/100 iters), loss = 0.432062
I1211 19:12:23.691025 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:12:23.691025 20404 solver.cpp:237]     Train net output #1: loss = 0.432062 (* 1 = 0.432062 loss)
I1211 19:12:23.691025 20404 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1211 19:12:31.735904 20404 solver.cpp:218] Iteration 24100 (12.4304 iter/s, 8.04482s/100 iters), loss = 0.340876
I1211 19:12:31.735904 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:12:31.735904 20404 solver.cpp:237]     Train net output #1: loss = 0.340876 (* 1 = 0.340876 loss)
I1211 19:12:31.735904 20404 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1211 19:12:39.815014 20404 solver.cpp:218] Iteration 24200 (12.3787 iter/s, 8.07838s/100 iters), loss = 0.419451
I1211 19:12:39.815014 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:12:39.815014 20404 solver.cpp:237]     Train net output #1: loss = 0.419451 (* 1 = 0.419451 loss)
I1211 19:12:39.815014 20404 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1211 19:12:47.946626 20404 solver.cpp:218] Iteration 24300 (12.2992 iter/s, 8.13062s/100 iters), loss = 0.428243
I1211 19:12:47.946626 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:12:47.946626 20404 solver.cpp:237]     Train net output #1: loss = 0.428243 (* 1 = 0.428243 loss)
I1211 19:12:47.946626 20404 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1211 19:12:56.099606 20404 solver.cpp:218] Iteration 24400 (12.2661 iter/s, 8.15256s/100 iters), loss = 0.345666
I1211 19:12:56.099606 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:12:56.099606 20404 solver.cpp:237]     Train net output #1: loss = 0.345666 (* 1 = 0.345666 loss)
I1211 19:12:56.099606 20404 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1211 19:13:03.838973  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:13:04.163503 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_24500.caffemodel
I1211 19:13:04.192008 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_24500.solverstate
I1211 19:13:04.198007 20404 solver.cpp:330] Iteration 24500, Testing net (#0)
I1211 19:13:04.198007 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:13:05.910207  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:13:05.978215 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7261
I1211 19:13:05.978215 20404 solver.cpp:397]     Test net output #1: loss = 0.839042 (* 1 = 0.839042 loss)
I1211 19:13:06.055717 20404 solver.cpp:218] Iteration 24500 (10.0445 iter/s, 9.95573s/100 iters), loss = 0.447719
I1211 19:13:06.055717 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:13:06.055717 20404 solver.cpp:237]     Train net output #1: loss = 0.447719 (* 1 = 0.447719 loss)
I1211 19:13:06.055717 20404 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1211 19:13:14.233597 20404 solver.cpp:218] Iteration 24600 (12.2287 iter/s, 8.17745s/100 iters), loss = 0.343785
I1211 19:13:14.233597 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:13:14.233597 20404 solver.cpp:237]     Train net output #1: loss = 0.343785 (* 1 = 0.343785 loss)
I1211 19:13:14.233597 20404 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1211 19:13:22.389932 20404 solver.cpp:218] Iteration 24700 (12.2618 iter/s, 8.15541s/100 iters), loss = 0.49639
I1211 19:13:22.389932 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:13:22.389932 20404 solver.cpp:237]     Train net output #1: loss = 0.49639 (* 1 = 0.49639 loss)
I1211 19:13:22.389932 20404 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1211 19:13:30.530318 20404 solver.cpp:218] Iteration 24800 (12.2841 iter/s, 8.14061s/100 iters), loss = 0.501017
I1211 19:13:30.531323 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:13:30.531323 20404 solver.cpp:237]     Train net output #1: loss = 0.501017 (* 1 = 0.501017 loss)
I1211 19:13:30.531323 20404 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1211 19:13:38.711405 20404 solver.cpp:218] Iteration 24900 (12.225 iter/s, 8.17999s/100 iters), loss = 0.410655
I1211 19:13:38.711405 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:13:38.711405 20404 solver.cpp:237]     Train net output #1: loss = 0.410655 (* 1 = 0.410655 loss)
I1211 19:13:38.711405 20404 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1211 19:13:46.491834  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:13:46.809375 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_25000.caffemodel
I1211 19:13:46.861377 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_25000.solverstate
I1211 19:13:46.868378 20404 solver.cpp:330] Iteration 25000, Testing net (#0)
I1211 19:13:46.868378 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:13:48.560533  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:13:48.628540 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6848
I1211 19:13:48.628540 20404 solver.cpp:397]     Test net output #1: loss = 1.00837 (* 1 = 1.00837 loss)
I1211 19:13:48.705042 20404 solver.cpp:218] Iteration 25000 (10.0073 iter/s, 9.99268s/100 iters), loss = 0.448872
I1211 19:13:48.705042 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:13:48.705042 20404 solver.cpp:237]     Train net output #1: loss = 0.448872 (* 1 = 0.448872 loss)
I1211 19:13:48.705042 20404 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1211 19:13:56.852257 20404 solver.cpp:218] Iteration 25100 (12.2743 iter/s, 8.14709s/100 iters), loss = 0.346297
I1211 19:13:56.852257 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:13:56.852257 20404 solver.cpp:237]     Train net output #1: loss = 0.346297 (* 1 = 0.346297 loss)
I1211 19:13:56.852257 20404 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1211 19:14:04.987061 20404 solver.cpp:218] Iteration 25200 (12.2939 iter/s, 8.13413s/100 iters), loss = 0.427204
I1211 19:14:04.987061 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:14:04.987061 20404 solver.cpp:237]     Train net output #1: loss = 0.427204 (* 1 = 0.427204 loss)
I1211 19:14:04.987061 20404 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1211 19:14:13.129837 20404 solver.cpp:218] Iteration 25300 (12.2813 iter/s, 8.14246s/100 iters), loss = 0.496077
I1211 19:14:13.129837 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:14:13.129837 20404 solver.cpp:237]     Train net output #1: loss = 0.496077 (* 1 = 0.496077 loss)
I1211 19:14:13.129837 20404 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1211 19:14:21.183936 20404 solver.cpp:218] Iteration 25400 (12.4174 iter/s, 8.0532s/100 iters), loss = 0.418028
I1211 19:14:21.183936 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:14:21.183936 20404 solver.cpp:237]     Train net output #1: loss = 0.418028 (* 1 = 0.418028 loss)
I1211 19:14:21.183936 20404 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1211 19:14:28.835561  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:14:29.153594 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_25500.caffemodel
I1211 19:14:29.184610 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_25500.solverstate
I1211 19:14:29.190594 20404 solver.cpp:330] Iteration 25500, Testing net (#0)
I1211 19:14:29.190594 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:14:30.886735  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:14:30.954744 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6498
I1211 19:14:30.954744 20404 solver.cpp:397]     Test net output #1: loss = 1.21949 (* 1 = 1.21949 loss)
I1211 19:14:31.029763 20404 solver.cpp:218] Iteration 25500 (10.1568 iter/s, 9.84561s/100 iters), loss = 0.313851
I1211 19:14:31.029763 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:14:31.029763 20404 solver.cpp:237]     Train net output #1: loss = 0.313851 (* 1 = 0.313851 loss)
I1211 19:14:31.029763 20404 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1211 19:14:39.087319 20404 solver.cpp:218] Iteration 25600 (12.4116 iter/s, 8.05695s/100 iters), loss = 0.366204
I1211 19:14:39.087319 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:14:39.087319 20404 solver.cpp:237]     Train net output #1: loss = 0.366204 (* 1 = 0.366204 loss)
I1211 19:14:39.087319 20404 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1211 19:14:47.127374 20404 solver.cpp:218] Iteration 25700 (12.4387 iter/s, 8.03941s/100 iters), loss = 0.379768
I1211 19:14:47.127874 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:14:47.127874 20404 solver.cpp:237]     Train net output #1: loss = 0.379768 (* 1 = 0.379768 loss)
I1211 19:14:47.127874 20404 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1211 19:14:55.154942 20404 solver.cpp:218] Iteration 25800 (12.458 iter/s, 8.027s/100 iters), loss = 0.373591
I1211 19:14:55.154942 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:14:55.154942 20404 solver.cpp:237]     Train net output #1: loss = 0.373591 (* 1 = 0.373591 loss)
I1211 19:14:55.154942 20404 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1211 19:15:03.136364 20404 solver.cpp:218] Iteration 25900 (12.5305 iter/s, 7.98053s/100 iters), loss = 0.480759
I1211 19:15:03.136364 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:15:03.136364 20404 solver.cpp:237]     Train net output #1: loss = 0.480759 (* 1 = 0.480759 loss)
I1211 19:15:03.136364 20404 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1211 19:15:10.838769  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:15:11.160804 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_26000.caffemodel
I1211 19:15:11.202802 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_26000.solverstate
I1211 19:15:11.208802 20404 solver.cpp:330] Iteration 26000, Testing net (#0)
I1211 19:15:11.208802 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:15:12.906991  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:15:12.972995 20404 solver.cpp:397]     Test net output #0: accuracy = 0.745
I1211 19:15:12.972995 20404 solver.cpp:397]     Test net output #1: loss = 0.774989 (* 1 = 0.774989 loss)
I1211 19:15:13.048014 20404 solver.cpp:218] Iteration 26000 (10.0897 iter/s, 9.91113s/100 iters), loss = 0.391388
I1211 19:15:13.048014 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:15:13.048014 20404 solver.cpp:237]     Train net output #1: loss = 0.391388 (* 1 = 0.391388 loss)
I1211 19:15:13.048014 20404 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1211 19:15:21.147992 20404 solver.cpp:218] Iteration 26100 (12.346 iter/s, 8.09979s/100 iters), loss = 0.450434
I1211 19:15:21.147992 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:15:21.147992 20404 solver.cpp:237]     Train net output #1: loss = 0.450434 (* 1 = 0.450434 loss)
I1211 19:15:21.147992 20404 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1211 19:15:29.258648 20404 solver.cpp:218] Iteration 26200 (12.3308 iter/s, 8.10979s/100 iters), loss = 0.41527
I1211 19:15:29.258648 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:15:29.258648 20404 solver.cpp:237]     Train net output #1: loss = 0.41527 (* 1 = 0.41527 loss)
I1211 19:15:29.258648 20404 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1211 19:15:37.374445 20404 solver.cpp:218] Iteration 26300 (12.3217 iter/s, 8.11579s/100 iters), loss = 0.387334
I1211 19:15:37.374445 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:15:37.374445 20404 solver.cpp:237]     Train net output #1: loss = 0.387334 (* 1 = 0.387334 loss)
I1211 19:15:37.374445 20404 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1211 19:15:45.456928 20404 solver.cpp:218] Iteration 26400 (12.3732 iter/s, 8.08199s/100 iters), loss = 0.412187
I1211 19:15:45.456928 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:15:45.456928 20404 solver.cpp:237]     Train net output #1: loss = 0.412187 (* 1 = 0.412187 loss)
I1211 19:15:45.456928 20404 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1211 19:15:53.154829  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:15:53.469041 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_26500.caffemodel
I1211 19:15:53.495040 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_26500.solverstate
I1211 19:15:53.502027 20404 solver.cpp:330] Iteration 26500, Testing net (#0)
I1211 19:15:53.502027 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:15:55.188352  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:15:55.255408 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6587
I1211 19:15:55.255408 20404 solver.cpp:397]     Test net output #1: loss = 1.07763 (* 1 = 1.07763 loss)
I1211 19:15:55.331385 20404 solver.cpp:218] Iteration 26500 (10.1275 iter/s, 9.87412s/100 iters), loss = 0.373257
I1211 19:15:55.332407 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:15:55.332407 20404 solver.cpp:237]     Train net output #1: loss = 0.373257 (* 1 = 0.373257 loss)
I1211 19:15:55.332407 20404 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1211 19:16:03.422472 20404 solver.cpp:218] Iteration 26600 (12.3615 iter/s, 8.08965s/100 iters), loss = 0.353094
I1211 19:16:03.422472 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:16:03.422472 20404 solver.cpp:237]     Train net output #1: loss = 0.353094 (* 1 = 0.353094 loss)
I1211 19:16:03.422472 20404 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1211 19:16:11.532502 20404 solver.cpp:218] Iteration 26700 (12.3297 iter/s, 8.11047s/100 iters), loss = 0.50113
I1211 19:16:11.533502 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:16:11.533502 20404 solver.cpp:237]     Train net output #1: loss = 0.50113 (* 1 = 0.50113 loss)
I1211 19:16:11.533502 20404 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1211 19:16:19.641414 20404 solver.cpp:218] Iteration 26800 (12.3339 iter/s, 8.10776s/100 iters), loss = 0.456692
I1211 19:16:19.641414 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 19:16:19.641414 20404 solver.cpp:237]     Train net output #1: loss = 0.456692 (* 1 = 0.456692 loss)
I1211 19:16:19.641414 20404 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1211 19:16:27.744727 20404 solver.cpp:218] Iteration 26900 (12.3407 iter/s, 8.10326s/100 iters), loss = 0.429277
I1211 19:16:27.744727 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:16:27.744727 20404 solver.cpp:237]     Train net output #1: loss = 0.429277 (* 1 = 0.429277 loss)
I1211 19:16:27.744727 20404 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1211 19:16:35.459998  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:16:35.784557 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_27000.caffemodel
I1211 19:16:35.832556 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_27000.solverstate
I1211 19:16:35.838557 20404 solver.cpp:330] Iteration 27000, Testing net (#0)
I1211 19:16:35.838557 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:16:37.543745  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:16:37.611749 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7177
I1211 19:16:37.611749 20404 solver.cpp:397]     Test net output #1: loss = 0.870798 (* 1 = 0.870798 loss)
I1211 19:16:37.688756 20404 solver.cpp:218] Iteration 27000 (10.0569 iter/s, 9.94345s/100 iters), loss = 0.388166
I1211 19:16:37.689762 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:16:37.689762 20404 solver.cpp:237]     Train net output #1: loss = 0.388166 (* 1 = 0.388166 loss)
I1211 19:16:37.689762 20404 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1211 19:16:45.772905 20404 solver.cpp:218] Iteration 27100 (12.371 iter/s, 8.08343s/100 iters), loss = 0.292331
I1211 19:16:45.772905 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:16:45.772905 20404 solver.cpp:237]     Train net output #1: loss = 0.292331 (* 1 = 0.292331 loss)
I1211 19:16:45.772905 20404 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1211 19:16:53.841316 20404 solver.cpp:218] Iteration 27200 (12.396 iter/s, 8.06709s/100 iters), loss = 0.423378
I1211 19:16:53.841316 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:16:53.841316 20404 solver.cpp:237]     Train net output #1: loss = 0.423378 (* 1 = 0.423378 loss)
I1211 19:16:53.841316 20404 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1211 19:17:01.977938 20404 solver.cpp:218] Iteration 27300 (12.2899 iter/s, 8.13675s/100 iters), loss = 0.444768
I1211 19:17:01.977938 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:17:01.977938 20404 solver.cpp:237]     Train net output #1: loss = 0.444769 (* 1 = 0.444769 loss)
I1211 19:17:01.977938 20404 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1211 19:17:10.057842 20404 solver.cpp:218] Iteration 27400 (12.3769 iter/s, 8.07958s/100 iters), loss = 0.416228
I1211 19:17:10.057842 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:17:10.057842 20404 solver.cpp:237]     Train net output #1: loss = 0.416228 (* 1 = 0.416228 loss)
I1211 19:17:10.057842 20404 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1211 19:17:17.783591  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:17:18.103615 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_27500.caffemodel
I1211 19:17:18.131615 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_27500.solverstate
I1211 19:17:18.137616 20404 solver.cpp:330] Iteration 27500, Testing net (#0)
I1211 19:17:18.138617 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:17:19.842778  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:17:19.910784 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7565
I1211 19:17:19.910784 20404 solver.cpp:397]     Test net output #1: loss = 0.673701 (* 1 = 0.673701 loss)
I1211 19:17:19.986788 20404 solver.cpp:218] Iteration 27500 (10.0725 iter/s, 9.92805s/100 iters), loss = 0.430584
I1211 19:17:19.986788 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:17:19.986788 20404 solver.cpp:237]     Train net output #1: loss = 0.430584 (* 1 = 0.430584 loss)
I1211 19:17:19.986788 20404 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1211 19:17:28.098424 20404 solver.cpp:218] Iteration 27600 (12.3289 iter/s, 8.11103s/100 iters), loss = 0.354682
I1211 19:17:28.098424 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:17:28.098424 20404 solver.cpp:237]     Train net output #1: loss = 0.354682 (* 1 = 0.354682 loss)
I1211 19:17:28.098424 20404 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1211 19:17:36.181651 20404 solver.cpp:218] Iteration 27700 (12.3726 iter/s, 8.08239s/100 iters), loss = 0.405529
I1211 19:17:36.181651 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:17:36.181651 20404 solver.cpp:237]     Train net output #1: loss = 0.405529 (* 1 = 0.405529 loss)
I1211 19:17:36.181651 20404 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1211 19:17:44.226542 20404 solver.cpp:218] Iteration 27800 (12.4307 iter/s, 8.04463s/100 iters), loss = 0.446806
I1211 19:17:44.226542 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:17:44.226542 20404 solver.cpp:237]     Train net output #1: loss = 0.446806 (* 1 = 0.446806 loss)
I1211 19:17:44.226542 20404 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1211 19:17:52.373368 20404 solver.cpp:218] Iteration 27900 (12.2757 iter/s, 8.14619s/100 iters), loss = 0.359217
I1211 19:17:52.373368 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:17:52.373368 20404 solver.cpp:237]     Train net output #1: loss = 0.359217 (* 1 = 0.359217 loss)
I1211 19:17:52.373368 20404 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1211 19:18:00.088515  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:18:00.410542 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_28000.caffemodel
I1211 19:18:00.468546 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_28000.solverstate
I1211 19:18:00.474551 20404 solver.cpp:330] Iteration 28000, Testing net (#0)
I1211 19:18:00.474551 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:18:02.176503  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:18:02.244514 20404 solver.cpp:397]     Test net output #0: accuracy = 0.783
I1211 19:18:02.244514 20404 solver.cpp:397]     Test net output #1: loss = 0.651013 (* 1 = 0.651013 loss)
I1211 19:18:02.319012 20404 solver.cpp:218] Iteration 28000 (10.0546 iter/s, 9.94566s/100 iters), loss = 0.474718
I1211 19:18:02.319012 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 19:18:02.320013 20404 solver.cpp:237]     Train net output #1: loss = 0.474718 (* 1 = 0.474718 loss)
I1211 19:18:02.320013 20404 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1211 19:18:10.415850 20404 solver.cpp:218] Iteration 28100 (12.3516 iter/s, 8.0961s/100 iters), loss = 0.440979
I1211 19:18:10.415850 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 19:18:10.415850 20404 solver.cpp:237]     Train net output #1: loss = 0.440979 (* 1 = 0.440979 loss)
I1211 19:18:10.415850 20404 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1211 19:18:18.476049 20404 solver.cpp:218] Iteration 28200 (12.4082 iter/s, 8.0592s/100 iters), loss = 0.394519
I1211 19:18:18.476049 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:18:18.476049 20404 solver.cpp:237]     Train net output #1: loss = 0.394519 (* 1 = 0.394519 loss)
I1211 19:18:18.476049 20404 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1211 19:18:26.520929 20404 solver.cpp:218] Iteration 28300 (12.4311 iter/s, 8.04434s/100 iters), loss = 0.438548
I1211 19:18:26.520929 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:18:26.520929 20404 solver.cpp:237]     Train net output #1: loss = 0.438548 (* 1 = 0.438548 loss)
I1211 19:18:26.520929 20404 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1211 19:18:34.542698 20404 solver.cpp:218] Iteration 28400 (12.4664 iter/s, 8.02156s/100 iters), loss = 0.303532
I1211 19:18:34.542698 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:18:34.542698 20404 solver.cpp:237]     Train net output #1: loss = 0.303532 (* 1 = 0.303532 loss)
I1211 19:18:34.542698 20404 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1211 19:18:42.114414  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:18:42.432703 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_28500.caffemodel
I1211 19:18:42.465204 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_28500.solverstate
I1211 19:18:42.470724 20404 solver.cpp:330] Iteration 28500, Testing net (#0)
I1211 19:18:42.470724 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:18:44.148046  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:18:44.214063 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6808
I1211 19:18:44.214063 20404 solver.cpp:397]     Test net output #1: loss = 0.980375 (* 1 = 0.980375 loss)
I1211 19:18:44.288782 20404 solver.cpp:218] Iteration 28500 (10.2615 iter/s, 9.74513s/100 iters), loss = 0.419718
I1211 19:18:44.288782 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:18:44.288782 20404 solver.cpp:237]     Train net output #1: loss = 0.419719 (* 1 = 0.419719 loss)
I1211 19:18:44.288782 20404 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1211 19:18:52.241363 20404 solver.cpp:218] Iteration 28600 (12.5755 iter/s, 7.95199s/100 iters), loss = 0.395474
I1211 19:18:52.241363 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:18:52.241363 20404 solver.cpp:237]     Train net output #1: loss = 0.395474 (* 1 = 0.395474 loss)
I1211 19:18:52.241363 20404 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1211 19:19:00.185166 20404 solver.cpp:218] Iteration 28700 (12.588 iter/s, 7.94406s/100 iters), loss = 0.436801
I1211 19:19:00.185166 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:19:00.185166 20404 solver.cpp:237]     Train net output #1: loss = 0.436801 (* 1 = 0.436801 loss)
I1211 19:19:00.185166 20404 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1211 19:19:08.139341 20404 solver.cpp:218] Iteration 28800 (12.5738 iter/s, 7.95302s/100 iters), loss = 0.48672
I1211 19:19:08.139341 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:19:08.139341 20404 solver.cpp:237]     Train net output #1: loss = 0.48672 (* 1 = 0.48672 loss)
I1211 19:19:08.139341 20404 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1211 19:19:16.096873 20404 solver.cpp:218] Iteration 28900 (12.5675 iter/s, 7.95703s/100 iters), loss = 0.294062
I1211 19:19:16.096873 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:19:16.096873 20404 solver.cpp:237]     Train net output #1: loss = 0.294062 (* 1 = 0.294062 loss)
I1211 19:19:16.096873 20404 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1211 19:19:23.667295  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:19:23.981822 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_29000.caffemodel
I1211 19:19:24.052836 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_29000.solverstate
I1211 19:19:24.058840 20404 solver.cpp:330] Iteration 29000, Testing net (#0)
I1211 19:19:24.058840 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:19:25.731241  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:19:25.797396 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6642
I1211 19:19:25.797396 20404 solver.cpp:397]     Test net output #1: loss = 1.04408 (* 1 = 1.04408 loss)
I1211 19:19:25.872411 20404 solver.cpp:218] Iteration 29000 (10.23 iter/s, 9.77518s/100 iters), loss = 0.395351
I1211 19:19:25.872411 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:19:25.872411 20404 solver.cpp:237]     Train net output #1: loss = 0.395351 (* 1 = 0.395351 loss)
I1211 19:19:25.872411 20404 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1211 19:19:33.808434 20404 solver.cpp:218] Iteration 29100 (12.6022 iter/s, 7.93514s/100 iters), loss = 0.359129
I1211 19:19:33.808434 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:19:33.808434 20404 solver.cpp:237]     Train net output #1: loss = 0.359129 (* 1 = 0.359129 loss)
I1211 19:19:33.808434 20404 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1211 19:19:41.752310 20404 solver.cpp:218] Iteration 29200 (12.5878 iter/s, 7.9442s/100 iters), loss = 0.510392
I1211 19:19:41.752310 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:19:41.752310 20404 solver.cpp:237]     Train net output #1: loss = 0.510392 (* 1 = 0.510392 loss)
I1211 19:19:41.752310 20404 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1211 19:19:49.693222 20404 solver.cpp:218] Iteration 29300 (12.5951 iter/s, 7.9396s/100 iters), loss = 0.529576
I1211 19:19:49.693222 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 19:19:49.693222 20404 solver.cpp:237]     Train net output #1: loss = 0.529576 (* 1 = 0.529576 loss)
I1211 19:19:49.693222 20404 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1211 19:19:57.634912 20404 solver.cpp:218] Iteration 29400 (12.5918 iter/s, 7.94168s/100 iters), loss = 0.373731
I1211 19:19:57.634912 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:19:57.634912 20404 solver.cpp:237]     Train net output #1: loss = 0.373731 (* 1 = 0.373731 loss)
I1211 19:19:57.634912 20404 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1211 19:20:05.270752  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:20:05.585383 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_29500.caffemodel
I1211 19:20:05.614912 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_29500.solverstate
I1211 19:20:05.661432 20404 solver.cpp:330] Iteration 29500, Testing net (#0)
I1211 19:20:05.661432 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:20:07.332296  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:20:07.398301 20404 solver.cpp:397]     Test net output #0: accuracy = 0.706
I1211 19:20:07.399300 20404 solver.cpp:397]     Test net output #1: loss = 0.924489 (* 1 = 0.924489 loss)
I1211 19:20:07.473311 20404 solver.cpp:218] Iteration 29500 (10.1648 iter/s, 9.83787s/100 iters), loss = 0.381437
I1211 19:20:07.473311 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:20:07.473311 20404 solver.cpp:237]     Train net output #1: loss = 0.381437 (* 1 = 0.381437 loss)
I1211 19:20:07.473311 20404 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1211 19:20:15.420053 20404 solver.cpp:218] Iteration 29600 (12.5847 iter/s, 7.94618s/100 iters), loss = 0.338732
I1211 19:20:15.420053 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:20:15.420053 20404 solver.cpp:237]     Train net output #1: loss = 0.338732 (* 1 = 0.338732 loss)
I1211 19:20:15.420053 20404 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1211 19:20:23.365962 20404 solver.cpp:218] Iteration 29700 (12.5853 iter/s, 7.94576s/100 iters), loss = 0.385789
I1211 19:20:23.365962 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:20:23.365962 20404 solver.cpp:237]     Train net output #1: loss = 0.385789 (* 1 = 0.385789 loss)
I1211 19:20:23.365962 20404 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1211 19:20:31.312911 20404 solver.cpp:218] Iteration 29800 (12.5848 iter/s, 7.94609s/100 iters), loss = 0.456369
I1211 19:20:31.312911 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:20:31.312911 20404 solver.cpp:237]     Train net output #1: loss = 0.456369 (* 1 = 0.456369 loss)
I1211 19:20:31.312911 20404 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1211 19:20:39.260857 20404 solver.cpp:218] Iteration 29900 (12.5828 iter/s, 7.94736s/100 iters), loss = 0.31151
I1211 19:20:39.260857 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:20:39.260857 20404 solver.cpp:237]     Train net output #1: loss = 0.31151 (* 1 = 0.31151 loss)
I1211 19:20:39.260857 20404 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1211 19:20:46.815405  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:20:47.129926 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_30000.caffemodel
I1211 19:20:47.156347 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_30000.solverstate
I1211 19:20:47.163350 20404 solver.cpp:330] Iteration 30000, Testing net (#0)
I1211 19:20:47.163350 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:20:48.835588  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:20:48.900693 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7747
I1211 19:20:48.900693 20404 solver.cpp:397]     Test net output #1: loss = 0.65851 (* 1 = 0.65851 loss)
I1211 19:20:48.975787 20404 solver.cpp:218] Iteration 30000 (10.2935 iter/s, 9.71484s/100 iters), loss = 0.411987
I1211 19:20:48.975787 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:20:48.975787 20404 solver.cpp:237]     Train net output #1: loss = 0.411987 (* 1 = 0.411987 loss)
I1211 19:20:48.975787 20404 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1211 19:20:56.919801 20404 solver.cpp:218] Iteration 30100 (12.5892 iter/s, 7.94332s/100 iters), loss = 0.363335
I1211 19:20:56.919801 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:20:56.919801 20404 solver.cpp:237]     Train net output #1: loss = 0.363335 (* 1 = 0.363335 loss)
I1211 19:20:56.919801 20404 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1211 19:21:04.877549 20404 solver.cpp:218] Iteration 30200 (12.5667 iter/s, 7.95753s/100 iters), loss = 0.402414
I1211 19:21:04.877549 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:21:04.877549 20404 solver.cpp:237]     Train net output #1: loss = 0.402414 (* 1 = 0.402414 loss)
I1211 19:21:04.877549 20404 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1211 19:21:12.833477 20404 solver.cpp:218] Iteration 30300 (12.5709 iter/s, 7.95485s/100 iters), loss = 0.429972
I1211 19:21:12.833477 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:21:12.833477 20404 solver.cpp:237]     Train net output #1: loss = 0.429972 (* 1 = 0.429972 loss)
I1211 19:21:12.833477 20404 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1211 19:21:20.784603 20404 solver.cpp:218] Iteration 30400 (12.5779 iter/s, 7.95047s/100 iters), loss = 0.376922
I1211 19:21:20.784603 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:21:20.784603 20404 solver.cpp:237]     Train net output #1: loss = 0.376922 (* 1 = 0.376922 loss)
I1211 19:21:20.784603 20404 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1211 19:21:28.346434  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:21:28.661478 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_30500.caffemodel
I1211 19:21:28.689478 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_30500.solverstate
I1211 19:21:28.736553 20404 solver.cpp:330] Iteration 30500, Testing net (#0)
I1211 19:21:28.736553 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:21:30.407630  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:21:30.474162 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6349
I1211 19:21:30.474162 20404 solver.cpp:397]     Test net output #1: loss = 1.13066 (* 1 = 1.13066 loss)
I1211 19:21:30.548880 20404 solver.cpp:218] Iteration 30500 (10.242 iter/s, 9.76373s/100 iters), loss = 0.447
I1211 19:21:30.548880 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:21:30.548880 20404 solver.cpp:237]     Train net output #1: loss = 0.447 (* 1 = 0.447 loss)
I1211 19:21:30.548880 20404 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1211 19:21:38.496896 20404 solver.cpp:218] Iteration 30600 (12.581 iter/s, 7.94851s/100 iters), loss = 0.385935
I1211 19:21:38.497895 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:21:38.497895 20404 solver.cpp:237]     Train net output #1: loss = 0.385935 (* 1 = 0.385935 loss)
I1211 19:21:38.497895 20404 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1211 19:21:46.448846 20404 solver.cpp:218] Iteration 30700 (12.5776 iter/s, 7.95063s/100 iters), loss = 0.368498
I1211 19:21:46.448846 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:21:46.448846 20404 solver.cpp:237]     Train net output #1: loss = 0.368498 (* 1 = 0.368498 loss)
I1211 19:21:46.448846 20404 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1211 19:21:54.397655 20404 solver.cpp:218] Iteration 30800 (12.5815 iter/s, 7.94816s/100 iters), loss = 0.418431
I1211 19:21:54.397655 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:21:54.397655 20404 solver.cpp:237]     Train net output #1: loss = 0.418431 (* 1 = 0.418431 loss)
I1211 19:21:54.397655 20404 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1211 19:22:02.344000 20404 solver.cpp:218] Iteration 30900 (12.5845 iter/s, 7.94626s/100 iters), loss = 0.295837
I1211 19:22:02.344000 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:22:02.344000 20404 solver.cpp:237]     Train net output #1: loss = 0.295837 (* 1 = 0.295837 loss)
I1211 19:22:02.344000 20404 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1211 19:22:09.908252  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:22:10.224295 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_31000.caffemodel
I1211 19:22:10.255303 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_31000.solverstate
I1211 19:22:10.260303 20404 solver.cpp:330] Iteration 31000, Testing net (#0)
I1211 19:22:10.261303 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:22:11.933959  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:22:12.000468 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7106
I1211 19:22:12.000468 20404 solver.cpp:397]     Test net output #1: loss = 0.892278 (* 1 = 0.892278 loss)
I1211 19:22:12.074458 20404 solver.cpp:218] Iteration 31000 (10.2776 iter/s, 9.72989s/100 iters), loss = 0.397618
I1211 19:22:12.074458 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:22:12.074458 20404 solver.cpp:237]     Train net output #1: loss = 0.397618 (* 1 = 0.397618 loss)
I1211 19:22:12.074959 20404 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1211 19:22:20.054208 20404 solver.cpp:218] Iteration 31100 (12.5323 iter/s, 7.97935s/100 iters), loss = 0.346532
I1211 19:22:20.054208 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:22:20.054208 20404 solver.cpp:237]     Train net output #1: loss = 0.346532 (* 1 = 0.346532 loss)
I1211 19:22:20.054208 20404 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1211 19:22:27.997076 20404 solver.cpp:218] Iteration 31200 (12.5901 iter/s, 7.94274s/100 iters), loss = 0.432537
I1211 19:22:27.997076 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:22:27.997076 20404 solver.cpp:237]     Train net output #1: loss = 0.432537 (* 1 = 0.432537 loss)
I1211 19:22:27.997076 20404 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1211 19:22:35.946460 20404 solver.cpp:218] Iteration 31300 (12.5813 iter/s, 7.94829s/100 iters), loss = 0.490144
I1211 19:22:35.946460 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:22:35.946460 20404 solver.cpp:237]     Train net output #1: loss = 0.490144 (* 1 = 0.490144 loss)
I1211 19:22:35.946460 20404 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1211 19:22:43.891196 20404 solver.cpp:218] Iteration 31400 (12.5878 iter/s, 7.9442s/100 iters), loss = 0.414107
I1211 19:22:43.891196 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:22:43.891196 20404 solver.cpp:237]     Train net output #1: loss = 0.414107 (* 1 = 0.414107 loss)
I1211 19:22:43.891196 20404 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1211 19:22:51.443482  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:22:51.757596 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_31500.caffemodel
I1211 19:22:51.798596 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_31500.solverstate
I1211 19:22:51.818596 20404 solver.cpp:330] Iteration 31500, Testing net (#0)
I1211 19:22:51.819597 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:22:53.489946  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:22:53.556486 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6258
I1211 19:22:53.557484 20404 solver.cpp:397]     Test net output #1: loss = 1.34017 (* 1 = 1.34017 loss)
I1211 19:22:53.631983 20404 solver.cpp:218] Iteration 31500 (10.2669 iter/s, 9.74008s/100 iters), loss = 0.350004
I1211 19:22:53.631983 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:22:53.631983 20404 solver.cpp:237]     Train net output #1: loss = 0.350004 (* 1 = 0.350004 loss)
I1211 19:22:53.631983 20404 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1211 19:23:01.577026 20404 solver.cpp:218] Iteration 31600 (12.5866 iter/s, 7.94494s/100 iters), loss = 0.404349
I1211 19:23:01.577026 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:23:01.577026 20404 solver.cpp:237]     Train net output #1: loss = 0.404349 (* 1 = 0.404349 loss)
I1211 19:23:01.577026 20404 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1211 19:23:09.531194 20404 solver.cpp:218] Iteration 31700 (12.5738 iter/s, 7.95303s/100 iters), loss = 0.420919
I1211 19:23:09.531194 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:23:09.531194 20404 solver.cpp:237]     Train net output #1: loss = 0.420919 (* 1 = 0.420919 loss)
I1211 19:23:09.531194 20404 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1211 19:23:17.482267 20404 solver.cpp:218] Iteration 31800 (12.5765 iter/s, 7.95136s/100 iters), loss = 0.404472
I1211 19:23:17.482267 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:23:17.482267 20404 solver.cpp:237]     Train net output #1: loss = 0.404472 (* 1 = 0.404472 loss)
I1211 19:23:17.482267 20404 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1211 19:23:25.429088 20404 solver.cpp:218] Iteration 31900 (12.5855 iter/s, 7.94563s/100 iters), loss = 0.304913
I1211 19:23:25.429088 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:23:25.429088 20404 solver.cpp:237]     Train net output #1: loss = 0.304913 (* 1 = 0.304913 loss)
I1211 19:23:25.429088 20404 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1211 19:23:32.983434  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:23:33.297451 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_32000.caffemodel
I1211 19:23:33.325451 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_32000.solverstate
I1211 19:23:33.331451 20404 solver.cpp:330] Iteration 32000, Testing net (#0)
I1211 19:23:33.332453 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:23:35.001688  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:23:35.067690 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7655
I1211 19:23:35.067690 20404 solver.cpp:397]     Test net output #1: loss = 0.684835 (* 1 = 0.684835 loss)
I1211 19:23:35.142192 20404 solver.cpp:218] Iteration 32000 (10.296 iter/s, 9.71255s/100 iters), loss = 0.371495
I1211 19:23:35.142192 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:23:35.142192 20404 solver.cpp:237]     Train net output #1: loss = 0.371495 (* 1 = 0.371495 loss)
I1211 19:23:35.142192 20404 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1211 19:23:43.092114 20404 solver.cpp:218] Iteration 32100 (12.5791 iter/s, 7.94971s/100 iters), loss = 0.361308
I1211 19:23:43.092114 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:23:43.092114 20404 solver.cpp:237]     Train net output #1: loss = 0.361308 (* 1 = 0.361308 loss)
I1211 19:23:43.092114 20404 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1211 19:23:51.045719 20404 solver.cpp:218] Iteration 32200 (12.5739 iter/s, 7.95297s/100 iters), loss = 0.430324
I1211 19:23:51.045719 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:23:51.045719 20404 solver.cpp:237]     Train net output #1: loss = 0.430324 (* 1 = 0.430324 loss)
I1211 19:23:51.045719 20404 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1211 19:23:59.000588 20404 solver.cpp:218] Iteration 32300 (12.5716 iter/s, 7.95446s/100 iters), loss = 0.461666
I1211 19:23:59.000588 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:23:59.000588 20404 solver.cpp:237]     Train net output #1: loss = 0.461666 (* 1 = 0.461666 loss)
I1211 19:23:59.000588 20404 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1211 19:24:06.945246 20404 solver.cpp:218] Iteration 32400 (12.5879 iter/s, 7.94414s/100 iters), loss = 0.420378
I1211 19:24:06.945246 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:24:06.945246 20404 solver.cpp:237]     Train net output #1: loss = 0.420378 (* 1 = 0.420378 loss)
I1211 19:24:06.945246 20404 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1211 19:24:14.508815  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:24:14.823849 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_32500.caffemodel
I1211 19:24:14.850850 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_32500.solverstate
I1211 19:24:14.884851 20404 solver.cpp:330] Iteration 32500, Testing net (#0)
I1211 19:24:14.884851 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:24:16.558084  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:24:16.625098 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6714
I1211 19:24:16.625098 20404 solver.cpp:397]     Test net output #1: loss = 1.0952 (* 1 = 1.0952 loss)
I1211 19:24:16.700096 20404 solver.cpp:218] Iteration 32500 (10.2521 iter/s, 9.75406s/100 iters), loss = 0.350276
I1211 19:24:16.700096 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:24:16.700096 20404 solver.cpp:237]     Train net output #1: loss = 0.350276 (* 1 = 0.350276 loss)
I1211 19:24:16.700096 20404 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1211 19:24:24.658411 20404 solver.cpp:218] Iteration 32600 (12.5662 iter/s, 7.95788s/100 iters), loss = 0.379976
I1211 19:24:24.658411 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:24:24.658411 20404 solver.cpp:237]     Train net output #1: loss = 0.379976 (* 1 = 0.379976 loss)
I1211 19:24:24.658411 20404 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1211 19:24:32.611462 20404 solver.cpp:218] Iteration 32700 (12.574 iter/s, 7.95289s/100 iters), loss = 0.458537
I1211 19:24:32.611948 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:24:32.611948 20404 solver.cpp:237]     Train net output #1: loss = 0.458537 (* 1 = 0.458537 loss)
I1211 19:24:32.611948 20404 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1211 19:24:40.556030 20404 solver.cpp:218] Iteration 32800 (12.5883 iter/s, 7.94389s/100 iters), loss = 0.504475
I1211 19:24:40.556030 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:24:40.556030 20404 solver.cpp:237]     Train net output #1: loss = 0.504475 (* 1 = 0.504475 loss)
I1211 19:24:40.556030 20404 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1211 19:24:48.502670 20404 solver.cpp:218] Iteration 32900 (12.5839 iter/s, 7.94668s/100 iters), loss = 0.367108
I1211 19:24:48.502670 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:24:48.502670 20404 solver.cpp:237]     Train net output #1: loss = 0.367108 (* 1 = 0.367108 loss)
I1211 19:24:48.502670 20404 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1211 19:24:56.059769  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:24:56.374759 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_33000.caffemodel
I1211 19:24:56.403759 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_33000.solverstate
I1211 19:24:56.409293 20404 solver.cpp:330] Iteration 33000, Testing net (#0)
I1211 19:24:56.409780 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:24:58.081953  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:24:58.148571 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7592
I1211 19:24:58.148571 20404 solver.cpp:397]     Test net output #1: loss = 0.724716 (* 1 = 0.724716 loss)
I1211 19:24:58.223570 20404 solver.cpp:218] Iteration 33000 (10.2883 iter/s, 9.71976s/100 iters), loss = 0.454537
I1211 19:24:58.223570 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:24:58.223570 20404 solver.cpp:237]     Train net output #1: loss = 0.454537 (* 1 = 0.454537 loss)
I1211 19:24:58.223570 20404 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1211 19:25:06.173621 20404 solver.cpp:218] Iteration 33100 (12.5789 iter/s, 7.94981s/100 iters), loss = 0.25518
I1211 19:25:06.173621 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:25:06.173621 20404 solver.cpp:237]     Train net output #1: loss = 0.25518 (* 1 = 0.25518 loss)
I1211 19:25:06.173621 20404 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1211 19:25:14.120906 20404 solver.cpp:218] Iteration 33200 (12.5843 iter/s, 7.94639s/100 iters), loss = 0.39678
I1211 19:25:14.120906 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:25:14.120906 20404 solver.cpp:237]     Train net output #1: loss = 0.39678 (* 1 = 0.39678 loss)
I1211 19:25:14.120906 20404 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1211 19:25:22.066818 20404 solver.cpp:218] Iteration 33300 (12.5846 iter/s, 7.94621s/100 iters), loss = 0.525934
I1211 19:25:22.066818 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I1211 19:25:22.067817 20404 solver.cpp:237]     Train net output #1: loss = 0.525934 (* 1 = 0.525934 loss)
I1211 19:25:22.067817 20404 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1211 19:25:30.023428 20404 solver.cpp:218] Iteration 33400 (12.569 iter/s, 7.95605s/100 iters), loss = 0.30946
I1211 19:25:30.023428 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:25:30.023428 20404 solver.cpp:237]     Train net output #1: loss = 0.30946 (* 1 = 0.30946 loss)
I1211 19:25:30.023428 20404 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1211 19:25:37.590219  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:25:37.902242 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_33500.caffemodel
I1211 19:25:37.929745 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_33500.solverstate
I1211 19:25:37.935746 20404 solver.cpp:330] Iteration 33500, Testing net (#0)
I1211 19:25:37.936246 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:25:39.606396  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:25:39.673403 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7435
I1211 19:25:39.673403 20404 solver.cpp:397]     Test net output #1: loss = 0.786397 (* 1 = 0.786397 loss)
I1211 19:25:39.747407 20404 solver.cpp:218] Iteration 33500 (10.2843 iter/s, 9.72354s/100 iters), loss = 0.425096
I1211 19:25:39.748407 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:25:39.748407 20404 solver.cpp:237]     Train net output #1: loss = 0.425096 (* 1 = 0.425096 loss)
I1211 19:25:39.748407 20404 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1211 19:25:47.691223 20404 solver.cpp:218] Iteration 33600 (12.5896 iter/s, 7.94309s/100 iters), loss = 0.415182
I1211 19:25:47.691223 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:25:47.691223 20404 solver.cpp:237]     Train net output #1: loss = 0.415182 (* 1 = 0.415182 loss)
I1211 19:25:47.691223 20404 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1211 19:25:55.636309 20404 solver.cpp:218] Iteration 33700 (12.5882 iter/s, 7.94393s/100 iters), loss = 0.468011
I1211 19:25:55.636309 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:25:55.636309 20404 solver.cpp:237]     Train net output #1: loss = 0.468011 (* 1 = 0.468011 loss)
I1211 19:25:55.636309 20404 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1211 19:26:03.587744 20404 solver.cpp:218] Iteration 33800 (12.5762 iter/s, 7.95156s/100 iters), loss = 0.453929
I1211 19:26:03.587744 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:26:03.587744 20404 solver.cpp:237]     Train net output #1: loss = 0.453929 (* 1 = 0.453929 loss)
I1211 19:26:03.587744 20404 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1211 19:26:11.540205 20404 solver.cpp:218] Iteration 33900 (12.5764 iter/s, 7.95142s/100 iters), loss = 0.484402
I1211 19:26:11.540205 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:26:11.540205 20404 solver.cpp:237]     Train net output #1: loss = 0.484402 (* 1 = 0.484402 loss)
I1211 19:26:11.540205 20404 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1211 19:26:19.092810  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:26:19.408828 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_34000.caffemodel
I1211 19:26:19.435828 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_34000.solverstate
I1211 19:26:19.441829 20404 solver.cpp:330] Iteration 34000, Testing net (#0)
I1211 19:26:19.441829 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:26:21.111063  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:26:21.178076 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8029
I1211 19:26:21.178076 20404 solver.cpp:397]     Test net output #1: loss = 0.576138 (* 1 = 0.576138 loss)
I1211 19:26:21.252578 20404 solver.cpp:218] Iteration 34000 (10.2965 iter/s, 9.71205s/100 iters), loss = 0.367233
I1211 19:26:21.252578 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:26:21.252578 20404 solver.cpp:237]     Train net output #1: loss = 0.367233 (* 1 = 0.367233 loss)
I1211 19:26:21.252578 20404 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1211 19:26:29.202853 20404 solver.cpp:218] Iteration 34100 (12.5792 iter/s, 7.94961s/100 iters), loss = 0.390218
I1211 19:26:29.202853 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:26:29.202853 20404 solver.cpp:237]     Train net output #1: loss = 0.390218 (* 1 = 0.390218 loss)
I1211 19:26:29.202853 20404 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1211 19:26:37.143693 20404 solver.cpp:218] Iteration 34200 (12.5934 iter/s, 7.94065s/100 iters), loss = 0.487548
I1211 19:26:37.143693 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 19:26:37.143693 20404 solver.cpp:237]     Train net output #1: loss = 0.487548 (* 1 = 0.487548 loss)
I1211 19:26:37.143693 20404 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1211 19:26:45.086925 20404 solver.cpp:218] Iteration 34300 (12.5894 iter/s, 7.94318s/100 iters), loss = 0.475233
I1211 19:26:45.087925 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:26:45.087925 20404 solver.cpp:237]     Train net output #1: loss = 0.475234 (* 1 = 0.475234 loss)
I1211 19:26:45.087925 20404 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1211 19:26:53.041921 20404 solver.cpp:218] Iteration 34400 (12.5724 iter/s, 7.95395s/100 iters), loss = 0.366102
I1211 19:26:53.041921 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:26:53.041921 20404 solver.cpp:237]     Train net output #1: loss = 0.366102 (* 1 = 0.366102 loss)
I1211 19:26:53.041921 20404 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1211 19:27:00.604748  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:27:00.917783 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_34500.caffemodel
I1211 19:27:00.946796 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_34500.solverstate
I1211 19:27:00.952796 20404 solver.cpp:330] Iteration 34500, Testing net (#0)
I1211 19:27:00.952796 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:27:02.622987  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:27:02.690006 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7626
I1211 19:27:02.690006 20404 solver.cpp:397]     Test net output #1: loss = 0.711992 (* 1 = 0.711992 loss)
I1211 19:27:02.764508 20404 solver.cpp:218] Iteration 34500 (10.2858 iter/s, 9.72216s/100 iters), loss = 0.382134
I1211 19:27:02.765007 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:27:02.765007 20404 solver.cpp:237]     Train net output #1: loss = 0.382134 (* 1 = 0.382134 loss)
I1211 19:27:02.765007 20404 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1211 19:27:10.709198 20404 solver.cpp:218] Iteration 34600 (12.5873 iter/s, 7.94453s/100 iters), loss = 0.30775
I1211 19:27:10.709198 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:27:10.709198 20404 solver.cpp:237]     Train net output #1: loss = 0.30775 (* 1 = 0.30775 loss)
I1211 19:27:10.709198 20404 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1211 19:27:18.655073 20404 solver.cpp:218] Iteration 34700 (12.5866 iter/s, 7.94497s/100 iters), loss = 0.442718
I1211 19:27:18.655073 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:27:18.655073 20404 solver.cpp:237]     Train net output #1: loss = 0.442718 (* 1 = 0.442718 loss)
I1211 19:27:18.655073 20404 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1211 19:27:26.607136 20404 solver.cpp:218] Iteration 34800 (12.5767 iter/s, 7.95119s/100 iters), loss = 0.445149
I1211 19:27:26.607136 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:27:26.607136 20404 solver.cpp:237]     Train net output #1: loss = 0.44515 (* 1 = 0.44515 loss)
I1211 19:27:26.607136 20404 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1211 19:27:34.552942 20404 solver.cpp:218] Iteration 34900 (12.5855 iter/s, 7.94567s/100 iters), loss = 0.251021
I1211 19:27:34.552942 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:27:34.552942 20404 solver.cpp:237]     Train net output #1: loss = 0.251021 (* 1 = 0.251021 loss)
I1211 19:27:34.552942 20404 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1211 19:27:42.115227  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:27:42.428246 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_35000.caffemodel
I1211 19:27:42.455245 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_35000.solverstate
I1211 19:27:42.461246 20404 solver.cpp:330] Iteration 35000, Testing net (#0)
I1211 19:27:42.461246 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:27:44.132728  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:27:44.198734 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7369
I1211 19:27:44.198734 20404 solver.cpp:397]     Test net output #1: loss = 0.792654 (* 1 = 0.792654 loss)
I1211 19:27:44.273735 20404 solver.cpp:218] Iteration 35000 (10.2881 iter/s, 9.71997s/100 iters), loss = 0.348367
I1211 19:27:44.273735 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:27:44.273735 20404 solver.cpp:237]     Train net output #1: loss = 0.348367 (* 1 = 0.348367 loss)
I1211 19:27:44.273735 20404 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1211 19:27:52.218510 20404 solver.cpp:218] Iteration 35100 (12.5875 iter/s, 7.94437s/100 iters), loss = 0.481853
I1211 19:27:52.218510 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:27:52.218510 20404 solver.cpp:237]     Train net output #1: loss = 0.481853 (* 1 = 0.481853 loss)
I1211 19:27:52.218510 20404 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1211 19:28:00.160833 20404 solver.cpp:218] Iteration 35200 (12.5916 iter/s, 7.94182s/100 iters), loss = 0.545913
I1211 19:28:00.160833 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:28:00.160833 20404 solver.cpp:237]     Train net output #1: loss = 0.545913 (* 1 = 0.545913 loss)
I1211 19:28:00.160833 20404 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1211 19:28:08.113911 20404 solver.cpp:218] Iteration 35300 (12.5736 iter/s, 7.95319s/100 iters), loss = 0.499359
I1211 19:28:08.114912 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:28:08.114912 20404 solver.cpp:237]     Train net output #1: loss = 0.499359 (* 1 = 0.499359 loss)
I1211 19:28:08.114912 20404 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1211 19:28:16.066073 20404 solver.cpp:218] Iteration 35400 (12.5765 iter/s, 7.95136s/100 iters), loss = 0.368675
I1211 19:28:16.066073 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:28:16.066073 20404 solver.cpp:237]     Train net output #1: loss = 0.368675 (* 1 = 0.368675 loss)
I1211 19:28:16.066073 20404 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1211 19:28:23.622808  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:28:23.936836 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_35500.caffemodel
I1211 19:28:23.970350 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_35500.solverstate
I1211 19:28:24.002867 20404 solver.cpp:330] Iteration 35500, Testing net (#0)
I1211 19:28:24.002867 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:28:25.674131  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:28:25.741135 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6899
I1211 19:28:25.741135 20404 solver.cpp:397]     Test net output #1: loss = 0.968689 (* 1 = 0.968689 loss)
I1211 19:28:25.816143 20404 solver.cpp:218] Iteration 35500 (10.2569 iter/s, 9.74949s/100 iters), loss = 0.409461
I1211 19:28:25.816143 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:28:25.816143 20404 solver.cpp:237]     Train net output #1: loss = 0.409461 (* 1 = 0.409461 loss)
I1211 19:28:25.816143 20404 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1211 19:28:33.767092 20404 solver.cpp:218] Iteration 35600 (12.5773 iter/s, 7.95084s/100 iters), loss = 0.394034
I1211 19:28:33.767092 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:28:33.768093 20404 solver.cpp:237]     Train net output #1: loss = 0.394034 (* 1 = 0.394034 loss)
I1211 19:28:33.768093 20404 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1211 19:28:41.717746 20404 solver.cpp:218] Iteration 35700 (12.5793 iter/s, 7.94955s/100 iters), loss = 0.329821
I1211 19:28:41.717746 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:28:41.717746 20404 solver.cpp:237]     Train net output #1: loss = 0.329821 (* 1 = 0.329821 loss)
I1211 19:28:41.717746 20404 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1211 19:28:49.664667 20404 solver.cpp:218] Iteration 35800 (12.5838 iter/s, 7.94675s/100 iters), loss = 0.400959
I1211 19:28:49.664667 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:28:49.664667 20404 solver.cpp:237]     Train net output #1: loss = 0.400959 (* 1 = 0.400959 loss)
I1211 19:28:49.664667 20404 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1211 19:28:57.613796 20404 solver.cpp:218] Iteration 35900 (12.5811 iter/s, 7.94842s/100 iters), loss = 0.321451
I1211 19:28:57.613796 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:28:57.613796 20404 solver.cpp:237]     Train net output #1: loss = 0.321451 (* 1 = 0.321451 loss)
I1211 19:28:57.613796 20404 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1211 19:29:05.175899  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:29:05.488931 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_36000.caffemodel
I1211 19:29:05.516435 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_36000.solverstate
I1211 19:29:05.521940 20404 solver.cpp:330] Iteration 36000, Testing net (#0)
I1211 19:29:05.521940 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:29:07.193101  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:29:07.259125 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7434
I1211 19:29:07.259125 20404 solver.cpp:397]     Test net output #1: loss = 0.798352 (* 1 = 0.798352 loss)
I1211 19:29:07.333158 20404 solver.cpp:218] Iteration 36000 (10.2894 iter/s, 9.71875s/100 iters), loss = 0.406356
I1211 19:29:07.333158 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:29:07.333158 20404 solver.cpp:237]     Train net output #1: loss = 0.406356 (* 1 = 0.406356 loss)
I1211 19:29:07.333158 20404 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1211 19:29:15.286937 20404 solver.cpp:218] Iteration 36100 (12.5729 iter/s, 7.95362s/100 iters), loss = 0.310592
I1211 19:29:15.286937 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:29:15.287938 20404 solver.cpp:237]     Train net output #1: loss = 0.310592 (* 1 = 0.310592 loss)
I1211 19:29:15.287938 20404 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1211 19:29:23.231328 20404 solver.cpp:218] Iteration 36200 (12.5882 iter/s, 7.94393s/100 iters), loss = 0.385752
I1211 19:29:23.232328 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:29:23.232328 20404 solver.cpp:237]     Train net output #1: loss = 0.385752 (* 1 = 0.385752 loss)
I1211 19:29:23.232328 20404 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1211 19:29:31.176749 20404 solver.cpp:218] Iteration 36300 (12.5867 iter/s, 7.94487s/100 iters), loss = 0.415111
I1211 19:29:31.176749 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:29:31.176749 20404 solver.cpp:237]     Train net output #1: loss = 0.415111 (* 1 = 0.415111 loss)
I1211 19:29:31.176749 20404 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1211 19:29:39.126147 20404 solver.cpp:218] Iteration 36400 (12.581 iter/s, 7.94851s/100 iters), loss = 0.308927
I1211 19:29:39.126147 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:29:39.126147 20404 solver.cpp:237]     Train net output #1: loss = 0.308927 (* 1 = 0.308927 loss)
I1211 19:29:39.126147 20404 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1211 19:29:46.687014  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:29:47.001058 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_36500.caffemodel
I1211 19:29:47.028066 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_36500.solverstate
I1211 19:29:47.044066 20404 solver.cpp:330] Iteration 36500, Testing net (#0)
I1211 19:29:47.044066 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:29:48.715906  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:29:48.782424 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7761
I1211 19:29:48.782424 20404 solver.cpp:397]     Test net output #1: loss = 0.685567 (* 1 = 0.685567 loss)
I1211 19:29:48.856459 20404 solver.cpp:218] Iteration 36500 (10.2776 iter/s, 9.7299s/100 iters), loss = 0.457317
I1211 19:29:48.856459 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:29:48.856459 20404 solver.cpp:237]     Train net output #1: loss = 0.457318 (* 1 = 0.457318 loss)
I1211 19:29:48.856459 20404 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1211 19:29:56.805272 20404 solver.cpp:218] Iteration 36600 (12.5815 iter/s, 7.94817s/100 iters), loss = 0.302498
I1211 19:29:56.805272 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:29:56.805272 20404 solver.cpp:237]     Train net output #1: loss = 0.302498 (* 1 = 0.302498 loss)
I1211 19:29:56.805272 20404 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1211 19:30:04.798651 20404 solver.cpp:218] Iteration 36700 (12.5107 iter/s, 7.99313s/100 iters), loss = 0.463609
I1211 19:30:04.798651 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:30:04.798651 20404 solver.cpp:237]     Train net output #1: loss = 0.463609 (* 1 = 0.463609 loss)
I1211 19:30:04.798651 20404 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1211 19:30:12.752497 20404 solver.cpp:218] Iteration 36800 (12.5742 iter/s, 7.95277s/100 iters), loss = 0.431044
I1211 19:30:12.752497 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I1211 19:30:12.752497 20404 solver.cpp:237]     Train net output #1: loss = 0.431044 (* 1 = 0.431044 loss)
I1211 19:30:12.752497 20404 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1211 19:30:20.708542 20404 solver.cpp:218] Iteration 36900 (12.57 iter/s, 7.95543s/100 iters), loss = 0.364722
I1211 19:30:20.708542 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:30:20.708542 20404 solver.cpp:237]     Train net output #1: loss = 0.364722 (* 1 = 0.364722 loss)
I1211 19:30:20.708542 20404 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1211 19:30:28.270560  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:30:28.585098 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_37000.caffemodel
I1211 19:30:28.614097 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_37000.solverstate
I1211 19:30:28.620108 20404 solver.cpp:330] Iteration 37000, Testing net (#0)
I1211 19:30:28.620108 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:30:30.290262  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:30:30.356266 20404 solver.cpp:397]     Test net output #0: accuracy = 0.713
I1211 19:30:30.356266 20404 solver.cpp:397]     Test net output #1: loss = 0.856477 (* 1 = 0.856477 loss)
I1211 19:30:30.430268 20404 solver.cpp:218] Iteration 37000 (10.286 iter/s, 9.72191s/100 iters), loss = 0.367211
I1211 19:30:30.430268 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:30:30.430268 20404 solver.cpp:237]     Train net output #1: loss = 0.367211 (* 1 = 0.367211 loss)
I1211 19:30:30.430268 20404 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1211 19:30:38.379410 20404 solver.cpp:218] Iteration 37100 (12.5818 iter/s, 7.948s/100 iters), loss = 0.399467
I1211 19:30:38.379410 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:30:38.379410 20404 solver.cpp:237]     Train net output #1: loss = 0.399467 (* 1 = 0.399467 loss)
I1211 19:30:38.379410 20404 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1211 19:30:46.331302 20404 solver.cpp:218] Iteration 37200 (12.5766 iter/s, 7.95127s/100 iters), loss = 0.512792
I1211 19:30:46.331302 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:30:46.331302 20404 solver.cpp:237]     Train net output #1: loss = 0.512792 (* 1 = 0.512792 loss)
I1211 19:30:46.331302 20404 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1211 19:30:54.272935 20404 solver.cpp:218] Iteration 37300 (12.592 iter/s, 7.94154s/100 iters), loss = 0.432314
I1211 19:30:54.272935 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:30:54.273434 20404 solver.cpp:237]     Train net output #1: loss = 0.432314 (* 1 = 0.432314 loss)
I1211 19:30:54.273434 20404 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1211 19:31:02.223278 20404 solver.cpp:218] Iteration 37400 (12.5782 iter/s, 7.95029s/100 iters), loss = 0.403852
I1211 19:31:02.223278 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:31:02.224278 20404 solver.cpp:237]     Train net output #1: loss = 0.403852 (* 1 = 0.403852 loss)
I1211 19:31:02.224278 20404 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1211 19:31:09.779327  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:31:10.092880 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_37500.caffemodel
I1211 19:31:10.122879 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_37500.solverstate
I1211 19:31:10.185894 20404 solver.cpp:330] Iteration 37500, Testing net (#0)
I1211 19:31:10.185894 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:31:11.857882  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:31:11.924448 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7545
I1211 19:31:11.924448 20404 solver.cpp:397]     Test net output #1: loss = 0.726193 (* 1 = 0.726193 loss)
I1211 19:31:11.998967 20404 solver.cpp:218] Iteration 37500 (10.2307 iter/s, 9.77446s/100 iters), loss = 0.472969
I1211 19:31:11.998967 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:31:11.998967 20404 solver.cpp:237]     Train net output #1: loss = 0.472969 (* 1 = 0.472969 loss)
I1211 19:31:11.998967 20404 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1211 19:31:19.960613 20404 solver.cpp:218] Iteration 37600 (12.5616 iter/s, 7.96075s/100 iters), loss = 0.354751
I1211 19:31:19.960613 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:31:19.960613 20404 solver.cpp:237]     Train net output #1: loss = 0.354751 (* 1 = 0.354751 loss)
I1211 19:31:19.960613 20404 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1211 19:31:27.914309 20404 solver.cpp:218] Iteration 37700 (12.5734 iter/s, 7.95328s/100 iters), loss = 0.455234
I1211 19:31:27.914309 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:31:27.914309 20404 solver.cpp:237]     Train net output #1: loss = 0.455235 (* 1 = 0.455235 loss)
I1211 19:31:27.914309 20404 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1211 19:31:35.868199 20404 solver.cpp:218] Iteration 37800 (12.5726 iter/s, 7.95379s/100 iters), loss = 0.454834
I1211 19:31:35.868199 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:31:35.868199 20404 solver.cpp:237]     Train net output #1: loss = 0.454834 (* 1 = 0.454834 loss)
I1211 19:31:35.868199 20404 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1211 19:31:43.827121 20404 solver.cpp:218] Iteration 37900 (12.5661 iter/s, 7.95792s/100 iters), loss = 0.267323
I1211 19:31:43.827121 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:31:43.827121 20404 solver.cpp:237]     Train net output #1: loss = 0.267323 (* 1 = 0.267323 loss)
I1211 19:31:43.827121 20404 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1211 19:31:51.394901  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:31:51.708950 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_38000.caffemodel
I1211 19:31:51.738948 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_38000.solverstate
I1211 19:31:51.744949 20404 solver.cpp:330] Iteration 38000, Testing net (#0)
I1211 19:31:51.744949 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:31:53.415088  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:31:53.481591 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6563
I1211 19:31:53.481591 20404 solver.cpp:397]     Test net output #1: loss = 1.05491 (* 1 = 1.05491 loss)
I1211 19:31:53.555091 20404 solver.cpp:218] Iteration 38000 (10.2795 iter/s, 9.72807s/100 iters), loss = 0.382269
I1211 19:31:53.555091 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:31:53.555091 20404 solver.cpp:237]     Train net output #1: loss = 0.382269 (* 1 = 0.382269 loss)
I1211 19:31:53.555091 20404 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1211 19:32:01.511838 20404 solver.cpp:218] Iteration 38100 (12.5686 iter/s, 7.95632s/100 iters), loss = 0.393772
I1211 19:32:01.511838 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:32:01.511838 20404 solver.cpp:237]     Train net output #1: loss = 0.393772 (* 1 = 0.393772 loss)
I1211 19:32:01.511838 20404 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1211 19:32:09.465939 20404 solver.cpp:218] Iteration 38200 (12.5737 iter/s, 7.95313s/100 iters), loss = 0.502879
I1211 19:32:09.465939 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:32:09.465939 20404 solver.cpp:237]     Train net output #1: loss = 0.502879 (* 1 = 0.502879 loss)
I1211 19:32:09.465939 20404 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1211 19:32:17.419824 20404 solver.cpp:218] Iteration 38300 (12.5729 iter/s, 7.95358s/100 iters), loss = 0.397596
I1211 19:32:17.419824 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:32:17.419824 20404 solver.cpp:237]     Train net output #1: loss = 0.397596 (* 1 = 0.397596 loss)
I1211 19:32:17.419824 20404 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1211 19:32:25.373525 20404 solver.cpp:218] Iteration 38400 (12.5744 iter/s, 7.95266s/100 iters), loss = 0.39618
I1211 19:32:25.373525 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:32:25.373525 20404 solver.cpp:237]     Train net output #1: loss = 0.39618 (* 1 = 0.39618 loss)
I1211 19:32:25.373525 20404 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1211 19:32:32.931614  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:32:33.246645 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_38500.caffemodel
I1211 19:32:33.273665 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_38500.solverstate
I1211 19:32:33.286149 20404 solver.cpp:330] Iteration 38500, Testing net (#0)
I1211 19:32:33.286149 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:32:34.956759  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:32:35.022764 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7314
I1211 19:32:35.022764 20404 solver.cpp:397]     Test net output #1: loss = 0.788505 (* 1 = 0.788505 loss)
I1211 19:32:35.097265 20404 solver.cpp:218] Iteration 38500 (10.2847 iter/s, 9.7232s/100 iters), loss = 0.363389
I1211 19:32:35.097265 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:32:35.097265 20404 solver.cpp:237]     Train net output #1: loss = 0.363389 (* 1 = 0.363389 loss)
I1211 19:32:35.097265 20404 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1211 19:32:43.044378 20404 solver.cpp:218] Iteration 38600 (12.5837 iter/s, 7.94678s/100 iters), loss = 0.450942
I1211 19:32:43.044378 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:32:43.044378 20404 solver.cpp:237]     Train net output #1: loss = 0.450942 (* 1 = 0.450942 loss)
I1211 19:32:43.044378 20404 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1211 19:32:50.987541 20404 solver.cpp:218] Iteration 38700 (12.5901 iter/s, 7.94273s/100 iters), loss = 0.404123
I1211 19:32:50.987541 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:32:50.987541 20404 solver.cpp:237]     Train net output #1: loss = 0.404123 (* 1 = 0.404123 loss)
I1211 19:32:50.987541 20404 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1211 19:32:58.931963 20404 solver.cpp:218] Iteration 38800 (12.5877 iter/s, 7.94423s/100 iters), loss = 0.464326
I1211 19:32:58.931963 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:32:58.931963 20404 solver.cpp:237]     Train net output #1: loss = 0.464326 (* 1 = 0.464326 loss)
I1211 19:32:58.931963 20404 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1211 19:33:06.870661 20404 solver.cpp:218] Iteration 38900 (12.5967 iter/s, 7.93856s/100 iters), loss = 0.372577
I1211 19:33:06.870661 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:33:06.870661 20404 solver.cpp:237]     Train net output #1: loss = 0.372577 (* 1 = 0.372577 loss)
I1211 19:33:06.870661 20404 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1211 19:33:14.427880  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:33:14.743405 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_39000.caffemodel
I1211 19:33:14.771404 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_39000.solverstate
I1211 19:33:14.777415 20404 solver.cpp:330] Iteration 39000, Testing net (#0)
I1211 19:33:14.777415 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:33:16.449005  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:33:16.515597 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7549
I1211 19:33:16.515597 20404 solver.cpp:397]     Test net output #1: loss = 0.721913 (* 1 = 0.721913 loss)
I1211 19:33:16.590601 20404 solver.cpp:218] Iteration 39000 (10.289 iter/s, 9.71915s/100 iters), loss = 0.353204
I1211 19:33:16.590601 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:33:16.590601 20404 solver.cpp:237]     Train net output #1: loss = 0.353204 (* 1 = 0.353204 loss)
I1211 19:33:16.590601 20404 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1211 19:33:24.531916 20404 solver.cpp:218] Iteration 39100 (12.593 iter/s, 7.94091s/100 iters), loss = 0.388439
I1211 19:33:24.531916 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:33:24.531916 20404 solver.cpp:237]     Train net output #1: loss = 0.388439 (* 1 = 0.388439 loss)
I1211 19:33:24.531916 20404 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1211 19:33:32.479786 20404 solver.cpp:218] Iteration 39200 (12.5837 iter/s, 7.94676s/100 iters), loss = 0.386611
I1211 19:33:32.479786 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:33:32.479786 20404 solver.cpp:237]     Train net output #1: loss = 0.386611 (* 1 = 0.386611 loss)
I1211 19:33:32.479786 20404 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1211 19:33:40.430662 20404 solver.cpp:218] Iteration 39300 (12.5771 iter/s, 7.95097s/100 iters), loss = 0.411438
I1211 19:33:40.430662 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:33:40.430662 20404 solver.cpp:237]     Train net output #1: loss = 0.411439 (* 1 = 0.411439 loss)
I1211 19:33:40.430662 20404 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1211 19:33:48.433949 20404 solver.cpp:218] Iteration 39400 (12.4963 iter/s, 8.0024s/100 iters), loss = 0.321255
I1211 19:33:48.433949 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:33:48.433949 20404 solver.cpp:237]     Train net output #1: loss = 0.321256 (* 1 = 0.321256 loss)
I1211 19:33:48.433949 20404 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1211 19:33:55.969148  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:33:56.283440 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_39500.caffemodel
I1211 19:33:56.310456 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_39500.solverstate
I1211 19:33:56.316455 20404 solver.cpp:330] Iteration 39500, Testing net (#0)
I1211 19:33:56.316942 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:33:57.981952  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:33:58.048956 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6494
I1211 19:33:58.048956 20404 solver.cpp:397]     Test net output #1: loss = 1.1224 (* 1 = 1.1224 loss)
I1211 19:33:58.122560 20404 solver.cpp:218] Iteration 39500 (10.3217 iter/s, 9.68831s/100 iters), loss = 0.352729
I1211 19:33:58.122560 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:33:58.122560 20404 solver.cpp:237]     Train net output #1: loss = 0.352729 (* 1 = 0.352729 loss)
I1211 19:33:58.122560 20404 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1211 19:34:06.057232 20404 solver.cpp:218] Iteration 39600 (12.6033 iter/s, 7.93444s/100 iters), loss = 0.332763
I1211 19:34:06.057232 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:34:06.057232 20404 solver.cpp:237]     Train net output #1: loss = 0.332763 (* 1 = 0.332763 loss)
I1211 19:34:06.057232 20404 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1211 19:34:13.996419 20404 solver.cpp:218] Iteration 39700 (12.597 iter/s, 7.93842s/100 iters), loss = 0.442284
I1211 19:34:13.996419 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:34:13.996419 20404 solver.cpp:237]     Train net output #1: loss = 0.442284 (* 1 = 0.442284 loss)
I1211 19:34:13.996419 20404 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1211 19:34:21.927265 20404 solver.cpp:218] Iteration 39800 (12.609 iter/s, 7.93085s/100 iters), loss = 0.416969
I1211 19:34:21.927265 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:34:21.927265 20404 solver.cpp:237]     Train net output #1: loss = 0.416969 (* 1 = 0.416969 loss)
I1211 19:34:21.927265 20404 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1211 19:34:29.864156 20404 solver.cpp:218] Iteration 39900 (12.6002 iter/s, 7.93637s/100 iters), loss = 0.378834
I1211 19:34:29.864156 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:34:29.864156 20404 solver.cpp:237]     Train net output #1: loss = 0.378834 (* 1 = 0.378834 loss)
I1211 19:34:29.864156 20404 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1211 19:34:37.394960  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:34:37.709002 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_40000.caffemodel
I1211 19:34:37.737015 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_40000.solverstate
I1211 19:34:37.742015 20404 solver.cpp:330] Iteration 40000, Testing net (#0)
I1211 19:34:37.743016 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:34:39.409195  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:34:39.475220 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7004
I1211 19:34:39.475220 20404 solver.cpp:397]     Test net output #1: loss = 0.911085 (* 1 = 0.911085 loss)
I1211 19:34:39.548235 20404 solver.cpp:218] Iteration 40000 (10.3267 iter/s, 9.68361s/100 iters), loss = 0.379602
I1211 19:34:39.548235 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:34:39.548235 20404 solver.cpp:237]     Train net output #1: loss = 0.379602 (* 1 = 0.379602 loss)
I1211 19:34:39.548235 20404 sgd_solver.cpp:105] Iteration 40000, lr = 0.1
I1211 19:34:47.486155 20404 solver.cpp:218] Iteration 40100 (12.5995 iter/s, 7.93684s/100 iters), loss = 0.275913
I1211 19:34:47.486155 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:34:47.486155 20404 solver.cpp:237]     Train net output #1: loss = 0.275913 (* 1 = 0.275913 loss)
I1211 19:34:47.486155 20404 sgd_solver.cpp:105] Iteration 40100, lr = 0.1
I1211 19:34:55.420845 20404 solver.cpp:218] Iteration 40200 (12.6041 iter/s, 7.9339s/100 iters), loss = 0.497966
I1211 19:34:55.420845 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:34:55.420845 20404 solver.cpp:237]     Train net output #1: loss = 0.497966 (* 1 = 0.497966 loss)
I1211 19:34:55.420845 20404 sgd_solver.cpp:105] Iteration 40200, lr = 0.1
I1211 19:35:03.354720 20404 solver.cpp:218] Iteration 40300 (12.6042 iter/s, 7.93388s/100 iters), loss = 0.431168
I1211 19:35:03.354720 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:35:03.354720 20404 solver.cpp:237]     Train net output #1: loss = 0.431168 (* 1 = 0.431168 loss)
I1211 19:35:03.354720 20404 sgd_solver.cpp:105] Iteration 40300, lr = 0.1
I1211 19:35:11.285051 20404 solver.cpp:218] Iteration 40400 (12.6107 iter/s, 7.92979s/100 iters), loss = 0.314944
I1211 19:35:11.285051 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:35:11.285051 20404 solver.cpp:237]     Train net output #1: loss = 0.314944 (* 1 = 0.314944 loss)
I1211 19:35:11.285051 20404 sgd_solver.cpp:105] Iteration 40400, lr = 0.1
I1211 19:35:18.841768  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:35:19.154788 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_40500.caffemodel
I1211 19:35:19.183787 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_40500.solverstate
I1211 19:35:19.210788 20404 solver.cpp:330] Iteration 40500, Testing net (#0)
I1211 19:35:19.210788 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:35:20.876776  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:35:20.942782 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7156
I1211 19:35:20.942782 20404 solver.cpp:397]     Test net output #1: loss = 0.850936 (* 1 = 0.850936 loss)
I1211 19:35:21.017283 20404 solver.cpp:218] Iteration 40500 (10.2758 iter/s, 9.73158s/100 iters), loss = 0.349629
I1211 19:35:21.017283 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:35:21.017283 20404 solver.cpp:237]     Train net output #1: loss = 0.349629 (* 1 = 0.349629 loss)
I1211 19:35:21.017283 20404 sgd_solver.cpp:105] Iteration 40500, lr = 0.1
I1211 19:35:28.960669 20404 solver.cpp:218] Iteration 40600 (12.5901 iter/s, 7.94277s/100 iters), loss = 0.345155
I1211 19:35:28.960669 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:35:28.960669 20404 solver.cpp:237]     Train net output #1: loss = 0.345155 (* 1 = 0.345155 loss)
I1211 19:35:28.960669 20404 sgd_solver.cpp:105] Iteration 40600, lr = 0.1
I1211 19:35:36.900625 20404 solver.cpp:218] Iteration 40700 (12.5952 iter/s, 7.93954s/100 iters), loss = 0.39105
I1211 19:35:36.900625 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:35:36.900625 20404 solver.cpp:237]     Train net output #1: loss = 0.39105 (* 1 = 0.39105 loss)
I1211 19:35:36.900625 20404 sgd_solver.cpp:105] Iteration 40700, lr = 0.1
I1211 19:35:44.822021 20404 solver.cpp:218] Iteration 40800 (12.6243 iter/s, 7.92123s/100 iters), loss = 0.413724
I1211 19:35:44.822021 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:35:44.822021 20404 solver.cpp:237]     Train net output #1: loss = 0.413724 (* 1 = 0.413724 loss)
I1211 19:35:44.822021 20404 sgd_solver.cpp:105] Iteration 40800, lr = 0.1
I1211 19:35:52.759824 20404 solver.cpp:218] Iteration 40900 (12.5994 iter/s, 7.93692s/100 iters), loss = 0.356688
I1211 19:35:52.759824 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:35:52.759824 20404 solver.cpp:237]     Train net output #1: loss = 0.356688 (* 1 = 0.356688 loss)
I1211 19:35:52.759824 20404 sgd_solver.cpp:105] Iteration 40900, lr = 0.1
I1211 19:36:00.300628  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:36:00.613673 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_41000.caffemodel
I1211 19:36:00.641178 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_41000.solverstate
I1211 19:36:00.646682 20404 solver.cpp:330] Iteration 41000, Testing net (#0)
I1211 19:36:00.646682 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:36:02.310786  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:36:02.376794 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7356
I1211 19:36:02.376794 20404 solver.cpp:397]     Test net output #1: loss = 0.791165 (* 1 = 0.791165 loss)
I1211 19:36:02.450799 20404 solver.cpp:218] Iteration 41000 (10.3187 iter/s, 9.69118s/100 iters), loss = 0.371075
I1211 19:36:02.450799 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:36:02.450799 20404 solver.cpp:237]     Train net output #1: loss = 0.371075 (* 1 = 0.371075 loss)
I1211 19:36:02.450799 20404 sgd_solver.cpp:105] Iteration 41000, lr = 0.1
I1211 19:36:10.383932 20404 solver.cpp:218] Iteration 41100 (12.6062 iter/s, 7.93261s/100 iters), loss = 0.389869
I1211 19:36:10.383932 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:36:10.383932 20404 solver.cpp:237]     Train net output #1: loss = 0.389869 (* 1 = 0.389869 loss)
I1211 19:36:10.383932 20404 sgd_solver.cpp:105] Iteration 41100, lr = 0.1
I1211 19:36:18.326849 20404 solver.cpp:218] Iteration 41200 (12.5913 iter/s, 7.942s/100 iters), loss = 0.441624
I1211 19:36:18.326849 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:36:18.326849 20404 solver.cpp:237]     Train net output #1: loss = 0.441624 (* 1 = 0.441624 loss)
I1211 19:36:18.326849 20404 sgd_solver.cpp:105] Iteration 41200, lr = 0.1
I1211 19:36:26.261759 20404 solver.cpp:218] Iteration 41300 (12.6038 iter/s, 7.93414s/100 iters), loss = 0.482743
I1211 19:36:26.261759 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:36:26.261759 20404 solver.cpp:237]     Train net output #1: loss = 0.482743 (* 1 = 0.482743 loss)
I1211 19:36:26.261759 20404 sgd_solver.cpp:105] Iteration 41300, lr = 0.1
I1211 19:36:34.199753 20404 solver.cpp:218] Iteration 41400 (12.5974 iter/s, 7.93814s/100 iters), loss = 0.436902
I1211 19:36:34.199753 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:36:34.199753 20404 solver.cpp:237]     Train net output #1: loss = 0.436902 (* 1 = 0.436902 loss)
I1211 19:36:34.199753 20404 sgd_solver.cpp:105] Iteration 41400, lr = 0.1
I1211 19:36:41.748355  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:36:42.060891 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_41500.caffemodel
I1211 19:36:42.090889 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_41500.solverstate
I1211 19:36:42.095906 20404 solver.cpp:330] Iteration 41500, Testing net (#0)
I1211 19:36:42.096894 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:36:43.763034  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:36:43.829031 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7782
I1211 19:36:43.829031 20404 solver.cpp:397]     Test net output #1: loss = 0.629593 (* 1 = 0.629593 loss)
I1211 19:36:43.903192 20404 solver.cpp:218] Iteration 41500 (10.3069 iter/s, 9.7022s/100 iters), loss = 0.431508
I1211 19:36:43.903192 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:36:43.903192 20404 solver.cpp:237]     Train net output #1: loss = 0.431508 (* 1 = 0.431508 loss)
I1211 19:36:43.903192 20404 sgd_solver.cpp:105] Iteration 41500, lr = 0.1
I1211 19:36:51.826450 20404 solver.cpp:218] Iteration 41600 (12.6213 iter/s, 7.9231s/100 iters), loss = 0.386992
I1211 19:36:51.826450 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:36:51.826450 20404 solver.cpp:237]     Train net output #1: loss = 0.386992 (* 1 = 0.386992 loss)
I1211 19:36:51.826450 20404 sgd_solver.cpp:105] Iteration 41600, lr = 0.1
I1211 19:36:59.757330 20404 solver.cpp:218] Iteration 41700 (12.6093 iter/s, 7.93067s/100 iters), loss = 0.463111
I1211 19:36:59.757330 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:36:59.757330 20404 solver.cpp:237]     Train net output #1: loss = 0.463111 (* 1 = 0.463111 loss)
I1211 19:36:59.757330 20404 sgd_solver.cpp:105] Iteration 41700, lr = 0.1
I1211 19:37:07.687943 20404 solver.cpp:218] Iteration 41800 (12.6099 iter/s, 7.93028s/100 iters), loss = 0.442007
I1211 19:37:07.688944 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:37:07.688944 20404 solver.cpp:237]     Train net output #1: loss = 0.442007 (* 1 = 0.442007 loss)
I1211 19:37:07.688944 20404 sgd_solver.cpp:105] Iteration 41800, lr = 0.1
I1211 19:37:15.622488 20404 solver.cpp:218] Iteration 41900 (12.6052 iter/s, 7.93321s/100 iters), loss = 0.303692
I1211 19:37:15.622488 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:37:15.622488 20404 solver.cpp:237]     Train net output #1: loss = 0.303692 (* 1 = 0.303692 loss)
I1211 19:37:15.622488 20404 sgd_solver.cpp:105] Iteration 41900, lr = 0.1
I1211 19:37:23.177716  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:37:23.492760 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_42000.caffemodel
I1211 19:37:23.553263 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_42000.solverstate
I1211 19:37:23.558764 20404 solver.cpp:330] Iteration 42000, Testing net (#0)
I1211 19:37:23.559264 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:37:25.224956  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:37:25.290959 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7616
I1211 19:37:25.290959 20404 solver.cpp:397]     Test net output #1: loss = 0.705737 (* 1 = 0.705737 loss)
I1211 19:37:25.364960 20404 solver.cpp:218] Iteration 42000 (10.2646 iter/s, 9.74226s/100 iters), loss = 0.391299
I1211 19:37:25.364960 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:37:25.364960 20404 solver.cpp:237]     Train net output #1: loss = 0.391299 (* 1 = 0.391299 loss)
I1211 19:37:25.364960 20404 sgd_solver.cpp:105] Iteration 42000, lr = 0.1
I1211 19:37:33.301726 20404 solver.cpp:218] Iteration 42100 (12.6004 iter/s, 7.93628s/100 iters), loss = 0.314884
I1211 19:37:33.301726 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:37:33.301726 20404 solver.cpp:237]     Train net output #1: loss = 0.314884 (* 1 = 0.314884 loss)
I1211 19:37:33.301726 20404 sgd_solver.cpp:105] Iteration 42100, lr = 0.1
I1211 19:37:41.233630 20404 solver.cpp:218] Iteration 42200 (12.6078 iter/s, 7.93158s/100 iters), loss = 0.404237
I1211 19:37:41.233630 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:37:41.233630 20404 solver.cpp:237]     Train net output #1: loss = 0.404237 (* 1 = 0.404237 loss)
I1211 19:37:41.233630 20404 sgd_solver.cpp:105] Iteration 42200, lr = 0.1
I1211 19:37:49.168251 20404 solver.cpp:218] Iteration 42300 (12.6044 iter/s, 7.93376s/100 iters), loss = 0.43253
I1211 19:37:49.168251 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:37:49.168251 20404 solver.cpp:237]     Train net output #1: loss = 0.432531 (* 1 = 0.432531 loss)
I1211 19:37:49.168251 20404 sgd_solver.cpp:105] Iteration 42300, lr = 0.1
I1211 19:37:57.102023 20404 solver.cpp:218] Iteration 42400 (12.6052 iter/s, 7.93323s/100 iters), loss = 0.316224
I1211 19:37:57.102023 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:37:57.102023 20404 solver.cpp:237]     Train net output #1: loss = 0.316224 (* 1 = 0.316224 loss)
I1211 19:37:57.102023 20404 sgd_solver.cpp:105] Iteration 42400, lr = 0.1
I1211 19:38:04.643687  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:38:04.957712 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_42500.caffemodel
I1211 19:38:04.985735 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_42500.solverstate
I1211 19:38:04.990731 20404 solver.cpp:330] Iteration 42500, Testing net (#0)
I1211 19:38:04.990731 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:38:06.658370  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:38:06.724882 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7385
I1211 19:38:06.724882 20404 solver.cpp:397]     Test net output #1: loss = 0.837677 (* 1 = 0.837677 loss)
I1211 19:38:06.799877 20404 solver.cpp:218] Iteration 42500 (10.3122 iter/s, 9.69724s/100 iters), loss = 0.409296
I1211 19:38:06.799877 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:38:06.799877 20404 solver.cpp:237]     Train net output #1: loss = 0.409296 (* 1 = 0.409296 loss)
I1211 19:38:06.799877 20404 sgd_solver.cpp:105] Iteration 42500, lr = 0.1
I1211 19:38:14.732156 20404 solver.cpp:218] Iteration 42600 (12.6067 iter/s, 7.93231s/100 iters), loss = 0.386785
I1211 19:38:14.732156 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:38:14.732156 20404 solver.cpp:237]     Train net output #1: loss = 0.386786 (* 1 = 0.386786 loss)
I1211 19:38:14.732156 20404 sgd_solver.cpp:105] Iteration 42600, lr = 0.1
I1211 19:38:22.668900 20404 solver.cpp:218] Iteration 42700 (12.601 iter/s, 7.93585s/100 iters), loss = 0.443605
I1211 19:38:22.668900 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:38:22.668900 20404 solver.cpp:237]     Train net output #1: loss = 0.443605 (* 1 = 0.443605 loss)
I1211 19:38:22.668900 20404 sgd_solver.cpp:105] Iteration 42700, lr = 0.1
I1211 19:38:30.608716 20404 solver.cpp:218] Iteration 42800 (12.5956 iter/s, 7.9393s/100 iters), loss = 0.445064
I1211 19:38:30.608716 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:38:30.608716 20404 solver.cpp:237]     Train net output #1: loss = 0.445064 (* 1 = 0.445064 loss)
I1211 19:38:30.608716 20404 sgd_solver.cpp:105] Iteration 42800, lr = 0.1
I1211 19:38:38.535598 20404 solver.cpp:218] Iteration 42900 (12.615 iter/s, 7.9271s/100 iters), loss = 0.326318
I1211 19:38:38.535598 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:38:38.535598 20404 solver.cpp:237]     Train net output #1: loss = 0.326318 (* 1 = 0.326318 loss)
I1211 19:38:38.536599 20404 sgd_solver.cpp:105] Iteration 42900, lr = 0.1
I1211 19:38:46.087316  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:38:46.401343 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_43000.caffemodel
I1211 19:38:46.454341 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_43000.solverstate
I1211 19:38:46.459846 20404 solver.cpp:330] Iteration 43000, Testing net (#0)
I1211 19:38:46.459846 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:38:48.123458  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:38:48.190474 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7149
I1211 19:38:48.190474 20404 solver.cpp:397]     Test net output #1: loss = 0.891025 (* 1 = 0.891025 loss)
I1211 19:38:48.265483 20404 solver.cpp:218] Iteration 43000 (10.2792 iter/s, 9.7284s/100 iters), loss = 0.361398
I1211 19:38:48.265483 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:38:48.265483 20404 solver.cpp:237]     Train net output #1: loss = 0.361399 (* 1 = 0.361399 loss)
I1211 19:38:48.265483 20404 sgd_solver.cpp:105] Iteration 43000, lr = 0.1
I1211 19:38:56.193691 20404 solver.cpp:218] Iteration 43100 (12.6139 iter/s, 7.92777s/100 iters), loss = 0.276894
I1211 19:38:56.193691 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:38:56.193691 20404 solver.cpp:237]     Train net output #1: loss = 0.276894 (* 1 = 0.276894 loss)
I1211 19:38:56.193691 20404 sgd_solver.cpp:105] Iteration 43100, lr = 0.1
I1211 19:39:04.132124 20404 solver.cpp:218] Iteration 43200 (12.5972 iter/s, 7.93826s/100 iters), loss = 0.459463
I1211 19:39:04.132124 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:39:04.132124 20404 solver.cpp:237]     Train net output #1: loss = 0.459463 (* 1 = 0.459463 loss)
I1211 19:39:04.132124 20404 sgd_solver.cpp:105] Iteration 43200, lr = 0.1
I1211 19:39:12.064072 20404 solver.cpp:218] Iteration 43300 (12.6082 iter/s, 7.93138s/100 iters), loss = 0.356609
I1211 19:39:12.064072 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:39:12.064072 20404 solver.cpp:237]     Train net output #1: loss = 0.35661 (* 1 = 0.35661 loss)
I1211 19:39:12.064072 20404 sgd_solver.cpp:105] Iteration 43300, lr = 0.1
I1211 19:39:20.003680 20404 solver.cpp:218] Iteration 43400 (12.5947 iter/s, 7.93984s/100 iters), loss = 0.387527
I1211 19:39:20.003680 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:39:20.004680 20404 solver.cpp:237]     Train net output #1: loss = 0.387527 (* 1 = 0.387527 loss)
I1211 19:39:20.004680 20404 sgd_solver.cpp:105] Iteration 43400, lr = 0.1
I1211 19:39:27.547560  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:39:27.860568 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_43500.caffemodel
I1211 19:39:27.888571 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_43500.solverstate
I1211 19:39:27.893575 20404 solver.cpp:330] Iteration 43500, Testing net (#0)
I1211 19:39:27.894577 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:39:29.560724  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:39:29.627730 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7658
I1211 19:39:29.627730 20404 solver.cpp:397]     Test net output #1: loss = 0.659579 (* 1 = 0.659579 loss)
I1211 19:39:29.700734 20404 solver.cpp:218] Iteration 43500 (10.3129 iter/s, 9.69658s/100 iters), loss = 0.400469
I1211 19:39:29.701735 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:39:29.701735 20404 solver.cpp:237]     Train net output #1: loss = 0.400469 (* 1 = 0.400469 loss)
I1211 19:39:29.701735 20404 sgd_solver.cpp:105] Iteration 43500, lr = 0.1
I1211 19:39:37.639459 20404 solver.cpp:218] Iteration 43600 (12.5984 iter/s, 7.9375s/100 iters), loss = 0.344593
I1211 19:39:37.639459 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:39:37.639459 20404 solver.cpp:237]     Train net output #1: loss = 0.344593 (* 1 = 0.344593 loss)
I1211 19:39:37.639459 20404 sgd_solver.cpp:105] Iteration 43600, lr = 0.1
I1211 19:39:45.572269 20404 solver.cpp:218] Iteration 43700 (12.6069 iter/s, 7.93214s/100 iters), loss = 0.395056
I1211 19:39:45.572269 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:39:45.572269 20404 solver.cpp:237]     Train net output #1: loss = 0.395056 (* 1 = 0.395056 loss)
I1211 19:39:45.572269 20404 sgd_solver.cpp:105] Iteration 43700, lr = 0.1
I1211 19:39:53.516155 20404 solver.cpp:218] Iteration 43800 (12.5888 iter/s, 7.94357s/100 iters), loss = 0.395301
I1211 19:39:53.516155 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:39:53.516155 20404 solver.cpp:237]     Train net output #1: loss = 0.395302 (* 1 = 0.395302 loss)
I1211 19:39:53.516155 20404 sgd_solver.cpp:105] Iteration 43800, lr = 0.1
I1211 19:40:01.452040 20404 solver.cpp:218] Iteration 43900 (12.6018 iter/s, 7.93535s/100 iters), loss = 0.401204
I1211 19:40:01.452040 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:40:01.452040 20404 solver.cpp:237]     Train net output #1: loss = 0.401204 (* 1 = 0.401204 loss)
I1211 19:40:01.452040 20404 sgd_solver.cpp:105] Iteration 43900, lr = 0.1
I1211 19:40:08.999737  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:40:09.313374 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_44000.caffemodel
I1211 19:40:09.341387 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_44000.solverstate
I1211 19:40:09.347373 20404 solver.cpp:330] Iteration 44000, Testing net (#0)
I1211 19:40:09.348383 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:40:11.016299  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:40:11.083295 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7527
I1211 19:40:11.083295 20404 solver.cpp:397]     Test net output #1: loss = 0.740063 (* 1 = 0.740063 loss)
I1211 19:40:11.157039 20404 solver.cpp:218] Iteration 44000 (10.3037 iter/s, 9.70521s/100 iters), loss = 0.40998
I1211 19:40:11.157039 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:40:11.157039 20404 solver.cpp:237]     Train net output #1: loss = 0.40998 (* 1 = 0.40998 loss)
I1211 19:40:11.158038 20404 sgd_solver.cpp:105] Iteration 44000, lr = 0.1
I1211 19:40:19.091055 20404 solver.cpp:218] Iteration 44100 (12.6049 iter/s, 7.93341s/100 iters), loss = 0.322367
I1211 19:40:19.091055 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:40:19.091055 20404 solver.cpp:237]     Train net output #1: loss = 0.322367 (* 1 = 0.322367 loss)
I1211 19:40:19.091055 20404 sgd_solver.cpp:105] Iteration 44100, lr = 0.1
I1211 19:40:27.021180 20404 solver.cpp:218] Iteration 44200 (12.6122 iter/s, 7.92883s/100 iters), loss = 0.47509
I1211 19:40:27.021180 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:40:27.021180 20404 solver.cpp:237]     Train net output #1: loss = 0.47509 (* 1 = 0.47509 loss)
I1211 19:40:27.021180 20404 sgd_solver.cpp:105] Iteration 44200, lr = 0.1
I1211 19:40:34.958215 20404 solver.cpp:218] Iteration 44300 (12.599 iter/s, 7.93717s/100 iters), loss = 0.443711
I1211 19:40:34.958215 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:40:34.958215 20404 solver.cpp:237]     Train net output #1: loss = 0.443711 (* 1 = 0.443711 loss)
I1211 19:40:34.958215 20404 sgd_solver.cpp:105] Iteration 44300, lr = 0.1
I1211 19:40:42.892148 20404 solver.cpp:218] Iteration 44400 (12.6049 iter/s, 7.93341s/100 iters), loss = 0.352913
I1211 19:40:42.892148 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:40:42.892148 20404 solver.cpp:237]     Train net output #1: loss = 0.352913 (* 1 = 0.352913 loss)
I1211 19:40:42.892148 20404 sgd_solver.cpp:105] Iteration 44400, lr = 0.1
I1211 19:40:50.434890  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:40:50.749913 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_44500.caffemodel
I1211 19:40:50.775907 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_44500.solverstate
I1211 19:40:50.781906 20404 solver.cpp:330] Iteration 44500, Testing net (#0)
I1211 19:40:50.781906 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:40:52.448098  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:40:52.515125 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7298
I1211 19:40:52.515125 20404 solver.cpp:397]     Test net output #1: loss = 0.907443 (* 1 = 0.907443 loss)
I1211 19:40:52.589118 20404 solver.cpp:218] Iteration 44500 (10.3134 iter/s, 9.69615s/100 iters), loss = 0.454453
I1211 19:40:52.589118 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:40:52.589118 20404 solver.cpp:237]     Train net output #1: loss = 0.454453 (* 1 = 0.454453 loss)
I1211 19:40:52.589118 20404 sgd_solver.cpp:105] Iteration 44500, lr = 0.1
I1211 19:41:00.535001 20404 solver.cpp:218] Iteration 44600 (12.5863 iter/s, 7.94517s/100 iters), loss = 0.345989
I1211 19:41:00.535001 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:41:00.535001 20404 solver.cpp:237]     Train net output #1: loss = 0.345989 (* 1 = 0.345989 loss)
I1211 19:41:00.535001 20404 sgd_solver.cpp:105] Iteration 44600, lr = 0.1
I1211 19:41:08.477707 20404 solver.cpp:218] Iteration 44700 (12.5906 iter/s, 7.94243s/100 iters), loss = 0.460284
I1211 19:41:08.477707 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:41:08.477707 20404 solver.cpp:237]     Train net output #1: loss = 0.460284 (* 1 = 0.460284 loss)
I1211 19:41:08.477707 20404 sgd_solver.cpp:105] Iteration 44700, lr = 0.1
I1211 19:41:16.421541 20404 solver.cpp:218] Iteration 44800 (12.5889 iter/s, 7.9435s/100 iters), loss = 0.463475
I1211 19:41:16.421541 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:41:16.421541 20404 solver.cpp:237]     Train net output #1: loss = 0.463475 (* 1 = 0.463475 loss)
I1211 19:41:16.421541 20404 sgd_solver.cpp:105] Iteration 44800, lr = 0.1
I1211 19:41:24.356137 20404 solver.cpp:218] Iteration 44900 (12.6043 iter/s, 7.9338s/100 iters), loss = 0.390865
I1211 19:41:24.356137 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:41:24.356137 20404 solver.cpp:237]     Train net output #1: loss = 0.390865 (* 1 = 0.390865 loss)
I1211 19:41:24.356137 20404 sgd_solver.cpp:105] Iteration 44900, lr = 0.1
I1211 19:41:31.888178  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:41:32.202217 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_45000.caffemodel
I1211 19:41:32.271251 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_45000.solverstate
I1211 19:41:32.276252 20404 solver.cpp:330] Iteration 45000, Testing net (#0)
I1211 19:41:32.277253 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:41:33.942500  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:41:34.009500 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6947
I1211 19:41:34.009500 20404 solver.cpp:397]     Test net output #1: loss = 0.957606 (* 1 = 0.957606 loss)
I1211 19:41:34.083505 20404 solver.cpp:218] Iteration 45000 (10.28 iter/s, 9.72762s/100 iters), loss = 0.378288
I1211 19:41:34.083505 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:41:34.083505 20404 solver.cpp:237]     Train net output #1: loss = 0.378288 (* 1 = 0.378288 loss)
I1211 19:41:34.083505 20404 sgd_solver.cpp:105] Iteration 45000, lr = 0.1
I1211 19:41:42.016400 20404 solver.cpp:218] Iteration 45100 (12.6069 iter/s, 7.93217s/100 iters), loss = 0.332154
I1211 19:41:42.016400 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:41:42.016400 20404 solver.cpp:237]     Train net output #1: loss = 0.332154 (* 1 = 0.332154 loss)
I1211 19:41:42.016400 20404 sgd_solver.cpp:105] Iteration 45100, lr = 0.1
I1211 19:41:49.952424 20404 solver.cpp:218] Iteration 45200 (12.6024 iter/s, 7.93499s/100 iters), loss = 0.377439
I1211 19:41:49.952424 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:41:49.952424 20404 solver.cpp:237]     Train net output #1: loss = 0.377439 (* 1 = 0.377439 loss)
I1211 19:41:49.952424 20404 sgd_solver.cpp:105] Iteration 45200, lr = 0.1
I1211 19:41:57.885208 20404 solver.cpp:218] Iteration 45300 (12.6067 iter/s, 7.93231s/100 iters), loss = 0.385603
I1211 19:41:57.885208 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:41:57.885208 20404 solver.cpp:237]     Train net output #1: loss = 0.385603 (* 1 = 0.385603 loss)
I1211 19:41:57.885208 20404 sgd_solver.cpp:105] Iteration 45300, lr = 0.1
I1211 19:42:05.813992 20404 solver.cpp:218] Iteration 45400 (12.6121 iter/s, 7.92887s/100 iters), loss = 0.459167
I1211 19:42:05.813992 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:42:05.813992 20404 solver.cpp:237]     Train net output #1: loss = 0.459167 (* 1 = 0.459167 loss)
I1211 19:42:05.813992 20404 sgd_solver.cpp:105] Iteration 45400, lr = 0.1
I1211 19:42:13.361706  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:42:13.675739 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_45500.caffemodel
I1211 19:42:13.703738 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_45500.solverstate
I1211 19:42:13.709739 20404 solver.cpp:330] Iteration 45500, Testing net (#0)
I1211 19:42:13.709739 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:42:15.376974  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:42:15.442996 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7687
I1211 19:42:15.442996 20404 solver.cpp:397]     Test net output #1: loss = 0.690782 (* 1 = 0.690782 loss)
I1211 19:42:15.516995 20404 solver.cpp:218] Iteration 45500 (10.3069 iter/s, 9.70223s/100 iters), loss = 0.374332
I1211 19:42:15.516995 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:42:15.516995 20404 solver.cpp:237]     Train net output #1: loss = 0.374332 (* 1 = 0.374332 loss)
I1211 19:42:15.516995 20404 sgd_solver.cpp:105] Iteration 45500, lr = 0.1
I1211 19:42:23.459856 20404 solver.cpp:218] Iteration 45600 (12.5904 iter/s, 7.94256s/100 iters), loss = 0.291034
I1211 19:42:23.459856 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:42:23.459856 20404 solver.cpp:237]     Train net output #1: loss = 0.291035 (* 1 = 0.291035 loss)
I1211 19:42:23.459856 20404 sgd_solver.cpp:105] Iteration 45600, lr = 0.1
I1211 19:42:31.399180 20404 solver.cpp:218] Iteration 45700 (12.5959 iter/s, 7.9391s/100 iters), loss = 0.477428
I1211 19:42:31.399180 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:42:31.399180 20404 solver.cpp:237]     Train net output #1: loss = 0.477428 (* 1 = 0.477428 loss)
I1211 19:42:31.399180 20404 sgd_solver.cpp:105] Iteration 45700, lr = 0.1
I1211 19:42:39.334053 20404 solver.cpp:218] Iteration 45800 (12.6037 iter/s, 7.93415s/100 iters), loss = 0.39013
I1211 19:42:39.334053 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:42:39.334053 20404 solver.cpp:237]     Train net output #1: loss = 0.39013 (* 1 = 0.39013 loss)
I1211 19:42:39.334053 20404 sgd_solver.cpp:105] Iteration 45800, lr = 0.1
I1211 19:42:47.268280 20404 solver.cpp:218] Iteration 45900 (12.605 iter/s, 7.93339s/100 iters), loss = 0.352607
I1211 19:42:47.268280 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:42:47.268280 20404 solver.cpp:237]     Train net output #1: loss = 0.352607 (* 1 = 0.352607 loss)
I1211 19:42:47.268280 20404 sgd_solver.cpp:105] Iteration 45900, lr = 0.1
I1211 19:42:54.817620  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:42:55.131639 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_46000.caffemodel
I1211 19:42:55.182646 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_46000.solverstate
I1211 19:42:55.188647 20404 solver.cpp:330] Iteration 46000, Testing net (#0)
I1211 19:42:55.189647 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:42:56.853780  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:42:56.919801 20404 solver.cpp:397]     Test net output #0: accuracy = 0.6841
I1211 19:42:56.919801 20404 solver.cpp:397]     Test net output #1: loss = 0.955686 (* 1 = 0.955686 loss)
I1211 19:42:56.993805 20404 solver.cpp:218] Iteration 46000 (10.2822 iter/s, 9.72557s/100 iters), loss = 0.475562
I1211 19:42:56.993805 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:42:56.993805 20404 solver.cpp:237]     Train net output #1: loss = 0.475562 (* 1 = 0.475562 loss)
I1211 19:42:56.993805 20404 sgd_solver.cpp:105] Iteration 46000, lr = 0.1
I1211 19:43:04.933624 20404 solver.cpp:218] Iteration 46100 (12.5951 iter/s, 7.93961s/100 iters), loss = 0.321111
I1211 19:43:04.934625 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:43:04.934625 20404 solver.cpp:237]     Train net output #1: loss = 0.321111 (* 1 = 0.321111 loss)
I1211 19:43:04.934625 20404 sgd_solver.cpp:105] Iteration 46100, lr = 0.1
I1211 19:43:12.874884 20404 solver.cpp:218] Iteration 46200 (12.5945 iter/s, 7.93999s/100 iters), loss = 0.495646
I1211 19:43:12.874884 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:43:12.874884 20404 solver.cpp:237]     Train net output #1: loss = 0.495646 (* 1 = 0.495646 loss)
I1211 19:43:12.874884 20404 sgd_solver.cpp:105] Iteration 46200, lr = 0.1
I1211 19:43:20.809725 20404 solver.cpp:218] Iteration 46300 (12.6034 iter/s, 7.93434s/100 iters), loss = 0.608361
I1211 19:43:20.809725 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.8
I1211 19:43:20.809725 20404 solver.cpp:237]     Train net output #1: loss = 0.608362 (* 1 = 0.608362 loss)
I1211 19:43:20.809725 20404 sgd_solver.cpp:105] Iteration 46300, lr = 0.1
I1211 19:43:28.748610 20404 solver.cpp:218] Iteration 46400 (12.5963 iter/s, 7.93887s/100 iters), loss = 0.409321
I1211 19:43:28.748610 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:43:28.748610 20404 solver.cpp:237]     Train net output #1: loss = 0.409322 (* 1 = 0.409322 loss)
I1211 19:43:28.748610 20404 sgd_solver.cpp:105] Iteration 46400, lr = 0.1
I1211 19:43:36.302453  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:43:36.616472 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_46500.caffemodel
I1211 19:43:36.647471 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_46500.solverstate
I1211 19:43:36.653471 20404 solver.cpp:330] Iteration 46500, Testing net (#0)
I1211 19:43:36.653471 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:43:38.320683  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:43:38.387686 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7833
I1211 19:43:38.387686 20404 solver.cpp:397]     Test net output #1: loss = 0.627474 (* 1 = 0.627474 loss)
I1211 19:43:38.461684 20404 solver.cpp:218] Iteration 46500 (10.2957 iter/s, 9.71277s/100 iters), loss = 0.450114
I1211 19:43:38.461684 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:43:38.461684 20404 solver.cpp:237]     Train net output #1: loss = 0.450114 (* 1 = 0.450114 loss)
I1211 19:43:38.461684 20404 sgd_solver.cpp:105] Iteration 46500, lr = 0.1
I1211 19:43:46.400686 20404 solver.cpp:218] Iteration 46600 (12.5972 iter/s, 7.93827s/100 iters), loss = 0.353623
I1211 19:43:46.400686 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:43:46.400686 20404 solver.cpp:237]     Train net output #1: loss = 0.353624 (* 1 = 0.353624 loss)
I1211 19:43:46.400686 20404 sgd_solver.cpp:105] Iteration 46600, lr = 0.1
I1211 19:43:54.335388 20404 solver.cpp:218] Iteration 46700 (12.6032 iter/s, 7.93447s/100 iters), loss = 0.453646
I1211 19:43:54.335388 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:43:54.335388 20404 solver.cpp:237]     Train net output #1: loss = 0.453646 (* 1 = 0.453646 loss)
I1211 19:43:54.335388 20404 sgd_solver.cpp:105] Iteration 46700, lr = 0.1
I1211 19:44:02.263561 20404 solver.cpp:218] Iteration 46800 (12.6144 iter/s, 7.92746s/100 iters), loss = 0.438206
I1211 19:44:02.263561 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:44:02.263561 20404 solver.cpp:237]     Train net output #1: loss = 0.438206 (* 1 = 0.438206 loss)
I1211 19:44:02.263561 20404 sgd_solver.cpp:105] Iteration 46800, lr = 0.1
I1211 19:44:10.196179 20404 solver.cpp:218] Iteration 46900 (12.6064 iter/s, 7.93248s/100 iters), loss = 0.341018
I1211 19:44:10.196179 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:44:10.197180 20404 solver.cpp:237]     Train net output #1: loss = 0.341018 (* 1 = 0.341018 loss)
I1211 19:44:10.197180 20404 sgd_solver.cpp:105] Iteration 46900, lr = 0.1
I1211 19:44:17.734863  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:44:18.049919 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_47000.caffemodel
I1211 19:44:18.103935 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_47000.solverstate
I1211 19:44:18.108937 20404 solver.cpp:330] Iteration 47000, Testing net (#0)
I1211 19:44:18.108937 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:44:19.776631  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:44:19.842119 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7968
I1211 19:44:19.842119 20404 solver.cpp:397]     Test net output #1: loss = 0.623297 (* 1 = 0.623297 loss)
I1211 19:44:19.917127 20404 solver.cpp:218] Iteration 47000 (10.2883 iter/s, 9.71978s/100 iters), loss = 0.308222
I1211 19:44:19.917127 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:44:19.917127 20404 solver.cpp:237]     Train net output #1: loss = 0.308222 (* 1 = 0.308222 loss)
I1211 19:44:19.917127 20404 sgd_solver.cpp:105] Iteration 47000, lr = 0.1
I1211 19:44:27.848948 20404 solver.cpp:218] Iteration 47100 (12.6086 iter/s, 7.93112s/100 iters), loss = 0.303486
I1211 19:44:27.848948 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:44:27.848948 20404 solver.cpp:237]     Train net output #1: loss = 0.303486 (* 1 = 0.303486 loss)
I1211 19:44:27.848948 20404 sgd_solver.cpp:105] Iteration 47100, lr = 0.1
I1211 19:44:35.785985 20404 solver.cpp:218] Iteration 47200 (12.5994 iter/s, 7.93688s/100 iters), loss = 0.387101
I1211 19:44:35.785985 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:44:35.785985 20404 solver.cpp:237]     Train net output #1: loss = 0.387101 (* 1 = 0.387101 loss)
I1211 19:44:35.785985 20404 sgd_solver.cpp:105] Iteration 47200, lr = 0.1
I1211 19:44:43.715895 20404 solver.cpp:218] Iteration 47300 (12.6116 iter/s, 7.9292s/100 iters), loss = 0.401894
I1211 19:44:43.715895 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:44:43.715895 20404 solver.cpp:237]     Train net output #1: loss = 0.401894 (* 1 = 0.401894 loss)
I1211 19:44:43.715895 20404 sgd_solver.cpp:105] Iteration 47300, lr = 0.1
I1211 19:44:51.655710 20404 solver.cpp:218] Iteration 47400 (12.5955 iter/s, 7.93937s/100 iters), loss = 0.381152
I1211 19:44:51.655710 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:44:51.655710 20404 solver.cpp:237]     Train net output #1: loss = 0.381152 (* 1 = 0.381152 loss)
I1211 19:44:51.655710 20404 sgd_solver.cpp:105] Iteration 47400, lr = 0.1
I1211 19:44:59.197214  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:44:59.511751 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_47500.caffemodel
I1211 19:44:59.539752 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_47500.solverstate
I1211 19:44:59.545752 20404 solver.cpp:330] Iteration 47500, Testing net (#0)
I1211 19:44:59.545752 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:45:01.212891  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:45:01.278888 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7524
I1211 19:45:01.278888 20404 solver.cpp:397]     Test net output #1: loss = 0.75144 (* 1 = 0.75144 loss)
I1211 19:45:01.352897 20404 solver.cpp:218] Iteration 47500 (10.3126 iter/s, 9.69688s/100 iters), loss = 0.449655
I1211 19:45:01.352897 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:45:01.352897 20404 solver.cpp:237]     Train net output #1: loss = 0.449655 (* 1 = 0.449655 loss)
I1211 19:45:01.352897 20404 sgd_solver.cpp:105] Iteration 47500, lr = 0.1
I1211 19:45:09.293649 20404 solver.cpp:218] Iteration 47600 (12.5947 iter/s, 7.93985s/100 iters), loss = 0.359062
I1211 19:45:09.293649 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:45:09.293649 20404 solver.cpp:237]     Train net output #1: loss = 0.359062 (* 1 = 0.359062 loss)
I1211 19:45:09.293649 20404 sgd_solver.cpp:105] Iteration 47600, lr = 0.1
I1211 19:45:17.234513 20404 solver.cpp:218] Iteration 47700 (12.5933 iter/s, 7.94073s/100 iters), loss = 0.447014
I1211 19:45:17.234513 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:45:17.234513 20404 solver.cpp:237]     Train net output #1: loss = 0.447014 (* 1 = 0.447014 loss)
I1211 19:45:17.234513 20404 sgd_solver.cpp:105] Iteration 47700, lr = 0.1
I1211 19:45:25.173444 20404 solver.cpp:218] Iteration 47800 (12.5968 iter/s, 7.93849s/100 iters), loss = 0.438527
I1211 19:45:25.173444 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:45:25.173444 20404 solver.cpp:237]     Train net output #1: loss = 0.438527 (* 1 = 0.438527 loss)
I1211 19:45:25.173444 20404 sgd_solver.cpp:105] Iteration 47800, lr = 0.1
I1211 19:45:33.105535 20404 solver.cpp:218] Iteration 47900 (12.6082 iter/s, 7.93133s/100 iters), loss = 0.272057
I1211 19:45:33.105535 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:45:33.105535 20404 solver.cpp:237]     Train net output #1: loss = 0.272058 (* 1 = 0.272058 loss)
I1211 19:45:33.105535 20404 sgd_solver.cpp:105] Iteration 47900, lr = 0.1
I1211 19:45:40.648581  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:45:40.962613 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_48000.caffemodel
I1211 19:45:41.019649 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_48000.solverstate
I1211 19:45:41.025655 20404 solver.cpp:330] Iteration 48000, Testing net (#0)
I1211 19:45:41.025655 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:45:42.690734  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:45:42.756742 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7446
I1211 19:45:42.756742 20404 solver.cpp:397]     Test net output #1: loss = 0.762589 (* 1 = 0.762589 loss)
I1211 19:45:42.830761 20404 solver.cpp:218] Iteration 48000 (10.2822 iter/s, 9.72553s/100 iters), loss = 0.380474
I1211 19:45:42.830761 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:45:42.831763 20404 solver.cpp:237]     Train net output #1: loss = 0.380475 (* 1 = 0.380475 loss)
I1211 19:45:42.831763 20404 sgd_solver.cpp:105] Iteration 48000, lr = 0.1
I1211 19:45:50.771718 20404 solver.cpp:218] Iteration 48100 (12.5937 iter/s, 7.94051s/100 iters), loss = 0.300716
I1211 19:45:50.772718 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:45:50.772718 20404 solver.cpp:237]     Train net output #1: loss = 0.300716 (* 1 = 0.300716 loss)
I1211 19:45:50.772718 20404 sgd_solver.cpp:105] Iteration 48100, lr = 0.1
I1211 19:45:58.702088 20404 solver.cpp:218] Iteration 48200 (12.612 iter/s, 7.92893s/100 iters), loss = 0.406108
I1211 19:45:58.702088 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:45:58.702088 20404 solver.cpp:237]     Train net output #1: loss = 0.406108 (* 1 = 0.406108 loss)
I1211 19:45:58.702088 20404 sgd_solver.cpp:105] Iteration 48200, lr = 0.1
I1211 19:46:06.626211 20404 solver.cpp:218] Iteration 48300 (12.6198 iter/s, 7.92404s/100 iters), loss = 0.514053
I1211 19:46:06.626211 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I1211 19:46:06.626211 20404 solver.cpp:237]     Train net output #1: loss = 0.514053 (* 1 = 0.514053 loss)
I1211 19:46:06.626211 20404 sgd_solver.cpp:105] Iteration 48300, lr = 0.1
I1211 19:46:14.560083 20404 solver.cpp:218] Iteration 48400 (12.6055 iter/s, 7.93303s/100 iters), loss = 0.356982
I1211 19:46:14.560083 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1211 19:46:14.560083 20404 solver.cpp:237]     Train net output #1: loss = 0.356982 (* 1 = 0.356982 loss)
I1211 19:46:14.560083 20404 sgd_solver.cpp:105] Iteration 48400, lr = 0.1
I1211 19:46:22.108575  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:46:22.421108 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_48500.caffemodel
I1211 19:46:22.448107 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_48500.solverstate
I1211 19:46:22.454108 20404 solver.cpp:330] Iteration 48500, Testing net (#0)
I1211 19:46:22.454108 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:46:24.122346  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:46:24.188345 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7943
I1211 19:46:24.189347 20404 solver.cpp:397]     Test net output #1: loss = 0.591294 (* 1 = 0.591294 loss)
I1211 19:46:24.262351 20404 solver.cpp:218] Iteration 48500 (10.3069 iter/s, 9.70224s/100 iters), loss = 0.391718
I1211 19:46:24.262351 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:46:24.262351 20404 solver.cpp:237]     Train net output #1: loss = 0.391718 (* 1 = 0.391718 loss)
I1211 19:46:24.262351 20404 sgd_solver.cpp:105] Iteration 48500, lr = 0.1
I1211 19:46:32.193938 20404 solver.cpp:218] Iteration 48600 (12.6093 iter/s, 7.93068s/100 iters), loss = 0.388039
I1211 19:46:32.193938 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I1211 19:46:32.193938 20404 solver.cpp:237]     Train net output #1: loss = 0.388039 (* 1 = 0.388039 loss)
I1211 19:46:32.193938 20404 sgd_solver.cpp:105] Iteration 48600, lr = 0.1
I1211 19:46:40.132741 20404 solver.cpp:218] Iteration 48700 (12.5973 iter/s, 7.93818s/100 iters), loss = 0.465418
I1211 19:46:40.132741 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:46:40.132741 20404 solver.cpp:237]     Train net output #1: loss = 0.465418 (* 1 = 0.465418 loss)
I1211 19:46:40.132741 20404 sgd_solver.cpp:105] Iteration 48700, lr = 0.1
I1211 19:46:48.070739 20404 solver.cpp:218] Iteration 48800 (12.5984 iter/s, 7.9375s/100 iters), loss = 0.429358
I1211 19:46:48.070739 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:46:48.070739 20404 solver.cpp:237]     Train net output #1: loss = 0.429358 (* 1 = 0.429358 loss)
I1211 19:46:48.070739 20404 sgd_solver.cpp:105] Iteration 48800, lr = 0.1
I1211 19:46:56.000315 20404 solver.cpp:218] Iteration 48900 (12.6107 iter/s, 7.92976s/100 iters), loss = 0.341944
I1211 19:46:56.000315 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:46:56.000315 20404 solver.cpp:237]     Train net output #1: loss = 0.341945 (* 1 = 0.341945 loss)
I1211 19:46:56.000315 20404 sgd_solver.cpp:105] Iteration 48900, lr = 0.1
I1211 19:47:03.546072  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:47:03.861093 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_49000.caffemodel
I1211 19:47:03.891093 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_49000.solverstate
I1211 19:47:03.896093 20404 solver.cpp:330] Iteration 49000, Testing net (#0)
I1211 19:47:03.896093 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:47:05.562281  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:47:05.629287 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7242
I1211 19:47:05.629287 20404 solver.cpp:397]     Test net output #1: loss = 0.860906 (* 1 = 0.860906 loss)
I1211 19:47:05.703285 20404 solver.cpp:218] Iteration 49000 (10.3075 iter/s, 9.70171s/100 iters), loss = 0.378816
I1211 19:47:05.703285 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I1211 19:47:05.703285 20404 solver.cpp:237]     Train net output #1: loss = 0.378816 (* 1 = 0.378816 loss)
I1211 19:47:05.703285 20404 sgd_solver.cpp:105] Iteration 49000, lr = 0.1
I1211 19:47:13.637373 20404 solver.cpp:218] Iteration 49100 (12.6046 iter/s, 7.9336s/100 iters), loss = 0.328464
I1211 19:47:13.637373 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:47:13.637373 20404 solver.cpp:237]     Train net output #1: loss = 0.328464 (* 1 = 0.328464 loss)
I1211 19:47:13.637373 20404 sgd_solver.cpp:105] Iteration 49100, lr = 0.1
I1211 19:47:21.563161 20404 solver.cpp:218] Iteration 49200 (12.6178 iter/s, 7.92532s/100 iters), loss = 0.318709
I1211 19:47:21.563161 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:47:21.563161 20404 solver.cpp:237]     Train net output #1: loss = 0.318709 (* 1 = 0.318709 loss)
I1211 19:47:21.563161 20404 sgd_solver.cpp:105] Iteration 49200, lr = 0.1
I1211 19:47:29.495774 20404 solver.cpp:218] Iteration 49300 (12.6058 iter/s, 7.93283s/100 iters), loss = 0.4509
I1211 19:47:29.495774 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I1211 19:47:29.495774 20404 solver.cpp:237]     Train net output #1: loss = 0.4509 (* 1 = 0.4509 loss)
I1211 19:47:29.495774 20404 sgd_solver.cpp:105] Iteration 49300, lr = 0.1
I1211 19:47:37.427038 20404 solver.cpp:218] Iteration 49400 (12.6103 iter/s, 7.93005s/100 iters), loss = 0.441935
I1211 19:47:37.427038 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:47:37.427038 20404 solver.cpp:237]     Train net output #1: loss = 0.441935 (* 1 = 0.441935 loss)
I1211 19:47:37.427038 20404 sgd_solver.cpp:105] Iteration 49400, lr = 0.1
I1211 19:47:44.964179  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:47:45.276729 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_49500.caffemodel
I1211 19:47:45.304729 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_49500.solverstate
I1211 19:47:45.309729 20404 solver.cpp:330] Iteration 49500, Testing net (#0)
I1211 19:47:45.309729 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:47:46.974853  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:47:47.040858 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8149
I1211 19:47:47.040858 20404 solver.cpp:397]     Test net output #1: loss = 0.559546 (* 1 = 0.559546 loss)
I1211 19:47:47.115859 20404 solver.cpp:218] Iteration 49500 (10.3215 iter/s, 9.68848s/100 iters), loss = 0.302868
I1211 19:47:47.115859 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:47:47.115859 20404 solver.cpp:237]     Train net output #1: loss = 0.302868 (* 1 = 0.302868 loss)
I1211 19:47:47.115859 20404 sgd_solver.cpp:105] Iteration 49500, lr = 0.1
I1211 19:47:55.046203 20404 solver.cpp:218] Iteration 49600 (12.6107 iter/s, 7.92979s/100 iters), loss = 0.33176
I1211 19:47:55.046203 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I1211 19:47:55.046203 20404 solver.cpp:237]     Train net output #1: loss = 0.33176 (* 1 = 0.33176 loss)
I1211 19:47:55.046203 20404 sgd_solver.cpp:105] Iteration 49600, lr = 0.1
I1211 19:48:02.980999 20404 solver.cpp:218] Iteration 49700 (12.6028 iter/s, 7.93475s/100 iters), loss = 0.482091
I1211 19:48:02.980999 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:48:02.980999 20404 solver.cpp:237]     Train net output #1: loss = 0.482091 (* 1 = 0.482091 loss)
I1211 19:48:02.980999 20404 sgd_solver.cpp:105] Iteration 49700, lr = 0.1
I1211 19:48:10.917862 20404 solver.cpp:218] Iteration 49800 (12.6005 iter/s, 7.93616s/100 iters), loss = 0.435283
I1211 19:48:10.917862 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I1211 19:48:10.917862 20404 solver.cpp:237]     Train net output #1: loss = 0.435283 (* 1 = 0.435283 loss)
I1211 19:48:10.917862 20404 sgd_solver.cpp:105] Iteration 49800, lr = 0.1
I1211 19:48:18.861181 20404 solver.cpp:218] Iteration 49900 (12.5905 iter/s, 7.94251s/100 iters), loss = 0.333628
I1211 19:48:18.861181 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 19:48:18.861181 20404 solver.cpp:237]     Train net output #1: loss = 0.333628 (* 1 = 0.333628 loss)
I1211 19:48:18.861181 20404 sgd_solver.cpp:105] Iteration 49900, lr = 0.1
I1211 19:48:26.407475  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:48:26.721495 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_50000.caffemodel
I1211 19:48:26.795516 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_50000.solverstate
I1211 19:48:26.801517 20404 solver.cpp:330] Iteration 50000, Testing net (#0)
I1211 19:48:26.801517 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:48:28.472721  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:48:28.539726 20404 solver.cpp:397]     Test net output #0: accuracy = 0.7663
I1211 19:48:28.540225 20404 solver.cpp:397]     Test net output #1: loss = 0.689051 (* 1 = 0.689051 loss)
I1211 19:48:28.613729 20404 solver.cpp:218] Iteration 50000 (10.2541 iter/s, 9.75222s/100 iters), loss = 0.477946
I1211 19:48:28.613729 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.83
I1211 19:48:28.613729 20404 solver.cpp:237]     Train net output #1: loss = 0.477946 (* 1 = 0.477946 loss)
I1211 19:48:28.613729 20404 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1211 19:48:28.613729 20404 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1211 19:48:36.546636 20404 solver.cpp:218] Iteration 50100 (12.6063 iter/s, 7.93252s/100 iters), loss = 0.22911
I1211 19:48:36.546636 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:48:36.546636 20404 solver.cpp:237]     Train net output #1: loss = 0.22911 (* 1 = 0.22911 loss)
I1211 19:48:36.546636 20404 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1211 19:48:44.478524 20404 solver.cpp:218] Iteration 50200 (12.6078 iter/s, 7.93162s/100 iters), loss = 0.260713
I1211 19:48:44.478524 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:48:44.478524 20404 solver.cpp:237]     Train net output #1: loss = 0.260713 (* 1 = 0.260713 loss)
I1211 19:48:44.478524 20404 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1211 19:48:52.415485 20404 solver.cpp:218] Iteration 50300 (12.6004 iter/s, 7.93623s/100 iters), loss = 0.242029
I1211 19:48:52.415485 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:48:52.415485 20404 solver.cpp:237]     Train net output #1: loss = 0.242029 (* 1 = 0.242029 loss)
I1211 19:48:52.415485 20404 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1211 19:49:00.353440 20404 solver.cpp:218] Iteration 50400 (12.5978 iter/s, 7.93792s/100 iters), loss = 0.234278
I1211 19:49:00.353440 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:49:00.353440 20404 solver.cpp:237]     Train net output #1: loss = 0.234278 (* 1 = 0.234278 loss)
I1211 19:49:00.353440 20404 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1211 19:49:07.904263  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:49:08.217290 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_50500.caffemodel
I1211 19:49:08.248293 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_50500.solverstate
I1211 19:49:08.255306 20404 solver.cpp:330] Iteration 50500, Testing net (#0)
I1211 19:49:08.255306 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:49:09.923437  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:49:09.989441 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8555
I1211 19:49:09.989441 20404 solver.cpp:397]     Test net output #1: loss = 0.447404 (* 1 = 0.447404 loss)
I1211 19:49:10.064446 20404 solver.cpp:218] Iteration 50500 (10.299 iter/s, 9.70967s/100 iters), loss = 0.216631
I1211 19:49:10.064446 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:49:10.064446 20404 solver.cpp:237]     Train net output #1: loss = 0.216631 (* 1 = 0.216631 loss)
I1211 19:49:10.064446 20404 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1211 19:49:17.999593 20404 solver.cpp:218] Iteration 50600 (12.6032 iter/s, 7.93451s/100 iters), loss = 0.205876
I1211 19:49:17.999593 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:49:17.999593 20404 solver.cpp:237]     Train net output #1: loss = 0.205876 (* 1 = 0.205876 loss)
I1211 19:49:17.999593 20404 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1211 19:49:25.937647 20404 solver.cpp:218] Iteration 50700 (12.5981 iter/s, 7.93768s/100 iters), loss = 0.29617
I1211 19:49:25.937647 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:49:25.937647 20404 solver.cpp:237]     Train net output #1: loss = 0.29617 (* 1 = 0.29617 loss)
I1211 19:49:25.937647 20404 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1211 19:49:33.868441 20404 solver.cpp:218] Iteration 50800 (12.6102 iter/s, 7.93007s/100 iters), loss = 0.237036
I1211 19:49:33.868441 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:49:33.868441 20404 solver.cpp:237]     Train net output #1: loss = 0.237036 (* 1 = 0.237036 loss)
I1211 19:49:33.868441 20404 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1211 19:49:41.797757 20404 solver.cpp:218] Iteration 50900 (12.6118 iter/s, 7.92907s/100 iters), loss = 0.169446
I1211 19:49:41.797757 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:49:41.798257 20404 solver.cpp:237]     Train net output #1: loss = 0.169446 (* 1 = 0.169446 loss)
I1211 19:49:41.798257 20404 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1211 19:49:49.340706  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:49:49.652726 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_51000.caffemodel
I1211 19:49:49.709391 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_51000.solverstate
I1211 19:49:49.715391 20404 solver.cpp:330] Iteration 51000, Testing net (#0)
I1211 19:49:49.715391 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:49:51.378476  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:49:51.444473 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8363
I1211 19:49:51.444473 20404 solver.cpp:397]     Test net output #1: loss = 0.504961 (* 1 = 0.504961 loss)
I1211 19:49:51.518035 20404 solver.cpp:218] Iteration 51000 (10.2882 iter/s, 9.71989s/100 iters), loss = 0.167573
I1211 19:49:51.518035 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:49:51.518035 20404 solver.cpp:237]     Train net output #1: loss = 0.167573 (* 1 = 0.167573 loss)
I1211 19:49:51.518035 20404 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1211 19:49:59.453275 20404 solver.cpp:218] Iteration 51100 (12.6028 iter/s, 7.93474s/100 iters), loss = 0.197578
I1211 19:49:59.453275 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:49:59.453275 20404 solver.cpp:237]     Train net output #1: loss = 0.197578 (* 1 = 0.197578 loss)
I1211 19:49:59.453275 20404 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1211 19:50:07.391284 20404 solver.cpp:218] Iteration 51200 (12.5988 iter/s, 7.93725s/100 iters), loss = 0.252446
I1211 19:50:07.391284 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:50:07.391284 20404 solver.cpp:237]     Train net output #1: loss = 0.252446 (* 1 = 0.252446 loss)
I1211 19:50:07.391284 20404 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1211 19:50:15.335850 20404 solver.cpp:218] Iteration 51300 (12.5873 iter/s, 7.94451s/100 iters), loss = 0.231345
I1211 19:50:15.335850 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:50:15.335850 20404 solver.cpp:237]     Train net output #1: loss = 0.231345 (* 1 = 0.231345 loss)
I1211 19:50:15.335850 20404 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1211 19:50:23.268573 20404 solver.cpp:218] Iteration 51400 (12.6079 iter/s, 7.93154s/100 iters), loss = 0.142586
I1211 19:50:23.268573 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:50:23.268573 20404 solver.cpp:237]     Train net output #1: loss = 0.142586 (* 1 = 0.142586 loss)
I1211 19:50:23.268573 20404 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1211 19:50:30.819326  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:50:31.131346 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_51500.caffemodel
I1211 19:50:31.164345 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_51500.solverstate
I1211 19:50:31.170351 20404 solver.cpp:330] Iteration 51500, Testing net (#0)
I1211 19:50:31.170850 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:50:32.837571  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:50:32.903218 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8275
I1211 19:50:32.904206 20404 solver.cpp:397]     Test net output #1: loss = 0.533012 (* 1 = 0.533012 loss)
I1211 19:50:32.977737 20404 solver.cpp:218] Iteration 51500 (10.2999 iter/s, 9.70887s/100 iters), loss = 0.182649
I1211 19:50:32.977737 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:50:32.977737 20404 solver.cpp:237]     Train net output #1: loss = 0.182649 (* 1 = 0.182649 loss)
I1211 19:50:32.977737 20404 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1211 19:50:40.910336 20404 solver.cpp:218] Iteration 51600 (12.6074 iter/s, 7.93186s/100 iters), loss = 0.193763
I1211 19:50:40.910336 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:50:40.910336 20404 solver.cpp:237]     Train net output #1: loss = 0.193763 (* 1 = 0.193763 loss)
I1211 19:50:40.910336 20404 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1211 19:50:48.836681 20404 solver.cpp:218] Iteration 51700 (12.6161 iter/s, 7.92639s/100 iters), loss = 0.228797
I1211 19:50:48.836681 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:50:48.836681 20404 solver.cpp:237]     Train net output #1: loss = 0.228797 (* 1 = 0.228797 loss)
I1211 19:50:48.836681 20404 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1211 19:50:56.782510 20404 solver.cpp:218] Iteration 51800 (12.5863 iter/s, 7.94512s/100 iters), loss = 0.207868
I1211 19:50:56.782510 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:50:56.782510 20404 solver.cpp:237]     Train net output #1: loss = 0.207869 (* 1 = 0.207869 loss)
I1211 19:50:56.782510 20404 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1211 19:51:04.719004 20404 solver.cpp:218] Iteration 51900 (12.601 iter/s, 7.93591s/100 iters), loss = 0.108987
I1211 19:51:04.719004 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:51:04.719004 20404 solver.cpp:237]     Train net output #1: loss = 0.108987 (* 1 = 0.108987 loss)
I1211 19:51:04.719004 20404 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1211 19:51:12.264817  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:51:12.578351 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_52000.caffemodel
I1211 19:51:12.636867 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_52000.solverstate
I1211 19:51:12.642868 20404 solver.cpp:330] Iteration 52000, Testing net (#0)
I1211 19:51:12.642868 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:51:14.307993  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:51:14.374992 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8209
I1211 19:51:14.374992 20404 solver.cpp:397]     Test net output #1: loss = 0.540772 (* 1 = 0.540772 loss)
I1211 19:51:14.450007 20404 solver.cpp:218] Iteration 52000 (10.2771 iter/s, 9.73034s/100 iters), loss = 0.160357
I1211 19:51:14.450007 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:51:14.450007 20404 solver.cpp:237]     Train net output #1: loss = 0.160357 (* 1 = 0.160357 loss)
I1211 19:51:14.450007 20404 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1211 19:51:22.381741 20404 solver.cpp:218] Iteration 52100 (12.6078 iter/s, 7.93162s/100 iters), loss = 0.192319
I1211 19:51:22.382241 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:51:22.382241 20404 solver.cpp:237]     Train net output #1: loss = 0.192319 (* 1 = 0.192319 loss)
I1211 19:51:22.382241 20404 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1211 19:51:30.311106 20404 solver.cpp:218] Iteration 52200 (12.6116 iter/s, 7.92923s/100 iters), loss = 0.23543
I1211 19:51:30.311106 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 19:51:30.311106 20404 solver.cpp:237]     Train net output #1: loss = 0.23543 (* 1 = 0.23543 loss)
I1211 19:51:30.311106 20404 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1211 19:51:38.241544 20404 solver.cpp:218] Iteration 52300 (12.6109 iter/s, 7.92965s/100 iters), loss = 0.147185
I1211 19:51:38.241544 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:51:38.241544 20404 solver.cpp:237]     Train net output #1: loss = 0.147185 (* 1 = 0.147185 loss)
I1211 19:51:38.241544 20404 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1211 19:51:46.179322 20404 solver.cpp:218] Iteration 52400 (12.5984 iter/s, 7.93751s/100 iters), loss = 0.117832
I1211 19:51:46.179322 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:51:46.179322 20404 solver.cpp:237]     Train net output #1: loss = 0.117832 (* 1 = 0.117832 loss)
I1211 19:51:46.179322 20404 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1211 19:51:53.725968  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:51:54.039019 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_52500.caffemodel
I1211 19:51:54.067023 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_52500.solverstate
I1211 19:51:54.072023 20404 solver.cpp:330] Iteration 52500, Testing net (#0)
I1211 19:51:54.073024 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:51:55.738684  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:51:55.804195 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8338
I1211 19:51:55.804195 20404 solver.cpp:397]     Test net output #1: loss = 0.508569 (* 1 = 0.508569 loss)
I1211 19:51:55.878202 20404 solver.cpp:218] Iteration 52500 (10.3112 iter/s, 9.69823s/100 iters), loss = 0.184991
I1211 19:51:55.878202 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:51:55.878202 20404 solver.cpp:237]     Train net output #1: loss = 0.184991 (* 1 = 0.184991 loss)
I1211 19:51:55.878202 20404 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1211 19:52:03.813097 20404 solver.cpp:218] Iteration 52600 (12.6036 iter/s, 7.93427s/100 iters), loss = 0.173526
I1211 19:52:03.813097 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:52:03.813097 20404 solver.cpp:237]     Train net output #1: loss = 0.173526 (* 1 = 0.173526 loss)
I1211 19:52:03.813097 20404 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1211 19:52:11.734946 20404 solver.cpp:218] Iteration 52700 (12.6247 iter/s, 7.92099s/100 iters), loss = 0.16427
I1211 19:52:11.734946 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:52:11.734946 20404 solver.cpp:237]     Train net output #1: loss = 0.16427 (* 1 = 0.16427 loss)
I1211 19:52:11.734946 20404 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1211 19:52:19.666299 20404 solver.cpp:218] Iteration 52800 (12.608 iter/s, 7.93147s/100 iters), loss = 0.145783
I1211 19:52:19.666299 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:52:19.666299 20404 solver.cpp:237]     Train net output #1: loss = 0.145783 (* 1 = 0.145783 loss)
I1211 19:52:19.666299 20404 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1211 19:52:27.592975 20404 solver.cpp:218] Iteration 52900 (12.6164 iter/s, 7.9262s/100 iters), loss = 0.0981042
I1211 19:52:27.592975 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:52:27.592975 20404 solver.cpp:237]     Train net output #1: loss = 0.0981042 (* 1 = 0.0981042 loss)
I1211 19:52:27.593977 20404 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1211 19:52:35.134135  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:52:35.447170 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_53000.caffemodel
I1211 19:52:35.504171 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_53000.solverstate
I1211 19:52:35.510172 20404 solver.cpp:330] Iteration 53000, Testing net (#0)
I1211 19:52:35.510172 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:52:37.174438  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:52:37.241942 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8434
I1211 19:52:37.241942 20404 solver.cpp:397]     Test net output #1: loss = 0.476971 (* 1 = 0.476971 loss)
I1211 19:52:37.316452 20404 solver.cpp:218] Iteration 53000 (10.2857 iter/s, 9.72227s/100 iters), loss = 0.15656
I1211 19:52:37.316452 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:52:37.316452 20404 solver.cpp:237]     Train net output #1: loss = 0.15656 (* 1 = 0.15656 loss)
I1211 19:52:37.316452 20404 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1211 19:52:45.247704 20404 solver.cpp:218] Iteration 53100 (12.6091 iter/s, 7.93075s/100 iters), loss = 0.158984
I1211 19:52:45.247704 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:52:45.247704 20404 solver.cpp:237]     Train net output #1: loss = 0.158984 (* 1 = 0.158984 loss)
I1211 19:52:45.247704 20404 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1211 19:52:53.173960 20404 solver.cpp:218] Iteration 53200 (12.617 iter/s, 7.92582s/100 iters), loss = 0.180964
I1211 19:52:53.173960 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:52:53.173960 20404 solver.cpp:237]     Train net output #1: loss = 0.180964 (* 1 = 0.180964 loss)
I1211 19:52:53.173960 20404 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1211 19:53:01.099345 20404 solver.cpp:218] Iteration 53300 (12.6186 iter/s, 7.92479s/100 iters), loss = 0.130466
I1211 19:53:01.099345 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:53:01.099345 20404 solver.cpp:237]     Train net output #1: loss = 0.130466 (* 1 = 0.130466 loss)
I1211 19:53:01.099345 20404 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1211 19:53:09.031582 20404 solver.cpp:218] Iteration 53400 (12.6078 iter/s, 7.93159s/100 iters), loss = 0.104892
I1211 19:53:09.031582 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:53:09.031582 20404 solver.cpp:237]     Train net output #1: loss = 0.104892 (* 1 = 0.104892 loss)
I1211 19:53:09.031582 20404 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1211 19:53:16.573263  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:53:16.886286 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_53500.caffemodel
I1211 19:53:16.914286 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_53500.solverstate
I1211 19:53:16.920287 20404 solver.cpp:330] Iteration 53500, Testing net (#0)
I1211 19:53:16.920287 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:53:18.586513  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:53:18.653012 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8312
I1211 19:53:18.653514 20404 solver.cpp:397]     Test net output #1: loss = 0.503568 (* 1 = 0.503568 loss)
I1211 19:53:18.727525 20404 solver.cpp:218] Iteration 53500 (10.3141 iter/s, 9.69542s/100 iters), loss = 0.0883501
I1211 19:53:18.727525 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:53:18.727525 20404 solver.cpp:237]     Train net output #1: loss = 0.0883501 (* 1 = 0.0883501 loss)
I1211 19:53:18.727525 20404 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1211 19:53:26.664098 20404 solver.cpp:218] Iteration 53600 (12.6004 iter/s, 7.93629s/100 iters), loss = 0.192129
I1211 19:53:26.664098 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:53:26.664098 20404 solver.cpp:237]     Train net output #1: loss = 0.192129 (* 1 = 0.192129 loss)
I1211 19:53:26.664098 20404 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1211 19:53:34.586982 20404 solver.cpp:218] Iteration 53700 (12.6224 iter/s, 7.92245s/100 iters), loss = 0.188279
I1211 19:53:34.586982 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:53:34.586982 20404 solver.cpp:237]     Train net output #1: loss = 0.188279 (* 1 = 0.188279 loss)
I1211 19:53:34.586982 20404 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1211 19:53:42.519619 20404 solver.cpp:218] Iteration 53800 (12.6074 iter/s, 7.93182s/100 iters), loss = 0.161477
I1211 19:53:42.519619 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:53:42.519619 20404 solver.cpp:237]     Train net output #1: loss = 0.161478 (* 1 = 0.161478 loss)
I1211 19:53:42.519619 20404 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1211 19:53:50.446741 20404 solver.cpp:218] Iteration 53900 (12.6152 iter/s, 7.92697s/100 iters), loss = 0.129074
I1211 19:53:50.446741 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:53:50.446741 20404 solver.cpp:237]     Train net output #1: loss = 0.129074 (* 1 = 0.129074 loss)
I1211 19:53:50.446741 20404 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1211 19:53:57.979532  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:53:58.294574 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_54000.caffemodel
I1211 19:53:58.344573 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_54000.solverstate
I1211 19:53:58.350584 20404 solver.cpp:330] Iteration 54000, Testing net (#0)
I1211 19:53:58.350584 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:54:00.018740  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:54:00.084764 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8478
I1211 19:54:00.084764 20404 solver.cpp:397]     Test net output #1: loss = 0.449971 (* 1 = 0.449971 loss)
I1211 19:54:00.159251 20404 solver.cpp:218] Iteration 54000 (10.2969 iter/s, 9.71164s/100 iters), loss = 0.125002
I1211 19:54:00.159251 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:54:00.159251 20404 solver.cpp:237]     Train net output #1: loss = 0.125002 (* 1 = 0.125002 loss)
I1211 19:54:00.159251 20404 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1211 19:54:08.097908 20404 solver.cpp:218] Iteration 54100 (12.5968 iter/s, 7.93854s/100 iters), loss = 0.118818
I1211 19:54:08.097908 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:54:08.097908 20404 solver.cpp:237]     Train net output #1: loss = 0.118818 (* 1 = 0.118818 loss)
I1211 19:54:08.097908 20404 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1211 19:54:16.029810 20404 solver.cpp:218] Iteration 54200 (12.6088 iter/s, 7.93097s/100 iters), loss = 0.220578
I1211 19:54:16.029810 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:54:16.029810 20404 solver.cpp:237]     Train net output #1: loss = 0.220578 (* 1 = 0.220578 loss)
I1211 19:54:16.029810 20404 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1211 19:54:23.957962 20404 solver.cpp:218] Iteration 54300 (12.6138 iter/s, 7.92783s/100 iters), loss = 0.117899
I1211 19:54:23.957962 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:54:23.957962 20404 solver.cpp:237]     Train net output #1: loss = 0.117899 (* 1 = 0.117899 loss)
I1211 19:54:23.957962 20404 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1211 19:54:31.890432 20404 solver.cpp:218] Iteration 54400 (12.6067 iter/s, 7.93226s/100 iters), loss = 0.108039
I1211 19:54:31.890432 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:54:31.890432 20404 solver.cpp:237]     Train net output #1: loss = 0.108039 (* 1 = 0.108039 loss)
I1211 19:54:31.890432 20404 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1211 19:54:39.443176  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:54:39.757840 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_54500.caffemodel
I1211 19:54:39.784382 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_54500.solverstate
I1211 19:54:39.789397 20404 solver.cpp:330] Iteration 54500, Testing net (#0)
I1211 19:54:39.790382 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:54:41.455693  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:54:41.520771 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8475
I1211 19:54:41.520771 20404 solver.cpp:397]     Test net output #1: loss = 0.458162 (* 1 = 0.458162 loss)
I1211 19:54:41.595275 20404 solver.cpp:218] Iteration 54500 (10.3051 iter/s, 9.70394s/100 iters), loss = 0.0903706
I1211 19:54:41.595275 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:54:41.595275 20404 solver.cpp:237]     Train net output #1: loss = 0.0903707 (* 1 = 0.0903707 loss)
I1211 19:54:41.595275 20404 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1211 19:54:49.520428 20404 solver.cpp:218] Iteration 54600 (12.6185 iter/s, 7.92489s/100 iters), loss = 0.111394
I1211 19:54:49.520428 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:54:49.520428 20404 solver.cpp:237]     Train net output #1: loss = 0.111394 (* 1 = 0.111394 loss)
I1211 19:54:49.520428 20404 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1211 19:54:57.454186 20404 solver.cpp:218] Iteration 54700 (12.605 iter/s, 7.93334s/100 iters), loss = 0.166889
I1211 19:54:57.454687 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:54:57.454687 20404 solver.cpp:237]     Train net output #1: loss = 0.166889 (* 1 = 0.166889 loss)
I1211 19:54:57.454687 20404 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1211 19:55:05.380054 20404 solver.cpp:218] Iteration 54800 (12.6175 iter/s, 7.92551s/100 iters), loss = 0.134498
I1211 19:55:05.380054 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:55:05.380054 20404 solver.cpp:237]     Train net output #1: loss = 0.134498 (* 1 = 0.134498 loss)
I1211 19:55:05.380054 20404 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1211 19:55:13.324976 20404 solver.cpp:218] Iteration 54900 (12.5873 iter/s, 7.94451s/100 iters), loss = 0.105052
I1211 19:55:13.324976 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:55:13.324976 20404 solver.cpp:237]     Train net output #1: loss = 0.105052 (* 1 = 0.105052 loss)
I1211 19:55:13.324976 20404 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1211 19:55:20.875721  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:55:21.190754 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_55000.caffemodel
I1211 19:55:21.245754 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_55000.solverstate
I1211 19:55:21.252262 20404 solver.cpp:330] Iteration 55000, Testing net (#0)
I1211 19:55:21.252262 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:55:22.918045  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:55:22.984086 20404 solver.cpp:397]     Test net output #0: accuracy = 0.867
I1211 19:55:22.984086 20404 solver.cpp:397]     Test net output #1: loss = 0.389677 (* 1 = 0.389677 loss)
I1211 19:55:23.058569 20404 solver.cpp:218] Iteration 55000 (10.2748 iter/s, 9.73251s/100 iters), loss = 0.135384
I1211 19:55:23.058569 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:55:23.058569 20404 solver.cpp:237]     Train net output #1: loss = 0.135384 (* 1 = 0.135384 loss)
I1211 19:55:23.058569 20404 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1211 19:55:30.989892 20404 solver.cpp:218] Iteration 55100 (12.6078 iter/s, 7.93162s/100 iters), loss = 0.118777
I1211 19:55:30.989892 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:55:30.989892 20404 solver.cpp:237]     Train net output #1: loss = 0.118777 (* 1 = 0.118777 loss)
I1211 19:55:30.989892 20404 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1211 19:55:38.918913 20404 solver.cpp:218] Iteration 55200 (12.6126 iter/s, 7.92856s/100 iters), loss = 0.18535
I1211 19:55:38.918913 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 19:55:38.918913 20404 solver.cpp:237]     Train net output #1: loss = 0.18535 (* 1 = 0.18535 loss)
I1211 19:55:38.918913 20404 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1211 19:55:46.854734 20404 solver.cpp:218] Iteration 55300 (12.6021 iter/s, 7.93518s/100 iters), loss = 0.108728
I1211 19:55:46.854734 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:55:46.854734 20404 solver.cpp:237]     Train net output #1: loss = 0.108728 (* 1 = 0.108728 loss)
I1211 19:55:46.854734 20404 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1211 19:55:54.782645 20404 solver.cpp:218] Iteration 55400 (12.6151 iter/s, 7.92698s/100 iters), loss = 0.120289
I1211 19:55:54.782645 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:55:54.782645 20404 solver.cpp:237]     Train net output #1: loss = 0.120289 (* 1 = 0.120289 loss)
I1211 19:55:54.782645 20404 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1211 19:56:02.331390  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:56:02.646422 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_55500.caffemodel
I1211 19:56:02.681428 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_55500.solverstate
I1211 19:56:02.688428 20404 solver.cpp:330] Iteration 55500, Testing net (#0)
I1211 19:56:02.688428 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:56:04.353662  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:56:04.419664 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8618
I1211 19:56:04.419664 20404 solver.cpp:397]     Test net output #1: loss = 0.410337 (* 1 = 0.410337 loss)
I1211 19:56:04.494670 20404 solver.cpp:218] Iteration 55500 (10.2973 iter/s, 9.71132s/100 iters), loss = 0.139299
I1211 19:56:04.494670 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:56:04.494670 20404 solver.cpp:237]     Train net output #1: loss = 0.139299 (* 1 = 0.139299 loss)
I1211 19:56:04.494670 20404 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1211 19:56:12.429765 20404 solver.cpp:218] Iteration 55600 (12.6024 iter/s, 7.93498s/100 iters), loss = 0.132117
I1211 19:56:12.429765 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:56:12.429765 20404 solver.cpp:237]     Train net output #1: loss = 0.132117 (* 1 = 0.132117 loss)
I1211 19:56:12.429765 20404 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1211 19:56:20.352728 20404 solver.cpp:218] Iteration 55700 (12.6217 iter/s, 7.92289s/100 iters), loss = 0.151233
I1211 19:56:20.352728 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:56:20.352728 20404 solver.cpp:237]     Train net output #1: loss = 0.151233 (* 1 = 0.151233 loss)
I1211 19:56:20.352728 20404 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1211 19:56:28.285428 20404 solver.cpp:218] Iteration 55800 (12.6077 iter/s, 7.93166s/100 iters), loss = 0.0896408
I1211 19:56:28.285428 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:56:28.285428 20404 solver.cpp:237]     Train net output #1: loss = 0.0896409 (* 1 = 0.0896409 loss)
I1211 19:56:28.285428 20404 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1211 19:56:36.214114 20404 solver.cpp:218] Iteration 55900 (12.6136 iter/s, 7.92795s/100 iters), loss = 0.0963943
I1211 19:56:36.214114 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:56:36.214114 20404 solver.cpp:237]     Train net output #1: loss = 0.0963945 (* 1 = 0.0963945 loss)
I1211 19:56:36.214114 20404 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1211 19:56:43.752794  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:56:44.065838 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_56000.caffemodel
I1211 19:56:44.124873 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_56000.solverstate
I1211 19:56:44.131902 20404 solver.cpp:330] Iteration 56000, Testing net (#0)
I1211 19:56:44.131902 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:56:45.797252  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:56:45.863255 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8696
I1211 19:56:45.863255 20404 solver.cpp:397]     Test net output #1: loss = 0.386179 (* 1 = 0.386179 loss)
I1211 19:56:45.937260 20404 solver.cpp:218] Iteration 56000 (10.2846 iter/s, 9.72329s/100 iters), loss = 0.0833599
I1211 19:56:45.937260 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:56:45.937260 20404 solver.cpp:237]     Train net output #1: loss = 0.0833601 (* 1 = 0.0833601 loss)
I1211 19:56:45.937260 20404 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1211 19:56:53.873082 20404 solver.cpp:218] Iteration 56100 (12.6023 iter/s, 7.93509s/100 iters), loss = 0.13211
I1211 19:56:53.873082 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:56:53.873082 20404 solver.cpp:237]     Train net output #1: loss = 0.13211 (* 1 = 0.13211 loss)
I1211 19:56:53.873082 20404 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1211 19:57:01.801939 20404 solver.cpp:218] Iteration 56200 (12.613 iter/s, 7.9283s/100 iters), loss = 0.175881
I1211 19:57:01.801939 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:57:01.801939 20404 solver.cpp:237]     Train net output #1: loss = 0.175881 (* 1 = 0.175881 loss)
I1211 19:57:01.801939 20404 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1211 19:57:09.732203 20404 solver.cpp:218] Iteration 56300 (12.6103 iter/s, 7.93001s/100 iters), loss = 0.104954
I1211 19:57:09.732203 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:57:09.732203 20404 solver.cpp:237]     Train net output #1: loss = 0.104954 (* 1 = 0.104954 loss)
I1211 19:57:09.732203 20404 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1211 19:57:17.661056 20404 solver.cpp:218] Iteration 56400 (12.6128 iter/s, 7.92844s/100 iters), loss = 0.103623
I1211 19:57:17.661056 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:57:17.661056 20404 solver.cpp:237]     Train net output #1: loss = 0.103623 (* 1 = 0.103623 loss)
I1211 19:57:17.661056 20404 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1211 19:57:25.206351  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:57:25.520871 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_56500.caffemodel
I1211 19:57:25.547875 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_56500.solverstate
I1211 19:57:25.553876 20404 solver.cpp:330] Iteration 56500, Testing net (#0)
I1211 19:57:25.553876 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:57:27.223513  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:57:27.289511 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8686
I1211 19:57:27.289511 20404 solver.cpp:397]     Test net output #1: loss = 0.402891 (* 1 = 0.402891 loss)
I1211 19:57:27.364516 20404 solver.cpp:218] Iteration 56500 (10.3064 iter/s, 9.70272s/100 iters), loss = 0.0821003
I1211 19:57:27.364516 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:57:27.364516 20404 solver.cpp:237]     Train net output #1: loss = 0.0821005 (* 1 = 0.0821005 loss)
I1211 19:57:27.364516 20404 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1211 19:57:35.293187 20404 solver.cpp:218] Iteration 56600 (12.6139 iter/s, 7.92779s/100 iters), loss = 0.138763
I1211 19:57:35.293187 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 19:57:35.293187 20404 solver.cpp:237]     Train net output #1: loss = 0.138763 (* 1 = 0.138763 loss)
I1211 19:57:35.293187 20404 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1211 19:57:43.222496 20404 solver.cpp:218] Iteration 56700 (12.6114 iter/s, 7.92933s/100 iters), loss = 0.167068
I1211 19:57:43.222496 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:57:43.222496 20404 solver.cpp:237]     Train net output #1: loss = 0.167068 (* 1 = 0.167068 loss)
I1211 19:57:43.222496 20404 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1211 19:57:51.153242 20404 solver.cpp:218] Iteration 56800 (12.6106 iter/s, 7.92982s/100 iters), loss = 0.122753
I1211 19:57:51.153242 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:57:51.153242 20404 solver.cpp:237]     Train net output #1: loss = 0.122753 (* 1 = 0.122753 loss)
I1211 19:57:51.153242 20404 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1211 19:57:59.085137 20404 solver.cpp:218] Iteration 56900 (12.6081 iter/s, 7.93144s/100 iters), loss = 0.137641
I1211 19:57:59.085137 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:57:59.085137 20404 solver.cpp:237]     Train net output #1: loss = 0.137641 (* 1 = 0.137641 loss)
I1211 19:57:59.085137 20404 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1211 19:58:06.621846  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:58:06.935881 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_57000.caffemodel
I1211 19:58:06.993880 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_57000.solverstate
I1211 19:58:07.000887 20404 solver.cpp:330] Iteration 57000, Testing net (#0)
I1211 19:58:07.000887 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:58:08.669101  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:58:08.735106 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8742
I1211 19:58:08.735106 20404 solver.cpp:397]     Test net output #1: loss = 0.371936 (* 1 = 0.371936 loss)
I1211 19:58:08.809110 20404 solver.cpp:218] Iteration 57000 (10.2846 iter/s, 9.72329s/100 iters), loss = 0.189259
I1211 19:58:08.809110 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:58:08.809110 20404 solver.cpp:237]     Train net output #1: loss = 0.189259 (* 1 = 0.189259 loss)
I1211 19:58:08.809110 20404 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1211 19:58:16.737192 20404 solver.cpp:218] Iteration 57100 (12.6133 iter/s, 7.92812s/100 iters), loss = 0.107603
I1211 19:58:16.737192 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:58:16.737192 20404 solver.cpp:237]     Train net output #1: loss = 0.107603 (* 1 = 0.107603 loss)
I1211 19:58:16.737192 20404 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1211 19:58:24.669097 20404 solver.cpp:218] Iteration 57200 (12.6086 iter/s, 7.93108s/100 iters), loss = 0.152099
I1211 19:58:24.669097 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 19:58:24.669097 20404 solver.cpp:237]     Train net output #1: loss = 0.152099 (* 1 = 0.152099 loss)
I1211 19:58:24.669097 20404 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1211 19:58:32.605285 20404 solver.cpp:218] Iteration 57300 (12.6014 iter/s, 7.93563s/100 iters), loss = 0.110744
I1211 19:58:32.605285 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:58:32.605285 20404 solver.cpp:237]     Train net output #1: loss = 0.110744 (* 1 = 0.110744 loss)
I1211 19:58:32.605285 20404 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1211 19:58:40.551556 20404 solver.cpp:218] Iteration 57400 (12.5845 iter/s, 7.94631s/100 iters), loss = 0.0965305
I1211 19:58:40.551556 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:58:40.551556 20404 solver.cpp:237]     Train net output #1: loss = 0.0965307 (* 1 = 0.0965307 loss)
I1211 19:58:40.551556 20404 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1211 19:58:48.105393  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:58:48.419468 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_57500.caffemodel
I1211 19:58:48.447474 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_57500.solverstate
I1211 19:58:48.453474 20404 solver.cpp:330] Iteration 57500, Testing net (#0)
I1211 19:58:48.453474 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:58:50.120786  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:58:50.186784 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8723
I1211 19:58:50.186784 20404 solver.cpp:397]     Test net output #1: loss = 0.382227 (* 1 = 0.382227 loss)
I1211 19:58:50.261790 20404 solver.cpp:218] Iteration 57500 (10.2994 iter/s, 9.70935s/100 iters), loss = 0.113066
I1211 19:58:50.261790 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:58:50.261790 20404 solver.cpp:237]     Train net output #1: loss = 0.113067 (* 1 = 0.113067 loss)
I1211 19:58:50.261790 20404 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1211 19:58:58.196620 20404 solver.cpp:218] Iteration 57600 (12.6026 iter/s, 7.93484s/100 iters), loss = 0.137808
I1211 19:58:58.196620 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:58:58.196620 20404 solver.cpp:237]     Train net output #1: loss = 0.137808 (* 1 = 0.137808 loss)
I1211 19:58:58.196620 20404 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1211 19:59:06.127564 20404 solver.cpp:218] Iteration 57700 (12.6108 iter/s, 7.92969s/100 iters), loss = 0.155845
I1211 19:59:06.127564 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:59:06.127564 20404 solver.cpp:237]     Train net output #1: loss = 0.155845 (* 1 = 0.155845 loss)
I1211 19:59:06.127564 20404 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1211 19:59:14.061606 20404 solver.cpp:218] Iteration 57800 (12.6042 iter/s, 7.93389s/100 iters), loss = 0.117428
I1211 19:59:14.061606 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 19:59:14.061606 20404 solver.cpp:237]     Train net output #1: loss = 0.117428 (* 1 = 0.117428 loss)
I1211 19:59:14.061606 20404 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1211 19:59:21.995770 20404 solver.cpp:218] Iteration 57900 (12.6038 iter/s, 7.93409s/100 iters), loss = 0.130001
I1211 19:59:21.996771 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:59:21.996771 20404 solver.cpp:237]     Train net output #1: loss = 0.130001 (* 1 = 0.130001 loss)
I1211 19:59:21.996771 20404 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1211 19:59:29.539554  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:59:29.851588 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_58000.caffemodel
I1211 19:59:29.898586 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_58000.solverstate
I1211 19:59:29.904587 20404 solver.cpp:330] Iteration 58000, Testing net (#0)
I1211 19:59:29.904587 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 19:59:31.572755  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 19:59:31.638761 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8762
I1211 19:59:31.638761 20404 solver.cpp:397]     Test net output #1: loss = 0.367782 (* 1 = 0.367782 loss)
I1211 19:59:31.712759 20404 solver.cpp:218] Iteration 58000 (10.2922 iter/s, 9.71614s/100 iters), loss = 0.166404
I1211 19:59:31.712759 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 19:59:31.712759 20404 solver.cpp:237]     Train net output #1: loss = 0.166404 (* 1 = 0.166404 loss)
I1211 19:59:31.712759 20404 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1211 19:59:39.643687 20404 solver.cpp:218] Iteration 58100 (12.6093 iter/s, 7.93062s/100 iters), loss = 0.111441
I1211 19:59:39.643687 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:59:39.643687 20404 solver.cpp:237]     Train net output #1: loss = 0.111442 (* 1 = 0.111442 loss)
I1211 19:59:39.643687 20404 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1211 19:59:47.589321 20404 solver.cpp:218] Iteration 58200 (12.5866 iter/s, 7.94497s/100 iters), loss = 0.0884672
I1211 19:59:47.589321 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 19:59:47.589321 20404 solver.cpp:237]     Train net output #1: loss = 0.0884674 (* 1 = 0.0884674 loss)
I1211 19:59:47.589321 20404 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1211 19:59:55.524827 20404 solver.cpp:218] Iteration 58300 (12.6032 iter/s, 7.93448s/100 iters), loss = 0.169134
I1211 19:59:55.524827 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 19:59:55.524827 20404 solver.cpp:237]     Train net output #1: loss = 0.169135 (* 1 = 0.169135 loss)
I1211 19:59:55.524827 20404 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1211 20:00:03.467499 20404 solver.cpp:218] Iteration 58400 (12.591 iter/s, 7.94216s/100 iters), loss = 0.0938997
I1211 20:00:03.467499 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:00:03.467499 20404 solver.cpp:237]     Train net output #1: loss = 0.0938999 (* 1 = 0.0938999 loss)
I1211 20:00:03.467499 20404 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1211 20:00:11.017740  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:00:11.332756 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_58500.caffemodel
I1211 20:00:11.361263 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_58500.solverstate
I1211 20:00:11.367763 20404 solver.cpp:330] Iteration 58500, Testing net (#0)
I1211 20:00:11.367763 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:00:13.035967  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:00:13.101972 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8769
I1211 20:00:13.101972 20404 solver.cpp:397]     Test net output #1: loss = 0.36423 (* 1 = 0.36423 loss)
I1211 20:00:13.175976 20404 solver.cpp:218] Iteration 58500 (10.3008 iter/s, 9.70796s/100 iters), loss = 0.186933
I1211 20:00:13.175976 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 20:00:13.175976 20404 solver.cpp:237]     Train net output #1: loss = 0.186933 (* 1 = 0.186933 loss)
I1211 20:00:13.175976 20404 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1211 20:00:21.116772 20404 solver.cpp:218] Iteration 58600 (12.5939 iter/s, 7.94036s/100 iters), loss = 0.148405
I1211 20:00:21.116772 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:00:21.116772 20404 solver.cpp:237]     Train net output #1: loss = 0.148405 (* 1 = 0.148405 loss)
I1211 20:00:21.116772 20404 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1211 20:00:29.043506 20404 solver.cpp:218] Iteration 58700 (12.6165 iter/s, 7.92612s/100 iters), loss = 0.18539
I1211 20:00:29.043506 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:00:29.043506 20404 solver.cpp:237]     Train net output #1: loss = 0.18539 (* 1 = 0.18539 loss)
I1211 20:00:29.043506 20404 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1211 20:00:36.980440 20404 solver.cpp:218] Iteration 58800 (12.5995 iter/s, 7.93683s/100 iters), loss = 0.126095
I1211 20:00:36.980440 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:00:36.980440 20404 solver.cpp:237]     Train net output #1: loss = 0.126095 (* 1 = 0.126095 loss)
I1211 20:00:36.980440 20404 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1211 20:00:44.912269 20404 solver.cpp:218] Iteration 58900 (12.6086 iter/s, 7.93112s/100 iters), loss = 0.0842158
I1211 20:00:44.912269 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:00:44.912269 20404 solver.cpp:237]     Train net output #1: loss = 0.084216 (* 1 = 0.084216 loss)
I1211 20:00:44.912269 20404 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1211 20:00:52.466969  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:00:52.782007 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_59000.caffemodel
I1211 20:00:52.833010 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_59000.solverstate
I1211 20:00:52.839011 20404 solver.cpp:330] Iteration 59000, Testing net (#0)
I1211 20:00:52.839011 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:00:54.505157  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:00:54.571666 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1211 20:00:54.571666 20404 solver.cpp:397]     Test net output #1: loss = 0.342406 (* 1 = 0.342406 loss)
I1211 20:00:54.645167 20404 solver.cpp:218] Iteration 59000 (10.2745 iter/s, 9.73279s/100 iters), loss = 0.129969
I1211 20:00:54.645167 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:00:54.645167 20404 solver.cpp:237]     Train net output #1: loss = 0.129969 (* 1 = 0.129969 loss)
I1211 20:00:54.645167 20404 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1211 20:01:02.571696 20404 solver.cpp:218] Iteration 59100 (12.6173 iter/s, 7.92561s/100 iters), loss = 0.0643924
I1211 20:01:02.571696 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:01:02.571696 20404 solver.cpp:237]     Train net output #1: loss = 0.0643925 (* 1 = 0.0643925 loss)
I1211 20:01:02.571696 20404 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1211 20:01:10.506302 20404 solver.cpp:218] Iteration 59200 (12.6039 iter/s, 7.93403s/100 iters), loss = 0.168178
I1211 20:01:10.506302 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:01:10.506302 20404 solver.cpp:237]     Train net output #1: loss = 0.168178 (* 1 = 0.168178 loss)
I1211 20:01:10.506302 20404 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1211 20:01:18.438360 20404 solver.cpp:218] Iteration 59300 (12.6071 iter/s, 7.93201s/100 iters), loss = 0.0688574
I1211 20:01:18.438360 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:01:18.438360 20404 solver.cpp:237]     Train net output #1: loss = 0.0688576 (* 1 = 0.0688576 loss)
I1211 20:01:18.438360 20404 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1211 20:01:26.364958 20404 solver.cpp:218] Iteration 59400 (12.617 iter/s, 7.9258s/100 iters), loss = 0.0693058
I1211 20:01:26.364958 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:01:26.364958 20404 solver.cpp:237]     Train net output #1: loss = 0.069306 (* 1 = 0.069306 loss)
I1211 20:01:26.364958 20404 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1211 20:01:33.909740  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:01:34.223775 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_59500.caffemodel
I1211 20:01:34.253777 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_59500.solverstate
I1211 20:01:34.258776 20404 solver.cpp:330] Iteration 59500, Testing net (#0)
I1211 20:01:34.259778 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:01:35.923915  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:01:35.990418 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8983
I1211 20:01:35.990418 20404 solver.cpp:397]     Test net output #1: loss = 0.304955 (* 1 = 0.304955 loss)
I1211 20:01:36.063921 20404 solver.cpp:218] Iteration 59500 (10.3106 iter/s, 9.69878s/100 iters), loss = 0.0891188
I1211 20:01:36.063921 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:01:36.063921 20404 solver.cpp:237]     Train net output #1: loss = 0.089119 (* 1 = 0.089119 loss)
I1211 20:01:36.063921 20404 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1211 20:01:44.003367 20404 solver.cpp:218] Iteration 59600 (12.5975 iter/s, 7.93811s/100 iters), loss = 0.0856517
I1211 20:01:44.003367 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:01:44.003367 20404 solver.cpp:237]     Train net output #1: loss = 0.0856519 (* 1 = 0.0856519 loss)
I1211 20:01:44.003367 20404 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1211 20:01:51.940943 20404 solver.cpp:218] Iteration 59700 (12.5984 iter/s, 7.9375s/100 iters), loss = 0.167657
I1211 20:01:51.940943 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:01:51.940943 20404 solver.cpp:237]     Train net output #1: loss = 0.167658 (* 1 = 0.167658 loss)
I1211 20:01:51.940943 20404 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1211 20:01:59.876894 20404 solver.cpp:218] Iteration 59800 (12.6014 iter/s, 7.93565s/100 iters), loss = 0.129008
I1211 20:01:59.876894 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:01:59.876894 20404 solver.cpp:237]     Train net output #1: loss = 0.129009 (* 1 = 0.129009 loss)
I1211 20:01:59.876894 20404 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1211 20:02:07.813786 20404 solver.cpp:218] Iteration 59900 (12.6012 iter/s, 7.93576s/100 iters), loss = 0.181694
I1211 20:02:07.813786 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:02:07.813786 20404 solver.cpp:237]     Train net output #1: loss = 0.181694 (* 1 = 0.181694 loss)
I1211 20:02:07.813786 20404 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1211 20:02:15.363719  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:02:15.677738 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_60000.caffemodel
I1211 20:02:15.736774 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_60000.solverstate
I1211 20:02:15.742775 20404 solver.cpp:330] Iteration 60000, Testing net (#0)
I1211 20:02:15.742775 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:02:17.409034  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:02:17.476037 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8932
I1211 20:02:17.476037 20404 solver.cpp:397]     Test net output #1: loss = 0.324588 (* 1 = 0.324588 loss)
I1211 20:02:17.550038 20404 solver.cpp:218] Iteration 60000 (10.2713 iter/s, 9.7359s/100 iters), loss = 0.130158
I1211 20:02:17.550038 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:02:17.550038 20404 solver.cpp:237]     Train net output #1: loss = 0.130158 (* 1 = 0.130158 loss)
I1211 20:02:17.550038 20404 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1211 20:02:25.482908 20404 solver.cpp:218] Iteration 60100 (12.6069 iter/s, 7.93214s/100 iters), loss = 0.112326
I1211 20:02:25.482908 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:02:25.482908 20404 solver.cpp:237]     Train net output #1: loss = 0.112326 (* 1 = 0.112326 loss)
I1211 20:02:25.482908 20404 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1211 20:02:33.417727 20404 solver.cpp:218] Iteration 60200 (12.6027 iter/s, 7.93484s/100 iters), loss = 0.169863
I1211 20:02:33.417727 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:02:33.417727 20404 solver.cpp:237]     Train net output #1: loss = 0.169863 (* 1 = 0.169863 loss)
I1211 20:02:33.417727 20404 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1211 20:02:41.358542 20404 solver.cpp:218] Iteration 60300 (12.5936 iter/s, 7.94051s/100 iters), loss = 0.0813769
I1211 20:02:41.358542 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:02:41.358542 20404 solver.cpp:237]     Train net output #1: loss = 0.0813771 (* 1 = 0.0813771 loss)
I1211 20:02:41.358542 20404 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1211 20:02:49.295387 20404 solver.cpp:218] Iteration 60400 (12.601 iter/s, 7.93585s/100 iters), loss = 0.086551
I1211 20:02:49.295387 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:02:49.295387 20404 solver.cpp:237]     Train net output #1: loss = 0.0865512 (* 1 = 0.0865512 loss)
I1211 20:02:49.295387 20404 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1211 20:02:56.841186  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:02:57.156217 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_60500.caffemodel
I1211 20:02:57.188218 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_60500.solverstate
I1211 20:02:57.194221 20404 solver.cpp:330] Iteration 60500, Testing net (#0)
I1211 20:02:57.194221 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:02:58.861374  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:02:58.927398 20404 solver.cpp:397]     Test net output #0: accuracy = 0.875
I1211 20:02:58.927398 20404 solver.cpp:397]     Test net output #1: loss = 0.387339 (* 1 = 0.387339 loss)
I1211 20:02:59.002403 20404 solver.cpp:218] Iteration 60500 (10.3025 iter/s, 9.70635s/100 iters), loss = 0.149772
I1211 20:02:59.002403 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:02:59.002403 20404 solver.cpp:237]     Train net output #1: loss = 0.149772 (* 1 = 0.149772 loss)
I1211 20:02:59.002403 20404 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1211 20:03:06.940284 20404 solver.cpp:218] Iteration 60600 (12.5979 iter/s, 7.9378s/100 iters), loss = 0.17431
I1211 20:03:06.940284 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:03:06.940284 20404 solver.cpp:237]     Train net output #1: loss = 0.17431 (* 1 = 0.17431 loss)
I1211 20:03:06.940284 20404 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1211 20:03:14.873219 20404 solver.cpp:218] Iteration 60700 (12.6062 iter/s, 7.9326s/100 iters), loss = 0.118869
I1211 20:03:14.873219 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:03:14.873219 20404 solver.cpp:237]     Train net output #1: loss = 0.118869 (* 1 = 0.118869 loss)
I1211 20:03:14.873219 20404 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1211 20:03:22.810057 20404 solver.cpp:218] Iteration 60800 (12.601 iter/s, 7.9359s/100 iters), loss = 0.111451
I1211 20:03:22.810057 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:03:22.810057 20404 solver.cpp:237]     Train net output #1: loss = 0.111451 (* 1 = 0.111451 loss)
I1211 20:03:22.810057 20404 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1211 20:03:30.755179 20404 solver.cpp:218] Iteration 60900 (12.5871 iter/s, 7.94465s/100 iters), loss = 0.0938825
I1211 20:03:30.755179 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:03:30.755179 20404 solver.cpp:237]     Train net output #1: loss = 0.0938827 (* 1 = 0.0938827 loss)
I1211 20:03:30.755179 20404 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1211 20:03:38.300487  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:03:38.614018 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_61000.caffemodel
I1211 20:03:38.738704 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_61000.solverstate
I1211 20:03:38.743711 20404 solver.cpp:330] Iteration 61000, Testing net (#0)
I1211 20:03:38.743711 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:03:40.408417  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:03:40.473940 20404 solver.cpp:397]     Test net output #0: accuracy = 0.885
I1211 20:03:40.473940 20404 solver.cpp:397]     Test net output #1: loss = 0.366481 (* 1 = 0.366481 loss)
I1211 20:03:40.548950 20404 solver.cpp:218] Iteration 61000 (10.211 iter/s, 9.79335s/100 iters), loss = 0.166952
I1211 20:03:40.548950 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:03:40.548950 20404 solver.cpp:237]     Train net output #1: loss = 0.166953 (* 1 = 0.166953 loss)
I1211 20:03:40.548950 20404 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1211 20:03:48.477744 20404 solver.cpp:218] Iteration 61100 (12.6121 iter/s, 7.9289s/100 iters), loss = 0.124102
I1211 20:03:48.477744 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:03:48.477744 20404 solver.cpp:237]     Train net output #1: loss = 0.124103 (* 1 = 0.124103 loss)
I1211 20:03:48.477744 20404 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1211 20:03:56.415156 20404 solver.cpp:218] Iteration 61200 (12.6005 iter/s, 7.9362s/100 iters), loss = 0.157714
I1211 20:03:56.415156 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:03:56.415156 20404 solver.cpp:237]     Train net output #1: loss = 0.157715 (* 1 = 0.157715 loss)
I1211 20:03:56.415156 20404 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1211 20:04:04.348027 20404 solver.cpp:218] Iteration 61300 (12.6061 iter/s, 7.93266s/100 iters), loss = 0.0997892
I1211 20:04:04.348027 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:04:04.348027 20404 solver.cpp:237]     Train net output #1: loss = 0.0997894 (* 1 = 0.0997894 loss)
I1211 20:04:04.348027 20404 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1211 20:04:12.280627 20404 solver.cpp:218] Iteration 61400 (12.6061 iter/s, 7.93265s/100 iters), loss = 0.0598849
I1211 20:04:12.280627 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:04:12.280627 20404 solver.cpp:237]     Train net output #1: loss = 0.0598851 (* 1 = 0.0598851 loss)
I1211 20:04:12.281641 20404 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1211 20:04:19.820051  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:04:20.132213 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_61500.caffemodel
I1211 20:04:20.160214 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_61500.solverstate
I1211 20:04:20.166215 20404 solver.cpp:330] Iteration 61500, Testing net (#0)
I1211 20:04:20.166215 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:04:21.833122  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:04:21.900102 20404 solver.cpp:397]     Test net output #0: accuracy = 0.872
I1211 20:04:21.900102 20404 solver.cpp:397]     Test net output #1: loss = 0.391555 (* 1 = 0.391555 loss)
I1211 20:04:21.974149 20404 solver.cpp:218] Iteration 61500 (10.3169 iter/s, 9.69282s/100 iters), loss = 0.105117
I1211 20:04:21.974149 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:04:21.974149 20404 solver.cpp:237]     Train net output #1: loss = 0.105118 (* 1 = 0.105118 loss)
I1211 20:04:21.974149 20404 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1211 20:04:29.913460 20404 solver.cpp:218] Iteration 61600 (12.5965 iter/s, 7.93872s/100 iters), loss = 0.0761885
I1211 20:04:29.913460 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:04:29.913460 20404 solver.cpp:237]     Train net output #1: loss = 0.0761887 (* 1 = 0.0761887 loss)
I1211 20:04:29.913460 20404 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1211 20:04:37.855327 20404 solver.cpp:218] Iteration 61700 (12.5923 iter/s, 7.94137s/100 iters), loss = 0.0995921
I1211 20:04:37.855327 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:04:37.855327 20404 solver.cpp:237]     Train net output #1: loss = 0.0995923 (* 1 = 0.0995923 loss)
I1211 20:04:37.855327 20404 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1211 20:04:45.796169 20404 solver.cpp:218] Iteration 61800 (12.5948 iter/s, 7.9398s/100 iters), loss = 0.103869
I1211 20:04:45.796169 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:04:45.796169 20404 solver.cpp:237]     Train net output #1: loss = 0.103869 (* 1 = 0.103869 loss)
I1211 20:04:45.796169 20404 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1211 20:04:53.731139 20404 solver.cpp:218] Iteration 61900 (12.6029 iter/s, 7.93466s/100 iters), loss = 0.176826
I1211 20:04:53.731139 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:04:53.731139 20404 solver.cpp:237]     Train net output #1: loss = 0.176826 (* 1 = 0.176826 loss)
I1211 20:04:53.731139 20404 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1211 20:05:01.266945  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:05:01.579982 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_62000.caffemodel
I1211 20:05:01.654063 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_62000.solverstate
I1211 20:05:01.661064 20404 solver.cpp:330] Iteration 62000, Testing net (#0)
I1211 20:05:01.661064 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:05:03.328721  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:05:03.394220 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8965
I1211 20:05:03.394220 20404 solver.cpp:397]     Test net output #1: loss = 0.330605 (* 1 = 0.330605 loss)
I1211 20:05:03.469244 20404 solver.cpp:218] Iteration 62000 (10.2698 iter/s, 9.73727s/100 iters), loss = 0.165615
I1211 20:05:03.469244 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:05:03.469244 20404 solver.cpp:237]     Train net output #1: loss = 0.165616 (* 1 = 0.165616 loss)
I1211 20:05:03.469244 20404 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1211 20:05:11.394671 20404 solver.cpp:218] Iteration 62100 (12.6178 iter/s, 7.92528s/100 iters), loss = 0.139398
I1211 20:05:11.394671 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:05:11.394671 20404 solver.cpp:237]     Train net output #1: loss = 0.139399 (* 1 = 0.139399 loss)
I1211 20:05:11.394671 20404 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1211 20:05:19.328662 20404 solver.cpp:218] Iteration 62200 (12.6049 iter/s, 7.93345s/100 iters), loss = 0.088593
I1211 20:05:19.328662 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:05:19.328662 20404 solver.cpp:237]     Train net output #1: loss = 0.0885933 (* 1 = 0.0885933 loss)
I1211 20:05:19.328662 20404 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1211 20:05:27.256067 20404 solver.cpp:218] Iteration 62300 (12.6154 iter/s, 7.92684s/100 iters), loss = 0.128507
I1211 20:05:27.256067 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:05:27.256067 20404 solver.cpp:237]     Train net output #1: loss = 0.128508 (* 1 = 0.128508 loss)
I1211 20:05:27.256067 20404 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1211 20:05:35.186036 20404 solver.cpp:218] Iteration 62400 (12.6104 iter/s, 7.92996s/100 iters), loss = 0.0666731
I1211 20:05:35.186036 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:05:35.186036 20404 solver.cpp:237]     Train net output #1: loss = 0.0666734 (* 1 = 0.0666734 loss)
I1211 20:05:35.186036 20404 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1211 20:05:42.725423  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:05:43.040995 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_62500.caffemodel
I1211 20:05:43.078533 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_62500.solverstate
I1211 20:05:43.085528 20404 solver.cpp:330] Iteration 62500, Testing net (#0)
I1211 20:05:43.085528 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:05:44.752643  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:05:44.819643 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8648
I1211 20:05:44.819643 20404 solver.cpp:397]     Test net output #1: loss = 0.435788 (* 1 = 0.435788 loss)
I1211 20:05:44.892649 20404 solver.cpp:218] Iteration 62500 (10.3025 iter/s, 9.70642s/100 iters), loss = 0.0975529
I1211 20:05:44.893651 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:05:44.893651 20404 solver.cpp:237]     Train net output #1: loss = 0.0975533 (* 1 = 0.0975533 loss)
I1211 20:05:44.893651 20404 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1211 20:05:52.824589 20404 solver.cpp:218] Iteration 62600 (12.6082 iter/s, 7.93132s/100 iters), loss = 0.162828
I1211 20:05:52.824589 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:05:52.824589 20404 solver.cpp:237]     Train net output #1: loss = 0.162828 (* 1 = 0.162828 loss)
I1211 20:05:52.824589 20404 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1211 20:06:00.766942 20404 solver.cpp:218] Iteration 62700 (12.5921 iter/s, 7.94149s/100 iters), loss = 0.141219
I1211 20:06:00.766942 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:06:00.766942 20404 solver.cpp:237]     Train net output #1: loss = 0.14122 (* 1 = 0.14122 loss)
I1211 20:06:00.766942 20404 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1211 20:06:08.692745 20404 solver.cpp:218] Iteration 62800 (12.6181 iter/s, 7.92515s/100 iters), loss = 0.126068
I1211 20:06:08.692745 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:06:08.692745 20404 solver.cpp:237]     Train net output #1: loss = 0.126068 (* 1 = 0.126068 loss)
I1211 20:06:08.692745 20404 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1211 20:06:16.624862 20404 solver.cpp:218] Iteration 62900 (12.6068 iter/s, 7.93221s/100 iters), loss = 0.0734553
I1211 20:06:16.624862 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:06:16.624862 20404 solver.cpp:237]     Train net output #1: loss = 0.0734557 (* 1 = 0.0734557 loss)
I1211 20:06:16.625847 20404 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1211 20:06:24.174793  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:06:24.490036 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_63000.caffemodel
I1211 20:06:24.518034 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_63000.solverstate
I1211 20:06:24.523032 20404 solver.cpp:330] Iteration 63000, Testing net (#0)
I1211 20:06:24.524018 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:06:26.188233  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:06:26.255758 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8794
I1211 20:06:26.255758 20404 solver.cpp:397]     Test net output #1: loss = 0.385711 (* 1 = 0.385711 loss)
I1211 20:06:26.329257 20404 solver.cpp:218] Iteration 63000 (10.3058 iter/s, 9.70329s/100 iters), loss = 0.117932
I1211 20:06:26.329257 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:06:26.329257 20404 solver.cpp:237]     Train net output #1: loss = 0.117932 (* 1 = 0.117932 loss)
I1211 20:06:26.329257 20404 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1211 20:06:34.267570 20404 solver.cpp:218] Iteration 63100 (12.5981 iter/s, 7.93774s/100 iters), loss = 0.212071
I1211 20:06:34.267570 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:06:34.267570 20404 solver.cpp:237]     Train net output #1: loss = 0.212071 (* 1 = 0.212071 loss)
I1211 20:06:34.267570 20404 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1211 20:06:42.205519 20404 solver.cpp:218] Iteration 63200 (12.5975 iter/s, 7.93806s/100 iters), loss = 0.0914447
I1211 20:06:42.205519 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:06:42.205519 20404 solver.cpp:237]     Train net output #1: loss = 0.0914451 (* 1 = 0.0914451 loss)
I1211 20:06:42.205519 20404 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1211 20:06:50.143273 20404 solver.cpp:218] Iteration 63300 (12.5997 iter/s, 7.93669s/100 iters), loss = 0.0752944
I1211 20:06:50.143273 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:06:50.143273 20404 solver.cpp:237]     Train net output #1: loss = 0.0752947 (* 1 = 0.0752947 loss)
I1211 20:06:50.143273 20404 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1211 20:06:58.082114 20404 solver.cpp:218] Iteration 63400 (12.5968 iter/s, 7.93849s/100 iters), loss = 0.109775
I1211 20:06:58.082114 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:06:58.082114 20404 solver.cpp:237]     Train net output #1: loss = 0.109776 (* 1 = 0.109776 loss)
I1211 20:06:58.082114 20404 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1211 20:07:05.630934  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:07:05.943954 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_63500.caffemodel
I1211 20:07:05.971961 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_63500.solverstate
I1211 20:07:05.976958 20404 solver.cpp:330] Iteration 63500, Testing net (#0)
I1211 20:07:05.976958 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:07:07.643594  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:07:07.709095 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8911
I1211 20:07:07.709095 20404 solver.cpp:397]     Test net output #1: loss = 0.334 (* 1 = 0.334 loss)
I1211 20:07:07.784101 20404 solver.cpp:218] Iteration 63500 (10.308 iter/s, 9.70124s/100 iters), loss = 0.18299
I1211 20:07:07.784101 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:07:07.784101 20404 solver.cpp:237]     Train net output #1: loss = 0.182991 (* 1 = 0.182991 loss)
I1211 20:07:07.784101 20404 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1211 20:07:15.711956 20404 solver.cpp:218] Iteration 63600 (12.6145 iter/s, 7.9274s/100 iters), loss = 0.0759653
I1211 20:07:15.711956 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:07:15.711956 20404 solver.cpp:237]     Train net output #1: loss = 0.0759657 (* 1 = 0.0759657 loss)
I1211 20:07:15.711956 20404 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1211 20:07:23.646088 20404 solver.cpp:218] Iteration 63700 (12.6043 iter/s, 7.93378s/100 iters), loss = 0.146531
I1211 20:07:23.646088 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:07:23.646088 20404 solver.cpp:237]     Train net output #1: loss = 0.146532 (* 1 = 0.146532 loss)
I1211 20:07:23.646088 20404 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1211 20:07:31.578863 20404 solver.cpp:218] Iteration 63800 (12.6065 iter/s, 7.93244s/100 iters), loss = 0.126256
I1211 20:07:31.578863 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:07:31.578863 20404 solver.cpp:237]     Train net output #1: loss = 0.126256 (* 1 = 0.126256 loss)
I1211 20:07:31.578863 20404 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1211 20:07:39.509012 20404 solver.cpp:218] Iteration 63900 (12.6105 iter/s, 7.92989s/100 iters), loss = 0.120786
I1211 20:07:39.509012 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:07:39.509012 20404 solver.cpp:237]     Train net output #1: loss = 0.120786 (* 1 = 0.120786 loss)
I1211 20:07:39.509012 20404 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1211 20:07:47.054321  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:07:47.368862 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_64000.caffemodel
I1211 20:07:47.425863 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_64000.solverstate
I1211 20:07:47.431864 20404 solver.cpp:330] Iteration 64000, Testing net (#0)
I1211 20:07:47.431864 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:07:49.095964  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:07:49.162953 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8765
I1211 20:07:49.162953 20404 solver.cpp:397]     Test net output #1: loss = 0.398667 (* 1 = 0.398667 loss)
I1211 20:07:49.235960 20404 solver.cpp:218] Iteration 64000 (10.281 iter/s, 9.7267s/100 iters), loss = 0.127585
I1211 20:07:49.236953 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:07:49.236953 20404 solver.cpp:237]     Train net output #1: loss = 0.127586 (* 1 = 0.127586 loss)
I1211 20:07:49.236953 20404 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1211 20:07:57.167897 20404 solver.cpp:218] Iteration 64100 (12.6088 iter/s, 7.93099s/100 iters), loss = 0.13845
I1211 20:07:57.167897 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:07:57.167897 20404 solver.cpp:237]     Train net output #1: loss = 0.13845 (* 1 = 0.13845 loss)
I1211 20:07:57.167897 20404 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1211 20:08:05.095826 20404 solver.cpp:218] Iteration 64200 (12.6138 iter/s, 7.92783s/100 iters), loss = 0.0946622
I1211 20:08:05.096827 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:08:05.096827 20404 solver.cpp:237]     Train net output #1: loss = 0.0946626 (* 1 = 0.0946626 loss)
I1211 20:08:05.096827 20404 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1211 20:08:13.030699 20404 solver.cpp:218] Iteration 64300 (12.6038 iter/s, 7.93412s/100 iters), loss = 0.0901957
I1211 20:08:13.030699 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:08:13.030699 20404 solver.cpp:237]     Train net output #1: loss = 0.0901961 (* 1 = 0.0901961 loss)
I1211 20:08:13.030699 20404 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1211 20:08:20.971663 20404 solver.cpp:218] Iteration 64400 (12.5934 iter/s, 7.94066s/100 iters), loss = 0.124051
I1211 20:08:20.971663 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:08:20.971663 20404 solver.cpp:237]     Train net output #1: loss = 0.124052 (* 1 = 0.124052 loss)
I1211 20:08:20.971663 20404 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1211 20:08:28.522367  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:08:28.834388 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_64500.caffemodel
I1211 20:08:28.863893 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_64500.solverstate
I1211 20:08:28.869398 20404 solver.cpp:330] Iteration 64500, Testing net (#0)
I1211 20:08:28.869398 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:08:30.536728  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:08:30.602735 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I1211 20:08:30.602735 20404 solver.cpp:397]     Test net output #1: loss = 0.353533 (* 1 = 0.353533 loss)
I1211 20:08:30.676751 20404 solver.cpp:218] Iteration 64500 (10.305 iter/s, 9.70404s/100 iters), loss = 0.105409
I1211 20:08:30.676751 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:08:30.676751 20404 solver.cpp:237]     Train net output #1: loss = 0.105409 (* 1 = 0.105409 loss)
I1211 20:08:30.676751 20404 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1211 20:08:38.613698 20404 solver.cpp:218] Iteration 64600 (12.5994 iter/s, 7.93686s/100 iters), loss = 0.114666
I1211 20:08:38.613698 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:08:38.613698 20404 solver.cpp:237]     Train net output #1: loss = 0.114667 (* 1 = 0.114667 loss)
I1211 20:08:38.613698 20404 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1211 20:08:46.552626 20404 solver.cpp:218] Iteration 64700 (12.597 iter/s, 7.93842s/100 iters), loss = 0.140037
I1211 20:08:46.552626 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:08:46.552626 20404 solver.cpp:237]     Train net output #1: loss = 0.140038 (* 1 = 0.140038 loss)
I1211 20:08:46.552626 20404 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1211 20:08:54.477759 20404 solver.cpp:218] Iteration 64800 (12.6188 iter/s, 7.92466s/100 iters), loss = 0.0674379
I1211 20:08:54.477759 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:08:54.477759 20404 solver.cpp:237]     Train net output #1: loss = 0.0674383 (* 1 = 0.0674383 loss)
I1211 20:08:54.477759 20404 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1211 20:09:02.409687 20404 solver.cpp:218] Iteration 64900 (12.6093 iter/s, 7.93068s/100 iters), loss = 0.103775
I1211 20:09:02.409687 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:09:02.409687 20404 solver.cpp:237]     Train net output #1: loss = 0.103776 (* 1 = 0.103776 loss)
I1211 20:09:02.409687 20404 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1211 20:09:09.947221  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:09:10.259832 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_65000.caffemodel
I1211 20:09:10.328899 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_65000.solverstate
I1211 20:09:10.333899 20404 solver.cpp:330] Iteration 65000, Testing net (#0)
I1211 20:09:10.334910 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:09:12.002239  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:09:12.067741 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8816
I1211 20:09:12.067741 20404 solver.cpp:397]     Test net output #1: loss = 0.375266 (* 1 = 0.375266 loss)
I1211 20:09:12.141242 20404 solver.cpp:218] Iteration 65000 (10.2764 iter/s, 9.73105s/100 iters), loss = 0.149256
I1211 20:09:12.141242 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:09:12.141242 20404 solver.cpp:237]     Train net output #1: loss = 0.149257 (* 1 = 0.149257 loss)
I1211 20:09:12.141242 20404 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1211 20:09:20.078330 20404 solver.cpp:218] Iteration 65100 (12.5992 iter/s, 7.937s/100 iters), loss = 0.141756
I1211 20:09:20.078330 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:09:20.078330 20404 solver.cpp:237]     Train net output #1: loss = 0.141757 (* 1 = 0.141757 loss)
I1211 20:09:20.078330 20404 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1211 20:09:28.008213 20404 solver.cpp:218] Iteration 65200 (12.6105 iter/s, 7.9299s/100 iters), loss = 0.0915421
I1211 20:09:28.008213 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:09:28.008213 20404 solver.cpp:237]     Train net output #1: loss = 0.0915425 (* 1 = 0.0915425 loss)
I1211 20:09:28.008213 20404 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1211 20:09:35.933444 20404 solver.cpp:218] Iteration 65300 (12.6197 iter/s, 7.92409s/100 iters), loss = 0.124754
I1211 20:09:35.933444 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:09:35.933444 20404 solver.cpp:237]     Train net output #1: loss = 0.124754 (* 1 = 0.124754 loss)
I1211 20:09:35.933444 20404 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1211 20:09:43.868944 20404 solver.cpp:218] Iteration 65400 (12.602 iter/s, 7.93526s/100 iters), loss = 0.123255
I1211 20:09:43.868944 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:09:43.868944 20404 solver.cpp:237]     Train net output #1: loss = 0.123256 (* 1 = 0.123256 loss)
I1211 20:09:43.868944 20404 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1211 20:09:51.419339  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:09:51.733892 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_65500.caffemodel
I1211 20:09:51.762892 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_65500.solverstate
I1211 20:09:51.767892 20404 solver.cpp:330] Iteration 65500, Testing net (#0)
I1211 20:09:51.768893 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:09:53.435045  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:09:53.502045 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8946
I1211 20:09:53.502045 20404 solver.cpp:397]     Test net output #1: loss = 0.328311 (* 1 = 0.328311 loss)
I1211 20:09:53.577050 20404 solver.cpp:218] Iteration 65500 (10.3015 iter/s, 9.70736s/100 iters), loss = 0.159497
I1211 20:09:53.577050 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:09:53.577050 20404 solver.cpp:237]     Train net output #1: loss = 0.159497 (* 1 = 0.159497 loss)
I1211 20:09:53.577050 20404 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1211 20:10:01.513501 20404 solver.cpp:218] Iteration 65600 (12.6008 iter/s, 7.93599s/100 iters), loss = 0.142641
I1211 20:10:01.513501 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:10:01.513501 20404 solver.cpp:237]     Train net output #1: loss = 0.142641 (* 1 = 0.142641 loss)
I1211 20:10:01.513501 20404 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1211 20:10:09.449867 20404 solver.cpp:218] Iteration 65700 (12.6004 iter/s, 7.93623s/100 iters), loss = 0.152323
I1211 20:10:09.449867 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:10:09.449867 20404 solver.cpp:237]     Train net output #1: loss = 0.152324 (* 1 = 0.152324 loss)
I1211 20:10:09.449867 20404 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1211 20:10:17.380555 20404 solver.cpp:218] Iteration 65800 (12.6108 iter/s, 7.92973s/100 iters), loss = 0.113216
I1211 20:10:17.380555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:10:17.380555 20404 solver.cpp:237]     Train net output #1: loss = 0.113217 (* 1 = 0.113217 loss)
I1211 20:10:17.380555 20404 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1211 20:10:25.314074 20404 solver.cpp:218] Iteration 65900 (12.6051 iter/s, 7.93329s/100 iters), loss = 0.114608
I1211 20:10:25.314074 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:10:25.314074 20404 solver.cpp:237]     Train net output #1: loss = 0.114609 (* 1 = 0.114609 loss)
I1211 20:10:25.314074 20404 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1211 20:10:32.842710  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:10:33.156816 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_66000.caffemodel
I1211 20:10:33.206823 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_66000.solverstate
I1211 20:10:33.212841 20404 solver.cpp:330] Iteration 66000, Testing net (#0)
I1211 20:10:33.212841 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:10:34.878942  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:10:34.944927 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8712
I1211 20:10:34.944927 20404 solver.cpp:397]     Test net output #1: loss = 0.434481 (* 1 = 0.434481 loss)
I1211 20:10:35.019453 20404 solver.cpp:218] Iteration 66000 (10.3046 iter/s, 9.70442s/100 iters), loss = 0.122426
I1211 20:10:35.019453 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:10:35.019453 20404 solver.cpp:237]     Train net output #1: loss = 0.122426 (* 1 = 0.122426 loss)
I1211 20:10:35.019453 20404 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1211 20:10:42.942484 20404 solver.cpp:218] Iteration 66100 (12.6218 iter/s, 7.92277s/100 iters), loss = 0.139069
I1211 20:10:42.942484 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:10:42.942484 20404 solver.cpp:237]     Train net output #1: loss = 0.139069 (* 1 = 0.139069 loss)
I1211 20:10:42.942484 20404 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1211 20:10:50.871810 20404 solver.cpp:218] Iteration 66200 (12.6115 iter/s, 7.92928s/100 iters), loss = 0.134606
I1211 20:10:50.871810 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:10:50.871810 20404 solver.cpp:237]     Train net output #1: loss = 0.134606 (* 1 = 0.134606 loss)
I1211 20:10:50.871810 20404 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1211 20:10:58.832603 20404 solver.cpp:218] Iteration 66300 (12.5634 iter/s, 7.9596s/100 iters), loss = 0.0684429
I1211 20:10:58.832603 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:10:58.832603 20404 solver.cpp:237]     Train net output #1: loss = 0.0684433 (* 1 = 0.0684433 loss)
I1211 20:10:58.832603 20404 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1211 20:11:06.761354 20404 solver.cpp:218] Iteration 66400 (12.6122 iter/s, 7.92883s/100 iters), loss = 0.126962
I1211 20:11:06.761354 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:11:06.761354 20404 solver.cpp:237]     Train net output #1: loss = 0.126963 (* 1 = 0.126963 loss)
I1211 20:11:06.761354 20404 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1211 20:11:14.301201  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:11:14.614722 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_66500.caffemodel
I1211 20:11:14.646225 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_66500.solverstate
I1211 20:11:14.651226 20404 solver.cpp:330] Iteration 66500, Testing net (#0)
I1211 20:11:14.652225 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:11:16.319488  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:11:16.385489 20404 solver.cpp:397]     Test net output #0: accuracy = 0.891
I1211 20:11:16.385489 20404 solver.cpp:397]     Test net output #1: loss = 0.326221 (* 1 = 0.326221 loss)
I1211 20:11:16.460506 20404 solver.cpp:218] Iteration 66500 (10.3106 iter/s, 9.69876s/100 iters), loss = 0.120013
I1211 20:11:16.460506 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:11:16.460506 20404 solver.cpp:237]     Train net output #1: loss = 0.120013 (* 1 = 0.120013 loss)
I1211 20:11:16.460506 20404 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1211 20:11:24.400323 20404 solver.cpp:218] Iteration 66600 (12.5952 iter/s, 7.9395s/100 iters), loss = 0.139141
I1211 20:11:24.400323 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:11:24.400323 20404 solver.cpp:237]     Train net output #1: loss = 0.139141 (* 1 = 0.139141 loss)
I1211 20:11:24.400323 20404 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1211 20:11:32.337855 20404 solver.cpp:218] Iteration 66700 (12.599 iter/s, 7.93715s/100 iters), loss = 0.150667
I1211 20:11:32.338856 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:11:32.338856 20404 solver.cpp:237]     Train net output #1: loss = 0.150667 (* 1 = 0.150667 loss)
I1211 20:11:32.338856 20404 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1211 20:11:40.269402 20404 solver.cpp:218] Iteration 66800 (12.6089 iter/s, 7.9309s/100 iters), loss = 0.118836
I1211 20:11:40.269402 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:11:40.269402 20404 solver.cpp:237]     Train net output #1: loss = 0.118836 (* 1 = 0.118836 loss)
I1211 20:11:40.269402 20404 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1211 20:11:48.201545 20404 solver.cpp:218] Iteration 66900 (12.6085 iter/s, 7.93118s/100 iters), loss = 0.117076
I1211 20:11:48.201545 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:11:48.201545 20404 solver.cpp:237]     Train net output #1: loss = 0.117076 (* 1 = 0.117076 loss)
I1211 20:11:48.201545 20404 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1211 20:11:55.748716  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:11:56.063320 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_67000.caffemodel
I1211 20:11:56.120823 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_67000.solverstate
I1211 20:11:56.126826 20404 solver.cpp:330] Iteration 67000, Testing net (#0)
I1211 20:11:56.127324 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:11:57.792668  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:11:57.858445 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I1211 20:11:57.858445 20404 solver.cpp:397]     Test net output #1: loss = 0.332034 (* 1 = 0.332034 loss)
I1211 20:11:57.933675 20404 solver.cpp:218] Iteration 67000 (10.2762 iter/s, 9.73119s/100 iters), loss = 0.111279
I1211 20:11:57.933675 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:11:57.933675 20404 solver.cpp:237]     Train net output #1: loss = 0.11128 (* 1 = 0.11128 loss)
I1211 20:11:57.933675 20404 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1211 20:12:05.866907 20404 solver.cpp:218] Iteration 67100 (12.6052 iter/s, 7.93324s/100 iters), loss = 0.130649
I1211 20:12:05.866907 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:12:05.866907 20404 solver.cpp:237]     Train net output #1: loss = 0.130649 (* 1 = 0.130649 loss)
I1211 20:12:05.866907 20404 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1211 20:12:13.810827 20404 solver.cpp:218] Iteration 67200 (12.5896 iter/s, 7.94307s/100 iters), loss = 0.140502
I1211 20:12:13.810827 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:12:13.810827 20404 solver.cpp:237]     Train net output #1: loss = 0.140502 (* 1 = 0.140502 loss)
I1211 20:12:13.810827 20404 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1211 20:12:21.737259 20404 solver.cpp:218] Iteration 67300 (12.617 iter/s, 7.92583s/100 iters), loss = 0.196608
I1211 20:12:21.737259 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:12:21.737259 20404 solver.cpp:237]     Train net output #1: loss = 0.196609 (* 1 = 0.196609 loss)
I1211 20:12:21.737259 20404 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1211 20:12:29.669674 20404 solver.cpp:218] Iteration 67400 (12.6059 iter/s, 7.93279s/100 iters), loss = 0.145788
I1211 20:12:29.670668 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:12:29.670668 20404 solver.cpp:237]     Train net output #1: loss = 0.145788 (* 1 = 0.145788 loss)
I1211 20:12:29.670668 20404 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1211 20:12:37.218405  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:12:37.529434 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_67500.caffemodel
I1211 20:12:37.556440 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_67500.solverstate
I1211 20:12:37.562441 20404 solver.cpp:330] Iteration 67500, Testing net (#0)
I1211 20:12:37.562441 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:12:39.228579  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:12:39.294584 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8641
I1211 20:12:39.294584 20404 solver.cpp:397]     Test net output #1: loss = 0.4303 (* 1 = 0.4303 loss)
I1211 20:12:39.368605 20404 solver.cpp:218] Iteration 67500 (10.3116 iter/s, 9.69782s/100 iters), loss = 0.103724
I1211 20:12:39.368605 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:12:39.368605 20404 solver.cpp:237]     Train net output #1: loss = 0.103724 (* 1 = 0.103724 loss)
I1211 20:12:39.368605 20404 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1211 20:12:47.312480 20404 solver.cpp:218] Iteration 67600 (12.5886 iter/s, 7.9437s/100 iters), loss = 0.0928431
I1211 20:12:47.312480 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:12:47.312480 20404 solver.cpp:237]     Train net output #1: loss = 0.0928434 (* 1 = 0.0928434 loss)
I1211 20:12:47.312480 20404 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1211 20:12:55.257697 20404 solver.cpp:218] Iteration 67700 (12.5878 iter/s, 7.94417s/100 iters), loss = 0.236737
I1211 20:12:55.257697 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 20:12:55.257697 20404 solver.cpp:237]     Train net output #1: loss = 0.236737 (* 1 = 0.236737 loss)
I1211 20:12:55.257697 20404 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1211 20:13:03.193429 20404 solver.cpp:218] Iteration 67800 (12.6013 iter/s, 7.9357s/100 iters), loss = 0.0982362
I1211 20:13:03.193429 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:13:03.193429 20404 solver.cpp:237]     Train net output #1: loss = 0.0982365 (* 1 = 0.0982365 loss)
I1211 20:13:03.193429 20404 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1211 20:13:11.131826 20404 solver.cpp:218] Iteration 67900 (12.5974 iter/s, 7.93816s/100 iters), loss = 0.091137
I1211 20:13:11.131826 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:13:11.131826 20404 solver.cpp:237]     Train net output #1: loss = 0.0911373 (* 1 = 0.0911373 loss)
I1211 20:13:11.131826 20404 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1211 20:13:18.682312  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:13:18.995334 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_68000.caffemodel
I1211 20:13:19.045840 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_68000.solverstate
I1211 20:13:19.052340 20404 solver.cpp:330] Iteration 68000, Testing net (#0)
I1211 20:13:19.052340 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:13:20.720576  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:13:20.786595 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8682
I1211 20:13:20.786595 20404 solver.cpp:397]     Test net output #1: loss = 0.447313 (* 1 = 0.447313 loss)
I1211 20:13:20.861587 20404 solver.cpp:218] Iteration 68000 (10.279 iter/s, 9.72861s/100 iters), loss = 0.13513
I1211 20:13:20.861587 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:13:20.861587 20404 solver.cpp:237]     Train net output #1: loss = 0.13513 (* 1 = 0.13513 loss)
I1211 20:13:20.861587 20404 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1211 20:13:28.793498 20404 solver.cpp:218] Iteration 68100 (12.608 iter/s, 7.9315s/100 iters), loss = 0.0853892
I1211 20:13:28.793498 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:13:28.793498 20404 solver.cpp:237]     Train net output #1: loss = 0.0853895 (* 1 = 0.0853895 loss)
I1211 20:13:28.793498 20404 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1211 20:13:36.727355 20404 solver.cpp:218] Iteration 68200 (12.6051 iter/s, 7.9333s/100 iters), loss = 0.118735
I1211 20:13:36.727355 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:13:36.727355 20404 solver.cpp:237]     Train net output #1: loss = 0.118735 (* 1 = 0.118735 loss)
I1211 20:13:36.727355 20404 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1211 20:13:44.670490 20404 solver.cpp:218] Iteration 68300 (12.5893 iter/s, 7.94328s/100 iters), loss = 0.143755
I1211 20:13:44.670490 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:13:44.670490 20404 solver.cpp:237]     Train net output #1: loss = 0.143755 (* 1 = 0.143755 loss)
I1211 20:13:44.670490 20404 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1211 20:13:52.603312 20404 solver.cpp:218] Iteration 68400 (12.6073 iter/s, 7.93193s/100 iters), loss = 0.076373
I1211 20:13:52.603312 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:13:52.603312 20404 solver.cpp:237]     Train net output #1: loss = 0.0763733 (* 1 = 0.0763733 loss)
I1211 20:13:52.603312 20404 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1211 20:14:00.152189  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:14:00.466212 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_68500.caffemodel
I1211 20:14:00.497211 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_68500.solverstate
I1211 20:14:00.503211 20404 solver.cpp:330] Iteration 68500, Testing net (#0)
I1211 20:14:00.504214 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:14:02.171336  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:14:02.238335 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8746
I1211 20:14:02.238335 20404 solver.cpp:397]     Test net output #1: loss = 0.395256 (* 1 = 0.395256 loss)
I1211 20:14:02.312345 20404 solver.cpp:218] Iteration 68500 (10.2996 iter/s, 9.7091s/100 iters), loss = 0.163362
I1211 20:14:02.312345 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:14:02.312345 20404 solver.cpp:237]     Train net output #1: loss = 0.163363 (* 1 = 0.163363 loss)
I1211 20:14:02.312345 20404 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1211 20:14:10.248399 20404 solver.cpp:218] Iteration 68600 (12.6014 iter/s, 7.93565s/100 iters), loss = 0.116742
I1211 20:14:10.248399 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:14:10.248399 20404 solver.cpp:237]     Train net output #1: loss = 0.116743 (* 1 = 0.116743 loss)
I1211 20:14:10.248399 20404 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1211 20:14:18.176172 20404 solver.cpp:218] Iteration 68700 (12.6155 iter/s, 7.92676s/100 iters), loss = 0.106026
I1211 20:14:18.176172 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:14:18.176172 20404 solver.cpp:237]     Train net output #1: loss = 0.106026 (* 1 = 0.106026 loss)
I1211 20:14:18.176172 20404 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1211 20:14:26.108964 20404 solver.cpp:218] Iteration 68800 (12.606 iter/s, 7.93274s/100 iters), loss = 0.112833
I1211 20:14:26.108964 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:14:26.108964 20404 solver.cpp:237]     Train net output #1: loss = 0.112833 (* 1 = 0.112833 loss)
I1211 20:14:26.108964 20404 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1211 20:14:34.041978 20404 solver.cpp:218] Iteration 68900 (12.6072 iter/s, 7.93197s/100 iters), loss = 0.113742
I1211 20:14:34.041978 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:14:34.041978 20404 solver.cpp:237]     Train net output #1: loss = 0.113742 (* 1 = 0.113742 loss)
I1211 20:14:34.041978 20404 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1211 20:14:41.585347  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:14:41.897246 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_69000.caffemodel
I1211 20:14:41.954268 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_69000.solverstate
I1211 20:14:41.960271 20404 solver.cpp:330] Iteration 69000, Testing net (#0)
I1211 20:14:41.960271 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:14:43.628315  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:14:43.694334 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8924
I1211 20:14:43.694334 20404 solver.cpp:397]     Test net output #1: loss = 0.356452 (* 1 = 0.356452 loss)
I1211 20:14:43.768353 20404 solver.cpp:218] Iteration 69000 (10.2818 iter/s, 9.72595s/100 iters), loss = 0.125419
I1211 20:14:43.768353 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:14:43.768353 20404 solver.cpp:237]     Train net output #1: loss = 0.125419 (* 1 = 0.125419 loss)
I1211 20:14:43.768353 20404 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1211 20:14:51.701496 20404 solver.cpp:218] Iteration 69100 (12.6052 iter/s, 7.93325s/100 iters), loss = 0.0803358
I1211 20:14:51.702497 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:14:51.702497 20404 solver.cpp:237]     Train net output #1: loss = 0.0803361 (* 1 = 0.0803361 loss)
I1211 20:14:51.702497 20404 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1211 20:14:59.642338 20404 solver.cpp:218] Iteration 69200 (12.5938 iter/s, 7.94039s/100 iters), loss = 0.139248
I1211 20:14:59.643338 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:14:59.643338 20404 solver.cpp:237]     Train net output #1: loss = 0.139248 (* 1 = 0.139248 loss)
I1211 20:14:59.643338 20404 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1211 20:15:07.569677 20404 solver.cpp:218] Iteration 69300 (12.6165 iter/s, 7.92614s/100 iters), loss = 0.112166
I1211 20:15:07.569677 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:15:07.569677 20404 solver.cpp:237]     Train net output #1: loss = 0.112166 (* 1 = 0.112166 loss)
I1211 20:15:07.569677 20404 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1211 20:15:15.503438 20404 solver.cpp:218] Iteration 69400 (12.6042 iter/s, 7.93384s/100 iters), loss = 0.127069
I1211 20:15:15.503438 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:15:15.503438 20404 solver.cpp:237]     Train net output #1: loss = 0.127069 (* 1 = 0.127069 loss)
I1211 20:15:15.503438 20404 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1211 20:15:23.058522  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:15:23.371582 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_69500.caffemodel
I1211 20:15:23.402585 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_69500.solverstate
I1211 20:15:23.408586 20404 solver.cpp:330] Iteration 69500, Testing net (#0)
I1211 20:15:23.408586 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:15:25.074523  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:15:25.140534 20404 solver.cpp:397]     Test net output #0: accuracy = 0.879
I1211 20:15:25.140534 20404 solver.cpp:397]     Test net output #1: loss = 0.385554 (* 1 = 0.385554 loss)
I1211 20:15:25.214553 20404 solver.cpp:218] Iteration 69500 (10.2981 iter/s, 9.71057s/100 iters), loss = 0.0837811
I1211 20:15:25.214553 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:15:25.214553 20404 solver.cpp:237]     Train net output #1: loss = 0.0837814 (* 1 = 0.0837814 loss)
I1211 20:15:25.214553 20404 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1211 20:15:33.148257 20404 solver.cpp:218] Iteration 69600 (12.6065 iter/s, 7.93243s/100 iters), loss = 0.109759
I1211 20:15:33.148257 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:15:33.148257 20404 solver.cpp:237]     Train net output #1: loss = 0.109759 (* 1 = 0.109759 loss)
I1211 20:15:33.148257 20404 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1211 20:15:41.075234 20404 solver.cpp:218] Iteration 69700 (12.6158 iter/s, 7.92655s/100 iters), loss = 0.100765
I1211 20:15:41.075234 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:15:41.075234 20404 solver.cpp:237]     Train net output #1: loss = 0.100765 (* 1 = 0.100765 loss)
I1211 20:15:41.075234 20404 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1211 20:15:49.003612 20404 solver.cpp:218] Iteration 69800 (12.6125 iter/s, 7.92865s/100 iters), loss = 0.106918
I1211 20:15:49.003612 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:15:49.003612 20404 solver.cpp:237]     Train net output #1: loss = 0.106919 (* 1 = 0.106919 loss)
I1211 20:15:49.003612 20404 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1211 20:15:56.943424 20404 solver.cpp:218] Iteration 69900 (12.5957 iter/s, 7.93921s/100 iters), loss = 0.08364
I1211 20:15:56.943424 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:15:56.943424 20404 solver.cpp:237]     Train net output #1: loss = 0.0836403 (* 1 = 0.0836403 loss)
I1211 20:15:56.943424 20404 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1211 20:16:04.487159  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:16:04.801225 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_70000.caffemodel
I1211 20:16:04.854225 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_70000.solverstate
I1211 20:16:04.860226 20404 solver.cpp:330] Iteration 70000, Testing net (#0)
I1211 20:16:04.860226 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:16:06.524530  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:16:06.590536 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9
I1211 20:16:06.591034 20404 solver.cpp:397]     Test net output #1: loss = 0.312469 (* 1 = 0.312469 loss)
I1211 20:16:06.664536 20404 solver.cpp:218] Iteration 70000 (10.2872 iter/s, 9.72084s/100 iters), loss = 0.151564
I1211 20:16:06.665536 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:16:06.665536 20404 solver.cpp:237]     Train net output #1: loss = 0.151564 (* 1 = 0.151564 loss)
I1211 20:16:06.665536 20404 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1211 20:16:14.597229 20404 solver.cpp:218] Iteration 70100 (12.6078 iter/s, 7.93158s/100 iters), loss = 0.0861618
I1211 20:16:14.597229 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:16:14.597229 20404 solver.cpp:237]     Train net output #1: loss = 0.0861621 (* 1 = 0.0861621 loss)
I1211 20:16:14.597229 20404 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1211 20:16:22.527493 20404 solver.cpp:218] Iteration 70200 (12.6102 iter/s, 7.93011s/100 iters), loss = 0.0896557
I1211 20:16:22.527493 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:16:22.527493 20404 solver.cpp:237]     Train net output #1: loss = 0.089656 (* 1 = 0.089656 loss)
I1211 20:16:22.527493 20404 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1211 20:16:30.465848 20404 solver.cpp:218] Iteration 70300 (12.5982 iter/s, 7.93763s/100 iters), loss = 0.1416
I1211 20:16:30.465848 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:16:30.465848 20404 solver.cpp:237]     Train net output #1: loss = 0.1416 (* 1 = 0.1416 loss)
I1211 20:16:30.465848 20404 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1211 20:16:38.390861 20404 solver.cpp:218] Iteration 70400 (12.619 iter/s, 7.92456s/100 iters), loss = 0.14629
I1211 20:16:38.391361 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:16:38.391361 20404 solver.cpp:237]     Train net output #1: loss = 0.14629 (* 1 = 0.14629 loss)
I1211 20:16:38.391361 20404 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1211 20:16:45.942250  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:16:46.257270 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_70500.caffemodel
I1211 20:16:46.285269 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_70500.solverstate
I1211 20:16:46.291275 20404 solver.cpp:330] Iteration 70500, Testing net (#0)
I1211 20:16:46.291275 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:16:47.956409  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:16:48.022415 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8772
I1211 20:16:48.022415 20404 solver.cpp:397]     Test net output #1: loss = 0.401591 (* 1 = 0.401591 loss)
I1211 20:16:48.096918 20404 solver.cpp:218] Iteration 70500 (10.3034 iter/s, 9.70553s/100 iters), loss = 0.0886475
I1211 20:16:48.097419 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:16:48.097419 20404 solver.cpp:237]     Train net output #1: loss = 0.0886478 (* 1 = 0.0886478 loss)
I1211 20:16:48.097419 20404 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1211 20:16:56.040552 20404 solver.cpp:218] Iteration 70600 (12.5897 iter/s, 7.94303s/100 iters), loss = 0.113094
I1211 20:16:56.040552 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:16:56.040552 20404 solver.cpp:237]     Train net output #1: loss = 0.113094 (* 1 = 0.113094 loss)
I1211 20:16:56.040552 20404 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1211 20:17:03.975412 20404 solver.cpp:218] Iteration 70700 (12.6033 iter/s, 7.93443s/100 iters), loss = 0.0991037
I1211 20:17:03.975412 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:17:03.975412 20404 solver.cpp:237]     Train net output #1: loss = 0.0991039 (* 1 = 0.0991039 loss)
I1211 20:17:03.975412 20404 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1211 20:17:11.911615 20404 solver.cpp:218] Iteration 70800 (12.6007 iter/s, 7.93609s/100 iters), loss = 0.126829
I1211 20:17:11.911615 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:17:11.911615 20404 solver.cpp:237]     Train net output #1: loss = 0.12683 (* 1 = 0.12683 loss)
I1211 20:17:11.911615 20404 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1211 20:17:19.845211 20404 solver.cpp:218] Iteration 70900 (12.6062 iter/s, 7.93263s/100 iters), loss = 0.099446
I1211 20:17:19.845211 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:17:19.845211 20404 solver.cpp:237]     Train net output #1: loss = 0.0994463 (* 1 = 0.0994463 loss)
I1211 20:17:19.845211 20404 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1211 20:17:27.780156  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:17:28.094173 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_71000.caffemodel
I1211 20:17:28.145171 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_71000.solverstate
I1211 20:17:28.151172 20404 solver.cpp:330] Iteration 71000, Testing net (#0)
I1211 20:17:28.151172 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:17:29.825502  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:17:29.892508 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8981
I1211 20:17:29.892508 20404 solver.cpp:397]     Test net output #1: loss = 0.334453 (* 1 = 0.334453 loss)
I1211 20:17:29.967008 20404 solver.cpp:218] Iteration 71000 (9.88005 iter/s, 10.1214s/100 iters), loss = 0.115363
I1211 20:17:29.967008 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:17:29.967008 20404 solver.cpp:237]     Train net output #1: loss = 0.115363 (* 1 = 0.115363 loss)
I1211 20:17:29.967008 20404 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1211 20:17:38.012665 20404 solver.cpp:218] Iteration 71100 (12.4291 iter/s, 8.04563s/100 iters), loss = 0.141607
I1211 20:17:38.012665 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:17:38.012665 20404 solver.cpp:237]     Train net output #1: loss = 0.141607 (* 1 = 0.141607 loss)
I1211 20:17:38.012665 20404 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1211 20:17:46.068668 20404 solver.cpp:218] Iteration 71200 (12.4145 iter/s, 8.05509s/100 iters), loss = 0.122142
I1211 20:17:46.069169 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:17:46.069169 20404 solver.cpp:237]     Train net output #1: loss = 0.122143 (* 1 = 0.122143 loss)
I1211 20:17:46.069169 20404 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1211 20:17:54.191668 20404 solver.cpp:218] Iteration 71300 (12.311 iter/s, 8.12279s/100 iters), loss = 0.117584
I1211 20:17:54.191668 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:17:54.191668 20404 solver.cpp:237]     Train net output #1: loss = 0.117584 (* 1 = 0.117584 loss)
I1211 20:17:54.192670 20404 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1211 20:18:02.343284 20404 solver.cpp:218] Iteration 71400 (12.2694 iter/s, 8.15034s/100 iters), loss = 0.0612626
I1211 20:18:02.343284 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:18:02.343284 20404 solver.cpp:237]     Train net output #1: loss = 0.0612628 (* 1 = 0.0612628 loss)
I1211 20:18:02.343284 20404 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1211 20:18:10.047829  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:18:10.373463 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_71500.caffemodel
I1211 20:18:10.402971 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_71500.solverstate
I1211 20:18:10.408969 20404 solver.cpp:330] Iteration 71500, Testing net (#0)
I1211 20:18:10.408969 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:18:12.115530  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:18:12.184538 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9017
I1211 20:18:12.184538 20404 solver.cpp:397]     Test net output #1: loss = 0.314725 (* 1 = 0.314725 loss)
I1211 20:18:12.260555 20404 solver.cpp:218] Iteration 71500 (10.0834 iter/s, 9.91728s/100 iters), loss = 0.127434
I1211 20:18:12.260555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:18:12.260555 20404 solver.cpp:237]     Train net output #1: loss = 0.127434 (* 1 = 0.127434 loss)
I1211 20:18:12.260555 20404 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1211 20:18:20.368070 20404 solver.cpp:218] Iteration 71600 (12.3358 iter/s, 8.10648s/100 iters), loss = 0.112134
I1211 20:18:20.368070 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:18:20.368070 20404 solver.cpp:237]     Train net output #1: loss = 0.112134 (* 1 = 0.112134 loss)
I1211 20:18:20.368070 20404 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1211 20:18:28.482699 20404 solver.cpp:218] Iteration 71700 (12.3242 iter/s, 8.1141s/100 iters), loss = 0.107283
I1211 20:18:28.482699 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:18:28.482699 20404 solver.cpp:237]     Train net output #1: loss = 0.107283 (* 1 = 0.107283 loss)
I1211 20:18:28.482699 20404 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1211 20:18:36.559716 20404 solver.cpp:218] Iteration 71800 (12.3818 iter/s, 8.07637s/100 iters), loss = 0.135719
I1211 20:18:36.559716 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:18:36.559716 20404 solver.cpp:237]     Train net output #1: loss = 0.135719 (* 1 = 0.135719 loss)
I1211 20:18:36.559716 20404 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1211 20:18:44.721046 20404 solver.cpp:218] Iteration 71900 (12.2535 iter/s, 8.16095s/100 iters), loss = 0.0755604
I1211 20:18:44.721046 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:18:44.721046 20404 solver.cpp:237]     Train net output #1: loss = 0.0755605 (* 1 = 0.0755605 loss)
I1211 20:18:44.721046 20404 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1211 20:18:52.422344  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:18:52.744594 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_72000.caffemodel
I1211 20:18:52.803750 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_72000.solverstate
I1211 20:18:52.809751 20404 solver.cpp:330] Iteration 72000, Testing net (#0)
I1211 20:18:52.809751 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:18:54.522918  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:18:54.591924 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8816
I1211 20:18:54.591924 20404 solver.cpp:397]     Test net output #1: loss = 0.383065 (* 1 = 0.383065 loss)
I1211 20:18:54.667695 20404 solver.cpp:218] Iteration 72000 (10.0536 iter/s, 9.94667s/100 iters), loss = 0.115379
I1211 20:18:54.667695 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:18:54.667695 20404 solver.cpp:237]     Train net output #1: loss = 0.115379 (* 1 = 0.115379 loss)
I1211 20:18:54.667695 20404 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1211 20:19:02.796870 20404 solver.cpp:218] Iteration 72100 (12.3032 iter/s, 8.12799s/100 iters), loss = 0.103533
I1211 20:19:02.796870 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:19:02.796870 20404 solver.cpp:237]     Train net output #1: loss = 0.103533 (* 1 = 0.103533 loss)
I1211 20:19:02.796870 20404 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1211 20:19:10.946946 20404 solver.cpp:218] Iteration 72200 (12.2698 iter/s, 8.15009s/100 iters), loss = 0.138637
I1211 20:19:10.946946 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:19:10.946946 20404 solver.cpp:237]     Train net output #1: loss = 0.138637 (* 1 = 0.138637 loss)
I1211 20:19:10.946946 20404 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1211 20:19:19.089612 20404 solver.cpp:218] Iteration 72300 (12.2816 iter/s, 8.14229s/100 iters), loss = 0.0793711
I1211 20:19:19.090595 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:19:19.090595 20404 solver.cpp:237]     Train net output #1: loss = 0.0793713 (* 1 = 0.0793713 loss)
I1211 20:19:19.090595 20404 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1211 20:19:27.261278 20404 solver.cpp:218] Iteration 72400 (12.2392 iter/s, 8.17045s/100 iters), loss = 0.0811464
I1211 20:19:27.261278 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:19:27.261278 20404 solver.cpp:237]     Train net output #1: loss = 0.0811465 (* 1 = 0.0811465 loss)
I1211 20:19:27.261278 20404 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1211 20:19:35.047479  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:19:35.368602 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_72500.caffemodel
I1211 20:19:35.400105 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_72500.solverstate
I1211 20:19:35.406105 20404 solver.cpp:330] Iteration 72500, Testing net (#0)
I1211 20:19:35.406105 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:19:37.113791  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:19:37.181289 20404 solver.cpp:397]     Test net output #0: accuracy = 0.881
I1211 20:19:37.181289 20404 solver.cpp:397]     Test net output #1: loss = 0.379225 (* 1 = 0.379225 loss)
I1211 20:19:37.258301 20404 solver.cpp:218] Iteration 72500 (10.0036 iter/s, 9.9964s/100 iters), loss = 0.108776
I1211 20:19:37.258301 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:19:37.258301 20404 solver.cpp:237]     Train net output #1: loss = 0.108776 (* 1 = 0.108776 loss)
I1211 20:19:37.258301 20404 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1211 20:19:45.310060 20404 solver.cpp:218] Iteration 72600 (12.421 iter/s, 8.0509s/100 iters), loss = 0.0519437
I1211 20:19:45.310060 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:19:45.310060 20404 solver.cpp:237]     Train net output #1: loss = 0.0519439 (* 1 = 0.0519439 loss)
I1211 20:19:45.310060 20404 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1211 20:19:53.300616 20404 solver.cpp:218] Iteration 72700 (12.5146 iter/s, 7.99069s/100 iters), loss = 0.131791
I1211 20:19:53.300616 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:19:53.300616 20404 solver.cpp:237]     Train net output #1: loss = 0.131791 (* 1 = 0.131791 loss)
I1211 20:19:53.300616 20404 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1211 20:20:01.342525 20404 solver.cpp:218] Iteration 72800 (12.4362 iter/s, 8.04105s/100 iters), loss = 0.165799
I1211 20:20:01.342525 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:20:01.342525 20404 solver.cpp:237]     Train net output #1: loss = 0.1658 (* 1 = 0.1658 loss)
I1211 20:20:01.342525 20404 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1211 20:20:09.365315 20404 solver.cpp:218] Iteration 72900 (12.4653 iter/s, 8.0223s/100 iters), loss = 0.0727502
I1211 20:20:09.365315 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:20:09.365816 20404 solver.cpp:237]     Train net output #1: loss = 0.0727503 (* 1 = 0.0727503 loss)
I1211 20:20:09.365816 20404 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1211 20:20:16.922011  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:20:17.238474 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_73000.caffemodel
I1211 20:20:17.292544 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_73000.solverstate
I1211 20:20:17.298559 20404 solver.cpp:330] Iteration 73000, Testing net (#0)
I1211 20:20:17.298559 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:20:18.966686  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:20:19.033825 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8805
I1211 20:20:19.033825 20404 solver.cpp:397]     Test net output #1: loss = 0.378793 (* 1 = 0.378793 loss)
I1211 20:20:19.107245 20404 solver.cpp:218] Iteration 73000 (10.2651 iter/s, 9.74179s/100 iters), loss = 0.144091
I1211 20:20:19.107245 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:20:19.107245 20404 solver.cpp:237]     Train net output #1: loss = 0.144091 (* 1 = 0.144091 loss)
I1211 20:20:19.107245 20404 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1211 20:20:27.068881 20404 solver.cpp:218] Iteration 73100 (12.5622 iter/s, 7.96042s/100 iters), loss = 0.140508
I1211 20:20:27.068881 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:20:27.068881 20404 solver.cpp:237]     Train net output #1: loss = 0.140508 (* 1 = 0.140508 loss)
I1211 20:20:27.068881 20404 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1211 20:20:35.023234 20404 solver.cpp:218] Iteration 73200 (12.5714 iter/s, 7.95454s/100 iters), loss = 0.0870163
I1211 20:20:35.023234 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:20:35.023234 20404 solver.cpp:237]     Train net output #1: loss = 0.0870164 (* 1 = 0.0870164 loss)
I1211 20:20:35.023234 20404 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1211 20:20:42.976331 20404 solver.cpp:218] Iteration 73300 (12.5754 iter/s, 7.95204s/100 iters), loss = 0.146658
I1211 20:20:42.976331 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:20:42.976331 20404 solver.cpp:237]     Train net output #1: loss = 0.146658 (* 1 = 0.146658 loss)
I1211 20:20:42.976331 20404 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1211 20:20:50.931367 20404 solver.cpp:218] Iteration 73400 (12.5717 iter/s, 7.95439s/100 iters), loss = 0.17454
I1211 20:20:50.931367 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:20:50.931367 20404 solver.cpp:237]     Train net output #1: loss = 0.17454 (* 1 = 0.17454 loss)
I1211 20:20:50.931367 20404 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1211 20:20:58.616348  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:20:58.935384 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_73500.caffemodel
I1211 20:20:58.962383 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_73500.solverstate
I1211 20:20:58.968384 20404 solver.cpp:330] Iteration 73500, Testing net (#0)
I1211 20:20:58.968384 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:21:00.665534  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:21:00.732574 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8851
I1211 20:21:00.732574 20404 solver.cpp:397]     Test net output #1: loss = 0.3729 (* 1 = 0.3729 loss)
I1211 20:21:00.806607 20404 solver.cpp:218] Iteration 73500 (10.1263 iter/s, 9.87527s/100 iters), loss = 0.100458
I1211 20:21:00.806607 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:21:00.806607 20404 solver.cpp:237]     Train net output #1: loss = 0.100458 (* 1 = 0.100458 loss)
I1211 20:21:00.806607 20404 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1211 20:21:08.856886 20404 solver.cpp:218] Iteration 73600 (12.4224 iter/s, 8.04998s/100 iters), loss = 0.15749
I1211 20:21:08.856886 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:21:08.856886 20404 solver.cpp:237]     Train net output #1: loss = 0.15749 (* 1 = 0.15749 loss)
I1211 20:21:08.856886 20404 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1211 20:21:16.990591 20404 solver.cpp:218] Iteration 73700 (12.2964 iter/s, 8.13244s/100 iters), loss = 0.143927
I1211 20:21:16.990591 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:21:16.990591 20404 solver.cpp:237]     Train net output #1: loss = 0.143927 (* 1 = 0.143927 loss)
I1211 20:21:16.990591 20404 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1211 20:21:24.941903 20404 solver.cpp:218] Iteration 73800 (12.5774 iter/s, 7.95079s/100 iters), loss = 0.0852195
I1211 20:21:24.941903 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:21:24.941903 20404 solver.cpp:237]     Train net output #1: loss = 0.0852196 (* 1 = 0.0852196 loss)
I1211 20:21:24.941903 20404 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1211 20:21:32.963832 20404 solver.cpp:218] Iteration 73900 (12.4667 iter/s, 8.02135s/100 iters), loss = 0.081875
I1211 20:21:32.963832 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:21:32.963832 20404 solver.cpp:237]     Train net output #1: loss = 0.0818752 (* 1 = 0.0818752 loss)
I1211 20:21:32.963832 20404 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1211 20:21:40.802193  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:21:41.121227 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_74000.caffemodel
I1211 20:21:41.184733 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_74000.solverstate
I1211 20:21:41.190248 20404 solver.cpp:330] Iteration 74000, Testing net (#0)
I1211 20:21:41.190248 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:21:42.869449  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:21:42.935465 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8822
I1211 20:21:42.935465 20404 solver.cpp:397]     Test net output #1: loss = 0.373411 (* 1 = 0.373411 loss)
I1211 20:21:43.009485 20404 solver.cpp:218] Iteration 74000 (9.95458 iter/s, 10.0456s/100 iters), loss = 0.162636
I1211 20:21:43.009485 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:21:43.009485 20404 solver.cpp:237]     Train net output #1: loss = 0.162637 (* 1 = 0.162637 loss)
I1211 20:21:43.009485 20404 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1211 20:21:50.961369 20404 solver.cpp:218] Iteration 74100 (12.5769 iter/s, 7.95111s/100 iters), loss = 0.176299
I1211 20:21:50.961369 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:21:50.961369 20404 solver.cpp:237]     Train net output #1: loss = 0.176299 (* 1 = 0.176299 loss)
I1211 20:21:50.961369 20404 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1211 20:21:58.921231 20404 solver.cpp:218] Iteration 74200 (12.5636 iter/s, 7.95947s/100 iters), loss = 0.110678
I1211 20:21:58.921231 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:21:58.921231 20404 solver.cpp:237]     Train net output #1: loss = 0.110679 (* 1 = 0.110679 loss)
I1211 20:21:58.921231 20404 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1211 20:22:06.901831 20404 solver.cpp:218] Iteration 74300 (12.5304 iter/s, 7.98058s/100 iters), loss = 0.0577682
I1211 20:22:06.901831 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:22:06.902832 20404 solver.cpp:237]     Train net output #1: loss = 0.0577683 (* 1 = 0.0577683 loss)
I1211 20:22:06.902832 20404 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1211 20:22:14.868222 20404 solver.cpp:218] Iteration 74400 (12.5545 iter/s, 7.96527s/100 iters), loss = 0.152465
I1211 20:22:14.868222 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:22:14.868222 20404 solver.cpp:237]     Train net output #1: loss = 0.152466 (* 1 = 0.152466 loss)
I1211 20:22:14.868222 20404 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1211 20:22:22.451963  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:22:22.766707 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_74500.caffemodel
I1211 20:22:22.805217 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_74500.solverstate
I1211 20:22:22.811218 20404 solver.cpp:330] Iteration 74500, Testing net (#0)
I1211 20:22:22.812217 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:22:24.484027  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:22:24.552026 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8816
I1211 20:22:24.552026 20404 solver.cpp:397]     Test net output #1: loss = 0.370064 (* 1 = 0.370064 loss)
I1211 20:22:24.626049 20404 solver.cpp:218] Iteration 74500 (10.2482 iter/s, 9.7578s/100 iters), loss = 0.125375
I1211 20:22:24.626049 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:22:24.626049 20404 solver.cpp:237]     Train net output #1: loss = 0.125375 (* 1 = 0.125375 loss)
I1211 20:22:24.626049 20404 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1211 20:22:32.677397 20404 solver.cpp:218] Iteration 74600 (12.4219 iter/s, 8.05032s/100 iters), loss = 0.0721484
I1211 20:22:32.677397 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:22:32.677397 20404 solver.cpp:237]     Train net output #1: loss = 0.0721485 (* 1 = 0.0721485 loss)
I1211 20:22:32.677397 20404 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1211 20:22:40.637199 20404 solver.cpp:218] Iteration 74700 (12.5629 iter/s, 7.95996s/100 iters), loss = 0.0749118
I1211 20:22:40.637199 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:22:40.637199 20404 solver.cpp:237]     Train net output #1: loss = 0.074912 (* 1 = 0.074912 loss)
I1211 20:22:40.637199 20404 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1211 20:22:48.572144 20404 solver.cpp:218] Iteration 74800 (12.6035 iter/s, 7.93429s/100 iters), loss = 0.123948
I1211 20:22:48.572144 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:22:48.572144 20404 solver.cpp:237]     Train net output #1: loss = 0.123948 (* 1 = 0.123948 loss)
I1211 20:22:48.572144 20404 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1211 20:22:56.515187 20404 solver.cpp:218] Iteration 74900 (12.5913 iter/s, 7.94199s/100 iters), loss = 0.0661623
I1211 20:22:56.515187 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:22:56.515187 20404 solver.cpp:237]     Train net output #1: loss = 0.0661624 (* 1 = 0.0661624 loss)
I1211 20:22:56.515187 20404 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1211 20:23:04.068259  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:23:04.382302 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_75000.caffemodel
I1211 20:23:04.415310 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_75000.solverstate
I1211 20:23:04.421329 20404 solver.cpp:330] Iteration 75000, Testing net (#0)
I1211 20:23:04.421329 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:23:06.095504  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:23:06.161515 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9019
I1211 20:23:06.161515 20404 solver.cpp:397]     Test net output #1: loss = 0.30659 (* 1 = 0.30659 loss)
I1211 20:23:06.237514 20404 solver.cpp:218] Iteration 75000 (10.2863 iter/s, 9.72167s/100 iters), loss = 0.0677919
I1211 20:23:06.237514 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:23:06.237514 20404 solver.cpp:237]     Train net output #1: loss = 0.067792 (* 1 = 0.067792 loss)
I1211 20:23:06.237514 20404 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1211 20:23:14.191975 20404 solver.cpp:218] Iteration 75100 (12.5722 iter/s, 7.95404s/100 iters), loss = 0.116663
I1211 20:23:14.191975 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:23:14.191975 20404 solver.cpp:237]     Train net output #1: loss = 0.116663 (* 1 = 0.116663 loss)
I1211 20:23:14.191975 20404 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1211 20:23:22.138864 20404 solver.cpp:218] Iteration 75200 (12.5843 iter/s, 7.9464s/100 iters), loss = 0.205028
I1211 20:23:22.138864 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:23:22.138864 20404 solver.cpp:237]     Train net output #1: loss = 0.205028 (* 1 = 0.205028 loss)
I1211 20:23:22.138864 20404 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1211 20:23:30.084003 20404 solver.cpp:218] Iteration 75300 (12.5859 iter/s, 7.94542s/100 iters), loss = 0.16246
I1211 20:23:30.084995 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:23:30.084995 20404 solver.cpp:237]     Train net output #1: loss = 0.16246 (* 1 = 0.16246 loss)
I1211 20:23:30.084995 20404 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1211 20:23:38.041169 20404 solver.cpp:218] Iteration 75400 (12.5689 iter/s, 7.95615s/100 iters), loss = 0.119525
I1211 20:23:38.041169 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:23:38.041169 20404 solver.cpp:237]     Train net output #1: loss = 0.119525 (* 1 = 0.119525 loss)
I1211 20:23:38.041169 20404 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1211 20:23:45.682911  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:23:45.999961 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_75500.caffemodel
I1211 20:23:46.039973 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_75500.solverstate
I1211 20:23:46.045974 20404 solver.cpp:330] Iteration 75500, Testing net (#0)
I1211 20:23:46.045974 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:23:47.734268  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:23:47.801266 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I1211 20:23:47.801266 20404 solver.cpp:397]     Test net output #1: loss = 0.333294 (* 1 = 0.333294 loss)
I1211 20:23:47.876276 20404 solver.cpp:218] Iteration 75500 (10.1681 iter/s, 9.8347s/100 iters), loss = 0.191829
I1211 20:23:47.876276 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 20:23:47.876276 20404 solver.cpp:237]     Train net output #1: loss = 0.191829 (* 1 = 0.191829 loss)
I1211 20:23:47.876276 20404 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1211 20:23:55.892036 20404 solver.cpp:218] Iteration 75600 (12.4768 iter/s, 8.0149s/100 iters), loss = 0.0986156
I1211 20:23:55.892036 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:23:55.892036 20404 solver.cpp:237]     Train net output #1: loss = 0.0986158 (* 1 = 0.0986158 loss)
I1211 20:23:55.892036 20404 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1211 20:24:03.896824 20404 solver.cpp:218] Iteration 75700 (12.4921 iter/s, 8.00506s/100 iters), loss = 0.107506
I1211 20:24:03.897825 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:24:03.897825 20404 solver.cpp:237]     Train net output #1: loss = 0.107506 (* 1 = 0.107506 loss)
I1211 20:24:03.897825 20404 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1211 20:24:11.848798 20404 solver.cpp:218] Iteration 75800 (12.5768 iter/s, 7.95112s/100 iters), loss = 0.080521
I1211 20:24:11.848798 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:24:11.848798 20404 solver.cpp:237]     Train net output #1: loss = 0.0805213 (* 1 = 0.0805213 loss)
I1211 20:24:11.848798 20404 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1211 20:24:19.801971 20404 solver.cpp:218] Iteration 75900 (12.5746 iter/s, 7.95254s/100 iters), loss = 0.0679645
I1211 20:24:19.801971 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:24:19.801971 20404 solver.cpp:237]     Train net output #1: loss = 0.0679647 (* 1 = 0.0679647 loss)
I1211 20:24:19.801971 20404 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1211 20:24:27.404464  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:24:27.720049 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_76000.caffemodel
I1211 20:24:27.754542 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_76000.solverstate
I1211 20:24:27.760543 20404 solver.cpp:330] Iteration 76000, Testing net (#0)
I1211 20:24:27.760543 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:24:29.434878  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:24:29.501878 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8815
I1211 20:24:29.501878 20404 solver.cpp:397]     Test net output #1: loss = 0.372688 (* 1 = 0.372688 loss)
I1211 20:24:29.576882 20404 solver.cpp:218] Iteration 76000 (10.2313 iter/s, 9.77397s/100 iters), loss = 0.0790923
I1211 20:24:29.576882 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:24:29.576882 20404 solver.cpp:237]     Train net output #1: loss = 0.0790925 (* 1 = 0.0790925 loss)
I1211 20:24:29.576882 20404 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1211 20:24:37.553478 20404 solver.cpp:218] Iteration 76100 (12.5375 iter/s, 7.9761s/100 iters), loss = 0.133215
I1211 20:24:37.553478 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:24:37.553478 20404 solver.cpp:237]     Train net output #1: loss = 0.133215 (* 1 = 0.133215 loss)
I1211 20:24:37.553478 20404 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1211 20:24:45.570411 20404 solver.cpp:218] Iteration 76200 (12.474 iter/s, 8.01667s/100 iters), loss = 0.142889
I1211 20:24:45.570411 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:24:45.570411 20404 solver.cpp:237]     Train net output #1: loss = 0.142889 (* 1 = 0.142889 loss)
I1211 20:24:45.570411 20404 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1211 20:24:53.549463 20404 solver.cpp:218] Iteration 76300 (12.5333 iter/s, 7.97874s/100 iters), loss = 0.106733
I1211 20:24:53.549463 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:24:53.549463 20404 solver.cpp:237]     Train net output #1: loss = 0.106733 (* 1 = 0.106733 loss)
I1211 20:24:53.549463 20404 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1211 20:25:01.530416 20404 solver.cpp:218] Iteration 76400 (12.5318 iter/s, 7.97968s/100 iters), loss = 0.151597
I1211 20:25:01.530416 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 20:25:01.530416 20404 solver.cpp:237]     Train net output #1: loss = 0.151597 (* 1 = 0.151597 loss)
I1211 20:25:01.530416 20404 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1211 20:25:09.155215  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:25:09.470743 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_76500.caffemodel
I1211 20:25:09.499245 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_76500.solverstate
I1211 20:25:09.530246 20404 solver.cpp:330] Iteration 76500, Testing net (#0)
I1211 20:25:09.530246 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:25:11.216378  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:25:11.282383 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8779
I1211 20:25:11.282383 20404 solver.cpp:397]     Test net output #1: loss = 0.393023 (* 1 = 0.393023 loss)
I1211 20:25:11.357383 20404 solver.cpp:218] Iteration 76500 (10.176 iter/s, 9.82705s/100 iters), loss = 0.141465
I1211 20:25:11.357383 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:25:11.357383 20404 solver.cpp:237]     Train net output #1: loss = 0.141465 (* 1 = 0.141465 loss)
I1211 20:25:11.357383 20404 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1211 20:25:19.452486 20404 solver.cpp:218] Iteration 76600 (12.3547 iter/s, 8.0941s/100 iters), loss = 0.0790808
I1211 20:25:19.452486 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:25:19.452486 20404 solver.cpp:237]     Train net output #1: loss = 0.0790811 (* 1 = 0.0790811 loss)
I1211 20:25:19.452486 20404 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1211 20:25:27.782423 20404 solver.cpp:218] Iteration 76700 (12.0059 iter/s, 8.32922s/100 iters), loss = 0.164846
I1211 20:25:27.782423 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:25:27.782423 20404 solver.cpp:237]     Train net output #1: loss = 0.164846 (* 1 = 0.164846 loss)
I1211 20:25:27.782423 20404 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1211 20:25:36.091781 20404 solver.cpp:218] Iteration 76800 (12.0352 iter/s, 8.30894s/100 iters), loss = 0.130291
I1211 20:25:36.091781 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:25:36.091781 20404 solver.cpp:237]     Train net output #1: loss = 0.130291 (* 1 = 0.130291 loss)
I1211 20:25:36.091781 20404 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1211 20:25:44.329913 20404 solver.cpp:218] Iteration 76900 (12.1399 iter/s, 8.23728s/100 iters), loss = 0.100069
I1211 20:25:44.329913 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:25:44.329913 20404 solver.cpp:237]     Train net output #1: loss = 0.100069 (* 1 = 0.100069 loss)
I1211 20:25:44.329913 20404 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1211 20:25:52.192476  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:25:52.520977 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_77000.caffemodel
I1211 20:25:52.551992 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_77000.solverstate
I1211 20:25:52.557987 20404 solver.cpp:330] Iteration 77000, Testing net (#0)
I1211 20:25:52.557987 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:25:54.291741  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:25:54.358722 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8692
I1211 20:25:54.358722 20404 solver.cpp:397]     Test net output #1: loss = 0.435128 (* 1 = 0.435128 loss)
I1211 20:25:54.435921 20404 solver.cpp:218] Iteration 77000 (9.89489 iter/s, 10.1062s/100 iters), loss = 0.191369
I1211 20:25:54.435921 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:25:54.436921 20404 solver.cpp:237]     Train net output #1: loss = 0.191369 (* 1 = 0.191369 loss)
I1211 20:25:54.436921 20404 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1211 20:26:02.578897 20404 solver.cpp:218] Iteration 77100 (12.2826 iter/s, 8.1416s/100 iters), loss = 0.153297
I1211 20:26:02.578897 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:26:02.578897 20404 solver.cpp:237]     Train net output #1: loss = 0.153298 (* 1 = 0.153298 loss)
I1211 20:26:02.578897 20404 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1211 20:26:10.692859 20404 solver.cpp:218] Iteration 77200 (12.325 iter/s, 8.11356s/100 iters), loss = 0.0882945
I1211 20:26:10.692859 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:26:10.692859 20404 solver.cpp:237]     Train net output #1: loss = 0.0882948 (* 1 = 0.0882948 loss)
I1211 20:26:10.692859 20404 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1211 20:26:18.857525 20404 solver.cpp:218] Iteration 77300 (12.2491 iter/s, 8.16385s/100 iters), loss = 0.151157
I1211 20:26:18.857525 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:26:18.857525 20404 solver.cpp:237]     Train net output #1: loss = 0.151158 (* 1 = 0.151158 loss)
I1211 20:26:18.857525 20404 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1211 20:26:27.023988 20404 solver.cpp:218] Iteration 77400 (12.2461 iter/s, 8.16585s/100 iters), loss = 0.102522
I1211 20:26:27.023988 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:26:27.023988 20404 solver.cpp:237]     Train net output #1: loss = 0.102522 (* 1 = 0.102522 loss)
I1211 20:26:27.023988 20404 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1211 20:26:34.683851  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:26:35.001823 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_77500.caffemodel
I1211 20:26:35.042327 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_77500.solverstate
I1211 20:26:35.064324 20404 solver.cpp:330] Iteration 77500, Testing net (#0)
I1211 20:26:35.064324 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:26:36.771280  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:26:36.839293 20404 solver.cpp:397]     Test net output #0: accuracy = 0.892
I1211 20:26:36.839293 20404 solver.cpp:397]     Test net output #1: loss = 0.346541 (* 1 = 0.346541 loss)
I1211 20:26:36.915314 20404 solver.cpp:218] Iteration 77500 (10.1106 iter/s, 9.89063s/100 iters), loss = 0.101703
I1211 20:26:36.915314 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:26:36.915314 20404 solver.cpp:237]     Train net output #1: loss = 0.101703 (* 1 = 0.101703 loss)
I1211 20:26:36.915314 20404 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1211 20:26:45.003131 20404 solver.cpp:218] Iteration 77600 (12.3647 iter/s, 8.08752s/100 iters), loss = 0.172426
I1211 20:26:45.003131 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:26:45.003131 20404 solver.cpp:237]     Train net output #1: loss = 0.172426 (* 1 = 0.172426 loss)
I1211 20:26:45.003131 20404 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1211 20:26:53.057574 20404 solver.cpp:218] Iteration 77700 (12.4157 iter/s, 8.05432s/100 iters), loss = 0.189127
I1211 20:26:53.057574 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:26:53.057574 20404 solver.cpp:237]     Train net output #1: loss = 0.189128 (* 1 = 0.189128 loss)
I1211 20:26:53.057574 20404 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1211 20:27:01.068081 20404 solver.cpp:218] Iteration 77800 (12.4846 iter/s, 8.00989s/100 iters), loss = 0.111939
I1211 20:27:01.068081 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:27:01.068081 20404 solver.cpp:237]     Train net output #1: loss = 0.111939 (* 1 = 0.111939 loss)
I1211 20:27:01.068081 20404 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1211 20:27:09.067231 20404 solver.cpp:218] Iteration 77900 (12.503 iter/s, 7.9981s/100 iters), loss = 0.0974778
I1211 20:27:09.067231 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:27:09.067231 20404 solver.cpp:237]     Train net output #1: loss = 0.0974781 (* 1 = 0.0974781 loss)
I1211 20:27:09.067231 20404 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1211 20:27:16.686568  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:27:17.001590 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_78000.caffemodel
I1211 20:27:17.029599 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_78000.solverstate
I1211 20:27:17.035600 20404 solver.cpp:330] Iteration 78000, Testing net (#0)
I1211 20:27:17.035600 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:27:18.729794  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:27:18.797793 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8768
I1211 20:27:18.797793 20404 solver.cpp:397]     Test net output #1: loss = 0.420549 (* 1 = 0.420549 loss)
I1211 20:27:18.871801 20404 solver.cpp:218] Iteration 78000 (10.1993 iter/s, 9.80461s/100 iters), loss = 0.111971
I1211 20:27:18.871801 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:27:18.871801 20404 solver.cpp:237]     Train net output #1: loss = 0.111971 (* 1 = 0.111971 loss)
I1211 20:27:18.871801 20404 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1211 20:27:27.044004 20404 solver.cpp:218] Iteration 78100 (12.2384 iter/s, 8.17103s/100 iters), loss = 0.144103
I1211 20:27:27.044004 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:27:27.044004 20404 solver.cpp:237]     Train net output #1: loss = 0.144103 (* 1 = 0.144103 loss)
I1211 20:27:27.044004 20404 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1211 20:27:35.223683 20404 solver.cpp:218] Iteration 78200 (12.2259 iter/s, 8.17936s/100 iters), loss = 0.116151
I1211 20:27:35.223683 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:27:35.223683 20404 solver.cpp:237]     Train net output #1: loss = 0.116152 (* 1 = 0.116152 loss)
I1211 20:27:35.223683 20404 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1211 20:27:43.431119 20404 solver.cpp:218] Iteration 78300 (12.1851 iter/s, 8.20674s/100 iters), loss = 0.0849346
I1211 20:27:43.431119 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:27:43.431119 20404 solver.cpp:237]     Train net output #1: loss = 0.0849349 (* 1 = 0.0849349 loss)
I1211 20:27:43.431119 20404 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1211 20:27:51.715539 20404 solver.cpp:218] Iteration 78400 (12.0718 iter/s, 8.2838s/100 iters), loss = 0.0858613
I1211 20:27:51.715539 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:27:51.715539 20404 solver.cpp:237]     Train net output #1: loss = 0.0858616 (* 1 = 0.0858616 loss)
I1211 20:27:51.715539 20404 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1211 20:27:59.474452  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:27:59.789484 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_78500.caffemodel
I1211 20:27:59.821491 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_78500.solverstate
I1211 20:27:59.856281 20404 solver.cpp:330] Iteration 78500, Testing net (#0)
I1211 20:27:59.856281 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:28:01.542465  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:28:01.609489 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8642
I1211 20:28:01.609489 20404 solver.cpp:397]     Test net output #1: loss = 0.439868 (* 1 = 0.439868 loss)
I1211 20:28:01.684479 20404 solver.cpp:218] Iteration 78500 (10.0313 iter/s, 9.9688s/100 iters), loss = 0.160059
I1211 20:28:01.684479 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:28:01.684479 20404 solver.cpp:237]     Train net output #1: loss = 0.160059 (* 1 = 0.160059 loss)
I1211 20:28:01.684479 20404 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1211 20:28:09.769177 20404 solver.cpp:218] Iteration 78600 (12.3706 iter/s, 8.08367s/100 iters), loss = 0.105846
I1211 20:28:09.769177 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:28:09.769177 20404 solver.cpp:237]     Train net output #1: loss = 0.105847 (* 1 = 0.105847 loss)
I1211 20:28:09.769177 20404 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1211 20:28:17.826577 20404 solver.cpp:218] Iteration 78700 (12.4111 iter/s, 8.05728s/100 iters), loss = 0.134137
I1211 20:28:17.826577 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:28:17.826577 20404 solver.cpp:237]     Train net output #1: loss = 0.134138 (* 1 = 0.134138 loss)
I1211 20:28:17.826577 20404 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1211 20:28:25.884496 20404 solver.cpp:218] Iteration 78800 (12.4111 iter/s, 8.05731s/100 iters), loss = 0.117822
I1211 20:28:25.884496 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:28:25.884496 20404 solver.cpp:237]     Train net output #1: loss = 0.117822 (* 1 = 0.117822 loss)
I1211 20:28:25.884496 20404 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1211 20:28:33.945757 20404 solver.cpp:218] Iteration 78900 (12.4055 iter/s, 8.06091s/100 iters), loss = 0.160606
I1211 20:28:33.946259 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:28:33.946259 20404 solver.cpp:237]     Train net output #1: loss = 0.160606 (* 1 = 0.160606 loss)
I1211 20:28:33.946259 20404 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1211 20:28:41.616878  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:28:41.934566 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_79000.caffemodel
I1211 20:28:41.963095 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_79000.solverstate
I1211 20:28:41.970088 20404 solver.cpp:330] Iteration 79000, Testing net (#0)
I1211 20:28:41.970088 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:28:43.655174  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:28:43.722548 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8719
I1211 20:28:43.722548 20404 solver.cpp:397]     Test net output #1: loss = 0.407411 (* 1 = 0.407411 loss)
I1211 20:28:43.796443 20404 solver.cpp:218] Iteration 79000 (10.1518 iter/s, 9.85049s/100 iters), loss = 0.122291
I1211 20:28:43.796443 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:28:43.797443 20404 solver.cpp:237]     Train net output #1: loss = 0.122291 (* 1 = 0.122291 loss)
I1211 20:28:43.797443 20404 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1211 20:28:51.883222 20404 solver.cpp:218] Iteration 79100 (12.3678 iter/s, 8.08554s/100 iters), loss = 0.089438
I1211 20:28:51.883222 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:28:51.883222 20404 solver.cpp:237]     Train net output #1: loss = 0.0894383 (* 1 = 0.0894383 loss)
I1211 20:28:51.883222 20404 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1211 20:28:59.949126 20404 solver.cpp:218] Iteration 79200 (12.3986 iter/s, 8.06543s/100 iters), loss = 0.0805142
I1211 20:28:59.949126 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:28:59.949126 20404 solver.cpp:237]     Train net output #1: loss = 0.0805145 (* 1 = 0.0805145 loss)
I1211 20:28:59.949126 20404 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1211 20:29:07.997205 20404 solver.cpp:218] Iteration 79300 (12.4264 iter/s, 8.0474s/100 iters), loss = 0.0852107
I1211 20:29:07.997205 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:29:07.997205 20404 solver.cpp:237]     Train net output #1: loss = 0.085211 (* 1 = 0.085211 loss)
I1211 20:29:07.997205 20404 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1211 20:29:16.057531 20404 solver.cpp:218] Iteration 79400 (12.4071 iter/s, 8.05991s/100 iters), loss = 0.0772354
I1211 20:29:16.057531 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:29:16.057531 20404 solver.cpp:237]     Train net output #1: loss = 0.0772358 (* 1 = 0.0772358 loss)
I1211 20:29:16.057531 20404 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1211 20:29:23.727905  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:29:24.046946 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_79500.caffemodel
I1211 20:29:24.078954 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_79500.solverstate
I1211 20:29:24.105955 20404 solver.cpp:330] Iteration 79500, Testing net (#0)
I1211 20:29:24.105955 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:29:25.806228  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:29:25.873728 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8746
I1211 20:29:25.873728 20404 solver.cpp:397]     Test net output #1: loss = 0.410269 (* 1 = 0.410269 loss)
I1211 20:29:25.948230 20404 solver.cpp:218] Iteration 79500 (10.111 iter/s, 9.89024s/100 iters), loss = 0.144939
I1211 20:29:25.948230 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:29:25.948230 20404 solver.cpp:237]     Train net output #1: loss = 0.14494 (* 1 = 0.14494 loss)
I1211 20:29:25.948230 20404 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1211 20:29:33.954521 20404 solver.cpp:218] Iteration 79600 (12.4903 iter/s, 8.00624s/100 iters), loss = 0.127251
I1211 20:29:33.954521 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:29:33.954521 20404 solver.cpp:237]     Train net output #1: loss = 0.127252 (* 1 = 0.127252 loss)
I1211 20:29:33.954521 20404 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1211 20:29:41.960214 20404 solver.cpp:218] Iteration 79700 (12.4924 iter/s, 8.00484s/100 iters), loss = 0.108863
I1211 20:29:41.960214 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:29:41.960214 20404 solver.cpp:237]     Train net output #1: loss = 0.108863 (* 1 = 0.108863 loss)
I1211 20:29:41.960214 20404 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1211 20:29:50.214704 20404 solver.cpp:218] Iteration 79800 (12.1157 iter/s, 8.25375s/100 iters), loss = 0.0457134
I1211 20:29:50.214704 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:29:50.214704 20404 solver.cpp:237]     Train net output #1: loss = 0.0457138 (* 1 = 0.0457138 loss)
I1211 20:29:50.214704 20404 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1211 20:29:58.400521 20404 solver.cpp:218] Iteration 79900 (12.2167 iter/s, 8.18552s/100 iters), loss = 0.0763245
I1211 20:29:58.400521 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:29:58.400521 20404 solver.cpp:237]     Train net output #1: loss = 0.0763248 (* 1 = 0.0763248 loss)
I1211 20:29:58.400521 20404 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1211 20:30:06.126814  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:30:06.450860 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_80000.caffemodel
I1211 20:30:06.480864 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_80000.solverstate
I1211 20:30:06.486867 20404 solver.cpp:330] Iteration 80000, Testing net (#0)
I1211 20:30:06.486867 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:30:08.187005  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:30:08.254004 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8701
I1211 20:30:08.254004 20404 solver.cpp:397]     Test net output #1: loss = 0.443018 (* 1 = 0.443018 loss)
I1211 20:30:08.329025 20404 solver.cpp:218] Iteration 80000 (10.0723 iter/s, 9.92827s/100 iters), loss = 0.111487
I1211 20:30:08.329025 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:30:08.329025 20404 solver.cpp:237]     Train net output #1: loss = 0.111487 (* 1 = 0.111487 loss)
I1211 20:30:08.329025 20404 sgd_solver.cpp:105] Iteration 80000, lr = 0.01
I1211 20:30:16.392738 20404 solver.cpp:218] Iteration 80100 (12.4029 iter/s, 8.06265s/100 iters), loss = 0.0730212
I1211 20:30:16.392738 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:30:16.392738 20404 solver.cpp:237]     Train net output #1: loss = 0.0730215 (* 1 = 0.0730215 loss)
I1211 20:30:16.392738 20404 sgd_solver.cpp:105] Iteration 80100, lr = 0.01
I1211 20:30:24.441938 20404 solver.cpp:218] Iteration 80200 (12.4234 iter/s, 8.04934s/100 iters), loss = 0.129799
I1211 20:30:24.441938 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:30:24.441938 20404 solver.cpp:237]     Train net output #1: loss = 0.129799 (* 1 = 0.129799 loss)
I1211 20:30:24.441938 20404 sgd_solver.cpp:105] Iteration 80200, lr = 0.01
I1211 20:30:32.516526 20404 solver.cpp:218] Iteration 80300 (12.3862 iter/s, 8.07352s/100 iters), loss = 0.102537
I1211 20:30:32.516526 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:30:32.516526 20404 solver.cpp:237]     Train net output #1: loss = 0.102537 (* 1 = 0.102537 loss)
I1211 20:30:32.516526 20404 sgd_solver.cpp:105] Iteration 80300, lr = 0.01
I1211 20:30:40.582581 20404 solver.cpp:218] Iteration 80400 (12.3979 iter/s, 8.06588s/100 iters), loss = 0.0634921
I1211 20:30:40.582581 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:30:40.582581 20404 solver.cpp:237]     Train net output #1: loss = 0.0634924 (* 1 = 0.0634924 loss)
I1211 20:30:40.582581 20404 sgd_solver.cpp:105] Iteration 80400, lr = 0.01
I1211 20:30:48.289654  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:30:48.620199 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_80500.caffemodel
I1211 20:30:48.648200 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_80500.solverstate
I1211 20:30:48.681788 20404 solver.cpp:330] Iteration 80500, Testing net (#0)
I1211 20:30:48.681788 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:30:50.409653  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:30:50.478667 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1211 20:30:50.478667 20404 solver.cpp:397]     Test net output #1: loss = 0.380095 (* 1 = 0.380095 loss)
I1211 20:30:50.556668 20404 solver.cpp:218] Iteration 80500 (10.0271 iter/s, 9.97302s/100 iters), loss = 0.106551
I1211 20:30:50.556668 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:30:50.556668 20404 solver.cpp:237]     Train net output #1: loss = 0.106551 (* 1 = 0.106551 loss)
I1211 20:30:50.556668 20404 sgd_solver.cpp:105] Iteration 80500, lr = 0.01
I1211 20:30:58.675762 20404 solver.cpp:218] Iteration 80600 (12.3175 iter/s, 8.11855s/100 iters), loss = 0.170826
I1211 20:30:58.675762 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:30:58.675762 20404 solver.cpp:237]     Train net output #1: loss = 0.170827 (* 1 = 0.170827 loss)
I1211 20:30:58.675762 20404 sgd_solver.cpp:105] Iteration 80600, lr = 0.01
I1211 20:31:06.732677 20404 solver.cpp:218] Iteration 80700 (12.4117 iter/s, 8.05693s/100 iters), loss = 0.122578
I1211 20:31:06.732677 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:31:06.732677 20404 solver.cpp:237]     Train net output #1: loss = 0.122578 (* 1 = 0.122578 loss)
I1211 20:31:06.732677 20404 sgd_solver.cpp:105] Iteration 80700, lr = 0.01
I1211 20:31:14.821167 20404 solver.cpp:218] Iteration 80800 (12.364 iter/s, 8.08803s/100 iters), loss = 0.193261
I1211 20:31:14.821167 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:31:14.821167 20404 solver.cpp:237]     Train net output #1: loss = 0.193261 (* 1 = 0.193261 loss)
I1211 20:31:14.821167 20404 sgd_solver.cpp:105] Iteration 80800, lr = 0.01
I1211 20:31:22.966395 20404 solver.cpp:218] Iteration 80900 (12.2783 iter/s, 8.14448s/100 iters), loss = 0.0921113
I1211 20:31:22.966395 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:31:22.966395 20404 solver.cpp:237]     Train net output #1: loss = 0.0921116 (* 1 = 0.0921116 loss)
I1211 20:31:22.966395 20404 sgd_solver.cpp:105] Iteration 80900, lr = 0.01
I1211 20:31:30.795375  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:31:31.118162 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_81000.caffemodel
I1211 20:31:31.151162 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_81000.solverstate
I1211 20:31:31.158162 20404 solver.cpp:330] Iteration 81000, Testing net (#0)
I1211 20:31:31.159163 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:31:32.870492  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:31:32.943500 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8524
I1211 20:31:32.943500 20404 solver.cpp:397]     Test net output #1: loss = 0.491417 (* 1 = 0.491417 loss)
I1211 20:31:33.020521 20404 solver.cpp:218] Iteration 81000 (9.94683 iter/s, 10.0535s/100 iters), loss = 0.137345
I1211 20:31:33.020521 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:31:33.020521 20404 solver.cpp:237]     Train net output #1: loss = 0.137345 (* 1 = 0.137345 loss)
I1211 20:31:33.020521 20404 sgd_solver.cpp:105] Iteration 81000, lr = 0.01
I1211 20:31:41.109748 20404 solver.cpp:218] Iteration 81100 (12.3632 iter/s, 8.08851s/100 iters), loss = 0.135915
I1211 20:31:41.109748 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:31:41.109748 20404 solver.cpp:237]     Train net output #1: loss = 0.135916 (* 1 = 0.135916 loss)
I1211 20:31:41.109748 20404 sgd_solver.cpp:105] Iteration 81100, lr = 0.01
I1211 20:31:49.137398 20404 solver.cpp:218] Iteration 81200 (12.4581 iter/s, 8.02691s/100 iters), loss = 0.176928
I1211 20:31:49.137398 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:31:49.137398 20404 solver.cpp:237]     Train net output #1: loss = 0.176929 (* 1 = 0.176929 loss)
I1211 20:31:49.137398 20404 sgd_solver.cpp:105] Iteration 81200, lr = 0.01
I1211 20:31:57.150825 20404 solver.cpp:218] Iteration 81300 (12.4798 iter/s, 8.01296s/100 iters), loss = 0.10723
I1211 20:31:57.150825 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:31:57.150825 20404 solver.cpp:237]     Train net output #1: loss = 0.10723 (* 1 = 0.10723 loss)
I1211 20:31:57.150825 20404 sgd_solver.cpp:105] Iteration 81300, lr = 0.01
I1211 20:32:05.102661 20404 solver.cpp:218] Iteration 81400 (12.5752 iter/s, 7.95215s/100 iters), loss = 0.115368
I1211 20:32:05.102661 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:32:05.103662 20404 solver.cpp:237]     Train net output #1: loss = 0.115368 (* 1 = 0.115368 loss)
I1211 20:32:05.103662 20404 sgd_solver.cpp:105] Iteration 81400, lr = 0.01
I1211 20:32:12.666913  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:32:12.981446 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_81500.caffemodel
I1211 20:32:13.011446 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_81500.solverstate
I1211 20:32:13.039446 20404 solver.cpp:330] Iteration 81500, Testing net (#0)
I1211 20:32:13.039446 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:32:14.709581  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:32:14.775585 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8831
I1211 20:32:14.775585 20404 solver.cpp:397]     Test net output #1: loss = 0.375885 (* 1 = 0.375885 loss)
I1211 20:32:14.849584 20404 solver.cpp:218] Iteration 81500 (10.2604 iter/s, 9.74616s/100 iters), loss = 0.137169
I1211 20:32:14.849584 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:32:14.849584 20404 solver.cpp:237]     Train net output #1: loss = 0.137169 (* 1 = 0.137169 loss)
I1211 20:32:14.849584 20404 sgd_solver.cpp:105] Iteration 81500, lr = 0.01
I1211 20:32:22.804474 20404 solver.cpp:218] Iteration 81600 (12.5713 iter/s, 7.95461s/100 iters), loss = 0.121469
I1211 20:32:22.804474 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:32:22.804474 20404 solver.cpp:237]     Train net output #1: loss = 0.121469 (* 1 = 0.121469 loss)
I1211 20:32:22.804474 20404 sgd_solver.cpp:105] Iteration 81600, lr = 0.01
I1211 20:32:30.836745 20404 solver.cpp:218] Iteration 81700 (12.4517 iter/s, 8.03103s/100 iters), loss = 0.145102
I1211 20:32:30.836745 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:32:30.836745 20404 solver.cpp:237]     Train net output #1: loss = 0.145103 (* 1 = 0.145103 loss)
I1211 20:32:30.836745 20404 sgd_solver.cpp:105] Iteration 81700, lr = 0.01
I1211 20:32:38.888545 20404 solver.cpp:218] Iteration 81800 (12.4196 iter/s, 8.0518s/100 iters), loss = 0.114163
I1211 20:32:38.888545 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:32:38.888545 20404 solver.cpp:237]     Train net output #1: loss = 0.114163 (* 1 = 0.114163 loss)
I1211 20:32:38.888545 20404 sgd_solver.cpp:105] Iteration 81800, lr = 0.01
I1211 20:32:46.937628 20404 solver.cpp:218] Iteration 81900 (12.4243 iter/s, 8.04875s/100 iters), loss = 0.104733
I1211 20:32:46.937628 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:32:46.937628 20404 solver.cpp:237]     Train net output #1: loss = 0.104734 (* 1 = 0.104734 loss)
I1211 20:32:46.937628 20404 sgd_solver.cpp:105] Iteration 81900, lr = 0.01
I1211 20:32:54.629580  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:32:54.949257 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_82000.caffemodel
I1211 20:32:54.978255 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_82000.solverstate
I1211 20:32:54.984262 20404 solver.cpp:330] Iteration 82000, Testing net (#0)
I1211 20:32:54.984262 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:32:56.677289  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:32:56.743880 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8663
I1211 20:32:56.743880 20404 solver.cpp:397]     Test net output #1: loss = 0.447783 (* 1 = 0.447783 loss)
I1211 20:32:56.817415 20404 solver.cpp:218] Iteration 82000 (10.1224 iter/s, 9.8791s/100 iters), loss = 0.107592
I1211 20:32:56.817415 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:32:56.817415 20404 solver.cpp:237]     Train net output #1: loss = 0.107592 (* 1 = 0.107592 loss)
I1211 20:32:56.817415 20404 sgd_solver.cpp:105] Iteration 82000, lr = 0.01
I1211 20:33:04.845970 20404 solver.cpp:218] Iteration 82100 (12.4564 iter/s, 8.028s/100 iters), loss = 0.0791246
I1211 20:33:04.845970 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:33:04.845970 20404 solver.cpp:237]     Train net output #1: loss = 0.0791251 (* 1 = 0.0791251 loss)
I1211 20:33:04.845970 20404 sgd_solver.cpp:105] Iteration 82100, lr = 0.01
I1211 20:33:12.800920 20404 solver.cpp:218] Iteration 82200 (12.5714 iter/s, 7.95459s/100 iters), loss = 0.105282
I1211 20:33:12.800920 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:33:12.800920 20404 solver.cpp:237]     Train net output #1: loss = 0.105282 (* 1 = 0.105282 loss)
I1211 20:33:12.801919 20404 sgd_solver.cpp:105] Iteration 82200, lr = 0.01
I1211 20:33:20.759621 20404 solver.cpp:218] Iteration 82300 (12.5656 iter/s, 7.95827s/100 iters), loss = 0.100949
I1211 20:33:20.760622 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:33:20.760622 20404 solver.cpp:237]     Train net output #1: loss = 0.100949 (* 1 = 0.100949 loss)
I1211 20:33:20.760622 20404 sgd_solver.cpp:105] Iteration 82300, lr = 0.01
I1211 20:33:28.713469 20404 solver.cpp:218] Iteration 82400 (12.5742 iter/s, 7.95278s/100 iters), loss = 0.123644
I1211 20:33:28.713469 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:33:28.713469 20404 solver.cpp:237]     Train net output #1: loss = 0.123644 (* 1 = 0.123644 loss)
I1211 20:33:28.713469 20404 sgd_solver.cpp:105] Iteration 82400, lr = 0.01
I1211 20:33:36.282709  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:33:36.597229 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_82500.caffemodel
I1211 20:33:36.628229 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_82500.solverstate
I1211 20:33:36.655227 20404 solver.cpp:330] Iteration 82500, Testing net (#0)
I1211 20:33:36.655227 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:33:38.327594  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:33:38.393597 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1211 20:33:38.393597 20404 solver.cpp:397]     Test net output #1: loss = 0.379612 (* 1 = 0.379612 loss)
I1211 20:33:38.468605 20404 solver.cpp:218] Iteration 82500 (10.2518 iter/s, 9.75437s/100 iters), loss = 0.145954
I1211 20:33:38.468605 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:33:38.468605 20404 solver.cpp:237]     Train net output #1: loss = 0.145955 (* 1 = 0.145955 loss)
I1211 20:33:38.468605 20404 sgd_solver.cpp:105] Iteration 82500, lr = 0.01
I1211 20:33:46.425801 20404 solver.cpp:218] Iteration 82600 (12.5679 iter/s, 7.95678s/100 iters), loss = 0.0861912
I1211 20:33:46.425801 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:33:46.425801 20404 solver.cpp:237]     Train net output #1: loss = 0.0861916 (* 1 = 0.0861916 loss)
I1211 20:33:46.425801 20404 sgd_solver.cpp:105] Iteration 82600, lr = 0.01
I1211 20:33:54.376917 20404 solver.cpp:218] Iteration 82700 (12.5771 iter/s, 7.95097s/100 iters), loss = 0.0619692
I1211 20:33:54.376917 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:33:54.376917 20404 solver.cpp:237]     Train net output #1: loss = 0.0619697 (* 1 = 0.0619697 loss)
I1211 20:33:54.376917 20404 sgd_solver.cpp:105] Iteration 82700, lr = 0.01
I1211 20:34:02.330683 20404 solver.cpp:218] Iteration 82800 (12.5738 iter/s, 7.95303s/100 iters), loss = 0.162727
I1211 20:34:02.330683 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:34:02.330683 20404 solver.cpp:237]     Train net output #1: loss = 0.162727 (* 1 = 0.162727 loss)
I1211 20:34:02.330683 20404 sgd_solver.cpp:105] Iteration 82800, lr = 0.01
I1211 20:34:10.277302 20404 solver.cpp:218] Iteration 82900 (12.5843 iter/s, 7.94641s/100 iters), loss = 0.123375
I1211 20:34:10.277302 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:34:10.277302 20404 solver.cpp:237]     Train net output #1: loss = 0.123376 (* 1 = 0.123376 loss)
I1211 20:34:10.277302 20404 sgd_solver.cpp:105] Iteration 82900, lr = 0.01
I1211 20:34:17.837579  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:34:18.151605 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_83000.caffemodel
I1211 20:34:18.183605 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_83000.solverstate
I1211 20:34:18.190110 20404 solver.cpp:330] Iteration 83000, Testing net (#0)
I1211 20:34:18.190110 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:34:19.859738  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:34:19.925751 20404 solver.cpp:397]     Test net output #0: accuracy = 0.874
I1211 20:34:19.925751 20404 solver.cpp:397]     Test net output #1: loss = 0.41479 (* 1 = 0.41479 loss)
I1211 20:34:20.000759 20404 solver.cpp:218] Iteration 83000 (10.2852 iter/s, 9.72269s/100 iters), loss = 0.200724
I1211 20:34:20.000759 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:34:20.000759 20404 solver.cpp:237]     Train net output #1: loss = 0.200725 (* 1 = 0.200725 loss)
I1211 20:34:20.000759 20404 sgd_solver.cpp:105] Iteration 83000, lr = 0.01
I1211 20:34:27.956858 20404 solver.cpp:218] Iteration 83100 (12.5703 iter/s, 7.95527s/100 iters), loss = 0.11078
I1211 20:34:27.956858 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:34:27.956858 20404 solver.cpp:237]     Train net output #1: loss = 0.11078 (* 1 = 0.11078 loss)
I1211 20:34:27.956858 20404 sgd_solver.cpp:105] Iteration 83100, lr = 0.01
I1211 20:34:35.899361 20404 solver.cpp:218] Iteration 83200 (12.5907 iter/s, 7.94235s/100 iters), loss = 0.115971
I1211 20:34:35.899361 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:34:35.899361 20404 solver.cpp:237]     Train net output #1: loss = 0.115971 (* 1 = 0.115971 loss)
I1211 20:34:35.899361 20404 sgd_solver.cpp:105] Iteration 83200, lr = 0.01
I1211 20:34:43.856678 20404 solver.cpp:218] Iteration 83300 (12.568 iter/s, 7.95674s/100 iters), loss = 0.0997317
I1211 20:34:43.856678 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:34:43.856678 20404 solver.cpp:237]     Train net output #1: loss = 0.0997321 (* 1 = 0.0997321 loss)
I1211 20:34:43.856678 20404 sgd_solver.cpp:105] Iteration 83300, lr = 0.01
I1211 20:34:51.815201 20404 solver.cpp:218] Iteration 83400 (12.565 iter/s, 7.95864s/100 iters), loss = 0.0839115
I1211 20:34:51.815201 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:34:51.815201 20404 solver.cpp:237]     Train net output #1: loss = 0.083912 (* 1 = 0.083912 loss)
I1211 20:34:51.815201 20404 sgd_solver.cpp:105] Iteration 83400, lr = 0.01
I1211 20:34:59.379566  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:34:59.692335 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_83500.caffemodel
I1211 20:34:59.723927 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_83500.solverstate
I1211 20:34:59.755939 20404 solver.cpp:330] Iteration 83500, Testing net (#0)
I1211 20:34:59.755939 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:35:01.427340  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:35:01.493338 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8837
I1211 20:35:01.493338 20404 solver.cpp:397]     Test net output #1: loss = 0.375558 (* 1 = 0.375558 loss)
I1211 20:35:01.568544 20404 solver.cpp:218] Iteration 83500 (10.2543 iter/s, 9.75196s/100 iters), loss = 0.0910364
I1211 20:35:01.568544 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:35:01.568544 20404 solver.cpp:237]     Train net output #1: loss = 0.0910368 (* 1 = 0.0910368 loss)
I1211 20:35:01.568544 20404 sgd_solver.cpp:105] Iteration 83500, lr = 0.01
I1211 20:35:09.519004 20404 solver.cpp:218] Iteration 83600 (12.578 iter/s, 7.95041s/100 iters), loss = 0.0662587
I1211 20:35:09.519505 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:35:09.519505 20404 solver.cpp:237]     Train net output #1: loss = 0.0662591 (* 1 = 0.0662591 loss)
I1211 20:35:09.519505 20404 sgd_solver.cpp:105] Iteration 83600, lr = 0.01
I1211 20:35:17.473337 20404 solver.cpp:218] Iteration 83700 (12.5727 iter/s, 7.95373s/100 iters), loss = 0.313789
I1211 20:35:17.473337 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I1211 20:35:17.473337 20404 solver.cpp:237]     Train net output #1: loss = 0.313789 (* 1 = 0.313789 loss)
I1211 20:35:17.473337 20404 sgd_solver.cpp:105] Iteration 83700, lr = 0.01
I1211 20:35:25.426719 20404 solver.cpp:218] Iteration 83800 (12.5733 iter/s, 7.95335s/100 iters), loss = 0.117061
I1211 20:35:25.426719 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:35:25.426719 20404 solver.cpp:237]     Train net output #1: loss = 0.117062 (* 1 = 0.117062 loss)
I1211 20:35:25.426719 20404 sgd_solver.cpp:105] Iteration 83800, lr = 0.01
I1211 20:35:33.383545 20404 solver.cpp:218] Iteration 83900 (12.5688 iter/s, 7.9562s/100 iters), loss = 0.0584867
I1211 20:35:33.383545 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:35:33.383545 20404 solver.cpp:237]     Train net output #1: loss = 0.0584872 (* 1 = 0.0584872 loss)
I1211 20:35:33.383545 20404 sgd_solver.cpp:105] Iteration 83900, lr = 0.01
I1211 20:35:40.954354  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:35:41.271387 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_84000.caffemodel
I1211 20:35:41.298393 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_84000.solverstate
I1211 20:35:41.304390 20404 solver.cpp:330] Iteration 84000, Testing net (#0)
I1211 20:35:41.304390 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:35:42.974570  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:35:43.040572 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8907
I1211 20:35:43.040572 20404 solver.cpp:397]     Test net output #1: loss = 0.357227 (* 1 = 0.357227 loss)
I1211 20:35:43.114591 20404 solver.cpp:218] Iteration 84000 (10.2772 iter/s, 9.73032s/100 iters), loss = 0.144485
I1211 20:35:43.114591 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:35:43.114591 20404 solver.cpp:237]     Train net output #1: loss = 0.144485 (* 1 = 0.144485 loss)
I1211 20:35:43.114591 20404 sgd_solver.cpp:105] Iteration 84000, lr = 0.01
I1211 20:35:51.060183 20404 solver.cpp:218] Iteration 84100 (12.5871 iter/s, 7.94461s/100 iters), loss = 0.133108
I1211 20:35:51.060183 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:35:51.060183 20404 solver.cpp:237]     Train net output #1: loss = 0.133109 (* 1 = 0.133109 loss)
I1211 20:35:51.060183 20404 sgd_solver.cpp:105] Iteration 84100, lr = 0.01
I1211 20:35:59.008415 20404 solver.cpp:218] Iteration 84200 (12.5817 iter/s, 7.94806s/100 iters), loss = 0.0792692
I1211 20:35:59.008415 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:35:59.008415 20404 solver.cpp:237]     Train net output #1: loss = 0.0792696 (* 1 = 0.0792696 loss)
I1211 20:35:59.008415 20404 sgd_solver.cpp:105] Iteration 84200, lr = 0.01
I1211 20:36:06.957408 20404 solver.cpp:218] Iteration 84300 (12.581 iter/s, 7.94852s/100 iters), loss = 0.100434
I1211 20:36:06.957408 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:36:06.957408 20404 solver.cpp:237]     Train net output #1: loss = 0.100435 (* 1 = 0.100435 loss)
I1211 20:36:06.957408 20404 sgd_solver.cpp:105] Iteration 84300, lr = 0.01
I1211 20:36:14.901427 20404 solver.cpp:218] Iteration 84400 (12.5883 iter/s, 7.94388s/100 iters), loss = 0.131379
I1211 20:36:14.901427 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:36:14.901427 20404 solver.cpp:237]     Train net output #1: loss = 0.13138 (* 1 = 0.13138 loss)
I1211 20:36:14.901427 20404 sgd_solver.cpp:105] Iteration 84400, lr = 0.01
I1211 20:36:22.454407  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:36:22.768468 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_84500.caffemodel
I1211 20:36:22.797468 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_84500.solverstate
I1211 20:36:22.822983 20404 solver.cpp:330] Iteration 84500, Testing net (#0)
I1211 20:36:22.823483 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:36:24.495666  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:36:24.561686 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8718
I1211 20:36:24.561686 20404 solver.cpp:397]     Test net output #1: loss = 0.422002 (* 1 = 0.422002 loss)
I1211 20:36:24.635706 20404 solver.cpp:218] Iteration 84500 (10.2737 iter/s, 9.7336s/100 iters), loss = 0.11401
I1211 20:36:24.635706 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:36:24.635706 20404 solver.cpp:237]     Train net output #1: loss = 0.114011 (* 1 = 0.114011 loss)
I1211 20:36:24.635706 20404 sgd_solver.cpp:105] Iteration 84500, lr = 0.01
I1211 20:36:32.580137 20404 solver.cpp:218] Iteration 84600 (12.589 iter/s, 7.94345s/100 iters), loss = 0.0870697
I1211 20:36:32.580137 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:36:32.580137 20404 solver.cpp:237]     Train net output #1: loss = 0.0870702 (* 1 = 0.0870702 loss)
I1211 20:36:32.580137 20404 sgd_solver.cpp:105] Iteration 84600, lr = 0.01
I1211 20:36:40.528287 20404 solver.cpp:218] Iteration 84700 (12.5822 iter/s, 7.94771s/100 iters), loss = 0.137599
I1211 20:36:40.528287 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:36:40.528287 20404 solver.cpp:237]     Train net output #1: loss = 0.137599 (* 1 = 0.137599 loss)
I1211 20:36:40.528287 20404 sgd_solver.cpp:105] Iteration 84700, lr = 0.01
I1211 20:36:48.482635 20404 solver.cpp:218] Iteration 84800 (12.5713 iter/s, 7.95462s/100 iters), loss = 0.0920442
I1211 20:36:48.482635 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:36:48.482635 20404 solver.cpp:237]     Train net output #1: loss = 0.0920447 (* 1 = 0.0920447 loss)
I1211 20:36:48.482635 20404 sgd_solver.cpp:105] Iteration 84800, lr = 0.01
I1211 20:36:56.442394 20404 solver.cpp:218] Iteration 84900 (12.5641 iter/s, 7.95918s/100 iters), loss = 0.0615573
I1211 20:36:56.442394 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:36:56.443395 20404 solver.cpp:237]     Train net output #1: loss = 0.0615577 (* 1 = 0.0615577 loss)
I1211 20:36:56.443395 20404 sgd_solver.cpp:105] Iteration 84900, lr = 0.01
I1211 20:37:04.006017  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:37:04.322862 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_85000.caffemodel
I1211 20:37:04.350391 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_85000.solverstate
I1211 20:37:04.356405 20404 solver.cpp:330] Iteration 85000, Testing net (#0)
I1211 20:37:04.356405 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:37:06.025877  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:37:06.091456 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8926
I1211 20:37:06.091456 20404 solver.cpp:397]     Test net output #1: loss = 0.348061 (* 1 = 0.348061 loss)
I1211 20:37:06.166499 20404 solver.cpp:218] Iteration 85000 (10.2852 iter/s, 9.72267s/100 iters), loss = 0.142512
I1211 20:37:06.166499 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:37:06.166499 20404 solver.cpp:237]     Train net output #1: loss = 0.142512 (* 1 = 0.142512 loss)
I1211 20:37:06.166499 20404 sgd_solver.cpp:105] Iteration 85000, lr = 0.01
I1211 20:37:14.103052 20404 solver.cpp:218] Iteration 85100 (12.5999 iter/s, 7.93658s/100 iters), loss = 0.150725
I1211 20:37:14.103052 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:37:14.103052 20404 solver.cpp:237]     Train net output #1: loss = 0.150725 (* 1 = 0.150725 loss)
I1211 20:37:14.103052 20404 sgd_solver.cpp:105] Iteration 85100, lr = 0.01
I1211 20:37:22.049865 20404 solver.cpp:218] Iteration 85200 (12.5839 iter/s, 7.94668s/100 iters), loss = 0.126398
I1211 20:37:22.050866 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:37:22.050866 20404 solver.cpp:237]     Train net output #1: loss = 0.126399 (* 1 = 0.126399 loss)
I1211 20:37:22.050866 20404 sgd_solver.cpp:105] Iteration 85200, lr = 0.01
I1211 20:37:29.994786 20404 solver.cpp:218] Iteration 85300 (12.5881 iter/s, 7.94398s/100 iters), loss = 0.18545
I1211 20:37:29.994786 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:37:29.994786 20404 solver.cpp:237]     Train net output #1: loss = 0.18545 (* 1 = 0.18545 loss)
I1211 20:37:29.994786 20404 sgd_solver.cpp:105] Iteration 85300, lr = 0.01
I1211 20:37:37.942665 20404 solver.cpp:218] Iteration 85400 (12.5831 iter/s, 7.94716s/100 iters), loss = 0.0786712
I1211 20:37:37.942665 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:37:37.942665 20404 solver.cpp:237]     Train net output #1: loss = 0.0786716 (* 1 = 0.0786716 loss)
I1211 20:37:37.942665 20404 sgd_solver.cpp:105] Iteration 85400, lr = 0.01
I1211 20:37:45.498489  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:37:45.811543 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_85500.caffemodel
I1211 20:37:45.841048 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_85500.solverstate
I1211 20:37:45.872563 20404 solver.cpp:330] Iteration 85500, Testing net (#0)
I1211 20:37:45.872563 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:37:47.543725  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:37:47.610728 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I1211 20:37:47.610728 20404 solver.cpp:397]     Test net output #1: loss = 0.348671 (* 1 = 0.348671 loss)
I1211 20:37:47.684734 20404 solver.cpp:218] Iteration 85500 (10.2651 iter/s, 9.74179s/100 iters), loss = 0.0856272
I1211 20:37:47.684734 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:37:47.684734 20404 solver.cpp:237]     Train net output #1: loss = 0.0856276 (* 1 = 0.0856276 loss)
I1211 20:37:47.684734 20404 sgd_solver.cpp:105] Iteration 85500, lr = 0.01
I1211 20:37:55.636070 20404 solver.cpp:218] Iteration 85600 (12.5779 iter/s, 7.95047s/100 iters), loss = 0.137423
I1211 20:37:55.636070 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:37:55.636070 20404 solver.cpp:237]     Train net output #1: loss = 0.137423 (* 1 = 0.137423 loss)
I1211 20:37:55.636070 20404 sgd_solver.cpp:105] Iteration 85600, lr = 0.01
I1211 20:38:03.582407 20404 solver.cpp:218] Iteration 85700 (12.5851 iter/s, 7.94589s/100 iters), loss = 0.074544
I1211 20:38:03.582407 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:38:03.582407 20404 solver.cpp:237]     Train net output #1: loss = 0.0745444 (* 1 = 0.0745444 loss)
I1211 20:38:03.582407 20404 sgd_solver.cpp:105] Iteration 85700, lr = 0.01
I1211 20:38:11.534260 20404 solver.cpp:218] Iteration 85800 (12.5764 iter/s, 7.95139s/100 iters), loss = 0.0669602
I1211 20:38:11.534260 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:38:11.534260 20404 solver.cpp:237]     Train net output #1: loss = 0.0669606 (* 1 = 0.0669606 loss)
I1211 20:38:11.534260 20404 sgd_solver.cpp:105] Iteration 85800, lr = 0.01
I1211 20:38:19.480959 20404 solver.cpp:218] Iteration 85900 (12.5837 iter/s, 7.9468s/100 iters), loss = 0.0601406
I1211 20:38:19.480959 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:38:19.480959 20404 solver.cpp:237]     Train net output #1: loss = 0.060141 (* 1 = 0.060141 loss)
I1211 20:38:19.480959 20404 sgd_solver.cpp:105] Iteration 85900, lr = 0.01
I1211 20:38:27.040293  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:38:27.354837 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_86000.caffemodel
I1211 20:38:27.382836 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_86000.solverstate
I1211 20:38:27.388837 20404 solver.cpp:330] Iteration 86000, Testing net (#0)
I1211 20:38:27.388837 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:38:29.059972  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:38:29.125970 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8807
I1211 20:38:29.125970 20404 solver.cpp:397]     Test net output #1: loss = 0.385966 (* 1 = 0.385966 loss)
I1211 20:38:29.201978 20404 solver.cpp:218] Iteration 86000 (10.2877 iter/s, 9.72035s/100 iters), loss = 0.160799
I1211 20:38:29.201978 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:38:29.201978 20404 solver.cpp:237]     Train net output #1: loss = 0.160799 (* 1 = 0.160799 loss)
I1211 20:38:29.201978 20404 sgd_solver.cpp:105] Iteration 86000, lr = 0.01
I1211 20:38:37.151892 20404 solver.cpp:218] Iteration 86100 (12.5801 iter/s, 7.94904s/100 iters), loss = 0.070976
I1211 20:38:37.151892 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:38:37.151892 20404 solver.cpp:237]     Train net output #1: loss = 0.0709764 (* 1 = 0.0709764 loss)
I1211 20:38:37.151892 20404 sgd_solver.cpp:105] Iteration 86100, lr = 0.01
I1211 20:38:45.104002 20404 solver.cpp:218] Iteration 86200 (12.5762 iter/s, 7.95153s/100 iters), loss = 0.142457
I1211 20:38:45.104002 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:38:45.104002 20404 solver.cpp:237]     Train net output #1: loss = 0.142457 (* 1 = 0.142457 loss)
I1211 20:38:45.104002 20404 sgd_solver.cpp:105] Iteration 86200, lr = 0.01
I1211 20:38:53.061301 20404 solver.cpp:218] Iteration 86300 (12.5668 iter/s, 7.95748s/100 iters), loss = 0.0849957
I1211 20:38:53.061301 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:38:53.061301 20404 solver.cpp:237]     Train net output #1: loss = 0.0849961 (* 1 = 0.0849961 loss)
I1211 20:38:53.061301 20404 sgd_solver.cpp:105] Iteration 86300, lr = 0.01
I1211 20:39:01.017254 20404 solver.cpp:218] Iteration 86400 (12.5702 iter/s, 7.95535s/100 iters), loss = 0.0747503
I1211 20:39:01.017254 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:39:01.017254 20404 solver.cpp:237]     Train net output #1: loss = 0.0747507 (* 1 = 0.0747507 loss)
I1211 20:39:01.017254 20404 sgd_solver.cpp:105] Iteration 86400, lr = 0.01
I1211 20:39:08.588065  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:39:08.902086 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_86500.caffemodel
I1211 20:39:08.930086 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_86500.solverstate
I1211 20:39:08.955602 20404 solver.cpp:330] Iteration 86500, Testing net (#0)
I1211 20:39:08.956101 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:39:10.627321  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:39:10.694329 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8848
I1211 20:39:10.694329 20404 solver.cpp:397]     Test net output #1: loss = 0.383545 (* 1 = 0.383545 loss)
I1211 20:39:10.768332 20404 solver.cpp:218] Iteration 86500 (10.2559 iter/s, 9.75047s/100 iters), loss = 0.113908
I1211 20:39:10.768332 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:39:10.768332 20404 solver.cpp:237]     Train net output #1: loss = 0.113908 (* 1 = 0.113908 loss)
I1211 20:39:10.768332 20404 sgd_solver.cpp:105] Iteration 86500, lr = 0.01
I1211 20:39:18.723527 20404 solver.cpp:218] Iteration 86600 (12.5715 iter/s, 7.95449s/100 iters), loss = 0.0806472
I1211 20:39:18.723527 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:39:18.723527 20404 solver.cpp:237]     Train net output #1: loss = 0.0806476 (* 1 = 0.0806476 loss)
I1211 20:39:18.723527 20404 sgd_solver.cpp:105] Iteration 86600, lr = 0.01
I1211 20:39:26.670114 20404 solver.cpp:218] Iteration 86700 (12.5848 iter/s, 7.9461s/100 iters), loss = 0.0882762
I1211 20:39:26.670114 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:39:26.670114 20404 solver.cpp:237]     Train net output #1: loss = 0.0882766 (* 1 = 0.0882766 loss)
I1211 20:39:26.670114 20404 sgd_solver.cpp:105] Iteration 86700, lr = 0.01
I1211 20:39:34.618402 20404 solver.cpp:218] Iteration 86800 (12.5813 iter/s, 7.94828s/100 iters), loss = 0.0935991
I1211 20:39:34.619401 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:39:34.619401 20404 solver.cpp:237]     Train net output #1: loss = 0.0935995 (* 1 = 0.0935995 loss)
I1211 20:39:34.619401 20404 sgd_solver.cpp:105] Iteration 86800, lr = 0.01
I1211 20:39:42.571713 20404 solver.cpp:218] Iteration 86900 (12.575 iter/s, 7.95226s/100 iters), loss = 0.117015
I1211 20:39:42.571713 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:39:42.571713 20404 solver.cpp:237]     Train net output #1: loss = 0.117016 (* 1 = 0.117016 loss)
I1211 20:39:42.571713 20404 sgd_solver.cpp:105] Iteration 86900, lr = 0.01
I1211 20:39:50.128062  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:39:50.444087 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_87000.caffemodel
I1211 20:39:50.474100 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_87000.solverstate
I1211 20:39:50.479102 20404 solver.cpp:330] Iteration 87000, Testing net (#0)
I1211 20:39:50.479102 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:39:52.150243  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:39:52.217254 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9003
I1211 20:39:52.217254 20404 solver.cpp:397]     Test net output #1: loss = 0.323746 (* 1 = 0.323746 loss)
I1211 20:39:52.291283 20404 solver.cpp:218] Iteration 87000 (10.2895 iter/s, 9.71869s/100 iters), loss = 0.112795
I1211 20:39:52.291283 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:39:52.291283 20404 solver.cpp:237]     Train net output #1: loss = 0.112795 (* 1 = 0.112795 loss)
I1211 20:39:52.291283 20404 sgd_solver.cpp:105] Iteration 87000, lr = 0.01
I1211 20:40:00.250159 20404 solver.cpp:218] Iteration 87100 (12.5651 iter/s, 7.95852s/100 iters), loss = 0.116699
I1211 20:40:00.250159 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:40:00.250159 20404 solver.cpp:237]     Train net output #1: loss = 0.1167 (* 1 = 0.1167 loss)
I1211 20:40:00.250159 20404 sgd_solver.cpp:105] Iteration 87100, lr = 0.01
I1211 20:40:08.228055 20404 solver.cpp:218] Iteration 87200 (12.5352 iter/s, 7.97752s/100 iters), loss = 0.13534
I1211 20:40:08.228055 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:40:08.228055 20404 solver.cpp:237]     Train net output #1: loss = 0.13534 (* 1 = 0.13534 loss)
I1211 20:40:08.228557 20404 sgd_solver.cpp:105] Iteration 87200, lr = 0.01
I1211 20:40:16.178328 20404 solver.cpp:218] Iteration 87300 (12.5793 iter/s, 7.9496s/100 iters), loss = 0.129725
I1211 20:40:16.178328 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:40:16.178328 20404 solver.cpp:237]     Train net output #1: loss = 0.129726 (* 1 = 0.129726 loss)
I1211 20:40:16.178328 20404 sgd_solver.cpp:105] Iteration 87300, lr = 0.01
I1211 20:40:24.140095 20404 solver.cpp:218] Iteration 87400 (12.5607 iter/s, 7.96132s/100 iters), loss = 0.0860193
I1211 20:40:24.140095 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:40:24.140095 20404 solver.cpp:237]     Train net output #1: loss = 0.0860198 (* 1 = 0.0860198 loss)
I1211 20:40:24.140095 20404 sgd_solver.cpp:105] Iteration 87400, lr = 0.01
I1211 20:40:31.708961  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:40:32.023535 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_87500.caffemodel
I1211 20:40:32.053037 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_87500.solverstate
I1211 20:40:32.080037 20404 solver.cpp:330] Iteration 87500, Testing net (#0)
I1211 20:40:32.081038 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:40:33.753397  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:40:33.820900 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8912
I1211 20:40:33.820900 20404 solver.cpp:397]     Test net output #1: loss = 0.356113 (* 1 = 0.356113 loss)
I1211 20:40:33.895403 20404 solver.cpp:218] Iteration 87500 (10.2516 iter/s, 9.75462s/100 iters), loss = 0.125106
I1211 20:40:33.895403 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:40:33.895403 20404 solver.cpp:237]     Train net output #1: loss = 0.125106 (* 1 = 0.125106 loss)
I1211 20:40:33.895403 20404 sgd_solver.cpp:105] Iteration 87500, lr = 0.01
I1211 20:40:41.844947 20404 solver.cpp:218] Iteration 87600 (12.5796 iter/s, 7.94937s/100 iters), loss = 0.139042
I1211 20:40:41.844947 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:40:41.844947 20404 solver.cpp:237]     Train net output #1: loss = 0.139042 (* 1 = 0.139042 loss)
I1211 20:40:41.844947 20404 sgd_solver.cpp:105] Iteration 87600, lr = 0.01
I1211 20:40:49.802579 20404 solver.cpp:218] Iteration 87700 (12.5675 iter/s, 7.95705s/100 iters), loss = 0.102614
I1211 20:40:49.802579 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:40:49.802579 20404 solver.cpp:237]     Train net output #1: loss = 0.102614 (* 1 = 0.102614 loss)
I1211 20:40:49.802579 20404 sgd_solver.cpp:105] Iteration 87700, lr = 0.01
I1211 20:40:57.752408 20404 solver.cpp:218] Iteration 87800 (12.5793 iter/s, 7.9496s/100 iters), loss = 0.0700556
I1211 20:40:57.752408 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:40:57.752408 20404 solver.cpp:237]     Train net output #1: loss = 0.070056 (* 1 = 0.070056 loss)
I1211 20:40:57.752408 20404 sgd_solver.cpp:105] Iteration 87800, lr = 0.01
I1211 20:41:05.703529 20404 solver.cpp:218] Iteration 87900 (12.5775 iter/s, 7.95069s/100 iters), loss = 0.192545
I1211 20:41:05.703529 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 20:41:05.703529 20404 solver.cpp:237]     Train net output #1: loss = 0.192545 (* 1 = 0.192545 loss)
I1211 20:41:05.703529 20404 sgd_solver.cpp:105] Iteration 87900, lr = 0.01
I1211 20:41:13.265316  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:41:13.579352 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_88000.caffemodel
I1211 20:41:13.606353 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_88000.solverstate
I1211 20:41:13.612354 20404 solver.cpp:330] Iteration 88000, Testing net (#0)
I1211 20:41:13.612354 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:41:15.282555  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:41:15.349560 20404 solver.cpp:397]     Test net output #0: accuracy = 0.895
I1211 20:41:15.349560 20404 solver.cpp:397]     Test net output #1: loss = 0.33237 (* 1 = 0.33237 loss)
I1211 20:41:15.424566 20404 solver.cpp:218] Iteration 88000 (10.2882 iter/s, 9.71992s/100 iters), loss = 0.1202
I1211 20:41:15.424566 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:41:15.424566 20404 solver.cpp:237]     Train net output #1: loss = 0.1202 (* 1 = 0.1202 loss)
I1211 20:41:15.424566 20404 sgd_solver.cpp:105] Iteration 88000, lr = 0.01
I1211 20:41:23.364856 20404 solver.cpp:218] Iteration 88100 (12.5946 iter/s, 7.93993s/100 iters), loss = 0.0590481
I1211 20:41:23.364856 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:41:23.364856 20404 solver.cpp:237]     Train net output #1: loss = 0.0590485 (* 1 = 0.0590485 loss)
I1211 20:41:23.364856 20404 sgd_solver.cpp:105] Iteration 88100, lr = 0.01
I1211 20:41:31.316839 20404 solver.cpp:218] Iteration 88200 (12.5768 iter/s, 7.95117s/100 iters), loss = 0.098647
I1211 20:41:31.316839 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:41:31.316839 20404 solver.cpp:237]     Train net output #1: loss = 0.0986474 (* 1 = 0.0986474 loss)
I1211 20:41:31.316839 20404 sgd_solver.cpp:105] Iteration 88200, lr = 0.01
I1211 20:41:39.258188 20404 solver.cpp:218] Iteration 88300 (12.5927 iter/s, 7.94109s/100 iters), loss = 0.126285
I1211 20:41:39.258188 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:41:39.258188 20404 solver.cpp:237]     Train net output #1: loss = 0.126285 (* 1 = 0.126285 loss)
I1211 20:41:39.258188 20404 sgd_solver.cpp:105] Iteration 88300, lr = 0.01
I1211 20:41:47.204020 20404 solver.cpp:218] Iteration 88400 (12.5851 iter/s, 7.94593s/100 iters), loss = 0.0813927
I1211 20:41:47.204020 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:41:47.205020 20404 solver.cpp:237]     Train net output #1: loss = 0.0813932 (* 1 = 0.0813932 loss)
I1211 20:41:47.205020 20404 sgd_solver.cpp:105] Iteration 88400, lr = 0.01
I1211 20:41:54.766885  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:41:55.082906 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_88500.caffemodel
I1211 20:41:55.110405 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_88500.solverstate
I1211 20:41:55.139406 20404 solver.cpp:330] Iteration 88500, Testing net (#0)
I1211 20:41:55.139406 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:41:56.812222  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:41:56.879225 20404 solver.cpp:397]     Test net output #0: accuracy = 0.866
I1211 20:41:56.879725 20404 solver.cpp:397]     Test net output #1: loss = 0.444012 (* 1 = 0.444012 loss)
I1211 20:41:56.952227 20404 solver.cpp:218] Iteration 88500 (10.259 iter/s, 9.74753s/100 iters), loss = 0.17366
I1211 20:41:56.952227 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 20:41:56.952227 20404 solver.cpp:237]     Train net output #1: loss = 0.173661 (* 1 = 0.173661 loss)
I1211 20:41:56.952227 20404 sgd_solver.cpp:105] Iteration 88500, lr = 0.01
I1211 20:42:04.898983 20404 solver.cpp:218] Iteration 88600 (12.585 iter/s, 7.94598s/100 iters), loss = 0.116249
I1211 20:42:04.898983 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:42:04.898983 20404 solver.cpp:237]     Train net output #1: loss = 0.11625 (* 1 = 0.11625 loss)
I1211 20:42:04.898983 20404 sgd_solver.cpp:105] Iteration 88600, lr = 0.01
I1211 20:42:12.845862 20404 solver.cpp:218] Iteration 88700 (12.584 iter/s, 7.94659s/100 iters), loss = 0.0987454
I1211 20:42:12.845862 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:42:12.845862 20404 solver.cpp:237]     Train net output #1: loss = 0.0987458 (* 1 = 0.0987458 loss)
I1211 20:42:12.845862 20404 sgd_solver.cpp:105] Iteration 88700, lr = 0.01
I1211 20:42:20.801962 20404 solver.cpp:218] Iteration 88800 (12.5704 iter/s, 7.95521s/100 iters), loss = 0.0932081
I1211 20:42:20.801962 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:42:20.801962 20404 solver.cpp:237]     Train net output #1: loss = 0.0932085 (* 1 = 0.0932085 loss)
I1211 20:42:20.801962 20404 sgd_solver.cpp:105] Iteration 88800, lr = 0.01
I1211 20:42:28.761021 20404 solver.cpp:218] Iteration 88900 (12.5642 iter/s, 7.9591s/100 iters), loss = 0.120687
I1211 20:42:28.762022 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:42:28.762022 20404 solver.cpp:237]     Train net output #1: loss = 0.120688 (* 1 = 0.120688 loss)
I1211 20:42:28.762022 20404 sgd_solver.cpp:105] Iteration 88900, lr = 0.01
I1211 20:42:36.319015  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:42:36.633064 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_89000.caffemodel
I1211 20:42:36.661064 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_89000.solverstate
I1211 20:42:36.667064 20404 solver.cpp:330] Iteration 89000, Testing net (#0)
I1211 20:42:36.667064 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:42:38.339184  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:42:38.406705 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8809
I1211 20:42:38.406705 20404 solver.cpp:397]     Test net output #1: loss = 0.386627 (* 1 = 0.386627 loss)
I1211 20:42:38.480201 20404 solver.cpp:218] Iteration 89000 (10.29 iter/s, 9.7182s/100 iters), loss = 0.09543
I1211 20:42:38.480201 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:42:38.480201 20404 solver.cpp:237]     Train net output #1: loss = 0.0954305 (* 1 = 0.0954305 loss)
I1211 20:42:38.480201 20404 sgd_solver.cpp:105] Iteration 89000, lr = 0.01
I1211 20:42:46.434115 20404 solver.cpp:218] Iteration 89100 (12.5728 iter/s, 7.95367s/100 iters), loss = 0.127119
I1211 20:42:46.434115 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:42:46.434115 20404 solver.cpp:237]     Train net output #1: loss = 0.12712 (* 1 = 0.12712 loss)
I1211 20:42:46.434115 20404 sgd_solver.cpp:105] Iteration 89100, lr = 0.01
I1211 20:42:54.385793 20404 solver.cpp:218] Iteration 89200 (12.5764 iter/s, 7.95138s/100 iters), loss = 0.117644
I1211 20:42:54.386795 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:42:54.386795 20404 solver.cpp:237]     Train net output #1: loss = 0.117645 (* 1 = 0.117645 loss)
I1211 20:42:54.386795 20404 sgd_solver.cpp:105] Iteration 89200, lr = 0.01
I1211 20:43:02.336719 20404 solver.cpp:218] Iteration 89300 (12.5787 iter/s, 7.94993s/100 iters), loss = 0.0666554
I1211 20:43:02.336719 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:43:02.336719 20404 solver.cpp:237]     Train net output #1: loss = 0.0666558 (* 1 = 0.0666558 loss)
I1211 20:43:02.336719 20404 sgd_solver.cpp:105] Iteration 89300, lr = 0.01
I1211 20:43:10.285562 20404 solver.cpp:218] Iteration 89400 (12.5816 iter/s, 7.94809s/100 iters), loss = 0.0930782
I1211 20:43:10.285562 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:43:10.285562 20404 solver.cpp:237]     Train net output #1: loss = 0.0930786 (* 1 = 0.0930786 loss)
I1211 20:43:10.285562 20404 sgd_solver.cpp:105] Iteration 89400, lr = 0.01
I1211 20:43:17.845360  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:43:18.161381 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_89500.caffemodel
I1211 20:43:18.196378 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_89500.solverstate
I1211 20:43:18.223400 20404 solver.cpp:330] Iteration 89500, Testing net (#0)
I1211 20:43:18.223400 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:43:19.895867  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:43:19.961885 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I1211 20:43:19.961885 20404 solver.cpp:397]     Test net output #1: loss = 0.353549 (* 1 = 0.353549 loss)
I1211 20:43:20.036891 20404 solver.cpp:218] Iteration 89500 (10.2555 iter/s, 9.75089s/100 iters), loss = 0.141943
I1211 20:43:20.036891 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:43:20.036891 20404 solver.cpp:237]     Train net output #1: loss = 0.141943 (* 1 = 0.141943 loss)
I1211 20:43:20.036891 20404 sgd_solver.cpp:105] Iteration 89500, lr = 0.01
I1211 20:43:27.999742 20404 solver.cpp:218] Iteration 89600 (12.5581 iter/s, 7.96299s/100 iters), loss = 0.0798835
I1211 20:43:27.999742 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:43:27.999742 20404 solver.cpp:237]     Train net output #1: loss = 0.079884 (* 1 = 0.079884 loss)
I1211 20:43:27.999742 20404 sgd_solver.cpp:105] Iteration 89600, lr = 0.01
I1211 20:43:35.952597 20404 solver.cpp:218] Iteration 89700 (12.5762 iter/s, 7.95154s/100 iters), loss = 0.0683289
I1211 20:43:35.952597 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:43:35.952597 20404 solver.cpp:237]     Train net output #1: loss = 0.0683294 (* 1 = 0.0683294 loss)
I1211 20:43:35.952597 20404 sgd_solver.cpp:105] Iteration 89700, lr = 0.01
I1211 20:43:43.911408 20404 solver.cpp:218] Iteration 89800 (12.565 iter/s, 7.95863s/100 iters), loss = 0.152719
I1211 20:43:43.911408 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:43:43.911408 20404 solver.cpp:237]     Train net output #1: loss = 0.152719 (* 1 = 0.152719 loss)
I1211 20:43:43.911408 20404 sgd_solver.cpp:105] Iteration 89800, lr = 0.01
I1211 20:43:51.860528 20404 solver.cpp:218] Iteration 89900 (12.5808 iter/s, 7.94861s/100 iters), loss = 0.0698007
I1211 20:43:51.860528 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:43:51.860528 20404 solver.cpp:237]     Train net output #1: loss = 0.0698011 (* 1 = 0.0698011 loss)
I1211 20:43:51.860528 20404 sgd_solver.cpp:105] Iteration 89900, lr = 0.01
I1211 20:43:59.430044  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:43:59.744072 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90000.caffemodel
I1211 20:43:59.796074 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate
I1211 20:43:59.802074 20404 solver.cpp:330] Iteration 90000, Testing net (#0)
I1211 20:43:59.802074 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:44:01.475186  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:44:01.541190 20404 solver.cpp:397]     Test net output #0: accuracy = 0.86
I1211 20:44:01.541190 20404 solver.cpp:397]     Test net output #1: loss = 0.45387 (* 1 = 0.45387 loss)
I1211 20:44:01.615190 20404 solver.cpp:218] Iteration 90000 (10.2517 iter/s, 9.75453s/100 iters), loss = 0.101387
I1211 20:44:01.615190 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:44:01.615190 20404 solver.cpp:237]     Train net output #1: loss = 0.101388 (* 1 = 0.101388 loss)
I1211 20:44:01.615190 20404 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1211 20:44:09.560587 20404 solver.cpp:218] Iteration 90100 (12.587 iter/s, 7.94473s/100 iters), loss = 0.066178
I1211 20:44:09.560587 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:44:09.560587 20404 solver.cpp:237]     Train net output #1: loss = 0.0661784 (* 1 = 0.0661784 loss)
I1211 20:44:09.560587 20404 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1211 20:44:17.498733 20404 solver.cpp:218] Iteration 90200 (12.5984 iter/s, 7.93753s/100 iters), loss = 0.087777
I1211 20:44:17.498733 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:44:17.498733 20404 solver.cpp:237]     Train net output #1: loss = 0.0877774 (* 1 = 0.0877774 loss)
I1211 20:44:17.498733 20404 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1211 20:44:25.449432 20404 solver.cpp:218] Iteration 90300 (12.5784 iter/s, 7.95015s/100 iters), loss = 0.119526
I1211 20:44:25.449432 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:44:25.449432 20404 solver.cpp:237]     Train net output #1: loss = 0.119526 (* 1 = 0.119526 loss)
I1211 20:44:25.449432 20404 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1211 20:44:33.400383 20404 solver.cpp:218] Iteration 90400 (12.5771 iter/s, 7.95095s/100 iters), loss = 0.167174
I1211 20:44:33.400383 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:44:33.400383 20404 solver.cpp:237]     Train net output #1: loss = 0.167174 (* 1 = 0.167174 loss)
I1211 20:44:33.400383 20404 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1211 20:44:40.957176  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:44:41.272207 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.caffemodel
I1211 20:44:41.304208 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.solverstate
I1211 20:44:41.310209 20404 solver.cpp:330] Iteration 90500, Testing net (#0)
I1211 20:44:41.310209 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:44:42.981417  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:44:43.047421 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8862
I1211 20:44:43.047421 20404 solver.cpp:397]     Test net output #1: loss = 0.375438 (* 1 = 0.375438 loss)
I1211 20:44:43.121420 20404 solver.cpp:218] Iteration 90500 (10.2875 iter/s, 9.72053s/100 iters), loss = 0.0885867
I1211 20:44:43.122421 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:44:43.122421 20404 solver.cpp:237]     Train net output #1: loss = 0.0885871 (* 1 = 0.0885871 loss)
I1211 20:44:43.122421 20404 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1211 20:44:51.075358 20404 solver.cpp:218] Iteration 90600 (12.5743 iter/s, 7.95272s/100 iters), loss = 0.0720709
I1211 20:44:51.075358 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:44:51.075358 20404 solver.cpp:237]     Train net output #1: loss = 0.0720713 (* 1 = 0.0720713 loss)
I1211 20:44:51.075358 20404 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1211 20:44:59.024183 20404 solver.cpp:218] Iteration 90700 (12.5805 iter/s, 7.94883s/100 iters), loss = 0.0938084
I1211 20:44:59.024183 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:44:59.024183 20404 solver.cpp:237]     Train net output #1: loss = 0.0938088 (* 1 = 0.0938088 loss)
I1211 20:44:59.024183 20404 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1211 20:45:06.979691 20404 solver.cpp:218] Iteration 90800 (12.5711 iter/s, 7.95476s/100 iters), loss = 0.0605108
I1211 20:45:06.979691 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:45:06.979691 20404 solver.cpp:237]     Train net output #1: loss = 0.0605112 (* 1 = 0.0605112 loss)
I1211 20:45:06.979691 20404 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1211 20:45:14.930058 20404 solver.cpp:218] Iteration 90900 (12.5785 iter/s, 7.95009s/100 iters), loss = 0.0783666
I1211 20:45:14.930058 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:45:14.930058 20404 solver.cpp:237]     Train net output #1: loss = 0.078367 (* 1 = 0.078367 loss)
I1211 20:45:14.930058 20404 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1211 20:45:22.492144  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:45:22.805755 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.caffemodel
I1211 20:45:22.832772 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.solverstate
I1211 20:45:22.856328 20404 solver.cpp:330] Iteration 91000, Testing net (#0)
I1211 20:45:22.856328 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:45:24.529386  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:45:24.596390 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8806
I1211 20:45:24.596390 20404 solver.cpp:397]     Test net output #1: loss = 0.388239 (* 1 = 0.388239 loss)
I1211 20:45:24.670435 20404 solver.cpp:218] Iteration 91000 (10.2674 iter/s, 9.73954s/100 iters), loss = 0.11333
I1211 20:45:24.670435 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:45:24.670435 20404 solver.cpp:237]     Train net output #1: loss = 0.11333 (* 1 = 0.11333 loss)
I1211 20:45:24.670435 20404 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1211 20:45:32.615810 20404 solver.cpp:218] Iteration 91100 (12.5861 iter/s, 7.94525s/100 iters), loss = 0.157745
I1211 20:45:32.615810 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:45:32.615810 20404 solver.cpp:237]     Train net output #1: loss = 0.157745 (* 1 = 0.157745 loss)
I1211 20:45:32.615810 20404 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1211 20:45:40.569823 20404 solver.cpp:218] Iteration 91200 (12.5736 iter/s, 7.95318s/100 iters), loss = 0.180344
I1211 20:45:40.569823 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:45:40.569823 20404 solver.cpp:237]     Train net output #1: loss = 0.180345 (* 1 = 0.180345 loss)
I1211 20:45:40.569823 20404 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1211 20:45:48.521636 20404 solver.cpp:218] Iteration 91300 (12.5758 iter/s, 7.95178s/100 iters), loss = 0.0915876
I1211 20:45:48.521636 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:45:48.521636 20404 solver.cpp:237]     Train net output #1: loss = 0.091588 (* 1 = 0.091588 loss)
I1211 20:45:48.521636 20404 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1211 20:45:56.468343 20404 solver.cpp:218] Iteration 91400 (12.5854 iter/s, 7.94569s/100 iters), loss = 0.103676
I1211 20:45:56.468343 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:45:56.468343 20404 solver.cpp:237]     Train net output #1: loss = 0.103676 (* 1 = 0.103676 loss)
I1211 20:45:56.468343 20404 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1211 20:46:04.026820  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:46:04.340850 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.caffemodel
I1211 20:46:04.369355 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.solverstate
I1211 20:46:04.374860 20404 solver.cpp:330] Iteration 91500, Testing net (#0)
I1211 20:46:04.374860 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:46:06.044982  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:46:06.110987 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8904
I1211 20:46:06.110987 20404 solver.cpp:397]     Test net output #1: loss = 0.365094 (* 1 = 0.365094 loss)
I1211 20:46:06.185994 20404 solver.cpp:218] Iteration 91500 (10.2911 iter/s, 9.71716s/100 iters), loss = 0.102445
I1211 20:46:06.185994 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:46:06.185994 20404 solver.cpp:237]     Train net output #1: loss = 0.102446 (* 1 = 0.102446 loss)
I1211 20:46:06.185994 20404 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1211 20:46:14.132781 20404 solver.cpp:218] Iteration 91600 (12.584 iter/s, 7.9466s/100 iters), loss = 0.0504747
I1211 20:46:14.132781 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:46:14.132781 20404 solver.cpp:237]     Train net output #1: loss = 0.0504752 (* 1 = 0.0504752 loss)
I1211 20:46:14.132781 20404 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1211 20:46:22.080636 20404 solver.cpp:218] Iteration 91700 (12.5828 iter/s, 7.94736s/100 iters), loss = 0.0817407
I1211 20:46:22.080636 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:46:22.080636 20404 solver.cpp:237]     Train net output #1: loss = 0.0817411 (* 1 = 0.0817411 loss)
I1211 20:46:22.080636 20404 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1211 20:46:30.028448 20404 solver.cpp:218] Iteration 91800 (12.5833 iter/s, 7.94707s/100 iters), loss = 0.13462
I1211 20:46:30.028448 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:46:30.028448 20404 solver.cpp:237]     Train net output #1: loss = 0.13462 (* 1 = 0.13462 loss)
I1211 20:46:30.028448 20404 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1211 20:46:37.975829 20404 solver.cpp:218] Iteration 91900 (12.5842 iter/s, 7.94645s/100 iters), loss = 0.0955215
I1211 20:46:37.975829 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:46:37.975829 20404 solver.cpp:237]     Train net output #1: loss = 0.0955219 (* 1 = 0.0955219 loss)
I1211 20:46:37.975829 20404 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1211 20:46:45.539069  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:46:45.854099 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.caffemodel
I1211 20:46:45.888129 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.solverstate
I1211 20:46:45.906191 20404 solver.cpp:330] Iteration 92000, Testing net (#0)
I1211 20:46:45.906191 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:46:47.577242  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:46:47.643275 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8971
I1211 20:46:47.643275 20404 solver.cpp:397]     Test net output #1: loss = 0.338013 (* 1 = 0.338013 loss)
I1211 20:46:47.718286 20404 solver.cpp:218] Iteration 92000 (10.2649 iter/s, 9.74196s/100 iters), loss = 0.194616
I1211 20:46:47.718286 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:46:47.718286 20404 solver.cpp:237]     Train net output #1: loss = 0.194616 (* 1 = 0.194616 loss)
I1211 20:46:47.718286 20404 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1211 20:46:55.663580 20404 solver.cpp:218] Iteration 92100 (12.5864 iter/s, 7.9451s/100 iters), loss = 0.113643
I1211 20:46:55.663580 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:46:55.663580 20404 solver.cpp:237]     Train net output #1: loss = 0.113643 (* 1 = 0.113643 loss)
I1211 20:46:55.663580 20404 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1211 20:47:03.624490 20404 solver.cpp:218] Iteration 92200 (12.5619 iter/s, 7.96058s/100 iters), loss = 0.129652
I1211 20:47:03.624490 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:47:03.624490 20404 solver.cpp:237]     Train net output #1: loss = 0.129652 (* 1 = 0.129652 loss)
I1211 20:47:03.624490 20404 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1211 20:47:11.579193 20404 solver.cpp:218] Iteration 92300 (12.5721 iter/s, 7.95413s/100 iters), loss = 0.103133
I1211 20:47:11.579193 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:47:11.579193 20404 solver.cpp:237]     Train net output #1: loss = 0.103133 (* 1 = 0.103133 loss)
I1211 20:47:11.579193 20404 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1211 20:47:19.535584 20404 solver.cpp:218] Iteration 92400 (12.5691 iter/s, 7.95603s/100 iters), loss = 0.0730262
I1211 20:47:19.535584 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:47:19.535584 20404 solver.cpp:237]     Train net output #1: loss = 0.0730265 (* 1 = 0.0730265 loss)
I1211 20:47:19.535584 20404 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1211 20:47:27.092430  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:47:27.408696 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.caffemodel
I1211 20:47:27.445694 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.solverstate
I1211 20:47:27.451696 20404 solver.cpp:330] Iteration 92500, Testing net (#0)
I1211 20:47:27.451696 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:47:29.124007  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:47:29.190016 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8855
I1211 20:47:29.190016 20404 solver.cpp:397]     Test net output #1: loss = 0.373983 (* 1 = 0.373983 loss)
I1211 20:47:29.265014 20404 solver.cpp:218] Iteration 92500 (10.2783 iter/s, 9.72923s/100 iters), loss = 0.0713997
I1211 20:47:29.265014 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:47:29.265014 20404 solver.cpp:237]     Train net output #1: loss = 0.0714001 (* 1 = 0.0714001 loss)
I1211 20:47:29.265014 20404 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1211 20:47:37.216035 20404 solver.cpp:218] Iteration 92600 (12.5782 iter/s, 7.95026s/100 iters), loss = 0.0828788
I1211 20:47:37.216035 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:47:37.216035 20404 solver.cpp:237]     Train net output #1: loss = 0.0828792 (* 1 = 0.0828792 loss)
I1211 20:47:37.216035 20404 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1211 20:47:45.158787 20404 solver.cpp:218] Iteration 92700 (12.5911 iter/s, 7.94212s/100 iters), loss = 0.102222
I1211 20:47:45.158787 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:47:45.158787 20404 solver.cpp:237]     Train net output #1: loss = 0.102222 (* 1 = 0.102222 loss)
I1211 20:47:45.158787 20404 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1211 20:47:53.111994 20404 solver.cpp:218] Iteration 92800 (12.574 iter/s, 7.9529s/100 iters), loss = 0.079491
I1211 20:47:53.111994 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:47:53.111994 20404 solver.cpp:237]     Train net output #1: loss = 0.0794913 (* 1 = 0.0794913 loss)
I1211 20:47:53.111994 20404 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1211 20:48:01.063850 20404 solver.cpp:218] Iteration 92900 (12.5771 iter/s, 7.95098s/100 iters), loss = 0.12279
I1211 20:48:01.063850 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:48:01.063850 20404 solver.cpp:237]     Train net output #1: loss = 0.12279 (* 1 = 0.12279 loss)
I1211 20:48:01.063850 20404 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1211 20:48:08.623809  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:48:08.939833 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.caffemodel
I1211 20:48:08.967833 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.solverstate
I1211 20:48:08.997350 20404 solver.cpp:330] Iteration 93000, Testing net (#0)
I1211 20:48:08.997350 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:48:10.673996  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:48:10.741026 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8729
I1211 20:48:10.741026 20404 solver.cpp:397]     Test net output #1: loss = 0.436644 (* 1 = 0.436644 loss)
I1211 20:48:10.815032 20404 solver.cpp:218] Iteration 93000 (10.2553 iter/s, 9.75105s/100 iters), loss = 0.126828
I1211 20:48:10.815032 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:48:10.815032 20404 solver.cpp:237]     Train net output #1: loss = 0.126828 (* 1 = 0.126828 loss)
I1211 20:48:10.815032 20404 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1211 20:48:18.761713 20404 solver.cpp:218] Iteration 93100 (12.5847 iter/s, 7.94616s/100 iters), loss = 0.114009
I1211 20:48:18.761713 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:48:18.761713 20404 solver.cpp:237]     Train net output #1: loss = 0.114009 (* 1 = 0.114009 loss)
I1211 20:48:18.761713 20404 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1211 20:48:26.712164 20404 solver.cpp:218] Iteration 93200 (12.5792 iter/s, 7.94963s/100 iters), loss = 0.100531
I1211 20:48:26.712164 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:48:26.712164 20404 solver.cpp:237]     Train net output #1: loss = 0.100531 (* 1 = 0.100531 loss)
I1211 20:48:26.712164 20404 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1211 20:48:34.657688 20404 solver.cpp:218] Iteration 93300 (12.5865 iter/s, 7.945s/100 iters), loss = 0.0751421
I1211 20:48:34.657688 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:48:34.657688 20404 solver.cpp:237]     Train net output #1: loss = 0.0751423 (* 1 = 0.0751423 loss)
I1211 20:48:34.657688 20404 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1211 20:48:42.596232 20404 solver.cpp:218] Iteration 93400 (12.5979 iter/s, 7.93785s/100 iters), loss = 0.0696019
I1211 20:48:42.596232 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:48:42.596232 20404 solver.cpp:237]     Train net output #1: loss = 0.0696022 (* 1 = 0.0696022 loss)
I1211 20:48:42.596232 20404 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1211 20:48:50.153481  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:48:50.468499 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.caffemodel
I1211 20:48:50.498500 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.solverstate
I1211 20:48:50.505005 20404 solver.cpp:330] Iteration 93500, Testing net (#0)
I1211 20:48:50.505504 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:48:52.178634  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:48:52.245656 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8686
I1211 20:48:52.245656 20404 solver.cpp:397]     Test net output #1: loss = 0.434745 (* 1 = 0.434745 loss)
I1211 20:48:52.320662 20404 solver.cpp:218] Iteration 93500 (10.2837 iter/s, 9.72408s/100 iters), loss = 0.0759959
I1211 20:48:52.320662 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:48:52.320662 20404 solver.cpp:237]     Train net output #1: loss = 0.0759962 (* 1 = 0.0759962 loss)
I1211 20:48:52.320662 20404 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1211 20:49:00.270573 20404 solver.cpp:218] Iteration 93600 (12.5795 iter/s, 7.94946s/100 iters), loss = 0.0802695
I1211 20:49:00.270573 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:49:00.270573 20404 solver.cpp:237]     Train net output #1: loss = 0.0802698 (* 1 = 0.0802698 loss)
I1211 20:49:00.270573 20404 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1211 20:49:08.217718 20404 solver.cpp:218] Iteration 93700 (12.5842 iter/s, 7.94646s/100 iters), loss = 0.115849
I1211 20:49:08.217718 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:49:08.217718 20404 solver.cpp:237]     Train net output #1: loss = 0.115849 (* 1 = 0.115849 loss)
I1211 20:49:08.217718 20404 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1211 20:49:16.168233 20404 solver.cpp:218] Iteration 93800 (12.5782 iter/s, 7.95027s/100 iters), loss = 0.0952789
I1211 20:49:16.168233 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:49:16.168233 20404 solver.cpp:237]     Train net output #1: loss = 0.0952791 (* 1 = 0.0952791 loss)
I1211 20:49:16.168233 20404 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1211 20:49:24.122459 20404 solver.cpp:218] Iteration 93900 (12.5734 iter/s, 7.95332s/100 iters), loss = 0.074642
I1211 20:49:24.122459 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:49:24.122459 20404 solver.cpp:237]     Train net output #1: loss = 0.0746422 (* 1 = 0.0746422 loss)
I1211 20:49:24.122459 20404 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1211 20:49:31.671881  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:49:31.984921 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.caffemodel
I1211 20:49:32.010921 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.solverstate
I1211 20:49:32.038727 20404 solver.cpp:330] Iteration 94000, Testing net (#0)
I1211 20:49:32.039727 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:49:33.711828  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:49:33.777835 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8785
I1211 20:49:33.777835 20404 solver.cpp:397]     Test net output #1: loss = 0.407269 (* 1 = 0.407269 loss)
I1211 20:49:33.852840 20404 solver.cpp:218] Iteration 94000 (10.2774 iter/s, 9.73006s/100 iters), loss = 0.151581
I1211 20:49:33.852840 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 20:49:33.852840 20404 solver.cpp:237]     Train net output #1: loss = 0.151582 (* 1 = 0.151582 loss)
I1211 20:49:33.852840 20404 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1211 20:49:41.816730 20404 solver.cpp:218] Iteration 94100 (12.5577 iter/s, 7.96324s/100 iters), loss = 0.103255
I1211 20:49:41.816730 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:49:41.816730 20404 solver.cpp:237]     Train net output #1: loss = 0.103255 (* 1 = 0.103255 loss)
I1211 20:49:41.816730 20404 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1211 20:49:49.763394 20404 solver.cpp:218] Iteration 94200 (12.5841 iter/s, 7.94653s/100 iters), loss = 0.124798
I1211 20:49:49.763394 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:49:49.763394 20404 solver.cpp:237]     Train net output #1: loss = 0.124798 (* 1 = 0.124798 loss)
I1211 20:49:49.763394 20404 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1211 20:49:57.717273 20404 solver.cpp:218] Iteration 94300 (12.5741 iter/s, 7.95287s/100 iters), loss = 0.101124
I1211 20:49:57.717273 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:49:57.717273 20404 solver.cpp:237]     Train net output #1: loss = 0.101124 (* 1 = 0.101124 loss)
I1211 20:49:57.717273 20404 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1211 20:50:05.694305 20404 solver.cpp:218] Iteration 94400 (12.536 iter/s, 7.97705s/100 iters), loss = 0.125099
I1211 20:50:05.694305 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:50:05.694305 20404 solver.cpp:237]     Train net output #1: loss = 0.125099 (* 1 = 0.125099 loss)
I1211 20:50:05.694305 20404 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1211 20:50:13.263526  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:50:13.577548 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.caffemodel
I1211 20:50:13.606549 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.solverstate
I1211 20:50:13.611547 20404 solver.cpp:330] Iteration 94500, Testing net (#0)
I1211 20:50:13.611547 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:50:15.281702  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:50:15.347700 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8644
I1211 20:50:15.348702 20404 solver.cpp:397]     Test net output #1: loss = 0.46009 (* 1 = 0.46009 loss)
I1211 20:50:15.422709 20404 solver.cpp:218] Iteration 94500 (10.2799 iter/s, 9.72774s/100 iters), loss = 0.0947051
I1211 20:50:15.422709 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:50:15.422709 20404 solver.cpp:237]     Train net output #1: loss = 0.0947054 (* 1 = 0.0947054 loss)
I1211 20:50:15.422709 20404 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1211 20:50:23.376457 20404 solver.cpp:218] Iteration 94600 (12.5727 iter/s, 7.95373s/100 iters), loss = 0.111174
I1211 20:50:23.376457 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:50:23.376457 20404 solver.cpp:237]     Train net output #1: loss = 0.111174 (* 1 = 0.111174 loss)
I1211 20:50:23.376457 20404 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1211 20:50:31.326509 20404 solver.cpp:218] Iteration 94700 (12.5793 iter/s, 7.9496s/100 iters), loss = 0.105638
I1211 20:50:31.326509 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:50:31.326509 20404 solver.cpp:237]     Train net output #1: loss = 0.105639 (* 1 = 0.105639 loss)
I1211 20:50:31.326509 20404 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1211 20:50:39.325662 20404 solver.cpp:218] Iteration 94800 (12.5031 iter/s, 7.99803s/100 iters), loss = 0.0829302
I1211 20:50:39.325662 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:50:39.325662 20404 solver.cpp:237]     Train net output #1: loss = 0.0829304 (* 1 = 0.0829304 loss)
I1211 20:50:39.325662 20404 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1211 20:50:47.269035 20404 solver.cpp:218] Iteration 94900 (12.5901 iter/s, 7.94274s/100 iters), loss = 0.174104
I1211 20:50:47.269035 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1211 20:50:47.269035 20404 solver.cpp:237]     Train net output #1: loss = 0.174104 (* 1 = 0.174104 loss)
I1211 20:50:47.269035 20404 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1211 20:50:54.823660  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:50:55.137701 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.caffemodel
I1211 20:50:55.171206 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.solverstate
I1211 20:50:55.177208 20404 solver.cpp:330] Iteration 95000, Testing net (#0)
I1211 20:50:55.177208 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:50:56.843391  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:50:56.909397 20404 solver.cpp:397]     Test net output #0: accuracy = 0.8749
I1211 20:50:56.909397 20404 solver.cpp:397]     Test net output #1: loss = 0.428987 (* 1 = 0.428987 loss)
I1211 20:50:56.983898 20404 solver.cpp:218] Iteration 95000 (10.2938 iter/s, 9.7146s/100 iters), loss = 0.153558
I1211 20:50:56.983898 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 20:50:56.983898 20404 solver.cpp:237]     Train net output #1: loss = 0.153558 (* 1 = 0.153558 loss)
I1211 20:50:56.983898 20404 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1211 20:50:56.983898 20404 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1211 20:51:04.919616 20404 solver.cpp:218] Iteration 95100 (12.6021 iter/s, 7.93516s/100 iters), loss = 0.0998402
I1211 20:51:04.919616 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:51:04.919616 20404 solver.cpp:237]     Train net output #1: loss = 0.0998405 (* 1 = 0.0998405 loss)
I1211 20:51:04.919616 20404 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1211 20:51:12.848251 20404 solver.cpp:218] Iteration 95200 (12.6136 iter/s, 7.92794s/100 iters), loss = 0.126471
I1211 20:51:12.848251 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:51:12.848251 20404 solver.cpp:237]     Train net output #1: loss = 0.126472 (* 1 = 0.126472 loss)
I1211 20:51:12.848251 20404 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1211 20:51:20.783957 20404 solver.cpp:218] Iteration 95300 (12.6023 iter/s, 7.93505s/100 iters), loss = 0.0327212
I1211 20:51:20.783957 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:51:20.783957 20404 solver.cpp:237]     Train net output #1: loss = 0.0327215 (* 1 = 0.0327215 loss)
I1211 20:51:20.783957 20404 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1211 20:51:28.717126 20404 solver.cpp:218] Iteration 95400 (12.6061 iter/s, 7.93267s/100 iters), loss = 0.031859
I1211 20:51:28.717126 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:51:28.717126 20404 solver.cpp:237]     Train net output #1: loss = 0.0318593 (* 1 = 0.0318593 loss)
I1211 20:51:28.717126 20404 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1211 20:51:36.271878  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:51:36.585896 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.caffemodel
I1211 20:51:36.613896 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.solverstate
I1211 20:51:36.619896 20404 solver.cpp:330] Iteration 95500, Testing net (#0)
I1211 20:51:36.619896 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:51:38.289247  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:51:38.355259 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9247
I1211 20:51:38.355259 20404 solver.cpp:397]     Test net output #1: loss = 0.249358 (* 1 = 0.249358 loss)
I1211 20:51:38.429258 20404 solver.cpp:218] Iteration 95500 (10.2966 iter/s, 9.71192s/100 iters), loss = 0.0877512
I1211 20:51:38.429258 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:51:38.429258 20404 solver.cpp:237]     Train net output #1: loss = 0.0877515 (* 1 = 0.0877515 loss)
I1211 20:51:38.429258 20404 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1211 20:51:46.361241 20404 solver.cpp:218] Iteration 95600 (12.6073 iter/s, 7.93189s/100 iters), loss = 0.0396991
I1211 20:51:46.361241 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:51:46.361241 20404 solver.cpp:237]     Train net output #1: loss = 0.0396994 (* 1 = 0.0396994 loss)
I1211 20:51:46.361241 20404 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1211 20:51:54.294634 20404 solver.cpp:218] Iteration 95700 (12.6063 iter/s, 7.93254s/100 iters), loss = 0.0819049
I1211 20:51:54.294634 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:51:54.294634 20404 solver.cpp:237]     Train net output #1: loss = 0.0819052 (* 1 = 0.0819052 loss)
I1211 20:51:54.294634 20404 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1211 20:52:02.226704 20404 solver.cpp:218] Iteration 95800 (12.6086 iter/s, 7.93111s/100 iters), loss = 0.0282504
I1211 20:52:02.226704 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:52:02.226704 20404 solver.cpp:237]     Train net output #1: loss = 0.0282508 (* 1 = 0.0282508 loss)
I1211 20:52:02.226704 20404 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1211 20:52:10.152778 20404 solver.cpp:218] Iteration 95900 (12.6173 iter/s, 7.9256s/100 iters), loss = 0.0301203
I1211 20:52:10.152778 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:52:10.152778 20404 solver.cpp:237]     Train net output #1: loss = 0.0301206 (* 1 = 0.0301206 loss)
I1211 20:52:10.152778 20404 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1211 20:52:17.698971  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:52:18.011715 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.caffemodel
I1211 20:52:18.041715 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.solverstate
I1211 20:52:18.047716 20404 solver.cpp:330] Iteration 96000, Testing net (#0)
I1211 20:52:18.047716 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:52:19.713789  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:52:19.779793 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9271
I1211 20:52:19.779793 20404 solver.cpp:397]     Test net output #1: loss = 0.240693 (* 1 = 0.240693 loss)
I1211 20:52:19.853628 20404 solver.cpp:218] Iteration 96000 (10.309 iter/s, 9.70023s/100 iters), loss = 0.049973
I1211 20:52:19.853628 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:52:19.853628 20404 solver.cpp:237]     Train net output #1: loss = 0.0499734 (* 1 = 0.0499734 loss)
I1211 20:52:19.853628 20404 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1211 20:52:27.784639 20404 solver.cpp:218] Iteration 96100 (12.6082 iter/s, 7.93134s/100 iters), loss = 0.068493
I1211 20:52:27.784639 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 20:52:27.784639 20404 solver.cpp:237]     Train net output #1: loss = 0.0684934 (* 1 = 0.0684934 loss)
I1211 20:52:27.784639 20404 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1211 20:52:35.721125 20404 solver.cpp:218] Iteration 96200 (12.6011 iter/s, 7.93583s/100 iters), loss = 0.0774216
I1211 20:52:35.721125 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:52:35.721125 20404 solver.cpp:237]     Train net output #1: loss = 0.0774219 (* 1 = 0.0774219 loss)
I1211 20:52:35.721125 20404 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1211 20:52:43.657971 20404 solver.cpp:218] Iteration 96300 (12.6012 iter/s, 7.93573s/100 iters), loss = 0.0213002
I1211 20:52:43.657971 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:52:43.657971 20404 solver.cpp:237]     Train net output #1: loss = 0.0213006 (* 1 = 0.0213006 loss)
I1211 20:52:43.657971 20404 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1211 20:52:51.589788 20404 solver.cpp:218] Iteration 96400 (12.6075 iter/s, 7.93178s/100 iters), loss = 0.0423831
I1211 20:52:51.589788 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:52:51.589788 20404 solver.cpp:237]     Train net output #1: loss = 0.0423834 (* 1 = 0.0423834 loss)
I1211 20:52:51.589788 20404 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1211 20:52:59.137869  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:52:59.451905 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.caffemodel
I1211 20:52:59.479904 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.solverstate
I1211 20:52:59.485905 20404 solver.cpp:330] Iteration 96500, Testing net (#0)
I1211 20:52:59.485905 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:53:01.153061  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:53:01.219066 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9261
I1211 20:53:01.219066 20404 solver.cpp:397]     Test net output #1: loss = 0.239168 (* 1 = 0.239168 loss)
I1211 20:53:01.293066 20404 solver.cpp:218] Iteration 96500 (10.3062 iter/s, 9.70288s/100 iters), loss = 0.0369311
I1211 20:53:01.293066 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:53:01.293066 20404 solver.cpp:237]     Train net output #1: loss = 0.0369315 (* 1 = 0.0369315 loss)
I1211 20:53:01.293066 20404 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1211 20:53:09.226250 20404 solver.cpp:218] Iteration 96600 (12.6067 iter/s, 7.93231s/100 iters), loss = 0.0561405
I1211 20:53:09.226250 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:53:09.226250 20404 solver.cpp:237]     Train net output #1: loss = 0.0561409 (* 1 = 0.0561409 loss)
I1211 20:53:09.226250 20404 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1211 20:53:17.157560 20404 solver.cpp:218] Iteration 96700 (12.6089 iter/s, 7.93093s/100 iters), loss = 0.0950255
I1211 20:53:17.157560 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 20:53:17.157560 20404 solver.cpp:237]     Train net output #1: loss = 0.0950258 (* 1 = 0.0950258 loss)
I1211 20:53:17.157560 20404 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1211 20:53:25.088573 20404 solver.cpp:218] Iteration 96800 (12.6091 iter/s, 7.93079s/100 iters), loss = 0.0237221
I1211 20:53:25.088573 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:53:25.088573 20404 solver.cpp:237]     Train net output #1: loss = 0.0237224 (* 1 = 0.0237224 loss)
I1211 20:53:25.088573 20404 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1211 20:53:33.022444 20404 solver.cpp:218] Iteration 96900 (12.6055 iter/s, 7.93305s/100 iters), loss = 0.0511222
I1211 20:53:33.022444 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:53:33.022444 20404 solver.cpp:237]     Train net output #1: loss = 0.0511225 (* 1 = 0.0511225 loss)
I1211 20:53:33.022444 20404 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1211 20:53:40.562266  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:53:40.876291 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.caffemodel
I1211 20:53:40.908294 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.solverstate
I1211 20:53:40.930311 20404 solver.cpp:330] Iteration 97000, Testing net (#0)
I1211 20:53:40.930311 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:53:42.597602  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:53:42.664623 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9272
I1211 20:53:42.664623 20404 solver.cpp:397]     Test net output #1: loss = 0.240396 (* 1 = 0.240396 loss)
I1211 20:53:42.738615 20404 solver.cpp:218] Iteration 97000 (10.2926 iter/s, 9.71571s/100 iters), loss = 0.0303274
I1211 20:53:42.738615 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:53:42.738615 20404 solver.cpp:237]     Train net output #1: loss = 0.0303277 (* 1 = 0.0303277 loss)
I1211 20:53:42.738615 20404 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1211 20:53:50.675323 20404 solver.cpp:218] Iteration 97100 (12.6002 iter/s, 7.93637s/100 iters), loss = 0.0710715
I1211 20:53:50.675323 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:53:50.675323 20404 solver.cpp:237]     Train net output #1: loss = 0.0710718 (* 1 = 0.0710718 loss)
I1211 20:53:50.675323 20404 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1211 20:53:58.620137 20404 solver.cpp:218] Iteration 97200 (12.5876 iter/s, 7.94431s/100 iters), loss = 0.0523138
I1211 20:53:58.620637 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:53:58.620637 20404 solver.cpp:237]     Train net output #1: loss = 0.0523141 (* 1 = 0.0523141 loss)
I1211 20:53:58.620637 20404 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1211 20:54:06.557353 20404 solver.cpp:218] Iteration 97300 (12.5991 iter/s, 7.93709s/100 iters), loss = 0.0225929
I1211 20:54:06.557353 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:54:06.557353 20404 solver.cpp:237]     Train net output #1: loss = 0.0225932 (* 1 = 0.0225932 loss)
I1211 20:54:06.557353 20404 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1211 20:54:14.497092 20404 solver.cpp:218] Iteration 97400 (12.5966 iter/s, 7.93862s/100 iters), loss = 0.0433251
I1211 20:54:14.497092 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:54:14.497092 20404 solver.cpp:237]     Train net output #1: loss = 0.0433254 (* 1 = 0.0433254 loss)
I1211 20:54:14.497092 20404 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1211 20:54:22.038019  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:54:22.352082 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.caffemodel
I1211 20:54:22.381084 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.solverstate
I1211 20:54:22.387084 20404 solver.cpp:330] Iteration 97500, Testing net (#0)
I1211 20:54:22.387084 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:54:24.052271  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:54:24.118275 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9291
I1211 20:54:24.118275 20404 solver.cpp:397]     Test net output #1: loss = 0.239409 (* 1 = 0.239409 loss)
I1211 20:54:24.191277 20404 solver.cpp:218] Iteration 97500 (10.3157 iter/s, 9.69397s/100 iters), loss = 0.0329308
I1211 20:54:24.191277 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:54:24.191277 20404 solver.cpp:237]     Train net output #1: loss = 0.0329312 (* 1 = 0.0329312 loss)
I1211 20:54:24.191277 20404 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1211 20:54:32.128772 20404 solver.cpp:218] Iteration 97600 (12.5993 iter/s, 7.93693s/100 iters), loss = 0.074434
I1211 20:54:32.128772 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:54:32.128772 20404 solver.cpp:237]     Train net output #1: loss = 0.0744343 (* 1 = 0.0744343 loss)
I1211 20:54:32.128772 20404 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1211 20:54:40.063820 20404 solver.cpp:218] Iteration 97700 (12.6035 iter/s, 7.93432s/100 iters), loss = 0.0647863
I1211 20:54:40.063820 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:54:40.063820 20404 solver.cpp:237]     Train net output #1: loss = 0.0647866 (* 1 = 0.0647866 loss)
I1211 20:54:40.063820 20404 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1211 20:54:48.001751 20404 solver.cpp:218] Iteration 97800 (12.5983 iter/s, 7.93759s/100 iters), loss = 0.0267736
I1211 20:54:48.001751 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:54:48.001751 20404 solver.cpp:237]     Train net output #1: loss = 0.0267739 (* 1 = 0.0267739 loss)
I1211 20:54:48.001751 20404 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1211 20:54:55.938340 20404 solver.cpp:218] Iteration 97900 (12.6008 iter/s, 7.93603s/100 iters), loss = 0.03007
I1211 20:54:55.938340 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:54:55.938340 20404 solver.cpp:237]     Train net output #1: loss = 0.0300703 (* 1 = 0.0300703 loss)
I1211 20:54:55.938340 20404 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1211 20:55:03.486570  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:55:03.800612 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.caffemodel
I1211 20:55:03.829617 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.solverstate
I1211 20:55:03.855634 20404 solver.cpp:330] Iteration 98000, Testing net (#0)
I1211 20:55:03.855634 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:55:05.523298  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:55:05.589799 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9287
I1211 20:55:05.589799 20404 solver.cpp:397]     Test net output #1: loss = 0.242885 (* 1 = 0.242885 loss)
I1211 20:55:05.663812 20404 solver.cpp:218] Iteration 98000 (10.2828 iter/s, 9.72495s/100 iters), loss = 0.030402
I1211 20:55:05.663812 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:55:05.663812 20404 solver.cpp:237]     Train net output #1: loss = 0.0304023 (* 1 = 0.0304023 loss)
I1211 20:55:05.663812 20404 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1211 20:55:13.607754 20404 solver.cpp:218] Iteration 98100 (12.588 iter/s, 7.94409s/100 iters), loss = 0.0412343
I1211 20:55:13.607754 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:55:13.607754 20404 solver.cpp:237]     Train net output #1: loss = 0.0412345 (* 1 = 0.0412345 loss)
I1211 20:55:13.607754 20404 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1211 20:55:21.547719 20404 solver.cpp:218] Iteration 98200 (12.5953 iter/s, 7.93949s/100 iters), loss = 0.0431022
I1211 20:55:21.548714 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:55:21.548714 20404 solver.cpp:237]     Train net output #1: loss = 0.0431025 (* 1 = 0.0431025 loss)
I1211 20:55:21.548714 20404 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1211 20:55:29.480626 20404 solver.cpp:218] Iteration 98300 (12.6072 iter/s, 7.93195s/100 iters), loss = 0.0172252
I1211 20:55:29.480626 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:55:29.480626 20404 solver.cpp:237]     Train net output #1: loss = 0.0172255 (* 1 = 0.0172255 loss)
I1211 20:55:29.480626 20404 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1211 20:55:37.411437 20404 solver.cpp:218] Iteration 98400 (12.6093 iter/s, 7.93068s/100 iters), loss = 0.0218527
I1211 20:55:37.411437 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:55:37.411437 20404 solver.cpp:237]     Train net output #1: loss = 0.021853 (* 1 = 0.021853 loss)
I1211 20:55:37.411437 20404 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1211 20:55:44.957211  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:55:45.271251 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.caffemodel
I1211 20:55:45.302251 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.solverstate
I1211 20:55:45.308254 20404 solver.cpp:330] Iteration 98500, Testing net (#0)
I1211 20:55:45.308254 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:55:46.975282  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:55:47.041287 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9285
I1211 20:55:47.041287 20404 solver.cpp:397]     Test net output #1: loss = 0.248358 (* 1 = 0.248358 loss)
I1211 20:55:47.115286 20404 solver.cpp:218] Iteration 98500 (10.3059 iter/s, 9.70314s/100 iters), loss = 0.0374557
I1211 20:55:47.115286 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:55:47.115286 20404 solver.cpp:237]     Train net output #1: loss = 0.0374559 (* 1 = 0.0374559 loss)
I1211 20:55:47.115286 20404 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1211 20:55:55.048414 20404 solver.cpp:218] Iteration 98600 (12.607 iter/s, 7.93208s/100 iters), loss = 0.0505884
I1211 20:55:55.048414 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:55:55.048414 20404 solver.cpp:237]     Train net output #1: loss = 0.0505886 (* 1 = 0.0505886 loss)
I1211 20:55:55.048414 20404 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1211 20:56:02.981884 20404 solver.cpp:218] Iteration 98700 (12.6054 iter/s, 7.93311s/100 iters), loss = 0.0565261
I1211 20:56:02.981884 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:56:02.981884 20404 solver.cpp:237]     Train net output #1: loss = 0.0565264 (* 1 = 0.0565264 loss)
I1211 20:56:02.981884 20404 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1211 20:56:10.920400 20404 solver.cpp:218] Iteration 98800 (12.597 iter/s, 7.9384s/100 iters), loss = 0.0175539
I1211 20:56:10.920400 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:56:10.920400 20404 solver.cpp:237]     Train net output #1: loss = 0.0175541 (* 1 = 0.0175541 loss)
I1211 20:56:10.920400 20404 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1211 20:56:18.852520 20404 solver.cpp:218] Iteration 98900 (12.6073 iter/s, 7.93194s/100 iters), loss = 0.0686321
I1211 20:56:18.853519 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:56:18.853519 20404 solver.cpp:237]     Train net output #1: loss = 0.0686324 (* 1 = 0.0686324 loss)
I1211 20:56:18.853519 20404 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1211 20:56:26.397550  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:56:26.712594 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.caffemodel
I1211 20:56:26.740598 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.solverstate
I1211 20:56:26.771615 20404 solver.cpp:330] Iteration 99000, Testing net (#0)
I1211 20:56:26.772616 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:56:28.439752  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:56:28.505753 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9283
I1211 20:56:28.505753 20404 solver.cpp:397]     Test net output #1: loss = 0.245941 (* 1 = 0.245941 loss)
I1211 20:56:28.579761 20404 solver.cpp:218] Iteration 99000 (10.2816 iter/s, 9.72612s/100 iters), loss = 0.0318141
I1211 20:56:28.579761 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:56:28.579761 20404 solver.cpp:237]     Train net output #1: loss = 0.0318143 (* 1 = 0.0318143 loss)
I1211 20:56:28.579761 20404 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1211 20:56:36.519603 20404 solver.cpp:218] Iteration 99100 (12.5957 iter/s, 7.93924s/100 iters), loss = 0.0207777
I1211 20:56:36.519603 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:56:36.519603 20404 solver.cpp:237]     Train net output #1: loss = 0.020778 (* 1 = 0.020778 loss)
I1211 20:56:36.519603 20404 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1211 20:56:44.453361 20404 solver.cpp:218] Iteration 99200 (12.6046 iter/s, 7.93362s/100 iters), loss = 0.0350648
I1211 20:56:44.453361 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:56:44.453361 20404 solver.cpp:237]     Train net output #1: loss = 0.0350651 (* 1 = 0.0350651 loss)
I1211 20:56:44.453361 20404 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1211 20:56:52.397267 20404 solver.cpp:218] Iteration 99300 (12.5895 iter/s, 7.94312s/100 iters), loss = 0.0249448
I1211 20:56:52.397267 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:56:52.397267 20404 solver.cpp:237]     Train net output #1: loss = 0.0249451 (* 1 = 0.0249451 loss)
I1211 20:56:52.397267 20404 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1211 20:57:00.331095 20404 solver.cpp:218] Iteration 99400 (12.6046 iter/s, 7.9336s/100 iters), loss = 0.0158033
I1211 20:57:00.331095 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:57:00.331095 20404 solver.cpp:237]     Train net output #1: loss = 0.0158035 (* 1 = 0.0158035 loss)
I1211 20:57:00.331095 20404 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1211 20:57:07.885329  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:57:08.200034 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.caffemodel
I1211 20:57:08.229032 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.solverstate
I1211 20:57:08.234032 20404 solver.cpp:330] Iteration 99500, Testing net (#0)
I1211 20:57:08.235033 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:57:09.903946  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:57:09.970470 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9282
I1211 20:57:09.970470 20404 solver.cpp:397]     Test net output #1: loss = 0.247795 (* 1 = 0.247795 loss)
I1211 20:57:10.045990 20404 solver.cpp:218] Iteration 99500 (10.2942 iter/s, 9.7142s/100 iters), loss = 0.0425302
I1211 20:57:10.045990 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:57:10.045990 20404 solver.cpp:237]     Train net output #1: loss = 0.0425305 (* 1 = 0.0425305 loss)
I1211 20:57:10.046492 20404 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1211 20:57:17.990016 20404 solver.cpp:218] Iteration 99600 (12.5888 iter/s, 7.9436s/100 iters), loss = 0.0343935
I1211 20:57:17.990016 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:57:17.990016 20404 solver.cpp:237]     Train net output #1: loss = 0.0343938 (* 1 = 0.0343938 loss)
I1211 20:57:17.990016 20404 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1211 20:57:25.920059 20404 solver.cpp:218] Iteration 99700 (12.6109 iter/s, 7.92962s/100 iters), loss = 0.0510439
I1211 20:57:25.920059 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:57:25.920059 20404 solver.cpp:237]     Train net output #1: loss = 0.0510442 (* 1 = 0.0510442 loss)
I1211 20:57:25.920059 20404 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1211 20:57:33.851855 20404 solver.cpp:218] Iteration 99800 (12.6085 iter/s, 7.93114s/100 iters), loss = 0.0214093
I1211 20:57:33.852355 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:57:33.852355 20404 solver.cpp:237]     Train net output #1: loss = 0.0214095 (* 1 = 0.0214095 loss)
I1211 20:57:33.852355 20404 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1211 20:57:41.776816 20404 solver.cpp:218] Iteration 99900 (12.6183 iter/s, 7.92501s/100 iters), loss = 0.03821
I1211 20:57:41.777817 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:57:41.777817 20404 solver.cpp:237]     Train net output #1: loss = 0.0382103 (* 1 = 0.0382103 loss)
I1211 20:57:41.777817 20404 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1211 20:57:49.319625  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:57:49.634656 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.caffemodel
I1211 20:57:49.662659 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.solverstate
I1211 20:57:49.722662 20404 solver.cpp:330] Iteration 100000, Testing net (#0)
I1211 20:57:49.722662 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:57:51.389866  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:57:51.456887 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9292
I1211 20:57:51.456887 20404 solver.cpp:397]     Test net output #1: loss = 0.244938 (* 1 = 0.244938 loss)
I1211 20:57:51.530889 20404 solver.cpp:218] Iteration 100000 (10.2536 iter/s, 9.75264s/100 iters), loss = 0.0230042
I1211 20:57:51.530889 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:57:51.530889 20404 solver.cpp:237]     Train net output #1: loss = 0.0230045 (* 1 = 0.0230045 loss)
I1211 20:57:51.530889 20404 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1211 20:57:59.463671 20404 solver.cpp:218] Iteration 100100 (12.6066 iter/s, 7.93233s/100 iters), loss = 0.0331699
I1211 20:57:59.463671 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:57:59.463671 20404 solver.cpp:237]     Train net output #1: loss = 0.0331701 (* 1 = 0.0331701 loss)
I1211 20:57:59.463671 20404 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1211 20:58:07.402554 20404 solver.cpp:218] Iteration 100200 (12.5959 iter/s, 7.9391s/100 iters), loss = 0.027069
I1211 20:58:07.402554 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:58:07.402554 20404 solver.cpp:237]     Train net output #1: loss = 0.0270693 (* 1 = 0.0270693 loss)
I1211 20:58:07.402554 20404 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1211 20:58:15.342370 20404 solver.cpp:218] Iteration 100300 (12.5958 iter/s, 7.93915s/100 iters), loss = 0.0185585
I1211 20:58:15.342370 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:58:15.342370 20404 solver.cpp:237]     Train net output #1: loss = 0.0185588 (* 1 = 0.0185588 loss)
I1211 20:58:15.342370 20404 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1211 20:58:23.274194 20404 solver.cpp:218] Iteration 100400 (12.6083 iter/s, 7.93131s/100 iters), loss = 0.0342701
I1211 20:58:23.274194 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:58:23.274194 20404 solver.cpp:237]     Train net output #1: loss = 0.0342703 (* 1 = 0.0342703 loss)
I1211 20:58:23.274194 20404 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1211 20:58:30.823985  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:58:31.138006 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.caffemodel
I1211 20:58:31.170019 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.solverstate
I1211 20:58:31.176020 20404 solver.cpp:330] Iteration 100500, Testing net (#0)
I1211 20:58:31.176020 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:58:32.846310  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:58:32.912314 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9298
I1211 20:58:32.912314 20404 solver.cpp:397]     Test net output #1: loss = 0.246643 (* 1 = 0.246643 loss)
I1211 20:58:32.987323 20404 solver.cpp:218] Iteration 100500 (10.2965 iter/s, 9.71203s/100 iters), loss = 0.0328462
I1211 20:58:32.987323 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:58:32.987323 20404 solver.cpp:237]     Train net output #1: loss = 0.0328464 (* 1 = 0.0328464 loss)
I1211 20:58:32.987323 20404 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1211 20:58:40.924332 20404 solver.cpp:218] Iteration 100600 (12.599 iter/s, 7.93713s/100 iters), loss = 0.0400637
I1211 20:58:40.924332 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:58:40.924332 20404 solver.cpp:237]     Train net output #1: loss = 0.040064 (* 1 = 0.040064 loss)
I1211 20:58:40.924332 20404 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1211 20:58:48.857192 20404 solver.cpp:218] Iteration 100700 (12.6075 iter/s, 7.93181s/100 iters), loss = 0.0470436
I1211 20:58:48.857192 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:58:48.857192 20404 solver.cpp:237]     Train net output #1: loss = 0.0470439 (* 1 = 0.0470439 loss)
I1211 20:58:48.857192 20404 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1211 20:58:56.794101 20404 solver.cpp:218] Iteration 100800 (12.5999 iter/s, 7.93658s/100 iters), loss = 0.0185707
I1211 20:58:56.794101 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:58:56.794101 20404 solver.cpp:237]     Train net output #1: loss = 0.018571 (* 1 = 0.018571 loss)
I1211 20:58:56.794101 20404 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1211 20:59:04.716238 20404 solver.cpp:218] Iteration 100900 (12.6228 iter/s, 7.92215s/100 iters), loss = 0.025916
I1211 20:59:04.716238 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:59:04.716238 20404 solver.cpp:237]     Train net output #1: loss = 0.0259162 (* 1 = 0.0259162 loss)
I1211 20:59:04.716238 20404 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1211 20:59:12.260020  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:59:12.574048 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.caffemodel
I1211 20:59:12.604053 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.solverstate
I1211 20:59:12.622051 20404 solver.cpp:330] Iteration 101000, Testing net (#0)
I1211 20:59:12.623052 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:59:14.290200  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:59:14.356199 20404 solver.cpp:397]     Test net output #0: accuracy = 0.93
I1211 20:59:14.356199 20404 solver.cpp:397]     Test net output #1: loss = 0.244449 (* 1 = 0.244449 loss)
I1211 20:59:14.430207 20404 solver.cpp:218] Iteration 101000 (10.2953 iter/s, 9.71314s/100 iters), loss = 0.0186489
I1211 20:59:14.430207 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:59:14.430207 20404 solver.cpp:237]     Train net output #1: loss = 0.0186491 (* 1 = 0.0186491 loss)
I1211 20:59:14.430207 20404 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1211 20:59:22.363569 20404 solver.cpp:218] Iteration 101100 (12.6061 iter/s, 7.93266s/100 iters), loss = 0.0300507
I1211 20:59:22.363569 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:59:22.363569 20404 solver.cpp:237]     Train net output #1: loss = 0.0300509 (* 1 = 0.0300509 loss)
I1211 20:59:22.363569 20404 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1211 20:59:30.293539 20404 solver.cpp:218] Iteration 101200 (12.6103 iter/s, 7.93003s/100 iters), loss = 0.0338004
I1211 20:59:30.293539 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 20:59:30.293539 20404 solver.cpp:237]     Train net output #1: loss = 0.0338007 (* 1 = 0.0338007 loss)
I1211 20:59:30.293539 20404 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1211 20:59:38.231278 20404 solver.cpp:218] Iteration 101300 (12.5989 iter/s, 7.93721s/100 iters), loss = 0.0467478
I1211 20:59:38.231278 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:59:38.231278 20404 solver.cpp:237]     Train net output #1: loss = 0.0467481 (* 1 = 0.0467481 loss)
I1211 20:59:38.231278 20404 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1211 20:59:46.160384 20404 solver.cpp:218] Iteration 101400 (12.6135 iter/s, 7.92803s/100 iters), loss = 0.0426708
I1211 20:59:46.160384 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 20:59:46.160384 20404 solver.cpp:237]     Train net output #1: loss = 0.042671 (* 1 = 0.042671 loss)
I1211 20:59:46.160384 20404 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1211 20:59:53.701797  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:59:54.013833 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.caffemodel
I1211 20:59:54.045840 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.solverstate
I1211 20:59:54.051841 20404 solver.cpp:330] Iteration 101500, Testing net (#0)
I1211 20:59:54.051841 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 20:59:55.717986  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 20:59:55.785025 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9282
I1211 20:59:55.785025 20404 solver.cpp:397]     Test net output #1: loss = 0.245457 (* 1 = 0.245457 loss)
I1211 20:59:55.859030 20404 solver.cpp:218] Iteration 101500 (10.3106 iter/s, 9.69872s/100 iters), loss = 0.0468335
I1211 20:59:55.859030 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 20:59:55.859030 20404 solver.cpp:237]     Train net output #1: loss = 0.0468337 (* 1 = 0.0468337 loss)
I1211 20:59:55.859030 20404 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1211 21:00:03.787122 20404 solver.cpp:218] Iteration 101600 (12.614 iter/s, 7.92767s/100 iters), loss = 0.0228941
I1211 21:00:03.787122 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:00:03.787122 20404 solver.cpp:237]     Train net output #1: loss = 0.0228943 (* 1 = 0.0228943 loss)
I1211 21:00:03.787122 20404 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1211 21:00:11.715864 20404 solver.cpp:218] Iteration 101700 (12.613 iter/s, 7.9283s/100 iters), loss = 0.0498795
I1211 21:00:11.715864 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 21:00:11.715864 20404 solver.cpp:237]     Train net output #1: loss = 0.0498797 (* 1 = 0.0498797 loss)
I1211 21:00:11.715864 20404 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1211 21:00:19.651243 20404 solver.cpp:218] Iteration 101800 (12.6033 iter/s, 7.93444s/100 iters), loss = 0.0241237
I1211 21:00:19.651243 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:00:19.651243 20404 solver.cpp:237]     Train net output #1: loss = 0.0241239 (* 1 = 0.0241239 loss)
I1211 21:00:19.651243 20404 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1211 21:00:27.601044 20404 solver.cpp:218] Iteration 101900 (12.5791 iter/s, 7.94971s/100 iters), loss = 0.0176428
I1211 21:00:27.601044 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:00:27.601044 20404 solver.cpp:237]     Train net output #1: loss = 0.0176431 (* 1 = 0.0176431 loss)
I1211 21:00:27.601044 20404 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1211 21:00:35.150158  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:00:35.466176 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.caffemodel
I1211 21:00:35.500176 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.solverstate
I1211 21:00:35.506176 20404 solver.cpp:330] Iteration 102000, Testing net (#0)
I1211 21:00:35.506176 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:00:37.172386  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:00:37.238894 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9293
I1211 21:00:37.238894 20404 solver.cpp:397]     Test net output #1: loss = 0.249211 (* 1 = 0.249211 loss)
I1211 21:00:37.312396 20404 solver.cpp:218] Iteration 102000 (10.2976 iter/s, 9.71098s/100 iters), loss = 0.0383728
I1211 21:00:37.312396 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:00:37.312396 20404 solver.cpp:237]     Train net output #1: loss = 0.0383731 (* 1 = 0.0383731 loss)
I1211 21:00:37.312396 20404 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1211 21:00:45.239956 20404 solver.cpp:218] Iteration 102100 (12.616 iter/s, 7.92645s/100 iters), loss = 0.0472022
I1211 21:00:45.239956 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:00:45.239956 20404 solver.cpp:237]     Train net output #1: loss = 0.0472024 (* 1 = 0.0472024 loss)
I1211 21:00:45.239956 20404 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1211 21:00:53.177193 20404 solver.cpp:218] Iteration 102200 (12.5995 iter/s, 7.93683s/100 iters), loss = 0.0303326
I1211 21:00:53.177193 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:00:53.177193 20404 solver.cpp:237]     Train net output #1: loss = 0.0303328 (* 1 = 0.0303328 loss)
I1211 21:00:53.177193 20404 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1211 21:01:01.108974 20404 solver.cpp:218] Iteration 102300 (12.6082 iter/s, 7.93132s/100 iters), loss = 0.0391684
I1211 21:01:01.108974 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:01:01.108974 20404 solver.cpp:237]     Train net output #1: loss = 0.0391686 (* 1 = 0.0391686 loss)
I1211 21:01:01.108974 20404 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1211 21:01:09.378247 20404 solver.cpp:218] Iteration 102400 (12.0937 iter/s, 8.26879s/100 iters), loss = 0.0250809
I1211 21:01:09.378247 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:01:09.378247 20404 solver.cpp:237]     Train net output #1: loss = 0.0250812 (* 1 = 0.0250812 loss)
I1211 21:01:09.378247 20404 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1211 21:01:17.018859  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:01:17.331904 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.caffemodel
I1211 21:01:17.360905 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.solverstate
I1211 21:01:17.366907 20404 solver.cpp:330] Iteration 102500, Testing net (#0)
I1211 21:01:17.366907 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:01:19.049063  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:01:19.116566 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9295
I1211 21:01:19.116566 20404 solver.cpp:397]     Test net output #1: loss = 0.249174 (* 1 = 0.249174 loss)
I1211 21:01:19.192067 20404 solver.cpp:218] Iteration 102500 (10.1905 iter/s, 9.8131s/100 iters), loss = 0.0363488
I1211 21:01:19.192067 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:01:19.192067 20404 solver.cpp:237]     Train net output #1: loss = 0.0363491 (* 1 = 0.0363491 loss)
I1211 21:01:19.192067 20404 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1211 21:01:27.213814 20404 solver.cpp:218] Iteration 102600 (12.4669 iter/s, 8.02127s/100 iters), loss = 0.0212921
I1211 21:01:27.213814 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:01:27.213814 20404 solver.cpp:237]     Train net output #1: loss = 0.0212923 (* 1 = 0.0212923 loss)
I1211 21:01:27.213814 20404 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1211 21:01:35.183213 20404 solver.cpp:218] Iteration 102700 (12.5489 iter/s, 7.96882s/100 iters), loss = 0.0285145
I1211 21:01:35.183213 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:01:35.183213 20404 solver.cpp:237]     Train net output #1: loss = 0.0285147 (* 1 = 0.0285147 loss)
I1211 21:01:35.183213 20404 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1211 21:01:43.154742 20404 solver.cpp:218] Iteration 102800 (12.5446 iter/s, 7.97157s/100 iters), loss = 0.0157786
I1211 21:01:43.154742 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:01:43.154742 20404 solver.cpp:237]     Train net output #1: loss = 0.0157788 (* 1 = 0.0157788 loss)
I1211 21:01:43.154742 20404 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1211 21:01:51.182394 20404 solver.cpp:218] Iteration 102900 (12.4581 iter/s, 8.02689s/100 iters), loss = 0.0178448
I1211 21:01:51.182394 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:01:51.182394 20404 solver.cpp:237]     Train net output #1: loss = 0.017845 (* 1 = 0.017845 loss)
I1211 21:01:51.182394 20404 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1211 21:01:58.782341  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:01:59.101909 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.caffemodel
I1211 21:01:59.185410 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.solverstate
I1211 21:01:59.191419 20404 solver.cpp:330] Iteration 103000, Testing net (#0)
I1211 21:01:59.191419 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:02:00.878649  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:02:00.944886 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9284
I1211 21:02:00.944886 20404 solver.cpp:397]     Test net output #1: loss = 0.253421 (* 1 = 0.253421 loss)
I1211 21:02:01.020944 20404 solver.cpp:218] Iteration 103000 (10.165 iter/s, 9.83764s/100 iters), loss = 0.0318941
I1211 21:02:01.020944 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:02:01.020944 20404 solver.cpp:237]     Train net output #1: loss = 0.0318943 (* 1 = 0.0318943 loss)
I1211 21:02:01.020944 20404 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1211 21:02:09.025907 20404 solver.cpp:218] Iteration 103100 (12.4926 iter/s, 8.00471s/100 iters), loss = 0.0604916
I1211 21:02:09.025907 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:02:09.025907 20404 solver.cpp:237]     Train net output #1: loss = 0.0604918 (* 1 = 0.0604918 loss)
I1211 21:02:09.025907 20404 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1211 21:02:17.034693 20404 solver.cpp:218] Iteration 103200 (12.4868 iter/s, 8.00849s/100 iters), loss = 0.0334674
I1211 21:02:17.034693 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:02:17.034693 20404 solver.cpp:237]     Train net output #1: loss = 0.0334676 (* 1 = 0.0334676 loss)
I1211 21:02:17.034693 20404 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1211 21:02:25.021538 20404 solver.cpp:218] Iteration 103300 (12.5219 iter/s, 7.986s/100 iters), loss = 0.0170541
I1211 21:02:25.021538 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:02:25.021538 20404 solver.cpp:237]     Train net output #1: loss = 0.0170543 (* 1 = 0.0170543 loss)
I1211 21:02:25.021538 20404 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1211 21:02:33.020589 20404 solver.cpp:218] Iteration 103400 (12.5026 iter/s, 7.99832s/100 iters), loss = 0.0168089
I1211 21:02:33.020589 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:02:33.020589 20404 solver.cpp:237]     Train net output #1: loss = 0.0168091 (* 1 = 0.0168091 loss)
I1211 21:02:33.020589 20404 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1211 21:02:40.606043  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:02:40.926070 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.caffemodel
I1211 21:02:40.953075 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.solverstate
I1211 21:02:40.959089 20404 solver.cpp:330] Iteration 103500, Testing net (#0)
I1211 21:02:40.959089 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:02:42.640280  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:02:42.707278 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9297
I1211 21:02:42.707278 20404 solver.cpp:397]     Test net output #1: loss = 0.247265 (* 1 = 0.247265 loss)
I1211 21:02:42.782291 20404 solver.cpp:218] Iteration 103500 (10.244 iter/s, 9.76177s/100 iters), loss = 0.0233983
I1211 21:02:42.782291 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:02:42.782291 20404 solver.cpp:237]     Train net output #1: loss = 0.0233986 (* 1 = 0.0233986 loss)
I1211 21:02:42.782291 20404 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1211 21:02:50.766185 20404 solver.cpp:218] Iteration 103600 (12.5259 iter/s, 7.98345s/100 iters), loss = 0.0278789
I1211 21:02:50.766185 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:02:50.766185 20404 solver.cpp:237]     Train net output #1: loss = 0.0278791 (* 1 = 0.0278791 loss)
I1211 21:02:50.766185 20404 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1211 21:02:58.747794 20404 solver.cpp:218] Iteration 103700 (12.5292 iter/s, 7.98134s/100 iters), loss = 0.0235826
I1211 21:02:58.747794 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:02:58.748796 20404 solver.cpp:237]     Train net output #1: loss = 0.0235828 (* 1 = 0.0235828 loss)
I1211 21:02:58.748796 20404 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1211 21:03:06.745604 20404 solver.cpp:218] Iteration 103800 (12.5054 iter/s, 7.99653s/100 iters), loss = 0.0315187
I1211 21:03:06.745604 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:03:06.745604 20404 solver.cpp:237]     Train net output #1: loss = 0.0315189 (* 1 = 0.0315189 loss)
I1211 21:03:06.745604 20404 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1211 21:03:14.792080 20404 solver.cpp:218] Iteration 103900 (12.4287 iter/s, 8.04587s/100 iters), loss = 0.0141463
I1211 21:03:14.792080 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:03:14.792080 20404 solver.cpp:237]     Train net output #1: loss = 0.0141465 (* 1 = 0.0141465 loss)
I1211 21:03:14.792080 20404 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1211 21:03:22.519330  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:03:22.842394 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.caffemodel
I1211 21:03:22.874390 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.solverstate
I1211 21:03:22.881392 20404 solver.cpp:330] Iteration 104000, Testing net (#0)
I1211 21:03:22.881392 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:03:24.591922  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:03:24.660944 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9286
I1211 21:03:24.660944 20404 solver.cpp:397]     Test net output #1: loss = 0.256018 (* 1 = 0.256018 loss)
I1211 21:03:24.738450 20404 solver.cpp:218] Iteration 104000 (10.0545 iter/s, 9.94576s/100 iters), loss = 0.0290634
I1211 21:03:24.738450 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:03:24.738450 20404 solver.cpp:237]     Train net output #1: loss = 0.0290636 (* 1 = 0.0290636 loss)
I1211 21:03:24.738450 20404 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1211 21:03:33.014889 20404 solver.cpp:218] Iteration 104100 (12.0821 iter/s, 8.27674s/100 iters), loss = 0.0209046
I1211 21:03:33.014889 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:03:33.014889 20404 solver.cpp:237]     Train net output #1: loss = 0.0209048 (* 1 = 0.0209048 loss)
I1211 21:03:33.014889 20404 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1211 21:03:41.005694 20404 solver.cpp:218] Iteration 104200 (12.5154 iter/s, 7.99018s/100 iters), loss = 0.033888
I1211 21:03:41.005694 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:03:41.005694 20404 solver.cpp:237]     Train net output #1: loss = 0.0338882 (* 1 = 0.0338882 loss)
I1211 21:03:41.005694 20404 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1211 21:03:49.225466 20404 solver.cpp:218] Iteration 104300 (12.1673 iter/s, 8.21878s/100 iters), loss = 0.0337096
I1211 21:03:49.225466 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:03:49.225466 20404 solver.cpp:237]     Train net output #1: loss = 0.0337098 (* 1 = 0.0337098 loss)
I1211 21:03:49.225466 20404 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1211 21:03:57.464131 20404 solver.cpp:218] Iteration 104400 (12.1391 iter/s, 8.23787s/100 iters), loss = 0.0119047
I1211 21:03:57.464131 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:03:57.464131 20404 solver.cpp:237]     Train net output #1: loss = 0.011905 (* 1 = 0.011905 loss)
I1211 21:03:57.464131 20404 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1211 21:04:05.288872  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:04:05.613863 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.caffemodel
I1211 21:04:05.645870 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.solverstate
I1211 21:04:05.651885 20404 solver.cpp:330] Iteration 104500, Testing net (#0)
I1211 21:04:05.651885 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:04:07.367136  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:04:07.434136 20404 solver.cpp:397]     Test net output #0: accuracy = 0.93
I1211 21:04:07.434136 20404 solver.cpp:397]     Test net output #1: loss = 0.248797 (* 1 = 0.248797 loss)
I1211 21:04:07.511142 20404 solver.cpp:218] Iteration 104500 (9.95363 iter/s, 10.0466s/100 iters), loss = 0.0288971
I1211 21:04:07.511142 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:04:07.511142 20404 solver.cpp:237]     Train net output #1: loss = 0.0288974 (* 1 = 0.0288974 loss)
I1211 21:04:07.511142 20404 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1211 21:04:15.597698 20404 solver.cpp:218] Iteration 104600 (12.3671 iter/s, 8.08595s/100 iters), loss = 0.0208627
I1211 21:04:15.597698 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:04:15.597698 20404 solver.cpp:237]     Train net output #1: loss = 0.020863 (* 1 = 0.020863 loss)
I1211 21:04:15.597698 20404 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1211 21:04:23.653986 20404 solver.cpp:218] Iteration 104700 (12.4138 iter/s, 8.05558s/100 iters), loss = 0.0214637
I1211 21:04:23.653986 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:04:23.653986 20404 solver.cpp:237]     Train net output #1: loss = 0.0214639 (* 1 = 0.0214639 loss)
I1211 21:04:23.653986 20404 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1211 21:04:31.594887 20404 solver.cpp:218] Iteration 104800 (12.5939 iter/s, 7.94035s/100 iters), loss = 0.0129834
I1211 21:04:31.594887 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:04:31.594887 20404 solver.cpp:237]     Train net output #1: loss = 0.0129836 (* 1 = 0.0129836 loss)
I1211 21:04:31.594887 20404 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1211 21:04:39.619817 20404 solver.cpp:218] Iteration 104900 (12.462 iter/s, 8.02439s/100 iters), loss = 0.0184642
I1211 21:04:39.619817 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:04:39.619817 20404 solver.cpp:237]     Train net output #1: loss = 0.0184644 (* 1 = 0.0184644 loss)
I1211 21:04:39.619817 20404 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1211 21:04:47.188637  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:04:47.505667 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.caffemodel
I1211 21:04:47.534668 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.solverstate
I1211 21:04:47.539669 20404 solver.cpp:330] Iteration 105000, Testing net (#0)
I1211 21:04:47.540669 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:04:49.232946  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:04:49.299952 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9303
I1211 21:04:49.299952 20404 solver.cpp:397]     Test net output #1: loss = 0.247834 (* 1 = 0.247834 loss)
I1211 21:04:49.374955 20404 solver.cpp:218] Iteration 105000 (10.2515 iter/s, 9.75464s/100 iters), loss = 0.0389141
I1211 21:04:49.374955 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:04:49.374955 20404 solver.cpp:237]     Train net output #1: loss = 0.0389143 (* 1 = 0.0389143 loss)
I1211 21:04:49.374955 20404 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1211 21:04:57.355887 20404 solver.cpp:218] Iteration 105100 (12.5296 iter/s, 7.98113s/100 iters), loss = 0.0231331
I1211 21:04:57.356889 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:04:57.356889 20404 solver.cpp:237]     Train net output #1: loss = 0.0231333 (* 1 = 0.0231333 loss)
I1211 21:04:57.356889 20404 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1211 21:05:05.332439 20404 solver.cpp:218] Iteration 105200 (12.5376 iter/s, 7.97603s/100 iters), loss = 0.021681
I1211 21:05:05.332439 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:05:05.332439 20404 solver.cpp:237]     Train net output #1: loss = 0.0216812 (* 1 = 0.0216812 loss)
I1211 21:05:05.332439 20404 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1211 21:05:13.354601 20404 solver.cpp:218] Iteration 105300 (12.467 iter/s, 8.02118s/100 iters), loss = 0.0130685
I1211 21:05:13.354601 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:05:13.354601 20404 solver.cpp:237]     Train net output #1: loss = 0.0130688 (* 1 = 0.0130688 loss)
I1211 21:05:13.354601 20404 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1211 21:05:21.319763 20404 solver.cpp:218] Iteration 105400 (12.5559 iter/s, 7.96439s/100 iters), loss = 0.0215761
I1211 21:05:21.319763 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:05:21.319763 20404 solver.cpp:237]     Train net output #1: loss = 0.0215764 (* 1 = 0.0215764 loss)
I1211 21:05:21.319763 20404 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1211 21:05:28.898830  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:05:29.212854 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.caffemodel
I1211 21:05:29.240854 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.solverstate
I1211 21:05:29.245854 20404 solver.cpp:330] Iteration 105500, Testing net (#0)
I1211 21:05:29.246856 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:05:30.917230  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:05:30.985734 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9303
I1211 21:05:30.986244 20404 solver.cpp:397]     Test net output #1: loss = 0.251685 (* 1 = 0.251685 loss)
I1211 21:05:31.061238 20404 solver.cpp:218] Iteration 105500 (10.2655 iter/s, 9.7414s/100 iters), loss = 0.0220939
I1211 21:05:31.061238 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:05:31.061238 20404 solver.cpp:237]     Train net output #1: loss = 0.0220941 (* 1 = 0.0220941 loss)
I1211 21:05:31.061238 20404 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1211 21:05:39.015996 20404 solver.cpp:218] Iteration 105600 (12.5724 iter/s, 7.95394s/100 iters), loss = 0.0380312
I1211 21:05:39.015996 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:05:39.015996 20404 solver.cpp:237]     Train net output #1: loss = 0.0380315 (* 1 = 0.0380315 loss)
I1211 21:05:39.015996 20404 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1211 21:05:47.003967 20404 solver.cpp:218] Iteration 105700 (12.5191 iter/s, 7.98781s/100 iters), loss = 0.0351007
I1211 21:05:47.003967 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:05:47.003967 20404 solver.cpp:237]     Train net output #1: loss = 0.0351009 (* 1 = 0.0351009 loss)
I1211 21:05:47.003967 20404 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1211 21:05:55.051703 20404 solver.cpp:218] Iteration 105800 (12.4267 iter/s, 8.04716s/100 iters), loss = 0.0191344
I1211 21:05:55.051703 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:05:55.051703 20404 solver.cpp:237]     Train net output #1: loss = 0.0191346 (* 1 = 0.0191346 loss)
I1211 21:05:55.051703 20404 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1211 21:06:03.002895 20404 solver.cpp:218] Iteration 105900 (12.5773 iter/s, 7.95085s/100 iters), loss = 0.0217693
I1211 21:06:03.002895 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:06:03.002895 20404 solver.cpp:237]     Train net output #1: loss = 0.0217695 (* 1 = 0.0217695 loss)
I1211 21:06:03.002895 20404 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1211 21:06:10.570891  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:06:10.884495 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.caffemodel
I1211 21:06:10.914000 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.solverstate
I1211 21:06:10.919998 20404 solver.cpp:330] Iteration 106000, Testing net (#0)
I1211 21:06:10.919998 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:06:12.590612  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:06:12.657133 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9292
I1211 21:06:12.657133 20404 solver.cpp:397]     Test net output #1: loss = 0.253835 (* 1 = 0.253835 loss)
I1211 21:06:12.731650 20404 solver.cpp:218] Iteration 106000 (10.2792 iter/s, 9.72838s/100 iters), loss = 0.0244836
I1211 21:06:12.732653 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:06:12.732653 20404 solver.cpp:237]     Train net output #1: loss = 0.0244838 (* 1 = 0.0244838 loss)
I1211 21:06:12.732653 20404 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1211 21:06:20.675024 20404 solver.cpp:218] Iteration 106100 (12.5911 iter/s, 7.94211s/100 iters), loss = 0.0296772
I1211 21:06:20.675024 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:06:20.675024 20404 solver.cpp:237]     Train net output #1: loss = 0.0296774 (* 1 = 0.0296774 loss)
I1211 21:06:20.675024 20404 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1211 21:06:28.627008 20404 solver.cpp:218] Iteration 106200 (12.5764 iter/s, 7.95142s/100 iters), loss = 0.0278756
I1211 21:06:28.627008 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:06:28.627008 20404 solver.cpp:237]     Train net output #1: loss = 0.0278758 (* 1 = 0.0278758 loss)
I1211 21:06:28.627008 20404 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1211 21:06:36.565796 20404 solver.cpp:218] Iteration 106300 (12.5964 iter/s, 7.93876s/100 iters), loss = 0.020393
I1211 21:06:36.565796 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:06:36.565796 20404 solver.cpp:237]     Train net output #1: loss = 0.0203932 (* 1 = 0.0203932 loss)
I1211 21:06:36.565796 20404 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1211 21:06:44.499977 20404 solver.cpp:218] Iteration 106400 (12.6048 iter/s, 7.9335s/100 iters), loss = 0.0152962
I1211 21:06:44.499977 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:06:44.500478 20404 solver.cpp:237]     Train net output #1: loss = 0.0152964 (* 1 = 0.0152964 loss)
I1211 21:06:44.500478 20404 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1211 21:06:52.055627  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:06:52.369678 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.caffemodel
I1211 21:06:52.398694 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.solverstate
I1211 21:06:52.404683 20404 solver.cpp:330] Iteration 106500, Testing net (#0)
I1211 21:06:52.404683 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:06:54.074967  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:06:54.141986 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9286
I1211 21:06:54.141986 20404 solver.cpp:397]     Test net output #1: loss = 0.254016 (* 1 = 0.254016 loss)
I1211 21:06:54.216980 20404 solver.cpp:218] Iteration 106500 (10.2921 iter/s, 9.71621s/100 iters), loss = 0.0174111
I1211 21:06:54.216980 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:06:54.216980 20404 solver.cpp:237]     Train net output #1: loss = 0.0174113 (* 1 = 0.0174113 loss)
I1211 21:06:54.216980 20404 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1211 21:07:02.163058 20404 solver.cpp:218] Iteration 106600 (12.5852 iter/s, 7.94584s/100 iters), loss = 0.0593327
I1211 21:07:02.163058 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 21:07:02.163058 20404 solver.cpp:237]     Train net output #1: loss = 0.0593329 (* 1 = 0.0593329 loss)
I1211 21:07:02.163058 20404 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1211 21:07:10.187829 20404 solver.cpp:218] Iteration 106700 (12.4628 iter/s, 8.02385s/100 iters), loss = 0.0233681
I1211 21:07:10.187829 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:07:10.187829 20404 solver.cpp:237]     Train net output #1: loss = 0.0233683 (* 1 = 0.0233683 loss)
I1211 21:07:10.187829 20404 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1211 21:07:18.148152 20404 solver.cpp:218] Iteration 106800 (12.5617 iter/s, 7.96071s/100 iters), loss = 0.0129825
I1211 21:07:18.149153 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:07:18.149153 20404 solver.cpp:237]     Train net output #1: loss = 0.0129827 (* 1 = 0.0129827 loss)
I1211 21:07:18.149153 20404 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1211 21:07:26.179574 20404 solver.cpp:218] Iteration 106900 (12.4531 iter/s, 8.03013s/100 iters), loss = 0.0220259
I1211 21:07:26.179574 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:07:26.179574 20404 solver.cpp:237]     Train net output #1: loss = 0.0220261 (* 1 = 0.0220261 loss)
I1211 21:07:26.179574 20404 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1211 21:07:33.742053  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:07:34.056097 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.caffemodel
I1211 21:07:34.083096 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.solverstate
I1211 21:07:34.093096 20404 solver.cpp:330] Iteration 107000, Testing net (#0)
I1211 21:07:34.093096 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:07:35.764396  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:07:35.830404 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9301
I1211 21:07:35.831403 20404 solver.cpp:397]     Test net output #1: loss = 0.248159 (* 1 = 0.248159 loss)
I1211 21:07:35.904417 20404 solver.cpp:218] Iteration 107000 (10.2829 iter/s, 9.72484s/100 iters), loss = 0.035056
I1211 21:07:35.905403 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:07:35.905403 20404 solver.cpp:237]     Train net output #1: loss = 0.0350563 (* 1 = 0.0350563 loss)
I1211 21:07:35.905403 20404 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1211 21:07:43.844581 20404 solver.cpp:218] Iteration 107100 (12.5963 iter/s, 7.93881s/100 iters), loss = 0.0188761
I1211 21:07:43.844581 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:07:43.844581 20404 solver.cpp:237]     Train net output #1: loss = 0.0188764 (* 1 = 0.0188764 loss)
I1211 21:07:43.844581 20404 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1211 21:07:51.790310 20404 solver.cpp:218] Iteration 107200 (12.5862 iter/s, 7.94521s/100 iters), loss = 0.0197871
I1211 21:07:51.790310 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:07:51.790310 20404 solver.cpp:237]     Train net output #1: loss = 0.0197874 (* 1 = 0.0197874 loss)
I1211 21:07:51.790310 20404 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1211 21:07:59.751032 20404 solver.cpp:218] Iteration 107300 (12.5619 iter/s, 7.96056s/100 iters), loss = 0.0183478
I1211 21:07:59.751032 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:07:59.751032 20404 solver.cpp:237]     Train net output #1: loss = 0.018348 (* 1 = 0.018348 loss)
I1211 21:07:59.751032 20404 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1211 21:08:07.690758 20404 solver.cpp:218] Iteration 107400 (12.596 iter/s, 7.93904s/100 iters), loss = 0.0201762
I1211 21:08:07.690758 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:08:07.690758 20404 solver.cpp:237]     Train net output #1: loss = 0.0201765 (* 1 = 0.0201765 loss)
I1211 21:08:07.690758 20404 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1211 21:08:15.254689  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:08:15.568295 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.caffemodel
I1211 21:08:15.600296 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.solverstate
I1211 21:08:15.606297 20404 solver.cpp:330] Iteration 107500, Testing net (#0)
I1211 21:08:15.606297 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:08:17.289997  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:08:17.356001 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9305
I1211 21:08:17.357002 20404 solver.cpp:397]     Test net output #1: loss = 0.248819 (* 1 = 0.248819 loss)
I1211 21:08:17.431505 20404 solver.cpp:218] Iteration 107500 (10.2668 iter/s, 9.74015s/100 iters), loss = 0.0138687
I1211 21:08:17.431505 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:08:17.431505 20404 solver.cpp:237]     Train net output #1: loss = 0.0138689 (* 1 = 0.0138689 loss)
I1211 21:08:17.431505 20404 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1211 21:08:25.382133 20404 solver.cpp:218] Iteration 107600 (12.5779 iter/s, 7.95043s/100 iters), loss = 0.019206
I1211 21:08:25.382133 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:08:25.382133 20404 solver.cpp:237]     Train net output #1: loss = 0.0192062 (* 1 = 0.0192062 loss)
I1211 21:08:25.382133 20404 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1211 21:08:33.337992 20404 solver.cpp:218] Iteration 107700 (12.5711 iter/s, 7.95476s/100 iters), loss = 0.0219652
I1211 21:08:33.337992 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:08:33.337992 20404 solver.cpp:237]     Train net output #1: loss = 0.0219654 (* 1 = 0.0219654 loss)
I1211 21:08:33.337992 20404 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1211 21:08:41.433603 20404 solver.cpp:218] Iteration 107800 (12.3522 iter/s, 8.09573s/100 iters), loss = 0.0145467
I1211 21:08:41.433603 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:08:41.433603 20404 solver.cpp:237]     Train net output #1: loss = 0.0145469 (* 1 = 0.0145469 loss)
I1211 21:08:41.433603 20404 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1211 21:08:49.476150 20404 solver.cpp:218] Iteration 107900 (12.436 iter/s, 8.04118s/100 iters), loss = 0.0147521
I1211 21:08:49.476150 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:08:49.476150 20404 solver.cpp:237]     Train net output #1: loss = 0.0147523 (* 1 = 0.0147523 loss)
I1211 21:08:49.476150 20404 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1211 21:08:57.041590  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:08:57.355890 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.caffemodel
I1211 21:08:57.383407 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.solverstate
I1211 21:08:57.389392 20404 solver.cpp:330] Iteration 108000, Testing net (#0)
I1211 21:08:57.389392 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:08:59.061239  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:08:59.128237 20404 solver.cpp:397]     Test net output #0: accuracy = 0.93
I1211 21:08:59.128237 20404 solver.cpp:397]     Test net output #1: loss = 0.249543 (* 1 = 0.249543 loss)
I1211 21:08:59.202519 20404 solver.cpp:218] Iteration 108000 (10.2816 iter/s, 9.72612s/100 iters), loss = 0.0297601
I1211 21:08:59.202519 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:08:59.202519 20404 solver.cpp:237]     Train net output #1: loss = 0.0297603 (* 1 = 0.0297603 loss)
I1211 21:08:59.202519 20404 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1211 21:09:07.136338 20404 solver.cpp:218] Iteration 108100 (12.6054 iter/s, 7.93314s/100 iters), loss = 0.030011
I1211 21:09:07.136338 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:09:07.136338 20404 solver.cpp:237]     Train net output #1: loss = 0.0300112 (* 1 = 0.0300112 loss)
I1211 21:09:07.136338 20404 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1211 21:09:15.095574 20404 solver.cpp:218] Iteration 108200 (12.5645 iter/s, 7.95896s/100 iters), loss = 0.028216
I1211 21:09:15.095574 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:09:15.095574 20404 solver.cpp:237]     Train net output #1: loss = 0.0282162 (* 1 = 0.0282162 loss)
I1211 21:09:15.095574 20404 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1211 21:09:23.059490 20404 solver.cpp:218] Iteration 108300 (12.558 iter/s, 7.96307s/100 iters), loss = 0.0217792
I1211 21:09:23.059490 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:09:23.059490 20404 solver.cpp:237]     Train net output #1: loss = 0.0217794 (* 1 = 0.0217794 loss)
I1211 21:09:23.059490 20404 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1211 21:09:31.005288 20404 solver.cpp:218] Iteration 108400 (12.5855 iter/s, 7.94566s/100 iters), loss = 0.0139972
I1211 21:09:31.005288 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:09:31.005288 20404 solver.cpp:237]     Train net output #1: loss = 0.0139974 (* 1 = 0.0139974 loss)
I1211 21:09:31.005288 20404 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1211 21:09:38.562937  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:09:38.878001 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.caffemodel
I1211 21:09:38.908004 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.solverstate
I1211 21:09:38.914003 20404 solver.cpp:330] Iteration 108500, Testing net (#0)
I1211 21:09:38.914003 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:09:40.586133  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:09:40.653134 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9303
I1211 21:09:40.653134 20404 solver.cpp:397]     Test net output #1: loss = 0.251447 (* 1 = 0.251447 loss)
I1211 21:09:40.727136 20404 solver.cpp:218] Iteration 108500 (10.2865 iter/s, 9.72145s/100 iters), loss = 0.0320612
I1211 21:09:40.727136 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:09:40.727136 20404 solver.cpp:237]     Train net output #1: loss = 0.0320614 (* 1 = 0.0320614 loss)
I1211 21:09:40.727136 20404 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1211 21:09:48.670867 20404 solver.cpp:218] Iteration 108600 (12.5901 iter/s, 7.94276s/100 iters), loss = 0.0342529
I1211 21:09:48.670867 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:09:48.670867 20404 solver.cpp:237]     Train net output #1: loss = 0.0342531 (* 1 = 0.0342531 loss)
I1211 21:09:48.670867 20404 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1211 21:09:56.743532 20404 solver.cpp:218] Iteration 108700 (12.3878 iter/s, 8.07249s/100 iters), loss = 0.0143232
I1211 21:09:56.743532 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:09:56.743532 20404 solver.cpp:237]     Train net output #1: loss = 0.0143235 (* 1 = 0.0143235 loss)
I1211 21:09:56.743532 20404 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1211 21:10:04.738080 20404 solver.cpp:218] Iteration 108800 (12.509 iter/s, 7.99424s/100 iters), loss = 0.019827
I1211 21:10:04.738080 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:10:04.738080 20404 solver.cpp:237]     Train net output #1: loss = 0.0198272 (* 1 = 0.0198272 loss)
I1211 21:10:04.738080 20404 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1211 21:10:12.710451 20404 solver.cpp:218] Iteration 108900 (12.5437 iter/s, 7.97213s/100 iters), loss = 0.0265744
I1211 21:10:12.711452 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:10:12.711452 20404 solver.cpp:237]     Train net output #1: loss = 0.0265746 (* 1 = 0.0265746 loss)
I1211 21:10:12.711452 20404 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1211 21:10:20.268051  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:10:20.580798 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.caffemodel
I1211 21:10:20.611799 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.solverstate
I1211 21:10:20.617801 20404 solver.cpp:330] Iteration 109000, Testing net (#0)
I1211 21:10:20.617801 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:10:22.292819  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:10:22.358814 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9313
I1211 21:10:22.358814 20404 solver.cpp:397]     Test net output #1: loss = 0.253294 (* 1 = 0.253294 loss)
I1211 21:10:22.433434 20404 solver.cpp:218] Iteration 109000 (10.2864 iter/s, 9.72161s/100 iters), loss = 0.0161216
I1211 21:10:22.433434 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:10:22.433434 20404 solver.cpp:237]     Train net output #1: loss = 0.0161218 (* 1 = 0.0161218 loss)
I1211 21:10:22.433434 20404 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1211 21:10:30.385109 20404 solver.cpp:218] Iteration 109100 (12.5762 iter/s, 7.95155s/100 iters), loss = 0.0222822
I1211 21:10:30.385109 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:10:30.385109 20404 solver.cpp:237]     Train net output #1: loss = 0.0222824 (* 1 = 0.0222824 loss)
I1211 21:10:30.385109 20404 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1211 21:10:38.338724 20404 solver.cpp:218] Iteration 109200 (12.5735 iter/s, 7.95321s/100 iters), loss = 0.0185482
I1211 21:10:38.338724 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:10:38.338724 20404 solver.cpp:237]     Train net output #1: loss = 0.0185485 (* 1 = 0.0185485 loss)
I1211 21:10:38.338724 20404 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1211 21:10:46.289297 20404 solver.cpp:218] Iteration 109300 (12.5781 iter/s, 7.95034s/100 iters), loss = 0.0139855
I1211 21:10:46.289297 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:10:46.290298 20404 solver.cpp:237]     Train net output #1: loss = 0.0139857 (* 1 = 0.0139857 loss)
I1211 21:10:46.290298 20404 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1211 21:10:54.279755 20404 solver.cpp:218] Iteration 109400 (12.5171 iter/s, 7.98904s/100 iters), loss = 0.0196088
I1211 21:10:54.279755 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:10:54.279755 20404 solver.cpp:237]     Train net output #1: loss = 0.019609 (* 1 = 0.019609 loss)
I1211 21:10:54.279755 20404 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1211 21:11:01.932796  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:11:02.248347 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.caffemodel
I1211 21:11:02.279353 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.solverstate
I1211 21:11:02.285367 20404 solver.cpp:330] Iteration 109500, Testing net (#0)
I1211 21:11:02.285852 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:11:03.999451  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:11:04.066450 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9306
I1211 21:11:04.066450 20404 solver.cpp:397]     Test net output #1: loss = 0.254847 (* 1 = 0.254847 loss)
I1211 21:11:04.143494 20404 solver.cpp:218] Iteration 109500 (10.138 iter/s, 9.86387s/100 iters), loss = 0.0212876
I1211 21:11:04.143494 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:11:04.143494 20404 solver.cpp:237]     Train net output #1: loss = 0.0212879 (* 1 = 0.0212879 loss)
I1211 21:11:04.143494 20404 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1211 21:11:12.149390 20404 solver.cpp:218] Iteration 109600 (12.4913 iter/s, 8.00555s/100 iters), loss = 0.0230263
I1211 21:11:12.150390 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:11:12.150390 20404 solver.cpp:237]     Train net output #1: loss = 0.0230266 (* 1 = 0.0230266 loss)
I1211 21:11:12.150390 20404 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1211 21:11:20.094399 20404 solver.cpp:218] Iteration 109700 (12.5886 iter/s, 7.94372s/100 iters), loss = 0.0304587
I1211 21:11:20.094399 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:11:20.094399 20404 solver.cpp:237]     Train net output #1: loss = 0.030459 (* 1 = 0.030459 loss)
I1211 21:11:20.094399 20404 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1211 21:11:28.027837 20404 solver.cpp:218] Iteration 109800 (12.6054 iter/s, 7.9331s/100 iters), loss = 0.0111577
I1211 21:11:28.027837 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:11:28.027837 20404 solver.cpp:237]     Train net output #1: loss = 0.0111579 (* 1 = 0.0111579 loss)
I1211 21:11:28.027837 20404 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1211 21:11:35.969177 20404 solver.cpp:218] Iteration 109900 (12.5922 iter/s, 7.94144s/100 iters), loss = 0.0258351
I1211 21:11:35.969177 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:11:35.969177 20404 solver.cpp:237]     Train net output #1: loss = 0.0258354 (* 1 = 0.0258354 loss)
I1211 21:11:35.970176 20404 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1211 21:11:43.520311  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:11:43.832805 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.caffemodel
I1211 21:11:43.860824 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.solverstate
I1211 21:11:43.866819 20404 solver.cpp:330] Iteration 110000, Testing net (#0)
I1211 21:11:43.866819 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:11:45.539568  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:11:45.606586 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 21:11:45.607084 20404 solver.cpp:397]     Test net output #1: loss = 0.251317 (* 1 = 0.251317 loss)
I1211 21:11:45.681617 20404 solver.cpp:218] Iteration 110000 (10.2969 iter/s, 9.71169s/100 iters), loss = 0.0185034
I1211 21:11:45.681617 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:11:45.681617 20404 solver.cpp:237]     Train net output #1: loss = 0.0185036 (* 1 = 0.0185036 loss)
I1211 21:11:45.681617 20404 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1211 21:11:53.623437 20404 solver.cpp:218] Iteration 110100 (12.5933 iter/s, 7.94075s/100 iters), loss = 0.0285311
I1211 21:11:53.623437 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:11:53.623437 20404 solver.cpp:237]     Train net output #1: loss = 0.0285313 (* 1 = 0.0285313 loss)
I1211 21:11:53.623437 20404 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1211 21:12:01.567867 20404 solver.cpp:218] Iteration 110200 (12.5882 iter/s, 7.94396s/100 iters), loss = 0.0492214
I1211 21:12:01.567867 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:12:01.567867 20404 solver.cpp:237]     Train net output #1: loss = 0.0492216 (* 1 = 0.0492216 loss)
I1211 21:12:01.567867 20404 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1211 21:12:09.521204 20404 solver.cpp:218] Iteration 110300 (12.5738 iter/s, 7.95306s/100 iters), loss = 0.0150854
I1211 21:12:09.521204 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:09.521705 20404 solver.cpp:237]     Train net output #1: loss = 0.0150856 (* 1 = 0.0150856 loss)
I1211 21:12:09.521705 20404 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1211 21:12:17.470633 20404 solver.cpp:218] Iteration 110400 (12.5802 iter/s, 7.94897s/100 iters), loss = 0.0148227
I1211 21:12:17.470633 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:17.470633 20404 solver.cpp:237]     Train net output #1: loss = 0.0148229 (* 1 = 0.0148229 loss)
I1211 21:12:17.470633 20404 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1211 21:12:25.048727  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:12:25.363021 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.caffemodel
I1211 21:12:25.394021 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.solverstate
I1211 21:12:25.400035 20404 solver.cpp:330] Iteration 110500, Testing net (#0)
I1211 21:12:25.400035 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:12:27.076061  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:12:27.144851 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9283
I1211 21:12:27.144851 20404 solver.cpp:397]     Test net output #1: loss = 0.256002 (* 1 = 0.256002 loss)
I1211 21:12:27.223357 20404 solver.cpp:218] Iteration 110500 (10.2541 iter/s, 9.75218s/100 iters), loss = 0.0175128
I1211 21:12:27.223857 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:27.223857 20404 solver.cpp:237]     Train net output #1: loss = 0.0175131 (* 1 = 0.0175131 loss)
I1211 21:12:27.223857 20404 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1211 21:12:35.453027 20404 solver.cpp:218] Iteration 110600 (12.1516 iter/s, 8.22937s/100 iters), loss = 0.0139608
I1211 21:12:35.453027 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:35.453027 20404 solver.cpp:237]     Train net output #1: loss = 0.0139611 (* 1 = 0.0139611 loss)
I1211 21:12:35.453027 20404 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1211 21:12:43.708474 20404 solver.cpp:218] Iteration 110700 (12.1136 iter/s, 8.25516s/100 iters), loss = 0.0166084
I1211 21:12:43.708474 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:43.708474 20404 solver.cpp:237]     Train net output #1: loss = 0.0166086 (* 1 = 0.0166086 loss)
I1211 21:12:43.708474 20404 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1211 21:12:51.866161 20404 solver.cpp:218] Iteration 110800 (12.2596 iter/s, 8.15688s/100 iters), loss = 0.0145024
I1211 21:12:51.866161 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:51.866161 20404 solver.cpp:237]     Train net output #1: loss = 0.0145026 (* 1 = 0.0145026 loss)
I1211 21:12:51.866161 20404 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1211 21:12:59.842057 20404 solver.cpp:218] Iteration 110900 (12.5382 iter/s, 7.97562s/100 iters), loss = 0.0160127
I1211 21:12:59.842057 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:12:59.842057 20404 solver.cpp:237]     Train net output #1: loss = 0.0160129 (* 1 = 0.0160129 loss)
I1211 21:12:59.842057 20404 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1211 21:13:07.389986  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:13:07.705014 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.caffemodel
I1211 21:13:07.734020 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.solverstate
I1211 21:13:07.739521 20404 solver.cpp:330] Iteration 111000, Testing net (#0)
I1211 21:13:07.739521 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:13:09.410207  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:13:09.477226 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9302
I1211 21:13:09.477226 20404 solver.cpp:397]     Test net output #1: loss = 0.255092 (* 1 = 0.255092 loss)
I1211 21:13:09.552232 20404 solver.cpp:218] Iteration 111000 (10.2995 iter/s, 9.70922s/100 iters), loss = 0.0207139
I1211 21:13:09.552232 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:13:09.552232 20404 solver.cpp:237]     Train net output #1: loss = 0.0207141 (* 1 = 0.0207141 loss)
I1211 21:13:09.552232 20404 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1211 21:13:17.493443 20404 solver.cpp:218] Iteration 111100 (12.5931 iter/s, 7.94084s/100 iters), loss = 0.0175057
I1211 21:13:17.493443 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:13:17.493443 20404 solver.cpp:237]     Train net output #1: loss = 0.0175059 (* 1 = 0.0175059 loss)
I1211 21:13:17.493443 20404 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1211 21:13:25.478004 20404 solver.cpp:218] Iteration 111200 (12.5253 iter/s, 7.98386s/100 iters), loss = 0.0326142
I1211 21:13:25.478004 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:13:25.478004 20404 solver.cpp:237]     Train net output #1: loss = 0.0326144 (* 1 = 0.0326144 loss)
I1211 21:13:25.478004 20404 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1211 21:13:33.457681 20404 solver.cpp:218] Iteration 111300 (12.5319 iter/s, 7.97964s/100 iters), loss = 0.0204687
I1211 21:13:33.458667 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:13:33.458667 20404 solver.cpp:237]     Train net output #1: loss = 0.0204689 (* 1 = 0.0204689 loss)
I1211 21:13:33.458667 20404 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1211 21:13:41.451772 20404 solver.cpp:218] Iteration 111400 (12.5104 iter/s, 7.99335s/100 iters), loss = 0.0172446
I1211 21:13:41.451772 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:13:41.451772 20404 solver.cpp:237]     Train net output #1: loss = 0.0172448 (* 1 = 0.0172448 loss)
I1211 21:13:41.451772 20404 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1211 21:13:49.131562  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:13:49.454854 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.caffemodel
I1211 21:13:49.485865 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.solverstate
I1211 21:13:49.491869 20404 solver.cpp:330] Iteration 111500, Testing net (#0)
I1211 21:13:49.491869 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:13:51.198393  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:13:51.266412 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9307
I1211 21:13:51.266412 20404 solver.cpp:397]     Test net output #1: loss = 0.256077 (* 1 = 0.256077 loss)
I1211 21:13:51.342437 20404 solver.cpp:218] Iteration 111500 (10.1118 iter/s, 9.88942s/100 iters), loss = 0.0146024
I1211 21:13:51.342437 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:13:51.342437 20404 solver.cpp:237]     Train net output #1: loss = 0.0146026 (* 1 = 0.0146026 loss)
I1211 21:13:51.342437 20404 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1211 21:13:59.463066 20404 solver.cpp:218] Iteration 111600 (12.3147 iter/s, 8.1204s/100 iters), loss = 0.0493634
I1211 21:13:59.463066 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:13:59.463066 20404 solver.cpp:237]     Train net output #1: loss = 0.0493636 (* 1 = 0.0493636 loss)
I1211 21:13:59.463066 20404 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1211 21:14:07.602077 20404 solver.cpp:218] Iteration 111700 (12.2878 iter/s, 8.13816s/100 iters), loss = 0.0185913
I1211 21:14:07.602077 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:14:07.602077 20404 solver.cpp:237]     Train net output #1: loss = 0.0185916 (* 1 = 0.0185916 loss)
I1211 21:14:07.602077 20404 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1211 21:14:15.685230 20404 solver.cpp:218] Iteration 111800 (12.372 iter/s, 8.08277s/100 iters), loss = 0.0106747
I1211 21:14:15.685230 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:14:15.685230 20404 solver.cpp:237]     Train net output #1: loss = 0.010675 (* 1 = 0.010675 loss)
I1211 21:14:15.685230 20404 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1211 21:14:23.719347 20404 solver.cpp:218] Iteration 111900 (12.4468 iter/s, 8.03417s/100 iters), loss = 0.0227926
I1211 21:14:23.719347 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:14:23.719347 20404 solver.cpp:237]     Train net output #1: loss = 0.0227929 (* 1 = 0.0227929 loss)
I1211 21:14:23.719347 20404 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1211 21:14:31.311839  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:14:31.630866 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.caffemodel
I1211 21:14:31.661872 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.solverstate
I1211 21:14:31.667871 20404 solver.cpp:330] Iteration 112000, Testing net (#0)
I1211 21:14:31.667871 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:14:33.358902  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:14:33.427917 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9296
I1211 21:14:33.427917 20404 solver.cpp:397]     Test net output #1: loss = 0.258426 (* 1 = 0.258426 loss)
I1211 21:14:33.503916 20404 solver.cpp:218] Iteration 112000 (10.2208 iter/s, 9.78402s/100 iters), loss = 0.0276899
I1211 21:14:33.503916 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:14:33.503916 20404 solver.cpp:237]     Train net output #1: loss = 0.0276901 (* 1 = 0.0276901 loss)
I1211 21:14:33.503916 20404 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1211 21:14:41.682179 20404 solver.cpp:218] Iteration 112100 (12.2283 iter/s, 8.17777s/100 iters), loss = 0.0239937
I1211 21:14:41.683177 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:14:41.683177 20404 solver.cpp:237]     Train net output #1: loss = 0.023994 (* 1 = 0.023994 loss)
I1211 21:14:41.683177 20404 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1211 21:14:49.738322 20404 solver.cpp:218] Iteration 112200 (12.4142 iter/s, 8.0553s/100 iters), loss = 0.0239098
I1211 21:14:49.738322 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:14:49.738322 20404 solver.cpp:237]     Train net output #1: loss = 0.02391 (* 1 = 0.02391 loss)
I1211 21:14:49.738322 20404 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1211 21:14:57.751996 20404 solver.cpp:218] Iteration 112300 (12.4794 iter/s, 8.01319s/100 iters), loss = 0.0130232
I1211 21:14:57.751996 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:14:57.751996 20404 solver.cpp:237]     Train net output #1: loss = 0.0130235 (* 1 = 0.0130235 loss)
I1211 21:14:57.751996 20404 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1211 21:15:05.816476 20404 solver.cpp:218] Iteration 112400 (12.4015 iter/s, 8.06352s/100 iters), loss = 0.0146267
I1211 21:15:05.816476 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:15:05.816476 20404 solver.cpp:237]     Train net output #1: loss = 0.0146269 (* 1 = 0.0146269 loss)
I1211 21:15:05.816476 20404 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1211 21:15:13.391753  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:15:13.703788 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.caffemodel
I1211 21:15:13.733291 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.solverstate
I1211 21:15:13.738792 20404 solver.cpp:330] Iteration 112500, Testing net (#0)
I1211 21:15:13.739292 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:15:15.421991  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:15:15.488996 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9318
I1211 21:15:15.488996 20404 solver.cpp:397]     Test net output #1: loss = 0.255899 (* 1 = 0.255899 loss)
I1211 21:15:15.564013 20404 solver.cpp:218] Iteration 112500 (10.2594 iter/s, 9.74713s/100 iters), loss = 0.0146447
I1211 21:15:15.564013 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:15:15.564013 20404 solver.cpp:237]     Train net output #1: loss = 0.014645 (* 1 = 0.014645 loss)
I1211 21:15:15.564013 20404 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1211 21:15:23.587100 20404 solver.cpp:218] Iteration 112600 (12.4651 iter/s, 8.02238s/100 iters), loss = 0.014629
I1211 21:15:23.587100 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:15:23.587100 20404 solver.cpp:237]     Train net output #1: loss = 0.0146293 (* 1 = 0.0146293 loss)
I1211 21:15:23.587100 20404 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1211 21:15:31.610574 20404 solver.cpp:218] Iteration 112700 (12.4636 iter/s, 8.02338s/100 iters), loss = 0.0241012
I1211 21:15:31.610574 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:15:31.610574 20404 solver.cpp:237]     Train net output #1: loss = 0.0241015 (* 1 = 0.0241015 loss)
I1211 21:15:31.610574 20404 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1211 21:15:39.635740 20404 solver.cpp:218] Iteration 112800 (12.4627 iter/s, 8.02392s/100 iters), loss = 0.0274268
I1211 21:15:39.635740 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:15:39.635740 20404 solver.cpp:237]     Train net output #1: loss = 0.027427 (* 1 = 0.027427 loss)
I1211 21:15:39.635740 20404 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1211 21:15:47.656170 20404 solver.cpp:218] Iteration 112900 (12.4686 iter/s, 8.02015s/100 iters), loss = 0.0134749
I1211 21:15:47.656170 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:15:47.656170 20404 solver.cpp:237]     Train net output #1: loss = 0.0134752 (* 1 = 0.0134752 loss)
I1211 21:15:47.656170 20404 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1211 21:15:55.207746  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:15:55.521792 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.caffemodel
I1211 21:15:55.549796 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.solverstate
I1211 21:15:55.555797 20404 solver.cpp:330] Iteration 113000, Testing net (#0)
I1211 21:15:55.556298 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:15:57.225920  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:15:57.292935 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1211 21:15:57.292935 20404 solver.cpp:397]     Test net output #1: loss = 0.257589 (* 1 = 0.257589 loss)
I1211 21:15:57.366942 20404 solver.cpp:218] Iteration 113000 (10.298 iter/s, 9.71066s/100 iters), loss = 0.0158968
I1211 21:15:57.366942 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:15:57.366942 20404 solver.cpp:237]     Train net output #1: loss = 0.0158971 (* 1 = 0.0158971 loss)
I1211 21:15:57.366942 20404 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1211 21:16:05.304256 20404 solver.cpp:218] Iteration 113100 (12.6005 iter/s, 7.93622s/100 iters), loss = 0.0373785
I1211 21:16:05.304256 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 21:16:05.304256 20404 solver.cpp:237]     Train net output #1: loss = 0.0373788 (* 1 = 0.0373788 loss)
I1211 21:16:05.304256 20404 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1211 21:16:13.244009 20404 solver.cpp:218] Iteration 113200 (12.5945 iter/s, 7.93999s/100 iters), loss = 0.0176857
I1211 21:16:13.244009 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:16:13.244009 20404 solver.cpp:237]     Train net output #1: loss = 0.0176859 (* 1 = 0.0176859 loss)
I1211 21:16:13.244009 20404 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1211 21:16:21.178994 20404 solver.cpp:218] Iteration 113300 (12.6035 iter/s, 7.93432s/100 iters), loss = 0.0129308
I1211 21:16:21.178994 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:16:21.178994 20404 solver.cpp:237]     Train net output #1: loss = 0.012931 (* 1 = 0.012931 loss)
I1211 21:16:21.178994 20404 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1211 21:16:29.114276 20404 solver.cpp:218] Iteration 113400 (12.6025 iter/s, 7.93496s/100 iters), loss = 0.0248791
I1211 21:16:29.114276 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:16:29.115269 20404 solver.cpp:237]     Train net output #1: loss = 0.0248793 (* 1 = 0.0248793 loss)
I1211 21:16:29.115269 20404 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1211 21:16:36.664901  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:16:36.978446 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.caffemodel
I1211 21:16:37.007447 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.solverstate
I1211 21:16:37.013450 20404 solver.cpp:330] Iteration 113500, Testing net (#0)
I1211 21:16:37.013450 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:16:38.686756  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:16:38.752754 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1211 21:16:38.752754 20404 solver.cpp:397]     Test net output #1: loss = 0.257377 (* 1 = 0.257377 loss)
I1211 21:16:38.827764 20404 solver.cpp:218] Iteration 113500 (10.2965 iter/s, 9.71205s/100 iters), loss = 0.0241168
I1211 21:16:38.827764 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:16:38.827764 20404 solver.cpp:237]     Train net output #1: loss = 0.0241171 (* 1 = 0.0241171 loss)
I1211 21:16:38.827764 20404 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1211 21:16:46.780616 20404 solver.cpp:218] Iteration 113600 (12.5748 iter/s, 7.95243s/100 iters), loss = 0.0170192
I1211 21:16:46.780616 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:16:46.780616 20404 solver.cpp:237]     Train net output #1: loss = 0.0170194 (* 1 = 0.0170194 loss)
I1211 21:16:46.780616 20404 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1211 21:16:54.713675 20404 solver.cpp:218] Iteration 113700 (12.6056 iter/s, 7.93301s/100 iters), loss = 0.0158544
I1211 21:16:54.713675 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:16:54.713675 20404 solver.cpp:237]     Train net output #1: loss = 0.0158547 (* 1 = 0.0158547 loss)
I1211 21:16:54.713675 20404 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1211 21:17:02.656486 20404 solver.cpp:218] Iteration 113800 (12.5913 iter/s, 7.94198s/100 iters), loss = 0.0161836
I1211 21:17:02.656486 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:02.656486 20404 solver.cpp:237]     Train net output #1: loss = 0.0161838 (* 1 = 0.0161838 loss)
I1211 21:17:02.656486 20404 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1211 21:17:10.600276 20404 solver.cpp:218] Iteration 113900 (12.5901 iter/s, 7.94278s/100 iters), loss = 0.0171777
I1211 21:17:10.600276 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:10.600276 20404 solver.cpp:237]     Train net output #1: loss = 0.017178 (* 1 = 0.017178 loss)
I1211 21:17:10.600276 20404 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1211 21:17:18.158396  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:17:18.473420 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.caffemodel
I1211 21:17:18.504425 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.solverstate
I1211 21:17:18.510426 20404 solver.cpp:330] Iteration 114000, Testing net (#0)
I1211 21:17:18.510426 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:17:20.183115  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:17:20.248626 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1211 21:17:20.248626 20404 solver.cpp:397]     Test net output #1: loss = 0.259047 (* 1 = 0.259047 loss)
I1211 21:17:20.322623 20404 solver.cpp:218] Iteration 114000 (10.2857 iter/s, 9.72219s/100 iters), loss = 0.0194736
I1211 21:17:20.322623 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:20.322623 20404 solver.cpp:237]     Train net output #1: loss = 0.0194739 (* 1 = 0.0194739 loss)
I1211 21:17:20.322623 20404 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1211 21:17:28.284817 20404 solver.cpp:218] Iteration 114100 (12.5602 iter/s, 7.96163s/100 iters), loss = 0.0212669
I1211 21:17:28.284817 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:28.284817 20404 solver.cpp:237]     Train net output #1: loss = 0.0212671 (* 1 = 0.0212671 loss)
I1211 21:17:28.284817 20404 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1211 21:17:36.226073 20404 solver.cpp:218] Iteration 114200 (12.593 iter/s, 7.94093s/100 iters), loss = 0.0169695
I1211 21:17:36.226073 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:36.226073 20404 solver.cpp:237]     Train net output #1: loss = 0.0169698 (* 1 = 0.0169698 loss)
I1211 21:17:36.226073 20404 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1211 21:17:44.173094 20404 solver.cpp:218] Iteration 114300 (12.5846 iter/s, 7.94623s/100 iters), loss = 0.0126475
I1211 21:17:44.173094 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:44.173094 20404 solver.cpp:237]     Train net output #1: loss = 0.0126478 (* 1 = 0.0126478 loss)
I1211 21:17:44.173094 20404 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1211 21:17:52.123394 20404 solver.cpp:218] Iteration 114400 (12.5782 iter/s, 7.95026s/100 iters), loss = 0.0174462
I1211 21:17:52.123394 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:17:52.123394 20404 solver.cpp:237]     Train net output #1: loss = 0.0174465 (* 1 = 0.0174465 loss)
I1211 21:17:52.123394 20404 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1211 21:17:59.680275  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:17:59.993322 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.caffemodel
I1211 21:18:00.025327 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.solverstate
I1211 21:18:00.031327 20404 solver.cpp:330] Iteration 114500, Testing net (#0)
I1211 21:18:00.031327 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:18:01.702466  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:18:01.768468 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9315
I1211 21:18:01.769470 20404 solver.cpp:397]     Test net output #1: loss = 0.252356 (* 1 = 0.252356 loss)
I1211 21:18:01.843468 20404 solver.cpp:218] Iteration 114500 (10.2886 iter/s, 9.7195s/100 iters), loss = 0.0206072
I1211 21:18:01.843468 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:01.843468 20404 solver.cpp:237]     Train net output #1: loss = 0.0206075 (* 1 = 0.0206075 loss)
I1211 21:18:01.843468 20404 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1211 21:18:09.781847 20404 solver.cpp:218] Iteration 114600 (12.5984 iter/s, 7.93754s/100 iters), loss = 0.0336019
I1211 21:18:09.781847 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:09.781847 20404 solver.cpp:237]     Train net output #1: loss = 0.0336022 (* 1 = 0.0336022 loss)
I1211 21:18:09.781847 20404 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1211 21:18:17.727732 20404 solver.cpp:218] Iteration 114700 (12.5864 iter/s, 7.94511s/100 iters), loss = 0.0156173
I1211 21:18:17.727732 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:17.727732 20404 solver.cpp:237]     Train net output #1: loss = 0.0156176 (* 1 = 0.0156176 loss)
I1211 21:18:17.727732 20404 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1211 21:18:25.664324 20404 solver.cpp:218] Iteration 114800 (12.6006 iter/s, 7.93611s/100 iters), loss = 0.0145174
I1211 21:18:25.664324 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:25.664324 20404 solver.cpp:237]     Train net output #1: loss = 0.0145176 (* 1 = 0.0145176 loss)
I1211 21:18:25.664324 20404 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1211 21:18:33.602401 20404 solver.cpp:218] Iteration 114900 (12.5984 iter/s, 7.93752s/100 iters), loss = 0.0146257
I1211 21:18:33.602401 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:33.602401 20404 solver.cpp:237]     Train net output #1: loss = 0.014626 (* 1 = 0.014626 loss)
I1211 21:18:33.602401 20404 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1211 21:18:41.156347  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:18:41.472874 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.caffemodel
I1211 21:18:41.499378 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.solverstate
I1211 21:18:41.506378 20404 solver.cpp:330] Iteration 115000, Testing net (#0)
I1211 21:18:41.506378 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:18:43.176386  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:18:43.242388 20404 solver.cpp:397]     Test net output #0: accuracy = 0.932
I1211 21:18:43.242388 20404 solver.cpp:397]     Test net output #1: loss = 0.253449 (* 1 = 0.253449 loss)
I1211 21:18:43.316396 20404 solver.cpp:218] Iteration 115000 (10.2945 iter/s, 9.71395s/100 iters), loss = 0.0162872
I1211 21:18:43.316396 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:43.316396 20404 solver.cpp:237]     Train net output #1: loss = 0.0162874 (* 1 = 0.0162874 loss)
I1211 21:18:43.316396 20404 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1211 21:18:51.262320 20404 solver.cpp:218] Iteration 115100 (12.5871 iter/s, 7.94465s/100 iters), loss = 0.0129921
I1211 21:18:51.262320 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:51.262320 20404 solver.cpp:237]     Train net output #1: loss = 0.0129923 (* 1 = 0.0129923 loss)
I1211 21:18:51.262320 20404 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1211 21:18:59.203292 20404 solver.cpp:218] Iteration 115200 (12.5935 iter/s, 7.94062s/100 iters), loss = 0.0143097
I1211 21:18:59.203292 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:18:59.203292 20404 solver.cpp:237]     Train net output #1: loss = 0.01431 (* 1 = 0.01431 loss)
I1211 21:18:59.203292 20404 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1211 21:19:07.141165 20404 solver.cpp:218] Iteration 115300 (12.5978 iter/s, 7.93792s/100 iters), loss = 0.0160713
I1211 21:19:07.141165 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:19:07.141165 20404 solver.cpp:237]     Train net output #1: loss = 0.0160716 (* 1 = 0.0160716 loss)
I1211 21:19:07.141165 20404 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1211 21:19:15.082317 20404 solver.cpp:218] Iteration 115400 (12.5941 iter/s, 7.94024s/100 iters), loss = 0.0364497
I1211 21:19:15.082317 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:19:15.082317 20404 solver.cpp:237]     Train net output #1: loss = 0.0364499 (* 1 = 0.0364499 loss)
I1211 21:19:15.082317 20404 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1211 21:19:22.629257  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:19:22.941289 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.caffemodel
I1211 21:19:22.969291 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.solverstate
I1211 21:19:22.975292 20404 solver.cpp:330] Iteration 115500, Testing net (#0)
I1211 21:19:22.975792 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:19:24.645403  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:19:24.711406 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9318
I1211 21:19:24.711406 20404 solver.cpp:397]     Test net output #1: loss = 0.254915 (* 1 = 0.254915 loss)
I1211 21:19:24.785909 20404 solver.cpp:218] Iteration 115500 (10.3065 iter/s, 9.70263s/100 iters), loss = 0.0178372
I1211 21:19:24.785909 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:19:24.785909 20404 solver.cpp:237]     Train net output #1: loss = 0.0178374 (* 1 = 0.0178374 loss)
I1211 21:19:24.785909 20404 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1211 21:19:32.720144 20404 solver.cpp:218] Iteration 115600 (12.6031 iter/s, 7.93457s/100 iters), loss = 0.0341734
I1211 21:19:32.720144 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:19:32.720144 20404 solver.cpp:237]     Train net output #1: loss = 0.0341737 (* 1 = 0.0341737 loss)
I1211 21:19:32.721127 20404 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1211 21:19:40.662691 20404 solver.cpp:218] Iteration 115700 (12.5921 iter/s, 7.94148s/100 iters), loss = 0.0244684
I1211 21:19:40.662691 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:19:40.662691 20404 solver.cpp:237]     Train net output #1: loss = 0.0244687 (* 1 = 0.0244687 loss)
I1211 21:19:40.662691 20404 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1211 21:19:48.602864 20404 solver.cpp:218] Iteration 115800 (12.5949 iter/s, 7.93974s/100 iters), loss = 0.0103988
I1211 21:19:48.602864 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:19:48.602864 20404 solver.cpp:237]     Train net output #1: loss = 0.010399 (* 1 = 0.010399 loss)
I1211 21:19:48.602864 20404 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1211 21:19:56.546952 20404 solver.cpp:218] Iteration 115900 (12.5881 iter/s, 7.94402s/100 iters), loss = 0.0134889
I1211 21:19:56.546952 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:19:56.546952 20404 solver.cpp:237]     Train net output #1: loss = 0.0134891 (* 1 = 0.0134891 loss)
I1211 21:19:56.546952 20404 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1211 21:20:04.133584  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:20:04.447615 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.caffemodel
I1211 21:20:04.476615 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.solverstate
I1211 21:20:04.482616 20404 solver.cpp:330] Iteration 116000, Testing net (#0)
I1211 21:20:04.482616 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:20:06.153776  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:20:06.221282 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9315
I1211 21:20:06.221282 20404 solver.cpp:397]     Test net output #1: loss = 0.253796 (* 1 = 0.253796 loss)
I1211 21:20:06.294780 20404 solver.cpp:218] Iteration 116000 (10.2593 iter/s, 9.74721s/100 iters), loss = 0.0223342
I1211 21:20:06.294780 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:06.294780 20404 solver.cpp:237]     Train net output #1: loss = 0.0223344 (* 1 = 0.0223344 loss)
I1211 21:20:06.294780 20404 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1211 21:20:14.242568 20404 solver.cpp:218] Iteration 116100 (12.5825 iter/s, 7.94755s/100 iters), loss = 0.0213295
I1211 21:20:14.242568 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:14.242568 20404 solver.cpp:237]     Train net output #1: loss = 0.0213298 (* 1 = 0.0213298 loss)
I1211 21:20:14.242568 20404 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1211 21:20:22.191345 20404 solver.cpp:218] Iteration 116200 (12.582 iter/s, 7.94788s/100 iters), loss = 0.0224775
I1211 21:20:22.191345 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:22.191345 20404 solver.cpp:237]     Train net output #1: loss = 0.0224777 (* 1 = 0.0224777 loss)
I1211 21:20:22.191345 20404 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1211 21:20:30.131813 20404 solver.cpp:218] Iteration 116300 (12.5953 iter/s, 7.93949s/100 iters), loss = 0.0107134
I1211 21:20:30.131813 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:30.131813 20404 solver.cpp:237]     Train net output #1: loss = 0.0107136 (* 1 = 0.0107136 loss)
I1211 21:20:30.131813 20404 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1211 21:20:38.076428 20404 solver.cpp:218] Iteration 116400 (12.587 iter/s, 7.94471s/100 iters), loss = 0.0131012
I1211 21:20:38.076428 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:38.076428 20404 solver.cpp:237]     Train net output #1: loss = 0.0131015 (* 1 = 0.0131015 loss)
I1211 21:20:38.076428 20404 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1211 21:20:45.632210  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:20:45.945260 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.caffemodel
I1211 21:20:45.973259 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.solverstate
I1211 21:20:45.979261 20404 solver.cpp:330] Iteration 116500, Testing net (#0)
I1211 21:20:45.979261 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:20:47.650245  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:20:47.716243 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1211 21:20:47.716243 20404 solver.cpp:397]     Test net output #1: loss = 0.253461 (* 1 = 0.253461 loss)
I1211 21:20:47.791254 20404 solver.cpp:218] Iteration 116500 (10.2943 iter/s, 9.71414s/100 iters), loss = 0.0170824
I1211 21:20:47.791254 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:47.791254 20404 solver.cpp:237]     Train net output #1: loss = 0.0170827 (* 1 = 0.0170827 loss)
I1211 21:20:47.791254 20404 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1211 21:20:55.739138 20404 solver.cpp:218] Iteration 116600 (12.5829 iter/s, 7.94732s/100 iters), loss = 0.0150739
I1211 21:20:55.739138 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:20:55.739138 20404 solver.cpp:237]     Train net output #1: loss = 0.0150742 (* 1 = 0.0150742 loss)
I1211 21:20:55.739138 20404 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1211 21:21:03.680690 20404 solver.cpp:218] Iteration 116700 (12.5926 iter/s, 7.94117s/100 iters), loss = 0.0244593
I1211 21:21:03.680690 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:21:03.680690 20404 solver.cpp:237]     Train net output #1: loss = 0.0244595 (* 1 = 0.0244595 loss)
I1211 21:21:03.680690 20404 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1211 21:21:11.617748 20404 solver.cpp:218] Iteration 116800 (12.6004 iter/s, 7.93624s/100 iters), loss = 0.0145739
I1211 21:21:11.617748 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:21:11.617748 20404 solver.cpp:237]     Train net output #1: loss = 0.0145742 (* 1 = 0.0145742 loss)
I1211 21:21:11.617748 20404 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1211 21:21:19.549777 20404 solver.cpp:218] Iteration 116900 (12.6065 iter/s, 7.93244s/100 iters), loss = 0.0231626
I1211 21:21:19.550776 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:21:19.550776 20404 solver.cpp:237]     Train net output #1: loss = 0.0231628 (* 1 = 0.0231628 loss)
I1211 21:21:19.550776 20404 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1211 21:21:27.109747  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:21:27.424821 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.caffemodel
I1211 21:21:27.458374 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.solverstate
I1211 21:21:27.463369 20404 solver.cpp:330] Iteration 117000, Testing net (#0)
I1211 21:21:27.464354 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:21:29.138221  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:21:29.205220 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9311
I1211 21:21:29.205220 20404 solver.cpp:397]     Test net output #1: loss = 0.257633 (* 1 = 0.257633 loss)
I1211 21:21:29.279721 20404 solver.cpp:218] Iteration 117000 (10.279 iter/s, 9.72861s/100 iters), loss = 0.0181453
I1211 21:21:29.279721 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:21:29.279721 20404 solver.cpp:237]     Train net output #1: loss = 0.0181455 (* 1 = 0.0181455 loss)
I1211 21:21:29.279721 20404 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1211 21:21:37.223629 20404 solver.cpp:218] Iteration 117100 (12.5889 iter/s, 7.94352s/100 iters), loss = 0.0311476
I1211 21:21:37.223629 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:21:37.223629 20404 solver.cpp:237]     Train net output #1: loss = 0.0311478 (* 1 = 0.0311478 loss)
I1211 21:21:37.223629 20404 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1211 21:21:45.189441 20404 solver.cpp:218] Iteration 117200 (12.5547 iter/s, 7.96517s/100 iters), loss = 0.0151187
I1211 21:21:45.189441 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:21:45.189441 20404 solver.cpp:237]     Train net output #1: loss = 0.015119 (* 1 = 0.015119 loss)
I1211 21:21:45.189441 20404 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1211 21:21:53.128427 20404 solver.cpp:218] Iteration 117300 (12.596 iter/s, 7.939s/100 iters), loss = 0.0204927
I1211 21:21:53.128427 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:21:53.128427 20404 solver.cpp:237]     Train net output #1: loss = 0.020493 (* 1 = 0.020493 loss)
I1211 21:21:53.128427 20404 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1211 21:22:01.070487 20404 solver.cpp:218] Iteration 117400 (12.5931 iter/s, 7.94085s/100 iters), loss = 0.0181296
I1211 21:22:01.070487 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:01.070487 20404 solver.cpp:237]     Train net output #1: loss = 0.0181298 (* 1 = 0.0181298 loss)
I1211 21:22:01.070487 20404 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1211 21:22:08.633286  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:22:08.946321 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.caffemodel
I1211 21:22:08.973830 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.solverstate
I1211 21:22:08.979846 20404 solver.cpp:330] Iteration 117500, Testing net (#0)
I1211 21:22:08.979846 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:22:10.651479  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:22:10.717484 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9306
I1211 21:22:10.717484 20404 solver.cpp:397]     Test net output #1: loss = 0.257158 (* 1 = 0.257158 loss)
I1211 21:22:10.793488 20404 solver.cpp:218] Iteration 117500 (10.2855 iter/s, 9.72243s/100 iters), loss = 0.0202975
I1211 21:22:10.793488 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:10.793488 20404 solver.cpp:237]     Train net output #1: loss = 0.0202978 (* 1 = 0.0202978 loss)
I1211 21:22:10.793488 20404 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1211 21:22:18.739910 20404 solver.cpp:218] Iteration 117600 (12.5852 iter/s, 7.94583s/100 iters), loss = 0.00911472
I1211 21:22:18.739910 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:18.739910 20404 solver.cpp:237]     Train net output #1: loss = 0.00911499 (* 1 = 0.00911499 loss)
I1211 21:22:18.739910 20404 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1211 21:22:26.682967 20404 solver.cpp:218] Iteration 117700 (12.5908 iter/s, 7.94232s/100 iters), loss = 0.0214859
I1211 21:22:26.682967 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:26.682967 20404 solver.cpp:237]     Train net output #1: loss = 0.0214862 (* 1 = 0.0214862 loss)
I1211 21:22:26.682967 20404 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1211 21:22:34.620766 20404 solver.cpp:218] Iteration 117800 (12.5988 iter/s, 7.93728s/100 iters), loss = 0.0138538
I1211 21:22:34.620766 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:34.620766 20404 solver.cpp:237]     Train net output #1: loss = 0.013854 (* 1 = 0.013854 loss)
I1211 21:22:34.620766 20404 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1211 21:22:42.557569 20404 solver.cpp:218] Iteration 117900 (12.5998 iter/s, 7.93665s/100 iters), loss = 0.014682
I1211 21:22:42.557569 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:42.557569 20404 solver.cpp:237]     Train net output #1: loss = 0.0146823 (* 1 = 0.0146823 loss)
I1211 21:22:42.557569 20404 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1211 21:22:50.113288  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:22:50.428361 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.caffemodel
I1211 21:22:50.462353 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.solverstate
I1211 21:22:50.467353 20404 solver.cpp:330] Iteration 118000, Testing net (#0)
I1211 21:22:50.467353 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:22:52.137737  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:22:52.203743 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9302
I1211 21:22:52.203743 20404 solver.cpp:397]     Test net output #1: loss = 0.258973 (* 1 = 0.258973 loss)
I1211 21:22:52.278743 20404 solver.cpp:218] Iteration 118000 (10.2875 iter/s, 9.72056s/100 iters), loss = 0.0152165
I1211 21:22:52.278743 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:22:52.278743 20404 solver.cpp:237]     Train net output #1: loss = 0.0152167 (* 1 = 0.0152167 loss)
I1211 21:22:52.278743 20404 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1211 21:23:00.224654 20404 solver.cpp:218] Iteration 118100 (12.5854 iter/s, 7.94571s/100 iters), loss = 0.0146672
I1211 21:23:00.224654 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:00.224654 20404 solver.cpp:237]     Train net output #1: loss = 0.0146675 (* 1 = 0.0146675 loss)
I1211 21:23:00.224654 20404 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1211 21:23:08.161650 20404 solver.cpp:218] Iteration 118200 (12.5993 iter/s, 7.93695s/100 iters), loss = 0.0217392
I1211 21:23:08.162649 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:08.162649 20404 solver.cpp:237]     Train net output #1: loss = 0.0217394 (* 1 = 0.0217394 loss)
I1211 21:23:08.162649 20404 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1211 21:23:16.101248 20404 solver.cpp:218] Iteration 118300 (12.5967 iter/s, 7.93859s/100 iters), loss = 0.0167432
I1211 21:23:16.101248 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:16.101248 20404 solver.cpp:237]     Train net output #1: loss = 0.0167435 (* 1 = 0.0167435 loss)
I1211 21:23:16.101248 20404 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1211 21:23:24.052783 20404 solver.cpp:218] Iteration 118400 (12.5776 iter/s, 7.95066s/100 iters), loss = 0.0155608
I1211 21:23:24.052783 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:24.052783 20404 solver.cpp:237]     Train net output #1: loss = 0.0155611 (* 1 = 0.0155611 loss)
I1211 21:23:24.052783 20404 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1211 21:23:31.612187  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:23:31.926224 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.caffemodel
I1211 21:23:31.954224 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.solverstate
I1211 21:23:31.960227 20404 solver.cpp:330] Iteration 118500, Testing net (#0)
I1211 21:23:31.960227 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:23:33.633625  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:23:33.700143 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9315
I1211 21:23:33.700655 20404 solver.cpp:397]     Test net output #1: loss = 0.258912 (* 1 = 0.258912 loss)
I1211 21:23:33.774646 20404 solver.cpp:218] Iteration 118500 (10.2866 iter/s, 9.72141s/100 iters), loss = 0.021268
I1211 21:23:33.774646 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:33.774646 20404 solver.cpp:237]     Train net output #1: loss = 0.0212683 (* 1 = 0.0212683 loss)
I1211 21:23:33.774646 20404 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1211 21:23:41.721629 20404 solver.cpp:218] Iteration 118600 (12.5838 iter/s, 7.94674s/100 iters), loss = 0.0149539
I1211 21:23:41.721629 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:41.721629 20404 solver.cpp:237]     Train net output #1: loss = 0.0149541 (* 1 = 0.0149541 loss)
I1211 21:23:41.721629 20404 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1211 21:23:49.665292 20404 solver.cpp:218] Iteration 118700 (12.59 iter/s, 7.94284s/100 iters), loss = 0.0234518
I1211 21:23:49.665292 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:49.665292 20404 solver.cpp:237]     Train net output #1: loss = 0.0234521 (* 1 = 0.0234521 loss)
I1211 21:23:49.665292 20404 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1211 21:23:57.613610 20404 solver.cpp:218] Iteration 118800 (12.5819 iter/s, 7.94792s/100 iters), loss = 0.0113727
I1211 21:23:57.613610 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:23:57.613610 20404 solver.cpp:237]     Train net output #1: loss = 0.011373 (* 1 = 0.011373 loss)
I1211 21:23:57.613610 20404 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1211 21:24:05.560935 20404 solver.cpp:218] Iteration 118900 (12.5834 iter/s, 7.94696s/100 iters), loss = 0.0163731
I1211 21:24:05.560935 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:24:05.560935 20404 solver.cpp:237]     Train net output #1: loss = 0.0163734 (* 1 = 0.0163734 loss)
I1211 21:24:05.560935 20404 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1211 21:24:13.117205  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:24:13.431744 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.caffemodel
I1211 21:24:13.459745 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.solverstate
I1211 21:24:13.464746 20404 solver.cpp:330] Iteration 119000, Testing net (#0)
I1211 21:24:13.464746 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:24:15.134865  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:24:15.201864 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1211 21:24:15.201864 20404 solver.cpp:397]     Test net output #1: loss = 0.258998 (* 1 = 0.258998 loss)
I1211 21:24:15.275874 20404 solver.cpp:218] Iteration 119000 (10.2943 iter/s, 9.71407s/100 iters), loss = 0.0246922
I1211 21:24:15.275874 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:24:15.275874 20404 solver.cpp:237]     Train net output #1: loss = 0.0246924 (* 1 = 0.0246924 loss)
I1211 21:24:15.275874 20404 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1211 21:24:23.207705 20404 solver.cpp:218] Iteration 119100 (12.6087 iter/s, 7.93103s/100 iters), loss = 0.0215603
I1211 21:24:23.207705 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:24:23.207705 20404 solver.cpp:237]     Train net output #1: loss = 0.0215606 (* 1 = 0.0215606 loss)
I1211 21:24:23.207705 20404 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1211 21:24:31.147902 20404 solver.cpp:218] Iteration 119200 (12.5944 iter/s, 7.94005s/100 iters), loss = 0.0229598
I1211 21:24:31.147902 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:24:31.147902 20404 solver.cpp:237]     Train net output #1: loss = 0.0229601 (* 1 = 0.0229601 loss)
I1211 21:24:31.147902 20404 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1211 21:24:39.094769 20404 solver.cpp:218] Iteration 119300 (12.5849 iter/s, 7.946s/100 iters), loss = 0.0145384
I1211 21:24:39.094769 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:24:39.094769 20404 solver.cpp:237]     Train net output #1: loss = 0.0145386 (* 1 = 0.0145386 loss)
I1211 21:24:39.094769 20404 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1211 21:24:47.040514 20404 solver.cpp:218] Iteration 119400 (12.5851 iter/s, 7.94588s/100 iters), loss = 0.0147319
I1211 21:24:47.040514 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:24:47.040514 20404 solver.cpp:237]     Train net output #1: loss = 0.0147322 (* 1 = 0.0147322 loss)
I1211 21:24:47.040514 20404 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1211 21:24:54.599310  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:24:54.913374 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.caffemodel
I1211 21:24:54.945919 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.solverstate
I1211 21:24:54.951920 20404 solver.cpp:330] Iteration 119500, Testing net (#0)
I1211 21:24:54.951920 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:24:56.623440  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:24:56.689944 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9313
I1211 21:24:56.689944 20404 solver.cpp:397]     Test net output #1: loss = 0.256807 (* 1 = 0.256807 loss)
I1211 21:24:56.763965 20404 solver.cpp:218] Iteration 119500 (10.2854 iter/s, 9.72254s/100 iters), loss = 0.0161359
I1211 21:24:56.763965 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:24:56.763965 20404 solver.cpp:237]     Train net output #1: loss = 0.0161361 (* 1 = 0.0161361 loss)
I1211 21:24:56.763965 20404 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1211 21:25:04.704872 20404 solver.cpp:218] Iteration 119600 (12.5944 iter/s, 7.94006s/100 iters), loss = 0.0244736
I1211 21:25:04.704872 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:04.704872 20404 solver.cpp:237]     Train net output #1: loss = 0.0244738 (* 1 = 0.0244738 loss)
I1211 21:25:04.704872 20404 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1211 21:25:12.633837 20404 solver.cpp:218] Iteration 119700 (12.6122 iter/s, 7.92881s/100 iters), loss = 0.0268306
I1211 21:25:12.633837 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:12.633837 20404 solver.cpp:237]     Train net output #1: loss = 0.0268308 (* 1 = 0.0268308 loss)
I1211 21:25:12.633837 20404 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1211 21:25:20.569221 20404 solver.cpp:218] Iteration 119800 (12.6026 iter/s, 7.93488s/100 iters), loss = 0.0112389
I1211 21:25:20.569221 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:20.569221 20404 solver.cpp:237]     Train net output #1: loss = 0.0112392 (* 1 = 0.0112392 loss)
I1211 21:25:20.569221 20404 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1211 21:25:28.516297 20404 solver.cpp:218] Iteration 119900 (12.5842 iter/s, 7.94649s/100 iters), loss = 0.0235301
I1211 21:25:28.516297 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:28.516297 20404 solver.cpp:237]     Train net output #1: loss = 0.0235303 (* 1 = 0.0235303 loss)
I1211 21:25:28.516297 20404 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1211 21:25:36.059314  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:25:36.372472 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.caffemodel
I1211 21:25:36.399468 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.solverstate
I1211 21:25:36.405467 20404 solver.cpp:330] Iteration 120000, Testing net (#0)
I1211 21:25:36.405467 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:25:38.077302  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:25:38.143805 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1211 21:25:38.144304 20404 solver.cpp:397]     Test net output #1: loss = 0.255703 (* 1 = 0.255703 loss)
I1211 21:25:38.219020 20404 solver.cpp:218] Iteration 120000 (10.307 iter/s, 9.7021s/100 iters), loss = 0.0260459
I1211 21:25:38.219020 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:38.219020 20404 solver.cpp:237]     Train net output #1: loss = 0.0260461 (* 1 = 0.0260461 loss)
I1211 21:25:38.219020 20404 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1211 21:25:46.169306 20404 solver.cpp:218] Iteration 120100 (12.5783 iter/s, 7.95021s/100 iters), loss = 0.0253437
I1211 21:25:46.169306 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:46.169306 20404 solver.cpp:237]     Train net output #1: loss = 0.025344 (* 1 = 0.025344 loss)
I1211 21:25:46.169306 20404 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1211 21:25:54.116127 20404 solver.cpp:218] Iteration 120200 (12.5842 iter/s, 7.94646s/100 iters), loss = 0.0136846
I1211 21:25:54.116127 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:25:54.116127 20404 solver.cpp:237]     Train net output #1: loss = 0.0136849 (* 1 = 0.0136849 loss)
I1211 21:25:54.116127 20404 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1211 21:26:02.064038 20404 solver.cpp:218] Iteration 120300 (12.5827 iter/s, 7.94741s/100 iters), loss = 0.0193259
I1211 21:26:02.064038 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:02.064038 20404 solver.cpp:237]     Train net output #1: loss = 0.0193262 (* 1 = 0.0193262 loss)
I1211 21:26:02.064038 20404 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1211 21:26:10.007876 20404 solver.cpp:218] Iteration 120400 (12.5898 iter/s, 7.94293s/100 iters), loss = 0.0116431
I1211 21:26:10.007876 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:10.007876 20404 solver.cpp:237]     Train net output #1: loss = 0.0116434 (* 1 = 0.0116434 loss)
I1211 21:26:10.007876 20404 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1211 21:26:17.562780  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:26:17.876796 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.caffemodel
I1211 21:26:17.904796 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.solverstate
I1211 21:26:17.911798 20404 solver.cpp:330] Iteration 120500, Testing net (#0)
I1211 21:26:17.911798 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:26:19.583963  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:26:19.650967 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1211 21:26:19.650967 20404 solver.cpp:397]     Test net output #1: loss = 0.254069 (* 1 = 0.254069 loss)
I1211 21:26:19.724977 20404 solver.cpp:218] Iteration 120500 (10.2913 iter/s, 9.71692s/100 iters), loss = 0.0211266
I1211 21:26:19.724977 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:19.724977 20404 solver.cpp:237]     Train net output #1: loss = 0.0211269 (* 1 = 0.0211269 loss)
I1211 21:26:19.724977 20404 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1211 21:26:27.714663 20404 solver.cpp:218] Iteration 120600 (12.5177 iter/s, 7.98868s/100 iters), loss = 0.0220862
I1211 21:26:27.714663 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:27.714663 20404 solver.cpp:237]     Train net output #1: loss = 0.0220864 (* 1 = 0.0220864 loss)
I1211 21:26:27.714663 20404 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1211 21:26:35.666533 20404 solver.cpp:218] Iteration 120700 (12.5765 iter/s, 7.95135s/100 iters), loss = 0.0165654
I1211 21:26:35.666533 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:35.666533 20404 solver.cpp:237]     Train net output #1: loss = 0.0165656 (* 1 = 0.0165656 loss)
I1211 21:26:35.666533 20404 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1211 21:26:43.608470 20404 solver.cpp:218] Iteration 120800 (12.5912 iter/s, 7.94204s/100 iters), loss = 0.013687
I1211 21:26:43.608470 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:43.608470 20404 solver.cpp:237]     Train net output #1: loss = 0.0136872 (* 1 = 0.0136872 loss)
I1211 21:26:43.608470 20404 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1211 21:26:51.552336 20404 solver.cpp:218] Iteration 120900 (12.5899 iter/s, 7.94287s/100 iters), loss = 0.0150909
I1211 21:26:51.552336 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:26:51.552336 20404 solver.cpp:237]     Train net output #1: loss = 0.0150911 (* 1 = 0.0150911 loss)
I1211 21:26:51.552336 20404 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1211 21:26:59.103027  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:26:59.417060 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.caffemodel
I1211 21:26:59.448062 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.solverstate
I1211 21:26:59.454062 20404 solver.cpp:330] Iteration 121000, Testing net (#0)
I1211 21:26:59.454062 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:27:01.126004  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:27:01.193011 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1211 21:27:01.193011 20404 solver.cpp:397]     Test net output #1: loss = 0.254156 (* 1 = 0.254156 loss)
I1211 21:27:01.268010 20404 solver.cpp:218] Iteration 121000 (10.2928 iter/s, 9.71554s/100 iters), loss = 0.0142174
I1211 21:27:01.268010 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:01.268010 20404 solver.cpp:237]     Train net output #1: loss = 0.0142177 (* 1 = 0.0142177 loss)
I1211 21:27:01.268010 20404 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1211 21:27:09.215934 20404 solver.cpp:218] Iteration 121100 (12.5835 iter/s, 7.9469s/100 iters), loss = 0.0594691
I1211 21:27:09.215934 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 21:27:09.215934 20404 solver.cpp:237]     Train net output #1: loss = 0.0594693 (* 1 = 0.0594693 loss)
I1211 21:27:09.215934 20404 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1211 21:27:17.143519 20404 solver.cpp:218] Iteration 121200 (12.6138 iter/s, 7.92783s/100 iters), loss = 0.0179776
I1211 21:27:17.143519 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:17.143519 20404 solver.cpp:237]     Train net output #1: loss = 0.0179778 (* 1 = 0.0179778 loss)
I1211 21:27:17.143519 20404 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1211 21:27:25.074113 20404 solver.cpp:218] Iteration 121300 (12.611 iter/s, 7.92959s/100 iters), loss = 0.0120557
I1211 21:27:25.074113 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:25.074113 20404 solver.cpp:237]     Train net output #1: loss = 0.0120559 (* 1 = 0.0120559 loss)
I1211 21:27:25.074113 20404 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1211 21:27:33.006986 20404 solver.cpp:218] Iteration 121400 (12.6068 iter/s, 7.93225s/100 iters), loss = 0.0230227
I1211 21:27:33.006986 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:33.006986 20404 solver.cpp:237]     Train net output #1: loss = 0.0230229 (* 1 = 0.0230229 loss)
I1211 21:27:33.006986 20404 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1211 21:27:40.553165  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:27:40.867236 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.caffemodel
I1211 21:27:40.895745 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.solverstate
I1211 21:27:40.901247 20404 solver.cpp:330] Iteration 121500, Testing net (#0)
I1211 21:27:40.902251 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:27:42.570370  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:27:42.636376 20404 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 21:27:42.636376 20404 solver.cpp:397]     Test net output #1: loss = 0.253955 (* 1 = 0.253955 loss)
I1211 21:27:42.711381 20404 solver.cpp:218] Iteration 121500 (10.3051 iter/s, 9.70393s/100 iters), loss = 0.0130986
I1211 21:27:42.711381 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:42.711381 20404 solver.cpp:237]     Train net output #1: loss = 0.0130989 (* 1 = 0.0130989 loss)
I1211 21:27:42.711381 20404 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1211 21:27:50.644889 20404 solver.cpp:218] Iteration 121600 (12.6042 iter/s, 7.93386s/100 iters), loss = 0.0147228
I1211 21:27:50.645897 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:50.645897 20404 solver.cpp:237]     Train net output #1: loss = 0.0147231 (* 1 = 0.0147231 loss)
I1211 21:27:50.645897 20404 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1211 21:27:58.587568 20404 solver.cpp:218] Iteration 121700 (12.5917 iter/s, 7.94175s/100 iters), loss = 0.0163115
I1211 21:27:58.587568 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:27:58.587568 20404 solver.cpp:237]     Train net output #1: loss = 0.0163117 (* 1 = 0.0163117 loss)
I1211 21:27:58.587568 20404 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1211 21:28:06.516621 20404 solver.cpp:218] Iteration 121800 (12.6123 iter/s, 7.92877s/100 iters), loss = 0.0125955
I1211 21:28:06.516621 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:28:06.516621 20404 solver.cpp:237]     Train net output #1: loss = 0.0125958 (* 1 = 0.0125958 loss)
I1211 21:28:06.516621 20404 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1211 21:28:14.452126 20404 solver.cpp:218] Iteration 121900 (12.602 iter/s, 7.93522s/100 iters), loss = 0.0144362
I1211 21:28:14.453127 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:28:14.453127 20404 solver.cpp:237]     Train net output #1: loss = 0.0144365 (* 1 = 0.0144365 loss)
I1211 21:28:14.453127 20404 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1211 21:28:22.008056  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:28:22.322125 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.caffemodel
I1211 21:28:22.350124 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.solverstate
I1211 21:28:22.356138 20404 solver.cpp:330] Iteration 122000, Testing net (#0)
I1211 21:28:22.356138 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:28:24.026932  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:28:24.092933 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1211 21:28:24.092933 20404 solver.cpp:397]     Test net output #1: loss = 0.258929 (* 1 = 0.258929 loss)
I1211 21:28:24.167490 20404 solver.cpp:218] Iteration 122000 (10.2942 iter/s, 9.71423s/100 iters), loss = 0.0158953
I1211 21:28:24.167490 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:28:24.167490 20404 solver.cpp:237]     Train net output #1: loss = 0.0158956 (* 1 = 0.0158956 loss)
I1211 21:28:24.167490 20404 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1211 21:28:32.113574 20404 solver.cpp:218] Iteration 122100 (12.5857 iter/s, 7.9455s/100 iters), loss = 0.0141501
I1211 21:28:32.113574 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:28:32.113574 20404 solver.cpp:237]     Train net output #1: loss = 0.0141504 (* 1 = 0.0141504 loss)
I1211 21:28:32.113574 20404 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1211 21:28:40.049554 20404 solver.cpp:218] Iteration 122200 (12.6009 iter/s, 7.93591s/100 iters), loss = 0.024411
I1211 21:28:40.049554 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:28:40.049554 20404 solver.cpp:237]     Train net output #1: loss = 0.0244112 (* 1 = 0.0244112 loss)
I1211 21:28:40.049554 20404 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1211 21:28:47.985152 20404 solver.cpp:218] Iteration 122300 (12.6025 iter/s, 7.9349s/100 iters), loss = 0.0251471
I1211 21:28:47.985152 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:28:47.985152 20404 solver.cpp:237]     Train net output #1: loss = 0.0251474 (* 1 = 0.0251474 loss)
I1211 21:28:47.985152 20404 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1211 21:28:55.920408 20404 solver.cpp:218] Iteration 122400 (12.6029 iter/s, 7.9347s/100 iters), loss = 0.0129019
I1211 21:28:55.920408 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:28:55.920408 20404 solver.cpp:237]     Train net output #1: loss = 0.0129021 (* 1 = 0.0129021 loss)
I1211 21:28:55.920408 20404 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1211 21:29:03.467126  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:29:03.781152 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.caffemodel
I1211 21:29:03.808172 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.solverstate
I1211 21:29:03.813169 20404 solver.cpp:330] Iteration 122500, Testing net (#0)
I1211 21:29:03.814164 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:29:05.485298  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:29:05.552305 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1211 21:29:05.552305 20404 solver.cpp:397]     Test net output #1: loss = 0.257251 (* 1 = 0.257251 loss)
I1211 21:29:05.626307 20404 solver.cpp:218] Iteration 122500 (10.3036 iter/s, 9.70535s/100 iters), loss = 0.023806
I1211 21:29:05.626307 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:29:05.626307 20404 solver.cpp:237]     Train net output #1: loss = 0.0238063 (* 1 = 0.0238063 loss)
I1211 21:29:05.626307 20404 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1211 21:29:13.563204 20404 solver.cpp:218] Iteration 122600 (12.6008 iter/s, 7.936s/100 iters), loss = 0.0292267
I1211 21:29:13.563204 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:29:13.563204 20404 solver.cpp:237]     Train net output #1: loss = 0.029227 (* 1 = 0.029227 loss)
I1211 21:29:13.563204 20404 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1211 21:29:21.508085 20404 solver.cpp:218] Iteration 122700 (12.5863 iter/s, 7.94516s/100 iters), loss = 0.0209971
I1211 21:29:21.508085 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:29:21.508085 20404 solver.cpp:237]     Train net output #1: loss = 0.0209974 (* 1 = 0.0209974 loss)
I1211 21:29:21.508085 20404 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1211 21:29:29.450860 20404 solver.cpp:218] Iteration 122800 (12.5915 iter/s, 7.94187s/100 iters), loss = 0.0110433
I1211 21:29:29.450860 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:29:29.450860 20404 solver.cpp:237]     Train net output #1: loss = 0.0110436 (* 1 = 0.0110436 loss)
I1211 21:29:29.450860 20404 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1211 21:29:37.394642 20404 solver.cpp:218] Iteration 122900 (12.5892 iter/s, 7.9433s/100 iters), loss = 0.016348
I1211 21:29:37.394642 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:29:37.394642 20404 solver.cpp:237]     Train net output #1: loss = 0.0163483 (* 1 = 0.0163483 loss)
I1211 21:29:37.394642 20404 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1211 21:29:44.954489  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:29:45.269507 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.caffemodel
I1211 21:29:45.298508 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.solverstate
I1211 21:29:45.304509 20404 solver.cpp:330] Iteration 123000, Testing net (#0)
I1211 21:29:45.304509 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:29:46.973930  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:29:47.040932 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1211 21:29:47.040932 20404 solver.cpp:397]     Test net output #1: loss = 0.255178 (* 1 = 0.255178 loss)
I1211 21:29:47.114936 20404 solver.cpp:218] Iteration 123000 (10.2886 iter/s, 9.71953s/100 iters), loss = 0.0273132
I1211 21:29:47.114936 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:29:47.114936 20404 solver.cpp:237]     Train net output #1: loss = 0.0273134 (* 1 = 0.0273134 loss)
I1211 21:29:47.114936 20404 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1211 21:29:55.056735 20404 solver.cpp:218] Iteration 123100 (12.5922 iter/s, 7.94144s/100 iters), loss = 0.0231644
I1211 21:29:55.056735 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:29:55.056735 20404 solver.cpp:237]     Train net output #1: loss = 0.0231647 (* 1 = 0.0231647 loss)
I1211 21:29:55.056735 20404 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1211 21:30:03.031018 20404 solver.cpp:218] Iteration 123200 (12.541 iter/s, 7.97383s/100 iters), loss = 0.0172087
I1211 21:30:03.031018 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:30:03.031018 20404 solver.cpp:237]     Train net output #1: loss = 0.017209 (* 1 = 0.017209 loss)
I1211 21:30:03.031018 20404 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1211 21:30:10.975082 20404 solver.cpp:218] Iteration 123300 (12.5899 iter/s, 7.94286s/100 iters), loss = 0.0120174
I1211 21:30:10.975082 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:30:10.975082 20404 solver.cpp:237]     Train net output #1: loss = 0.0120177 (* 1 = 0.0120177 loss)
I1211 21:30:10.975082 20404 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1211 21:30:18.978024 20404 solver.cpp:218] Iteration 123400 (12.4958 iter/s, 8.00266s/100 iters), loss = 0.0130743
I1211 21:30:18.978024 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:30:18.978024 20404 solver.cpp:237]     Train net output #1: loss = 0.0130745 (* 1 = 0.0130745 loss)
I1211 21:30:18.978024 20404 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1211 21:30:26.521929  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:30:26.834951 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.caffemodel
I1211 21:30:26.861966 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.solverstate
I1211 21:30:26.868952 20404 solver.cpp:330] Iteration 123500, Testing net (#0)
I1211 21:30:26.868952 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:30:28.536211  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:30:28.603214 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1211 21:30:28.603214 20404 solver.cpp:397]     Test net output #1: loss = 0.255869 (* 1 = 0.255869 loss)
I1211 21:30:28.676216 20404 solver.cpp:218] Iteration 123500 (10.311 iter/s, 9.69838s/100 iters), loss = 0.0313985
I1211 21:30:28.677217 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:30:28.677217 20404 solver.cpp:237]     Train net output #1: loss = 0.0313988 (* 1 = 0.0313988 loss)
I1211 21:30:28.677217 20404 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1211 21:30:36.595508 20404 solver.cpp:218] Iteration 123600 (12.6293 iter/s, 7.91808s/100 iters), loss = 0.0119991
I1211 21:30:36.595508 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:30:36.595508 20404 solver.cpp:237]     Train net output #1: loss = 0.0119994 (* 1 = 0.0119994 loss)
I1211 21:30:36.595508 20404 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1211 21:30:44.515940 20404 solver.cpp:218] Iteration 123700 (12.6259 iter/s, 7.9202s/100 iters), loss = 0.016704
I1211 21:30:44.516443 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:30:44.516443 20404 solver.cpp:237]     Train net output #1: loss = 0.0167043 (* 1 = 0.0167043 loss)
I1211 21:30:44.516443 20404 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1211 21:30:52.441818 20404 solver.cpp:218] Iteration 123800 (12.6176 iter/s, 7.92546s/100 iters), loss = 0.0156763
I1211 21:30:52.441818 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:30:52.441818 20404 solver.cpp:237]     Train net output #1: loss = 0.0156765 (* 1 = 0.0156765 loss)
I1211 21:30:52.441818 20404 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1211 21:31:00.369653 20404 solver.cpp:218] Iteration 123900 (12.6142 iter/s, 7.92757s/100 iters), loss = 0.012631
I1211 21:31:00.369653 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:00.370654 20404 solver.cpp:237]     Train net output #1: loss = 0.0126312 (* 1 = 0.0126312 loss)
I1211 21:31:00.370654 20404 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1211 21:31:07.906412  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:31:08.219946 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.caffemodel
I1211 21:31:08.250453 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.solverstate
I1211 21:31:08.256451 20404 solver.cpp:330] Iteration 124000, Testing net (#0)
I1211 21:31:08.256451 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:31:09.923631  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:31:09.990658 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1211 21:31:09.990658 20404 solver.cpp:397]     Test net output #1: loss = 0.259744 (* 1 = 0.259744 loss)
I1211 21:31:10.064106 20404 solver.cpp:218] Iteration 124000 (10.3162 iter/s, 9.6935s/100 iters), loss = 0.0164993
I1211 21:31:10.064106 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:10.064106 20404 solver.cpp:237]     Train net output #1: loss = 0.0164996 (* 1 = 0.0164996 loss)
I1211 21:31:10.064106 20404 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1211 21:31:17.975131 20404 solver.cpp:218] Iteration 124100 (12.6409 iter/s, 7.91083s/100 iters), loss = 0.0311567
I1211 21:31:17.975131 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:31:17.975131 20404 solver.cpp:237]     Train net output #1: loss = 0.031157 (* 1 = 0.031157 loss)
I1211 21:31:17.975131 20404 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1211 21:31:25.901237 20404 solver.cpp:218] Iteration 124200 (12.6173 iter/s, 7.92561s/100 iters), loss = 0.0168852
I1211 21:31:25.901237 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:25.901237 20404 solver.cpp:237]     Train net output #1: loss = 0.0168855 (* 1 = 0.0168855 loss)
I1211 21:31:25.901237 20404 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1211 21:31:33.828215 20404 solver.cpp:218] Iteration 124300 (12.6168 iter/s, 7.92593s/100 iters), loss = 0.00907083
I1211 21:31:33.828215 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:33.828215 20404 solver.cpp:237]     Train net output #1: loss = 0.00907109 (* 1 = 0.00907109 loss)
I1211 21:31:33.828215 20404 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1211 21:31:41.753597 20404 solver.cpp:218] Iteration 124400 (12.6177 iter/s, 7.92536s/100 iters), loss = 0.0123338
I1211 21:31:41.753597 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:41.753597 20404 solver.cpp:237]     Train net output #1: loss = 0.012334 (* 1 = 0.012334 loss)
I1211 21:31:41.753597 20404 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1211 21:31:49.286653  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:31:49.598673 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.caffemodel
I1211 21:31:49.628176 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.solverstate
I1211 21:31:49.634176 20404 solver.cpp:330] Iteration 124500, Testing net (#0)
I1211 21:31:49.634176 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:31:51.301367  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:31:51.367374 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1211 21:31:51.367374 20404 solver.cpp:397]     Test net output #1: loss = 0.262713 (* 1 = 0.262713 loss)
I1211 21:31:51.441876 20404 solver.cpp:218] Iteration 124500 (10.3229 iter/s, 9.68719s/100 iters), loss = 0.0148668
I1211 21:31:51.441876 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:51.441876 20404 solver.cpp:237]     Train net output #1: loss = 0.0148671 (* 1 = 0.0148671 loss)
I1211 21:31:51.441876 20404 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1211 21:31:59.377300 20404 solver.cpp:218] Iteration 124600 (12.6022 iter/s, 7.93511s/100 iters), loss = 0.0145989
I1211 21:31:59.377300 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:31:59.377300 20404 solver.cpp:237]     Train net output #1: loss = 0.0145992 (* 1 = 0.0145992 loss)
I1211 21:31:59.377300 20404 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1211 21:32:07.317188 20404 solver.cpp:218] Iteration 124700 (12.5953 iter/s, 7.93945s/100 iters), loss = 0.0117035
I1211 21:32:07.317188 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:07.317188 20404 solver.cpp:237]     Train net output #1: loss = 0.0117038 (* 1 = 0.0117038 loss)
I1211 21:32:07.317188 20404 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1211 21:32:15.257155 20404 solver.cpp:218] Iteration 124800 (12.5955 iter/s, 7.93934s/100 iters), loss = 0.0186931
I1211 21:32:15.257155 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:15.257155 20404 solver.cpp:237]     Train net output #1: loss = 0.0186934 (* 1 = 0.0186934 loss)
I1211 21:32:15.257155 20404 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1211 21:32:23.190062 20404 solver.cpp:218] Iteration 124900 (12.6057 iter/s, 7.93291s/100 iters), loss = 0.0156872
I1211 21:32:23.190062 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:23.190062 20404 solver.cpp:237]     Train net output #1: loss = 0.0156875 (* 1 = 0.0156875 loss)
I1211 21:32:23.190062 20404 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1211 21:32:30.733922  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:32:31.045940 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.caffemodel
I1211 21:32:31.072943 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.solverstate
I1211 21:32:31.078943 20404 solver.cpp:330] Iteration 125000, Testing net (#0)
I1211 21:32:31.079946 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:32:32.746376  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:32:32.812392 20404 solver.cpp:397]     Test net output #0: accuracy = 0.931
I1211 21:32:32.812392 20404 solver.cpp:397]     Test net output #1: loss = 0.260382 (* 1 = 0.260382 loss)
I1211 21:32:32.886412 20404 solver.cpp:218] Iteration 125000 (10.3143 iter/s, 9.69529s/100 iters), loss = 0.012728
I1211 21:32:32.886412 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:32.886412 20404 solver.cpp:237]     Train net output #1: loss = 0.0127283 (* 1 = 0.0127283 loss)
I1211 21:32:32.886412 20404 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1211 21:32:40.815363 20404 solver.cpp:218] Iteration 125100 (12.6128 iter/s, 7.92844s/100 iters), loss = 0.019869
I1211 21:32:40.815363 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:40.815363 20404 solver.cpp:237]     Train net output #1: loss = 0.0198693 (* 1 = 0.0198693 loss)
I1211 21:32:40.815363 20404 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1211 21:32:48.742128 20404 solver.cpp:218] Iteration 125200 (12.6162 iter/s, 7.92629s/100 iters), loss = 0.0138218
I1211 21:32:48.742128 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:48.742128 20404 solver.cpp:237]     Train net output #1: loss = 0.0138221 (* 1 = 0.0138221 loss)
I1211 21:32:48.742128 20404 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1211 21:32:56.677001 20404 solver.cpp:218] Iteration 125300 (12.6034 iter/s, 7.93438s/100 iters), loss = 0.010734
I1211 21:32:56.677001 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:32:56.677001 20404 solver.cpp:237]     Train net output #1: loss = 0.0107343 (* 1 = 0.0107343 loss)
I1211 21:32:56.677001 20404 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1211 21:33:04.604831 20404 solver.cpp:218] Iteration 125400 (12.6139 iter/s, 7.92774s/100 iters), loss = 0.0117804
I1211 21:33:04.604831 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:04.604831 20404 solver.cpp:237]     Train net output #1: loss = 0.0117807 (* 1 = 0.0117807 loss)
I1211 21:33:04.604831 20404 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1211 21:33:12.143498  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:33:12.456765 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.caffemodel
I1211 21:33:12.485853 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.solverstate
I1211 21:33:12.490867 20404 solver.cpp:330] Iteration 125500, Testing net (#0)
I1211 21:33:12.490867 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:33:14.159286  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:33:14.224779 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9315
I1211 21:33:14.224779 20404 solver.cpp:397]     Test net output #1: loss = 0.259709 (* 1 = 0.259709 loss)
I1211 21:33:14.299789 20404 solver.cpp:218] Iteration 125500 (10.3158 iter/s, 9.69385s/100 iters), loss = 0.0118642
I1211 21:33:14.299789 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:14.299789 20404 solver.cpp:237]     Train net output #1: loss = 0.0118645 (* 1 = 0.0118645 loss)
I1211 21:33:14.299789 20404 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1211 21:33:22.226917 20404 solver.cpp:218] Iteration 125600 (12.6143 iter/s, 7.9275s/100 iters), loss = 0.0119741
I1211 21:33:22.226917 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:22.226917 20404 solver.cpp:237]     Train net output #1: loss = 0.0119743 (* 1 = 0.0119743 loss)
I1211 21:33:22.226917 20404 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1211 21:33:30.155742 20404 solver.cpp:218] Iteration 125700 (12.6141 iter/s, 7.92762s/100 iters), loss = 0.0211328
I1211 21:33:30.155742 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:30.155742 20404 solver.cpp:237]     Train net output #1: loss = 0.0211331 (* 1 = 0.0211331 loss)
I1211 21:33:30.155742 20404 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1211 21:33:38.084990 20404 solver.cpp:218] Iteration 125800 (12.6126 iter/s, 7.92856s/100 iters), loss = 0.0153948
I1211 21:33:38.084990 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:38.084990 20404 solver.cpp:237]     Train net output #1: loss = 0.015395 (* 1 = 0.015395 loss)
I1211 21:33:38.084990 20404 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1211 21:33:46.006191 20404 solver.cpp:218] Iteration 125900 (12.6242 iter/s, 7.92131s/100 iters), loss = 0.0176059
I1211 21:33:46.006191 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:46.006191 20404 solver.cpp:237]     Train net output #1: loss = 0.0176061 (* 1 = 0.0176061 loss)
I1211 21:33:46.006191 20404 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1211 21:33:53.537590  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:33:53.853624 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.caffemodel
I1211 21:33:53.880632 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.solverstate
I1211 21:33:53.886632 20404 solver.cpp:330] Iteration 126000, Testing net (#0)
I1211 21:33:53.887634 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:33:55.552877  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:33:55.617882 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1211 21:33:55.617882 20404 solver.cpp:397]     Test net output #1: loss = 0.259268 (* 1 = 0.259268 loss)
I1211 21:33:55.692905 20404 solver.cpp:218] Iteration 126000 (10.3245 iter/s, 9.68567s/100 iters), loss = 0.0130358
I1211 21:33:55.692905 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:33:55.692905 20404 solver.cpp:237]     Train net output #1: loss = 0.013036 (* 1 = 0.013036 loss)
I1211 21:33:55.692905 20404 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1211 21:34:03.620754 20404 solver.cpp:218] Iteration 126100 (12.6146 iter/s, 7.92733s/100 iters), loss = 0.0104169
I1211 21:34:03.620754 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:03.620754 20404 solver.cpp:237]     Train net output #1: loss = 0.0104171 (* 1 = 0.0104171 loss)
I1211 21:34:03.620754 20404 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1211 21:34:11.552122 20404 solver.cpp:218] Iteration 126200 (12.6088 iter/s, 7.93098s/100 iters), loss = 0.0115911
I1211 21:34:11.552122 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:11.552122 20404 solver.cpp:237]     Train net output #1: loss = 0.0115914 (* 1 = 0.0115914 loss)
I1211 21:34:11.552122 20404 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1211 21:34:19.484149 20404 solver.cpp:218] Iteration 126300 (12.6068 iter/s, 7.93225s/100 iters), loss = 0.011585
I1211 21:34:19.484149 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:19.484149 20404 solver.cpp:237]     Train net output #1: loss = 0.0115853 (* 1 = 0.0115853 loss)
I1211 21:34:19.484149 20404 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1211 21:34:27.407723 20404 solver.cpp:218] Iteration 126400 (12.6221 iter/s, 7.92259s/100 iters), loss = 0.0151894
I1211 21:34:27.407723 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:27.407723 20404 solver.cpp:237]     Train net output #1: loss = 0.0151897 (* 1 = 0.0151897 loss)
I1211 21:34:27.407723 20404 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1211 21:34:34.947098  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:34:35.260130 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.caffemodel
I1211 21:34:35.292687 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.solverstate
I1211 21:34:35.298688 20404 solver.cpp:330] Iteration 126500, Testing net (#0)
I1211 21:34:35.298688 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:34:36.966982  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:34:37.033485 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1211 21:34:37.033485 20404 solver.cpp:397]     Test net output #1: loss = 0.260743 (* 1 = 0.260743 loss)
I1211 21:34:37.107497 20404 solver.cpp:218] Iteration 126500 (10.3099 iter/s, 9.69942s/100 iters), loss = 0.0139096
I1211 21:34:37.107497 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:37.107497 20404 solver.cpp:237]     Train net output #1: loss = 0.0139099 (* 1 = 0.0139099 loss)
I1211 21:34:37.107497 20404 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1211 21:34:45.029943 20404 solver.cpp:218] Iteration 126600 (12.6238 iter/s, 7.92155s/100 iters), loss = 0.0111495
I1211 21:34:45.029943 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:45.029943 20404 solver.cpp:237]     Train net output #1: loss = 0.0111497 (* 1 = 0.0111497 loss)
I1211 21:34:45.029943 20404 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1211 21:34:52.960516 20404 solver.cpp:218] Iteration 126700 (12.6102 iter/s, 7.93011s/100 iters), loss = 0.0145225
I1211 21:34:52.960516 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:34:52.960516 20404 solver.cpp:237]     Train net output #1: loss = 0.0145228 (* 1 = 0.0145228 loss)
I1211 21:34:52.960516 20404 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1211 21:35:00.881239 20404 solver.cpp:218] Iteration 126800 (12.6245 iter/s, 7.92112s/100 iters), loss = 0.016829
I1211 21:35:00.882241 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:00.882241 20404 solver.cpp:237]     Train net output #1: loss = 0.0168293 (* 1 = 0.0168293 loss)
I1211 21:35:00.882241 20404 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1211 21:35:08.803870 20404 solver.cpp:218] Iteration 126900 (12.623 iter/s, 7.92206s/100 iters), loss = 0.0126669
I1211 21:35:08.803870 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:08.803870 20404 solver.cpp:237]     Train net output #1: loss = 0.0126672 (* 1 = 0.0126672 loss)
I1211 21:35:08.803870 20404 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1211 21:35:16.346000  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:35:16.660084 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.caffemodel
I1211 21:35:16.687086 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.solverstate
I1211 21:35:16.693087 20404 solver.cpp:330] Iteration 127000, Testing net (#0)
I1211 21:35:16.693087 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:35:18.360785  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:35:18.427286 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 21:35:18.427286 20404 solver.cpp:397]     Test net output #1: loss = 0.259695 (* 1 = 0.259695 loss)
I1211 21:35:18.502295 20404 solver.cpp:218] Iteration 127000 (10.3124 iter/s, 9.69708s/100 iters), loss = 0.0162269
I1211 21:35:18.502295 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:18.502295 20404 solver.cpp:237]     Train net output #1: loss = 0.0162271 (* 1 = 0.0162271 loss)
I1211 21:35:18.502295 20404 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1211 21:35:26.423959 20404 solver.cpp:218] Iteration 127100 (12.6238 iter/s, 7.92154s/100 iters), loss = 0.0102297
I1211 21:35:26.423959 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:26.423959 20404 solver.cpp:237]     Train net output #1: loss = 0.01023 (* 1 = 0.01023 loss)
I1211 21:35:26.423959 20404 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1211 21:35:34.353719 20404 solver.cpp:218] Iteration 127200 (12.6114 iter/s, 7.92934s/100 iters), loss = 0.0142762
I1211 21:35:34.353719 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:34.353719 20404 solver.cpp:237]     Train net output #1: loss = 0.0142764 (* 1 = 0.0142764 loss)
I1211 21:35:34.353719 20404 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1211 21:35:42.283555 20404 solver.cpp:218] Iteration 127300 (12.6113 iter/s, 7.92937s/100 iters), loss = 0.0153653
I1211 21:35:42.283555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:42.283555 20404 solver.cpp:237]     Train net output #1: loss = 0.0153655 (* 1 = 0.0153655 loss)
I1211 21:35:42.283555 20404 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1211 21:35:50.202679 20404 solver.cpp:218] Iteration 127400 (12.6287 iter/s, 7.91847s/100 iters), loss = 0.0134429
I1211 21:35:50.202679 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:50.202679 20404 solver.cpp:237]     Train net output #1: loss = 0.0134431 (* 1 = 0.0134431 loss)
I1211 21:35:50.202679 20404 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1211 21:35:57.736188  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:35:58.051254 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.caffemodel
I1211 21:35:58.078258 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.solverstate
I1211 21:35:58.084273 20404 solver.cpp:330] Iteration 127500, Testing net (#0)
I1211 21:35:58.084273 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:35:59.750484  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:35:59.816514 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9308
I1211 21:35:59.816514 20404 solver.cpp:397]     Test net output #1: loss = 0.260021 (* 1 = 0.260021 loss)
I1211 21:35:59.890522 20404 solver.cpp:218] Iteration 127500 (10.3227 iter/s, 9.68738s/100 iters), loss = 0.0126145
I1211 21:35:59.890522 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:35:59.890522 20404 solver.cpp:237]     Train net output #1: loss = 0.0126148 (* 1 = 0.0126148 loss)
I1211 21:35:59.890522 20404 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1211 21:36:07.810858 20404 solver.cpp:218] Iteration 127600 (12.6269 iter/s, 7.91963s/100 iters), loss = 0.027254
I1211 21:36:07.810858 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:36:07.810858 20404 solver.cpp:237]     Train net output #1: loss = 0.0272542 (* 1 = 0.0272542 loss)
I1211 21:36:07.810858 20404 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1211 21:36:15.738639 20404 solver.cpp:218] Iteration 127700 (12.6151 iter/s, 7.927s/100 iters), loss = 0.0104981
I1211 21:36:15.738639 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:36:15.738639 20404 solver.cpp:237]     Train net output #1: loss = 0.0104984 (* 1 = 0.0104984 loss)
I1211 21:36:15.738639 20404 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1211 21:36:23.672435 20404 solver.cpp:218] Iteration 127800 (12.6052 iter/s, 7.93321s/100 iters), loss = 0.0104967
I1211 21:36:23.672435 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:36:23.672435 20404 solver.cpp:237]     Train net output #1: loss = 0.0104969 (* 1 = 0.0104969 loss)
I1211 21:36:23.672435 20404 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1211 21:36:31.609359 20404 solver.cpp:218] Iteration 127900 (12.5993 iter/s, 7.93697s/100 iters), loss = 0.016529
I1211 21:36:31.609359 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:36:31.609359 20404 solver.cpp:237]     Train net output #1: loss = 0.0165293 (* 1 = 0.0165293 loss)
I1211 21:36:31.609359 20404 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1211 21:36:39.147465  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:36:39.461493 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.caffemodel
I1211 21:36:39.489502 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.solverstate
I1211 21:36:39.495502 20404 solver.cpp:330] Iteration 128000, Testing net (#0)
I1211 21:36:39.495502 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:36:41.163889  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:36:41.229894 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1211 21:36:41.229894 20404 solver.cpp:397]     Test net output #1: loss = 0.259722 (* 1 = 0.259722 loss)
I1211 21:36:41.303908 20404 solver.cpp:218] Iteration 128000 (10.3155 iter/s, 9.69417s/100 iters), loss = 0.0130195
I1211 21:36:41.303908 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:36:41.303908 20404 solver.cpp:237]     Train net output #1: loss = 0.0130197 (* 1 = 0.0130197 loss)
I1211 21:36:41.303908 20404 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1211 21:36:49.224702 20404 solver.cpp:218] Iteration 128100 (12.6258 iter/s, 7.9203s/100 iters), loss = 0.0154907
I1211 21:36:49.224702 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:36:49.224702 20404 solver.cpp:237]     Train net output #1: loss = 0.0154909 (* 1 = 0.0154909 loss)
I1211 21:36:49.224702 20404 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1211 21:36:57.147223 20404 solver.cpp:218] Iteration 128200 (12.6238 iter/s, 7.92154s/100 iters), loss = 0.0244856
I1211 21:36:57.147223 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:36:57.147223 20404 solver.cpp:237]     Train net output #1: loss = 0.0244859 (* 1 = 0.0244859 loss)
I1211 21:36:57.147223 20404 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1211 21:37:05.073005 20404 solver.cpp:218] Iteration 128300 (12.6168 iter/s, 7.92592s/100 iters), loss = 0.0163771
I1211 21:37:05.074007 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:37:05.074007 20404 solver.cpp:237]     Train net output #1: loss = 0.0163774 (* 1 = 0.0163774 loss)
I1211 21:37:05.074007 20404 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1211 21:37:13.004088 20404 solver.cpp:218] Iteration 128400 (12.6094 iter/s, 7.9306s/100 iters), loss = 0.0120329
I1211 21:37:13.005089 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:37:13.005089 20404 solver.cpp:237]     Train net output #1: loss = 0.0120332 (* 1 = 0.0120332 loss)
I1211 21:37:13.005089 20404 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1211 21:37:20.546578  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:37:20.860388 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.caffemodel
I1211 21:37:20.888402 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.solverstate
I1211 21:37:20.894389 20404 solver.cpp:330] Iteration 128500, Testing net (#0)
I1211 21:37:20.894389 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:37:22.559999  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:37:22.626015 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1211 21:37:22.626015 20404 solver.cpp:397]     Test net output #1: loss = 0.261303 (* 1 = 0.261303 loss)
I1211 21:37:22.700019 20404 solver.cpp:218] Iteration 128500 (10.315 iter/s, 9.69461s/100 iters), loss = 0.0139597
I1211 21:37:22.700019 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:37:22.700019 20404 solver.cpp:237]     Train net output #1: loss = 0.0139599 (* 1 = 0.0139599 loss)
I1211 21:37:22.700019 20404 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1211 21:37:30.643252 20404 solver.cpp:218] Iteration 128600 (12.5894 iter/s, 7.94316s/100 iters), loss = 0.0260964
I1211 21:37:30.643252 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:37:30.643252 20404 solver.cpp:237]     Train net output #1: loss = 0.0260967 (* 1 = 0.0260967 loss)
I1211 21:37:30.643252 20404 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1211 21:37:38.577553 20404 solver.cpp:218] Iteration 128700 (12.6044 iter/s, 7.93371s/100 iters), loss = 0.0109734
I1211 21:37:38.577553 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:37:38.577553 20404 solver.cpp:237]     Train net output #1: loss = 0.0109737 (* 1 = 0.0109737 loss)
I1211 21:37:38.577553 20404 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1211 21:37:46.504297 20404 solver.cpp:218] Iteration 128800 (12.6167 iter/s, 7.92602s/100 iters), loss = 0.0126633
I1211 21:37:46.504297 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:37:46.504297 20404 solver.cpp:237]     Train net output #1: loss = 0.0126635 (* 1 = 0.0126635 loss)
I1211 21:37:46.504297 20404 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1211 21:37:54.437108 20404 solver.cpp:218] Iteration 128900 (12.6064 iter/s, 7.93251s/100 iters), loss = 0.0116141
I1211 21:37:54.437108 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:37:54.437108 20404 solver.cpp:237]     Train net output #1: loss = 0.0116143 (* 1 = 0.0116143 loss)
I1211 21:37:54.437108 20404 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1211 21:38:01.979838  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:38:02.293901 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.caffemodel
I1211 21:38:02.322906 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.solverstate
I1211 21:38:02.328907 20404 solver.cpp:330] Iteration 129000, Testing net (#0)
I1211 21:38:02.328907 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:38:03.997428  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:38:04.063431 20404 solver.cpp:397]     Test net output #0: accuracy = 0.932
I1211 21:38:04.063431 20404 solver.cpp:397]     Test net output #1: loss = 0.260609 (* 1 = 0.260609 loss)
I1211 21:38:04.137439 20404 solver.cpp:218] Iteration 129000 (10.3101 iter/s, 9.69927s/100 iters), loss = 0.0146323
I1211 21:38:04.137439 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:04.137439 20404 solver.cpp:237]     Train net output #1: loss = 0.0146326 (* 1 = 0.0146326 loss)
I1211 21:38:04.137439 20404 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1211 21:38:12.063202 20404 solver.cpp:218] Iteration 129100 (12.6175 iter/s, 7.92549s/100 iters), loss = 0.0205194
I1211 21:38:12.063202 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:12.063202 20404 solver.cpp:237]     Train net output #1: loss = 0.0205197 (* 1 = 0.0205197 loss)
I1211 21:38:12.063202 20404 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1211 21:38:19.990967 20404 solver.cpp:218] Iteration 129200 (12.614 iter/s, 7.92772s/100 iters), loss = 0.0158955
I1211 21:38:19.990967 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:19.990967 20404 solver.cpp:237]     Train net output #1: loss = 0.0158957 (* 1 = 0.0158957 loss)
I1211 21:38:19.990967 20404 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1211 21:38:28.288677 20404 solver.cpp:218] Iteration 129300 (12.0533 iter/s, 8.29652s/100 iters), loss = 0.0124751
I1211 21:38:28.288677 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:28.288677 20404 solver.cpp:237]     Train net output #1: loss = 0.0124753 (* 1 = 0.0124753 loss)
I1211 21:38:28.288677 20404 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1211 21:38:36.275578 20404 solver.cpp:218] Iteration 129400 (12.5209 iter/s, 7.98663s/100 iters), loss = 0.0102041
I1211 21:38:36.275578 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:36.275578 20404 solver.cpp:237]     Train net output #1: loss = 0.0102043 (* 1 = 0.0102043 loss)
I1211 21:38:36.275578 20404 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1211 21:38:43.937602  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:38:44.253163 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.caffemodel
I1211 21:38:44.284178 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.solverstate
I1211 21:38:44.290172 20404 solver.cpp:330] Iteration 129500, Testing net (#0)
I1211 21:38:44.291172 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:38:45.971418  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:38:46.037914 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1211 21:38:46.037914 20404 solver.cpp:397]     Test net output #1: loss = 0.257493 (* 1 = 0.257493 loss)
I1211 21:38:46.111932 20404 solver.cpp:218] Iteration 129500 (10.1667 iter/s, 9.83605s/100 iters), loss = 0.0172773
I1211 21:38:46.111932 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:46.111932 20404 solver.cpp:237]     Train net output #1: loss = 0.0172776 (* 1 = 0.0172776 loss)
I1211 21:38:46.111932 20404 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1211 21:38:54.287801 20404 solver.cpp:218] Iteration 129600 (12.2324 iter/s, 8.17503s/100 iters), loss = 0.00981588
I1211 21:38:54.287801 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:38:54.287801 20404 solver.cpp:237]     Train net output #1: loss = 0.00981616 (* 1 = 0.00981616 loss)
I1211 21:38:54.287801 20404 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1211 21:39:02.511589 20404 solver.cpp:218] Iteration 129700 (12.1604 iter/s, 8.22342s/100 iters), loss = 0.0149371
I1211 21:39:02.512089 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:02.512089 20404 solver.cpp:237]     Train net output #1: loss = 0.0149373 (* 1 = 0.0149373 loss)
I1211 21:39:02.512089 20404 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1211 21:39:10.744334 20404 solver.cpp:218] Iteration 129800 (12.1476 iter/s, 8.23208s/100 iters), loss = 0.0146613
I1211 21:39:10.744334 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:10.744334 20404 solver.cpp:237]     Train net output #1: loss = 0.0146615 (* 1 = 0.0146615 loss)
I1211 21:39:10.744334 20404 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1211 21:39:18.954334 20404 solver.cpp:218] Iteration 129900 (12.1807 iter/s, 8.20971s/100 iters), loss = 0.00965176
I1211 21:39:18.954334 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:18.954334 20404 solver.cpp:237]     Train net output #1: loss = 0.00965203 (* 1 = 0.00965203 loss)
I1211 21:39:18.954334 20404 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1211 21:39:26.751600  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:39:27.066241 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.caffemodel
I1211 21:39:27.099242 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.solverstate
I1211 21:39:27.105255 20404 solver.cpp:330] Iteration 130000, Testing net (#0)
I1211 21:39:27.105255 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:39:28.807245  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:39:28.874750 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 21:39:28.874750 20404 solver.cpp:397]     Test net output #1: loss = 0.25645 (* 1 = 0.25645 loss)
I1211 21:39:28.949793 20404 solver.cpp:218] Iteration 130000 (10.0056 iter/s, 9.99444s/100 iters), loss = 0.0127876
I1211 21:39:28.949793 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:28.949793 20404 solver.cpp:237]     Train net output #1: loss = 0.0127878 (* 1 = 0.0127878 loss)
I1211 21:39:28.949793 20404 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1211 21:39:37.022053 20404 solver.cpp:218] Iteration 130100 (12.3893 iter/s, 8.07147s/100 iters), loss = 0.0118008
I1211 21:39:37.022053 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:37.022053 20404 solver.cpp:237]     Train net output #1: loss = 0.0118011 (* 1 = 0.0118011 loss)
I1211 21:39:37.022053 20404 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1211 21:39:45.048740 20404 solver.cpp:218] Iteration 130200 (12.4588 iter/s, 8.02644s/100 iters), loss = 0.0192959
I1211 21:39:45.048740 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:45.048740 20404 solver.cpp:237]     Train net output #1: loss = 0.0192961 (* 1 = 0.0192961 loss)
I1211 21:39:45.048740 20404 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1211 21:39:53.019353 20404 solver.cpp:218] Iteration 130300 (12.5463 iter/s, 7.97049s/100 iters), loss = 0.0117777
I1211 21:39:53.019353 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:39:53.019353 20404 solver.cpp:237]     Train net output #1: loss = 0.011778 (* 1 = 0.011778 loss)
I1211 21:39:53.019353 20404 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1211 21:40:01.044266 20404 solver.cpp:218] Iteration 130400 (12.462 iter/s, 8.02439s/100 iters), loss = 0.0143844
I1211 21:40:01.044266 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:01.044266 20404 solver.cpp:237]     Train net output #1: loss = 0.0143847 (* 1 = 0.0143847 loss)
I1211 21:40:01.044266 20404 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1211 21:40:08.613224  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:40:08.927520 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.caffemodel
I1211 21:40:08.957069 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.solverstate
I1211 21:40:08.962085 20404 solver.cpp:330] Iteration 130500, Testing net (#0)
I1211 21:40:08.962085 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:40:10.636757  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:40:10.702273 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 21:40:10.703274 20404 solver.cpp:397]     Test net output #1: loss = 0.257069 (* 1 = 0.257069 loss)
I1211 21:40:10.777302 20404 solver.cpp:218] Iteration 130500 (10.2751 iter/s, 9.73229s/100 iters), loss = 0.022634
I1211 21:40:10.777302 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:10.777302 20404 solver.cpp:237]     Train net output #1: loss = 0.0226343 (* 1 = 0.0226343 loss)
I1211 21:40:10.777302 20404 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1211 21:40:18.781158 20404 solver.cpp:218] Iteration 130600 (12.4941 iter/s, 8.00379s/100 iters), loss = 0.0152341
I1211 21:40:18.781158 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:18.781158 20404 solver.cpp:237]     Train net output #1: loss = 0.0152344 (* 1 = 0.0152344 loss)
I1211 21:40:18.781158 20404 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1211 21:40:26.810669 20404 solver.cpp:218] Iteration 130700 (12.4551 iter/s, 8.02885s/100 iters), loss = 0.0211716
I1211 21:40:26.810669 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:26.810669 20404 solver.cpp:237]     Train net output #1: loss = 0.0211719 (* 1 = 0.0211719 loss)
I1211 21:40:26.810669 20404 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1211 21:40:34.955664 20404 solver.cpp:218] Iteration 130800 (12.2788 iter/s, 8.1441s/100 iters), loss = 0.0107273
I1211 21:40:34.955664 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:34.955664 20404 solver.cpp:237]     Train net output #1: loss = 0.0107276 (* 1 = 0.0107276 loss)
I1211 21:40:34.956166 20404 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1211 21:40:43.198892 20404 solver.cpp:218] Iteration 130900 (12.1327 iter/s, 8.2422s/100 iters), loss = 0.0143658
I1211 21:40:43.198892 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:43.198892 20404 solver.cpp:237]     Train net output #1: loss = 0.0143661 (* 1 = 0.0143661 loss)
I1211 21:40:43.198892 20404 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1211 21:40:50.909857  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:40:51.227893 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.caffemodel
I1211 21:40:51.255899 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.solverstate
I1211 21:40:51.261898 20404 solver.cpp:330] Iteration 131000, Testing net (#0)
I1211 21:40:51.262398 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:40:52.943135  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:40:53.012142 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 21:40:53.012142 20404 solver.cpp:397]     Test net output #1: loss = 0.253813 (* 1 = 0.253813 loss)
I1211 21:40:53.089177 20404 solver.cpp:218] Iteration 131000 (10.111 iter/s, 9.89018s/100 iters), loss = 0.0144786
I1211 21:40:53.089177 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:40:53.089177 20404 solver.cpp:237]     Train net output #1: loss = 0.0144789 (* 1 = 0.0144789 loss)
I1211 21:40:53.089177 20404 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1211 21:41:01.191714 20404 solver.cpp:218] Iteration 131100 (12.3434 iter/s, 8.10151s/100 iters), loss = 0.0168161
I1211 21:41:01.191714 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:01.191714 20404 solver.cpp:237]     Train net output #1: loss = 0.0168164 (* 1 = 0.0168164 loss)
I1211 21:41:01.191714 20404 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1211 21:41:09.281385 20404 solver.cpp:218] Iteration 131200 (12.361 iter/s, 8.08993s/100 iters), loss = 0.019305
I1211 21:41:09.282384 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:09.282384 20404 solver.cpp:237]     Train net output #1: loss = 0.0193053 (* 1 = 0.0193053 loss)
I1211 21:41:09.282384 20404 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1211 21:41:17.413606 20404 solver.cpp:218] Iteration 131300 (12.2976 iter/s, 8.13165s/100 iters), loss = 0.0130549
I1211 21:41:17.414607 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:17.414607 20404 solver.cpp:237]     Train net output #1: loss = 0.0130552 (* 1 = 0.0130552 loss)
I1211 21:41:17.414607 20404 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1211 21:41:25.457532 20404 solver.cpp:218] Iteration 131400 (12.4328 iter/s, 8.04327s/100 iters), loss = 0.0180926
I1211 21:41:25.457532 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:25.457532 20404 solver.cpp:237]     Train net output #1: loss = 0.0180929 (* 1 = 0.0180929 loss)
I1211 21:41:25.457532 20404 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1211 21:41:33.021301  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:41:33.336088 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.caffemodel
I1211 21:41:33.369072 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.solverstate
I1211 21:41:33.375097 20404 solver.cpp:330] Iteration 131500, Testing net (#0)
I1211 21:41:33.375097 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:41:35.048804  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:41:35.115825 20404 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 21:41:35.115825 20404 solver.cpp:397]     Test net output #1: loss = 0.257088 (* 1 = 0.257088 loss)
I1211 21:41:35.189833 20404 solver.cpp:218] Iteration 131500 (10.2764 iter/s, 9.73099s/100 iters), loss = 0.0232664
I1211 21:41:35.189833 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:41:35.189833 20404 solver.cpp:237]     Train net output #1: loss = 0.0232667 (* 1 = 0.0232667 loss)
I1211 21:41:35.189833 20404 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1211 21:41:43.148793 20404 solver.cpp:218] Iteration 131600 (12.5646 iter/s, 7.95886s/100 iters), loss = 0.0143254
I1211 21:41:43.148793 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:43.148793 20404 solver.cpp:237]     Train net output #1: loss = 0.0143256 (* 1 = 0.0143256 loss)
I1211 21:41:43.148793 20404 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1211 21:41:51.151849 20404 solver.cpp:218] Iteration 131700 (12.4956 iter/s, 8.0028s/100 iters), loss = 0.0108092
I1211 21:41:51.151849 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:51.151849 20404 solver.cpp:237]     Train net output #1: loss = 0.0108095 (* 1 = 0.0108095 loss)
I1211 21:41:51.151849 20404 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1211 21:41:59.092684 20404 solver.cpp:218] Iteration 131800 (12.5949 iter/s, 7.93973s/100 iters), loss = 0.0139728
I1211 21:41:59.092684 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:41:59.092684 20404 solver.cpp:237]     Train net output #1: loss = 0.013973 (* 1 = 0.013973 loss)
I1211 21:41:59.092684 20404 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1211 21:42:07.043731 20404 solver.cpp:218] Iteration 131900 (12.5772 iter/s, 7.95087s/100 iters), loss = 0.0174825
I1211 21:42:07.043731 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:07.043731 20404 solver.cpp:237]     Train net output #1: loss = 0.0174827 (* 1 = 0.0174827 loss)
I1211 21:42:07.043731 20404 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1211 21:42:14.610414  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:42:14.926416 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.caffemodel
I1211 21:42:14.954414 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.solverstate
I1211 21:42:14.961417 20404 solver.cpp:330] Iteration 132000, Testing net (#0)
I1211 21:42:14.961417 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:42:16.638660  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:42:16.705165 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 21:42:16.705165 20404 solver.cpp:397]     Test net output #1: loss = 0.255629 (* 1 = 0.255629 loss)
I1211 21:42:16.779670 20404 solver.cpp:218] Iteration 132000 (10.2713 iter/s, 9.73582s/100 iters), loss = 0.0179479
I1211 21:42:16.779670 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:16.779670 20404 solver.cpp:237]     Train net output #1: loss = 0.0179482 (* 1 = 0.0179482 loss)
I1211 21:42:16.779670 20404 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1211 21:42:24.778450 20404 solver.cpp:218] Iteration 132100 (12.5029 iter/s, 7.99814s/100 iters), loss = 0.0131478
I1211 21:42:24.778450 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:24.778450 20404 solver.cpp:237]     Train net output #1: loss = 0.0131481 (* 1 = 0.0131481 loss)
I1211 21:42:24.778450 20404 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1211 21:42:32.735922 20404 solver.cpp:218] Iteration 132200 (12.5681 iter/s, 7.95663s/100 iters), loss = 0.0155159
I1211 21:42:32.735922 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:32.735922 20404 solver.cpp:237]     Train net output #1: loss = 0.0155162 (* 1 = 0.0155162 loss)
I1211 21:42:32.735922 20404 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1211 21:42:40.701887 20404 solver.cpp:218] Iteration 132300 (12.5545 iter/s, 7.96524s/100 iters), loss = 0.0094673
I1211 21:42:40.701887 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:40.701887 20404 solver.cpp:237]     Train net output #1: loss = 0.0094676 (* 1 = 0.0094676 loss)
I1211 21:42:40.701887 20404 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1211 21:42:48.699275 20404 solver.cpp:218] Iteration 132400 (12.5038 iter/s, 7.99757s/100 iters), loss = 0.0135939
I1211 21:42:48.700274 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:48.700274 20404 solver.cpp:237]     Train net output #1: loss = 0.0135941 (* 1 = 0.0135941 loss)
I1211 21:42:48.700274 20404 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1211 21:42:56.320564  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:42:56.633654 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.caffemodel
I1211 21:42:56.663655 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.solverstate
I1211 21:42:56.669654 20404 solver.cpp:330] Iteration 132500, Testing net (#0)
I1211 21:42:56.669654 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:42:58.338855  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:42:58.404867 20404 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 21:42:58.404867 20404 solver.cpp:397]     Test net output #1: loss = 0.253492 (* 1 = 0.253492 loss)
I1211 21:42:58.480861 20404 solver.cpp:218] Iteration 132500 (10.2247 iter/s, 9.78021s/100 iters), loss = 0.0231966
I1211 21:42:58.480861 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:42:58.480861 20404 solver.cpp:237]     Train net output #1: loss = 0.0231969 (* 1 = 0.0231969 loss)
I1211 21:42:58.480861 20404 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1211 21:43:06.521649 20404 solver.cpp:218] Iteration 132600 (12.4372 iter/s, 8.04037s/100 iters), loss = 0.0155244
I1211 21:43:06.521649 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:43:06.521649 20404 solver.cpp:237]     Train net output #1: loss = 0.0155247 (* 1 = 0.0155247 loss)
I1211 21:43:06.521649 20404 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1211 21:43:14.803697 20404 solver.cpp:218] Iteration 132700 (12.0746 iter/s, 8.28187s/100 iters), loss = 0.0231709
I1211 21:43:14.803697 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:43:14.803697 20404 solver.cpp:237]     Train net output #1: loss = 0.0231712 (* 1 = 0.0231712 loss)
I1211 21:43:14.803697 20404 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1211 21:43:23.060757 20404 solver.cpp:218] Iteration 132800 (12.1116 iter/s, 8.25653s/100 iters), loss = 0.0335923
I1211 21:43:23.060757 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:43:23.060757 20404 solver.cpp:237]     Train net output #1: loss = 0.0335926 (* 1 = 0.0335926 loss)
I1211 21:43:23.060757 20404 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1211 21:43:31.381973 20404 solver.cpp:218] Iteration 132900 (12.0181 iter/s, 8.3208s/100 iters), loss = 0.0142627
I1211 21:43:31.381973 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:43:31.381973 20404 solver.cpp:237]     Train net output #1: loss = 0.014263 (* 1 = 0.014263 loss)
I1211 21:43:31.381973 20404 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1211 21:43:39.003418  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:43:39.324461 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.caffemodel
I1211 21:43:39.355461 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.solverstate
I1211 21:43:39.361470 20404 solver.cpp:330] Iteration 133000, Testing net (#0)
I1211 21:43:39.361470 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:43:41.050612  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:43:41.116619 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1211 21:43:41.116619 20404 solver.cpp:397]     Test net output #1: loss = 0.261091 (* 1 = 0.261091 loss)
I1211 21:43:41.191622 20404 solver.cpp:218] Iteration 133000 (10.1955 iter/s, 9.80828s/100 iters), loss = 0.0139853
I1211 21:43:41.191622 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:43:41.191622 20404 solver.cpp:237]     Train net output #1: loss = 0.0139855 (* 1 = 0.0139855 loss)
I1211 21:43:41.191622 20404 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1211 21:43:49.205396 20404 solver.cpp:218] Iteration 133100 (12.4796 iter/s, 8.0131s/100 iters), loss = 0.0186301
I1211 21:43:49.205396 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:43:49.205396 20404 solver.cpp:237]     Train net output #1: loss = 0.0186304 (* 1 = 0.0186304 loss)
I1211 21:43:49.205396 20404 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1211 21:43:57.217433 20404 solver.cpp:218] Iteration 133200 (12.4813 iter/s, 8.01199s/100 iters), loss = 0.0112769
I1211 21:43:57.217433 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:43:57.217433 20404 solver.cpp:237]     Train net output #1: loss = 0.0112772 (* 1 = 0.0112772 loss)
I1211 21:43:57.217433 20404 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1211 21:44:05.230746 20404 solver.cpp:218] Iteration 133300 (12.4792 iter/s, 8.01333s/100 iters), loss = 0.0101762
I1211 21:44:05.231745 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:05.231745 20404 solver.cpp:237]     Train net output #1: loss = 0.0101765 (* 1 = 0.0101765 loss)
I1211 21:44:05.231745 20404 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1211 21:44:13.204824 20404 solver.cpp:218] Iteration 133400 (12.5426 iter/s, 7.97285s/100 iters), loss = 0.0196131
I1211 21:44:13.204824 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:13.204824 20404 solver.cpp:237]     Train net output #1: loss = 0.0196133 (* 1 = 0.0196133 loss)
I1211 21:44:13.204824 20404 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1211 21:44:20.819034  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:44:21.133352 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.caffemodel
I1211 21:44:21.161355 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.solverstate
I1211 21:44:21.167353 20404 solver.cpp:330] Iteration 133500, Testing net (#0)
I1211 21:44:21.167353 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:44:22.841061  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:44:22.907579 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 21:44:22.907579 20404 solver.cpp:397]     Test net output #1: loss = 0.255814 (* 1 = 0.255814 loss)
I1211 21:44:22.981678 20404 solver.cpp:218] Iteration 133500 (10.2283 iter/s, 9.77682s/100 iters), loss = 0.0178581
I1211 21:44:22.981678 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:22.981678 20404 solver.cpp:237]     Train net output #1: loss = 0.0178584 (* 1 = 0.0178584 loss)
I1211 21:44:22.981678 20404 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1211 21:44:30.946508 20404 solver.cpp:218] Iteration 133600 (12.5569 iter/s, 7.96372s/100 iters), loss = 0.0143932
I1211 21:44:30.946508 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:30.946508 20404 solver.cpp:237]     Train net output #1: loss = 0.0143935 (* 1 = 0.0143935 loss)
I1211 21:44:30.946508 20404 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1211 21:44:38.910768 20404 solver.cpp:218] Iteration 133700 (12.5565 iter/s, 7.96403s/100 iters), loss = 0.0125225
I1211 21:44:38.911262 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:38.911262 20404 solver.cpp:237]     Train net output #1: loss = 0.0125228 (* 1 = 0.0125228 loss)
I1211 21:44:38.911262 20404 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1211 21:44:46.870271 20404 solver.cpp:218] Iteration 133800 (12.5647 iter/s, 7.95878s/100 iters), loss = 0.0192685
I1211 21:44:46.870271 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:46.870271 20404 solver.cpp:237]     Train net output #1: loss = 0.0192688 (* 1 = 0.0192688 loss)
I1211 21:44:46.870271 20404 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1211 21:44:54.841971 20404 solver.cpp:218] Iteration 133900 (12.5449 iter/s, 7.97136s/100 iters), loss = 0.0151732
I1211 21:44:54.841971 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:44:54.841971 20404 solver.cpp:237]     Train net output #1: loss = 0.0151735 (* 1 = 0.0151735 loss)
I1211 21:44:54.841971 20404 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1211 21:45:02.419404  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:45:02.734974 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.caffemodel
I1211 21:45:02.768987 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.solverstate
I1211 21:45:02.774992 20404 solver.cpp:330] Iteration 134000, Testing net (#0)
I1211 21:45:02.774992 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:45:04.449126  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:45:04.515626 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1211 21:45:04.515626 20404 solver.cpp:397]     Test net output #1: loss = 0.254525 (* 1 = 0.254525 loss)
I1211 21:45:04.590129 20404 solver.cpp:218] Iteration 134000 (10.2589 iter/s, 9.74761s/100 iters), loss = 0.0127446
I1211 21:45:04.590129 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:04.590129 20404 solver.cpp:237]     Train net output #1: loss = 0.0127449 (* 1 = 0.0127449 loss)
I1211 21:45:04.590129 20404 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1211 21:45:12.549793 20404 solver.cpp:218] Iteration 134100 (12.5645 iter/s, 7.95891s/100 iters), loss = 0.0139524
I1211 21:45:12.549793 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:12.549793 20404 solver.cpp:237]     Train net output #1: loss = 0.0139527 (* 1 = 0.0139527 loss)
I1211 21:45:12.549793 20404 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1211 21:45:20.515923 20404 solver.cpp:218] Iteration 134200 (12.5531 iter/s, 7.96617s/100 iters), loss = 0.0104404
I1211 21:45:20.515923 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:20.515923 20404 solver.cpp:237]     Train net output #1: loss = 0.0104407 (* 1 = 0.0104407 loss)
I1211 21:45:20.515923 20404 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1211 21:45:28.483911 20404 solver.cpp:218] Iteration 134300 (12.5511 iter/s, 7.96745s/100 iters), loss = 0.013593
I1211 21:45:28.483911 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:28.483911 20404 solver.cpp:237]     Train net output #1: loss = 0.0135933 (* 1 = 0.0135933 loss)
I1211 21:45:28.483911 20404 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1211 21:45:36.455524 20404 solver.cpp:218] Iteration 134400 (12.5455 iter/s, 7.97101s/100 iters), loss = 0.0169794
I1211 21:45:36.455524 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:36.455524 20404 solver.cpp:237]     Train net output #1: loss = 0.0169797 (* 1 = 0.0169797 loss)
I1211 21:45:36.455524 20404 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1211 21:45:44.022717  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:45:44.337268 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.caffemodel
I1211 21:45:44.365772 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.solverstate
I1211 21:45:44.371773 20404 solver.cpp:330] Iteration 134500, Testing net (#0)
I1211 21:45:44.371773 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:45:46.045032  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:45:46.111030 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1211 21:45:46.111030 20404 solver.cpp:397]     Test net output #1: loss = 0.258609 (* 1 = 0.258609 loss)
I1211 21:45:46.186038 20404 solver.cpp:218] Iteration 134500 (10.278 iter/s, 9.72954s/100 iters), loss = 0.016322
I1211 21:45:46.186038 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:46.186038 20404 solver.cpp:237]     Train net output #1: loss = 0.0163223 (* 1 = 0.0163223 loss)
I1211 21:45:46.186038 20404 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1211 21:45:54.143901 20404 solver.cpp:218] Iteration 134600 (12.5663 iter/s, 7.95781s/100 iters), loss = 0.0281663
I1211 21:45:54.143901 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:45:54.143901 20404 solver.cpp:237]     Train net output #1: loss = 0.0281666 (* 1 = 0.0281666 loss)
I1211 21:45:54.143901 20404 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1211 21:46:02.105024 20404 solver.cpp:218] Iteration 134700 (12.5621 iter/s, 7.96045s/100 iters), loss = 0.0149882
I1211 21:46:02.105024 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:02.105024 20404 solver.cpp:237]     Train net output #1: loss = 0.0149885 (* 1 = 0.0149885 loss)
I1211 21:46:02.105024 20404 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1211 21:46:10.059389 20404 solver.cpp:218] Iteration 134800 (12.5719 iter/s, 7.95428s/100 iters), loss = 0.0137088
I1211 21:46:10.060394 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:10.060394 20404 solver.cpp:237]     Train net output #1: loss = 0.0137091 (* 1 = 0.0137091 loss)
I1211 21:46:10.060394 20404 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1211 21:46:18.017112 20404 solver.cpp:218] Iteration 134900 (12.5677 iter/s, 7.95692s/100 iters), loss = 0.0103325
I1211 21:46:18.017112 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:18.017112 20404 solver.cpp:237]     Train net output #1: loss = 0.0103328 (* 1 = 0.0103328 loss)
I1211 21:46:18.017112 20404 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1211 21:46:25.594611  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:46:25.909654 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.caffemodel
I1211 21:46:25.939158 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.solverstate
I1211 21:46:25.944658 20404 solver.cpp:330] Iteration 135000, Testing net (#0)
I1211 21:46:25.945158 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:46:27.621800  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:46:27.687805 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 21:46:27.687805 20404 solver.cpp:397]     Test net output #1: loss = 0.258844 (* 1 = 0.258844 loss)
I1211 21:46:27.762812 20404 solver.cpp:218] Iteration 135000 (10.2614 iter/s, 9.74521s/100 iters), loss = 0.0123803
I1211 21:46:27.762812 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:27.762812 20404 solver.cpp:237]     Train net output #1: loss = 0.0123806 (* 1 = 0.0123806 loss)
I1211 21:46:27.762812 20404 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1211 21:46:35.728976 20404 solver.cpp:218] Iteration 135100 (12.5542 iter/s, 7.96544s/100 iters), loss = 0.0145403
I1211 21:46:35.728976 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:35.728976 20404 solver.cpp:237]     Train net output #1: loss = 0.0145406 (* 1 = 0.0145406 loss)
I1211 21:46:35.728976 20404 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1211 21:46:43.693394 20404 solver.cpp:218] Iteration 135200 (12.5571 iter/s, 7.96363s/100 iters), loss = 0.0150297
I1211 21:46:43.693394 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:43.693394 20404 solver.cpp:237]     Train net output #1: loss = 0.01503 (* 1 = 0.01503 loss)
I1211 21:46:43.693394 20404 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1211 21:46:51.664021 20404 solver.cpp:218] Iteration 135300 (12.5462 iter/s, 7.97055s/100 iters), loss = 0.0227645
I1211 21:46:51.664021 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:46:51.664021 20404 solver.cpp:237]     Train net output #1: loss = 0.0227648 (* 1 = 0.0227648 loss)
I1211 21:46:51.664021 20404 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1211 21:46:59.643820 20404 solver.cpp:218] Iteration 135400 (12.533 iter/s, 7.97894s/100 iters), loss = 0.0163779
I1211 21:46:59.643820 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:46:59.643820 20404 solver.cpp:237]     Train net output #1: loss = 0.0163782 (* 1 = 0.0163782 loss)
I1211 21:46:59.643820 20404 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1211 21:47:07.229698  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:47:07.545734 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.caffemodel
I1211 21:47:07.573750 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.solverstate
I1211 21:47:07.579748 20404 solver.cpp:330] Iteration 135500, Testing net (#0)
I1211 21:47:07.579748 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:47:09.254380  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:47:09.320883 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 21:47:09.320883 20404 solver.cpp:397]     Test net output #1: loss = 0.252856 (* 1 = 0.252856 loss)
I1211 21:47:09.394888 20404 solver.cpp:218] Iteration 135500 (10.2557 iter/s, 9.75066s/100 iters), loss = 0.0165947
I1211 21:47:09.394888 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:47:09.394888 20404 solver.cpp:237]     Train net output #1: loss = 0.016595 (* 1 = 0.016595 loss)
I1211 21:47:09.394888 20404 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1211 21:47:17.361470 20404 solver.cpp:218] Iteration 135600 (12.5543 iter/s, 7.9654s/100 iters), loss = 0.00997941
I1211 21:47:17.361470 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:47:17.361470 20404 solver.cpp:237]     Train net output #1: loss = 0.0099797 (* 1 = 0.0099797 loss)
I1211 21:47:17.361470 20404 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1211 21:47:25.326959 20404 solver.cpp:218] Iteration 135700 (12.5547 iter/s, 7.96514s/100 iters), loss = 0.0416873
I1211 21:47:25.326959 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 21:47:25.326959 20404 solver.cpp:237]     Train net output #1: loss = 0.0416876 (* 1 = 0.0416876 loss)
I1211 21:47:25.326959 20404 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1211 21:47:33.294811 20404 solver.cpp:218] Iteration 135800 (12.55 iter/s, 7.9681s/100 iters), loss = 0.0126977
I1211 21:47:33.294811 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:47:33.294811 20404 solver.cpp:237]     Train net output #1: loss = 0.012698 (* 1 = 0.012698 loss)
I1211 21:47:33.295811 20404 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1211 21:47:41.251224 20404 solver.cpp:218] Iteration 135900 (12.5702 iter/s, 7.95532s/100 iters), loss = 0.0134078
I1211 21:47:41.251224 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:47:41.251224 20404 solver.cpp:237]     Train net output #1: loss = 0.0134081 (* 1 = 0.0134081 loss)
I1211 21:47:41.251224 20404 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1211 21:47:48.823984  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:47:49.139690 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.caffemodel
I1211 21:47:49.178197 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.solverstate
I1211 21:47:49.184212 20404 solver.cpp:330] Iteration 136000, Testing net (#0)
I1211 21:47:49.184212 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:47:50.859153  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:47:50.925173 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9313
I1211 21:47:50.925173 20404 solver.cpp:397]     Test net output #1: loss = 0.264912 (* 1 = 0.264912 loss)
I1211 21:47:50.999204 20404 solver.cpp:218] Iteration 136000 (10.2593 iter/s, 9.74722s/100 iters), loss = 0.0198004
I1211 21:47:50.999204 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:47:50.999204 20404 solver.cpp:237]     Train net output #1: loss = 0.0198007 (* 1 = 0.0198007 loss)
I1211 21:47:50.999204 20404 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1211 21:47:58.962141 20404 solver.cpp:218] Iteration 136100 (12.559 iter/s, 7.96243s/100 iters), loss = 0.0103654
I1211 21:47:58.962141 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:47:58.962141 20404 solver.cpp:237]     Train net output #1: loss = 0.0103657 (* 1 = 0.0103657 loss)
I1211 21:47:58.962141 20404 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1211 21:48:06.922912 20404 solver.cpp:218] Iteration 136200 (12.562 iter/s, 7.96051s/100 iters), loss = 0.0149878
I1211 21:48:06.922912 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:06.922912 20404 solver.cpp:237]     Train net output #1: loss = 0.0149881 (* 1 = 0.0149881 loss)
I1211 21:48:06.922912 20404 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1211 21:48:14.889883 20404 solver.cpp:218] Iteration 136300 (12.5528 iter/s, 7.96635s/100 iters), loss = 0.0101201
I1211 21:48:14.889883 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:14.889883 20404 solver.cpp:237]     Train net output #1: loss = 0.0101204 (* 1 = 0.0101204 loss)
I1211 21:48:14.889883 20404 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1211 21:48:22.855882 20404 solver.cpp:218] Iteration 136400 (12.5546 iter/s, 7.96523s/100 iters), loss = 0.0106427
I1211 21:48:22.855882 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:22.855882 20404 solver.cpp:237]     Train net output #1: loss = 0.010643 (* 1 = 0.010643 loss)
I1211 21:48:22.855882 20404 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1211 21:48:30.427701  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:48:30.744736 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.caffemodel
I1211 21:48:30.773741 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.solverstate
I1211 21:48:30.779741 20404 solver.cpp:330] Iteration 136500, Testing net (#0)
I1211 21:48:30.779741 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:48:32.457356  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:48:32.524363 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 21:48:32.524363 20404 solver.cpp:397]     Test net output #1: loss = 0.262059 (* 1 = 0.262059 loss)
I1211 21:48:32.599385 20404 solver.cpp:218] Iteration 136500 (10.2641 iter/s, 9.74267s/100 iters), loss = 0.0158759
I1211 21:48:32.599385 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:32.599385 20404 solver.cpp:237]     Train net output #1: loss = 0.0158762 (* 1 = 0.0158762 loss)
I1211 21:48:32.599385 20404 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1211 21:48:40.558537 20404 solver.cpp:218] Iteration 136600 (12.5635 iter/s, 7.95958s/100 iters), loss = 0.0162843
I1211 21:48:40.559537 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:40.559537 20404 solver.cpp:237]     Train net output #1: loss = 0.0162846 (* 1 = 0.0162846 loss)
I1211 21:48:40.559537 20404 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1211 21:48:48.522090 20404 solver.cpp:218] Iteration 136700 (12.5585 iter/s, 7.96272s/100 iters), loss = 0.0134324
I1211 21:48:48.522090 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:48.522090 20404 solver.cpp:237]     Train net output #1: loss = 0.0134327 (* 1 = 0.0134327 loss)
I1211 21:48:48.522090 20404 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1211 21:48:56.483422 20404 solver.cpp:218] Iteration 136800 (12.561 iter/s, 7.96112s/100 iters), loss = 0.00832638
I1211 21:48:56.483422 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:48:56.483422 20404 solver.cpp:237]     Train net output #1: loss = 0.00832667 (* 1 = 0.00832667 loss)
I1211 21:48:56.483422 20404 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1211 21:49:04.435559 20404 solver.cpp:218] Iteration 136900 (12.5769 iter/s, 7.95106s/100 iters), loss = 0.0104115
I1211 21:49:04.435559 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:49:04.435559 20404 solver.cpp:237]     Train net output #1: loss = 0.0104118 (* 1 = 0.0104118 loss)
I1211 21:49:04.435559 20404 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1211 21:49:12.001690  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:49:12.315544 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.caffemodel
I1211 21:49:12.344048 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.solverstate
I1211 21:49:12.350049 20404 solver.cpp:330] Iteration 137000, Testing net (#0)
I1211 21:49:12.350049 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:49:14.026990  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:49:14.093502 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1211 21:49:14.093502 20404 solver.cpp:397]     Test net output #1: loss = 0.262226 (* 1 = 0.262226 loss)
I1211 21:49:14.168552 20404 solver.cpp:218] Iteration 137000 (10.2751 iter/s, 9.7323s/100 iters), loss = 0.0182767
I1211 21:49:14.168552 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:49:14.168552 20404 solver.cpp:237]     Train net output #1: loss = 0.018277 (* 1 = 0.018277 loss)
I1211 21:49:14.168552 20404 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1211 21:49:22.115514 20404 solver.cpp:218] Iteration 137100 (12.5843 iter/s, 7.94638s/100 iters), loss = 0.0081199
I1211 21:49:22.115514 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:49:22.115514 20404 solver.cpp:237]     Train net output #1: loss = 0.0081202 (* 1 = 0.0081202 loss)
I1211 21:49:22.115514 20404 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1211 21:49:30.067519 20404 solver.cpp:218] Iteration 137200 (12.5751 iter/s, 7.9522s/100 iters), loss = 0.0175539
I1211 21:49:30.067519 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:49:30.067519 20404 solver.cpp:237]     Train net output #1: loss = 0.0175542 (* 1 = 0.0175542 loss)
I1211 21:49:30.067519 20404 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1211 21:49:38.021215 20404 solver.cpp:218] Iteration 137300 (12.5736 iter/s, 7.95317s/100 iters), loss = 0.0217473
I1211 21:49:38.021215 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:49:38.021215 20404 solver.cpp:237]     Train net output #1: loss = 0.0217476 (* 1 = 0.0217476 loss)
I1211 21:49:38.021215 20404 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1211 21:49:45.973341 20404 solver.cpp:218] Iteration 137400 (12.576 iter/s, 7.95165s/100 iters), loss = 0.00995264
I1211 21:49:45.974341 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:49:45.974341 20404 solver.cpp:237]     Train net output #1: loss = 0.00995294 (* 1 = 0.00995294 loss)
I1211 21:49:45.974341 20404 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1211 21:49:53.526434  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:49:53.837935 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.caffemodel
I1211 21:49:53.865934 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.solverstate
I1211 21:49:53.876443 20404 solver.cpp:330] Iteration 137500, Testing net (#0)
I1211 21:49:53.876935 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:49:55.548719  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:49:55.615725 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 21:49:55.615725 20404 solver.cpp:397]     Test net output #1: loss = 0.260049 (* 1 = 0.260049 loss)
I1211 21:49:55.689726 20404 solver.cpp:218] Iteration 137500 (10.2932 iter/s, 9.71517s/100 iters), loss = 0.0222404
I1211 21:49:55.689726 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:49:55.689726 20404 solver.cpp:237]     Train net output #1: loss = 0.0222407 (* 1 = 0.0222407 loss)
I1211 21:49:55.689726 20404 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1211 21:50:03.643970 20404 solver.cpp:218] Iteration 137600 (12.573 iter/s, 7.95355s/100 iters), loss = 0.0150969
I1211 21:50:03.643970 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:50:03.643970 20404 solver.cpp:237]     Train net output #1: loss = 0.0150972 (* 1 = 0.0150972 loss)
I1211 21:50:03.643970 20404 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1211 21:50:11.593153 20404 solver.cpp:218] Iteration 137700 (12.5804 iter/s, 7.9489s/100 iters), loss = 0.025783
I1211 21:50:11.593153 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:50:11.593153 20404 solver.cpp:237]     Train net output #1: loss = 0.0257833 (* 1 = 0.0257833 loss)
I1211 21:50:11.593153 20404 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1211 21:50:19.545073 20404 solver.cpp:218] Iteration 137800 (12.5759 iter/s, 7.9517s/100 iters), loss = 0.0136801
I1211 21:50:19.545073 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:50:19.545073 20404 solver.cpp:237]     Train net output #1: loss = 0.0136804 (* 1 = 0.0136804 loss)
I1211 21:50:19.545073 20404 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1211 21:50:27.508919 20404 solver.cpp:218] Iteration 137900 (12.5583 iter/s, 7.96283s/100 iters), loss = 0.020157
I1211 21:50:27.508919 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:50:27.508919 20404 solver.cpp:237]     Train net output #1: loss = 0.0201573 (* 1 = 0.0201573 loss)
I1211 21:50:27.508919 20404 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1211 21:50:35.064636  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:50:35.379672 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.caffemodel
I1211 21:50:35.411675 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.solverstate
I1211 21:50:35.417675 20404 solver.cpp:330] Iteration 138000, Testing net (#0)
I1211 21:50:35.417675 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:50:37.093793  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:50:37.160799 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 21:50:37.160799 20404 solver.cpp:397]     Test net output #1: loss = 0.258993 (* 1 = 0.258993 loss)
I1211 21:50:37.235803 20404 solver.cpp:218] Iteration 138000 (10.281 iter/s, 9.7267s/100 iters), loss = 0.0121993
I1211 21:50:37.235803 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:50:37.235803 20404 solver.cpp:237]     Train net output #1: loss = 0.0121996 (* 1 = 0.0121996 loss)
I1211 21:50:37.235803 20404 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1211 21:50:45.182464 20404 solver.cpp:218] Iteration 138100 (12.5848 iter/s, 7.94611s/100 iters), loss = 0.016682
I1211 21:50:45.182464 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:50:45.182464 20404 solver.cpp:237]     Train net output #1: loss = 0.0166823 (* 1 = 0.0166823 loss)
I1211 21:50:45.182963 20404 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1211 21:50:53.131886 20404 solver.cpp:218] Iteration 138200 (12.5804 iter/s, 7.94889s/100 iters), loss = 0.016243
I1211 21:50:53.131886 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:50:53.131886 20404 solver.cpp:237]     Train net output #1: loss = 0.0162433 (* 1 = 0.0162433 loss)
I1211 21:50:53.131886 20404 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1211 21:51:01.096809 20404 solver.cpp:218] Iteration 138300 (12.5564 iter/s, 7.96408s/100 iters), loss = 0.011361
I1211 21:51:01.096809 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:01.096809 20404 solver.cpp:237]     Train net output #1: loss = 0.0113613 (* 1 = 0.0113613 loss)
I1211 21:51:01.096809 20404 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1211 21:51:09.060410 20404 solver.cpp:218] Iteration 138400 (12.5572 iter/s, 7.96354s/100 iters), loss = 0.0121219
I1211 21:51:09.060410 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:09.060410 20404 solver.cpp:237]     Train net output #1: loss = 0.0121222 (* 1 = 0.0121222 loss)
I1211 21:51:09.060410 20404 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1211 21:51:16.624650  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:51:16.939538 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.caffemodel
I1211 21:51:16.968539 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.solverstate
I1211 21:51:16.975540 20404 solver.cpp:330] Iteration 138500, Testing net (#0)
I1211 21:51:16.975540 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:51:18.649318  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:51:18.715651 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1211 21:51:18.715651 20404 solver.cpp:397]     Test net output #1: loss = 0.257042 (* 1 = 0.257042 loss)
I1211 21:51:18.789640 20404 solver.cpp:218] Iteration 138500 (10.2789 iter/s, 9.72865s/100 iters), loss = 0.0147085
I1211 21:51:18.790146 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:18.790146 20404 solver.cpp:237]     Train net output #1: loss = 0.0147088 (* 1 = 0.0147088 loss)
I1211 21:51:18.790146 20404 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1211 21:51:26.739673 20404 solver.cpp:218] Iteration 138600 (12.5792 iter/s, 7.94966s/100 iters), loss = 0.00968547
I1211 21:51:26.739673 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:26.739673 20404 solver.cpp:237]     Train net output #1: loss = 0.00968576 (* 1 = 0.00968576 loss)
I1211 21:51:26.739673 20404 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1211 21:51:34.689313 20404 solver.cpp:218] Iteration 138700 (12.5805 iter/s, 7.94884s/100 iters), loss = 0.0135466
I1211 21:51:34.689313 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:34.689313 20404 solver.cpp:237]     Train net output #1: loss = 0.0135469 (* 1 = 0.0135469 loss)
I1211 21:51:34.689313 20404 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1211 21:51:42.640415 20404 solver.cpp:218] Iteration 138800 (12.5776 iter/s, 7.95062s/100 iters), loss = 0.013906
I1211 21:51:42.640415 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:42.640415 20404 solver.cpp:237]     Train net output #1: loss = 0.0139063 (* 1 = 0.0139063 loss)
I1211 21:51:42.640415 20404 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1211 21:51:50.586786 20404 solver.cpp:218] Iteration 138900 (12.585 iter/s, 7.94598s/100 iters), loss = 0.0117649
I1211 21:51:50.586786 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:51:50.586786 20404 solver.cpp:237]     Train net output #1: loss = 0.0117652 (* 1 = 0.0117652 loss)
I1211 21:51:50.586786 20404 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1211 21:51:58.136381  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:51:58.450422 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.caffemodel
I1211 21:51:58.481420 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.solverstate
I1211 21:51:58.487421 20404 solver.cpp:330] Iteration 139000, Testing net (#0)
I1211 21:51:58.487421 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:52:00.163568  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:52:00.230576 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1211 21:52:00.230576 20404 solver.cpp:397]     Test net output #1: loss = 0.260896 (* 1 = 0.260896 loss)
I1211 21:52:00.305079 20404 solver.cpp:218] Iteration 139000 (10.2904 iter/s, 9.7178s/100 iters), loss = 0.0182194
I1211 21:52:00.305079 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:52:00.305079 20404 solver.cpp:237]     Train net output #1: loss = 0.0182197 (* 1 = 0.0182197 loss)
I1211 21:52:00.305079 20404 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1211 21:52:08.258240 20404 solver.cpp:218] Iteration 139100 (12.5744 iter/s, 7.95265s/100 iters), loss = 0.0275954
I1211 21:52:08.258240 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:52:08.258240 20404 solver.cpp:237]     Train net output #1: loss = 0.0275957 (* 1 = 0.0275957 loss)
I1211 21:52:08.258240 20404 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1211 21:52:16.222153 20404 solver.cpp:218] Iteration 139200 (12.5578 iter/s, 7.9632s/100 iters), loss = 0.0249976
I1211 21:52:16.222153 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:52:16.222153 20404 solver.cpp:237]     Train net output #1: loss = 0.0249979 (* 1 = 0.0249979 loss)
I1211 21:52:16.222153 20404 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1211 21:52:24.169981 20404 solver.cpp:218] Iteration 139300 (12.582 iter/s, 7.94786s/100 iters), loss = 0.0102152
I1211 21:52:24.169981 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:52:24.169981 20404 solver.cpp:237]     Train net output #1: loss = 0.0102155 (* 1 = 0.0102155 loss)
I1211 21:52:24.169981 20404 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1211 21:52:32.114444 20404 solver.cpp:218] Iteration 139400 (12.5886 iter/s, 7.94369s/100 iters), loss = 0.0101054
I1211 21:52:32.114444 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:52:32.114444 20404 solver.cpp:237]     Train net output #1: loss = 0.0101057 (* 1 = 0.0101057 loss)
I1211 21:52:32.114444 20404 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1211 21:52:39.679821  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:52:39.992842 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.caffemodel
I1211 21:52:40.023346 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.solverstate
I1211 21:52:40.029847 20404 solver.cpp:330] Iteration 139500, Testing net (#0)
I1211 21:52:40.030347 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:52:41.703006  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:52:41.769026 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9313
I1211 21:52:41.770025 20404 solver.cpp:397]     Test net output #1: loss = 0.26744 (* 1 = 0.26744 loss)
I1211 21:52:41.844030 20404 solver.cpp:218] Iteration 139500 (10.2788 iter/s, 9.72873s/100 iters), loss = 0.0153673
I1211 21:52:41.844030 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:52:41.844030 20404 solver.cpp:237]     Train net output #1: loss = 0.0153676 (* 1 = 0.0153676 loss)
I1211 21:52:41.844030 20404 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1211 21:52:49.793759 20404 solver.cpp:218] Iteration 139600 (12.5789 iter/s, 7.94981s/100 iters), loss = 0.0290951
I1211 21:52:49.793759 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 21:52:49.793759 20404 solver.cpp:237]     Train net output #1: loss = 0.0290954 (* 1 = 0.0290954 loss)
I1211 21:52:49.793759 20404 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1211 21:52:57.745312 20404 solver.cpp:218] Iteration 139700 (12.5772 iter/s, 7.95092s/100 iters), loss = 0.0163045
I1211 21:52:57.745312 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:52:57.745312 20404 solver.cpp:237]     Train net output #1: loss = 0.0163048 (* 1 = 0.0163048 loss)
I1211 21:52:57.745312 20404 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1211 21:53:05.697602 20404 solver.cpp:218] Iteration 139800 (12.576 iter/s, 7.95166s/100 iters), loss = 0.0150637
I1211 21:53:05.697602 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:05.697602 20404 solver.cpp:237]     Train net output #1: loss = 0.015064 (* 1 = 0.015064 loss)
I1211 21:53:05.697602 20404 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1211 21:53:13.652609 20404 solver.cpp:218] Iteration 139900 (12.5711 iter/s, 7.95477s/100 iters), loss = 0.0132964
I1211 21:53:13.652609 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:13.652609 20404 solver.cpp:237]     Train net output #1: loss = 0.0132967 (* 1 = 0.0132967 loss)
I1211 21:53:13.652609 20404 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1211 21:53:21.214781  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:53:21.529805 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.caffemodel
I1211 21:53:21.557814 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.solverstate
I1211 21:53:21.564818 20404 solver.cpp:330] Iteration 140000, Testing net (#0)
I1211 21:53:21.564818 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:53:23.243016  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:53:23.309018 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1211 21:53:23.309018 20404 solver.cpp:397]     Test net output #1: loss = 0.262339 (* 1 = 0.262339 loss)
I1211 21:53:23.383028 20404 solver.cpp:218] Iteration 140000 (10.2778 iter/s, 9.72969s/100 iters), loss = 0.0112316
I1211 21:53:23.383028 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:23.383028 20404 solver.cpp:237]     Train net output #1: loss = 0.0112319 (* 1 = 0.0112319 loss)
I1211 21:53:23.383028 20404 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1211 21:53:31.343940 20404 solver.cpp:218] Iteration 140100 (12.5629 iter/s, 7.95992s/100 iters), loss = 0.0107245
I1211 21:53:31.343940 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:31.343940 20404 solver.cpp:237]     Train net output #1: loss = 0.0107248 (* 1 = 0.0107248 loss)
I1211 21:53:31.343940 20404 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1211 21:53:39.304165 20404 solver.cpp:218] Iteration 140200 (12.5633 iter/s, 7.95967s/100 iters), loss = 0.0109385
I1211 21:53:39.304165 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:39.304165 20404 solver.cpp:237]     Train net output #1: loss = 0.0109388 (* 1 = 0.0109388 loss)
I1211 21:53:39.304165 20404 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1211 21:53:47.349135 20404 solver.cpp:218] Iteration 140300 (12.43 iter/s, 8.04503s/100 iters), loss = 0.0107262
I1211 21:53:47.349135 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:47.349135 20404 solver.cpp:237]     Train net output #1: loss = 0.0107265 (* 1 = 0.0107265 loss)
I1211 21:53:47.349135 20404 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1211 21:53:55.379793 20404 solver.cpp:218] Iteration 140400 (12.4539 iter/s, 8.02958s/100 iters), loss = 0.0116682
I1211 21:53:55.379793 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:53:55.379793 20404 solver.cpp:237]     Train net output #1: loss = 0.0116685 (* 1 = 0.0116685 loss)
I1211 21:53:55.379793 20404 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1211 21:54:02.980963  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:54:03.296289 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.caffemodel
I1211 21:54:03.332291 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.solverstate
I1211 21:54:03.338795 20404 solver.cpp:330] Iteration 140500, Testing net (#0)
I1211 21:54:03.338795 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:54:05.023105  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:54:05.089241 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1211 21:54:05.089241 20404 solver.cpp:397]     Test net output #1: loss = 0.253597 (* 1 = 0.253597 loss)
I1211 21:54:05.163627 20404 solver.cpp:218] Iteration 140500 (10.2209 iter/s, 9.78388s/100 iters), loss = 0.0189806
I1211 21:54:05.163627 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:05.163627 20404 solver.cpp:237]     Train net output #1: loss = 0.0189809 (* 1 = 0.0189809 loss)
I1211 21:54:05.163627 20404 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1211 21:54:13.166090 20404 solver.cpp:218] Iteration 140600 (12.4972 iter/s, 8.00179s/100 iters), loss = 0.0123085
I1211 21:54:13.166090 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:13.166090 20404 solver.cpp:237]     Train net output #1: loss = 0.0123088 (* 1 = 0.0123088 loss)
I1211 21:54:13.166090 20404 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1211 21:54:21.165382 20404 solver.cpp:218] Iteration 140700 (12.5015 iter/s, 7.99905s/100 iters), loss = 0.0180708
I1211 21:54:21.165382 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:21.165382 20404 solver.cpp:237]     Train net output #1: loss = 0.0180711 (* 1 = 0.0180711 loss)
I1211 21:54:21.165382 20404 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1211 21:54:29.123385 20404 solver.cpp:218] Iteration 140800 (12.5668 iter/s, 7.95746s/100 iters), loss = 0.0113541
I1211 21:54:29.123385 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:29.123385 20404 solver.cpp:237]     Train net output #1: loss = 0.0113544 (* 1 = 0.0113544 loss)
I1211 21:54:29.123385 20404 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1211 21:54:37.088865 20404 solver.cpp:218] Iteration 140900 (12.5546 iter/s, 7.96522s/100 iters), loss = 0.0110284
I1211 21:54:37.089864 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:37.089864 20404 solver.cpp:237]     Train net output #1: loss = 0.0110287 (* 1 = 0.0110287 loss)
I1211 21:54:37.089864 20404 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1211 21:54:44.665887  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:54:44.978938 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.caffemodel
I1211 21:54:45.006935 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.solverstate
I1211 21:54:45.012938 20404 solver.cpp:330] Iteration 141000, Testing net (#0)
I1211 21:54:45.013947 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:54:46.689195  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:54:46.755210 20404 solver.cpp:397]     Test net output #0: accuracy = 0.932
I1211 21:54:46.755210 20404 solver.cpp:397]     Test net output #1: loss = 0.260722 (* 1 = 0.260722 loss)
I1211 21:54:46.829215 20404 solver.cpp:218] Iteration 141000 (10.2675 iter/s, 9.73943s/100 iters), loss = 0.0171328
I1211 21:54:46.829215 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:46.829215 20404 solver.cpp:237]     Train net output #1: loss = 0.0171331 (* 1 = 0.0171331 loss)
I1211 21:54:46.829215 20404 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1211 21:54:54.786124 20404 solver.cpp:218] Iteration 141100 (12.5691 iter/s, 7.956s/100 iters), loss = 0.0138015
I1211 21:54:54.786124 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:54:54.786124 20404 solver.cpp:237]     Train net output #1: loss = 0.0138018 (* 1 = 0.0138018 loss)
I1211 21:54:54.786124 20404 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1211 21:55:02.747149 20404 solver.cpp:218] Iteration 141200 (12.5618 iter/s, 7.96067s/100 iters), loss = 0.0117503
I1211 21:55:02.747149 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:02.747149 20404 solver.cpp:237]     Train net output #1: loss = 0.0117506 (* 1 = 0.0117506 loss)
I1211 21:55:02.747149 20404 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1211 21:55:10.710244 20404 solver.cpp:218] Iteration 141300 (12.5586 iter/s, 7.96268s/100 iters), loss = 0.0127499
I1211 21:55:10.710244 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:10.710244 20404 solver.cpp:237]     Train net output #1: loss = 0.0127502 (* 1 = 0.0127502 loss)
I1211 21:55:10.710244 20404 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1211 21:55:18.662106 20404 solver.cpp:218] Iteration 141400 (12.5764 iter/s, 7.95143s/100 iters), loss = 0.014305
I1211 21:55:18.662607 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:18.662607 20404 solver.cpp:237]     Train net output #1: loss = 0.0143053 (* 1 = 0.0143053 loss)
I1211 21:55:18.662607 20404 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1211 21:55:26.225550  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:55:26.540570 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.caffemodel
I1211 21:55:26.567574 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.solverstate
I1211 21:55:26.573575 20404 solver.cpp:330] Iteration 141500, Testing net (#0)
I1211 21:55:26.573575 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:55:28.250195  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:55:28.316197 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1211 21:55:28.316197 20404 solver.cpp:397]     Test net output #1: loss = 0.264202 (* 1 = 0.264202 loss)
I1211 21:55:28.390213 20404 solver.cpp:218] Iteration 141500 (10.2797 iter/s, 9.7279s/100 iters), loss = 0.0131722
I1211 21:55:28.391213 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:28.391213 20404 solver.cpp:237]     Train net output #1: loss = 0.0131725 (* 1 = 0.0131725 loss)
I1211 21:55:28.391213 20404 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1211 21:55:36.346777 20404 solver.cpp:218] Iteration 141600 (12.5702 iter/s, 7.95533s/100 iters), loss = 0.0170071
I1211 21:55:36.346777 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:36.346777 20404 solver.cpp:237]     Train net output #1: loss = 0.0170074 (* 1 = 0.0170074 loss)
I1211 21:55:36.346777 20404 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1211 21:55:44.303845 20404 solver.cpp:218] Iteration 141700 (12.5682 iter/s, 7.95657s/100 iters), loss = 0.0109072
I1211 21:55:44.303845 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:44.303845 20404 solver.cpp:237]     Train net output #1: loss = 0.0109075 (* 1 = 0.0109075 loss)
I1211 21:55:44.303845 20404 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1211 21:55:52.241703 20404 solver.cpp:218] Iteration 141800 (12.599 iter/s, 7.93717s/100 iters), loss = 0.0138245
I1211 21:55:52.241703 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:55:52.241703 20404 solver.cpp:237]     Train net output #1: loss = 0.0138248 (* 1 = 0.0138248 loss)
I1211 21:55:52.241703 20404 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1211 21:56:00.202132 20404 solver.cpp:218] Iteration 141900 (12.563 iter/s, 7.95991s/100 iters), loss = 0.00991027
I1211 21:56:00.202132 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:00.202132 20404 solver.cpp:237]     Train net output #1: loss = 0.00991058 (* 1 = 0.00991058 loss)
I1211 21:56:00.202132 20404 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1211 21:56:07.767832  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:56:08.083130 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.caffemodel
I1211 21:56:08.110131 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.solverstate
I1211 21:56:08.117132 20404 solver.cpp:330] Iteration 142000, Testing net (#0)
I1211 21:56:08.117132 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:56:09.788832  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:56:09.854933 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1211 21:56:09.854933 20404 solver.cpp:397]     Test net output #1: loss = 0.268188 (* 1 = 0.268188 loss)
I1211 21:56:09.929427 20404 solver.cpp:218] Iteration 142000 (10.2807 iter/s, 9.72696s/100 iters), loss = 0.0219434
I1211 21:56:09.929427 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:09.929427 20404 solver.cpp:237]     Train net output #1: loss = 0.0219437 (* 1 = 0.0219437 loss)
I1211 21:56:09.929427 20404 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1211 21:56:17.889622 20404 solver.cpp:218] Iteration 142100 (12.5631 iter/s, 7.95981s/100 iters), loss = 0.0124813
I1211 21:56:17.889622 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:17.889622 20404 solver.cpp:237]     Train net output #1: loss = 0.0124816 (* 1 = 0.0124816 loss)
I1211 21:56:17.889622 20404 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1211 21:56:25.852825 20404 solver.cpp:218] Iteration 142200 (12.5588 iter/s, 7.96255s/100 iters), loss = 0.0175297
I1211 21:56:25.852825 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:25.852825 20404 solver.cpp:237]     Train net output #1: loss = 0.01753 (* 1 = 0.01753 loss)
I1211 21:56:25.852825 20404 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1211 21:56:33.896852 20404 solver.cpp:218] Iteration 142300 (12.4317 iter/s, 8.04395s/100 iters), loss = 0.011916
I1211 21:56:33.896852 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:33.896852 20404 solver.cpp:237]     Train net output #1: loss = 0.0119163 (* 1 = 0.0119163 loss)
I1211 21:56:33.896852 20404 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1211 21:56:41.931123 20404 solver.cpp:218] Iteration 142400 (12.4471 iter/s, 8.03397s/100 iters), loss = 0.0117367
I1211 21:56:41.931123 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:41.931123 20404 solver.cpp:237]     Train net output #1: loss = 0.011737 (* 1 = 0.011737 loss)
I1211 21:56:41.931123 20404 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1211 21:56:49.603127  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:56:49.919159 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.caffemodel
I1211 21:56:49.953166 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.solverstate
I1211 21:56:49.959166 20404 solver.cpp:330] Iteration 142500, Testing net (#0)
I1211 21:56:49.959166 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:56:51.636459  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:56:51.703961 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1211 21:56:51.703961 20404 solver.cpp:397]     Test net output #1: loss = 0.264032 (* 1 = 0.264032 loss)
I1211 21:56:51.778470 20404 solver.cpp:218] Iteration 142500 (10.1563 iter/s, 9.84615s/100 iters), loss = 0.018564
I1211 21:56:51.778470 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:51.778470 20404 solver.cpp:237]     Train net output #1: loss = 0.0185643 (* 1 = 0.0185643 loss)
I1211 21:56:51.778470 20404 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1211 21:56:59.874940 20404 solver.cpp:218] Iteration 142600 (12.3519 iter/s, 8.09592s/100 iters), loss = 0.00893831
I1211 21:56:59.874940 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:56:59.874940 20404 solver.cpp:237]     Train net output #1: loss = 0.00893861 (* 1 = 0.00893861 loss)
I1211 21:56:59.874940 20404 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1211 21:57:07.878747 20404 solver.cpp:218] Iteration 142700 (12.4936 iter/s, 8.00411s/100 iters), loss = 0.011127
I1211 21:57:07.878747 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:07.879746 20404 solver.cpp:237]     Train net output #1: loss = 0.0111273 (* 1 = 0.0111273 loss)
I1211 21:57:07.879746 20404 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1211 21:57:15.864926 20404 solver.cpp:218] Iteration 142800 (12.5225 iter/s, 7.98562s/100 iters), loss = 0.0101623
I1211 21:57:15.864926 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:15.864926 20404 solver.cpp:237]     Train net output #1: loss = 0.0101626 (* 1 = 0.0101626 loss)
I1211 21:57:15.864926 20404 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1211 21:57:23.909271 20404 solver.cpp:218] Iteration 142900 (12.4327 iter/s, 8.04329s/100 iters), loss = 0.0108229
I1211 21:57:23.909271 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:23.909271 20404 solver.cpp:237]     Train net output #1: loss = 0.0108232 (* 1 = 0.0108232 loss)
I1211 21:57:23.909271 20404 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1211 21:57:31.542901  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:57:31.858952 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.caffemodel
I1211 21:57:31.886471 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.solverstate
I1211 21:57:31.893476 20404 solver.cpp:330] Iteration 143000, Testing net (#0)
I1211 21:57:31.893476 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:57:33.568169  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:57:33.634182 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9323
I1211 21:57:33.634182 20404 solver.cpp:397]     Test net output #1: loss = 0.264717 (* 1 = 0.264717 loss)
I1211 21:57:33.708225 20404 solver.cpp:218] Iteration 143000 (10.2053 iter/s, 9.79879s/100 iters), loss = 0.0190464
I1211 21:57:33.708225 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:33.708225 20404 solver.cpp:237]     Train net output #1: loss = 0.0190467 (* 1 = 0.0190467 loss)
I1211 21:57:33.708225 20404 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1211 21:57:41.664055 20404 solver.cpp:218] Iteration 143100 (12.5707 iter/s, 7.95502s/100 iters), loss = 0.0104709
I1211 21:57:41.664556 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:41.664556 20404 solver.cpp:237]     Train net output #1: loss = 0.0104712 (* 1 = 0.0104712 loss)
I1211 21:57:41.664556 20404 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1211 21:57:49.640738 20404 solver.cpp:218] Iteration 143200 (12.5378 iter/s, 7.97588s/100 iters), loss = 0.0111271
I1211 21:57:49.640738 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:49.640738 20404 solver.cpp:237]     Train net output #1: loss = 0.0111274 (* 1 = 0.0111274 loss)
I1211 21:57:49.640738 20404 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1211 21:57:57.608422 20404 solver.cpp:218] Iteration 143300 (12.5517 iter/s, 7.96706s/100 iters), loss = 0.012274
I1211 21:57:57.608422 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:57:57.608422 20404 solver.cpp:237]     Train net output #1: loss = 0.0122743 (* 1 = 0.0122743 loss)
I1211 21:57:57.608422 20404 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1211 21:58:05.564461 20404 solver.cpp:218] Iteration 143400 (12.5696 iter/s, 7.95573s/100 iters), loss = 0.0137047
I1211 21:58:05.564461 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:05.564461 20404 solver.cpp:237]     Train net output #1: loss = 0.013705 (* 1 = 0.013705 loss)
I1211 21:58:05.564461 20404 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1211 21:58:13.129037  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:58:13.444535 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.caffemodel
I1211 21:58:13.473541 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.solverstate
I1211 21:58:13.479555 20404 solver.cpp:330] Iteration 143500, Testing net (#0)
I1211 21:58:13.479555 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:58:15.151053  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:58:15.218063 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 21:58:15.218063 20404 solver.cpp:397]     Test net output #1: loss = 0.263112 (* 1 = 0.263112 loss)
I1211 21:58:15.292734 20404 solver.cpp:218] Iteration 143500 (10.2802 iter/s, 9.72746s/100 iters), loss = 0.0112757
I1211 21:58:15.292734 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:15.292734 20404 solver.cpp:237]     Train net output #1: loss = 0.011276 (* 1 = 0.011276 loss)
I1211 21:58:15.292734 20404 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1211 21:58:23.245764 20404 solver.cpp:218] Iteration 143600 (12.5748 iter/s, 7.95244s/100 iters), loss = 0.0108593
I1211 21:58:23.245764 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:23.245764 20404 solver.cpp:237]     Train net output #1: loss = 0.0108596 (* 1 = 0.0108596 loss)
I1211 21:58:23.245764 20404 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1211 21:58:31.210819 20404 solver.cpp:218] Iteration 143700 (12.5547 iter/s, 7.96514s/100 iters), loss = 0.0197631
I1211 21:58:31.210819 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:31.210819 20404 solver.cpp:237]     Train net output #1: loss = 0.0197635 (* 1 = 0.0197635 loss)
I1211 21:58:31.210819 20404 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1211 21:58:39.178161 20404 solver.cpp:218] Iteration 143800 (12.5523 iter/s, 7.96668s/100 iters), loss = 0.0126244
I1211 21:58:39.178663 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:39.178663 20404 solver.cpp:237]     Train net output #1: loss = 0.0126247 (* 1 = 0.0126247 loss)
I1211 21:58:39.178663 20404 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1211 21:58:47.131920 20404 solver.cpp:218] Iteration 143900 (12.5734 iter/s, 7.95328s/100 iters), loss = 0.0147498
I1211 21:58:47.131920 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:47.131920 20404 solver.cpp:237]     Train net output #1: loss = 0.0147501 (* 1 = 0.0147501 loss)
I1211 21:58:47.131920 20404 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1211 21:58:54.808272  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:58:55.132148 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.caffemodel
I1211 21:58:55.173151 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.solverstate
I1211 21:58:55.178660 20404 solver.cpp:330] Iteration 144000, Testing net (#0)
I1211 21:58:55.179160 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:58:56.862718  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:58:56.929235 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1211 21:58:56.930235 20404 solver.cpp:397]     Test net output #1: loss = 0.260515 (* 1 = 0.260515 loss)
I1211 21:58:57.006268 20404 solver.cpp:218] Iteration 144000 (10.1281 iter/s, 9.87349s/100 iters), loss = 0.0123016
I1211 21:58:57.006268 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:58:57.006268 20404 solver.cpp:237]     Train net output #1: loss = 0.0123019 (* 1 = 0.0123019 loss)
I1211 21:58:57.006268 20404 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1211 21:59:05.062602 20404 solver.cpp:218] Iteration 144100 (12.4136 iter/s, 8.05571s/100 iters), loss = 0.0123576
I1211 21:59:05.062602 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:05.062602 20404 solver.cpp:237]     Train net output #1: loss = 0.0123579 (* 1 = 0.0123579 loss)
I1211 21:59:05.062602 20404 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1211 21:59:13.111388 20404 solver.cpp:218] Iteration 144200 (12.4247 iter/s, 8.04847s/100 iters), loss = 0.00995082
I1211 21:59:13.111388 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:13.111388 20404 solver.cpp:237]     Train net output #1: loss = 0.00995112 (* 1 = 0.00995112 loss)
I1211 21:59:13.111388 20404 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1211 21:59:21.138244 20404 solver.cpp:218] Iteration 144300 (12.458 iter/s, 8.02698s/100 iters), loss = 0.0112348
I1211 21:59:21.139245 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:21.139245 20404 solver.cpp:237]     Train net output #1: loss = 0.0112351 (* 1 = 0.0112351 loss)
I1211 21:59:21.139245 20404 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1211 21:59:29.261380 20404 solver.cpp:218] Iteration 144400 (12.3118 iter/s, 8.12229s/100 iters), loss = 0.0147371
I1211 21:59:29.261380 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:29.261380 20404 solver.cpp:237]     Train net output #1: loss = 0.0147374 (* 1 = 0.0147374 loss)
I1211 21:59:29.261380 20404 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1211 21:59:36.904745  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:59:37.219287 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.caffemodel
I1211 21:59:37.250288 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.solverstate
I1211 21:59:37.257289 20404 solver.cpp:330] Iteration 144500, Testing net (#0)
I1211 21:59:37.257289 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 21:59:38.931442  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 21:59:38.997440 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1211 21:59:38.997440 20404 solver.cpp:397]     Test net output #1: loss = 0.262295 (* 1 = 0.262295 loss)
I1211 21:59:39.071447 20404 solver.cpp:218] Iteration 144500 (10.1948 iter/s, 9.80897s/100 iters), loss = 0.0118703
I1211 21:59:39.071447 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:39.071447 20404 solver.cpp:237]     Train net output #1: loss = 0.0118705 (* 1 = 0.0118705 loss)
I1211 21:59:39.071447 20404 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1211 21:59:47.028393 20404 solver.cpp:218] Iteration 144600 (12.5684 iter/s, 7.95648s/100 iters), loss = 0.0125303
I1211 21:59:47.028393 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:47.028393 20404 solver.cpp:237]     Train net output #1: loss = 0.0125306 (* 1 = 0.0125306 loss)
I1211 21:59:47.028393 20404 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1211 21:59:54.984272 20404 solver.cpp:218] Iteration 144700 (12.5699 iter/s, 7.95552s/100 iters), loss = 0.0123385
I1211 21:59:54.984272 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 21:59:54.984272 20404 solver.cpp:237]     Train net output #1: loss = 0.0123388 (* 1 = 0.0123388 loss)
I1211 21:59:54.984272 20404 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1211 22:00:02.948397 20404 solver.cpp:218] Iteration 144800 (12.5566 iter/s, 7.96393s/100 iters), loss = 0.00775492
I1211 22:00:02.948397 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:02.948397 20404 solver.cpp:237]     Train net output #1: loss = 0.0077552 (* 1 = 0.0077552 loss)
I1211 22:00:02.948397 20404 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1211 22:00:10.931434 20404 solver.cpp:218] Iteration 144900 (12.527 iter/s, 7.98274s/100 iters), loss = 0.0112414
I1211 22:00:10.931434 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:10.931434 20404 solver.cpp:237]     Train net output #1: loss = 0.0112416 (* 1 = 0.0112416 loss)
I1211 22:00:10.931434 20404 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1211 22:00:18.494302  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:00:18.808332 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.caffemodel
I1211 22:00:18.835333 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.solverstate
I1211 22:00:18.841334 20404 solver.cpp:330] Iteration 145000, Testing net (#0)
I1211 22:00:18.841334 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:00:20.515468  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:00:20.581472 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9318
I1211 22:00:20.581472 20404 solver.cpp:397]     Test net output #1: loss = 0.265031 (* 1 = 0.265031 loss)
I1211 22:00:20.656471 20404 solver.cpp:218] Iteration 145000 (10.284 iter/s, 9.72388s/100 iters), loss = 0.0126184
I1211 22:00:20.656471 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:20.656471 20404 solver.cpp:237]     Train net output #1: loss = 0.0126187 (* 1 = 0.0126187 loss)
I1211 22:00:20.656471 20404 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1211 22:00:28.618461 20404 solver.cpp:218] Iteration 145100 (12.5599 iter/s, 7.96188s/100 iters), loss = 0.0180432
I1211 22:00:28.618461 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:28.618461 20404 solver.cpp:237]     Train net output #1: loss = 0.0180435 (* 1 = 0.0180435 loss)
I1211 22:00:28.618461 20404 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1211 22:00:36.632411 20404 solver.cpp:218] Iteration 145200 (12.4785 iter/s, 8.01377s/100 iters), loss = 0.0162191
I1211 22:00:36.632411 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:36.632411 20404 solver.cpp:237]     Train net output #1: loss = 0.0162193 (* 1 = 0.0162193 loss)
I1211 22:00:36.632411 20404 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1211 22:00:44.651993 20404 solver.cpp:218] Iteration 145300 (12.4714 iter/s, 8.01836s/100 iters), loss = 0.0109064
I1211 22:00:44.651993 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:44.651993 20404 solver.cpp:237]     Train net output #1: loss = 0.0109067 (* 1 = 0.0109067 loss)
I1211 22:00:44.651993 20404 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1211 22:00:52.646049 20404 solver.cpp:218] Iteration 145400 (12.5087 iter/s, 7.99442s/100 iters), loss = 0.0111525
I1211 22:00:52.646049 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:00:52.647048 20404 solver.cpp:237]     Train net output #1: loss = 0.0111528 (* 1 = 0.0111528 loss)
I1211 22:00:52.647048 20404 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1211 22:01:00.201232  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:01:00.515298 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.caffemodel
I1211 22:01:00.543298 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.solverstate
I1211 22:01:00.549299 20404 solver.cpp:330] Iteration 145500, Testing net (#0)
I1211 22:01:00.549299 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:01:02.220516  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:01:02.288058 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1211 22:01:02.288058 20404 solver.cpp:397]     Test net output #1: loss = 0.266304 (* 1 = 0.266304 loss)
I1211 22:01:02.362555 20404 solver.cpp:218] Iteration 145500 (10.2933 iter/s, 9.71502s/100 iters), loss = 0.0162395
I1211 22:01:02.362555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:02.362555 20404 solver.cpp:237]     Train net output #1: loss = 0.0162398 (* 1 = 0.0162398 loss)
I1211 22:01:02.362555 20404 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1211 22:01:10.318509 20404 solver.cpp:218] Iteration 145600 (12.5689 iter/s, 7.95612s/100 iters), loss = 0.0198144
I1211 22:01:10.318509 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:10.318509 20404 solver.cpp:237]     Train net output #1: loss = 0.0198146 (* 1 = 0.0198146 loss)
I1211 22:01:10.318509 20404 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1211 22:01:18.286465 20404 solver.cpp:218] Iteration 145700 (12.5517 iter/s, 7.96704s/100 iters), loss = 0.0189895
I1211 22:01:18.286465 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:18.286465 20404 solver.cpp:237]     Train net output #1: loss = 0.0189898 (* 1 = 0.0189898 loss)
I1211 22:01:18.286465 20404 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1211 22:01:26.348296 20404 solver.cpp:218] Iteration 145800 (12.4053 iter/s, 8.06107s/100 iters), loss = 0.0139236
I1211 22:01:26.348296 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:26.348296 20404 solver.cpp:237]     Train net output #1: loss = 0.0139239 (* 1 = 0.0139239 loss)
I1211 22:01:26.348296 20404 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1211 22:01:34.291141 20404 solver.cpp:218] Iteration 145900 (12.5903 iter/s, 7.94259s/100 iters), loss = 0.0136796
I1211 22:01:34.291141 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:34.291141 20404 solver.cpp:237]     Train net output #1: loss = 0.0136798 (* 1 = 0.0136798 loss)
I1211 22:01:34.291141 20404 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1211 22:01:41.853958  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:01:42.166095 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.caffemodel
I1211 22:01:42.195098 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.solverstate
I1211 22:01:42.201102 20404 solver.cpp:330] Iteration 146000, Testing net (#0)
I1211 22:01:42.201102 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:01:43.873889  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:01:43.940066 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9317
I1211 22:01:43.940066 20404 solver.cpp:397]     Test net output #1: loss = 0.264426 (* 1 = 0.264426 loss)
I1211 22:01:44.014585 20404 solver.cpp:218] Iteration 146000 (10.2852 iter/s, 9.72269s/100 iters), loss = 0.0148286
I1211 22:01:44.014585 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:44.014585 20404 solver.cpp:237]     Train net output #1: loss = 0.0148289 (* 1 = 0.0148289 loss)
I1211 22:01:44.014585 20404 sgd_solver.cpp:105] Iteration 146000, lr = 0.001
I1211 22:01:52.148356 20404 solver.cpp:218] Iteration 146100 (12.2943 iter/s, 8.13385s/100 iters), loss = 0.00992543
I1211 22:01:52.148356 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:01:52.148356 20404 solver.cpp:237]     Train net output #1: loss = 0.0099257 (* 1 = 0.0099257 loss)
I1211 22:01:52.148356 20404 sgd_solver.cpp:105] Iteration 146100, lr = 0.001
I1211 22:02:00.185710 20404 solver.cpp:218] Iteration 146200 (12.4431 iter/s, 8.03658s/100 iters), loss = 0.0117286
I1211 22:02:00.185710 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:00.185710 20404 solver.cpp:237]     Train net output #1: loss = 0.0117289 (* 1 = 0.0117289 loss)
I1211 22:02:00.185710 20404 sgd_solver.cpp:105] Iteration 146200, lr = 0.001
I1211 22:02:08.239305 20404 solver.cpp:218] Iteration 146300 (12.4186 iter/s, 8.05244s/100 iters), loss = 0.00955056
I1211 22:02:08.239305 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:08.239305 20404 solver.cpp:237]     Train net output #1: loss = 0.00955083 (* 1 = 0.00955083 loss)
I1211 22:02:08.239305 20404 sgd_solver.cpp:105] Iteration 146300, lr = 0.001
I1211 22:02:16.201697 20404 solver.cpp:218] Iteration 146400 (12.5597 iter/s, 7.96199s/100 iters), loss = 0.0111962
I1211 22:02:16.201697 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:16.201697 20404 solver.cpp:237]     Train net output #1: loss = 0.0111964 (* 1 = 0.0111964 loss)
I1211 22:02:16.201697 20404 sgd_solver.cpp:105] Iteration 146400, lr = 0.001
I1211 22:02:23.763969  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:02:24.076989 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146500.caffemodel
I1211 22:02:24.104492 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146500.solverstate
I1211 22:02:24.110494 20404 solver.cpp:330] Iteration 146500, Testing net (#0)
I1211 22:02:24.110994 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:02:25.782165  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:02:25.849179 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9323
I1211 22:02:25.849179 20404 solver.cpp:397]     Test net output #1: loss = 0.264116 (* 1 = 0.264116 loss)
I1211 22:02:25.923182 20404 solver.cpp:218] Iteration 146500 (10.2864 iter/s, 9.72154s/100 iters), loss = 0.0145541
I1211 22:02:25.923182 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:25.923182 20404 solver.cpp:237]     Train net output #1: loss = 0.0145544 (* 1 = 0.0145544 loss)
I1211 22:02:25.923182 20404 sgd_solver.cpp:105] Iteration 146500, lr = 0.001
I1211 22:02:33.875142 20404 solver.cpp:218] Iteration 146600 (12.5777 iter/s, 7.9506s/100 iters), loss = 0.0126429
I1211 22:02:33.875142 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:33.875142 20404 solver.cpp:237]     Train net output #1: loss = 0.0126432 (* 1 = 0.0126432 loss)
I1211 22:02:33.875142 20404 sgd_solver.cpp:105] Iteration 146600, lr = 0.001
I1211 22:02:41.823926 20404 solver.cpp:218] Iteration 146700 (12.5805 iter/s, 7.94881s/100 iters), loss = 0.0093871
I1211 22:02:41.823926 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:41.823926 20404 solver.cpp:237]     Train net output #1: loss = 0.00938738 (* 1 = 0.00938738 loss)
I1211 22:02:41.823926 20404 sgd_solver.cpp:105] Iteration 146700, lr = 0.001
I1211 22:02:49.774741 20404 solver.cpp:218] Iteration 146800 (12.5782 iter/s, 7.95023s/100 iters), loss = 0.0115837
I1211 22:02:49.774741 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:49.774741 20404 solver.cpp:237]     Train net output #1: loss = 0.011584 (* 1 = 0.011584 loss)
I1211 22:02:49.774741 20404 sgd_solver.cpp:105] Iteration 146800, lr = 0.001
I1211 22:02:57.717842 20404 solver.cpp:218] Iteration 146900 (12.591 iter/s, 7.94219s/100 iters), loss = 0.0124248
I1211 22:02:57.717842 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:02:57.717842 20404 solver.cpp:237]     Train net output #1: loss = 0.0124251 (* 1 = 0.0124251 loss)
I1211 22:02:57.717842 20404 sgd_solver.cpp:105] Iteration 146900, lr = 0.001
I1211 22:03:05.286197  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:03:05.600414 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147000.caffemodel
I1211 22:03:05.633440 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147000.solverstate
I1211 22:03:05.639454 20404 solver.cpp:330] Iteration 147000, Testing net (#0)
I1211 22:03:05.639454 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:03:07.311098  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:03:07.377187 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1211 22:03:07.377187 20404 solver.cpp:397]     Test net output #1: loss = 0.266742 (* 1 = 0.266742 loss)
I1211 22:03:07.450255 20404 solver.cpp:218] Iteration 147000 (10.2748 iter/s, 9.73257s/100 iters), loss = 0.0156339
I1211 22:03:07.450255 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:07.450255 20404 solver.cpp:237]     Train net output #1: loss = 0.0156341 (* 1 = 0.0156341 loss)
I1211 22:03:07.450255 20404 sgd_solver.cpp:105] Iteration 147000, lr = 0.001
I1211 22:03:15.499717 20404 solver.cpp:218] Iteration 147100 (12.4239 iter/s, 8.04897s/100 iters), loss = 0.0143747
I1211 22:03:15.499717 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:15.499717 20404 solver.cpp:237]     Train net output #1: loss = 0.014375 (* 1 = 0.014375 loss)
I1211 22:03:15.499717 20404 sgd_solver.cpp:105] Iteration 147100, lr = 0.001
I1211 22:03:23.631554 20404 solver.cpp:218] Iteration 147200 (12.2986 iter/s, 8.13102s/100 iters), loss = 0.0156772
I1211 22:03:23.631554 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:23.631554 20404 solver.cpp:237]     Train net output #1: loss = 0.0156775 (* 1 = 0.0156775 loss)
I1211 22:03:23.631554 20404 sgd_solver.cpp:105] Iteration 147200, lr = 0.001
I1211 22:03:31.668364 20404 solver.cpp:218] Iteration 147300 (12.4443 iter/s, 8.03584s/100 iters), loss = 0.00969732
I1211 22:03:31.668364 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:31.668364 20404 solver.cpp:237]     Train net output #1: loss = 0.0096976 (* 1 = 0.0096976 loss)
I1211 22:03:31.668364 20404 sgd_solver.cpp:105] Iteration 147300, lr = 0.001
I1211 22:03:39.668386 20404 solver.cpp:218] Iteration 147400 (12.5001 iter/s, 7.99995s/100 iters), loss = 0.0110596
I1211 22:03:39.668386 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:39.668386 20404 solver.cpp:237]     Train net output #1: loss = 0.0110599 (* 1 = 0.0110599 loss)
I1211 22:03:39.668386 20404 sgd_solver.cpp:105] Iteration 147400, lr = 0.001
I1211 22:03:47.259508  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:03:47.575533 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147500.caffemodel
I1211 22:03:47.604533 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147500.solverstate
I1211 22:03:47.611536 20404 solver.cpp:330] Iteration 147500, Testing net (#0)
I1211 22:03:47.611536 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:03:49.290657  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:03:49.356663 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9317
I1211 22:03:49.356663 20404 solver.cpp:397]     Test net output #1: loss = 0.266279 (* 1 = 0.266279 loss)
I1211 22:03:49.431166 20404 solver.cpp:218] Iteration 147500 (10.2437 iter/s, 9.76212s/100 iters), loss = 0.0141002
I1211 22:03:49.431166 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:49.431166 20404 solver.cpp:237]     Train net output #1: loss = 0.0141004 (* 1 = 0.0141004 loss)
I1211 22:03:49.431166 20404 sgd_solver.cpp:105] Iteration 147500, lr = 0.001
I1211 22:03:57.402935 20404 solver.cpp:218] Iteration 147600 (12.5453 iter/s, 7.97114s/100 iters), loss = 0.0142163
I1211 22:03:57.402935 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:03:57.402935 20404 solver.cpp:237]     Train net output #1: loss = 0.0142166 (* 1 = 0.0142166 loss)
I1211 22:03:57.402935 20404 sgd_solver.cpp:105] Iteration 147600, lr = 0.001
I1211 22:04:05.385581 20404 solver.cpp:218] Iteration 147700 (12.5269 iter/s, 7.98282s/100 iters), loss = 0.0121075
I1211 22:04:05.386580 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:05.386580 20404 solver.cpp:237]     Train net output #1: loss = 0.0121078 (* 1 = 0.0121078 loss)
I1211 22:04:05.386580 20404 sgd_solver.cpp:105] Iteration 147700, lr = 0.001
I1211 22:04:13.374027 20404 solver.cpp:218] Iteration 147800 (12.5203 iter/s, 7.98702s/100 iters), loss = 0.0116663
I1211 22:04:13.374027 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:13.374027 20404 solver.cpp:237]     Train net output #1: loss = 0.0116666 (* 1 = 0.0116666 loss)
I1211 22:04:13.374027 20404 sgd_solver.cpp:105] Iteration 147800, lr = 0.001
I1211 22:04:21.336218 20404 solver.cpp:218] Iteration 147900 (12.5603 iter/s, 7.96157s/100 iters), loss = 0.0156409
I1211 22:04:21.336218 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:21.336218 20404 solver.cpp:237]     Train net output #1: loss = 0.0156411 (* 1 = 0.0156411 loss)
I1211 22:04:21.336218 20404 sgd_solver.cpp:105] Iteration 147900, lr = 0.001
I1211 22:04:28.898607  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:04:29.215440 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148000.caffemodel
I1211 22:04:29.244946 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148000.solverstate
I1211 22:04:29.251446 20404 solver.cpp:330] Iteration 148000, Testing net (#0)
I1211 22:04:29.251446 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:04:30.923164  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:04:30.990200 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1211 22:04:30.990200 20404 solver.cpp:397]     Test net output #1: loss = 0.264108 (* 1 = 0.264108 loss)
I1211 22:04:31.064188 20404 solver.cpp:218] Iteration 148000 (10.2798 iter/s, 9.72783s/100 iters), loss = 0.0151793
I1211 22:04:31.064188 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:31.064188 20404 solver.cpp:237]     Train net output #1: loss = 0.0151796 (* 1 = 0.0151796 loss)
I1211 22:04:31.064188 20404 sgd_solver.cpp:105] Iteration 148000, lr = 0.001
I1211 22:04:39.018189 20404 solver.cpp:218] Iteration 148100 (12.5724 iter/s, 7.95392s/100 iters), loss = 0.0113219
I1211 22:04:39.018189 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:39.018189 20404 solver.cpp:237]     Train net output #1: loss = 0.0113221 (* 1 = 0.0113221 loss)
I1211 22:04:39.018189 20404 sgd_solver.cpp:105] Iteration 148100, lr = 0.001
I1211 22:04:46.959919 20404 solver.cpp:218] Iteration 148200 (12.5933 iter/s, 7.94071s/100 iters), loss = 0.0108903
I1211 22:04:46.959919 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:46.959919 20404 solver.cpp:237]     Train net output #1: loss = 0.0108905 (* 1 = 0.0108905 loss)
I1211 22:04:46.959919 20404 sgd_solver.cpp:105] Iteration 148200, lr = 0.001
I1211 22:04:54.921310 20404 solver.cpp:218] Iteration 148300 (12.5618 iter/s, 7.96065s/100 iters), loss = 0.0100653
I1211 22:04:54.921310 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:04:54.921310 20404 solver.cpp:237]     Train net output #1: loss = 0.0100656 (* 1 = 0.0100656 loss)
I1211 22:04:54.921310 20404 sgd_solver.cpp:105] Iteration 148300, lr = 0.001
I1211 22:05:02.867184 20404 solver.cpp:218] Iteration 148400 (12.5858 iter/s, 7.94545s/100 iters), loss = 0.0111039
I1211 22:05:02.867184 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:02.867184 20404 solver.cpp:237]     Train net output #1: loss = 0.0111041 (* 1 = 0.0111041 loss)
I1211 22:05:02.867184 20404 sgd_solver.cpp:105] Iteration 148400, lr = 0.001
I1211 22:05:10.437611  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:05:10.751634 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148500.caffemodel
I1211 22:05:10.783649 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148500.solverstate
I1211 22:05:10.789643 20404 solver.cpp:330] Iteration 148500, Testing net (#0)
I1211 22:05:10.789643 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:05:12.462019  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:05:12.528026 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 22:05:12.528026 20404 solver.cpp:397]     Test net output #1: loss = 0.263705 (* 1 = 0.263705 loss)
I1211 22:05:12.603034 20404 solver.cpp:218] Iteration 148500 (10.2717 iter/s, 9.73547s/100 iters), loss = 0.0122001
I1211 22:05:12.603034 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:12.603034 20404 solver.cpp:237]     Train net output #1: loss = 0.0122003 (* 1 = 0.0122003 loss)
I1211 22:05:12.603034 20404 sgd_solver.cpp:105] Iteration 148500, lr = 0.001
I1211 22:05:20.554633 20404 solver.cpp:218] Iteration 148600 (12.5766 iter/s, 7.95126s/100 iters), loss = 0.0153182
I1211 22:05:20.554633 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:20.554633 20404 solver.cpp:237]     Train net output #1: loss = 0.0153185 (* 1 = 0.0153185 loss)
I1211 22:05:20.554633 20404 sgd_solver.cpp:105] Iteration 148600, lr = 0.001
I1211 22:05:28.503259 20404 solver.cpp:218] Iteration 148700 (12.5821 iter/s, 7.94777s/100 iters), loss = 0.0102758
I1211 22:05:28.503259 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:28.503259 20404 solver.cpp:237]     Train net output #1: loss = 0.010276 (* 1 = 0.010276 loss)
I1211 22:05:28.503259 20404 sgd_solver.cpp:105] Iteration 148700, lr = 0.001
I1211 22:05:36.486567 20404 solver.cpp:218] Iteration 148800 (12.5255 iter/s, 7.98372s/100 iters), loss = 0.00925661
I1211 22:05:36.487566 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:36.487566 20404 solver.cpp:237]     Train net output #1: loss = 0.00925689 (* 1 = 0.00925689 loss)
I1211 22:05:36.487566 20404 sgd_solver.cpp:105] Iteration 148800, lr = 0.001
I1211 22:05:44.438923 20404 solver.cpp:218] Iteration 148900 (12.576 iter/s, 7.95167s/100 iters), loss = 0.0130198
I1211 22:05:44.438923 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:44.438923 20404 solver.cpp:237]     Train net output #1: loss = 0.0130201 (* 1 = 0.0130201 loss)
I1211 22:05:44.438923 20404 sgd_solver.cpp:105] Iteration 148900, lr = 0.001
I1211 22:05:52.010867  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:05:52.326928 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149000.caffemodel
I1211 22:05:52.359928 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149000.solverstate
I1211 22:05:52.364928 20404 solver.cpp:330] Iteration 149000, Testing net (#0)
I1211 22:05:52.365929 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:05:54.041074  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:05:54.108098 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1211 22:05:54.108098 20404 solver.cpp:397]     Test net output #1: loss = 0.261529 (* 1 = 0.261529 loss)
I1211 22:05:54.182585 20404 solver.cpp:218] Iteration 149000 (10.2643 iter/s, 9.74249s/100 iters), loss = 0.0123313
I1211 22:05:54.182585 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:05:54.182585 20404 solver.cpp:237]     Train net output #1: loss = 0.0123315 (* 1 = 0.0123315 loss)
I1211 22:05:54.182585 20404 sgd_solver.cpp:105] Iteration 149000, lr = 0.001
I1211 22:06:02.153800 20404 solver.cpp:218] Iteration 149100 (12.5458 iter/s, 7.97081s/100 iters), loss = 0.013876
I1211 22:06:02.153800 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:02.153800 20404 solver.cpp:237]     Train net output #1: loss = 0.0138763 (* 1 = 0.0138763 loss)
I1211 22:06:02.153800 20404 sgd_solver.cpp:105] Iteration 149100, lr = 0.001
I1211 22:06:10.125974 20404 solver.cpp:218] Iteration 149200 (12.5441 iter/s, 7.97188s/100 iters), loss = 0.0173824
I1211 22:06:10.125974 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:10.125974 20404 solver.cpp:237]     Train net output #1: loss = 0.0173827 (* 1 = 0.0173827 loss)
I1211 22:06:10.125974 20404 sgd_solver.cpp:105] Iteration 149200, lr = 0.001
I1211 22:06:18.090490 20404 solver.cpp:218] Iteration 149300 (12.5572 iter/s, 7.96358s/100 iters), loss = 0.0116751
I1211 22:06:18.090490 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:18.090490 20404 solver.cpp:237]     Train net output #1: loss = 0.0116753 (* 1 = 0.0116753 loss)
I1211 22:06:18.090490 20404 sgd_solver.cpp:105] Iteration 149300, lr = 0.001
I1211 22:06:26.064116 20404 solver.cpp:218] Iteration 149400 (12.5415 iter/s, 7.97354s/100 iters), loss = 0.0114785
I1211 22:06:26.064116 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:26.064116 20404 solver.cpp:237]     Train net output #1: loss = 0.0114788 (* 1 = 0.0114788 loss)
I1211 22:06:26.064116 20404 sgd_solver.cpp:105] Iteration 149400, lr = 0.001
I1211 22:06:33.652390  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:06:33.968523 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149500.caffemodel
I1211 22:06:34.004532 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149500.solverstate
I1211 22:06:34.010532 20404 solver.cpp:330] Iteration 149500, Testing net (#0)
I1211 22:06:34.010532 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:06:35.700700  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:06:35.767699 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1211 22:06:35.767699 20404 solver.cpp:397]     Test net output #1: loss = 0.265741 (* 1 = 0.265741 loss)
I1211 22:06:35.841703 20404 solver.cpp:218] Iteration 149500 (10.2283 iter/s, 9.77681s/100 iters), loss = 0.0148979
I1211 22:06:35.841703 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:35.841703 20404 solver.cpp:237]     Train net output #1: loss = 0.0148982 (* 1 = 0.0148982 loss)
I1211 22:06:35.841703 20404 sgd_solver.cpp:105] Iteration 149500, lr = 0.001
I1211 22:06:43.840947 20404 solver.cpp:218] Iteration 149600 (12.5017 iter/s, 7.99891s/100 iters), loss = 0.0118841
I1211 22:06:43.840947 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:43.840947 20404 solver.cpp:237]     Train net output #1: loss = 0.0118844 (* 1 = 0.0118844 loss)
I1211 22:06:43.840947 20404 sgd_solver.cpp:105] Iteration 149600, lr = 0.001
I1211 22:06:51.855634 20404 solver.cpp:218] Iteration 149700 (12.4783 iter/s, 8.01394s/100 iters), loss = 0.0207775
I1211 22:06:51.855634 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:51.855634 20404 solver.cpp:237]     Train net output #1: loss = 0.0207778 (* 1 = 0.0207778 loss)
I1211 22:06:51.855634 20404 sgd_solver.cpp:105] Iteration 149700, lr = 0.001
I1211 22:06:59.859062 20404 solver.cpp:218] Iteration 149800 (12.4949 iter/s, 8.00327s/100 iters), loss = 0.00953126
I1211 22:06:59.859062 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:06:59.859062 20404 solver.cpp:237]     Train net output #1: loss = 0.00953154 (* 1 = 0.00953154 loss)
I1211 22:06:59.859062 20404 sgd_solver.cpp:105] Iteration 149800, lr = 0.001
I1211 22:07:07.858920 20404 solver.cpp:218] Iteration 149900 (12.5017 iter/s, 7.99893s/100 iters), loss = 0.0112617
I1211 22:07:07.858920 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:07:07.858920 20404 solver.cpp:237]     Train net output #1: loss = 0.011262 (* 1 = 0.011262 loss)
I1211 22:07:07.858920 20404 sgd_solver.cpp:105] Iteration 149900, lr = 0.001
I1211 22:07:15.435561  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:07:15.749833 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150000.caffemodel
I1211 22:07:15.776828 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150000.solverstate
I1211 22:07:15.782829 20404 solver.cpp:330] Iteration 150000, Testing net (#0)
I1211 22:07:15.782829 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:07:17.458748  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:07:17.524369 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9313
I1211 22:07:17.524369 20404 solver.cpp:397]     Test net output #1: loss = 0.272117 (* 1 = 0.272117 loss)
I1211 22:07:17.599372 20404 solver.cpp:218] Iteration 150000 (10.2663 iter/s, 9.74063s/100 iters), loss = 0.0137313
I1211 22:07:17.599372 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:07:17.599372 20404 solver.cpp:237]     Train net output #1: loss = 0.0137316 (* 1 = 0.0137316 loss)
I1211 22:07:17.599372 20404 sgd_solver.cpp:105] Iteration 150000, lr = 0.001
I1211 22:07:25.625227 20404 solver.cpp:218] Iteration 150100 (12.4618 iter/s, 8.02455s/100 iters), loss = 0.0150047
I1211 22:07:25.625227 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:07:25.625227 20404 solver.cpp:237]     Train net output #1: loss = 0.015005 (* 1 = 0.015005 loss)
I1211 22:07:25.625227 20404 sgd_solver.cpp:105] Iteration 150100, lr = 0.001
I1211 22:07:33.722009 20404 solver.cpp:218] Iteration 150200 (12.351 iter/s, 8.0965s/100 iters), loss = 0.0210948
I1211 22:07:33.722009 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:07:33.722009 20404 solver.cpp:237]     Train net output #1: loss = 0.0210951 (* 1 = 0.0210951 loss)
I1211 22:07:33.722009 20404 sgd_solver.cpp:105] Iteration 150200, lr = 0.001
I1211 22:07:41.767467 20404 solver.cpp:218] Iteration 150300 (12.4296 iter/s, 8.04534s/100 iters), loss = 0.014521
I1211 22:07:41.767467 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:07:41.767467 20404 solver.cpp:237]     Train net output #1: loss = 0.0145213 (* 1 = 0.0145213 loss)
I1211 22:07:41.767467 20404 sgd_solver.cpp:105] Iteration 150300, lr = 0.001
I1211 22:07:49.854460 20404 solver.cpp:218] Iteration 150400 (12.3667 iter/s, 8.08626s/100 iters), loss = 0.0132709
I1211 22:07:49.854460 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:07:49.854460 20404 solver.cpp:237]     Train net output #1: loss = 0.0132712 (* 1 = 0.0132712 loss)
I1211 22:07:49.854460 20404 sgd_solver.cpp:105] Iteration 150400, lr = 0.001
I1211 22:07:57.492508  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:07:57.813549 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150500.caffemodel
I1211 22:07:57.843565 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150500.solverstate
I1211 22:07:57.849565 20404 solver.cpp:330] Iteration 150500, Testing net (#0)
I1211 22:07:57.850566 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:07:59.541761  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:07:59.609760 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9315
I1211 22:07:59.609760 20404 solver.cpp:397]     Test net output #1: loss = 0.267505 (* 1 = 0.267505 loss)
I1211 22:07:59.683766 20404 solver.cpp:218] Iteration 150500 (10.174 iter/s, 9.829s/100 iters), loss = 0.0317689
I1211 22:07:59.683766 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:07:59.683766 20404 solver.cpp:237]     Train net output #1: loss = 0.0317692 (* 1 = 0.0317692 loss)
I1211 22:07:59.683766 20404 sgd_solver.cpp:105] Iteration 150500, lr = 0.001
I1211 22:08:07.788791 20404 solver.cpp:218] Iteration 150600 (12.3389 iter/s, 8.10445s/100 iters), loss = 0.0214867
I1211 22:08:07.788791 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:08:07.788791 20404 solver.cpp:237]     Train net output #1: loss = 0.021487 (* 1 = 0.021487 loss)
I1211 22:08:07.788791 20404 sgd_solver.cpp:105] Iteration 150600, lr = 0.001
I1211 22:08:15.796952 20404 solver.cpp:218] Iteration 150700 (12.4889 iter/s, 8.0071s/100 iters), loss = 0.0246979
I1211 22:08:15.796952 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:08:15.796952 20404 solver.cpp:237]     Train net output #1: loss = 0.0246982 (* 1 = 0.0246982 loss)
I1211 22:08:15.796952 20404 sgd_solver.cpp:105] Iteration 150700, lr = 0.001
I1211 22:08:23.859243 20404 solver.cpp:218] Iteration 150800 (12.4031 iter/s, 8.06252s/100 iters), loss = 0.0104856
I1211 22:08:23.859243 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:08:23.859243 20404 solver.cpp:237]     Train net output #1: loss = 0.0104859 (* 1 = 0.0104859 loss)
I1211 22:08:23.859243 20404 sgd_solver.cpp:105] Iteration 150800, lr = 0.001
I1211 22:08:31.956398 20404 solver.cpp:218] Iteration 150900 (12.3508 iter/s, 8.09666s/100 iters), loss = 0.032763
I1211 22:08:31.956398 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:08:31.956398 20404 solver.cpp:237]     Train net output #1: loss = 0.0327633 (* 1 = 0.0327633 loss)
I1211 22:08:31.956398 20404 sgd_solver.cpp:105] Iteration 150900, lr = 0.001
I1211 22:08:39.580396  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:08:39.895417 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151000.caffemodel
I1211 22:08:39.922417 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151000.solverstate
I1211 22:08:39.928419 20404 solver.cpp:330] Iteration 151000, Testing net (#0)
I1211 22:08:39.928419 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:08:41.611543  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:08:41.678550 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1211 22:08:41.678550 20404 solver.cpp:397]     Test net output #1: loss = 0.267249 (* 1 = 0.267249 loss)
I1211 22:08:41.753051 20404 solver.cpp:218] Iteration 151000 (10.2087 iter/s, 9.79553s/100 iters), loss = 0.0161056
I1211 22:08:41.753051 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:08:41.753051 20404 solver.cpp:237]     Train net output #1: loss = 0.0161059 (* 1 = 0.0161059 loss)
I1211 22:08:41.753051 20404 sgd_solver.cpp:105] Iteration 151000, lr = 0.001
I1211 22:08:49.871999 20404 solver.cpp:218] Iteration 151100 (12.3171 iter/s, 8.11878s/100 iters), loss = 0.0190746
I1211 22:08:49.871999 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:08:49.871999 20404 solver.cpp:237]     Train net output #1: loss = 0.0190749 (* 1 = 0.0190749 loss)
I1211 22:08:49.871999 20404 sgd_solver.cpp:105] Iteration 151100, lr = 0.001
I1211 22:08:57.872117 20404 solver.cpp:218] Iteration 151200 (12.5015 iter/s, 7.99904s/100 iters), loss = 0.0143909
I1211 22:08:57.872117 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:08:57.872117 20404 solver.cpp:237]     Train net output #1: loss = 0.0143912 (* 1 = 0.0143912 loss)
I1211 22:08:57.872117 20404 sgd_solver.cpp:105] Iteration 151200, lr = 0.001
I1211 22:09:05.925606 20404 solver.cpp:218] Iteration 151300 (12.4169 iter/s, 8.05351s/100 iters), loss = 0.0120338
I1211 22:09:05.925606 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:09:05.925606 20404 solver.cpp:237]     Train net output #1: loss = 0.0120341 (* 1 = 0.0120341 loss)
I1211 22:09:05.925606 20404 sgd_solver.cpp:105] Iteration 151300, lr = 0.001
I1211 22:09:14.049007 20404 solver.cpp:218] Iteration 151400 (12.3105 iter/s, 8.12312s/100 iters), loss = 0.0133374
I1211 22:09:14.049007 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:09:14.050006 20404 solver.cpp:237]     Train net output #1: loss = 0.0133377 (* 1 = 0.0133377 loss)
I1211 22:09:14.050006 20404 sgd_solver.cpp:105] Iteration 151400, lr = 0.001
I1211 22:09:21.650712  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:09:21.964637 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151500.caffemodel
I1211 22:09:21.994165 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151500.solverstate
I1211 22:09:22.000155 20404 solver.cpp:330] Iteration 151500, Testing net (#0)
I1211 22:09:22.000155 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:09:23.672387  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:09:23.739388 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1211 22:09:23.739388 20404 solver.cpp:397]     Test net output #1: loss = 0.269164 (* 1 = 0.269164 loss)
I1211 22:09:23.812958 20404 solver.cpp:218] Iteration 151500 (10.2428 iter/s, 9.76293s/100 iters), loss = 0.014531
I1211 22:09:23.812958 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:09:23.812958 20404 solver.cpp:237]     Train net output #1: loss = 0.0145313 (* 1 = 0.0145313 loss)
I1211 22:09:23.812958 20404 sgd_solver.cpp:105] Iteration 151500, lr = 0.001
I1211 22:09:31.774602 20404 solver.cpp:218] Iteration 151600 (12.5615 iter/s, 7.96082s/100 iters), loss = 0.010103
I1211 22:09:31.774602 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:09:31.774602 20404 solver.cpp:237]     Train net output #1: loss = 0.0101033 (* 1 = 0.0101033 loss)
I1211 22:09:31.774602 20404 sgd_solver.cpp:105] Iteration 151600, lr = 0.001
I1211 22:09:39.744302 20404 solver.cpp:218] Iteration 151700 (12.5476 iter/s, 7.96967s/100 iters), loss = 0.0102912
I1211 22:09:39.744302 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:09:39.744302 20404 solver.cpp:237]     Train net output #1: loss = 0.0102915 (* 1 = 0.0102915 loss)
I1211 22:09:39.744302 20404 sgd_solver.cpp:105] Iteration 151700, lr = 0.001
I1211 22:09:47.714109 20404 solver.cpp:218] Iteration 151800 (12.5489 iter/s, 7.9688s/100 iters), loss = 0.0250185
I1211 22:09:47.714109 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:09:47.714109 20404 solver.cpp:237]     Train net output #1: loss = 0.0250188 (* 1 = 0.0250188 loss)
I1211 22:09:47.714109 20404 sgd_solver.cpp:105] Iteration 151800, lr = 0.001
I1211 22:09:55.690865 20404 solver.cpp:218] Iteration 151900 (12.5377 iter/s, 7.97595s/100 iters), loss = 0.0162215
I1211 22:09:55.690865 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:09:55.690865 20404 solver.cpp:237]     Train net output #1: loss = 0.0162218 (* 1 = 0.0162218 loss)
I1211 22:09:55.690865 20404 sgd_solver.cpp:105] Iteration 151900, lr = 0.001
I1211 22:10:03.315675  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:10:03.628696 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152000.caffemodel
I1211 22:10:03.657696 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152000.solverstate
I1211 22:10:03.663697 20404 solver.cpp:330] Iteration 152000, Testing net (#0)
I1211 22:10:03.664201 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:10:05.338845  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:10:05.405854 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1211 22:10:05.405854 20404 solver.cpp:397]     Test net output #1: loss = 0.267957 (* 1 = 0.267957 loss)
I1211 22:10:05.479856 20404 solver.cpp:218] Iteration 152000 (10.2157 iter/s, 9.78881s/100 iters), loss = 0.0137405
I1211 22:10:05.479856 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:10:05.479856 20404 solver.cpp:237]     Train net output #1: loss = 0.0137408 (* 1 = 0.0137408 loss)
I1211 22:10:05.479856 20404 sgd_solver.cpp:105] Iteration 152000, lr = 0.001
I1211 22:10:13.481196 20404 solver.cpp:218] Iteration 152100 (12.499 iter/s, 8.00062s/100 iters), loss = 0.0423336
I1211 22:10:13.481196 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:10:13.481196 20404 solver.cpp:237]     Train net output #1: loss = 0.0423339 (* 1 = 0.0423339 loss)
I1211 22:10:13.481196 20404 sgd_solver.cpp:105] Iteration 152100, lr = 0.001
I1211 22:10:21.579501 20404 solver.cpp:218] Iteration 152200 (12.3486 iter/s, 8.09809s/100 iters), loss = 0.0137593
I1211 22:10:21.580001 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:10:21.580001 20404 solver.cpp:237]     Train net output #1: loss = 0.0137596 (* 1 = 0.0137596 loss)
I1211 22:10:21.580001 20404 sgd_solver.cpp:105] Iteration 152200, lr = 0.001
I1211 22:10:29.614485 20404 solver.cpp:218] Iteration 152300 (12.4464 iter/s, 8.03445s/100 iters), loss = 0.0108086
I1211 22:10:29.614485 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:10:29.614485 20404 solver.cpp:237]     Train net output #1: loss = 0.0108089 (* 1 = 0.0108089 loss)
I1211 22:10:29.614485 20404 sgd_solver.cpp:105] Iteration 152300, lr = 0.001
I1211 22:10:37.658409 20404 solver.cpp:218] Iteration 152400 (12.4324 iter/s, 8.04353s/100 iters), loss = 0.0160276
I1211 22:10:37.658409 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:10:37.658409 20404 solver.cpp:237]     Train net output #1: loss = 0.0160279 (* 1 = 0.0160279 loss)
I1211 22:10:37.658409 20404 sgd_solver.cpp:105] Iteration 152400, lr = 0.001
I1211 22:10:45.312875  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:10:45.629184 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152500.caffemodel
I1211 22:10:45.660184 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152500.solverstate
I1211 22:10:45.666185 20404 solver.cpp:330] Iteration 152500, Testing net (#0)
I1211 22:10:45.666185 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:10:47.359370  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:10:47.426378 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9314
I1211 22:10:47.426378 20404 solver.cpp:397]     Test net output #1: loss = 0.268447 (* 1 = 0.268447 loss)
I1211 22:10:47.502387 20404 solver.cpp:218] Iteration 152500 (10.1594 iter/s, 9.84309s/100 iters), loss = 0.0131607
I1211 22:10:47.502387 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:10:47.502387 20404 solver.cpp:237]     Train net output #1: loss = 0.013161 (* 1 = 0.013161 loss)
I1211 22:10:47.502387 20404 sgd_solver.cpp:105] Iteration 152500, lr = 0.001
I1211 22:10:55.516583 20404 solver.cpp:218] Iteration 152600 (12.4788 iter/s, 8.01362s/100 iters), loss = 0.0118598
I1211 22:10:55.516583 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:10:55.516583 20404 solver.cpp:237]     Train net output #1: loss = 0.0118601 (* 1 = 0.0118601 loss)
I1211 22:10:55.516583 20404 sgd_solver.cpp:105] Iteration 152600, lr = 0.001
I1211 22:11:03.524850 20404 solver.cpp:218] Iteration 152700 (12.4873 iter/s, 8.00813s/100 iters), loss = 0.013818
I1211 22:11:03.524850 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:11:03.524850 20404 solver.cpp:237]     Train net output #1: loss = 0.0138183 (* 1 = 0.0138183 loss)
I1211 22:11:03.524850 20404 sgd_solver.cpp:105] Iteration 152700, lr = 0.001
I1211 22:11:11.548702 20404 solver.cpp:218] Iteration 152800 (12.4636 iter/s, 8.02337s/100 iters), loss = 0.00863571
I1211 22:11:11.548702 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:11:11.548702 20404 solver.cpp:237]     Train net output #1: loss = 0.008636 (* 1 = 0.008636 loss)
I1211 22:11:11.548702 20404 sgd_solver.cpp:105] Iteration 152800, lr = 0.001
I1211 22:11:19.673898 20404 solver.cpp:218] Iteration 152900 (12.3077 iter/s, 8.12498s/100 iters), loss = 0.0134724
I1211 22:11:19.674897 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:11:19.674897 20404 solver.cpp:237]     Train net output #1: loss = 0.0134726 (* 1 = 0.0134726 loss)
I1211 22:11:19.674897 20404 sgd_solver.cpp:105] Iteration 152900, lr = 0.001
I1211 22:11:27.357791  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:11:27.681825 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153000.caffemodel
I1211 22:11:27.710836 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153000.solverstate
I1211 22:11:27.716837 20404 solver.cpp:330] Iteration 153000, Testing net (#0)
I1211 22:11:27.716837 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:11:29.420059  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:11:29.487562 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 22:11:29.487562 20404 solver.cpp:397]     Test net output #1: loss = 0.264576 (* 1 = 0.264576 loss)
I1211 22:11:29.562067 20404 solver.cpp:218] Iteration 153000 (10.1145 iter/s, 9.88676s/100 iters), loss = 0.010895
I1211 22:11:29.562067 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:11:29.562067 20404 solver.cpp:237]     Train net output #1: loss = 0.0108953 (* 1 = 0.0108953 loss)
I1211 22:11:29.562067 20404 sgd_solver.cpp:46] MultiStep Status: Iteration 153000, step = 3
I1211 22:11:29.562067 20404 sgd_solver.cpp:105] Iteration 153000, lr = 0.0001
I1211 22:11:37.597190 20404 solver.cpp:218] Iteration 153100 (12.4462 iter/s, 8.03461s/100 iters), loss = 0.00987875
I1211 22:11:37.597190 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:11:37.597190 20404 solver.cpp:237]     Train net output #1: loss = 0.00987903 (* 1 = 0.00987903 loss)
I1211 22:11:37.597190 20404 sgd_solver.cpp:105] Iteration 153100, lr = 0.0001
I1211 22:11:45.643316 20404 solver.cpp:218] Iteration 153200 (12.4296 iter/s, 8.04531s/100 iters), loss = 0.0416547
I1211 22:11:45.643316 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:11:45.643316 20404 solver.cpp:237]     Train net output #1: loss = 0.041655 (* 1 = 0.041655 loss)
I1211 22:11:45.643316 20404 sgd_solver.cpp:105] Iteration 153200, lr = 0.0001
I1211 22:11:53.729423 20404 solver.cpp:218] Iteration 153300 (12.3677 iter/s, 8.08559s/100 iters), loss = 0.0134723
I1211 22:11:53.729423 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:11:53.729423 20404 solver.cpp:237]     Train net output #1: loss = 0.0134726 (* 1 = 0.0134726 loss)
I1211 22:11:53.729423 20404 sgd_solver.cpp:105] Iteration 153300, lr = 0.0001
I1211 22:12:01.762233 20404 solver.cpp:218] Iteration 153400 (12.4489 iter/s, 8.03284s/100 iters), loss = 0.0132984
I1211 22:12:01.762233 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:01.762233 20404 solver.cpp:237]     Train net output #1: loss = 0.0132987 (* 1 = 0.0132987 loss)
I1211 22:12:01.762233 20404 sgd_solver.cpp:105] Iteration 153400, lr = 0.0001
I1211 22:12:09.394268  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:12:09.711611 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153500.caffemodel
I1211 22:12:09.739121 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153500.solverstate
I1211 22:12:09.745136 20404 solver.cpp:330] Iteration 153500, Testing net (#0)
I1211 22:12:09.745620 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:12:11.419033  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:12:11.485734 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 22:12:11.485734 20404 solver.cpp:397]     Test net output #1: loss = 0.263432 (* 1 = 0.263432 loss)
I1211 22:12:11.561300 20404 solver.cpp:218] Iteration 153500 (10.2063 iter/s, 9.79785s/100 iters), loss = 0.0110003
I1211 22:12:11.561300 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:11.561300 20404 solver.cpp:237]     Train net output #1: loss = 0.0110006 (* 1 = 0.0110006 loss)
I1211 22:12:11.561300 20404 sgd_solver.cpp:105] Iteration 153500, lr = 0.0001
I1211 22:12:19.626092 20404 solver.cpp:218] Iteration 153600 (12.4 iter/s, 8.06454s/100 iters), loss = 0.013681
I1211 22:12:19.626092 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:19.626092 20404 solver.cpp:237]     Train net output #1: loss = 0.0136813 (* 1 = 0.0136813 loss)
I1211 22:12:19.626092 20404 sgd_solver.cpp:105] Iteration 153600, lr = 0.0001
I1211 22:12:27.738555 20404 solver.cpp:218] Iteration 153700 (12.3277 iter/s, 8.11181s/100 iters), loss = 0.0142201
I1211 22:12:27.738555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:27.738555 20404 solver.cpp:237]     Train net output #1: loss = 0.0142203 (* 1 = 0.0142203 loss)
I1211 22:12:27.738555 20404 sgd_solver.cpp:105] Iteration 153700, lr = 0.0001
I1211 22:12:35.883801 20404 solver.cpp:218] Iteration 153800 (12.277 iter/s, 8.14532s/100 iters), loss = 0.011775
I1211 22:12:35.884801 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:35.884801 20404 solver.cpp:237]     Train net output #1: loss = 0.0117753 (* 1 = 0.0117753 loss)
I1211 22:12:35.884801 20404 sgd_solver.cpp:105] Iteration 153800, lr = 0.0001
I1211 22:12:43.946478 20404 solver.cpp:218] Iteration 153900 (12.4052 iter/s, 8.06113s/100 iters), loss = 0.0111565
I1211 22:12:43.946478 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:43.946478 20404 solver.cpp:237]     Train net output #1: loss = 0.0111568 (* 1 = 0.0111568 loss)
I1211 22:12:43.946478 20404 sgd_solver.cpp:105] Iteration 153900, lr = 0.0001
I1211 22:12:51.609484  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:12:51.924022 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154000.caffemodel
I1211 22:12:51.952036 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154000.solverstate
I1211 22:12:51.958040 20404 solver.cpp:330] Iteration 154000, Testing net (#0)
I1211 22:12:51.958040 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:12:53.633173  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:12:53.699177 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 22:12:53.699177 20404 solver.cpp:397]     Test net output #1: loss = 0.262139 (* 1 = 0.262139 loss)
I1211 22:12:53.774178 20404 solver.cpp:218] Iteration 154000 (10.1753 iter/s, 9.82774s/100 iters), loss = 0.0118574
I1211 22:12:53.774178 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:12:53.774178 20404 solver.cpp:237]     Train net output #1: loss = 0.0118577 (* 1 = 0.0118577 loss)
I1211 22:12:53.774178 20404 sgd_solver.cpp:105] Iteration 154000, lr = 0.0001
I1211 22:13:01.774803 20404 solver.cpp:218] Iteration 154100 (12.4995 iter/s, 8.0003s/100 iters), loss = 0.0108251
I1211 22:13:01.775804 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:01.775804 20404 solver.cpp:237]     Train net output #1: loss = 0.0108254 (* 1 = 0.0108254 loss)
I1211 22:13:01.775804 20404 sgd_solver.cpp:105] Iteration 154100, lr = 0.0001
I1211 22:13:09.760834 20404 solver.cpp:218] Iteration 154200 (12.524 iter/s, 7.98466s/100 iters), loss = 0.0184636
I1211 22:13:09.760834 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:09.760834 20404 solver.cpp:237]     Train net output #1: loss = 0.0184639 (* 1 = 0.0184639 loss)
I1211 22:13:09.760834 20404 sgd_solver.cpp:105] Iteration 154200, lr = 0.0001
I1211 22:13:17.778895 20404 solver.cpp:218] Iteration 154300 (12.4724 iter/s, 8.01768s/100 iters), loss = 0.0114501
I1211 22:13:17.778895 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:17.778895 20404 solver.cpp:237]     Train net output #1: loss = 0.0114504 (* 1 = 0.0114504 loss)
I1211 22:13:17.778895 20404 sgd_solver.cpp:105] Iteration 154300, lr = 0.0001
I1211 22:13:25.866350 20404 solver.cpp:218] Iteration 154400 (12.3649 iter/s, 8.08742s/100 iters), loss = 0.00971297
I1211 22:13:25.866350 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:25.866350 20404 solver.cpp:237]     Train net output #1: loss = 0.00971325 (* 1 = 0.00971325 loss)
I1211 22:13:25.866350 20404 sgd_solver.cpp:105] Iteration 154400, lr = 0.0001
I1211 22:13:33.660878  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:13:33.979213 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154500.caffemodel
I1211 22:13:34.009201 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154500.solverstate
I1211 22:13:34.014212 20404 solver.cpp:330] Iteration 154500, Testing net (#0)
I1211 22:13:34.015218 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:13:35.701802  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:13:35.768828 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 22:13:35.768828 20404 solver.cpp:397]     Test net output #1: loss = 0.262789 (* 1 = 0.262789 loss)
I1211 22:13:35.842867 20404 solver.cpp:218] Iteration 154500 (10.0243 iter/s, 9.97579s/100 iters), loss = 0.0127164
I1211 22:13:35.842867 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:35.842867 20404 solver.cpp:237]     Train net output #1: loss = 0.0127166 (* 1 = 0.0127166 loss)
I1211 22:13:35.842867 20404 sgd_solver.cpp:105] Iteration 154500, lr = 0.0001
I1211 22:13:43.930058 20404 solver.cpp:218] Iteration 154600 (12.3662 iter/s, 8.08654s/100 iters), loss = 0.0118494
I1211 22:13:43.930058 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:43.930058 20404 solver.cpp:237]     Train net output #1: loss = 0.0118497 (* 1 = 0.0118497 loss)
I1211 22:13:43.930058 20404 sgd_solver.cpp:105] Iteration 154600, lr = 0.0001
I1211 22:13:52.130704 20404 solver.cpp:218] Iteration 154700 (12.1952 iter/s, 8.19992s/100 iters), loss = 0.015955
I1211 22:13:52.130704 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:13:52.130704 20404 solver.cpp:237]     Train net output #1: loss = 0.0159553 (* 1 = 0.0159553 loss)
I1211 22:13:52.130704 20404 sgd_solver.cpp:105] Iteration 154700, lr = 0.0001
I1211 22:14:00.189843 20404 solver.cpp:218] Iteration 154800 (12.4089 iter/s, 8.05874s/100 iters), loss = 0.0153106
I1211 22:14:00.189843 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:14:00.189843 20404 solver.cpp:237]     Train net output #1: loss = 0.0153108 (* 1 = 0.0153108 loss)
I1211 22:14:00.189843 20404 sgd_solver.cpp:105] Iteration 154800, lr = 0.0001
I1211 22:14:08.194365 20404 solver.cpp:218] Iteration 154900 (12.494 iter/s, 8.00385s/100 iters), loss = 0.0235441
I1211 22:14:08.194365 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:14:08.194365 20404 solver.cpp:237]     Train net output #1: loss = 0.0235443 (* 1 = 0.0235443 loss)
I1211 22:14:08.194365 20404 sgd_solver.cpp:105] Iteration 154900, lr = 0.0001
I1211 22:14:15.906404  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:14:16.235949 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155000.caffemodel
I1211 22:14:16.266451 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155000.solverstate
I1211 22:14:16.272454 20404 solver.cpp:330] Iteration 155000, Testing net (#0)
I1211 22:14:16.273452 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:14:17.973632  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:14:18.043133 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1211 22:14:18.043133 20404 solver.cpp:397]     Test net output #1: loss = 0.262698 (* 1 = 0.262698 loss)
I1211 22:14:18.119637 20404 solver.cpp:218] Iteration 155000 (10.0759 iter/s, 9.92471s/100 iters), loss = 0.0119198
I1211 22:14:18.119637 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:14:18.119637 20404 solver.cpp:237]     Train net output #1: loss = 0.0119201 (* 1 = 0.0119201 loss)
I1211 22:14:18.119637 20404 sgd_solver.cpp:105] Iteration 155000, lr = 0.0001
I1211 22:14:26.092136 20404 solver.cpp:218] Iteration 155100 (12.5442 iter/s, 7.97178s/100 iters), loss = 0.0107025
I1211 22:14:26.092136 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:14:26.092136 20404 solver.cpp:237]     Train net output #1: loss = 0.0107028 (* 1 = 0.0107028 loss)
I1211 22:14:26.092136 20404 sgd_solver.cpp:105] Iteration 155100, lr = 0.0001
I1211 22:14:34.193941 20404 solver.cpp:218] Iteration 155200 (12.3433 iter/s, 8.10157s/100 iters), loss = 0.0116866
I1211 22:14:34.193941 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:14:34.193941 20404 solver.cpp:237]     Train net output #1: loss = 0.0116868 (* 1 = 0.0116868 loss)
I1211 22:14:34.193941 20404 sgd_solver.cpp:105] Iteration 155200, lr = 0.0001
I1211 22:14:42.291961 20404 solver.cpp:218] Iteration 155300 (12.3503 iter/s, 8.09697s/100 iters), loss = 0.013208
I1211 22:14:42.291961 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:14:42.291961 20404 solver.cpp:237]     Train net output #1: loss = 0.0132082 (* 1 = 0.0132082 loss)
I1211 22:14:42.291961 20404 sgd_solver.cpp:105] Iteration 155300, lr = 0.0001
I1211 22:14:50.432164 20404 solver.cpp:218] Iteration 155400 (12.2847 iter/s, 8.14024s/100 iters), loss = 0.0142164
I1211 22:14:50.432164 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:14:50.432164 20404 solver.cpp:237]     Train net output #1: loss = 0.0142167 (* 1 = 0.0142167 loss)
I1211 22:14:50.432164 20404 sgd_solver.cpp:105] Iteration 155400, lr = 0.0001
I1211 22:14:58.042094  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:14:58.358150 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155500.caffemodel
I1211 22:14:58.388149 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155500.solverstate
I1211 22:14:58.394156 20404 solver.cpp:330] Iteration 155500, Testing net (#0)
I1211 22:14:58.394156 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:15:00.069353  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:15:00.136353 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 22:15:00.136353 20404 solver.cpp:397]     Test net output #1: loss = 0.261193 (* 1 = 0.261193 loss)
I1211 22:15:00.211359 20404 solver.cpp:218] Iteration 155500 (10.2265 iter/s, 9.77847s/100 iters), loss = 0.0105694
I1211 22:15:00.211359 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:00.211359 20404 solver.cpp:237]     Train net output #1: loss = 0.0105697 (* 1 = 0.0105697 loss)
I1211 22:15:00.211359 20404 sgd_solver.cpp:105] Iteration 155500, lr = 0.0001
I1211 22:15:08.346861 20404 solver.cpp:218] Iteration 155600 (12.2928 iter/s, 8.13483s/100 iters), loss = 0.00951227
I1211 22:15:08.346861 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:08.346861 20404 solver.cpp:237]     Train net output #1: loss = 0.00951254 (* 1 = 0.00951254 loss)
I1211 22:15:08.346861 20404 sgd_solver.cpp:105] Iteration 155600, lr = 0.0001
I1211 22:15:16.410297 20404 solver.cpp:218] Iteration 155700 (12.4027 iter/s, 8.06275s/100 iters), loss = 0.0120007
I1211 22:15:16.410297 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:16.410297 20404 solver.cpp:237]     Train net output #1: loss = 0.012001 (* 1 = 0.012001 loss)
I1211 22:15:16.410297 20404 sgd_solver.cpp:105] Iteration 155700, lr = 0.0001
I1211 22:15:24.557399 20404 solver.cpp:218] Iteration 155800 (12.2748 iter/s, 8.14679s/100 iters), loss = 0.00994025
I1211 22:15:24.557899 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:24.557899 20404 solver.cpp:237]     Train net output #1: loss = 0.00994052 (* 1 = 0.00994052 loss)
I1211 22:15:24.557899 20404 sgd_solver.cpp:105] Iteration 155800, lr = 0.0001
I1211 22:15:32.644830 20404 solver.cpp:218] Iteration 155900 (12.3657 iter/s, 8.08686s/100 iters), loss = 0.0113593
I1211 22:15:32.644830 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:32.644830 20404 solver.cpp:237]     Train net output #1: loss = 0.0113595 (* 1 = 0.0113595 loss)
I1211 22:15:32.644830 20404 sgd_solver.cpp:105] Iteration 155900, lr = 0.0001
I1211 22:15:40.336469  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:15:40.653920 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156000.caffemodel
I1211 22:15:40.681936 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156000.solverstate
I1211 22:15:40.687932 20404 solver.cpp:330] Iteration 156000, Testing net (#0)
I1211 22:15:40.687932 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:15:42.380416  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:15:42.446398 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 22:15:42.446398 20404 solver.cpp:397]     Test net output #1: loss = 0.26111 (* 1 = 0.26111 loss)
I1211 22:15:42.521131 20404 solver.cpp:218] Iteration 156000 (10.1262 iter/s, 9.87537s/100 iters), loss = 0.0109986
I1211 22:15:42.521131 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:42.521131 20404 solver.cpp:237]     Train net output #1: loss = 0.0109989 (* 1 = 0.0109989 loss)
I1211 22:15:42.521131 20404 sgd_solver.cpp:105] Iteration 156000, lr = 0.0001
I1211 22:15:50.540122 20404 solver.cpp:218] Iteration 156100 (12.471 iter/s, 8.01862s/100 iters), loss = 0.010105
I1211 22:15:50.540122 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:50.540122 20404 solver.cpp:237]     Train net output #1: loss = 0.0101053 (* 1 = 0.0101053 loss)
I1211 22:15:50.540122 20404 sgd_solver.cpp:105] Iteration 156100, lr = 0.0001
I1211 22:15:58.498718 20404 solver.cpp:218] Iteration 156200 (12.5657 iter/s, 7.95815s/100 iters), loss = 0.0152926
I1211 22:15:58.498718 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:15:58.498718 20404 solver.cpp:237]     Train net output #1: loss = 0.0152929 (* 1 = 0.0152929 loss)
I1211 22:15:58.498718 20404 sgd_solver.cpp:105] Iteration 156200, lr = 0.0001
I1211 22:16:06.539517 20404 solver.cpp:218] Iteration 156300 (12.4372 iter/s, 8.04041s/100 iters), loss = 0.0111426
I1211 22:16:06.539517 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:06.539517 20404 solver.cpp:237]     Train net output #1: loss = 0.0111429 (* 1 = 0.0111429 loss)
I1211 22:16:06.539517 20404 sgd_solver.cpp:105] Iteration 156300, lr = 0.0001
I1211 22:16:14.626555 20404 solver.cpp:218] Iteration 156400 (12.3668 iter/s, 8.08615s/100 iters), loss = 0.0147489
I1211 22:16:14.626555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:14.626555 20404 solver.cpp:237]     Train net output #1: loss = 0.0147492 (* 1 = 0.0147492 loss)
I1211 22:16:14.626555 20404 sgd_solver.cpp:105] Iteration 156400, lr = 0.0001
I1211 22:16:22.368072  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:16:22.685281 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156500.caffemodel
I1211 22:16:22.714280 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156500.solverstate
I1211 22:16:22.719295 20404 solver.cpp:330] Iteration 156500, Testing net (#0)
I1211 22:16:22.720280 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:16:24.434968  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:16:24.503959 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 22:16:24.503959 20404 solver.cpp:397]     Test net output #1: loss = 0.261095 (* 1 = 0.261095 loss)
I1211 22:16:24.580967 20404 solver.cpp:218] Iteration 156500 (10.0459 iter/s, 9.95429s/100 iters), loss = 0.0122065
I1211 22:16:24.580967 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:24.580967 20404 solver.cpp:237]     Train net output #1: loss = 0.0122068 (* 1 = 0.0122068 loss)
I1211 22:16:24.580967 20404 sgd_solver.cpp:105] Iteration 156500, lr = 0.0001
I1211 22:16:32.626044 20404 solver.cpp:218] Iteration 156600 (12.4304 iter/s, 8.04479s/100 iters), loss = 0.0132757
I1211 22:16:32.626044 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:32.626044 20404 solver.cpp:237]     Train net output #1: loss = 0.013276 (* 1 = 0.013276 loss)
I1211 22:16:32.626044 20404 sgd_solver.cpp:105] Iteration 156600, lr = 0.0001
I1211 22:16:40.603461 20404 solver.cpp:218] Iteration 156700 (12.5368 iter/s, 7.97653s/100 iters), loss = 0.010887
I1211 22:16:40.603461 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:40.603461 20404 solver.cpp:237]     Train net output #1: loss = 0.0108873 (* 1 = 0.0108873 loss)
I1211 22:16:40.603461 20404 sgd_solver.cpp:105] Iteration 156700, lr = 0.0001
I1211 22:16:48.637919 20404 solver.cpp:218] Iteration 156800 (12.4466 iter/s, 8.03431s/100 iters), loss = 0.010052
I1211 22:16:48.637919 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:48.637919 20404 solver.cpp:237]     Train net output #1: loss = 0.0100522 (* 1 = 0.0100522 loss)
I1211 22:16:48.637919 20404 sgd_solver.cpp:105] Iteration 156800, lr = 0.0001
I1211 22:16:56.743445 20404 solver.cpp:218] Iteration 156900 (12.3389 iter/s, 8.10444s/100 iters), loss = 0.0104475
I1211 22:16:56.743445 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:16:56.743445 20404 solver.cpp:237]     Train net output #1: loss = 0.0104477 (* 1 = 0.0104477 loss)
I1211 22:16:56.743445 20404 sgd_solver.cpp:105] Iteration 156900, lr = 0.0001
I1211 22:17:04.507967  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:17:04.823925 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157000.caffemodel
I1211 22:17:04.851924 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157000.solverstate
I1211 22:17:04.857925 20404 solver.cpp:330] Iteration 157000, Testing net (#0)
I1211 22:17:04.857925 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:17:06.535153  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:17:06.601874 20404 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 22:17:06.601874 20404 solver.cpp:397]     Test net output #1: loss = 0.261647 (* 1 = 0.261647 loss)
I1211 22:17:06.675875 20404 solver.cpp:218] Iteration 157000 (10.0683 iter/s, 9.93218s/100 iters), loss = 0.0127235
I1211 22:17:06.675875 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:06.675875 20404 solver.cpp:237]     Train net output #1: loss = 0.0127238 (* 1 = 0.0127238 loss)
I1211 22:17:06.675875 20404 sgd_solver.cpp:105] Iteration 157000, lr = 0.0001
I1211 22:17:14.703447 20404 solver.cpp:218] Iteration 157100 (12.4575 iter/s, 8.02726s/100 iters), loss = 0.00882913
I1211 22:17:14.703447 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:14.703447 20404 solver.cpp:237]     Train net output #1: loss = 0.00882941 (* 1 = 0.00882941 loss)
I1211 22:17:14.703447 20404 sgd_solver.cpp:105] Iteration 157100, lr = 0.0001
I1211 22:17:22.788759 20404 solver.cpp:218] Iteration 157200 (12.3698 iter/s, 8.08422s/100 iters), loss = 0.0114125
I1211 22:17:22.788759 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:22.788759 20404 solver.cpp:237]     Train net output #1: loss = 0.0114127 (* 1 = 0.0114127 loss)
I1211 22:17:22.788759 20404 sgd_solver.cpp:105] Iteration 157200, lr = 0.0001
I1211 22:17:30.812577 20404 solver.cpp:218] Iteration 157300 (12.4637 iter/s, 8.02333s/100 iters), loss = 0.011774
I1211 22:17:30.812577 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:30.812577 20404 solver.cpp:237]     Train net output #1: loss = 0.0117743 (* 1 = 0.0117743 loss)
I1211 22:17:30.812577 20404 sgd_solver.cpp:105] Iteration 157300, lr = 0.0001
I1211 22:17:38.892189 20404 solver.cpp:218] Iteration 157400 (12.3777 iter/s, 8.07902s/100 iters), loss = 0.0126491
I1211 22:17:38.892189 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:38.892189 20404 solver.cpp:237]     Train net output #1: loss = 0.0126494 (* 1 = 0.0126494 loss)
I1211 22:17:38.892189 20404 sgd_solver.cpp:105] Iteration 157400, lr = 0.0001
I1211 22:17:46.546034  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:17:46.865067 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157500.caffemodel
I1211 22:17:46.898072 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157500.solverstate
I1211 22:17:46.904582 20404 solver.cpp:330] Iteration 157500, Testing net (#0)
I1211 22:17:46.904582 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:17:48.596729  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:17:48.664232 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 22:17:48.664232 20404 solver.cpp:397]     Test net output #1: loss = 0.262219 (* 1 = 0.262219 loss)
I1211 22:17:48.738235 20404 solver.cpp:218] Iteration 157500 (10.1567 iter/s, 9.84573s/100 iters), loss = 0.0141052
I1211 22:17:48.738235 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:48.738235 20404 solver.cpp:237]     Train net output #1: loss = 0.0141055 (* 1 = 0.0141055 loss)
I1211 22:17:48.738235 20404 sgd_solver.cpp:105] Iteration 157500, lr = 0.0001
I1211 22:17:56.805588 20404 solver.cpp:218] Iteration 157600 (12.3967 iter/s, 8.06665s/100 iters), loss = 0.0170526
I1211 22:17:56.805588 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:17:56.805588 20404 solver.cpp:237]     Train net output #1: loss = 0.0170529 (* 1 = 0.0170529 loss)
I1211 22:17:56.805588 20404 sgd_solver.cpp:105] Iteration 157600, lr = 0.0001
I1211 22:18:04.842488 20404 solver.cpp:218] Iteration 157700 (12.4431 iter/s, 8.03659s/100 iters), loss = 0.0154197
I1211 22:18:04.842488 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:18:04.842488 20404 solver.cpp:237]     Train net output #1: loss = 0.0154199 (* 1 = 0.0154199 loss)
I1211 22:18:04.842488 20404 sgd_solver.cpp:105] Iteration 157700, lr = 0.0001
I1211 22:18:12.822324 20404 solver.cpp:218] Iteration 157800 (12.5322 iter/s, 7.97944s/100 iters), loss = 0.00825674
I1211 22:18:12.822324 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:18:12.822324 20404 solver.cpp:237]     Train net output #1: loss = 0.00825702 (* 1 = 0.00825702 loss)
I1211 22:18:12.822324 20404 sgd_solver.cpp:105] Iteration 157800, lr = 0.0001
I1211 22:18:20.792610 20404 solver.cpp:218] Iteration 157900 (12.5473 iter/s, 7.96981s/100 iters), loss = 0.0105819
I1211 22:18:20.792610 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:18:20.792610 20404 solver.cpp:237]     Train net output #1: loss = 0.0105822 (* 1 = 0.0105822 loss)
I1211 22:18:20.792610 20404 sgd_solver.cpp:105] Iteration 157900, lr = 0.0001
I1211 22:18:28.461623  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:18:28.782395 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158000.caffemodel
I1211 22:18:28.809420 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158000.solverstate
I1211 22:18:28.815901 20404 solver.cpp:330] Iteration 158000, Testing net (#0)
I1211 22:18:28.816401 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:18:30.506955  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:18:30.574949 20404 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 22:18:30.574949 20404 solver.cpp:397]     Test net output #1: loss = 0.262204 (* 1 = 0.262204 loss)
I1211 22:18:30.648977 20404 solver.cpp:218] Iteration 158000 (10.1468 iter/s, 9.85537s/100 iters), loss = 0.0125123
I1211 22:18:30.648977 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:18:30.648977 20404 solver.cpp:237]     Train net output #1: loss = 0.0125125 (* 1 = 0.0125125 loss)
I1211 22:18:30.648977 20404 sgd_solver.cpp:105] Iteration 158000, lr = 0.0001
I1211 22:18:38.668057 20404 solver.cpp:218] Iteration 158100 (12.47 iter/s, 8.01926s/100 iters), loss = 0.0100864
I1211 22:18:38.668057 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:18:38.668057 20404 solver.cpp:237]     Train net output #1: loss = 0.0100867 (* 1 = 0.0100867 loss)
I1211 22:18:38.668057 20404 sgd_solver.cpp:105] Iteration 158100, lr = 0.0001
I1211 22:18:46.712448 20404 solver.cpp:218] Iteration 158200 (12.4326 iter/s, 8.04338s/100 iters), loss = 0.0150974
I1211 22:18:46.712448 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:18:46.712448 20404 solver.cpp:237]     Train net output #1: loss = 0.0150977 (* 1 = 0.0150977 loss)
I1211 22:18:46.712448 20404 sgd_solver.cpp:105] Iteration 158200, lr = 0.0001
I1211 22:18:54.686662 20404 solver.cpp:218] Iteration 158300 (12.5415 iter/s, 7.97353s/100 iters), loss = 0.0160705
I1211 22:18:54.686662 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:18:54.686662 20404 solver.cpp:237]     Train net output #1: loss = 0.0160708 (* 1 = 0.0160708 loss)
I1211 22:18:54.686662 20404 sgd_solver.cpp:105] Iteration 158300, lr = 0.0001
I1211 22:19:02.743295 20404 solver.cpp:218] Iteration 158400 (12.4117 iter/s, 8.05693s/100 iters), loss = 0.0135555
I1211 22:19:02.744295 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:02.744295 20404 solver.cpp:237]     Train net output #1: loss = 0.0135558 (* 1 = 0.0135558 loss)
I1211 22:19:02.744295 20404 sgd_solver.cpp:105] Iteration 158400, lr = 0.0001
I1211 22:19:10.417191  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:19:10.730746 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158500.caffemodel
I1211 22:19:10.758855 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158500.solverstate
I1211 22:19:10.764854 20404 solver.cpp:330] Iteration 158500, Testing net (#0)
I1211 22:19:10.764854 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:19:12.440770  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:19:12.506765 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 22:19:12.506765 20404 solver.cpp:397]     Test net output #1: loss = 0.261656 (* 1 = 0.261656 loss)
I1211 22:19:12.581804 20404 solver.cpp:218] Iteration 158500 (10.1655 iter/s, 9.83719s/100 iters), loss = 0.0105362
I1211 22:19:12.581804 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:12.581804 20404 solver.cpp:237]     Train net output #1: loss = 0.0105365 (* 1 = 0.0105365 loss)
I1211 22:19:12.581804 20404 sgd_solver.cpp:105] Iteration 158500, lr = 0.0001
I1211 22:19:20.705477 20404 solver.cpp:218] Iteration 158600 (12.3109 iter/s, 8.12291s/100 iters), loss = 0.0126942
I1211 22:19:20.705477 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:20.705477 20404 solver.cpp:237]     Train net output #1: loss = 0.0126945 (* 1 = 0.0126945 loss)
I1211 22:19:20.705477 20404 sgd_solver.cpp:105] Iteration 158600, lr = 0.0001
I1211 22:19:28.873070 20404 solver.cpp:218] Iteration 158700 (12.2435 iter/s, 8.16763s/100 iters), loss = 0.0104915
I1211 22:19:28.873070 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:28.873070 20404 solver.cpp:237]     Train net output #1: loss = 0.0104918 (* 1 = 0.0104918 loss)
I1211 22:19:28.873070 20404 sgd_solver.cpp:105] Iteration 158700, lr = 0.0001
I1211 22:19:37.010118 20404 solver.cpp:218] Iteration 158800 (12.2899 iter/s, 8.13676s/100 iters), loss = 0.010396
I1211 22:19:37.010118 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:37.010118 20404 solver.cpp:237]     Train net output #1: loss = 0.0103963 (* 1 = 0.0103963 loss)
I1211 22:19:37.010118 20404 sgd_solver.cpp:105] Iteration 158800, lr = 0.0001
I1211 22:19:45.118074 20404 solver.cpp:218] Iteration 158900 (12.3355 iter/s, 8.10666s/100 iters), loss = 0.0101868
I1211 22:19:45.118074 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:45.118074 20404 solver.cpp:237]     Train net output #1: loss = 0.0101871 (* 1 = 0.0101871 loss)
I1211 22:19:45.118074 20404 sgd_solver.cpp:105] Iteration 158900, lr = 0.0001
I1211 22:19:52.796800  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:19:53.110303 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159000.caffemodel
I1211 22:19:53.139305 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159000.solverstate
I1211 22:19:53.145309 20404 solver.cpp:330] Iteration 159000, Testing net (#0)
I1211 22:19:53.145309 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:19:54.847281  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:19:54.913252 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 22:19:54.913252 20404 solver.cpp:397]     Test net output #1: loss = 0.26082 (* 1 = 0.26082 loss)
I1211 22:19:54.988278 20404 solver.cpp:218] Iteration 159000 (10.1315 iter/s, 9.8702s/100 iters), loss = 0.0144793
I1211 22:19:54.988278 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:19:54.988278 20404 solver.cpp:237]     Train net output #1: loss = 0.0144796 (* 1 = 0.0144796 loss)
I1211 22:19:54.988278 20404 sgd_solver.cpp:105] Iteration 159000, lr = 0.0001
I1211 22:20:03.055862 20404 solver.cpp:218] Iteration 159100 (12.3968 iter/s, 8.06657s/100 iters), loss = 0.0149791
I1211 22:20:03.055862 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:03.055862 20404 solver.cpp:237]     Train net output #1: loss = 0.0149794 (* 1 = 0.0149794 loss)
I1211 22:20:03.055862 20404 sgd_solver.cpp:105] Iteration 159100, lr = 0.0001
I1211 22:20:11.085443 20404 solver.cpp:218] Iteration 159200 (12.4538 iter/s, 8.02969s/100 iters), loss = 0.0111642
I1211 22:20:11.085443 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:11.085443 20404 solver.cpp:237]     Train net output #1: loss = 0.0111645 (* 1 = 0.0111645 loss)
I1211 22:20:11.085443 20404 sgd_solver.cpp:105] Iteration 159200, lr = 0.0001
I1211 22:20:19.117110 20404 solver.cpp:218] Iteration 159300 (12.452 iter/s, 8.03082s/100 iters), loss = 0.0121779
I1211 22:20:19.117110 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:19.117110 20404 solver.cpp:237]     Train net output #1: loss = 0.0121782 (* 1 = 0.0121782 loss)
I1211 22:20:19.117110 20404 sgd_solver.cpp:105] Iteration 159300, lr = 0.0001
I1211 22:20:27.118834 20404 solver.cpp:218] Iteration 159400 (12.4977 iter/s, 8.00144s/100 iters), loss = 0.0216755
I1211 22:20:27.118834 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:27.118834 20404 solver.cpp:237]     Train net output #1: loss = 0.0216758 (* 1 = 0.0216758 loss)
I1211 22:20:27.118834 20404 sgd_solver.cpp:105] Iteration 159400, lr = 0.0001
I1211 22:20:34.789082  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:20:35.104831 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159500.caffemodel
I1211 22:20:35.142828 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159500.solverstate
I1211 22:20:35.149827 20404 solver.cpp:330] Iteration 159500, Testing net (#0)
I1211 22:20:35.149827 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:20:36.829744  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:20:36.896772 20404 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 22:20:36.896772 20404 solver.cpp:397]     Test net output #1: loss = 0.261079 (* 1 = 0.261079 loss)
I1211 22:20:36.970798 20404 solver.cpp:218] Iteration 159500 (10.1515 iter/s, 9.85079s/100 iters), loss = 0.0119407
I1211 22:20:36.970798 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:36.970798 20404 solver.cpp:237]     Train net output #1: loss = 0.0119409 (* 1 = 0.0119409 loss)
I1211 22:20:36.970798 20404 sgd_solver.cpp:105] Iteration 159500, lr = 0.0001
I1211 22:20:45.060183 20404 solver.cpp:218] Iteration 159600 (12.3629 iter/s, 8.08875s/100 iters), loss = 0.0144701
I1211 22:20:45.060183 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:45.060183 20404 solver.cpp:237]     Train net output #1: loss = 0.0144704 (* 1 = 0.0144704 loss)
I1211 22:20:45.060183 20404 sgd_solver.cpp:105] Iteration 159600, lr = 0.0001
I1211 22:20:53.152149 20404 solver.cpp:218] Iteration 159700 (12.3587 iter/s, 8.09148s/100 iters), loss = 0.0111112
I1211 22:20:53.152149 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:20:53.152149 20404 solver.cpp:237]     Train net output #1: loss = 0.0111115 (* 1 = 0.0111115 loss)
I1211 22:20:53.152149 20404 sgd_solver.cpp:105] Iteration 159700, lr = 0.0001
I1211 22:21:01.298715 20404 solver.cpp:218] Iteration 159800 (12.2747 iter/s, 8.14683s/100 iters), loss = 0.00943863
I1211 22:21:01.299716 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:21:01.299716 20404 solver.cpp:237]     Train net output #1: loss = 0.00943891 (* 1 = 0.00943891 loss)
I1211 22:21:01.299716 20404 sgd_solver.cpp:105] Iteration 159800, lr = 0.0001
I1211 22:21:09.429005 20404 solver.cpp:218] Iteration 159900 (12.3015 iter/s, 8.1291s/100 iters), loss = 0.0105761
I1211 22:21:09.429005 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:21:09.429005 20404 solver.cpp:237]     Train net output #1: loss = 0.0105763 (* 1 = 0.0105763 loss)
I1211 22:21:09.429005 20404 sgd_solver.cpp:105] Iteration 159900, lr = 0.0001
I1211 22:21:17.021914  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:21:17.339956 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160000.caffemodel
I1211 22:21:17.369493 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160000.solverstate
I1211 22:21:17.375481 20404 solver.cpp:330] Iteration 160000, Testing net (#0)
I1211 22:21:17.375977 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:21:19.078693  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:21:19.146208 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1211 22:21:19.146208 20404 solver.cpp:397]     Test net output #1: loss = 0.260709 (* 1 = 0.260709 loss)
I1211 22:21:19.227219 20404 solver.cpp:218] Iteration 160000 (10.2067 iter/s, 9.7975s/100 iters), loss = 0.0138243
I1211 22:21:19.227219 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:21:19.227219 20404 solver.cpp:237]     Train net output #1: loss = 0.0138245 (* 1 = 0.0138245 loss)
I1211 22:21:19.227219 20404 sgd_solver.cpp:105] Iteration 160000, lr = 0.0001
I1211 22:21:27.326071 20404 solver.cpp:218] Iteration 160100 (12.348 iter/s, 8.09845s/100 iters), loss = 0.0222849
I1211 22:21:27.326071 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:21:27.326071 20404 solver.cpp:237]     Train net output #1: loss = 0.0222852 (* 1 = 0.0222852 loss)
I1211 22:21:27.326071 20404 sgd_solver.cpp:105] Iteration 160100, lr = 0.0001
I1211 22:21:35.319767 20404 solver.cpp:218] Iteration 160200 (12.5095 iter/s, 7.99393s/100 iters), loss = 0.0125842
I1211 22:21:35.320768 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:21:35.320768 20404 solver.cpp:237]     Train net output #1: loss = 0.0125845 (* 1 = 0.0125845 loss)
I1211 22:21:35.320768 20404 sgd_solver.cpp:105] Iteration 160200, lr = 0.0001
I1211 22:21:43.354861 20404 solver.cpp:218] Iteration 160300 (12.4462 iter/s, 8.03455s/100 iters), loss = 0.0129114
I1211 22:21:43.355861 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:21:43.355861 20404 solver.cpp:237]     Train net output #1: loss = 0.0129117 (* 1 = 0.0129117 loss)
I1211 22:21:43.355861 20404 sgd_solver.cpp:105] Iteration 160300, lr = 0.0001
I1211 22:21:51.458956 20404 solver.cpp:218] Iteration 160400 (12.3405 iter/s, 8.10337s/100 iters), loss = 0.0107858
I1211 22:21:51.458956 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:21:51.458956 20404 solver.cpp:237]     Train net output #1: loss = 0.0107861 (* 1 = 0.0107861 loss)
I1211 22:21:51.458956 20404 sgd_solver.cpp:105] Iteration 160400, lr = 0.0001
I1211 22:21:59.061480  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:21:59.376852 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160500.caffemodel
I1211 22:21:59.411417 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160500.solverstate
I1211 22:21:59.418416 20404 solver.cpp:330] Iteration 160500, Testing net (#0)
I1211 22:21:59.418416 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:22:01.092114  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:22:01.157632 20404 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 22:22:01.157632 20404 solver.cpp:397]     Test net output #1: loss = 0.261545 (* 1 = 0.261545 loss)
I1211 22:22:01.232659 20404 solver.cpp:218] Iteration 160500 (10.2323 iter/s, 9.77298s/100 iters), loss = 0.0131223
I1211 22:22:01.232659 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:01.232659 20404 solver.cpp:237]     Train net output #1: loss = 0.0131226 (* 1 = 0.0131226 loss)
I1211 22:22:01.232659 20404 sgd_solver.cpp:105] Iteration 160500, lr = 0.0001
I1211 22:22:09.229696 20404 solver.cpp:218] Iteration 160600 (12.5056 iter/s, 7.99643s/100 iters), loss = 0.0164914
I1211 22:22:09.229696 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:09.229696 20404 solver.cpp:237]     Train net output #1: loss = 0.0164917 (* 1 = 0.0164917 loss)
I1211 22:22:09.229696 20404 sgd_solver.cpp:105] Iteration 160600, lr = 0.0001
I1211 22:22:17.247946 20404 solver.cpp:218] Iteration 160700 (12.472 iter/s, 8.01799s/100 iters), loss = 0.0109451
I1211 22:22:17.247946 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:17.247946 20404 solver.cpp:237]     Train net output #1: loss = 0.0109453 (* 1 = 0.0109453 loss)
I1211 22:22:17.247946 20404 sgd_solver.cpp:105] Iteration 160700, lr = 0.0001
I1211 22:22:25.282661 20404 solver.cpp:218] Iteration 160800 (12.4472 iter/s, 8.03392s/100 iters), loss = 0.00962379
I1211 22:22:25.282661 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:25.282661 20404 solver.cpp:237]     Train net output #1: loss = 0.00962407 (* 1 = 0.00962407 loss)
I1211 22:22:25.282661 20404 sgd_solver.cpp:105] Iteration 160800, lr = 0.0001
I1211 22:22:33.286187 20404 solver.cpp:218] Iteration 160900 (12.4962 iter/s, 8.00246s/100 iters), loss = 0.0101922
I1211 22:22:33.286187 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:33.286187 20404 solver.cpp:237]     Train net output #1: loss = 0.0101925 (* 1 = 0.0101925 loss)
I1211 22:22:33.286187 20404 sgd_solver.cpp:105] Iteration 160900, lr = 0.0001
I1211 22:22:40.857480  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:22:41.172504 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161000.caffemodel
I1211 22:22:41.203040 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161000.solverstate
I1211 22:22:41.209527 20404 solver.cpp:330] Iteration 161000, Testing net (#0)
I1211 22:22:41.209527 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:22:42.882539  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:22:42.949545 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1211 22:22:42.949545 20404 solver.cpp:397]     Test net output #1: loss = 0.26238 (* 1 = 0.26238 loss)
I1211 22:22:43.023555 20404 solver.cpp:218] Iteration 161000 (10.2697 iter/s, 9.73734s/100 iters), loss = 0.0115003
I1211 22:22:43.023555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:43.023555 20404 solver.cpp:237]     Train net output #1: loss = 0.0115005 (* 1 = 0.0115005 loss)
I1211 22:22:43.023555 20404 sgd_solver.cpp:105] Iteration 161000, lr = 0.0001
I1211 22:22:51.029669 20404 solver.cpp:218] Iteration 161100 (12.4911 iter/s, 8.00571s/100 iters), loss = 0.00972986
I1211 22:22:51.030668 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:51.030668 20404 solver.cpp:237]     Train net output #1: loss = 0.00973015 (* 1 = 0.00973015 loss)
I1211 22:22:51.030668 20404 sgd_solver.cpp:105] Iteration 161100, lr = 0.0001
I1211 22:22:59.030661 20404 solver.cpp:218] Iteration 161200 (12.5001 iter/s, 7.99996s/100 iters), loss = 0.0163174
I1211 22:22:59.030661 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:22:59.030661 20404 solver.cpp:237]     Train net output #1: loss = 0.0163177 (* 1 = 0.0163177 loss)
I1211 22:22:59.030661 20404 sgd_solver.cpp:105] Iteration 161200, lr = 0.0001
I1211 22:23:07.085870 20404 solver.cpp:218] Iteration 161300 (12.4151 iter/s, 8.05474s/100 iters), loss = 0.0103931
I1211 22:23:07.085870 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:07.085870 20404 solver.cpp:237]     Train net output #1: loss = 0.0103934 (* 1 = 0.0103934 loss)
I1211 22:23:07.085870 20404 sgd_solver.cpp:105] Iteration 161300, lr = 0.0001
I1211 22:23:15.140616 20404 solver.cpp:218] Iteration 161400 (12.4158 iter/s, 8.05425s/100 iters), loss = 0.0147977
I1211 22:23:15.140616 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:15.140616 20404 solver.cpp:237]     Train net output #1: loss = 0.014798 (* 1 = 0.014798 loss)
I1211 22:23:15.140616 20404 sgd_solver.cpp:105] Iteration 161400, lr = 0.0001
I1211 22:23:22.722523  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:23:23.038796 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161500.caffemodel
I1211 22:23:23.067785 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161500.solverstate
I1211 22:23:23.073784 20404 solver.cpp:330] Iteration 161500, Testing net (#0)
I1211 22:23:23.074786 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:23:24.764102  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:23:24.832234 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 22:23:24.832234 20404 solver.cpp:397]     Test net output #1: loss = 0.262604 (* 1 = 0.262604 loss)
I1211 22:23:24.906760 20404 solver.cpp:218] Iteration 161500 (10.2405 iter/s, 9.76516s/100 iters), loss = 0.0153621
I1211 22:23:24.906760 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:24.906760 20404 solver.cpp:237]     Train net output #1: loss = 0.0153624 (* 1 = 0.0153624 loss)
I1211 22:23:24.906760 20404 sgd_solver.cpp:105] Iteration 161500, lr = 0.0001
I1211 22:23:32.910317 20404 solver.cpp:218] Iteration 161600 (12.4946 iter/s, 8.00343s/100 iters), loss = 0.0116837
I1211 22:23:32.910817 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:32.910817 20404 solver.cpp:237]     Train net output #1: loss = 0.0116839 (* 1 = 0.0116839 loss)
I1211 22:23:32.910817 20404 sgd_solver.cpp:105] Iteration 161600, lr = 0.0001
I1211 22:23:40.896849 20404 solver.cpp:218] Iteration 161700 (12.522 iter/s, 7.98597s/100 iters), loss = 0.00938118
I1211 22:23:40.896849 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:40.896849 20404 solver.cpp:237]     Train net output #1: loss = 0.00938146 (* 1 = 0.00938146 loss)
I1211 22:23:40.896849 20404 sgd_solver.cpp:105] Iteration 161700, lr = 0.0001
I1211 22:23:48.896315 20404 solver.cpp:218] Iteration 161800 (12.5017 iter/s, 7.9989s/100 iters), loss = 0.00875092
I1211 22:23:48.896315 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:48.896315 20404 solver.cpp:237]     Train net output #1: loss = 0.0087512 (* 1 = 0.0087512 loss)
I1211 22:23:48.896315 20404 sgd_solver.cpp:105] Iteration 161800, lr = 0.0001
I1211 22:23:56.881070 20404 solver.cpp:218] Iteration 161900 (12.5241 iter/s, 7.98462s/100 iters), loss = 0.015199
I1211 22:23:56.881070 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:23:56.881070 20404 solver.cpp:237]     Train net output #1: loss = 0.0151993 (* 1 = 0.0151993 loss)
I1211 22:23:56.881070 20404 sgd_solver.cpp:105] Iteration 161900, lr = 0.0001
I1211 22:24:04.501776  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:24:04.814690 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162000.caffemodel
I1211 22:24:04.841195 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162000.solverstate
I1211 22:24:04.847194 20404 solver.cpp:330] Iteration 162000, Testing net (#0)
I1211 22:24:04.848197 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:24:06.520349  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:24:06.587348 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 22:24:06.587348 20404 solver.cpp:397]     Test net output #1: loss = 0.261647 (* 1 = 0.261647 loss)
I1211 22:24:06.661353 20404 solver.cpp:218] Iteration 162000 (10.2256 iter/s, 9.77935s/100 iters), loss = 0.0178123
I1211 22:24:06.661353 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:06.661353 20404 solver.cpp:237]     Train net output #1: loss = 0.0178126 (* 1 = 0.0178126 loss)
I1211 22:24:06.661353 20404 sgd_solver.cpp:105] Iteration 162000, lr = 0.0001
I1211 22:24:14.735442 20404 solver.cpp:218] Iteration 162100 (12.3852 iter/s, 8.07415s/100 iters), loss = 0.0107053
I1211 22:24:14.735442 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:14.735442 20404 solver.cpp:237]     Train net output #1: loss = 0.0107056 (* 1 = 0.0107056 loss)
I1211 22:24:14.736443 20404 sgd_solver.cpp:105] Iteration 162100, lr = 0.0001
I1211 22:24:22.798003 20404 solver.cpp:218] Iteration 162200 (12.404 iter/s, 8.06192s/100 iters), loss = 0.0100503
I1211 22:24:22.798003 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:22.798003 20404 solver.cpp:237]     Train net output #1: loss = 0.0100506 (* 1 = 0.0100506 loss)
I1211 22:24:22.798003 20404 sgd_solver.cpp:105] Iteration 162200, lr = 0.0001
I1211 22:24:30.916844 20404 solver.cpp:218] Iteration 162300 (12.3188 iter/s, 8.11765s/100 iters), loss = 0.0147908
I1211 22:24:30.916844 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:30.916844 20404 solver.cpp:237]     Train net output #1: loss = 0.0147911 (* 1 = 0.0147911 loss)
I1211 22:24:30.916844 20404 sgd_solver.cpp:105] Iteration 162300, lr = 0.0001
I1211 22:24:39.075626 20404 solver.cpp:218] Iteration 162400 (12.2579 iter/s, 8.15804s/100 iters), loss = 0.0120475
I1211 22:24:39.075626 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:39.075626 20404 solver.cpp:237]     Train net output #1: loss = 0.0120478 (* 1 = 0.0120478 loss)
I1211 22:24:39.075626 20404 sgd_solver.cpp:105] Iteration 162400, lr = 0.0001
I1211 22:24:46.729744  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:24:47.048836 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162500.caffemodel
I1211 22:24:47.088835 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162500.solverstate
I1211 22:24:47.095819 20404 solver.cpp:330] Iteration 162500, Testing net (#0)
I1211 22:24:47.095819 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:24:48.775317  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:24:48.842332 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1211 22:24:48.842332 20404 solver.cpp:397]     Test net output #1: loss = 0.261086 (* 1 = 0.261086 loss)
I1211 22:24:48.916323 20404 solver.cpp:218] Iteration 162500 (10.162 iter/s, 9.84054s/100 iters), loss = 0.014885
I1211 22:24:48.916323 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:48.916323 20404 solver.cpp:237]     Train net output #1: loss = 0.0148853 (* 1 = 0.0148853 loss)
I1211 22:24:48.916323 20404 sgd_solver.cpp:105] Iteration 162500, lr = 0.0001
I1211 22:24:56.926581 20404 solver.cpp:218] Iteration 162600 (12.485 iter/s, 8.00964s/100 iters), loss = 0.0116187
I1211 22:24:56.927080 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:24:56.927080 20404 solver.cpp:237]     Train net output #1: loss = 0.0116189 (* 1 = 0.0116189 loss)
I1211 22:24:56.927080 20404 sgd_solver.cpp:105] Iteration 162600, lr = 0.0001
I1211 22:25:04.975512 20404 solver.cpp:218] Iteration 162700 (12.4243 iter/s, 8.04873s/100 iters), loss = 0.0132082
I1211 22:25:04.975512 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:04.975512 20404 solver.cpp:237]     Train net output #1: loss = 0.0132085 (* 1 = 0.0132085 loss)
I1211 22:25:04.975512 20404 sgd_solver.cpp:105] Iteration 162700, lr = 0.0001
I1211 22:25:12.987211 20404 solver.cpp:218] Iteration 162800 (12.4823 iter/s, 8.01138s/100 iters), loss = 0.0107347
I1211 22:25:12.988212 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:12.988212 20404 solver.cpp:237]     Train net output #1: loss = 0.010735 (* 1 = 0.010735 loss)
I1211 22:25:12.988212 20404 sgd_solver.cpp:105] Iteration 162800, lr = 0.0001
I1211 22:25:20.954329 20404 solver.cpp:218] Iteration 162900 (12.5531 iter/s, 7.96615s/100 iters), loss = 0.0146767
I1211 22:25:20.954329 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:20.954329 20404 solver.cpp:237]     Train net output #1: loss = 0.014677 (* 1 = 0.014677 loss)
I1211 22:25:20.954329 20404 sgd_solver.cpp:105] Iteration 162900, lr = 0.0001
I1211 22:25:28.563530  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:25:28.880453 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163000.caffemodel
I1211 22:25:28.921453 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163000.solverstate
I1211 22:25:28.929455 20404 solver.cpp:330] Iteration 163000, Testing net (#0)
I1211 22:25:28.929455 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:25:30.615701  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:25:30.682713 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 22:25:30.682713 20404 solver.cpp:397]     Test net output #1: loss = 0.261243 (* 1 = 0.261243 loss)
I1211 22:25:30.758733 20404 solver.cpp:218] Iteration 163000 (10.1998 iter/s, 9.8041s/100 iters), loss = 0.0102034
I1211 22:25:30.758733 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:30.758733 20404 solver.cpp:237]     Train net output #1: loss = 0.0102037 (* 1 = 0.0102037 loss)
I1211 22:25:30.758733 20404 sgd_solver.cpp:105] Iteration 163000, lr = 0.0001
I1211 22:25:38.801568 20404 solver.cpp:218] Iteration 163100 (12.4342 iter/s, 8.04234s/100 iters), loss = 0.0120375
I1211 22:25:38.801568 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:38.801568 20404 solver.cpp:237]     Train net output #1: loss = 0.0120377 (* 1 = 0.0120377 loss)
I1211 22:25:38.801568 20404 sgd_solver.cpp:105] Iteration 163100, lr = 0.0001
I1211 22:25:46.887089 20404 solver.cpp:218] Iteration 163200 (12.3689 iter/s, 8.08476s/100 iters), loss = 0.0108269
I1211 22:25:46.887089 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:46.887089 20404 solver.cpp:237]     Train net output #1: loss = 0.0108272 (* 1 = 0.0108272 loss)
I1211 22:25:46.887089 20404 sgd_solver.cpp:105] Iteration 163200, lr = 0.0001
I1211 22:25:54.924953 20404 solver.cpp:218] Iteration 163300 (12.4429 iter/s, 8.03672s/100 iters), loss = 0.0118378
I1211 22:25:54.924953 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:25:54.924953 20404 solver.cpp:237]     Train net output #1: loss = 0.0118381 (* 1 = 0.0118381 loss)
I1211 22:25:54.924953 20404 sgd_solver.cpp:105] Iteration 163300, lr = 0.0001
I1211 22:26:02.954639 20404 solver.cpp:218] Iteration 163400 (12.4542 iter/s, 8.02939s/100 iters), loss = 0.0113544
I1211 22:26:02.955140 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:02.955140 20404 solver.cpp:237]     Train net output #1: loss = 0.0113547 (* 1 = 0.0113547 loss)
I1211 22:26:02.955140 20404 sgd_solver.cpp:105] Iteration 163400, lr = 0.0001
I1211 22:26:10.627002  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:26:10.942062 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163500.caffemodel
I1211 22:26:10.971081 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163500.solverstate
I1211 22:26:10.977071 20404 solver.cpp:330] Iteration 163500, Testing net (#0)
I1211 22:26:10.977071 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:26:12.653913  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:26:12.719414 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 22:26:12.719414 20404 solver.cpp:397]     Test net output #1: loss = 0.261864 (* 1 = 0.261864 loss)
I1211 22:26:12.794437 20404 solver.cpp:218] Iteration 163500 (10.1633 iter/s, 9.83928s/100 iters), loss = 0.0202949
I1211 22:26:12.794437 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:12.794437 20404 solver.cpp:237]     Train net output #1: loss = 0.0202952 (* 1 = 0.0202952 loss)
I1211 22:26:12.794437 20404 sgd_solver.cpp:105] Iteration 163500, lr = 0.0001
I1211 22:26:20.755347 20404 solver.cpp:218] Iteration 163600 (12.5622 iter/s, 7.96038s/100 iters), loss = 0.0118809
I1211 22:26:20.755347 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:20.755847 20404 solver.cpp:237]     Train net output #1: loss = 0.0118811 (* 1 = 0.0118811 loss)
I1211 22:26:20.755847 20404 sgd_solver.cpp:105] Iteration 163600, lr = 0.0001
I1211 22:26:28.718585 20404 solver.cpp:218] Iteration 163700 (12.5591 iter/s, 7.96237s/100 iters), loss = 0.0105934
I1211 22:26:28.718585 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:28.718585 20404 solver.cpp:237]     Train net output #1: loss = 0.0105937 (* 1 = 0.0105937 loss)
I1211 22:26:28.718585 20404 sgd_solver.cpp:105] Iteration 163700, lr = 0.0001
I1211 22:26:36.683078 20404 solver.cpp:218] Iteration 163800 (12.5561 iter/s, 7.96425s/100 iters), loss = 0.00979276
I1211 22:26:36.683078 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:36.683078 20404 solver.cpp:237]     Train net output #1: loss = 0.00979304 (* 1 = 0.00979304 loss)
I1211 22:26:36.683078 20404 sgd_solver.cpp:105] Iteration 163800, lr = 0.0001
I1211 22:26:44.642247 20404 solver.cpp:218] Iteration 163900 (12.5646 iter/s, 7.9589s/100 iters), loss = 0.0122635
I1211 22:26:44.642247 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:44.642247 20404 solver.cpp:237]     Train net output #1: loss = 0.0122638 (* 1 = 0.0122638 loss)
I1211 22:26:44.642247 20404 sgd_solver.cpp:105] Iteration 163900, lr = 0.0001
I1211 22:26:52.214687  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:26:52.532006 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164000.caffemodel
I1211 22:26:52.571009 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164000.solverstate
I1211 22:26:52.577509 20404 solver.cpp:330] Iteration 164000, Testing net (#0)
I1211 22:26:52.577509 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:26:54.250289  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:26:54.318567 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 22:26:54.318567 20404 solver.cpp:397]     Test net output #1: loss = 0.262039 (* 1 = 0.262039 loss)
I1211 22:26:54.392891 20404 solver.cpp:218] Iteration 164000 (10.2565 iter/s, 9.74993s/100 iters), loss = 0.0135897
I1211 22:26:54.392891 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:26:54.392891 20404 solver.cpp:237]     Train net output #1: loss = 0.0135899 (* 1 = 0.0135899 loss)
I1211 22:26:54.392891 20404 sgd_solver.cpp:105] Iteration 164000, lr = 0.0001
I1211 22:27:02.431641 20404 solver.cpp:218] Iteration 164100 (12.4398 iter/s, 8.0387s/100 iters), loss = 0.0120007
I1211 22:27:02.431641 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:02.431641 20404 solver.cpp:237]     Train net output #1: loss = 0.012001 (* 1 = 0.012001 loss)
I1211 22:27:02.431641 20404 sgd_solver.cpp:105] Iteration 164100, lr = 0.0001
I1211 22:27:10.452531 20404 solver.cpp:218] Iteration 164200 (12.4683 iter/s, 8.02037s/100 iters), loss = 0.0139082
I1211 22:27:10.452531 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:10.452531 20404 solver.cpp:237]     Train net output #1: loss = 0.0139085 (* 1 = 0.0139085 loss)
I1211 22:27:10.452531 20404 sgd_solver.cpp:105] Iteration 164200, lr = 0.0001
I1211 22:27:18.524590 20404 solver.cpp:218] Iteration 164300 (12.3897 iter/s, 8.07122s/100 iters), loss = 0.01177
I1211 22:27:18.524590 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:18.524590 20404 solver.cpp:237]     Train net output #1: loss = 0.0117703 (* 1 = 0.0117703 loss)
I1211 22:27:18.524590 20404 sgd_solver.cpp:105] Iteration 164300, lr = 0.0001
I1211 22:27:26.564647 20404 solver.cpp:218] Iteration 164400 (12.4388 iter/s, 8.03936s/100 iters), loss = 0.0095855
I1211 22:27:26.564647 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:26.564647 20404 solver.cpp:237]     Train net output #1: loss = 0.00958577 (* 1 = 0.00958577 loss)
I1211 22:27:26.564647 20404 sgd_solver.cpp:105] Iteration 164400, lr = 0.0001
I1211 22:27:34.152663  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:27:34.470301 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164500.caffemodel
I1211 22:27:34.498812 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164500.solverstate
I1211 22:27:34.504812 20404 solver.cpp:330] Iteration 164500, Testing net (#0)
I1211 22:27:34.505808 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:27:36.192804  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:27:36.260805 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 22:27:36.260805 20404 solver.cpp:397]     Test net output #1: loss = 0.26196 (* 1 = 0.26196 loss)
I1211 22:27:36.335816 20404 solver.cpp:218] Iteration 164500 (10.2343 iter/s, 9.77107s/100 iters), loss = 0.0130855
I1211 22:27:36.335816 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:36.335816 20404 solver.cpp:237]     Train net output #1: loss = 0.0130857 (* 1 = 0.0130857 loss)
I1211 22:27:36.335816 20404 sgd_solver.cpp:105] Iteration 164500, lr = 0.0001
I1211 22:27:44.362285 20404 solver.cpp:218] Iteration 164600 (12.4602 iter/s, 8.02553s/100 iters), loss = 0.0125097
I1211 22:27:44.362285 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:44.362285 20404 solver.cpp:237]     Train net output #1: loss = 0.0125099 (* 1 = 0.0125099 loss)
I1211 22:27:44.362285 20404 sgd_solver.cpp:105] Iteration 164600, lr = 0.0001
I1211 22:27:52.374306 20404 solver.cpp:218] Iteration 164700 (12.4818 iter/s, 8.01164s/100 iters), loss = 0.0147113
I1211 22:27:52.374306 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:27:52.374306 20404 solver.cpp:237]     Train net output #1: loss = 0.0147116 (* 1 = 0.0147116 loss)
I1211 22:27:52.374306 20404 sgd_solver.cpp:105] Iteration 164700, lr = 0.0001
I1211 22:28:00.329298 20404 solver.cpp:218] Iteration 164800 (12.5711 iter/s, 7.95476s/100 iters), loss = 0.0139125
I1211 22:28:00.329298 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:00.329298 20404 solver.cpp:237]     Train net output #1: loss = 0.0139128 (* 1 = 0.0139128 loss)
I1211 22:28:00.329298 20404 sgd_solver.cpp:105] Iteration 164800, lr = 0.0001
I1211 22:28:08.300806 20404 solver.cpp:218] Iteration 164900 (12.5462 iter/s, 7.97054s/100 iters), loss = 0.0110042
I1211 22:28:08.300806 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:08.300806 20404 solver.cpp:237]     Train net output #1: loss = 0.0110045 (* 1 = 0.0110045 loss)
I1211 22:28:08.300806 20404 sgd_solver.cpp:105] Iteration 164900, lr = 0.0001
I1211 22:28:15.877836  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:28:16.194355 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165000.caffemodel
I1211 22:28:16.222858 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165000.solverstate
I1211 22:28:16.228860 20404 solver.cpp:330] Iteration 165000, Testing net (#0)
I1211 22:28:16.228860 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:28:17.903468  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:28:17.968971 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 22:28:17.968971 20404 solver.cpp:397]     Test net output #1: loss = 0.261233 (* 1 = 0.261233 loss)
I1211 22:28:18.043979 20404 solver.cpp:218] Iteration 165000 (10.2644 iter/s, 9.74242s/100 iters), loss = 0.0175292
I1211 22:28:18.043979 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:18.043979 20404 solver.cpp:237]     Train net output #1: loss = 0.0175294 (* 1 = 0.0175294 loss)
I1211 22:28:18.043979 20404 sgd_solver.cpp:105] Iteration 165000, lr = 0.0001
I1211 22:28:26.006245 20404 solver.cpp:218] Iteration 165100 (12.5598 iter/s, 7.9619s/100 iters), loss = 0.0136511
I1211 22:28:26.006245 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:26.006245 20404 solver.cpp:237]     Train net output #1: loss = 0.0136514 (* 1 = 0.0136514 loss)
I1211 22:28:26.006245 20404 sgd_solver.cpp:105] Iteration 165100, lr = 0.0001
I1211 22:28:33.973003 20404 solver.cpp:218] Iteration 165200 (12.5519 iter/s, 7.96689s/100 iters), loss = 0.0120611
I1211 22:28:33.973003 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:33.974014 20404 solver.cpp:237]     Train net output #1: loss = 0.0120614 (* 1 = 0.0120614 loss)
I1211 22:28:33.974014 20404 sgd_solver.cpp:105] Iteration 165200, lr = 0.0001
I1211 22:28:42.060721 20404 solver.cpp:218] Iteration 165300 (12.3655 iter/s, 8.08699s/100 iters), loss = 0.0112737
I1211 22:28:42.060721 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:42.060721 20404 solver.cpp:237]     Train net output #1: loss = 0.011274 (* 1 = 0.011274 loss)
I1211 22:28:42.060721 20404 sgd_solver.cpp:105] Iteration 165300, lr = 0.0001
I1211 22:28:50.070236 20404 solver.cpp:218] Iteration 165400 (12.4863 iter/s, 8.00876s/100 iters), loss = 0.00972533
I1211 22:28:50.070236 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:50.070236 20404 solver.cpp:237]     Train net output #1: loss = 0.00972561 (* 1 = 0.00972561 loss)
I1211 22:28:50.070236 20404 sgd_solver.cpp:105] Iteration 165400, lr = 0.0001
I1211 22:28:57.774880  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:28:58.090927 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165500.caffemodel
I1211 22:28:58.118417 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165500.solverstate
I1211 22:28:58.124686 20404 solver.cpp:330] Iteration 165500, Testing net (#0)
I1211 22:28:58.124686 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:28:59.824318  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:28:59.891316 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 22:28:59.891316 20404 solver.cpp:397]     Test net output #1: loss = 0.26133 (* 1 = 0.26133 loss)
I1211 22:28:59.967331 20404 solver.cpp:218] Iteration 165500 (10.1041 iter/s, 9.89698s/100 iters), loss = 0.0139338
I1211 22:28:59.968331 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:28:59.968331 20404 solver.cpp:237]     Train net output #1: loss = 0.0139341 (* 1 = 0.0139341 loss)
I1211 22:28:59.968331 20404 sgd_solver.cpp:105] Iteration 165500, lr = 0.0001
I1211 22:29:08.094724 20404 solver.cpp:218] Iteration 165600 (12.3048 iter/s, 8.12688s/100 iters), loss = 0.0113158
I1211 22:29:08.094724 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:08.095737 20404 solver.cpp:237]     Train net output #1: loss = 0.0113161 (* 1 = 0.0113161 loss)
I1211 22:29:08.095737 20404 sgd_solver.cpp:105] Iteration 165600, lr = 0.0001
I1211 22:29:16.163919 20404 solver.cpp:218] Iteration 165700 (12.3943 iter/s, 8.06821s/100 iters), loss = 0.0101671
I1211 22:29:16.163919 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:16.163919 20404 solver.cpp:237]     Train net output #1: loss = 0.0101673 (* 1 = 0.0101673 loss)
I1211 22:29:16.163919 20404 sgd_solver.cpp:105] Iteration 165700, lr = 0.0001
I1211 22:29:24.306478 20404 solver.cpp:218] Iteration 165800 (12.2819 iter/s, 8.14203s/100 iters), loss = 0.0100396
I1211 22:29:24.306478 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:24.306478 20404 solver.cpp:237]     Train net output #1: loss = 0.0100399 (* 1 = 0.0100399 loss)
I1211 22:29:24.306478 20404 sgd_solver.cpp:105] Iteration 165800, lr = 0.0001
I1211 22:29:32.383961 20404 solver.cpp:218] Iteration 165900 (12.3819 iter/s, 8.07631s/100 iters), loss = 0.0130943
I1211 22:29:32.383961 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:32.383961 20404 solver.cpp:237]     Train net output #1: loss = 0.0130946 (* 1 = 0.0130946 loss)
I1211 22:29:32.383961 20404 sgd_solver.cpp:105] Iteration 165900, lr = 0.0001
I1211 22:29:40.041050  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:29:40.358091 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166000.caffemodel
I1211 22:29:40.391089 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166000.solverstate
I1211 22:29:40.397091 20404 solver.cpp:330] Iteration 166000, Testing net (#0)
I1211 22:29:40.397091 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:29:42.102311  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:29:42.169327 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1211 22:29:42.169327 20404 solver.cpp:397]     Test net output #1: loss = 0.26164 (* 1 = 0.26164 loss)
I1211 22:29:42.243347 20404 solver.cpp:218] Iteration 166000 (10.1429 iter/s, 9.85908s/100 iters), loss = 0.0142027
I1211 22:29:42.243347 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:42.243347 20404 solver.cpp:237]     Train net output #1: loss = 0.014203 (* 1 = 0.014203 loss)
I1211 22:29:42.243347 20404 sgd_solver.cpp:105] Iteration 166000, lr = 0.0001
I1211 22:29:50.284279 20404 solver.cpp:218] Iteration 166100 (12.4371 iter/s, 8.04044s/100 iters), loss = 0.0147159
I1211 22:29:50.284279 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:50.284279 20404 solver.cpp:237]     Train net output #1: loss = 0.0147162 (* 1 = 0.0147162 loss)
I1211 22:29:50.284279 20404 sgd_solver.cpp:105] Iteration 166100, lr = 0.0001
I1211 22:29:58.341312 20404 solver.cpp:218] Iteration 166200 (12.4117 iter/s, 8.05691s/100 iters), loss = 0.0109157
I1211 22:29:58.341312 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:29:58.341312 20404 solver.cpp:237]     Train net output #1: loss = 0.010916 (* 1 = 0.010916 loss)
I1211 22:29:58.341312 20404 sgd_solver.cpp:105] Iteration 166200, lr = 0.0001
I1211 22:30:06.315220 20404 solver.cpp:218] Iteration 166300 (12.5426 iter/s, 7.97285s/100 iters), loss = 0.00934393
I1211 22:30:06.315220 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:30:06.315220 20404 solver.cpp:237]     Train net output #1: loss = 0.00934421 (* 1 = 0.00934421 loss)
I1211 22:30:06.315220 20404 sgd_solver.cpp:105] Iteration 166300, lr = 0.0001
I1211 22:30:14.325083 20404 solver.cpp:218] Iteration 166400 (12.485 iter/s, 8.00962s/100 iters), loss = 0.0098351
I1211 22:30:14.325083 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:30:14.325083 20404 solver.cpp:237]     Train net output #1: loss = 0.00983538 (* 1 = 0.00983538 loss)
I1211 22:30:14.325083 20404 sgd_solver.cpp:105] Iteration 166400, lr = 0.0001
I1211 22:30:21.942905  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:30:22.256937 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166500.caffemodel
I1211 22:30:22.284937 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166500.solverstate
I1211 22:30:22.291937 20404 solver.cpp:330] Iteration 166500, Testing net (#0)
I1211 22:30:22.291937 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:30:23.966367  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:30:24.035388 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1211 22:30:24.036397 20404 solver.cpp:397]     Test net output #1: loss = 0.261867 (* 1 = 0.261867 loss)
I1211 22:30:24.110389 20404 solver.cpp:218] Iteration 166500 (10.2202 iter/s, 9.78451s/100 iters), loss = 0.0125968
I1211 22:30:24.110389 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:30:24.110389 20404 solver.cpp:237]     Train net output #1: loss = 0.0125971 (* 1 = 0.0125971 loss)
I1211 22:30:24.110389 20404 sgd_solver.cpp:105] Iteration 166500, lr = 0.0001
I1211 22:30:32.226660 20404 solver.cpp:218] Iteration 166600 (12.3215 iter/s, 8.11587s/100 iters), loss = 0.0113623
I1211 22:30:32.226660 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:30:32.226660 20404 solver.cpp:237]     Train net output #1: loss = 0.0113626 (* 1 = 0.0113626 loss)
I1211 22:30:32.226660 20404 sgd_solver.cpp:105] Iteration 166600, lr = 0.0001
I1211 22:30:40.298101 20404 solver.cpp:218] Iteration 166700 (12.3902 iter/s, 8.07089s/100 iters), loss = 0.0218297
I1211 22:30:40.298101 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:30:40.298101 20404 solver.cpp:237]     Train net output #1: loss = 0.02183 (* 1 = 0.02183 loss)
I1211 22:30:40.298101 20404 sgd_solver.cpp:105] Iteration 166700, lr = 0.0001
I1211 22:30:48.495200 20404 solver.cpp:218] Iteration 166800 (12.2004 iter/s, 8.19647s/100 iters), loss = 0.00866834
I1211 22:30:48.495200 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:30:48.495200 20404 solver.cpp:237]     Train net output #1: loss = 0.00866861 (* 1 = 0.00866861 loss)
I1211 22:30:48.495200 20404 sgd_solver.cpp:105] Iteration 166800, lr = 0.0001
I1211 22:30:56.629101 20404 solver.cpp:218] Iteration 166900 (12.2942 iter/s, 8.13393s/100 iters), loss = 0.0122987
I1211 22:30:56.629101 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:30:56.629101 20404 solver.cpp:237]     Train net output #1: loss = 0.012299 (* 1 = 0.012299 loss)
I1211 22:30:56.629101 20404 sgd_solver.cpp:105] Iteration 166900, lr = 0.0001
I1211 22:31:04.277079  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:31:04.590078 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167000.caffemodel
I1211 22:31:04.626087 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167000.solverstate
I1211 22:31:04.632087 20404 solver.cpp:330] Iteration 167000, Testing net (#0)
I1211 22:31:04.632087 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:31:06.312687  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:31:06.380188 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 22:31:06.380188 20404 solver.cpp:397]     Test net output #1: loss = 0.261574 (* 1 = 0.261574 loss)
I1211 22:31:06.455199 20404 solver.cpp:218] Iteration 167000 (10.1778 iter/s, 9.82531s/100 iters), loss = 0.0124171
I1211 22:31:06.455199 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:31:06.455199 20404 solver.cpp:237]     Train net output #1: loss = 0.0124174 (* 1 = 0.0124174 loss)
I1211 22:31:06.455199 20404 sgd_solver.cpp:105] Iteration 167000, lr = 0.0001
I1211 22:31:14.527050 20404 solver.cpp:218] Iteration 167100 (12.3898 iter/s, 8.07115s/100 iters), loss = 0.00944701
I1211 22:31:14.527050 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:31:14.527050 20404 solver.cpp:237]     Train net output #1: loss = 0.00944729 (* 1 = 0.00944729 loss)
I1211 22:31:14.527050 20404 sgd_solver.cpp:105] Iteration 167100, lr = 0.0001
I1211 22:31:22.698896 20404 solver.cpp:218] Iteration 167200 (12.2378 iter/s, 8.17138s/100 iters), loss = 0.0138599
I1211 22:31:22.698896 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:31:22.698896 20404 solver.cpp:237]     Train net output #1: loss = 0.0138602 (* 1 = 0.0138602 loss)
I1211 22:31:22.698896 20404 sgd_solver.cpp:105] Iteration 167200, lr = 0.0001
I1211 22:31:30.775985 20404 solver.cpp:218] Iteration 167300 (12.3813 iter/s, 8.07673s/100 iters), loss = 0.00934345
I1211 22:31:30.775985 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:31:30.775985 20404 solver.cpp:237]     Train net output #1: loss = 0.00934373 (* 1 = 0.00934373 loss)
I1211 22:31:30.775985 20404 sgd_solver.cpp:105] Iteration 167300, lr = 0.0001
I1211 22:31:38.774381 20404 solver.cpp:218] Iteration 167400 (12.5035 iter/s, 7.99777s/100 iters), loss = 0.0112377
I1211 22:31:38.774381 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:31:38.774381 20404 solver.cpp:237]     Train net output #1: loss = 0.011238 (* 1 = 0.011238 loss)
I1211 22:31:38.774381 20404 sgd_solver.cpp:105] Iteration 167400, lr = 0.0001
I1211 22:31:46.542454  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:31:46.857270 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167500.caffemodel
I1211 22:31:46.889281 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167500.solverstate
I1211 22:31:46.896270 20404 solver.cpp:330] Iteration 167500, Testing net (#0)
I1211 22:31:46.896270 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:31:48.587710  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:31:48.654147 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 22:31:48.654147 20404 solver.cpp:397]     Test net output #1: loss = 0.261281 (* 1 = 0.261281 loss)
I1211 22:31:48.729151 20404 solver.cpp:218] Iteration 167500 (10.0463 iter/s, 9.95387s/100 iters), loss = 0.0255525
I1211 22:31:48.729151 20404 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:31:48.729151 20404 solver.cpp:237]     Train net output #1: loss = 0.0255528 (* 1 = 0.0255528 loss)
I1211 22:31:48.729151 20404 sgd_solver.cpp:105] Iteration 167500, lr = 0.0001
I1211 22:31:56.808814 20404 solver.cpp:218] Iteration 167600 (12.3767 iter/s, 8.0797s/100 iters), loss = 0.0107607
I1211 22:31:56.808814 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:31:56.808814 20404 solver.cpp:237]     Train net output #1: loss = 0.010761 (* 1 = 0.010761 loss)
I1211 22:31:56.808814 20404 sgd_solver.cpp:105] Iteration 167600, lr = 0.0001
I1211 22:32:04.802044 20404 solver.cpp:218] Iteration 167700 (12.5113 iter/s, 7.9928s/100 iters), loss = 0.0119621
I1211 22:32:04.802044 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:04.802044 20404 solver.cpp:237]     Train net output #1: loss = 0.0119623 (* 1 = 0.0119623 loss)
I1211 22:32:04.802044 20404 sgd_solver.cpp:105] Iteration 167700, lr = 0.0001
I1211 22:32:12.867894 20404 solver.cpp:218] Iteration 167800 (12.3983 iter/s, 8.06563s/100 iters), loss = 0.00936854
I1211 22:32:12.867894 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:12.867894 20404 solver.cpp:237]     Train net output #1: loss = 0.00936883 (* 1 = 0.00936883 loss)
I1211 22:32:12.867894 20404 sgd_solver.cpp:105] Iteration 167800, lr = 0.0001
I1211 22:32:20.896919 20404 solver.cpp:218] Iteration 167900 (12.4566 iter/s, 8.02789s/100 iters), loss = 0.011218
I1211 22:32:20.896919 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:20.896919 20404 solver.cpp:237]     Train net output #1: loss = 0.0112183 (* 1 = 0.0112183 loss)
I1211 22:32:20.896919 20404 sgd_solver.cpp:105] Iteration 167900, lr = 0.0001
I1211 22:32:28.517869  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:32:28.834391 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168000.caffemodel
I1211 22:32:28.864894 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168000.solverstate
I1211 22:32:28.870896 20404 solver.cpp:330] Iteration 168000, Testing net (#0)
I1211 22:32:28.870896 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:32:30.568066  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:32:30.637573 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 22:32:30.637573 20404 solver.cpp:397]     Test net output #1: loss = 0.262181 (* 1 = 0.262181 loss)
I1211 22:32:30.714093 20404 solver.cpp:218] Iteration 168000 (10.1868 iter/s, 9.81664s/100 iters), loss = 0.0114835
I1211 22:32:30.714093 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:30.714093 20404 solver.cpp:237]     Train net output #1: loss = 0.0114838 (* 1 = 0.0114838 loss)
I1211 22:32:30.714093 20404 sgd_solver.cpp:105] Iteration 168000, lr = 0.0001
I1211 22:32:38.761843 20404 solver.cpp:218] Iteration 168100 (12.427 iter/s, 8.04697s/100 iters), loss = 0.0111492
I1211 22:32:38.761843 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:38.761843 20404 solver.cpp:237]     Train net output #1: loss = 0.0111495 (* 1 = 0.0111495 loss)
I1211 22:32:38.761843 20404 sgd_solver.cpp:105] Iteration 168100, lr = 0.0001
I1211 22:32:46.861012 20404 solver.cpp:218] Iteration 168200 (12.3474 iter/s, 8.0989s/100 iters), loss = 0.0127925
I1211 22:32:46.861012 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:46.861012 20404 solver.cpp:237]     Train net output #1: loss = 0.0127928 (* 1 = 0.0127928 loss)
I1211 22:32:46.861012 20404 sgd_solver.cpp:105] Iteration 168200, lr = 0.0001
I1211 22:32:54.875134 20404 solver.cpp:218] Iteration 168300 (12.4793 iter/s, 8.0133s/100 iters), loss = 0.00964311
I1211 22:32:54.875134 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:32:54.875134 20404 solver.cpp:237]     Train net output #1: loss = 0.00964339 (* 1 = 0.00964339 loss)
I1211 22:32:54.875134 20404 sgd_solver.cpp:105] Iteration 168300, lr = 0.0001
I1211 22:33:02.830898 20404 solver.cpp:218] Iteration 168400 (12.5705 iter/s, 7.95514s/100 iters), loss = 0.0102822
I1211 22:33:02.830898 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:02.830898 20404 solver.cpp:237]     Train net output #1: loss = 0.0102825 (* 1 = 0.0102825 loss)
I1211 22:33:02.830898 20404 sgd_solver.cpp:105] Iteration 168400, lr = 0.0001
I1211 22:33:10.470752  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:33:10.797791 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168500.caffemodel
I1211 22:33:10.830790 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168500.solverstate
I1211 22:33:10.837792 20404 solver.cpp:330] Iteration 168500, Testing net (#0)
I1211 22:33:10.837792 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:33:12.528954  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:33:12.594961 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1211 22:33:12.594961 20404 solver.cpp:397]     Test net output #1: loss = 0.260929 (* 1 = 0.260929 loss)
I1211 22:33:12.667966 20404 solver.cpp:218] Iteration 168500 (10.1654 iter/s, 9.83731s/100 iters), loss = 0.0128824
I1211 22:33:12.667966 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:12.667966 20404 solver.cpp:237]     Train net output #1: loss = 0.0128827 (* 1 = 0.0128827 loss)
I1211 22:33:12.667966 20404 sgd_solver.cpp:105] Iteration 168500, lr = 0.0001
I1211 22:33:20.815487 20404 solver.cpp:218] Iteration 168600 (12.2752 iter/s, 8.1465s/100 iters), loss = 0.0157601
I1211 22:33:20.815487 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:20.815487 20404 solver.cpp:237]     Train net output #1: loss = 0.0157604 (* 1 = 0.0157604 loss)
I1211 22:33:20.815487 20404 sgd_solver.cpp:105] Iteration 168600, lr = 0.0001
I1211 22:33:28.803589 20404 solver.cpp:218] Iteration 168700 (12.5198 iter/s, 7.98734s/100 iters), loss = 0.0115344
I1211 22:33:28.803589 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:28.803589 20404 solver.cpp:237]     Train net output #1: loss = 0.0115347 (* 1 = 0.0115347 loss)
I1211 22:33:28.803589 20404 sgd_solver.cpp:105] Iteration 168700, lr = 0.0001
I1211 22:33:36.766662 20404 solver.cpp:218] Iteration 168800 (12.5577 iter/s, 7.96324s/100 iters), loss = 0.0188146
I1211 22:33:36.766662 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:36.766662 20404 solver.cpp:237]     Train net output #1: loss = 0.0188149 (* 1 = 0.0188149 loss)
I1211 22:33:36.766662 20404 sgd_solver.cpp:105] Iteration 168800, lr = 0.0001
I1211 22:33:44.726052 20404 solver.cpp:218] Iteration 168900 (12.565 iter/s, 7.95859s/100 iters), loss = 0.0141686
I1211 22:33:44.726052 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:44.726052 20404 solver.cpp:237]     Train net output #1: loss = 0.0141689 (* 1 = 0.0141689 loss)
I1211 22:33:44.726052 20404 sgd_solver.cpp:105] Iteration 168900, lr = 0.0001
I1211 22:33:52.314654  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:33:52.629956 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169000.caffemodel
I1211 22:33:52.659471 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169000.solverstate
I1211 22:33:52.665976 20404 solver.cpp:330] Iteration 169000, Testing net (#0)
I1211 22:33:52.665976 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:33:54.343075  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:33:54.409080 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 22:33:54.409080 20404 solver.cpp:397]     Test net output #1: loss = 0.260955 (* 1 = 0.260955 loss)
I1211 22:33:54.483084 20404 solver.cpp:218] Iteration 169000 (10.2496 iter/s, 9.75645s/100 iters), loss = 0.0121095
I1211 22:33:54.483084 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:33:54.483084 20404 solver.cpp:237]     Train net output #1: loss = 0.0121098 (* 1 = 0.0121098 loss)
I1211 22:33:54.483084 20404 sgd_solver.cpp:105] Iteration 169000, lr = 0.0001
I1211 22:34:02.532827 20404 solver.cpp:218] Iteration 169100 (12.4236 iter/s, 8.04923s/100 iters), loss = 0.0101506
I1211 22:34:02.532827 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:02.532827 20404 solver.cpp:237]     Train net output #1: loss = 0.0101509 (* 1 = 0.0101509 loss)
I1211 22:34:02.532827 20404 sgd_solver.cpp:105] Iteration 169100, lr = 0.0001
I1211 22:34:10.638026 20404 solver.cpp:218] Iteration 169200 (12.3379 iter/s, 8.10514s/100 iters), loss = 0.0135625
I1211 22:34:10.638026 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:10.638026 20404 solver.cpp:237]     Train net output #1: loss = 0.0135628 (* 1 = 0.0135628 loss)
I1211 22:34:10.638026 20404 sgd_solver.cpp:105] Iteration 169200, lr = 0.0001
I1211 22:34:18.641569 20404 solver.cpp:218] Iteration 169300 (12.4955 iter/s, 8.0029s/100 iters), loss = 0.0141838
I1211 22:34:18.641569 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:18.641569 20404 solver.cpp:237]     Train net output #1: loss = 0.0141841 (* 1 = 0.0141841 loss)
I1211 22:34:18.641569 20404 sgd_solver.cpp:105] Iteration 169300, lr = 0.0001
I1211 22:34:26.606721 20404 solver.cpp:218] Iteration 169400 (12.5564 iter/s, 7.96407s/100 iters), loss = 0.00969258
I1211 22:34:26.606721 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:26.606721 20404 solver.cpp:237]     Train net output #1: loss = 0.00969287 (* 1 = 0.00969287 loss)
I1211 22:34:26.606721 20404 sgd_solver.cpp:105] Iteration 169400, lr = 0.0001
I1211 22:34:34.293823  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:34:34.612610 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169500.caffemodel
I1211 22:34:34.640628 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169500.solverstate
I1211 22:34:34.646625 20404 solver.cpp:330] Iteration 169500, Testing net (#0)
I1211 22:34:34.647630 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:34:36.323748  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:34:36.389783 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 22:34:36.389783 20404 solver.cpp:397]     Test net output #1: loss = 0.261335 (* 1 = 0.261335 loss)
I1211 22:34:36.464263 20404 solver.cpp:218] Iteration 169500 (10.1451 iter/s, 9.85698s/100 iters), loss = 0.0127756
I1211 22:34:36.464263 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:36.464263 20404 solver.cpp:237]     Train net output #1: loss = 0.0127759 (* 1 = 0.0127759 loss)
I1211 22:34:36.464263 20404 sgd_solver.cpp:105] Iteration 169500, lr = 0.0001
I1211 22:34:44.463179 20404 solver.cpp:218] Iteration 169600 (12.5023 iter/s, 7.99854s/100 iters), loss = 0.00860059
I1211 22:34:44.463179 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:44.463179 20404 solver.cpp:237]     Train net output #1: loss = 0.00860087 (* 1 = 0.00860087 loss)
I1211 22:34:44.463179 20404 sgd_solver.cpp:105] Iteration 169600, lr = 0.0001
I1211 22:34:52.423671 20404 solver.cpp:218] Iteration 169700 (12.5631 iter/s, 7.95984s/100 iters), loss = 0.0177947
I1211 22:34:52.423671 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:34:52.423671 20404 solver.cpp:237]     Train net output #1: loss = 0.017795 (* 1 = 0.017795 loss)
I1211 22:34:52.423671 20404 sgd_solver.cpp:105] Iteration 169700, lr = 0.0001
I1211 22:35:00.467744 20404 solver.cpp:218] Iteration 169800 (12.4309 iter/s, 8.04448s/100 iters), loss = 0.0206318
I1211 22:35:00.468741 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:00.468741 20404 solver.cpp:237]     Train net output #1: loss = 0.0206321 (* 1 = 0.0206321 loss)
I1211 22:35:00.468741 20404 sgd_solver.cpp:105] Iteration 169800, lr = 0.0001
I1211 22:35:08.468857 20404 solver.cpp:218] Iteration 169900 (12.5005 iter/s, 7.99967s/100 iters), loss = 0.0115294
I1211 22:35:08.468857 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:08.468857 20404 solver.cpp:237]     Train net output #1: loss = 0.0115297 (* 1 = 0.0115297 loss)
I1211 22:35:08.468857 20404 sgd_solver.cpp:105] Iteration 169900, lr = 0.0001
I1211 22:35:16.134474  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:35:16.472517 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170000.caffemodel
I1211 22:35:16.511111 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170000.solverstate
I1211 22:35:16.518106 20404 solver.cpp:330] Iteration 170000, Testing net (#0)
I1211 22:35:16.518106 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:35:18.216811  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:35:18.283823 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 22:35:18.284315 20404 solver.cpp:397]     Test net output #1: loss = 0.260673 (* 1 = 0.260673 loss)
I1211 22:35:18.359819 20404 solver.cpp:218] Iteration 170000 (10.1109 iter/s, 9.89032s/100 iters), loss = 0.0116193
I1211 22:35:18.359819 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:18.359819 20404 solver.cpp:237]     Train net output #1: loss = 0.0116196 (* 1 = 0.0116196 loss)
I1211 22:35:18.359819 20404 sgd_solver.cpp:105] Iteration 170000, lr = 0.0001
I1211 22:35:26.401577 20404 solver.cpp:218] Iteration 170100 (12.4361 iter/s, 8.04109s/100 iters), loss = 0.019497
I1211 22:35:26.401577 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:26.401577 20404 solver.cpp:237]     Train net output #1: loss = 0.0194973 (* 1 = 0.0194973 loss)
I1211 22:35:26.401577 20404 sgd_solver.cpp:105] Iteration 170100, lr = 0.0001
I1211 22:35:34.523707 20404 solver.cpp:218] Iteration 170200 (12.3124 iter/s, 8.12188s/100 iters), loss = 0.0119366
I1211 22:35:34.523707 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:34.523707 20404 solver.cpp:237]     Train net output #1: loss = 0.0119369 (* 1 = 0.0119369 loss)
I1211 22:35:34.523707 20404 sgd_solver.cpp:105] Iteration 170200, lr = 0.0001
I1211 22:35:42.610570 20404 solver.cpp:218] Iteration 170300 (12.3656 iter/s, 8.08694s/100 iters), loss = 0.0113016
I1211 22:35:42.610570 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:42.611572 20404 solver.cpp:237]     Train net output #1: loss = 0.0113018 (* 1 = 0.0113018 loss)
I1211 22:35:42.611572 20404 sgd_solver.cpp:105] Iteration 170300, lr = 0.0001
I1211 22:35:50.720832 20404 solver.cpp:218] Iteration 170400 (12.3319 iter/s, 8.10905s/100 iters), loss = 0.00968716
I1211 22:35:50.720832 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:35:50.720832 20404 solver.cpp:237]     Train net output #1: loss = 0.00968744 (* 1 = 0.00968744 loss)
I1211 22:35:50.720832 20404 sgd_solver.cpp:105] Iteration 170400, lr = 0.0001
I1211 22:35:58.498730  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:35:58.813772 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170500.caffemodel
I1211 22:35:58.843772 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170500.solverstate
I1211 22:35:58.849772 20404 solver.cpp:330] Iteration 170500, Testing net (#0)
I1211 22:35:58.849772 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:36:00.544936  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:36:00.611943 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 22:36:00.611943 20404 solver.cpp:397]     Test net output #1: loss = 0.261399 (* 1 = 0.261399 loss)
I1211 22:36:00.686944 20404 solver.cpp:218] Iteration 170500 (10.034 iter/s, 9.96616s/100 iters), loss = 0.0109888
I1211 22:36:00.686944 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:00.686944 20404 solver.cpp:237]     Train net output #1: loss = 0.0109891 (* 1 = 0.0109891 loss)
I1211 22:36:00.686944 20404 sgd_solver.cpp:105] Iteration 170500, lr = 0.0001
I1211 22:36:08.739715 20404 solver.cpp:218] Iteration 170600 (12.4188 iter/s, 8.05233s/100 iters), loss = 0.0100197
I1211 22:36:08.739715 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:08.739715 20404 solver.cpp:237]     Train net output #1: loss = 0.01002 (* 1 = 0.01002 loss)
I1211 22:36:08.740710 20404 sgd_solver.cpp:105] Iteration 170600, lr = 0.0001
I1211 22:36:16.847373 20404 solver.cpp:218] Iteration 170700 (12.335 iter/s, 8.107s/100 iters), loss = 0.0117846
I1211 22:36:16.847373 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:16.847373 20404 solver.cpp:237]     Train net output #1: loss = 0.0117849 (* 1 = 0.0117849 loss)
I1211 22:36:16.847373 20404 sgd_solver.cpp:105] Iteration 170700, lr = 0.0001
I1211 22:36:24.974797 20404 solver.cpp:218] Iteration 170800 (12.3046 iter/s, 8.12705s/100 iters), loss = 0.0102181
I1211 22:36:24.974797 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:24.974797 20404 solver.cpp:237]     Train net output #1: loss = 0.0102184 (* 1 = 0.0102184 loss)
I1211 22:36:24.974797 20404 sgd_solver.cpp:105] Iteration 170800, lr = 0.0001
I1211 22:36:33.200026 20404 solver.cpp:218] Iteration 170900 (12.1591 iter/s, 8.22429s/100 iters), loss = 0.0116124
I1211 22:36:33.200026 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:33.200026 20404 solver.cpp:237]     Train net output #1: loss = 0.0116127 (* 1 = 0.0116127 loss)
I1211 22:36:33.200026 20404 sgd_solver.cpp:105] Iteration 170900, lr = 0.0001
I1211 22:36:40.809499  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:36:41.125661 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171000.caffemodel
I1211 22:36:41.159662 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171000.solverstate
I1211 22:36:41.167663 20404 solver.cpp:330] Iteration 171000, Testing net (#0)
I1211 22:36:41.167663 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:36:42.872587  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:36:42.939595 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 22:36:42.939595 20404 solver.cpp:397]     Test net output #1: loss = 0.261073 (* 1 = 0.261073 loss)
I1211 22:36:43.014601 20404 solver.cpp:218] Iteration 171000 (10.1901 iter/s, 9.81345s/100 iters), loss = 0.00982447
I1211 22:36:43.014601 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:43.014601 20404 solver.cpp:237]     Train net output #1: loss = 0.00982476 (* 1 = 0.00982476 loss)
I1211 22:36:43.014601 20404 sgd_solver.cpp:105] Iteration 171000, lr = 0.0001
I1211 22:36:51.143710 20404 solver.cpp:218] Iteration 171100 (12.3016 iter/s, 8.12905s/100 iters), loss = 0.0137597
I1211 22:36:51.143710 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:51.143710 20404 solver.cpp:237]     Train net output #1: loss = 0.01376 (* 1 = 0.01376 loss)
I1211 22:36:51.143710 20404 sgd_solver.cpp:105] Iteration 171100, lr = 0.0001
I1211 22:36:59.117959 20404 solver.cpp:218] Iteration 171200 (12.5414 iter/s, 7.97357s/100 iters), loss = 0.0114047
I1211 22:36:59.117959 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:36:59.117959 20404 solver.cpp:237]     Train net output #1: loss = 0.011405 (* 1 = 0.011405 loss)
I1211 22:36:59.117959 20404 sgd_solver.cpp:105] Iteration 171200, lr = 0.0001
I1211 22:37:07.156067 20404 solver.cpp:218] Iteration 171300 (12.441 iter/s, 8.03792s/100 iters), loss = 0.0106209
I1211 22:37:07.156067 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:07.156067 20404 solver.cpp:237]     Train net output #1: loss = 0.0106212 (* 1 = 0.0106212 loss)
I1211 22:37:07.156067 20404 sgd_solver.cpp:105] Iteration 171300, lr = 0.0001
I1211 22:37:15.166383 20404 solver.cpp:218] Iteration 171400 (12.4856 iter/s, 8.00921s/100 iters), loss = 0.0159788
I1211 22:37:15.166383 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:15.166383 20404 solver.cpp:237]     Train net output #1: loss = 0.015979 (* 1 = 0.015979 loss)
I1211 22:37:15.166383 20404 sgd_solver.cpp:105] Iteration 171400, lr = 0.0001
I1211 22:37:22.862747  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:37:23.186779 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171500.caffemodel
I1211 22:37:23.215780 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171500.solverstate
I1211 22:37:23.222786 20404 solver.cpp:330] Iteration 171500, Testing net (#0)
I1211 22:37:23.222786 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:37:24.926548  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:37:24.993052 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 22:37:24.993052 20404 solver.cpp:397]     Test net output #1: loss = 0.260718 (* 1 = 0.260718 loss)
I1211 22:37:25.067056 20404 solver.cpp:218] Iteration 171500 (10.1006 iter/s, 9.90035s/100 iters), loss = 0.0166226
I1211 22:37:25.067056 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:25.067056 20404 solver.cpp:237]     Train net output #1: loss = 0.0166229 (* 1 = 0.0166229 loss)
I1211 22:37:25.067056 20404 sgd_solver.cpp:105] Iteration 171500, lr = 0.0001
I1211 22:37:33.092831 20404 solver.cpp:218] Iteration 171600 (12.4609 iter/s, 8.02511s/100 iters), loss = 0.0134123
I1211 22:37:33.092831 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:33.092831 20404 solver.cpp:237]     Train net output #1: loss = 0.0134126 (* 1 = 0.0134126 loss)
I1211 22:37:33.092831 20404 sgd_solver.cpp:105] Iteration 171600, lr = 0.0001
I1211 22:37:41.191213 20404 solver.cpp:218] Iteration 171700 (12.3488 iter/s, 8.09798s/100 iters), loss = 0.0119096
I1211 22:37:41.191213 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:41.191213 20404 solver.cpp:237]     Train net output #1: loss = 0.0119099 (* 1 = 0.0119099 loss)
I1211 22:37:41.191213 20404 sgd_solver.cpp:105] Iteration 171700, lr = 0.0001
I1211 22:37:49.220120 20404 solver.cpp:218] Iteration 171800 (12.4554 iter/s, 8.02862s/100 iters), loss = 0.0130632
I1211 22:37:49.220120 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:49.220120 20404 solver.cpp:237]     Train net output #1: loss = 0.0130635 (* 1 = 0.0130635 loss)
I1211 22:37:49.220120 20404 sgd_solver.cpp:105] Iteration 171800, lr = 0.0001
I1211 22:37:57.189013 20404 solver.cpp:218] Iteration 171900 (12.5503 iter/s, 7.96791s/100 iters), loss = 0.0118542
I1211 22:37:57.189013 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:37:57.189013 20404 solver.cpp:237]     Train net output #1: loss = 0.0118545 (* 1 = 0.0118545 loss)
I1211 22:37:57.189013 20404 sgd_solver.cpp:105] Iteration 171900, lr = 0.0001
I1211 22:38:04.804633  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:38:05.118671 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_172000.caffemodel
I1211 22:38:05.147683 20404 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_172000.solverstate
I1211 22:38:05.154685 20404 solver.cpp:330] Iteration 172000, Testing net (#0)
I1211 22:38:05.154685 20404 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:38:06.827805  6752 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:38:06.894815 20404 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 22:38:06.894815 20404 solver.cpp:397]     Test net output #1: loss = 0.261256 (* 1 = 0.261256 loss)
I1211 22:38:06.970841 20404 solver.cpp:218] Iteration 172000 (10.2231 iter/s, 9.78174s/100 iters), loss = 0.0110153
I1211 22:38:06.970841 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:38:06.970841 20404 solver.cpp:237]     Train net output #1: loss = 0.0110156 (* 1 = 0.0110156 loss)
I1211 22:38:06.970841 20404 sgd_solver.cpp:105] Iteration 172000, lr = 0.0001
I1211 22:38:15.043121 20404 solver.cpp:218] Iteration 172100 (12.3895 iter/s, 8.07138s/100 iters), loss = 0.0135248
I1211 22:38:15.043623 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:38:15.043623 20404 solver.cpp:237]     Train net output #1: loss = 0.0135251 (* 1 = 0.0135251 loss)
I1211 22:38:15.043623 20404 sgd_solver.cpp:105] Iteration 172100, lr = 0.0001
I1211 22:38:22.991555 20404 solver.cpp:218] Iteration 172200 (12.5825 iter/s, 7.94753s/100 iters), loss = 0.0189326
I1211 22:38:22.991555 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:38:22.991555 20404 solver.cpp:237]     Train net output #1: loss = 0.0189329 (* 1 = 0.0189329 loss)
I1211 22:38:22.991555 20404 sgd_solver.cpp:105] Iteration 172200, lr = 0.0001
I1211 22:38:30.982087 20404 solver.cpp:218] Iteration 172300 (12.5141 iter/s, 7.99096s/100 iters), loss = 0.00921702
I1211 22:38:30.983088 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:38:30.983088 20404 solver.cpp:237]     Train net output #1: loss = 0.00921731 (* 1 = 0.00921731 loss)
I1211 22:38:30.983088 20404 sgd_solver.cpp:105] Iteration 172300, lr = 0.0001
I1211 22:38:38.962291 20404 solver.cpp:218] Iteration 172400 (12.5332 iter/s, 7.97879s/100 iters), loss = 0.0133033
I1211 22:38:38.962291 20404 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:38:38.962291 20404 solver.cpp:237]     Train net output #1: loss = 0.0133035 (* 1 = 0.0133035 loss)
I1211 22:38:38.962291 20404 sgd_solver.cpp:105] Iteration 172400, lr = 0.0001
I1211 22:38:46.761611  9884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:38:47.097735 20404 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resne