
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt --snapshot=examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate 
I1203 19:42:55.354758 21228 caffe.cpp:219] Using GPUs 0
I1203 19:42:55.546277 21228 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1203 19:42:55.870043 21228 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1203 19:42:55.889045 21228 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/resnet32_with3pooling"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 195000
stepvalue: 220000
stepvalue: 270000
type: "AdaDelta"
I1203 19:42:55.916044 21228 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 19:42:55.918033 21228 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 19:42:55.918033 21228 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1203 19:42:55.919033 21228 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1203 19:42:55.919033 21228 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1203 19:42:55.919033 21228 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy_training"
  include
I1203 19:42:55.968183 21228 layer_factory.cpp:58] Creating layer cifar
I1203 19:42:55.973197 21228 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I1203 19:42:55.974206 21228 net.cpp:84] Creating Layer cifar
I1203 19:42:55.974206 21228 net.cpp:380] cifar -> data
I1203 19:42:55.974206 21228 net.cpp:380] cifar -> label
I1203 19:42:55.975198 21228 data_layer.cpp:45] output data size: 100,3,32,32
I1203 19:42:55.981196 21228 net.cpp:122] Setting up cifar
I1203 19:42:55.981196 21228 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1203 19:42:55.981196 21228 net.cpp:129] Top shape: 100 (100)
I1203 19:42:55.981196 21228 net.cpp:137] Memory required for data: 1229200
I1203 19:42:55.981196 21228 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1203 19:42:55.981196 21228 net.cpp:84] Creating Layer label_cifar_1_split
I1203 19:42:55.981196 21228 net.cpp:406] label_cifar_1_split <- label
I1203 19:42:55.981196 21228 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1203 19:42:55.981196 21228 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1203 19:42:55.981196 21228 net.cpp:122] Setting up label_cifar_1_split
I1203 19:42:55.981196 21228 net.cpp:129] Top shape: 100 (100)
I1203 19:42:55.981196 21228 net.cpp:129] Top shape: 100 (100)
I1203 19:42:55.981196 21228 net.cpp:137] Memory required for data: 1230000
I1203 19:42:55.981196 21228 layer_factory.cpp:58] Creating layer first_conv
I1203 19:42:55.981196 21228 net.cpp:84] Creating Layer first_conv
I1203 19:42:55.981196 21228 net.cpp:406] first_conv <- data
I1203 19:42:55.981196 21228 net.cpp:380] first_conv -> first_conv
I1203 19:42:55.982111 10440 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1203 19:42:56.244132 21228 net.cpp:122] Setting up first_conv
I1203 19:42:56.244132 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.244132 21228 net.cpp:137] Memory required for data: 7783600
I1203 19:42:56.244132 21228 layer_factory.cpp:58] Creating layer first_conv_bn
I1203 19:42:56.244132 21228 net.cpp:84] Creating Layer first_conv_bn
I1203 19:42:56.244132 21228 net.cpp:406] first_conv_bn <- first_conv
I1203 19:42:56.244132 21228 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1203 19:42:56.244132 21228 net.cpp:122] Setting up first_conv_bn
I1203 19:42:56.244132 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.244132 21228 net.cpp:137] Memory required for data: 14337200
I1203 19:42:56.244132 21228 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 19:42:56.244132 21228 net.cpp:84] Creating Layer first_conv_scale
I1203 19:42:56.244132 21228 net.cpp:406] first_conv_scale <- first_conv
I1203 19:42:56.244132 21228 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1203 19:42:56.244132 21228 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 19:42:56.244132 21228 net.cpp:122] Setting up first_conv_scale
I1203 19:42:56.244132 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.244132 21228 net.cpp:137] Memory required for data: 20890800
I1203 19:42:56.244132 21228 layer_factory.cpp:58] Creating layer first_conv_relu
I1203 19:42:56.244132 21228 net.cpp:84] Creating Layer first_conv_relu
I1203 19:42:56.244132 21228 net.cpp:406] first_conv_relu <- first_conv
I1203 19:42:56.244132 21228 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1203 19:42:56.245131 21228 net.cpp:122] Setting up first_conv_relu
I1203 19:42:56.245131 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.245131 21228 net.cpp:137] Memory required for data: 27444400
I1203 19:42:56.245131 21228 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1203 19:42:56.245131 21228 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1203 19:42:56.245131 21228 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1203 19:42:56.245131 21228 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1203 19:42:56.245131 21228 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1203 19:42:56.245131 21228 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1203 19:42:56.245131 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.245131 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.245131 21228 net.cpp:137] Memory required for data: 40551600
I1203 19:42:56.245131 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1203 19:42:56.245131 21228 net.cpp:84] Creating Layer group0_block0_conv0
I1203 19:42:56.245131 21228 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1203 19:42:56.245131 21228 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1203 19:42:56.247130 21228 net.cpp:122] Setting up group0_block0_conv0
I1203 19:42:56.247130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.247130 21228 net.cpp:137] Memory required for data: 47105200
I1203 19:42:56.247130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1203 19:42:56.247130 21228 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1203 19:42:56.247130 21228 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1203 19:42:56.247130 21228 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1203 19:42:56.247130 21228 net.cpp:122] Setting up group0_block0_conv0_bn
I1203 19:42:56.247130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.247130 21228 net.cpp:137] Memory required for data: 53658800
I1203 19:42:56.247130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 19:42:56.247130 21228 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1203 19:42:56.247130 21228 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1203 19:42:56.247130 21228 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1203 19:42:56.247130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 19:42:56.247130 21228 net.cpp:122] Setting up group0_block0_conv0_scale
I1203 19:42:56.247130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.247130 21228 net.cpp:137] Memory required for data: 60212400
I1203 19:42:56.247130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1203 19:42:56.247130 21228 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1203 19:42:56.247130 21228 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1203 19:42:56.247130 21228 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1203 19:42:56.247130 21228 net.cpp:122] Setting up group0_block0_conv0_relu
I1203 19:42:56.247130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.247130 21228 net.cpp:137] Memory required for data: 66766000
I1203 19:42:56.247130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1203 19:42:56.247130 21228 net.cpp:84] Creating Layer group0_block0_conv1
I1203 19:42:56.247130 21228 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1203 19:42:56.247130 21228 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1203 19:42:56.248131 21228 net.cpp:122] Setting up group0_block0_conv1
I1203 19:42:56.249130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.249130 21228 net.cpp:137] Memory required for data: 73319600
I1203 19:42:56.249130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1203 19:42:56.249130 21228 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1203 19:42:56.249130 21228 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1203 19:42:56.249130 21228 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1203 19:42:56.249130 21228 net.cpp:122] Setting up group0_block0_conv1_bn
I1203 19:42:56.249130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.249130 21228 net.cpp:137] Memory required for data: 79873200
I1203 19:42:56.249130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 19:42:56.249130 21228 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1203 19:42:56.249130 21228 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1203 19:42:56.249130 21228 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1203 19:42:56.249130 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 19:42:56.249130 21228 net.cpp:122] Setting up group0_block0_conv1_scale
I1203 19:42:56.249130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.249130 21228 net.cpp:137] Memory required for data: 86426800
I1203 19:42:56.249130 21228 layer_factory.cpp:58] Creating layer group0_block0_sum
I1203 19:42:56.249130 21228 net.cpp:84] Creating Layer group0_block0_sum
I1203 19:42:56.249130 21228 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1203 19:42:56.249130 21228 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1203 19:42:56.249130 21228 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1203 19:42:56.249130 21228 net.cpp:122] Setting up group0_block0_sum
I1203 19:42:56.249130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.249130 21228 net.cpp:137] Memory required for data: 92980400
I1203 19:42:56.249130 21228 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1203 19:42:56.249130 21228 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1203 19:42:56.249130 21228 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1203 19:42:56.249130 21228 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1203 19:42:56.249130 21228 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1203 19:42:56.249130 21228 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1203 19:42:56.249130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.249130 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.249130 21228 net.cpp:137] Memory required for data: 106087600
I1203 19:42:56.249130 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1203 19:42:56.249130 21228 net.cpp:84] Creating Layer group0_block1_conv0
I1203 19:42:56.249130 21228 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1203 19:42:56.249130 21228 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1203 19:42:56.251138 21228 net.cpp:122] Setting up group0_block1_conv0
I1203 19:42:56.251138 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.251138 21228 net.cpp:137] Memory required for data: 112641200
I1203 19:42:56.251138 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1203 19:42:56.251138 21228 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1203 19:42:56.251138 21228 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1203 19:42:56.251138 21228 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1203 19:42:56.251138 21228 net.cpp:122] Setting up group0_block1_conv0_bn
I1203 19:42:56.251138 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.251138 21228 net.cpp:137] Memory required for data: 119194800
I1203 19:42:56.251138 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 19:42:56.251138 21228 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1203 19:42:56.251138 21228 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1203 19:42:56.251138 21228 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1203 19:42:56.251138 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 19:42:56.252144 21228 net.cpp:122] Setting up group0_block1_conv0_scale
I1203 19:42:56.252144 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.252144 21228 net.cpp:137] Memory required for data: 125748400
I1203 19:42:56.252144 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1203 19:42:56.252144 21228 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1203 19:42:56.252144 21228 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1203 19:42:56.252144 21228 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1203 19:42:56.252144 21228 net.cpp:122] Setting up group0_block1_conv0_relu
I1203 19:42:56.252144 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.252144 21228 net.cpp:137] Memory required for data: 132302000
I1203 19:42:56.252144 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1203 19:42:56.252144 21228 net.cpp:84] Creating Layer group0_block1_conv1
I1203 19:42:56.252144 21228 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1203 19:42:56.252144 21228 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1203 19:42:56.253638 21228 net.cpp:122] Setting up group0_block1_conv1
I1203 19:42:56.253638 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.253638 21228 net.cpp:137] Memory required for data: 138855600
I1203 19:42:56.253638 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1203 19:42:56.253638 21228 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1203 19:42:56.253638 21228 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1203 19:42:56.253638 21228 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1203 19:42:56.254139 21228 net.cpp:122] Setting up group0_block1_conv1_bn
I1203 19:42:56.254139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.254139 21228 net.cpp:137] Memory required for data: 145409200
I1203 19:42:56.254139 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 19:42:56.254139 21228 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1203 19:42:56.254139 21228 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1203 19:42:56.254139 21228 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1203 19:42:56.254139 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 19:42:56.254139 21228 net.cpp:122] Setting up group0_block1_conv1_scale
I1203 19:42:56.254139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.254139 21228 net.cpp:137] Memory required for data: 151962800
I1203 19:42:56.254139 21228 layer_factory.cpp:58] Creating layer group0_block1_sum
I1203 19:42:56.254139 21228 net.cpp:84] Creating Layer group0_block1_sum
I1203 19:42:56.254139 21228 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1203 19:42:56.254139 21228 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1203 19:42:56.254139 21228 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1203 19:42:56.254139 21228 net.cpp:122] Setting up group0_block1_sum
I1203 19:42:56.254139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.254139 21228 net.cpp:137] Memory required for data: 158516400
I1203 19:42:56.254139 21228 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1203 19:42:56.254139 21228 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1203 19:42:56.254638 21228 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1203 19:42:56.254638 21228 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1203 19:42:56.254638 21228 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1203 19:42:56.254638 21228 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1203 19:42:56.254638 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.254638 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.254638 21228 net.cpp:137] Memory required for data: 171623600
I1203 19:42:56.254638 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1203 19:42:56.254638 21228 net.cpp:84] Creating Layer group0_block2_conv0
I1203 19:42:56.254638 21228 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1203 19:42:56.254638 21228 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1203 19:42:56.255640 21228 net.cpp:122] Setting up group0_block2_conv0
I1203 19:42:56.255640 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.255640 21228 net.cpp:137] Memory required for data: 178177200
I1203 19:42:56.255640 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1203 19:42:56.255640 21228 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1203 19:42:56.255640 21228 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1203 19:42:56.255640 21228 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1203 19:42:56.256139 21228 net.cpp:122] Setting up group0_block2_conv0_bn
I1203 19:42:56.256139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.256139 21228 net.cpp:137] Memory required for data: 184730800
I1203 19:42:56.256139 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 19:42:56.256139 21228 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1203 19:42:56.256139 21228 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1203 19:42:56.256139 21228 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1203 19:42:56.256139 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 19:42:56.256139 21228 net.cpp:122] Setting up group0_block2_conv0_scale
I1203 19:42:56.256639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.256639 21228 net.cpp:137] Memory required for data: 191284400
I1203 19:42:56.256639 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1203 19:42:56.256639 21228 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1203 19:42:56.256639 21228 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1203 19:42:56.256639 21228 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1203 19:42:56.256639 21228 net.cpp:122] Setting up group0_block2_conv0_relu
I1203 19:42:56.256639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.256639 21228 net.cpp:137] Memory required for data: 197838000
I1203 19:42:56.256639 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1203 19:42:56.256639 21228 net.cpp:84] Creating Layer group0_block2_conv1
I1203 19:42:56.256639 21228 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1203 19:42:56.256639 21228 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1203 19:42:56.258138 21228 net.cpp:122] Setting up group0_block2_conv1
I1203 19:42:56.258138 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.258138 21228 net.cpp:137] Memory required for data: 204391600
I1203 19:42:56.258138 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1203 19:42:56.258138 21228 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1203 19:42:56.258138 21228 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1203 19:42:56.258138 21228 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1203 19:42:56.258639 21228 net.cpp:122] Setting up group0_block2_conv1_bn
I1203 19:42:56.258639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.258639 21228 net.cpp:137] Memory required for data: 210945200
I1203 19:42:56.258639 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 19:42:56.258639 21228 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1203 19:42:56.258639 21228 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1203 19:42:56.258639 21228 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1203 19:42:56.258639 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 19:42:56.258639 21228 net.cpp:122] Setting up group0_block2_conv1_scale
I1203 19:42:56.258639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.258639 21228 net.cpp:137] Memory required for data: 217498800
I1203 19:42:56.258639 21228 layer_factory.cpp:58] Creating layer group0_block2_sum
I1203 19:42:56.258639 21228 net.cpp:84] Creating Layer group0_block2_sum
I1203 19:42:56.258639 21228 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1203 19:42:56.258639 21228 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1203 19:42:56.258639 21228 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1203 19:42:56.258639 21228 net.cpp:122] Setting up group0_block2_sum
I1203 19:42:56.258639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.258639 21228 net.cpp:137] Memory required for data: 224052400
I1203 19:42:56.258639 21228 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1203 19:42:56.258639 21228 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1203 19:42:56.258639 21228 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1203 19:42:56.258639 21228 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1203 19:42:56.258639 21228 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1203 19:42:56.258639 21228 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1203 19:42:56.258639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.258639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.259140 21228 net.cpp:137] Memory required for data: 237159600
I1203 19:42:56.259140 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1203 19:42:56.259140 21228 net.cpp:84] Creating Layer group0_block3_conv0
I1203 19:42:56.259140 21228 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1203 19:42:56.259140 21228 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1203 19:42:56.260139 21228 net.cpp:122] Setting up group0_block3_conv0
I1203 19:42:56.260139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.260139 21228 net.cpp:137] Memory required for data: 243713200
I1203 19:42:56.260139 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1203 19:42:56.260139 21228 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1203 19:42:56.260139 21228 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1203 19:42:56.260139 21228 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1203 19:42:56.260139 21228 net.cpp:122] Setting up group0_block3_conv0_bn
I1203 19:42:56.260139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.260139 21228 net.cpp:137] Memory required for data: 250266800
I1203 19:42:56.260139 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 19:42:56.260139 21228 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1203 19:42:56.260139 21228 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1203 19:42:56.260139 21228 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1203 19:42:56.260639 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 19:42:56.260639 21228 net.cpp:122] Setting up group0_block3_conv0_scale
I1203 19:42:56.260639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.260639 21228 net.cpp:137] Memory required for data: 256820400
I1203 19:42:56.260639 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1203 19:42:56.260639 21228 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1203 19:42:56.260639 21228 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1203 19:42:56.260639 21228 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1203 19:42:56.260639 21228 net.cpp:122] Setting up group0_block3_conv0_relu
I1203 19:42:56.260639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.260639 21228 net.cpp:137] Memory required for data: 263374000
I1203 19:42:56.260639 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1203 19:42:56.260639 21228 net.cpp:84] Creating Layer group0_block3_conv1
I1203 19:42:56.260639 21228 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1203 19:42:56.260639 21228 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1203 19:42:56.262140 21228 net.cpp:122] Setting up group0_block3_conv1
I1203 19:42:56.262140 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.262140 21228 net.cpp:137] Memory required for data: 269927600
I1203 19:42:56.262140 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1203 19:42:56.262140 21228 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1203 19:42:56.262140 21228 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1203 19:42:56.262140 21228 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1203 19:42:56.262140 21228 net.cpp:122] Setting up group0_block3_conv1_bn
I1203 19:42:56.262140 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.262140 21228 net.cpp:137] Memory required for data: 276481200
I1203 19:42:56.262140 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 19:42:56.262140 21228 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1203 19:42:56.262140 21228 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1203 19:42:56.262140 21228 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1203 19:42:56.262140 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 19:42:56.262140 21228 net.cpp:122] Setting up group0_block3_conv1_scale
I1203 19:42:56.262140 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.262140 21228 net.cpp:137] Memory required for data: 283034800
I1203 19:42:56.262140 21228 layer_factory.cpp:58] Creating layer group0_block3_sum
I1203 19:42:56.262140 21228 net.cpp:84] Creating Layer group0_block3_sum
I1203 19:42:56.262140 21228 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1203 19:42:56.262140 21228 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1203 19:42:56.262140 21228 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1203 19:42:56.262639 21228 net.cpp:122] Setting up group0_block3_sum
I1203 19:42:56.262639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.262639 21228 net.cpp:137] Memory required for data: 289588400
I1203 19:42:56.262639 21228 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1203 19:42:56.262639 21228 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1203 19:42:56.262639 21228 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1203 19:42:56.262639 21228 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1203 19:42:56.262639 21228 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1203 19:42:56.262639 21228 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1203 19:42:56.262639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.262639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.262639 21228 net.cpp:137] Memory required for data: 302695600
I1203 19:42:56.262639 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1203 19:42:56.262639 21228 net.cpp:84] Creating Layer group0_block4_conv0
I1203 19:42:56.262639 21228 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1203 19:42:56.262639 21228 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1203 19:42:56.263639 21228 net.cpp:122] Setting up group0_block4_conv0
I1203 19:42:56.263639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.263639 21228 net.cpp:137] Memory required for data: 309249200
I1203 19:42:56.263639 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1203 19:42:56.263639 21228 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1203 19:42:56.263639 21228 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1203 19:42:56.263639 21228 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1203 19:42:56.263639 21228 net.cpp:122] Setting up group0_block4_conv0_bn
I1203 19:42:56.263639 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.263639 21228 net.cpp:137] Memory required for data: 315802800
I1203 19:42:56.263639 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 19:42:56.263639 21228 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1203 19:42:56.263639 21228 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1203 19:42:56.264139 21228 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1203 19:42:56.264139 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 19:42:56.264139 21228 net.cpp:122] Setting up group0_block4_conv0_scale
I1203 19:42:56.264139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.264139 21228 net.cpp:137] Memory required for data: 322356400
I1203 19:42:56.264139 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1203 19:42:56.264139 21228 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1203 19:42:56.264139 21228 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1203 19:42:56.264139 21228 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1203 19:42:56.264139 21228 net.cpp:122] Setting up group0_block4_conv0_relu
I1203 19:42:56.264139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.264139 21228 net.cpp:137] Memory required for data: 328910000
I1203 19:42:56.264139 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1203 19:42:56.264139 21228 net.cpp:84] Creating Layer group0_block4_conv1
I1203 19:42:56.264139 21228 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1203 19:42:56.264639 21228 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1203 19:42:56.265638 21228 net.cpp:122] Setting up group0_block4_conv1
I1203 19:42:56.265638 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.265638 21228 net.cpp:137] Memory required for data: 335463600
I1203 19:42:56.265638 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1203 19:42:56.265638 21228 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1203 19:42:56.265638 21228 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1203 19:42:56.265638 21228 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1203 19:42:56.265638 21228 net.cpp:122] Setting up group0_block4_conv1_bn
I1203 19:42:56.265638 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.265638 21228 net.cpp:137] Memory required for data: 342017200
I1203 19:42:56.265638 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 19:42:56.265638 21228 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1203 19:42:56.265638 21228 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1203 19:42:56.265638 21228 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1203 19:42:56.265638 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 19:42:56.266139 21228 net.cpp:122] Setting up group0_block4_conv1_scale
I1203 19:42:56.266139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.266139 21228 net.cpp:137] Memory required for data: 348570800
I1203 19:42:56.266139 21228 layer_factory.cpp:58] Creating layer group0_block4_sum
I1203 19:42:56.266139 21228 net.cpp:84] Creating Layer group0_block4_sum
I1203 19:42:56.266139 21228 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1203 19:42:56.266139 21228 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1203 19:42:56.266139 21228 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1203 19:42:56.266139 21228 net.cpp:122] Setting up group0_block4_sum
I1203 19:42:56.266139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.266139 21228 net.cpp:137] Memory required for data: 355124400
I1203 19:42:56.266139 21228 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1203 19:42:56.266139 21228 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1203 19:42:56.266139 21228 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1203 19:42:56.266139 21228 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1203 19:42:56.266139 21228 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1203 19:42:56.266139 21228 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1203 19:42:56.266139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.266139 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.266139 21228 net.cpp:137] Memory required for data: 368231600
I1203 19:42:56.266139 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1203 19:42:56.266139 21228 net.cpp:84] Creating Layer group1_block0_conv0
I1203 19:42:56.266139 21228 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1203 19:42:56.266139 21228 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1203 19:42:56.268641 21228 net.cpp:122] Setting up group1_block0_conv0
I1203 19:42:56.268641 21228 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1203 19:42:56.268641 21228 net.cpp:137] Memory required for data: 381338800
I1203 19:42:56.268641 21228 layer_factory.cpp:58] Creating layer pool1
I1203 19:42:56.268641 21228 net.cpp:84] Creating Layer pool1
I1203 19:42:56.269140 21228 net.cpp:406] pool1 <- group1_block0_conv0
I1203 19:42:56.269140 21228 net.cpp:380] pool1 -> pool1
I1203 19:42:56.269140 21228 net.cpp:122] Setting up pool1
I1203 19:42:56.269140 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.269140 21228 net.cpp:137] Memory required for data: 384615600
I1203 19:42:56.269140 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1203 19:42:56.269140 21228 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1203 19:42:56.269140 21228 net.cpp:406] group1_block0_conv0_bn <- pool1
I1203 19:42:56.269140 21228 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1203 19:42:56.269140 21228 net.cpp:122] Setting up group1_block0_conv0_bn
I1203 19:42:56.269140 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.269140 21228 net.cpp:137] Memory required for data: 387892400
I1203 19:42:56.269140 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 19:42:56.269140 21228 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1203 19:42:56.269140 21228 net.cpp:406] group1_block0_conv0_scale <- pool1
I1203 19:42:56.269140 21228 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1203 19:42:56.269140 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 19:42:56.269140 21228 net.cpp:122] Setting up group1_block0_conv0_scale
I1203 19:42:56.269140 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.269140 21228 net.cpp:137] Memory required for data: 391169200
I1203 19:42:56.269140 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1203 19:42:56.269140 21228 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1203 19:42:56.269140 21228 net.cpp:406] group1_block0_conv0_relu <- pool1
I1203 19:42:56.269140 21228 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1203 19:42:56.269140 21228 net.cpp:122] Setting up group1_block0_conv0_relu
I1203 19:42:56.269140 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.269140 21228 net.cpp:137] Memory required for data: 394446000
I1203 19:42:56.269140 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1203 19:42:56.269140 21228 net.cpp:84] Creating Layer group1_block0_conv1
I1203 19:42:56.269140 21228 net.cpp:406] group1_block0_conv1 <- pool1
I1203 19:42:56.269140 21228 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1203 19:42:56.271147 21228 net.cpp:122] Setting up group1_block0_conv1
I1203 19:42:56.271147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.271147 21228 net.cpp:137] Memory required for data: 397722800
I1203 19:42:56.271147 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1203 19:42:56.271147 21228 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1203 19:42:56.271147 21228 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1203 19:42:56.271147 21228 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1203 19:42:56.271147 21228 net.cpp:122] Setting up group1_block0_conv1_bn
I1203 19:42:56.271147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.271147 21228 net.cpp:137] Memory required for data: 400999600
I1203 19:42:56.271147 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 19:42:56.271147 21228 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1203 19:42:56.271147 21228 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1203 19:42:56.271147 21228 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1203 19:42:56.271147 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 19:42:56.271147 21228 net.cpp:122] Setting up group1_block0_conv1_scale
I1203 19:42:56.271147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.271147 21228 net.cpp:137] Memory required for data: 404276400
I1203 19:42:56.272146 21228 layer_factory.cpp:58] Creating layer group1_block0_proj
I1203 19:42:56.272146 21228 net.cpp:84] Creating Layer group1_block0_proj
I1203 19:42:56.272146 21228 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1203 19:42:56.272146 21228 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1203 19:42:56.273146 21228 net.cpp:122] Setting up group1_block0_proj
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1203 19:42:56.273146 21228 net.cpp:137] Memory required for data: 416577200
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer pool2
I1203 19:42:56.273146 21228 net.cpp:84] Creating Layer pool2
I1203 19:42:56.273146 21228 net.cpp:406] pool2 <- group1_block0_proj
I1203 19:42:56.273146 21228 net.cpp:380] pool2 -> pool2
I1203 19:42:56.273146 21228 net.cpp:122] Setting up pool2
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.273146 21228 net.cpp:137] Memory required for data: 419854000
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1203 19:42:56.273146 21228 net.cpp:84] Creating Layer group1_block0_proj_bn
I1203 19:42:56.273146 21228 net.cpp:406] group1_block0_proj_bn <- pool2
I1203 19:42:56.273146 21228 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1203 19:42:56.273146 21228 net.cpp:122] Setting up group1_block0_proj_bn
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.273146 21228 net.cpp:137] Memory required for data: 423130800
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 19:42:56.273146 21228 net.cpp:84] Creating Layer group1_block0_proj_scale
I1203 19:42:56.273146 21228 net.cpp:406] group1_block0_proj_scale <- pool2
I1203 19:42:56.273146 21228 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 19:42:56.273146 21228 net.cpp:122] Setting up group1_block0_proj_scale
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.273146 21228 net.cpp:137] Memory required for data: 426407600
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer group1_block0_sum
I1203 19:42:56.273146 21228 net.cpp:84] Creating Layer group1_block0_sum
I1203 19:42:56.273146 21228 net.cpp:406] group1_block0_sum <- pool2
I1203 19:42:56.273146 21228 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1203 19:42:56.273146 21228 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1203 19:42:56.273146 21228 net.cpp:122] Setting up group1_block0_sum
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.273146 21228 net.cpp:137] Memory required for data: 429684400
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1203 19:42:56.273146 21228 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1203 19:42:56.273146 21228 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1203 19:42:56.273146 21228 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1203 19:42:56.273146 21228 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1203 19:42:56.273146 21228 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.273146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.273146 21228 net.cpp:137] Memory required for data: 436238000
I1203 19:42:56.273146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1203 19:42:56.273146 21228 net.cpp:84] Creating Layer group1_block1_conv0
I1203 19:42:56.273146 21228 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1203 19:42:56.273146 21228 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1203 19:42:56.275146 21228 net.cpp:122] Setting up group1_block1_conv0
I1203 19:42:56.275146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.275146 21228 net.cpp:137] Memory required for data: 439514800
I1203 19:42:56.275146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1203 19:42:56.275146 21228 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1203 19:42:56.275146 21228 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1203 19:42:56.275146 21228 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1203 19:42:56.275146 21228 net.cpp:122] Setting up group1_block1_conv0_bn
I1203 19:42:56.275146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.275146 21228 net.cpp:137] Memory required for data: 442791600
I1203 19:42:56.275146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 19:42:56.275146 21228 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1203 19:42:56.275146 21228 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1203 19:42:56.275146 21228 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1203 19:42:56.275146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 19:42:56.275146 21228 net.cpp:122] Setting up group1_block1_conv0_scale
I1203 19:42:56.275146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.275146 21228 net.cpp:137] Memory required for data: 446068400
I1203 19:42:56.275146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1203 19:42:56.275146 21228 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1203 19:42:56.275146 21228 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1203 19:42:56.275146 21228 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1203 19:42:56.275146 21228 net.cpp:122] Setting up group1_block1_conv0_relu
I1203 19:42:56.275146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.275146 21228 net.cpp:137] Memory required for data: 449345200
I1203 19:42:56.275146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1203 19:42:56.275146 21228 net.cpp:84] Creating Layer group1_block1_conv1
I1203 19:42:56.275146 21228 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1203 19:42:56.275146 21228 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1203 19:42:56.277146 21228 net.cpp:122] Setting up group1_block1_conv1
I1203 19:42:56.277146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.277146 21228 net.cpp:137] Memory required for data: 452622000
I1203 19:42:56.277146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1203 19:42:56.277146 21228 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1203 19:42:56.277146 21228 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1203 19:42:56.277146 21228 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1203 19:42:56.277146 21228 net.cpp:122] Setting up group1_block1_conv1_bn
I1203 19:42:56.277146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.277146 21228 net.cpp:137] Memory required for data: 455898800
I1203 19:42:56.277146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 19:42:56.277146 21228 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1203 19:42:56.277146 21228 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1203 19:42:56.277146 21228 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1203 19:42:56.277146 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 19:42:56.277146 21228 net.cpp:122] Setting up group1_block1_conv1_scale
I1203 19:42:56.277146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.277146 21228 net.cpp:137] Memory required for data: 459175600
I1203 19:42:56.277146 21228 layer_factory.cpp:58] Creating layer group1_block1_sum
I1203 19:42:56.277146 21228 net.cpp:84] Creating Layer group1_block1_sum
I1203 19:42:56.277146 21228 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1203 19:42:56.277146 21228 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1203 19:42:56.277146 21228 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1203 19:42:56.277146 21228 net.cpp:122] Setting up group1_block1_sum
I1203 19:42:56.277146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.277146 21228 net.cpp:137] Memory required for data: 462452400
I1203 19:42:56.277146 21228 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1203 19:42:56.277146 21228 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1203 19:42:56.277146 21228 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1203 19:42:56.277146 21228 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1203 19:42:56.277146 21228 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1203 19:42:56.277146 21228 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1203 19:42:56.277146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.277146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.277146 21228 net.cpp:137] Memory required for data: 469006000
I1203 19:42:56.277146 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1203 19:42:56.277146 21228 net.cpp:84] Creating Layer group1_block2_conv0
I1203 19:42:56.277146 21228 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1203 19:42:56.277146 21228 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1203 19:42:56.279146 21228 net.cpp:122] Setting up group1_block2_conv0
I1203 19:42:56.279146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.279146 21228 net.cpp:137] Memory required for data: 472282800
I1203 19:42:56.279146 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1203 19:42:56.279146 21228 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1203 19:42:56.279146 21228 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1203 19:42:56.279146 21228 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1203 19:42:56.279146 21228 net.cpp:122] Setting up group1_block2_conv0_bn
I1203 19:42:56.279146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.279146 21228 net.cpp:137] Memory required for data: 475559600
I1203 19:42:56.279146 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 19:42:56.279146 21228 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1203 19:42:56.279146 21228 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1203 19:42:56.279146 21228 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1203 19:42:56.279146 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 19:42:56.279146 21228 net.cpp:122] Setting up group1_block2_conv0_scale
I1203 19:42:56.279146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.279146 21228 net.cpp:137] Memory required for data: 478836400
I1203 19:42:56.279146 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1203 19:42:56.279146 21228 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1203 19:42:56.279146 21228 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1203 19:42:56.279146 21228 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1203 19:42:56.279146 21228 net.cpp:122] Setting up group1_block2_conv0_relu
I1203 19:42:56.279146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.279146 21228 net.cpp:137] Memory required for data: 482113200
I1203 19:42:56.279146 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1203 19:42:56.279146 21228 net.cpp:84] Creating Layer group1_block2_conv1
I1203 19:42:56.279146 21228 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1203 19:42:56.279146 21228 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1203 19:42:56.281147 21228 net.cpp:122] Setting up group1_block2_conv1
I1203 19:42:56.281147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.281147 21228 net.cpp:137] Memory required for data: 485390000
I1203 19:42:56.281147 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1203 19:42:56.281147 21228 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1203 19:42:56.281147 21228 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1203 19:42:56.281147 21228 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1203 19:42:56.282147 21228 net.cpp:122] Setting up group1_block2_conv1_bn
I1203 19:42:56.282147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.282147 21228 net.cpp:137] Memory required for data: 488666800
I1203 19:42:56.282147 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 19:42:56.282147 21228 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1203 19:42:56.282147 21228 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1203 19:42:56.282147 21228 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1203 19:42:56.282147 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 19:42:56.282147 21228 net.cpp:122] Setting up group1_block2_conv1_scale
I1203 19:42:56.282147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.282147 21228 net.cpp:137] Memory required for data: 491943600
I1203 19:42:56.282147 21228 layer_factory.cpp:58] Creating layer group1_block2_sum
I1203 19:42:56.282147 21228 net.cpp:84] Creating Layer group1_block2_sum
I1203 19:42:56.282147 21228 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1203 19:42:56.282147 21228 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1203 19:42:56.282147 21228 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1203 19:42:56.282147 21228 net.cpp:122] Setting up group1_block2_sum
I1203 19:42:56.282147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.282147 21228 net.cpp:137] Memory required for data: 495220400
I1203 19:42:56.282147 21228 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1203 19:42:56.282147 21228 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1203 19:42:56.282147 21228 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1203 19:42:56.282147 21228 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1203 19:42:56.282147 21228 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1203 19:42:56.282147 21228 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1203 19:42:56.282147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.282147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.282147 21228 net.cpp:137] Memory required for data: 501774000
I1203 19:42:56.282147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1203 19:42:56.282147 21228 net.cpp:84] Creating Layer group1_block3_conv0
I1203 19:42:56.282147 21228 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1203 19:42:56.282147 21228 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1203 19:42:56.284147 21228 net.cpp:122] Setting up group1_block3_conv0
I1203 19:42:56.284147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.284147 21228 net.cpp:137] Memory required for data: 505050800
I1203 19:42:56.284147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1203 19:42:56.284147 21228 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1203 19:42:56.284147 21228 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1203 19:42:56.284147 21228 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1203 19:42:56.284147 21228 net.cpp:122] Setting up group1_block3_conv0_bn
I1203 19:42:56.284147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.284147 21228 net.cpp:137] Memory required for data: 508327600
I1203 19:42:56.284147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 19:42:56.284147 21228 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1203 19:42:56.284147 21228 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1203 19:42:56.284147 21228 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1203 19:42:56.284147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 19:42:56.284147 21228 net.cpp:122] Setting up group1_block3_conv0_scale
I1203 19:42:56.284147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.284147 21228 net.cpp:137] Memory required for data: 511604400
I1203 19:42:56.284147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1203 19:42:56.285147 21228 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1203 19:42:56.285147 21228 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1203 19:42:56.285147 21228 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1203 19:42:56.286146 21228 net.cpp:122] Setting up group1_block3_conv0_relu
I1203 19:42:56.286146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.286146 21228 net.cpp:137] Memory required for data: 514881200
I1203 19:42:56.286146 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1203 19:42:56.286146 21228 net.cpp:84] Creating Layer group1_block3_conv1
I1203 19:42:56.286146 21228 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1203 19:42:56.286146 21228 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1203 19:42:56.287147 21228 net.cpp:122] Setting up group1_block3_conv1
I1203 19:42:56.287147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.287147 21228 net.cpp:137] Memory required for data: 518158000
I1203 19:42:56.287147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1203 19:42:56.287147 21228 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1203 19:42:56.287147 21228 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1203 19:42:56.287147 21228 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1203 19:42:56.287147 21228 net.cpp:122] Setting up group1_block3_conv1_bn
I1203 19:42:56.287147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.287147 21228 net.cpp:137] Memory required for data: 521434800
I1203 19:42:56.287147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 19:42:56.287147 21228 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1203 19:42:56.287147 21228 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1203 19:42:56.287147 21228 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1203 19:42:56.287147 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 19:42:56.287147 21228 net.cpp:122] Setting up group1_block3_conv1_scale
I1203 19:42:56.287147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.287147 21228 net.cpp:137] Memory required for data: 524711600
I1203 19:42:56.287147 21228 layer_factory.cpp:58] Creating layer group1_block3_sum
I1203 19:42:56.287147 21228 net.cpp:84] Creating Layer group1_block3_sum
I1203 19:42:56.287147 21228 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1203 19:42:56.287147 21228 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1203 19:42:56.287147 21228 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1203 19:42:56.287147 21228 net.cpp:122] Setting up group1_block3_sum
I1203 19:42:56.287147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.287147 21228 net.cpp:137] Memory required for data: 527988400
I1203 19:42:56.287147 21228 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1203 19:42:56.287147 21228 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1203 19:42:56.287147 21228 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1203 19:42:56.287147 21228 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1203 19:42:56.287147 21228 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1203 19:42:56.287147 21228 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1203 19:42:56.287147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.287147 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.287147 21228 net.cpp:137] Memory required for data: 534542000
I1203 19:42:56.287147 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1203 19:42:56.287147 21228 net.cpp:84] Creating Layer group1_block4_conv0
I1203 19:42:56.287147 21228 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1203 19:42:56.287147 21228 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1203 19:42:56.289146 21228 net.cpp:122] Setting up group1_block4_conv0
I1203 19:42:56.289146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.289146 21228 net.cpp:137] Memory required for data: 537818800
I1203 19:42:56.289146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1203 19:42:56.289146 21228 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1203 19:42:56.289146 21228 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1203 19:42:56.289146 21228 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1203 19:42:56.289146 21228 net.cpp:122] Setting up group1_block4_conv0_bn
I1203 19:42:56.289146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.289146 21228 net.cpp:137] Memory required for data: 541095600
I1203 19:42:56.289146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 19:42:56.289146 21228 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1203 19:42:56.289146 21228 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1203 19:42:56.289146 21228 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1203 19:42:56.289146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 19:42:56.289146 21228 net.cpp:122] Setting up group1_block4_conv0_scale
I1203 19:42:56.289146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.289146 21228 net.cpp:137] Memory required for data: 544372400
I1203 19:42:56.289146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1203 19:42:56.289146 21228 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1203 19:42:56.289146 21228 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1203 19:42:56.289146 21228 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1203 19:42:56.290146 21228 net.cpp:122] Setting up group1_block4_conv0_relu
I1203 19:42:56.290146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.290146 21228 net.cpp:137] Memory required for data: 547649200
I1203 19:42:56.290146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1203 19:42:56.290146 21228 net.cpp:84] Creating Layer group1_block4_conv1
I1203 19:42:56.290146 21228 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1203 19:42:56.290146 21228 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1203 19:42:56.291146 21228 net.cpp:122] Setting up group1_block4_conv1
I1203 19:42:56.291146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.291146 21228 net.cpp:137] Memory required for data: 550926000
I1203 19:42:56.291146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1203 19:42:56.291146 21228 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1203 19:42:56.291146 21228 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1203 19:42:56.291146 21228 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1203 19:42:56.291146 21228 net.cpp:122] Setting up group1_block4_conv1_bn
I1203 19:42:56.291146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.291146 21228 net.cpp:137] Memory required for data: 554202800
I1203 19:42:56.291146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 19:42:56.291146 21228 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1203 19:42:56.291146 21228 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1203 19:42:56.291146 21228 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1203 19:42:56.291146 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 19:42:56.291146 21228 net.cpp:122] Setting up group1_block4_conv1_scale
I1203 19:42:56.291146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.291146 21228 net.cpp:137] Memory required for data: 557479600
I1203 19:42:56.291146 21228 layer_factory.cpp:58] Creating layer group1_block4_sum
I1203 19:42:56.291146 21228 net.cpp:84] Creating Layer group1_block4_sum
I1203 19:42:56.291146 21228 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1203 19:42:56.291146 21228 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1203 19:42:56.291146 21228 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1203 19:42:56.291146 21228 net.cpp:122] Setting up group1_block4_sum
I1203 19:42:56.291146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.291146 21228 net.cpp:137] Memory required for data: 560756400
I1203 19:42:56.291146 21228 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1203 19:42:56.291146 21228 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1203 19:42:56.291146 21228 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1203 19:42:56.291146 21228 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1203 19:42:56.291146 21228 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1203 19:42:56.291146 21228 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1203 19:42:56.291146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.291146 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.291146 21228 net.cpp:137] Memory required for data: 567310000
I1203 19:42:56.291146 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1203 19:42:56.291146 21228 net.cpp:84] Creating Layer group2_block0_conv0
I1203 19:42:56.291146 21228 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1203 19:42:56.291146 21228 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1203 19:42:56.293146 21228 net.cpp:122] Setting up group2_block0_conv0
I1203 19:42:56.293146 21228 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1203 19:42:56.293146 21228 net.cpp:137] Memory required for data: 573863600
I1203 19:42:56.293146 21228 layer_factory.cpp:58] Creating layer pool3
I1203 19:42:56.293146 21228 net.cpp:84] Creating Layer pool3
I1203 19:42:56.293146 21228 net.cpp:406] pool3 <- group2_block0_conv0
I1203 19:42:56.293146 21228 net.cpp:380] pool3 -> pool3
I1203 19:42:56.293146 21228 net.cpp:122] Setting up pool3
I1203 19:42:56.293146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.293146 21228 net.cpp:137] Memory required for data: 575502000
I1203 19:42:56.293146 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1203 19:42:56.293146 21228 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1203 19:42:56.293146 21228 net.cpp:406] group2_block0_conv0_bn <- pool3
I1203 19:42:56.293146 21228 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1203 19:42:56.294147 21228 net.cpp:122] Setting up group2_block0_conv0_bn
I1203 19:42:56.294147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.294147 21228 net.cpp:137] Memory required for data: 577140400
I1203 19:42:56.294147 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 19:42:56.294147 21228 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1203 19:42:56.294147 21228 net.cpp:406] group2_block0_conv0_scale <- pool3
I1203 19:42:56.294147 21228 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1203 19:42:56.294147 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 19:42:56.294147 21228 net.cpp:122] Setting up group2_block0_conv0_scale
I1203 19:42:56.294147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.294147 21228 net.cpp:137] Memory required for data: 578778800
I1203 19:42:56.294147 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1203 19:42:56.294147 21228 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1203 19:42:56.294147 21228 net.cpp:406] group2_block0_conv0_relu <- pool3
I1203 19:42:56.294147 21228 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1203 19:42:56.294147 21228 net.cpp:122] Setting up group2_block0_conv0_relu
I1203 19:42:56.294147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.294147 21228 net.cpp:137] Memory required for data: 580417200
I1203 19:42:56.294147 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1203 19:42:56.294147 21228 net.cpp:84] Creating Layer group2_block0_conv1
I1203 19:42:56.294147 21228 net.cpp:406] group2_block0_conv1 <- pool3
I1203 19:42:56.294147 21228 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1203 19:42:56.296146 21228 net.cpp:122] Setting up group2_block0_conv1
I1203 19:42:56.296146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.296146 21228 net.cpp:137] Memory required for data: 582055600
I1203 19:42:56.296146 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1203 19:42:56.296146 21228 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1203 19:42:56.296146 21228 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1203 19:42:56.296146 21228 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1203 19:42:56.296146 21228 net.cpp:122] Setting up group2_block0_conv1_bn
I1203 19:42:56.296146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.296146 21228 net.cpp:137] Memory required for data: 583694000
I1203 19:42:56.296146 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 19:42:56.296146 21228 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1203 19:42:56.296146 21228 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1203 19:42:56.296146 21228 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1203 19:42:56.296146 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 19:42:56.296146 21228 net.cpp:122] Setting up group2_block0_conv1_scale
I1203 19:42:56.296146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.296146 21228 net.cpp:137] Memory required for data: 585332400
I1203 19:42:56.296146 21228 layer_factory.cpp:58] Creating layer group2_block0_proj
I1203 19:42:56.296146 21228 net.cpp:84] Creating Layer group2_block0_proj
I1203 19:42:56.296146 21228 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1203 19:42:56.296146 21228 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1203 19:42:56.298146 21228 net.cpp:122] Setting up group2_block0_proj
I1203 19:42:56.298146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.298146 21228 net.cpp:137] Memory required for data: 586970800
I1203 19:42:56.298146 21228 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1203 19:42:56.298146 21228 net.cpp:84] Creating Layer group2_block0_proj_bn
I1203 19:42:56.298146 21228 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1203 19:42:56.298146 21228 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1203 19:42:56.298146 21228 net.cpp:122] Setting up group2_block0_proj_bn
I1203 19:42:56.298146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.298146 21228 net.cpp:137] Memory required for data: 588609200
I1203 19:42:56.298146 21228 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 19:42:56.298146 21228 net.cpp:84] Creating Layer group2_block0_proj_scale
I1203 19:42:56.298146 21228 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1203 19:42:56.298146 21228 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1203 19:42:56.298146 21228 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 19:42:56.298146 21228 net.cpp:122] Setting up group2_block0_proj_scale
I1203 19:42:56.298146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.298146 21228 net.cpp:137] Memory required for data: 590247600
I1203 19:42:56.298146 21228 layer_factory.cpp:58] Creating layer group2_block0_sum
I1203 19:42:56.298146 21228 net.cpp:84] Creating Layer group2_block0_sum
I1203 19:42:56.298146 21228 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1203 19:42:56.298146 21228 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1203 19:42:56.298146 21228 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1203 19:42:56.298146 21228 net.cpp:122] Setting up group2_block0_sum
I1203 19:42:56.298146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.298146 21228 net.cpp:137] Memory required for data: 591886000
I1203 19:42:56.298146 21228 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1203 19:42:56.298146 21228 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1203 19:42:56.298146 21228 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1203 19:42:56.298146 21228 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1203 19:42:56.298146 21228 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1203 19:42:56.298146 21228 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1203 19:42:56.298146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.298146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.298146 21228 net.cpp:137] Memory required for data: 595162800
I1203 19:42:56.298146 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1203 19:42:56.298146 21228 net.cpp:84] Creating Layer group2_block1_conv0
I1203 19:42:56.298146 21228 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1203 19:42:56.298146 21228 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1203 19:42:56.300146 21228 net.cpp:122] Setting up group2_block1_conv0
I1203 19:42:56.300146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.300146 21228 net.cpp:137] Memory required for data: 596801200
I1203 19:42:56.300146 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1203 19:42:56.300146 21228 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1203 19:42:56.300146 21228 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1203 19:42:56.300146 21228 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1203 19:42:56.301147 21228 net.cpp:122] Setting up group2_block1_conv0_bn
I1203 19:42:56.301147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.301147 21228 net.cpp:137] Memory required for data: 598439600
I1203 19:42:56.301147 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 19:42:56.301147 21228 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1203 19:42:56.301147 21228 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1203 19:42:56.301147 21228 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1203 19:42:56.301147 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 19:42:56.301147 21228 net.cpp:122] Setting up group2_block1_conv0_scale
I1203 19:42:56.301147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.301147 21228 net.cpp:137] Memory required for data: 600078000
I1203 19:42:56.301147 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1203 19:42:56.301147 21228 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1203 19:42:56.301147 21228 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1203 19:42:56.301147 21228 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1203 19:42:56.302150 21228 net.cpp:122] Setting up group2_block1_conv0_relu
I1203 19:42:56.302150 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.302150 21228 net.cpp:137] Memory required for data: 601716400
I1203 19:42:56.302150 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1203 19:42:56.302150 21228 net.cpp:84] Creating Layer group2_block1_conv1
I1203 19:42:56.302150 21228 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1203 19:42:56.302150 21228 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1203 19:42:56.304145 21228 net.cpp:122] Setting up group2_block1_conv1
I1203 19:42:56.304145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.304145 21228 net.cpp:137] Memory required for data: 603354800
I1203 19:42:56.304145 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1203 19:42:56.304145 21228 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1203 19:42:56.304145 21228 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1203 19:42:56.304145 21228 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1203 19:42:56.304145 21228 net.cpp:122] Setting up group2_block1_conv1_bn
I1203 19:42:56.304145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.304145 21228 net.cpp:137] Memory required for data: 604993200
I1203 19:42:56.304145 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 19:42:56.304145 21228 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1203 19:42:56.304145 21228 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1203 19:42:56.304145 21228 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1203 19:42:56.304145 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 19:42:56.304145 21228 net.cpp:122] Setting up group2_block1_conv1_scale
I1203 19:42:56.304145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.304145 21228 net.cpp:137] Memory required for data: 606631600
I1203 19:42:56.304145 21228 layer_factory.cpp:58] Creating layer group2_block1_sum
I1203 19:42:56.304145 21228 net.cpp:84] Creating Layer group2_block1_sum
I1203 19:42:56.304145 21228 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1203 19:42:56.304145 21228 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1203 19:42:56.304145 21228 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1203 19:42:56.304145 21228 net.cpp:122] Setting up group2_block1_sum
I1203 19:42:56.304145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.304145 21228 net.cpp:137] Memory required for data: 608270000
I1203 19:42:56.304145 21228 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1203 19:42:56.304145 21228 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1203 19:42:56.304145 21228 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1203 19:42:56.304145 21228 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1203 19:42:56.304145 21228 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1203 19:42:56.304145 21228 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1203 19:42:56.304145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.304145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.304145 21228 net.cpp:137] Memory required for data: 611546800
I1203 19:42:56.304145 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1203 19:42:56.304145 21228 net.cpp:84] Creating Layer group2_block2_conv0
I1203 19:42:56.304145 21228 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1203 19:42:56.304145 21228 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1203 19:42:56.306145 21228 net.cpp:122] Setting up group2_block2_conv0
I1203 19:42:56.306145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.306145 21228 net.cpp:137] Memory required for data: 613185200
I1203 19:42:56.306145 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1203 19:42:56.306145 21228 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1203 19:42:56.306145 21228 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1203 19:42:56.306145 21228 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1203 19:42:56.306145 21228 net.cpp:122] Setting up group2_block2_conv0_bn
I1203 19:42:56.306145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.306145 21228 net.cpp:137] Memory required for data: 614823600
I1203 19:42:56.306145 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 19:42:56.306145 21228 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1203 19:42:56.306145 21228 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1203 19:42:56.306145 21228 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1203 19:42:56.306145 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 19:42:56.306145 21228 net.cpp:122] Setting up group2_block2_conv0_scale
I1203 19:42:56.306145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.306145 21228 net.cpp:137] Memory required for data: 616462000
I1203 19:42:56.306145 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1203 19:42:56.306145 21228 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1203 19:42:56.306145 21228 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1203 19:42:56.306145 21228 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1203 19:42:56.307147 21228 net.cpp:122] Setting up group2_block2_conv0_relu
I1203 19:42:56.307147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.307147 21228 net.cpp:137] Memory required for data: 618100400
I1203 19:42:56.307147 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1203 19:42:56.307147 21228 net.cpp:84] Creating Layer group2_block2_conv1
I1203 19:42:56.307147 21228 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1203 19:42:56.307147 21228 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1203 19:42:56.308146 21228 net.cpp:122] Setting up group2_block2_conv1
I1203 19:42:56.308146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.308146 21228 net.cpp:137] Memory required for data: 619738800
I1203 19:42:56.308146 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1203 19:42:56.308146 21228 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1203 19:42:56.308146 21228 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1203 19:42:56.308146 21228 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1203 19:42:56.309146 21228 net.cpp:122] Setting up group2_block2_conv1_bn
I1203 19:42:56.309146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.309146 21228 net.cpp:137] Memory required for data: 621377200
I1203 19:42:56.309146 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 19:42:56.309146 21228 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1203 19:42:56.309146 21228 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1203 19:42:56.309146 21228 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1203 19:42:56.309146 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 19:42:56.309146 21228 net.cpp:122] Setting up group2_block2_conv1_scale
I1203 19:42:56.309146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.309146 21228 net.cpp:137] Memory required for data: 623015600
I1203 19:42:56.309146 21228 layer_factory.cpp:58] Creating layer group2_block2_sum
I1203 19:42:56.309146 21228 net.cpp:84] Creating Layer group2_block2_sum
I1203 19:42:56.309146 21228 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1203 19:42:56.309146 21228 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1203 19:42:56.309146 21228 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1203 19:42:56.309146 21228 net.cpp:122] Setting up group2_block2_sum
I1203 19:42:56.309146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.309146 21228 net.cpp:137] Memory required for data: 624654000
I1203 19:42:56.309146 21228 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1203 19:42:56.309146 21228 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1203 19:42:56.309146 21228 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1203 19:42:56.309146 21228 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1203 19:42:56.309146 21228 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1203 19:42:56.309146 21228 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1203 19:42:56.309146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.309146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.309146 21228 net.cpp:137] Memory required for data: 627930800
I1203 19:42:56.309146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1203 19:42:56.309146 21228 net.cpp:84] Creating Layer group2_block3_conv0
I1203 19:42:56.309146 21228 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1203 19:42:56.309146 21228 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1203 19:42:56.311146 21228 net.cpp:122] Setting up group2_block3_conv0
I1203 19:42:56.311146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.311146 21228 net.cpp:137] Memory required for data: 629569200
I1203 19:42:56.311146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1203 19:42:56.311146 21228 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1203 19:42:56.311146 21228 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1203 19:42:56.311146 21228 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1203 19:42:56.311146 21228 net.cpp:122] Setting up group2_block3_conv0_bn
I1203 19:42:56.311146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.311146 21228 net.cpp:137] Memory required for data: 631207600
I1203 19:42:56.311146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 19:42:56.311146 21228 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1203 19:42:56.311146 21228 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1203 19:42:56.311146 21228 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1203 19:42:56.311146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 19:42:56.311146 21228 net.cpp:122] Setting up group2_block3_conv0_scale
I1203 19:42:56.311146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.311146 21228 net.cpp:137] Memory required for data: 632846000
I1203 19:42:56.311146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1203 19:42:56.311146 21228 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1203 19:42:56.311146 21228 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1203 19:42:56.311146 21228 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1203 19:42:56.312146 21228 net.cpp:122] Setting up group2_block3_conv0_relu
I1203 19:42:56.312146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.312146 21228 net.cpp:137] Memory required for data: 634484400
I1203 19:42:56.312146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1203 19:42:56.312146 21228 net.cpp:84] Creating Layer group2_block3_conv1
I1203 19:42:56.312146 21228 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1203 19:42:56.312146 21228 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1203 19:42:56.313145 21228 net.cpp:122] Setting up group2_block3_conv1
I1203 19:42:56.313145 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.313145 21228 net.cpp:137] Memory required for data: 636122800
I1203 19:42:56.313145 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1203 19:42:56.313145 21228 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1203 19:42:56.313145 21228 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1203 19:42:56.313145 21228 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1203 19:42:56.314146 21228 net.cpp:122] Setting up group2_block3_conv1_bn
I1203 19:42:56.314146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.314146 21228 net.cpp:137] Memory required for data: 637761200
I1203 19:42:56.314146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 19:42:56.314146 21228 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1203 19:42:56.314146 21228 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1203 19:42:56.314146 21228 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1203 19:42:56.314146 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 19:42:56.314146 21228 net.cpp:122] Setting up group2_block3_conv1_scale
I1203 19:42:56.314146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.314146 21228 net.cpp:137] Memory required for data: 639399600
I1203 19:42:56.314146 21228 layer_factory.cpp:58] Creating layer group2_block3_sum
I1203 19:42:56.314146 21228 net.cpp:84] Creating Layer group2_block3_sum
I1203 19:42:56.314146 21228 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1203 19:42:56.314146 21228 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1203 19:42:56.314146 21228 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1203 19:42:56.314146 21228 net.cpp:122] Setting up group2_block3_sum
I1203 19:42:56.314146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.314146 21228 net.cpp:137] Memory required for data: 641038000
I1203 19:42:56.314146 21228 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1203 19:42:56.314146 21228 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1203 19:42:56.314146 21228 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1203 19:42:56.314146 21228 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1203 19:42:56.314146 21228 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1203 19:42:56.314146 21228 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1203 19:42:56.314146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.314146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.314146 21228 net.cpp:137] Memory required for data: 644314800
I1203 19:42:56.314146 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1203 19:42:56.314146 21228 net.cpp:84] Creating Layer group2_block4_conv0
I1203 19:42:56.314146 21228 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1203 19:42:56.314146 21228 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1203 19:42:56.316146 21228 net.cpp:122] Setting up group2_block4_conv0
I1203 19:42:56.316146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.316146 21228 net.cpp:137] Memory required for data: 645953200
I1203 19:42:56.316146 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1203 19:42:56.316146 21228 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1203 19:42:56.316146 21228 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1203 19:42:56.316146 21228 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1203 19:42:56.316146 21228 net.cpp:122] Setting up group2_block4_conv0_bn
I1203 19:42:56.316146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.316146 21228 net.cpp:137] Memory required for data: 647591600
I1203 19:42:56.316146 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 19:42:56.316146 21228 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1203 19:42:56.316146 21228 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1203 19:42:56.316146 21228 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1203 19:42:56.316146 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 19:42:56.316146 21228 net.cpp:122] Setting up group2_block4_conv0_scale
I1203 19:42:56.316146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.316146 21228 net.cpp:137] Memory required for data: 649230000
I1203 19:42:56.316146 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1203 19:42:56.316146 21228 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1203 19:42:56.316146 21228 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1203 19:42:56.316146 21228 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1203 19:42:56.317147 21228 net.cpp:122] Setting up group2_block4_conv0_relu
I1203 19:42:56.317147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.317147 21228 net.cpp:137] Memory required for data: 650868400
I1203 19:42:56.317147 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1203 19:42:56.317147 21228 net.cpp:84] Creating Layer group2_block4_conv1
I1203 19:42:56.317147 21228 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1203 19:42:56.317147 21228 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1203 19:42:56.319146 21228 net.cpp:122] Setting up group2_block4_conv1
I1203 19:42:56.319146 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.319146 21228 net.cpp:137] Memory required for data: 652506800
I1203 19:42:56.319146 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1203 19:42:56.319146 21228 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1203 19:42:56.319146 21228 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1203 19:42:56.319146 21228 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1203 19:42:56.320147 21228 net.cpp:122] Setting up group2_block4_conv1_bn
I1203 19:42:56.320147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.320147 21228 net.cpp:137] Memory required for data: 654145200
I1203 19:42:56.320147 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 19:42:56.320147 21228 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1203 19:42:56.320147 21228 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1203 19:42:56.320147 21228 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1203 19:42:56.320147 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 19:42:56.320147 21228 net.cpp:122] Setting up group2_block4_conv1_scale
I1203 19:42:56.320147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.320147 21228 net.cpp:137] Memory required for data: 655783600
I1203 19:42:56.320147 21228 layer_factory.cpp:58] Creating layer group2_block4_sum
I1203 19:42:56.320147 21228 net.cpp:84] Creating Layer group2_block4_sum
I1203 19:42:56.320147 21228 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1203 19:42:56.320147 21228 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1203 19:42:56.320147 21228 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1203 19:42:56.320147 21228 net.cpp:122] Setting up group2_block4_sum
I1203 19:42:56.320147 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.320147 21228 net.cpp:137] Memory required for data: 657422000
I1203 19:42:56.320147 21228 layer_factory.cpp:58] Creating layer global_avg_pool
I1203 19:42:56.320147 21228 net.cpp:84] Creating Layer global_avg_pool
I1203 19:42:56.320147 21228 net.cpp:406] global_avg_pool <- group2_block4_sum
I1203 19:42:56.320147 21228 net.cpp:380] global_avg_pool -> global_avg_pool
I1203 19:42:56.320147 21228 net.cpp:122] Setting up global_avg_pool
I1203 19:42:56.320147 21228 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1203 19:42:56.320147 21228 net.cpp:137] Memory required for data: 657447600
I1203 19:42:56.320147 21228 layer_factory.cpp:58] Creating layer fc
I1203 19:42:56.320147 21228 net.cpp:84] Creating Layer fc
I1203 19:42:56.320147 21228 net.cpp:406] fc <- global_avg_pool
I1203 19:42:56.320147 21228 net.cpp:380] fc -> fc
I1203 19:42:56.320147 21228 net.cpp:122] Setting up fc
I1203 19:42:56.320147 21228 net.cpp:129] Top shape: 100 10 (1000)
I1203 19:42:56.320147 21228 net.cpp:137] Memory required for data: 657451600
I1203 19:42:56.320147 21228 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1203 19:42:56.320147 21228 net.cpp:84] Creating Layer fc_fc_0_split
I1203 19:42:56.320147 21228 net.cpp:406] fc_fc_0_split <- fc
I1203 19:42:56.320147 21228 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1203 19:42:56.320147 21228 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1203 19:42:56.321146 21228 net.cpp:122] Setting up fc_fc_0_split
I1203 19:42:56.321146 21228 net.cpp:129] Top shape: 100 10 (1000)
I1203 19:42:56.321146 21228 net.cpp:129] Top shape: 100 10 (1000)
I1203 19:42:56.321146 21228 net.cpp:137] Memory required for data: 657459600
I1203 19:42:56.321146 21228 layer_factory.cpp:58] Creating layer accuracy_training
I1203 19:42:56.321146 21228 net.cpp:84] Creating Layer accuracy_training
I1203 19:42:56.321146 21228 net.cpp:406] accuracy_training <- fc_fc_0_split_0
I1203 19:42:56.321146 21228 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1203 19:42:56.321146 21228 net.cpp:380] accuracy_training -> accuracy_training
I1203 19:42:56.321146 21228 net.cpp:122] Setting up accuracy_training
I1203 19:42:56.321146 21228 net.cpp:129] Top shape: (1)
I1203 19:42:56.321146 21228 net.cpp:137] Memory required for data: 657459604
I1203 19:42:56.321146 21228 layer_factory.cpp:58] Creating layer loss
I1203 19:42:56.321146 21228 net.cpp:84] Creating Layer loss
I1203 19:42:56.321146 21228 net.cpp:406] loss <- fc_fc_0_split_1
I1203 19:42:56.321146 21228 net.cpp:406] loss <- label_cifar_1_split_1
I1203 19:42:56.321146 21228 net.cpp:380] loss -> loss
I1203 19:42:56.321146 21228 layer_factory.cpp:58] Creating layer loss
I1203 19:42:56.321146 21228 net.cpp:122] Setting up loss
I1203 19:42:56.321146 21228 net.cpp:129] Top shape: (1)
I1203 19:42:56.321146 21228 net.cpp:132]     with loss weight 1
I1203 19:42:56.321146 21228 net.cpp:137] Memory required for data: 657459608
I1203 19:42:56.321146 21228 net.cpp:198] loss needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:200] accuracy_training does not need backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] fc_fc_0_split needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] fc needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] global_avg_pool needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_sum needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv1 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block4_conv0 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_sum needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv1 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block3_conv0 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_sum needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv1 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block2_conv0 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_sum needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv1 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block1_conv0 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_sum needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_proj needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv1 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] pool3 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group2_block0_conv0 needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group1_block4_sum needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1203 19:42:56.321146 21228 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block4_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block4_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block3_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block2_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block1_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] pool2 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_proj needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] pool1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group1_block0_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block4_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block3_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block2_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block1_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_sum needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv1 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] group0_block0_conv0 needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] first_conv_relu needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] first_conv_scale needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] first_conv_bn needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:198] first_conv needs backward computation.
I1203 19:42:56.322146 21228 net.cpp:200] label_cifar_1_split does not need backward computation.
I1203 19:42:56.322146 21228 net.cpp:200] cifar does not need backward computation.
I1203 19:42:56.322146 21228 net.cpp:242] This network produces output accuracy_training
I1203 19:42:56.322146 21228 net.cpp:242] This network produces output loss
I1203 19:42:56.322146 21228 net.cpp:255] Network initialization done.
I1203 19:42:56.323146 21228 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 19:42:56.324146 21228 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1203 19:42:56.324146 21228 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 19:42:56.324146 21228 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1203 19:42:56.324146 21228 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1203 19:42:56.324146 21228 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "Soft
I1203 19:42:56.325146 21228 layer_factory.cpp:58] Creating layer cifar
I1203 19:42:56.330147 21228 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I1203 19:42:56.331153 21228 net.cpp:84] Creating Layer cifar
I1203 19:42:56.331153 21228 net.cpp:380] cifar -> data
I1203 19:42:56.331153 21228 net.cpp:380] cifar -> label
I1203 19:42:56.331153 21228 data_layer.cpp:45] output data size: 100,3,32,32
I1203 19:42:56.337146 21228 net.cpp:122] Setting up cifar
I1203 19:42:56.337146 21228 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1203 19:42:56.337146 21228 net.cpp:129] Top shape: 100 (100)
I1203 19:42:56.337146 21228 net.cpp:137] Memory required for data: 1229200
I1203 19:42:56.337146 21228 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1203 19:42:56.337146 21228 net.cpp:84] Creating Layer label_cifar_1_split
I1203 19:42:56.337146 21228 net.cpp:406] label_cifar_1_split <- label
I1203 19:42:56.338146 21228 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1203 19:42:56.338146 21228 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1203 19:42:56.338146 21228 net.cpp:122] Setting up label_cifar_1_split
I1203 19:42:56.338146 21228 net.cpp:129] Top shape: 100 (100)
I1203 19:42:56.338146 21228 net.cpp:129] Top shape: 100 (100)
I1203 19:42:56.338146 21228 net.cpp:137] Memory required for data: 1230000
I1203 19:42:56.338146 21228 layer_factory.cpp:58] Creating layer first_conv
I1203 19:42:56.338146 21228 net.cpp:84] Creating Layer first_conv
I1203 19:42:56.338146 21228 net.cpp:406] first_conv <- data
I1203 19:42:56.338146 21228 net.cpp:380] first_conv -> first_conv
I1203 19:42:56.339146 21128 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1203 19:42:56.339146 21228 net.cpp:122] Setting up first_conv
I1203 19:42:56.339146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.339146 21228 net.cpp:137] Memory required for data: 7783600
I1203 19:42:56.339146 21228 layer_factory.cpp:58] Creating layer first_conv_bn
I1203 19:42:56.339146 21228 net.cpp:84] Creating Layer first_conv_bn
I1203 19:42:56.339146 21228 net.cpp:406] first_conv_bn <- first_conv
I1203 19:42:56.339146 21228 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1203 19:42:56.340147 21228 net.cpp:122] Setting up first_conv_bn
I1203 19:42:56.340147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.340147 21228 net.cpp:137] Memory required for data: 14337200
I1203 19:42:56.340147 21228 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 19:42:56.340147 21228 net.cpp:84] Creating Layer first_conv_scale
I1203 19:42:56.340147 21228 net.cpp:406] first_conv_scale <- first_conv
I1203 19:42:56.340147 21228 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1203 19:42:56.340147 21228 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 19:42:56.340147 21228 net.cpp:122] Setting up first_conv_scale
I1203 19:42:56.340147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.340147 21228 net.cpp:137] Memory required for data: 20890800
I1203 19:42:56.340147 21228 layer_factory.cpp:58] Creating layer first_conv_relu
I1203 19:42:56.340147 21228 net.cpp:84] Creating Layer first_conv_relu
I1203 19:42:56.340147 21228 net.cpp:406] first_conv_relu <- first_conv
I1203 19:42:56.340147 21228 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1203 19:42:56.340147 21228 net.cpp:122] Setting up first_conv_relu
I1203 19:42:56.340147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.340147 21228 net.cpp:137] Memory required for data: 27444400
I1203 19:42:56.340147 21228 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1203 19:42:56.340147 21228 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1203 19:42:56.340147 21228 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1203 19:42:56.340147 21228 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1203 19:42:56.340147 21228 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1203 19:42:56.340147 21228 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1203 19:42:56.340147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.340147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.340147 21228 net.cpp:137] Memory required for data: 40551600
I1203 19:42:56.340147 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1203 19:42:56.340147 21228 net.cpp:84] Creating Layer group0_block0_conv0
I1203 19:42:56.340147 21228 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1203 19:42:56.340147 21228 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1203 19:42:56.342146 21228 net.cpp:122] Setting up group0_block0_conv0
I1203 19:42:56.342146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.342146 21228 net.cpp:137] Memory required for data: 47105200
I1203 19:42:56.342146 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1203 19:42:56.342146 21228 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1203 19:42:56.342146 21228 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1203 19:42:56.342146 21228 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1203 19:42:56.342146 21228 net.cpp:122] Setting up group0_block0_conv0_bn
I1203 19:42:56.342146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.342146 21228 net.cpp:137] Memory required for data: 53658800
I1203 19:42:56.342146 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 19:42:56.342146 21228 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1203 19:42:56.342146 21228 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1203 19:42:56.342146 21228 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1203 19:42:56.342146 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 19:42:56.342146 21228 net.cpp:122] Setting up group0_block0_conv0_scale
I1203 19:42:56.342146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.342146 21228 net.cpp:137] Memory required for data: 60212400
I1203 19:42:56.342146 21228 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1203 19:42:56.342146 21228 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1203 19:42:56.342146 21228 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1203 19:42:56.342146 21228 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1203 19:42:56.344147 21228 net.cpp:122] Setting up group0_block0_conv0_relu
I1203 19:42:56.344147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.344147 21228 net.cpp:137] Memory required for data: 66766000
I1203 19:42:56.344147 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1203 19:42:56.344147 21228 net.cpp:84] Creating Layer group0_block0_conv1
I1203 19:42:56.344147 21228 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1203 19:42:56.344147 21228 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1203 19:42:56.345147 21228 net.cpp:122] Setting up group0_block0_conv1
I1203 19:42:56.345147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.345147 21228 net.cpp:137] Memory required for data: 73319600
I1203 19:42:56.345147 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1203 19:42:56.345147 21228 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1203 19:42:56.345147 21228 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1203 19:42:56.345147 21228 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1203 19:42:56.345147 21228 net.cpp:122] Setting up group0_block0_conv1_bn
I1203 19:42:56.345147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.345147 21228 net.cpp:137] Memory required for data: 79873200
I1203 19:42:56.345147 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 19:42:56.345147 21228 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1203 19:42:56.345147 21228 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1203 19:42:56.345147 21228 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1203 19:42:56.345147 21228 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 19:42:56.346146 21228 net.cpp:122] Setting up group0_block0_conv1_scale
I1203 19:42:56.346146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.346146 21228 net.cpp:137] Memory required for data: 86426800
I1203 19:42:56.346146 21228 layer_factory.cpp:58] Creating layer group0_block0_sum
I1203 19:42:56.346146 21228 net.cpp:84] Creating Layer group0_block0_sum
I1203 19:42:56.346146 21228 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1203 19:42:56.346146 21228 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1203 19:42:56.346146 21228 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1203 19:42:56.346146 21228 net.cpp:122] Setting up group0_block0_sum
I1203 19:42:56.346146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.346146 21228 net.cpp:137] Memory required for data: 92980400
I1203 19:42:56.346146 21228 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1203 19:42:56.346146 21228 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1203 19:42:56.346146 21228 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1203 19:42:56.346146 21228 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1203 19:42:56.346146 21228 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1203 19:42:56.346146 21228 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1203 19:42:56.346146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.346146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.346146 21228 net.cpp:137] Memory required for data: 106087600
I1203 19:42:56.346146 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1203 19:42:56.346146 21228 net.cpp:84] Creating Layer group0_block1_conv0
I1203 19:42:56.346146 21228 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1203 19:42:56.346146 21228 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1203 19:42:56.347146 21228 net.cpp:122] Setting up group0_block1_conv0
I1203 19:42:56.347146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.347146 21228 net.cpp:137] Memory required for data: 112641200
I1203 19:42:56.347146 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1203 19:42:56.347146 21228 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1203 19:42:56.347146 21228 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1203 19:42:56.347146 21228 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1203 19:42:56.347146 21228 net.cpp:122] Setting up group0_block1_conv0_bn
I1203 19:42:56.347146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.347146 21228 net.cpp:137] Memory required for data: 119194800
I1203 19:42:56.347146 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 19:42:56.347146 21228 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1203 19:42:56.347146 21228 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1203 19:42:56.347146 21228 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1203 19:42:56.347146 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 19:42:56.347146 21228 net.cpp:122] Setting up group0_block1_conv0_scale
I1203 19:42:56.347146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.347146 21228 net.cpp:137] Memory required for data: 125748400
I1203 19:42:56.347146 21228 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1203 19:42:56.347146 21228 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1203 19:42:56.347146 21228 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1203 19:42:56.348146 21228 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1203 19:42:56.348146 21228 net.cpp:122] Setting up group0_block1_conv0_relu
I1203 19:42:56.348146 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.348146 21228 net.cpp:137] Memory required for data: 132302000
I1203 19:42:56.348146 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1203 19:42:56.348146 21228 net.cpp:84] Creating Layer group0_block1_conv1
I1203 19:42:56.348146 21228 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1203 19:42:56.348146 21228 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1203 19:42:56.350147 21228 net.cpp:122] Setting up group0_block1_conv1
I1203 19:42:56.350147 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.350147 21228 net.cpp:137] Memory required for data: 138855600
I1203 19:42:56.350147 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1203 19:42:56.350147 21228 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1203 19:42:56.350147 21228 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1203 19:42:56.350147 21228 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1203 19:42:56.351148 21228 net.cpp:122] Setting up group0_block1_conv1_bn
I1203 19:42:56.351148 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.351148 21228 net.cpp:137] Memory required for data: 145409200
I1203 19:42:56.351148 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 19:42:56.351148 21228 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1203 19:42:56.351148 21228 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1203 19:42:56.351148 21228 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1203 19:42:56.351148 21228 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 19:42:56.351148 21228 net.cpp:122] Setting up group0_block1_conv1_scale
I1203 19:42:56.351148 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.351148 21228 net.cpp:137] Memory required for data: 151962800
I1203 19:42:56.351148 21228 layer_factory.cpp:58] Creating layer group0_block1_sum
I1203 19:42:56.351148 21228 net.cpp:84] Creating Layer group0_block1_sum
I1203 19:42:56.351148 21228 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1203 19:42:56.351148 21228 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1203 19:42:56.351148 21228 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1203 19:42:56.351148 21228 net.cpp:122] Setting up group0_block1_sum
I1203 19:42:56.351148 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.351148 21228 net.cpp:137] Memory required for data: 158516400
I1203 19:42:56.351148 21228 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1203 19:42:56.351148 21228 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1203 19:42:56.351148 21228 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1203 19:42:56.352149 21228 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1203 19:42:56.352149 21228 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1203 19:42:56.352149 21228 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1203 19:42:56.352149 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.352149 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.352149 21228 net.cpp:137] Memory required for data: 171623600
I1203 19:42:56.352149 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1203 19:42:56.352149 21228 net.cpp:84] Creating Layer group0_block2_conv0
I1203 19:42:56.352149 21228 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1203 19:42:56.352149 21228 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1203 19:42:56.353652 21228 net.cpp:122] Setting up group0_block2_conv0
I1203 19:42:56.353652 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.353652 21228 net.cpp:137] Memory required for data: 178177200
I1203 19:42:56.353652 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1203 19:42:56.353652 21228 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1203 19:42:56.353652 21228 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1203 19:42:56.353652 21228 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1203 19:42:56.354152 21228 net.cpp:122] Setting up group0_block2_conv0_bn
I1203 19:42:56.354152 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.354152 21228 net.cpp:137] Memory required for data: 184730800
I1203 19:42:56.354152 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 19:42:56.354152 21228 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1203 19:42:56.354152 21228 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1203 19:42:56.354152 21228 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1203 19:42:56.354152 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 19:42:56.354152 21228 net.cpp:122] Setting up group0_block2_conv0_scale
I1203 19:42:56.354652 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.354652 21228 net.cpp:137] Memory required for data: 191284400
I1203 19:42:56.354652 21228 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1203 19:42:56.354652 21228 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1203 19:42:56.354652 21228 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1203 19:42:56.354652 21228 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1203 19:42:56.355654 21228 net.cpp:122] Setting up group0_block2_conv0_relu
I1203 19:42:56.355654 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.355654 21228 net.cpp:137] Memory required for data: 197838000
I1203 19:42:56.355654 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1203 19:42:56.355654 21228 net.cpp:84] Creating Layer group0_block2_conv1
I1203 19:42:56.355654 21228 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1203 19:42:56.355654 21228 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1203 19:42:56.356653 21228 net.cpp:122] Setting up group0_block2_conv1
I1203 19:42:56.356653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.356653 21228 net.cpp:137] Memory required for data: 204391600
I1203 19:42:56.356653 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1203 19:42:56.356653 21228 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1203 19:42:56.356653 21228 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1203 19:42:56.356653 21228 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1203 19:42:56.357153 21228 net.cpp:122] Setting up group0_block2_conv1_bn
I1203 19:42:56.357153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.357153 21228 net.cpp:137] Memory required for data: 210945200
I1203 19:42:56.357153 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 19:42:56.357153 21228 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1203 19:42:56.357153 21228 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1203 19:42:56.357153 21228 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1203 19:42:56.357153 21228 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 19:42:56.357153 21228 net.cpp:122] Setting up group0_block2_conv1_scale
I1203 19:42:56.357153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.357153 21228 net.cpp:137] Memory required for data: 217498800
I1203 19:42:56.357153 21228 layer_factory.cpp:58] Creating layer group0_block2_sum
I1203 19:42:56.357153 21228 net.cpp:84] Creating Layer group0_block2_sum
I1203 19:42:56.357153 21228 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1203 19:42:56.357153 21228 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1203 19:42:56.357153 21228 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1203 19:42:56.357153 21228 net.cpp:122] Setting up group0_block2_sum
I1203 19:42:56.357153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.357153 21228 net.cpp:137] Memory required for data: 224052400
I1203 19:42:56.357153 21228 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1203 19:42:56.357153 21228 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1203 19:42:56.357653 21228 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1203 19:42:56.357653 21228 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1203 19:42:56.357653 21228 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1203 19:42:56.357653 21228 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1203 19:42:56.357653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.357653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.357653 21228 net.cpp:137] Memory required for data: 237159600
I1203 19:42:56.357653 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1203 19:42:56.357653 21228 net.cpp:84] Creating Layer group0_block3_conv0
I1203 19:42:56.357653 21228 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1203 19:42:56.357653 21228 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1203 19:42:56.358654 21228 net.cpp:122] Setting up group0_block3_conv0
I1203 19:42:56.358654 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.358654 21228 net.cpp:137] Memory required for data: 243713200
I1203 19:42:56.358654 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1203 19:42:56.358654 21228 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1203 19:42:56.358654 21228 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1203 19:42:56.358654 21228 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1203 19:42:56.359153 21228 net.cpp:122] Setting up group0_block3_conv0_bn
I1203 19:42:56.359153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.359153 21228 net.cpp:137] Memory required for data: 250266800
I1203 19:42:56.359153 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 19:42:56.359153 21228 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1203 19:42:56.359153 21228 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1203 19:42:56.359153 21228 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1203 19:42:56.359153 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 19:42:56.359153 21228 net.cpp:122] Setting up group0_block3_conv0_scale
I1203 19:42:56.359153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.359153 21228 net.cpp:137] Memory required for data: 256820400
I1203 19:42:56.359153 21228 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1203 19:42:56.359153 21228 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1203 19:42:56.359153 21228 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1203 19:42:56.359153 21228 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1203 19:42:56.359660 21228 net.cpp:122] Setting up group0_block3_conv0_relu
I1203 19:42:56.359660 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.359660 21228 net.cpp:137] Memory required for data: 263374000
I1203 19:42:56.359660 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1203 19:42:56.359660 21228 net.cpp:84] Creating Layer group0_block3_conv1
I1203 19:42:56.359660 21228 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1203 19:42:56.359660 21228 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1203 19:42:56.361153 21228 net.cpp:122] Setting up group0_block3_conv1
I1203 19:42:56.361153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.361153 21228 net.cpp:137] Memory required for data: 269927600
I1203 19:42:56.361153 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1203 19:42:56.361153 21228 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1203 19:42:56.361153 21228 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1203 19:42:56.361153 21228 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1203 19:42:56.361153 21228 net.cpp:122] Setting up group0_block3_conv1_bn
I1203 19:42:56.361153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.361153 21228 net.cpp:137] Memory required for data: 276481200
I1203 19:42:56.361153 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 19:42:56.361153 21228 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1203 19:42:56.361153 21228 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1203 19:42:56.361153 21228 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1203 19:42:56.361153 21228 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 19:42:56.361153 21228 net.cpp:122] Setting up group0_block3_conv1_scale
I1203 19:42:56.361153 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.361153 21228 net.cpp:137] Memory required for data: 283034800
I1203 19:42:56.361153 21228 layer_factory.cpp:58] Creating layer group0_block3_sum
I1203 19:42:56.361654 21228 net.cpp:84] Creating Layer group0_block3_sum
I1203 19:42:56.361654 21228 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1203 19:42:56.361654 21228 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1203 19:42:56.361654 21228 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1203 19:42:56.361654 21228 net.cpp:122] Setting up group0_block3_sum
I1203 19:42:56.361654 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.361654 21228 net.cpp:137] Memory required for data: 289588400
I1203 19:42:56.361654 21228 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1203 19:42:56.361654 21228 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1203 19:42:56.361654 21228 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1203 19:42:56.361654 21228 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1203 19:42:56.361654 21228 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1203 19:42:56.361654 21228 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1203 19:42:56.361654 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.361654 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.361654 21228 net.cpp:137] Memory required for data: 302695600
I1203 19:42:56.361654 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1203 19:42:56.361654 21228 net.cpp:84] Creating Layer group0_block4_conv0
I1203 19:42:56.361654 21228 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1203 19:42:56.361654 21228 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1203 19:42:56.363153 21228 net.cpp:122] Setting up group0_block4_conv0
I1203 19:42:56.363654 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.363654 21228 net.cpp:137] Memory required for data: 309249200
I1203 19:42:56.363654 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1203 19:42:56.363654 21228 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1203 19:42:56.363654 21228 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1203 19:42:56.363654 21228 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1203 19:42:56.364154 21228 net.cpp:122] Setting up group0_block4_conv0_bn
I1203 19:42:56.364154 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.364154 21228 net.cpp:137] Memory required for data: 315802800
I1203 19:42:56.364154 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 19:42:56.364154 21228 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1203 19:42:56.364154 21228 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1203 19:42:56.364154 21228 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1203 19:42:56.364154 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 19:42:56.364154 21228 net.cpp:122] Setting up group0_block4_conv0_scale
I1203 19:42:56.364154 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.364154 21228 net.cpp:137] Memory required for data: 322356400
I1203 19:42:56.364154 21228 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1203 19:42:56.364154 21228 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1203 19:42:56.364154 21228 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1203 19:42:56.364655 21228 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1203 19:42:56.364655 21228 net.cpp:122] Setting up group0_block4_conv0_relu
I1203 19:42:56.364655 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.364655 21228 net.cpp:137] Memory required for data: 328910000
I1203 19:42:56.364655 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1203 19:42:56.364655 21228 net.cpp:84] Creating Layer group0_block4_conv1
I1203 19:42:56.364655 21228 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1203 19:42:56.364655 21228 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1203 19:42:56.366159 21228 net.cpp:122] Setting up group0_block4_conv1
I1203 19:42:56.366159 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.366159 21228 net.cpp:137] Memory required for data: 335463600
I1203 19:42:56.366159 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1203 19:42:56.366159 21228 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1203 19:42:56.366159 21228 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1203 19:42:56.366159 21228 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1203 19:42:56.366159 21228 net.cpp:122] Setting up group0_block4_conv1_bn
I1203 19:42:56.366159 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.366159 21228 net.cpp:137] Memory required for data: 342017200
I1203 19:42:56.366159 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 19:42:56.366159 21228 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1203 19:42:56.366159 21228 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1203 19:42:56.366159 21228 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1203 19:42:56.366653 21228 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 19:42:56.366653 21228 net.cpp:122] Setting up group0_block4_conv1_scale
I1203 19:42:56.366653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.366653 21228 net.cpp:137] Memory required for data: 348570800
I1203 19:42:56.366653 21228 layer_factory.cpp:58] Creating layer group0_block4_sum
I1203 19:42:56.366653 21228 net.cpp:84] Creating Layer group0_block4_sum
I1203 19:42:56.366653 21228 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1203 19:42:56.366653 21228 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1203 19:42:56.366653 21228 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1203 19:42:56.366653 21228 net.cpp:122] Setting up group0_block4_sum
I1203 19:42:56.366653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.366653 21228 net.cpp:137] Memory required for data: 355124400
I1203 19:42:56.366653 21228 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1203 19:42:56.366653 21228 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1203 19:42:56.366653 21228 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1203 19:42:56.366653 21228 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1203 19:42:56.366653 21228 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1203 19:42:56.366653 21228 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1203 19:42:56.366653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.366653 21228 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 19:42:56.366653 21228 net.cpp:137] Memory required for data: 368231600
I1203 19:42:56.366653 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1203 19:42:56.367154 21228 net.cpp:84] Creating Layer group1_block0_conv0
I1203 19:42:56.367154 21228 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1203 19:42:56.367154 21228 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1203 19:42:56.369153 21228 net.cpp:122] Setting up group1_block0_conv0
I1203 19:42:56.369153 21228 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1203 19:42:56.369153 21228 net.cpp:137] Memory required for data: 381338800
I1203 19:42:56.369153 21228 layer_factory.cpp:58] Creating layer pool1
I1203 19:42:56.369153 21228 net.cpp:84] Creating Layer pool1
I1203 19:42:56.369153 21228 net.cpp:406] pool1 <- group1_block0_conv0
I1203 19:42:56.369153 21228 net.cpp:380] pool1 -> pool1
I1203 19:42:56.369153 21228 net.cpp:122] Setting up pool1
I1203 19:42:56.369153 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.369153 21228 net.cpp:137] Memory required for data: 384615600
I1203 19:42:56.369153 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1203 19:42:56.369153 21228 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1203 19:42:56.369153 21228 net.cpp:406] group1_block0_conv0_bn <- pool1
I1203 19:42:56.369153 21228 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1203 19:42:56.370157 21228 net.cpp:122] Setting up group1_block0_conv0_bn
I1203 19:42:56.370157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.370157 21228 net.cpp:137] Memory required for data: 387892400
I1203 19:42:56.370157 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 19:42:56.370157 21228 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1203 19:42:56.370157 21228 net.cpp:406] group1_block0_conv0_scale <- pool1
I1203 19:42:56.370157 21228 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1203 19:42:56.370157 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 19:42:56.370157 21228 net.cpp:122] Setting up group1_block0_conv0_scale
I1203 19:42:56.370157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.370157 21228 net.cpp:137] Memory required for data: 391169200
I1203 19:42:56.370157 21228 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1203 19:42:56.370157 21228 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1203 19:42:56.370157 21228 net.cpp:406] group1_block0_conv0_relu <- pool1
I1203 19:42:56.370157 21228 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1203 19:42:56.370157 21228 net.cpp:122] Setting up group1_block0_conv0_relu
I1203 19:42:56.370157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.370157 21228 net.cpp:137] Memory required for data: 394446000
I1203 19:42:56.370157 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1203 19:42:56.370157 21228 net.cpp:84] Creating Layer group1_block0_conv1
I1203 19:42:56.370157 21228 net.cpp:406] group1_block0_conv1 <- pool1
I1203 19:42:56.370157 21228 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1203 19:42:56.371156 21228 net.cpp:122] Setting up group1_block0_conv1
I1203 19:42:56.371156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.371156 21228 net.cpp:137] Memory required for data: 397722800
I1203 19:42:56.371156 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1203 19:42:56.371156 21228 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1203 19:42:56.371156 21228 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1203 19:42:56.371156 21228 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1203 19:42:56.372158 21228 net.cpp:122] Setting up group1_block0_conv1_bn
I1203 19:42:56.372158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.372158 21228 net.cpp:137] Memory required for data: 400999600
I1203 19:42:56.372158 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 19:42:56.372158 21228 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1203 19:42:56.372158 21228 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1203 19:42:56.372158 21228 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1203 19:42:56.372158 21228 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 19:42:56.372158 21228 net.cpp:122] Setting up group1_block0_conv1_scale
I1203 19:42:56.372158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.372158 21228 net.cpp:137] Memory required for data: 404276400
I1203 19:42:56.372158 21228 layer_factory.cpp:58] Creating layer group1_block0_proj
I1203 19:42:56.372158 21228 net.cpp:84] Creating Layer group1_block0_proj
I1203 19:42:56.372158 21228 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1203 19:42:56.372158 21228 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1203 19:42:56.373157 21228 net.cpp:122] Setting up group1_block0_proj
I1203 19:42:56.373157 21228 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1203 19:42:56.373157 21228 net.cpp:137] Memory required for data: 416577200
I1203 19:42:56.373157 21228 layer_factory.cpp:58] Creating layer pool2
I1203 19:42:56.373157 21228 net.cpp:84] Creating Layer pool2
I1203 19:42:56.373157 21228 net.cpp:406] pool2 <- group1_block0_proj
I1203 19:42:56.373157 21228 net.cpp:380] pool2 -> pool2
I1203 19:42:56.373157 21228 net.cpp:122] Setting up pool2
I1203 19:42:56.373157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.373157 21228 net.cpp:137] Memory required for data: 419854000
I1203 19:42:56.373157 21228 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1203 19:42:56.373157 21228 net.cpp:84] Creating Layer group1_block0_proj_bn
I1203 19:42:56.373157 21228 net.cpp:406] group1_block0_proj_bn <- pool2
I1203 19:42:56.373157 21228 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1203 19:42:56.373157 21228 net.cpp:122] Setting up group1_block0_proj_bn
I1203 19:42:56.373157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.373157 21228 net.cpp:137] Memory required for data: 423130800
I1203 19:42:56.374157 21228 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 19:42:56.374157 21228 net.cpp:84] Creating Layer group1_block0_proj_scale
I1203 19:42:56.374157 21228 net.cpp:406] group1_block0_proj_scale <- pool2
I1203 19:42:56.374157 21228 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1203 19:42:56.374157 21228 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 19:42:56.374157 21228 net.cpp:122] Setting up group1_block0_proj_scale
I1203 19:42:56.374157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.374157 21228 net.cpp:137] Memory required for data: 426407600
I1203 19:42:56.374157 21228 layer_factory.cpp:58] Creating layer group1_block0_sum
I1203 19:42:56.374157 21228 net.cpp:84] Creating Layer group1_block0_sum
I1203 19:42:56.374157 21228 net.cpp:406] group1_block0_sum <- pool2
I1203 19:42:56.374157 21228 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1203 19:42:56.374157 21228 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1203 19:42:56.374157 21228 net.cpp:122] Setting up group1_block0_sum
I1203 19:42:56.374157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.374157 21228 net.cpp:137] Memory required for data: 429684400
I1203 19:42:56.374157 21228 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1203 19:42:56.374157 21228 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1203 19:42:56.374157 21228 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1203 19:42:56.374157 21228 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1203 19:42:56.374157 21228 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1203 19:42:56.374157 21228 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1203 19:42:56.374157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.374157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.374157 21228 net.cpp:137] Memory required for data: 436238000
I1203 19:42:56.374157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1203 19:42:56.374157 21228 net.cpp:84] Creating Layer group1_block1_conv0
I1203 19:42:56.374157 21228 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1203 19:42:56.374157 21228 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1203 19:42:56.375157 21228 net.cpp:122] Setting up group1_block1_conv0
I1203 19:42:56.375157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.375157 21228 net.cpp:137] Memory required for data: 439514800
I1203 19:42:56.375157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1203 19:42:56.375157 21228 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1203 19:42:56.375157 21228 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1203 19:42:56.375157 21228 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1203 19:42:56.376157 21228 net.cpp:122] Setting up group1_block1_conv0_bn
I1203 19:42:56.376157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.376157 21228 net.cpp:137] Memory required for data: 442791600
I1203 19:42:56.376157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 19:42:56.376157 21228 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1203 19:42:56.376157 21228 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1203 19:42:56.376157 21228 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1203 19:42:56.376157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 19:42:56.376157 21228 net.cpp:122] Setting up group1_block1_conv0_scale
I1203 19:42:56.376157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.376157 21228 net.cpp:137] Memory required for data: 446068400
I1203 19:42:56.376157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1203 19:42:56.376157 21228 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1203 19:42:56.376157 21228 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1203 19:42:56.376157 21228 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1203 19:42:56.376157 21228 net.cpp:122] Setting up group1_block1_conv0_relu
I1203 19:42:56.376157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.376157 21228 net.cpp:137] Memory required for data: 449345200
I1203 19:42:56.376157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1203 19:42:56.376157 21228 net.cpp:84] Creating Layer group1_block1_conv1
I1203 19:42:56.376157 21228 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1203 19:42:56.376157 21228 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1203 19:42:56.377156 21228 net.cpp:122] Setting up group1_block1_conv1
I1203 19:42:56.377156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.377156 21228 net.cpp:137] Memory required for data: 452622000
I1203 19:42:56.377156 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1203 19:42:56.377156 21228 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1203 19:42:56.377156 21228 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1203 19:42:56.377156 21228 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1203 19:42:56.378157 21228 net.cpp:122] Setting up group1_block1_conv1_bn
I1203 19:42:56.378157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.378157 21228 net.cpp:137] Memory required for data: 455898800
I1203 19:42:56.378157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 19:42:56.378157 21228 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1203 19:42:56.378157 21228 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1203 19:42:56.378157 21228 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1203 19:42:56.378157 21228 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 19:42:56.378157 21228 net.cpp:122] Setting up group1_block1_conv1_scale
I1203 19:42:56.378157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.378157 21228 net.cpp:137] Memory required for data: 459175600
I1203 19:42:56.378157 21228 layer_factory.cpp:58] Creating layer group1_block1_sum
I1203 19:42:56.378157 21228 net.cpp:84] Creating Layer group1_block1_sum
I1203 19:42:56.378157 21228 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1203 19:42:56.378157 21228 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1203 19:42:56.378157 21228 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1203 19:42:56.378157 21228 net.cpp:122] Setting up group1_block1_sum
I1203 19:42:56.378157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.378157 21228 net.cpp:137] Memory required for data: 462452400
I1203 19:42:56.378157 21228 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1203 19:42:56.378157 21228 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1203 19:42:56.378157 21228 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1203 19:42:56.378157 21228 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1203 19:42:56.378157 21228 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1203 19:42:56.378157 21228 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1203 19:42:56.378157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.378157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.378157 21228 net.cpp:137] Memory required for data: 469006000
I1203 19:42:56.378157 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1203 19:42:56.378157 21228 net.cpp:84] Creating Layer group1_block2_conv0
I1203 19:42:56.378157 21228 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1203 19:42:56.378157 21228 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1203 19:42:56.379156 21228 net.cpp:122] Setting up group1_block2_conv0
I1203 19:42:56.379156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.379156 21228 net.cpp:137] Memory required for data: 472282800
I1203 19:42:56.379156 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1203 19:42:56.379156 21228 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1203 19:42:56.379156 21228 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1203 19:42:56.379156 21228 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1203 19:42:56.380157 21228 net.cpp:122] Setting up group1_block2_conv0_bn
I1203 19:42:56.380157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.380157 21228 net.cpp:137] Memory required for data: 475559600
I1203 19:42:56.380157 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 19:42:56.380157 21228 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1203 19:42:56.380157 21228 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1203 19:42:56.380157 21228 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1203 19:42:56.380157 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 19:42:56.380157 21228 net.cpp:122] Setting up group1_block2_conv0_scale
I1203 19:42:56.380157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.380157 21228 net.cpp:137] Memory required for data: 478836400
I1203 19:42:56.380157 21228 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1203 19:42:56.380157 21228 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1203 19:42:56.380157 21228 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1203 19:42:56.380157 21228 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1203 19:42:56.380157 21228 net.cpp:122] Setting up group1_block2_conv0_relu
I1203 19:42:56.380157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.380157 21228 net.cpp:137] Memory required for data: 482113200
I1203 19:42:56.380157 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1203 19:42:56.380157 21228 net.cpp:84] Creating Layer group1_block2_conv1
I1203 19:42:56.380157 21228 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1203 19:42:56.380157 21228 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1203 19:42:56.381157 21228 net.cpp:122] Setting up group1_block2_conv1
I1203 19:42:56.381157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.381157 21228 net.cpp:137] Memory required for data: 485390000
I1203 19:42:56.381157 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1203 19:42:56.381157 21228 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1203 19:42:56.381157 21228 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1203 19:42:56.382158 21228 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1203 19:42:56.382158 21228 net.cpp:122] Setting up group1_block2_conv1_bn
I1203 19:42:56.382158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.382158 21228 net.cpp:137] Memory required for data: 488666800
I1203 19:42:56.382158 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 19:42:56.382158 21228 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1203 19:42:56.382158 21228 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1203 19:42:56.382158 21228 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1203 19:42:56.382158 21228 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 19:42:56.382158 21228 net.cpp:122] Setting up group1_block2_conv1_scale
I1203 19:42:56.382158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.382158 21228 net.cpp:137] Memory required for data: 491943600
I1203 19:42:56.382158 21228 layer_factory.cpp:58] Creating layer group1_block2_sum
I1203 19:42:56.382158 21228 net.cpp:84] Creating Layer group1_block2_sum
I1203 19:42:56.382158 21228 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1203 19:42:56.382158 21228 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1203 19:42:56.382158 21228 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1203 19:42:56.382158 21228 net.cpp:122] Setting up group1_block2_sum
I1203 19:42:56.382158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.382158 21228 net.cpp:137] Memory required for data: 495220400
I1203 19:42:56.382158 21228 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1203 19:42:56.382158 21228 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1203 19:42:56.382158 21228 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1203 19:42:56.382158 21228 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1203 19:42:56.382158 21228 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1203 19:42:56.382158 21228 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1203 19:42:56.382158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.382158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.382158 21228 net.cpp:137] Memory required for data: 501774000
I1203 19:42:56.382158 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1203 19:42:56.382158 21228 net.cpp:84] Creating Layer group1_block3_conv0
I1203 19:42:56.382158 21228 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1203 19:42:56.382158 21228 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1203 19:42:56.384157 21228 net.cpp:122] Setting up group1_block3_conv0
I1203 19:42:56.384157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.384157 21228 net.cpp:137] Memory required for data: 505050800
I1203 19:42:56.384157 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1203 19:42:56.384157 21228 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1203 19:42:56.384157 21228 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1203 19:42:56.384157 21228 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1203 19:42:56.385164 21228 net.cpp:122] Setting up group1_block3_conv0_bn
I1203 19:42:56.385164 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.385164 21228 net.cpp:137] Memory required for data: 508327600
I1203 19:42:56.385164 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 19:42:56.385164 21228 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1203 19:42:56.385164 21228 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1203 19:42:56.385164 21228 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1203 19:42:56.385164 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 19:42:56.385164 21228 net.cpp:122] Setting up group1_block3_conv0_scale
I1203 19:42:56.385164 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.385164 21228 net.cpp:137] Memory required for data: 511604400
I1203 19:42:56.385164 21228 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1203 19:42:56.385164 21228 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1203 19:42:56.385164 21228 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1203 19:42:56.385164 21228 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1203 19:42:56.385164 21228 net.cpp:122] Setting up group1_block3_conv0_relu
I1203 19:42:56.385164 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.385164 21228 net.cpp:137] Memory required for data: 514881200
I1203 19:42:56.385164 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1203 19:42:56.385164 21228 net.cpp:84] Creating Layer group1_block3_conv1
I1203 19:42:56.385164 21228 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1203 19:42:56.386157 21228 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1203 19:42:56.387156 21228 net.cpp:122] Setting up group1_block3_conv1
I1203 19:42:56.387156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.387156 21228 net.cpp:137] Memory required for data: 518158000
I1203 19:42:56.387156 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1203 19:42:56.387156 21228 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1203 19:42:56.387156 21228 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1203 19:42:56.387156 21228 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1203 19:42:56.387156 21228 net.cpp:122] Setting up group1_block3_conv1_bn
I1203 19:42:56.387156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.387156 21228 net.cpp:137] Memory required for data: 521434800
I1203 19:42:56.387156 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 19:42:56.387156 21228 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1203 19:42:56.387156 21228 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1203 19:42:56.387156 21228 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1203 19:42:56.387156 21228 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 19:42:56.387156 21228 net.cpp:122] Setting up group1_block3_conv1_scale
I1203 19:42:56.387156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.387156 21228 net.cpp:137] Memory required for data: 524711600
I1203 19:42:56.387156 21228 layer_factory.cpp:58] Creating layer group1_block3_sum
I1203 19:42:56.387156 21228 net.cpp:84] Creating Layer group1_block3_sum
I1203 19:42:56.387156 21228 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1203 19:42:56.387156 21228 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1203 19:42:56.387156 21228 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1203 19:42:56.387156 21228 net.cpp:122] Setting up group1_block3_sum
I1203 19:42:56.387156 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.387156 21228 net.cpp:137] Memory required for data: 527988400
I1203 19:42:56.387156 21228 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1203 19:42:56.387156 21228 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1203 19:42:56.387156 21228 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1203 19:42:56.387156 21228 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1203 19:42:56.388157 21228 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1203 19:42:56.388157 21228 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1203 19:42:56.388157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.388157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.388157 21228 net.cpp:137] Memory required for data: 534542000
I1203 19:42:56.388157 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1203 19:42:56.388157 21228 net.cpp:84] Creating Layer group1_block4_conv0
I1203 19:42:56.388157 21228 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1203 19:42:56.388157 21228 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1203 19:42:56.389158 21228 net.cpp:122] Setting up group1_block4_conv0
I1203 19:42:56.389158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.389158 21228 net.cpp:137] Memory required for data: 537818800
I1203 19:42:56.389158 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1203 19:42:56.389158 21228 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1203 19:42:56.389158 21228 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1203 19:42:56.389158 21228 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1203 19:42:56.389158 21228 net.cpp:122] Setting up group1_block4_conv0_bn
I1203 19:42:56.389158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.389158 21228 net.cpp:137] Memory required for data: 541095600
I1203 19:42:56.389158 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 19:42:56.389158 21228 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1203 19:42:56.389158 21228 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1203 19:42:56.389158 21228 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1203 19:42:56.390157 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 19:42:56.390157 21228 net.cpp:122] Setting up group1_block4_conv0_scale
I1203 19:42:56.390157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.390157 21228 net.cpp:137] Memory required for data: 544372400
I1203 19:42:56.390157 21228 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1203 19:42:56.390157 21228 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1203 19:42:56.390157 21228 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1203 19:42:56.390157 21228 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1203 19:42:56.390157 21228 net.cpp:122] Setting up group1_block4_conv0_relu
I1203 19:42:56.390157 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.390157 21228 net.cpp:137] Memory required for data: 547649200
I1203 19:42:56.390157 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1203 19:42:56.390157 21228 net.cpp:84] Creating Layer group1_block4_conv1
I1203 19:42:56.390157 21228 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1203 19:42:56.390157 21228 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1203 19:42:56.391156 21228 net.cpp:122] Setting up group1_block4_conv1
I1203 19:42:56.392158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.392158 21228 net.cpp:137] Memory required for data: 550926000
I1203 19:42:56.392158 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1203 19:42:56.392158 21228 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1203 19:42:56.392158 21228 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1203 19:42:56.392158 21228 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1203 19:42:56.392158 21228 net.cpp:122] Setting up group1_block4_conv1_bn
I1203 19:42:56.392158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.392158 21228 net.cpp:137] Memory required for data: 554202800
I1203 19:42:56.392158 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 19:42:56.392158 21228 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1203 19:42:56.392158 21228 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1203 19:42:56.392158 21228 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1203 19:42:56.392158 21228 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 19:42:56.392158 21228 net.cpp:122] Setting up group1_block4_conv1_scale
I1203 19:42:56.392158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.392158 21228 net.cpp:137] Memory required for data: 557479600
I1203 19:42:56.392158 21228 layer_factory.cpp:58] Creating layer group1_block4_sum
I1203 19:42:56.392158 21228 net.cpp:84] Creating Layer group1_block4_sum
I1203 19:42:56.392158 21228 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1203 19:42:56.392158 21228 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1203 19:42:56.392158 21228 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1203 19:42:56.392158 21228 net.cpp:122] Setting up group1_block4_sum
I1203 19:42:56.392158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.392158 21228 net.cpp:137] Memory required for data: 560756400
I1203 19:42:56.392158 21228 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1203 19:42:56.392158 21228 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1203 19:42:56.392158 21228 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1203 19:42:56.392158 21228 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1203 19:42:56.392158 21228 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1203 19:42:56.392158 21228 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1203 19:42:56.392158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.392158 21228 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 19:42:56.392158 21228 net.cpp:137] Memory required for data: 567310000
I1203 19:42:56.392158 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1203 19:42:56.392158 21228 net.cpp:84] Creating Layer group2_block0_conv0
I1203 19:42:56.392158 21228 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1203 19:42:56.392158 21228 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1203 19:42:56.394157 21228 net.cpp:122] Setting up group2_block0_conv0
I1203 19:42:56.394157 21228 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1203 19:42:56.394157 21228 net.cpp:137] Memory required for data: 573863600
I1203 19:42:56.394157 21228 layer_factory.cpp:58] Creating layer pool3
I1203 19:42:56.394157 21228 net.cpp:84] Creating Layer pool3
I1203 19:42:56.394157 21228 net.cpp:406] pool3 <- group2_block0_conv0
I1203 19:42:56.394157 21228 net.cpp:380] pool3 -> pool3
I1203 19:42:56.394157 21228 net.cpp:122] Setting up pool3
I1203 19:42:56.394157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.394157 21228 net.cpp:137] Memory required for data: 575502000
I1203 19:42:56.394157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1203 19:42:56.394157 21228 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1203 19:42:56.394157 21228 net.cpp:406] group2_block0_conv0_bn <- pool3
I1203 19:42:56.394157 21228 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1203 19:42:56.394157 21228 net.cpp:122] Setting up group2_block0_conv0_bn
I1203 19:42:56.394157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.394157 21228 net.cpp:137] Memory required for data: 577140400
I1203 19:42:56.394157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 19:42:56.394157 21228 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1203 19:42:56.394157 21228 net.cpp:406] group2_block0_conv0_scale <- pool3
I1203 19:42:56.394157 21228 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1203 19:42:56.394157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 19:42:56.394157 21228 net.cpp:122] Setting up group2_block0_conv0_scale
I1203 19:42:56.394157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.394157 21228 net.cpp:137] Memory required for data: 578778800
I1203 19:42:56.394157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1203 19:42:56.394157 21228 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1203 19:42:56.394157 21228 net.cpp:406] group2_block0_conv0_relu <- pool3
I1203 19:42:56.394157 21228 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1203 19:42:56.394157 21228 net.cpp:122] Setting up group2_block0_conv0_relu
I1203 19:42:56.394157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.394157 21228 net.cpp:137] Memory required for data: 580417200
I1203 19:42:56.394157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1203 19:42:56.395157 21228 net.cpp:84] Creating Layer group2_block0_conv1
I1203 19:42:56.395157 21228 net.cpp:406] group2_block0_conv1 <- pool3
I1203 19:42:56.395157 21228 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1203 19:42:56.396157 21228 net.cpp:122] Setting up group2_block0_conv1
I1203 19:42:56.396157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.396157 21228 net.cpp:137] Memory required for data: 582055600
I1203 19:42:56.396157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1203 19:42:56.397157 21228 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1203 19:42:56.397157 21228 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1203 19:42:56.397157 21228 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1203 19:42:56.397157 21228 net.cpp:122] Setting up group2_block0_conv1_bn
I1203 19:42:56.397157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.397157 21228 net.cpp:137] Memory required for data: 583694000
I1203 19:42:56.397157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 19:42:56.397157 21228 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1203 19:42:56.397157 21228 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1203 19:42:56.397157 21228 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1203 19:42:56.397157 21228 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 19:42:56.397157 21228 net.cpp:122] Setting up group2_block0_conv1_scale
I1203 19:42:56.397157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.397157 21228 net.cpp:137] Memory required for data: 585332400
I1203 19:42:56.397157 21228 layer_factory.cpp:58] Creating layer group2_block0_proj
I1203 19:42:56.397157 21228 net.cpp:84] Creating Layer group2_block0_proj
I1203 19:42:56.397157 21228 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1203 19:42:56.397157 21228 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1203 19:42:56.398157 21228 net.cpp:122] Setting up group2_block0_proj
I1203 19:42:56.398157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.398157 21228 net.cpp:137] Memory required for data: 586970800
I1203 19:42:56.398157 21228 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1203 19:42:56.398157 21228 net.cpp:84] Creating Layer group2_block0_proj_bn
I1203 19:42:56.398157 21228 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1203 19:42:56.398157 21228 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1203 19:42:56.398157 21228 net.cpp:122] Setting up group2_block0_proj_bn
I1203 19:42:56.398157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.398157 21228 net.cpp:137] Memory required for data: 588609200
I1203 19:42:56.398157 21228 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 19:42:56.398157 21228 net.cpp:84] Creating Layer group2_block0_proj_scale
I1203 19:42:56.398157 21228 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1203 19:42:56.398157 21228 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1203 19:42:56.398157 21228 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 19:42:56.399158 21228 net.cpp:122] Setting up group2_block0_proj_scale
I1203 19:42:56.399158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.399158 21228 net.cpp:137] Memory required for data: 590247600
I1203 19:42:56.399158 21228 layer_factory.cpp:58] Creating layer group2_block0_sum
I1203 19:42:56.399158 21228 net.cpp:84] Creating Layer group2_block0_sum
I1203 19:42:56.399158 21228 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1203 19:42:56.399158 21228 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1203 19:42:56.399158 21228 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1203 19:42:56.399158 21228 net.cpp:122] Setting up group2_block0_sum
I1203 19:42:56.399158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.399158 21228 net.cpp:137] Memory required for data: 591886000
I1203 19:42:56.399158 21228 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1203 19:42:56.399158 21228 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1203 19:42:56.399158 21228 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1203 19:42:56.399158 21228 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1203 19:42:56.399158 21228 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1203 19:42:56.399158 21228 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1203 19:42:56.399158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.399158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.399158 21228 net.cpp:137] Memory required for data: 595162800
I1203 19:42:56.399158 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1203 19:42:56.399158 21228 net.cpp:84] Creating Layer group2_block1_conv0
I1203 19:42:56.399158 21228 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1203 19:42:56.399158 21228 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1203 19:42:56.401156 21228 net.cpp:122] Setting up group2_block1_conv0
I1203 19:42:56.401156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.401156 21228 net.cpp:137] Memory required for data: 596801200
I1203 19:42:56.401156 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1203 19:42:56.401156 21228 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1203 19:42:56.401156 21228 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1203 19:42:56.401156 21228 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1203 19:42:56.402164 21228 net.cpp:122] Setting up group2_block1_conv0_bn
I1203 19:42:56.402164 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.402164 21228 net.cpp:137] Memory required for data: 598439600
I1203 19:42:56.402164 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 19:42:56.402164 21228 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1203 19:42:56.402164 21228 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1203 19:42:56.402164 21228 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1203 19:42:56.402164 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 19:42:56.402164 21228 net.cpp:122] Setting up group2_block1_conv0_scale
I1203 19:42:56.402164 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.402164 21228 net.cpp:137] Memory required for data: 600078000
I1203 19:42:56.402164 21228 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1203 19:42:56.402164 21228 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1203 19:42:56.402164 21228 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1203 19:42:56.402164 21228 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1203 19:42:56.402164 21228 net.cpp:122] Setting up group2_block1_conv0_relu
I1203 19:42:56.402164 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.402164 21228 net.cpp:137] Memory required for data: 601716400
I1203 19:42:56.402164 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1203 19:42:56.402164 21228 net.cpp:84] Creating Layer group2_block1_conv1
I1203 19:42:56.402164 21228 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1203 19:42:56.402164 21228 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1203 19:42:56.405158 21228 net.cpp:122] Setting up group2_block1_conv1
I1203 19:42:56.405158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.405158 21228 net.cpp:137] Memory required for data: 603354800
I1203 19:42:56.405158 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1203 19:42:56.405158 21228 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1203 19:42:56.405158 21228 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1203 19:42:56.405158 21228 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1203 19:42:56.405158 21228 net.cpp:122] Setting up group2_block1_conv1_bn
I1203 19:42:56.405158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.405158 21228 net.cpp:137] Memory required for data: 604993200
I1203 19:42:56.405158 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 19:42:56.405158 21228 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1203 19:42:56.405158 21228 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1203 19:42:56.405158 21228 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1203 19:42:56.405158 21228 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 19:42:56.405158 21228 net.cpp:122] Setting up group2_block1_conv1_scale
I1203 19:42:56.405158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.405158 21228 net.cpp:137] Memory required for data: 606631600
I1203 19:42:56.405158 21228 layer_factory.cpp:58] Creating layer group2_block1_sum
I1203 19:42:56.405158 21228 net.cpp:84] Creating Layer group2_block1_sum
I1203 19:42:56.405158 21228 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1203 19:42:56.405158 21228 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1203 19:42:56.405158 21228 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1203 19:42:56.406157 21228 net.cpp:122] Setting up group2_block1_sum
I1203 19:42:56.406157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.406157 21228 net.cpp:137] Memory required for data: 608270000
I1203 19:42:56.406157 21228 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1203 19:42:56.406157 21228 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1203 19:42:56.406157 21228 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1203 19:42:56.406157 21228 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1203 19:42:56.406157 21228 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1203 19:42:56.406157 21228 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1203 19:42:56.406157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.406157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.406157 21228 net.cpp:137] Memory required for data: 611546800
I1203 19:42:56.406157 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1203 19:42:56.406157 21228 net.cpp:84] Creating Layer group2_block2_conv0
I1203 19:42:56.406157 21228 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1203 19:42:56.406157 21228 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1203 19:42:56.408156 21228 net.cpp:122] Setting up group2_block2_conv0
I1203 19:42:56.408156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.408156 21228 net.cpp:137] Memory required for data: 613185200
I1203 19:42:56.408156 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1203 19:42:56.408156 21228 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1203 19:42:56.408156 21228 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1203 19:42:56.408156 21228 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1203 19:42:56.408156 21228 net.cpp:122] Setting up group2_block2_conv0_bn
I1203 19:42:56.408156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.408156 21228 net.cpp:137] Memory required for data: 614823600
I1203 19:42:56.408156 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 19:42:56.408156 21228 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1203 19:42:56.408156 21228 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1203 19:42:56.408156 21228 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1203 19:42:56.408156 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 19:42:56.408156 21228 net.cpp:122] Setting up group2_block2_conv0_scale
I1203 19:42:56.408156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.408156 21228 net.cpp:137] Memory required for data: 616462000
I1203 19:42:56.408156 21228 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1203 19:42:56.408156 21228 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1203 19:42:56.408156 21228 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1203 19:42:56.408156 21228 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1203 19:42:56.408156 21228 net.cpp:122] Setting up group2_block2_conv0_relu
I1203 19:42:56.408156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.408156 21228 net.cpp:137] Memory required for data: 618100400
I1203 19:42:56.408156 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1203 19:42:56.408156 21228 net.cpp:84] Creating Layer group2_block2_conv1
I1203 19:42:56.408156 21228 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1203 19:42:56.408156 21228 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1203 19:42:56.411157 21228 net.cpp:122] Setting up group2_block2_conv1
I1203 19:42:56.411157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.411157 21228 net.cpp:137] Memory required for data: 619738800
I1203 19:42:56.411157 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1203 19:42:56.411157 21228 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1203 19:42:56.411157 21228 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1203 19:42:56.411157 21228 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1203 19:42:56.411157 21228 net.cpp:122] Setting up group2_block2_conv1_bn
I1203 19:42:56.411157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.411157 21228 net.cpp:137] Memory required for data: 621377200
I1203 19:42:56.411157 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 19:42:56.411157 21228 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1203 19:42:56.411157 21228 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1203 19:42:56.411157 21228 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1203 19:42:56.411157 21228 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 19:42:56.411157 21228 net.cpp:122] Setting up group2_block2_conv1_scale
I1203 19:42:56.411157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.411157 21228 net.cpp:137] Memory required for data: 623015600
I1203 19:42:56.411157 21228 layer_factory.cpp:58] Creating layer group2_block2_sum
I1203 19:42:56.411157 21228 net.cpp:84] Creating Layer group2_block2_sum
I1203 19:42:56.411157 21228 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1203 19:42:56.411157 21228 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1203 19:42:56.411157 21228 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1203 19:42:56.411157 21228 net.cpp:122] Setting up group2_block2_sum
I1203 19:42:56.411157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.411157 21228 net.cpp:137] Memory required for data: 624654000
I1203 19:42:56.411157 21228 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1203 19:42:56.411157 21228 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1203 19:42:56.411157 21228 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1203 19:42:56.411157 21228 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1203 19:42:56.411157 21228 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1203 19:42:56.412158 21228 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1203 19:42:56.412158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.412158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.412158 21228 net.cpp:137] Memory required for data: 627930800
I1203 19:42:56.412158 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1203 19:42:56.412158 21228 net.cpp:84] Creating Layer group2_block3_conv0
I1203 19:42:56.412158 21228 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1203 19:42:56.412158 21228 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1203 19:42:56.413156 21228 net.cpp:122] Setting up group2_block3_conv0
I1203 19:42:56.413156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.413156 21228 net.cpp:137] Memory required for data: 629569200
I1203 19:42:56.413156 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1203 19:42:56.413156 21228 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1203 19:42:56.413156 21228 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1203 19:42:56.413156 21228 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1203 19:42:56.414157 21228 net.cpp:122] Setting up group2_block3_conv0_bn
I1203 19:42:56.414157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.414157 21228 net.cpp:137] Memory required for data: 631207600
I1203 19:42:56.414157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 19:42:56.414157 21228 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1203 19:42:56.414157 21228 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1203 19:42:56.414157 21228 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1203 19:42:56.414157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 19:42:56.414157 21228 net.cpp:122] Setting up group2_block3_conv0_scale
I1203 19:42:56.414157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.414157 21228 net.cpp:137] Memory required for data: 632846000
I1203 19:42:56.414157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1203 19:42:56.414157 21228 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1203 19:42:56.414157 21228 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1203 19:42:56.414157 21228 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1203 19:42:56.414157 21228 net.cpp:122] Setting up group2_block3_conv0_relu
I1203 19:42:56.414157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.414157 21228 net.cpp:137] Memory required for data: 634484400
I1203 19:42:56.414157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1203 19:42:56.414157 21228 net.cpp:84] Creating Layer group2_block3_conv1
I1203 19:42:56.414157 21228 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1203 19:42:56.414157 21228 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1203 19:42:56.416157 21228 net.cpp:122] Setting up group2_block3_conv1
I1203 19:42:56.416157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.416157 21228 net.cpp:137] Memory required for data: 636122800
I1203 19:42:56.416157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1203 19:42:56.416157 21228 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1203 19:42:56.416157 21228 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1203 19:42:56.416157 21228 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1203 19:42:56.416157 21228 net.cpp:122] Setting up group2_block3_conv1_bn
I1203 19:42:56.416157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.416157 21228 net.cpp:137] Memory required for data: 637761200
I1203 19:42:56.416157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 19:42:56.416157 21228 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1203 19:42:56.416157 21228 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1203 19:42:56.416157 21228 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1203 19:42:56.416157 21228 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 19:42:56.416157 21228 net.cpp:122] Setting up group2_block3_conv1_scale
I1203 19:42:56.416157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.417156 21228 net.cpp:137] Memory required for data: 639399600
I1203 19:42:56.417156 21228 layer_factory.cpp:58] Creating layer group2_block3_sum
I1203 19:42:56.417156 21228 net.cpp:84] Creating Layer group2_block3_sum
I1203 19:42:56.417156 21228 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1203 19:42:56.417156 21228 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1203 19:42:56.417156 21228 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1203 19:42:56.417156 21228 net.cpp:122] Setting up group2_block3_sum
I1203 19:42:56.417156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.417156 21228 net.cpp:137] Memory required for data: 641038000
I1203 19:42:56.417156 21228 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1203 19:42:56.417156 21228 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1203 19:42:56.417156 21228 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1203 19:42:56.417156 21228 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1203 19:42:56.417156 21228 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1203 19:42:56.417156 21228 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1203 19:42:56.417156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.417156 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.417156 21228 net.cpp:137] Memory required for data: 644314800
I1203 19:42:56.417156 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1203 19:42:56.417156 21228 net.cpp:84] Creating Layer group2_block4_conv0
I1203 19:42:56.417156 21228 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1203 19:42:56.417156 21228 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1203 19:42:56.420157 21228 net.cpp:122] Setting up group2_block4_conv0
I1203 19:42:56.420157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.420157 21228 net.cpp:137] Memory required for data: 645953200
I1203 19:42:56.420157 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1203 19:42:56.420157 21228 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1203 19:42:56.420157 21228 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1203 19:42:56.420157 21228 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1203 19:42:56.420157 21228 net.cpp:122] Setting up group2_block4_conv0_bn
I1203 19:42:56.420157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.420157 21228 net.cpp:137] Memory required for data: 647591600
I1203 19:42:56.420157 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 19:42:56.420157 21228 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1203 19:42:56.420157 21228 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1203 19:42:56.420157 21228 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1203 19:42:56.420157 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 19:42:56.420157 21228 net.cpp:122] Setting up group2_block4_conv0_scale
I1203 19:42:56.420157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.420157 21228 net.cpp:137] Memory required for data: 649230000
I1203 19:42:56.420157 21228 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1203 19:42:56.420157 21228 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1203 19:42:56.420157 21228 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1203 19:42:56.420157 21228 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1203 19:42:56.420157 21228 net.cpp:122] Setting up group2_block4_conv0_relu
I1203 19:42:56.420157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.421157 21228 net.cpp:137] Memory required for data: 650868400
I1203 19:42:56.421157 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1203 19:42:56.421157 21228 net.cpp:84] Creating Layer group2_block4_conv1
I1203 19:42:56.421157 21228 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1203 19:42:56.421157 21228 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1203 19:42:56.422158 21228 net.cpp:122] Setting up group2_block4_conv1
I1203 19:42:56.422158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.422158 21228 net.cpp:137] Memory required for data: 652506800
I1203 19:42:56.422158 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1203 19:42:56.422158 21228 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1203 19:42:56.422158 21228 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1203 19:42:56.422158 21228 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1203 19:42:56.422158 21228 net.cpp:122] Setting up group2_block4_conv1_bn
I1203 19:42:56.422158 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.422158 21228 net.cpp:137] Memory required for data: 654145200
I1203 19:42:56.422158 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 19:42:56.422158 21228 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1203 19:42:56.422158 21228 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1203 19:42:56.422158 21228 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1203 19:42:56.422158 21228 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 19:42:56.423157 21228 net.cpp:122] Setting up group2_block4_conv1_scale
I1203 19:42:56.423157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.423157 21228 net.cpp:137] Memory required for data: 655783600
I1203 19:42:56.423157 21228 layer_factory.cpp:58] Creating layer group2_block4_sum
I1203 19:42:56.423157 21228 net.cpp:84] Creating Layer group2_block4_sum
I1203 19:42:56.423157 21228 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1203 19:42:56.423157 21228 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1203 19:42:56.423157 21228 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1203 19:42:56.423157 21228 net.cpp:122] Setting up group2_block4_sum
I1203 19:42:56.423157 21228 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 19:42:56.423157 21228 net.cpp:137] Memory required for data: 657422000
I1203 19:42:56.423157 21228 layer_factory.cpp:58] Creating layer global_avg_pool
I1203 19:42:56.423157 21228 net.cpp:84] Creating Layer global_avg_pool
I1203 19:42:56.423157 21228 net.cpp:406] global_avg_pool <- group2_block4_sum
I1203 19:42:56.423157 21228 net.cpp:380] global_avg_pool -> global_avg_pool
I1203 19:42:56.423157 21228 net.cpp:122] Setting up global_avg_pool
I1203 19:42:56.423157 21228 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1203 19:42:56.423157 21228 net.cpp:137] Memory required for data: 657447600
I1203 19:42:56.423157 21228 layer_factory.cpp:58] Creating layer fc
I1203 19:42:56.423157 21228 net.cpp:84] Creating Layer fc
I1203 19:42:56.423157 21228 net.cpp:406] fc <- global_avg_pool
I1203 19:42:56.423157 21228 net.cpp:380] fc -> fc
I1203 19:42:56.424157 21228 net.cpp:122] Setting up fc
I1203 19:42:56.424157 21228 net.cpp:129] Top shape: 100 10 (1000)
I1203 19:42:56.424157 21228 net.cpp:137] Memory required for data: 657451600
I1203 19:42:56.424157 21228 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1203 19:42:56.424157 21228 net.cpp:84] Creating Layer fc_fc_0_split
I1203 19:42:56.424157 21228 net.cpp:406] fc_fc_0_split <- fc
I1203 19:42:56.424157 21228 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1203 19:42:56.424157 21228 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1203 19:42:56.424157 21228 net.cpp:122] Setting up fc_fc_0_split
I1203 19:42:56.424157 21228 net.cpp:129] Top shape: 100 10 (1000)
I1203 19:42:56.424157 21228 net.cpp:129] Top shape: 100 10 (1000)
I1203 19:42:56.424157 21228 net.cpp:137] Memory required for data: 657459600
I1203 19:42:56.424157 21228 layer_factory.cpp:58] Creating layer accuracy
I1203 19:42:56.424157 21228 net.cpp:84] Creating Layer accuracy
I1203 19:42:56.424157 21228 net.cpp:406] accuracy <- fc_fc_0_split_0
I1203 19:42:56.424157 21228 net.cpp:406] accuracy <- label_cifar_1_split_0
I1203 19:42:56.424157 21228 net.cpp:380] accuracy -> accuracy
I1203 19:42:56.424157 21228 net.cpp:122] Setting up accuracy
I1203 19:42:56.424157 21228 net.cpp:129] Top shape: (1)
I1203 19:42:56.424157 21228 net.cpp:137] Memory required for data: 657459604
I1203 19:42:56.424157 21228 layer_factory.cpp:58] Creating layer loss
I1203 19:42:56.424157 21228 net.cpp:84] Creating Layer loss
I1203 19:42:56.424157 21228 net.cpp:406] loss <- fc_fc_0_split_1
I1203 19:42:56.424157 21228 net.cpp:406] loss <- label_cifar_1_split_1
I1203 19:42:56.424157 21228 net.cpp:380] loss -> loss
I1203 19:42:56.424157 21228 layer_factory.cpp:58] Creating layer loss
I1203 19:42:56.424157 21228 net.cpp:122] Setting up loss
I1203 19:42:56.424157 21228 net.cpp:129] Top shape: (1)
I1203 19:42:56.424157 21228 net.cpp:132]     with loss weight 1
I1203 19:42:56.424157 21228 net.cpp:137] Memory required for data: 657459608
I1203 19:42:56.424157 21228 net.cpp:198] loss needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:200] accuracy does not need backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] fc_fc_0_split needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] fc needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] global_avg_pool needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_sum needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv1 needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block4_conv0 needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_sum needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv1 needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block3_conv0 needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_sum needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv1 needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1203 19:42:56.424157 21228 net.cpp:198] group2_block2_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block1_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_proj needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] pool3 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group2_block0_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block4_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block3_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block2_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block1_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] pool2 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_proj needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] pool1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group1_block0_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block4_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block3_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block2_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block1_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_sum needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv1 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] group0_block0_conv0 needs backward computation.
I1203 19:42:56.425158 21228 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1203 19:42:56.426156 21228 net.cpp:198] first_conv_relu needs backward computation.
I1203 19:42:56.426156 21228 net.cpp:198] first_conv_scale needs backward computation.
I1203 19:42:56.426156 21228 net.cpp:198] first_conv_bn needs backward computation.
I1203 19:42:56.426156 21228 net.cpp:198] first_conv needs backward computation.
I1203 19:42:56.426156 21228 net.cpp:200] label_cifar_1_split does not need backward computation.
I1203 19:42:56.426156 21228 net.cpp:200] cifar does not need backward computation.
I1203 19:42:56.426156 21228 net.cpp:242] This network produces output accuracy
I1203 19:42:56.426156 21228 net.cpp:242] This network produces output loss
I1203 19:42:56.426156 21228 net.cpp:255] Network initialization done.
I1203 19:42:56.426156 21228 solver.cpp:56] Solver scaffolding done.
I1203 19:42:56.439157 21228 caffe.cpp:243] Resuming from examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate
I1203 19:42:56.446156 21228 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/snaps/resnet32_with3pooling_iter_90000.caffemodel
I1203 19:42:56.446156 21228 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1203 19:42:56.446156 21228 sgd_solver.cpp:318] SGDSolver: restoring history
I1203 19:42:56.455162 21228 caffe.cpp:249] Starting Optimization
I1203 19:42:56.455162 21228 solver.cpp:272] Solving CIFAR10_resnet_32_with 3pooling
I1203 19:42:56.455162 21228 solver.cpp:273] Learning Rate Policy: multistep
I1203 19:42:56.459662 21228 solver.cpp:330] Iteration 90000, Testing net (#0)
I1203 19:42:56.464162 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:42:58.293380 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:42:58.362398 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8685
I1203 19:42:58.362398 21228 solver.cpp:397]     Test net output #1: loss = 0.443522 (* 1 = 0.443522 loss)
I1203 19:42:58.553915 21228 solver.cpp:218] Iteration 90000 (42922.8 iter/s, 2.09679s/100 iters), loss = 0.118051
I1203 19:42:58.553915 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:42:58.553915 21228 solver.cpp:237]     Train net output #1: loss = 0.118051 (* 1 = 0.118051 loss)
I1203 19:42:58.553915 21228 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1203 19:43:06.950278 21228 solver.cpp:218] Iteration 90100 (11.9104 iter/s, 8.39601s/100 iters), loss = 0.104071
I1203 19:43:06.950278 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:43:06.950278 21228 solver.cpp:237]     Train net output #1: loss = 0.104071 (* 1 = 0.104071 loss)
I1203 19:43:06.950278 21228 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1203 19:43:15.259845 21228 solver.cpp:218] Iteration 90200 (12.0349 iter/s, 8.30919s/100 iters), loss = 0.0957874
I1203 19:43:15.260345 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:43:15.260345 21228 solver.cpp:237]     Train net output #1: loss = 0.0957874 (* 1 = 0.0957874 loss)
I1203 19:43:15.260345 21228 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1203 19:43:23.570801 21228 solver.cpp:218] Iteration 90300 (12.0334 iter/s, 8.31017s/100 iters), loss = 0.146764
I1203 19:43:23.570801 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:43:23.570801 21228 solver.cpp:237]     Train net output #1: loss = 0.146764 (* 1 = 0.146764 loss)
I1203 19:43:23.570801 21228 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1203 19:43:31.867491 21228 solver.cpp:218] Iteration 90400 (12.0534 iter/s, 8.29641s/100 iters), loss = 0.0491471
I1203 19:43:31.867992 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:43:31.867992 21228 solver.cpp:237]     Train net output #1: loss = 0.0491471 (* 1 = 0.0491471 loss)
I1203 19:43:31.867992 21228 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1203 19:43:39.787871 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:43:40.115010 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.caffemodel
I1203 19:43:40.149013 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.solverstate
I1203 19:43:40.157013 21228 solver.cpp:330] Iteration 90500, Testing net (#0)
I1203 19:43:40.157013 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:43:41.888267 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:43:41.957265 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8903
I1203 19:43:41.957265 21228 solver.cpp:397]     Test net output #1: loss = 0.368289 (* 1 = 0.368289 loss)
I1203 19:43:42.036274 21228 solver.cpp:218] Iteration 90500 (9.8353 iter/s, 10.1675s/100 iters), loss = 0.14558
I1203 19:43:42.036274 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 19:43:42.036274 21228 solver.cpp:237]     Train net output #1: loss = 0.14558 (* 1 = 0.14558 loss)
I1203 19:43:42.036274 21228 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1203 19:43:50.457914 21228 solver.cpp:218] Iteration 90600 (11.8752 iter/s, 8.42091s/100 iters), loss = 0.154726
I1203 19:43:50.457914 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:43:50.457914 21228 solver.cpp:237]     Train net output #1: loss = 0.154726 (* 1 = 0.154726 loss)
I1203 19:43:50.457914 21228 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1203 19:43:58.843284 21228 solver.cpp:218] Iteration 90700 (11.9262 iter/s, 8.38488s/100 iters), loss = 0.0897444
I1203 19:43:58.843284 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:43:58.843284 21228 solver.cpp:237]     Train net output #1: loss = 0.0897444 (* 1 = 0.0897444 loss)
I1203 19:43:58.843284 21228 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1203 19:44:07.199582 21228 solver.cpp:218] Iteration 90800 (11.9677 iter/s, 8.35583s/100 iters), loss = 0.0785091
I1203 19:44:07.199582 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:44:07.199582 21228 solver.cpp:237]     Train net output #1: loss = 0.0785091 (* 1 = 0.0785091 loss)
I1203 19:44:07.199582 21228 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1203 19:44:15.517273 21228 solver.cpp:218] Iteration 90900 (12.0234 iter/s, 8.31713s/100 iters), loss = 0.106188
I1203 19:44:15.517273 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:44:15.517273 21228 solver.cpp:237]     Train net output #1: loss = 0.106188 (* 1 = 0.106188 loss)
I1203 19:44:15.517273 21228 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1203 19:44:23.451474 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:44:23.782515 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.caffemodel
I1203 19:44:23.813518 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.solverstate
I1203 19:44:23.821517 21228 solver.cpp:330] Iteration 91000, Testing net (#0)
I1203 19:44:23.821517 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:44:25.547824 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:44:25.616840 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8626
I1203 19:44:25.616840 21228 solver.cpp:397]     Test net output #1: loss = 0.456093 (* 1 = 0.456093 loss)
I1203 19:44:25.697847 21228 solver.cpp:218] Iteration 91000 (9.82329 iter/s, 10.1799s/100 iters), loss = 0.0904509
I1203 19:44:25.697847 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:44:25.697847 21228 solver.cpp:237]     Train net output #1: loss = 0.0904509 (* 1 = 0.0904509 loss)
I1203 19:44:25.697847 21228 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1203 19:44:34.022411 21228 solver.cpp:218] Iteration 91100 (12.013 iter/s, 8.32433s/100 iters), loss = 0.132015
I1203 19:44:34.022411 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:44:34.022411 21228 solver.cpp:237]     Train net output #1: loss = 0.132015 (* 1 = 0.132015 loss)
I1203 19:44:34.022411 21228 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1203 19:44:42.358252 21228 solver.cpp:218] Iteration 91200 (11.9977 iter/s, 8.33494s/100 iters), loss = 0.0969388
I1203 19:44:42.358252 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:44:42.358252 21228 solver.cpp:237]     Train net output #1: loss = 0.0969389 (* 1 = 0.0969389 loss)
I1203 19:44:42.358252 21228 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1203 19:44:50.698020 21228 solver.cpp:218] Iteration 91300 (11.9916 iter/s, 8.3392s/100 iters), loss = 0.0676862
I1203 19:44:50.698020 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:44:50.698020 21228 solver.cpp:237]     Train net output #1: loss = 0.0676863 (* 1 = 0.0676863 loss)
I1203 19:44:50.698020 21228 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1203 19:44:59.030403 21228 solver.cpp:218] Iteration 91400 (12.002 iter/s, 8.33198s/100 iters), loss = 0.106793
I1203 19:44:59.030403 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:44:59.030403 21228 solver.cpp:237]     Train net output #1: loss = 0.106793 (* 1 = 0.106793 loss)
I1203 19:44:59.030403 21228 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1203 19:45:06.958900 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:45:07.287463 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.caffemodel
I1203 19:45:07.323767 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.solverstate
I1203 19:45:07.329782 21228 solver.cpp:330] Iteration 91500, Testing net (#0)
I1203 19:45:07.329782 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:45:09.049391 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:45:09.118397 21228 solver.cpp:397]     Test net output #0: accuracy = 0.884
I1203 19:45:09.118397 21228 solver.cpp:397]     Test net output #1: loss = 0.384764 (* 1 = 0.384764 loss)
I1203 19:45:09.197901 21228 solver.cpp:218] Iteration 91500 (9.83594 iter/s, 10.1668s/100 iters), loss = 0.0938981
I1203 19:45:09.197901 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:45:09.197901 21228 solver.cpp:237]     Train net output #1: loss = 0.0938982 (* 1 = 0.0938982 loss)
I1203 19:45:09.197901 21228 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1203 19:45:17.615789 21228 solver.cpp:218] Iteration 91600 (11.879 iter/s, 8.41822s/100 iters), loss = 0.13396
I1203 19:45:17.616789 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:45:17.616789 21228 solver.cpp:237]     Train net output #1: loss = 0.13396 (* 1 = 0.13396 loss)
I1203 19:45:17.616789 21228 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1203 19:45:26.033498 21228 solver.cpp:218] Iteration 91700 (11.8818 iter/s, 8.41625s/100 iters), loss = 0.0942622
I1203 19:45:26.033498 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:45:26.033498 21228 solver.cpp:237]     Train net output #1: loss = 0.0942623 (* 1 = 0.0942623 loss)
I1203 19:45:26.033498 21228 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1203 19:45:34.468199 21228 solver.cpp:218] Iteration 91800 (11.8559 iter/s, 8.43461s/100 iters), loss = 0.123291
I1203 19:45:34.468199 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:45:34.468199 21228 solver.cpp:237]     Train net output #1: loss = 0.123291 (* 1 = 0.123291 loss)
I1203 19:45:34.468199 21228 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1203 19:45:42.884387 21228 solver.cpp:218] Iteration 91900 (11.8831 iter/s, 8.4153s/100 iters), loss = 0.101403
I1203 19:45:42.884387 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:45:42.884387 21228 solver.cpp:237]     Train net output #1: loss = 0.101403 (* 1 = 0.101403 loss)
I1203 19:45:42.884387 21228 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1203 19:45:50.915096 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:45:51.248116 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.caffemodel
I1203 19:45:51.278116 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.solverstate
I1203 19:45:51.284116 21228 solver.cpp:330] Iteration 92000, Testing net (#0)
I1203 19:45:51.284116 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:45:53.016461 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:45:53.084460 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8635
I1203 19:45:53.084460 21228 solver.cpp:397]     Test net output #1: loss = 0.444663 (* 1 = 0.444663 loss)
I1203 19:45:53.162477 21228 solver.cpp:218] Iteration 92000 (9.72969 iter/s, 10.2778s/100 iters), loss = 0.068404
I1203 19:45:53.162477 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:45:53.162477 21228 solver.cpp:237]     Train net output #1: loss = 0.068404 (* 1 = 0.068404 loss)
I1203 19:45:53.162477 21228 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1203 19:46:01.597199 21228 solver.cpp:218] Iteration 92100 (11.8568 iter/s, 8.43397s/100 iters), loss = 0.0989971
I1203 19:46:01.597199 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:46:01.597199 21228 solver.cpp:237]     Train net output #1: loss = 0.0989971 (* 1 = 0.0989971 loss)
I1203 19:46:01.597199 21228 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1203 19:46:10.019565 21228 solver.cpp:218] Iteration 92200 (11.8732 iter/s, 8.4223s/100 iters), loss = 0.178667
I1203 19:46:10.019565 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1203 19:46:10.019565 21228 solver.cpp:237]     Train net output #1: loss = 0.178667 (* 1 = 0.178667 loss)
I1203 19:46:10.019565 21228 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1203 19:46:18.445392 21228 solver.cpp:218] Iteration 92300 (11.8696 iter/s, 8.4249s/100 iters), loss = 0.155284
I1203 19:46:18.445392 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:46:18.445392 21228 solver.cpp:237]     Train net output #1: loss = 0.155285 (* 1 = 0.155285 loss)
I1203 19:46:18.445392 21228 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1203 19:46:26.876116 21228 solver.cpp:218] Iteration 92400 (11.8623 iter/s, 8.43009s/100 iters), loss = 0.152445
I1203 19:46:26.876116 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1203 19:46:26.876116 21228 solver.cpp:237]     Train net output #1: loss = 0.152445 (* 1 = 0.152445 loss)
I1203 19:46:26.876116 21228 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1203 19:46:34.885449 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:46:35.217803 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.caffemodel
I1203 19:46:35.260823 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.solverstate
I1203 19:46:35.267815 21228 solver.cpp:330] Iteration 92500, Testing net (#0)
I1203 19:46:35.267815 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:46:37.001529 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:46:37.070832 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8838
I1203 19:46:37.070832 21228 solver.cpp:397]     Test net output #1: loss = 0.385272 (* 1 = 0.385272 loss)
I1203 19:46:37.146879 21228 solver.cpp:218] Iteration 92500 (9.73629 iter/s, 10.2708s/100 iters), loss = 0.138704
I1203 19:46:37.147881 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:46:37.147881 21228 solver.cpp:237]     Train net output #1: loss = 0.138704 (* 1 = 0.138704 loss)
I1203 19:46:37.147881 21228 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1203 19:46:45.595227 21228 solver.cpp:218] Iteration 92600 (11.8383 iter/s, 8.44717s/100 iters), loss = 0.106513
I1203 19:46:45.595227 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:46:45.595227 21228 solver.cpp:237]     Train net output #1: loss = 0.106513 (* 1 = 0.106513 loss)
I1203 19:46:45.595227 21228 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1203 19:46:54.004077 21228 solver.cpp:218] Iteration 92700 (11.8925 iter/s, 8.40866s/100 iters), loss = 0.12608
I1203 19:46:54.004077 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:46:54.004077 21228 solver.cpp:237]     Train net output #1: loss = 0.12608 (* 1 = 0.12608 loss)
I1203 19:46:54.004077 21228 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1203 19:47:02.416237 21228 solver.cpp:218] Iteration 92800 (11.8883 iter/s, 8.41164s/100 iters), loss = 0.0794841
I1203 19:47:02.416237 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:47:02.416237 21228 solver.cpp:237]     Train net output #1: loss = 0.0794841 (* 1 = 0.0794841 loss)
I1203 19:47:02.416237 21228 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1203 19:47:10.846212 21228 solver.cpp:218] Iteration 92900 (11.8632 iter/s, 8.42945s/100 iters), loss = 0.0345667
I1203 19:47:10.846212 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:47:10.846212 21228 solver.cpp:237]     Train net output #1: loss = 0.0345667 (* 1 = 0.0345667 loss)
I1203 19:47:10.846212 21228 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1203 19:47:18.878888 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:47:19.207913 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.caffemodel
I1203 19:47:19.236912 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.solverstate
I1203 19:47:19.243917 21228 solver.cpp:330] Iteration 93000, Testing net (#0)
I1203 19:47:19.243917 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:47:20.976395 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:47:21.047416 21228 solver.cpp:397]     Test net output #0: accuracy = 0.892
I1203 19:47:21.047416 21228 solver.cpp:397]     Test net output #1: loss = 0.352659 (* 1 = 0.352659 loss)
I1203 19:47:21.132755 21228 solver.cpp:218] Iteration 93000 (9.72233 iter/s, 10.2856s/100 iters), loss = 0.149126
I1203 19:47:21.132755 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 19:47:21.132755 21228 solver.cpp:237]     Train net output #1: loss = 0.149126 (* 1 = 0.149126 loss)
I1203 19:47:21.132755 21228 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1203 19:47:29.539160 21228 solver.cpp:218] Iteration 93100 (11.8966 iter/s, 8.40574s/100 iters), loss = 0.120273
I1203 19:47:29.539160 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 19:47:29.539160 21228 solver.cpp:237]     Train net output #1: loss = 0.120273 (* 1 = 0.120273 loss)
I1203 19:47:29.539160 21228 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1203 19:47:37.949350 21228 solver.cpp:218] Iteration 93200 (11.8905 iter/s, 8.41011s/100 iters), loss = 0.134265
I1203 19:47:37.949350 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:47:37.949350 21228 solver.cpp:237]     Train net output #1: loss = 0.134265 (* 1 = 0.134265 loss)
I1203 19:47:37.949350 21228 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1203 19:47:46.349606 21228 solver.cpp:218] Iteration 93300 (11.9061 iter/s, 8.39907s/100 iters), loss = 0.124532
I1203 19:47:46.349606 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:47:46.349606 21228 solver.cpp:237]     Train net output #1: loss = 0.124532 (* 1 = 0.124532 loss)
I1203 19:47:46.349606 21228 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1203 19:47:54.748159 21228 solver.cpp:218] Iteration 93400 (11.9071 iter/s, 8.39832s/100 iters), loss = 0.0841163
I1203 19:47:54.748159 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:47:54.748159 21228 solver.cpp:237]     Train net output #1: loss = 0.0841164 (* 1 = 0.0841164 loss)
I1203 19:47:54.748159 21228 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1203 19:48:02.746050 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:48:03.077836 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.caffemodel
I1203 19:48:03.107836 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.solverstate
I1203 19:48:03.114853 21228 solver.cpp:330] Iteration 93500, Testing net (#0)
I1203 19:48:03.114853 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:48:04.851725 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:48:04.920737 21228 solver.cpp:397]     Test net output #0: accuracy = 0.869
I1203 19:48:04.920737 21228 solver.cpp:397]     Test net output #1: loss = 0.4501 (* 1 = 0.4501 loss)
I1203 19:48:04.999737 21228 solver.cpp:218] Iteration 93500 (9.75493 iter/s, 10.2512s/100 iters), loss = 0.141749
I1203 19:48:04.999737 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1203 19:48:04.999737 21228 solver.cpp:237]     Train net output #1: loss = 0.141749 (* 1 = 0.141749 loss)
I1203 19:48:04.999737 21228 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1203 19:48:13.457410 21228 solver.cpp:218] Iteration 93600 (11.8244 iter/s, 8.45708s/100 iters), loss = 0.109498
I1203 19:48:13.457410 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:48:13.457410 21228 solver.cpp:237]     Train net output #1: loss = 0.109498 (* 1 = 0.109498 loss)
I1203 19:48:13.457410 21228 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1203 19:48:21.886426 21228 solver.cpp:218] Iteration 93700 (11.8642 iter/s, 8.42875s/100 iters), loss = 0.112699
I1203 19:48:21.886426 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:48:21.886426 21228 solver.cpp:237]     Train net output #1: loss = 0.1127 (* 1 = 0.1127 loss)
I1203 19:48:21.886426 21228 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1203 19:48:30.300542 21228 solver.cpp:218] Iteration 93800 (11.8863 iter/s, 8.41308s/100 iters), loss = 0.145257
I1203 19:48:30.300542 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:48:30.300542 21228 solver.cpp:237]     Train net output #1: loss = 0.145257 (* 1 = 0.145257 loss)
I1203 19:48:30.300542 21228 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1203 19:48:38.658083 21228 solver.cpp:218] Iteration 93900 (11.9663 iter/s, 8.35683s/100 iters), loss = 0.124333
I1203 19:48:38.658083 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:48:38.658083 21228 solver.cpp:237]     Train net output #1: loss = 0.124333 (* 1 = 0.124333 loss)
I1203 19:48:38.658083 21228 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1203 19:48:46.630993 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:48:46.959556 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.caffemodel
I1203 19:48:46.989050 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.solverstate
I1203 19:48:46.996050 21228 solver.cpp:330] Iteration 94000, Testing net (#0)
I1203 19:48:46.996050 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:48:48.716172 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:48:48.784183 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8724
I1203 19:48:48.784183 21228 solver.cpp:397]     Test net output #1: loss = 0.409058 (* 1 = 0.409058 loss)
I1203 19:48:48.862685 21228 solver.cpp:218] Iteration 94000 (9.8001 iter/s, 10.204s/100 iters), loss = 0.119234
I1203 19:48:48.862685 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:48:48.862685 21228 solver.cpp:237]     Train net output #1: loss = 0.119234 (* 1 = 0.119234 loss)
I1203 19:48:48.862685 21228 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1203 19:48:57.278985 21228 solver.cpp:218] Iteration 94100 (11.882 iter/s, 8.4161s/100 iters), loss = 0.121579
I1203 19:48:57.278985 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:48:57.278985 21228 solver.cpp:237]     Train net output #1: loss = 0.121579 (* 1 = 0.121579 loss)
I1203 19:48:57.278985 21228 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1203 19:49:05.633747 21228 solver.cpp:218] Iteration 94200 (11.9709 iter/s, 8.3536s/100 iters), loss = 0.114342
I1203 19:49:05.633747 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 19:49:05.633747 21228 solver.cpp:237]     Train net output #1: loss = 0.114342 (* 1 = 0.114342 loss)
I1203 19:49:05.633747 21228 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1203 19:49:14.008061 21228 solver.cpp:218] Iteration 94300 (11.9415 iter/s, 8.37418s/100 iters), loss = 0.168636
I1203 19:49:14.008061 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 19:49:14.008061 21228 solver.cpp:237]     Train net output #1: loss = 0.168636 (* 1 = 0.168636 loss)
I1203 19:49:14.008061 21228 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1203 19:49:22.385296 21228 solver.cpp:218] Iteration 94400 (11.9383 iter/s, 8.37637s/100 iters), loss = 0.0598528
I1203 19:49:22.385296 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:49:22.385296 21228 solver.cpp:237]     Train net output #1: loss = 0.0598529 (* 1 = 0.0598529 loss)
I1203 19:49:22.385296 21228 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1203 19:49:30.335235 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:49:30.665165 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.caffemodel
I1203 19:49:30.701165 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.solverstate
I1203 19:49:30.709183 21228 solver.cpp:330] Iteration 94500, Testing net (#0)
I1203 19:49:30.709183 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:49:32.431108 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:49:32.499150 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8782
I1203 19:49:32.499150 21228 solver.cpp:397]     Test net output #1: loss = 0.399964 (* 1 = 0.399964 loss)
I1203 19:49:32.576196 21228 solver.cpp:218] Iteration 94500 (9.81304 iter/s, 10.1905s/100 iters), loss = 0.0946881
I1203 19:49:32.576196 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:49:32.576196 21228 solver.cpp:237]     Train net output #1: loss = 0.0946882 (* 1 = 0.0946882 loss)
I1203 19:49:32.576196 21228 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1203 19:49:40.977579 21228 solver.cpp:218] Iteration 94600 (11.9032 iter/s, 8.40114s/100 iters), loss = 0.0674296
I1203 19:49:40.977579 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:49:40.977579 21228 solver.cpp:237]     Train net output #1: loss = 0.0674297 (* 1 = 0.0674297 loss)
I1203 19:49:40.977579 21228 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1203 19:49:49.325124 21228 solver.cpp:218] Iteration 94700 (11.9809 iter/s, 8.34661s/100 iters), loss = 0.0750542
I1203 19:49:49.325124 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:49:49.325124 21228 solver.cpp:237]     Train net output #1: loss = 0.0750544 (* 1 = 0.0750544 loss)
I1203 19:49:49.325124 21228 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1203 19:49:57.770231 21228 solver.cpp:218] Iteration 94800 (11.8422 iter/s, 8.44439s/100 iters), loss = 0.0544811
I1203 19:49:57.770231 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:49:57.770231 21228 solver.cpp:237]     Train net output #1: loss = 0.0544812 (* 1 = 0.0544812 loss)
I1203 19:49:57.770231 21228 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1203 19:50:06.273453 21228 solver.cpp:218] Iteration 94900 (11.7612 iter/s, 8.50251s/100 iters), loss = 0.0900963
I1203 19:50:06.273453 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:50:06.273453 21228 solver.cpp:237]     Train net output #1: loss = 0.0900964 (* 1 = 0.0900964 loss)
I1203 19:50:06.273453 21228 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1203 19:50:14.224560 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:50:14.552610 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.caffemodel
I1203 19:50:14.582614 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.solverstate
I1203 19:50:14.588615 21228 solver.cpp:330] Iteration 95000, Testing net (#0)
I1203 19:50:14.588615 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:50:16.310772 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:50:16.379792 21228 solver.cpp:397]     Test net output #0: accuracy = 0.8871
I1203 19:50:16.379792 21228 solver.cpp:397]     Test net output #1: loss = 0.365384 (* 1 = 0.365384 loss)
I1203 19:50:16.457792 21228 solver.cpp:218] Iteration 95000 (9.81953 iter/s, 10.1838s/100 iters), loss = 0.114812
I1203 19:50:16.457792 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 19:50:16.457792 21228 solver.cpp:237]     Train net output #1: loss = 0.114812 (* 1 = 0.114812 loss)
I1203 19:50:16.457792 21228 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1203 19:50:16.457792 21228 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1203 19:50:24.799960 21228 solver.cpp:218] Iteration 95100 (11.9878 iter/s, 8.34183s/100 iters), loss = 0.251381
I1203 19:50:24.799960 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1203 19:50:24.799960 21228 solver.cpp:237]     Train net output #1: loss = 0.251381 (* 1 = 0.251381 loss)
I1203 19:50:24.799960 21228 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1203 19:50:33.137490 21228 solver.cpp:218] Iteration 95200 (11.9951 iter/s, 8.33672s/100 iters), loss = 0.0758652
I1203 19:50:33.137490 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:50:33.137490 21228 solver.cpp:237]     Train net output #1: loss = 0.0758653 (* 1 = 0.0758653 loss)
I1203 19:50:33.137490 21228 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1203 19:50:41.495883 21228 solver.cpp:218] Iteration 95300 (11.9636 iter/s, 8.35869s/100 iters), loss = 0.060203
I1203 19:50:41.496894 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:50:41.496894 21228 solver.cpp:237]     Train net output #1: loss = 0.0602032 (* 1 = 0.0602032 loss)
I1203 19:50:41.496894 21228 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1203 19:50:49.828649 21228 solver.cpp:218] Iteration 95400 (12.0027 iter/s, 8.33145s/100 iters), loss = 0.0610744
I1203 19:50:49.828649 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:50:49.828649 21228 solver.cpp:237]     Train net output #1: loss = 0.0610745 (* 1 = 0.0610745 loss)
I1203 19:50:49.828649 21228 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1203 19:50:57.792228 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:50:58.129266 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.caffemodel
I1203 19:50:58.160270 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.solverstate
I1203 19:50:58.166770 21228 solver.cpp:330] Iteration 95500, Testing net (#0)
I1203 19:50:58.167270 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:50:59.896633 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:50:59.966135 21228 solver.cpp:397]     Test net output #0: accuracy = 0.922
I1203 19:50:59.966135 21228 solver.cpp:397]     Test net output #1: loss = 0.252384 (* 1 = 0.252384 loss)
I1203 19:51:00.042248 21228 solver.cpp:218] Iteration 95500 (9.79161 iter/s, 10.2128s/100 iters), loss = 0.0344513
I1203 19:51:00.042248 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:51:00.042248 21228 solver.cpp:237]     Train net output #1: loss = 0.0344514 (* 1 = 0.0344514 loss)
I1203 19:51:00.042248 21228 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1203 19:51:08.519671 21228 solver.cpp:218] Iteration 95600 (11.7966 iter/s, 8.47702s/100 iters), loss = 0.0679729
I1203 19:51:08.519671 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:51:08.519671 21228 solver.cpp:237]     Train net output #1: loss = 0.067973 (* 1 = 0.067973 loss)
I1203 19:51:08.519671 21228 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1203 19:51:16.920277 21228 solver.cpp:218] Iteration 95700 (11.9054 iter/s, 8.39957s/100 iters), loss = 0.0585331
I1203 19:51:16.920277 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:51:16.920277 21228 solver.cpp:237]     Train net output #1: loss = 0.0585331 (* 1 = 0.0585331 loss)
I1203 19:51:16.920277 21228 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1203 19:51:25.304941 21228 solver.cpp:218] Iteration 95800 (11.9263 iter/s, 8.38482s/100 iters), loss = 0.0749596
I1203 19:51:25.305943 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:51:25.305943 21228 solver.cpp:237]     Train net output #1: loss = 0.0749597 (* 1 = 0.0749597 loss)
I1203 19:51:25.305943 21228 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1203 19:51:33.727087 21228 solver.cpp:218] Iteration 95900 (11.8751 iter/s, 8.42101s/100 iters), loss = 0.0380548
I1203 19:51:33.727087 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:51:33.727087 21228 solver.cpp:237]     Train net output #1: loss = 0.0380548 (* 1 = 0.0380548 loss)
I1203 19:51:33.727087 21228 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1203 19:51:41.728940 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:51:42.062960 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.caffemodel
I1203 19:51:42.097976 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.solverstate
I1203 19:51:42.105975 21228 solver.cpp:330] Iteration 96000, Testing net (#0)
I1203 19:51:42.105975 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:51:43.845217 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:51:43.916234 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9256
I1203 19:51:43.916234 21228 solver.cpp:397]     Test net output #1: loss = 0.2354 (* 1 = 0.2354 loss)
I1203 19:51:43.994237 21228 solver.cpp:218] Iteration 96000 (9.74053 iter/s, 10.2664s/100 iters), loss = 0.044406
I1203 19:51:43.994237 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:51:43.994237 21228 solver.cpp:237]     Train net output #1: loss = 0.0444061 (* 1 = 0.0444061 loss)
I1203 19:51:43.994237 21228 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1203 19:51:52.453737 21228 solver.cpp:218] Iteration 96100 (11.8214 iter/s, 8.45921s/100 iters), loss = 0.0767096
I1203 19:51:52.453737 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:51:52.453737 21228 solver.cpp:237]     Train net output #1: loss = 0.0767097 (* 1 = 0.0767097 loss)
I1203 19:51:52.453737 21228 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1203 19:52:00.855813 21228 solver.cpp:218] Iteration 96200 (11.9024 iter/s, 8.40164s/100 iters), loss = 0.0470982
I1203 19:52:00.855813 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:52:00.855813 21228 solver.cpp:237]     Train net output #1: loss = 0.0470983 (* 1 = 0.0470983 loss)
I1203 19:52:00.855813 21228 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1203 19:52:09.258323 21228 solver.cpp:218] Iteration 96300 (11.902 iter/s, 8.40197s/100 iters), loss = 0.0239152
I1203 19:52:09.258323 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:52:09.258323 21228 solver.cpp:237]     Train net output #1: loss = 0.0239153 (* 1 = 0.0239153 loss)
I1203 19:52:09.258323 21228 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1203 19:52:17.672150 21228 solver.cpp:218] Iteration 96400 (11.8852 iter/s, 8.4138s/100 iters), loss = 0.045997
I1203 19:52:17.672150 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:52:17.672150 21228 solver.cpp:237]     Train net output #1: loss = 0.0459971 (* 1 = 0.0459971 loss)
I1203 19:52:17.673151 21228 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1203 19:52:25.692992 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:52:26.024044 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.caffemodel
I1203 19:52:26.060045 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.solverstate
I1203 19:52:26.067045 21228 solver.cpp:330] Iteration 96500, Testing net (#0)
I1203 19:52:26.067045 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:52:27.792083 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:52:27.861088 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9281
I1203 19:52:27.861088 21228 solver.cpp:397]     Test net output #1: loss = 0.234229 (* 1 = 0.234229 loss)
I1203 19:52:27.941128 21228 solver.cpp:218] Iteration 96500 (9.73903 iter/s, 10.268s/100 iters), loss = 0.0395171
I1203 19:52:27.941128 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:52:27.941128 21228 solver.cpp:237]     Train net output #1: loss = 0.0395172 (* 1 = 0.0395172 loss)
I1203 19:52:27.941128 21228 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1203 19:52:36.352764 21228 solver.cpp:218] Iteration 96600 (11.8887 iter/s, 8.41137s/100 iters), loss = 0.0677018
I1203 19:52:36.352764 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:52:36.352764 21228 solver.cpp:237]     Train net output #1: loss = 0.0677019 (* 1 = 0.0677019 loss)
I1203 19:52:36.352764 21228 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1203 19:52:44.757836 21228 solver.cpp:218] Iteration 96700 (11.8984 iter/s, 8.40448s/100 iters), loss = 0.0352429
I1203 19:52:44.757836 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:52:44.757836 21228 solver.cpp:237]     Train net output #1: loss = 0.035243 (* 1 = 0.035243 loss)
I1203 19:52:44.757836 21228 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1203 19:52:53.239928 21228 solver.cpp:218] Iteration 96800 (11.7906 iter/s, 8.48136s/100 iters), loss = 0.0184129
I1203 19:52:53.239928 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:52:53.239928 21228 solver.cpp:237]     Train net output #1: loss = 0.018413 (* 1 = 0.018413 loss)
I1203 19:52:53.239928 21228 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1203 19:53:01.656718 21228 solver.cpp:218] Iteration 96900 (11.8819 iter/s, 8.41614s/100 iters), loss = 0.0342408
I1203 19:53:01.656718 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:53:01.656718 21228 solver.cpp:237]     Train net output #1: loss = 0.0342409 (* 1 = 0.0342409 loss)
I1203 19:53:01.656718 21228 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1203 19:53:09.615002 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:53:09.944023 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.caffemodel
I1203 19:53:09.975025 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.solverstate
I1203 19:53:09.981025 21228 solver.cpp:330] Iteration 97000, Testing net (#0)
I1203 19:53:09.981025 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:53:11.706751 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:53:11.775259 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9259
I1203 19:53:11.775259 21228 solver.cpp:397]     Test net output #1: loss = 0.238866 (* 1 = 0.238866 loss)
I1203 19:53:11.852265 21228 solver.cpp:218] Iteration 97000 (9.80844 iter/s, 10.1953s/100 iters), loss = 0.0348998
I1203 19:53:11.852265 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:53:11.852265 21228 solver.cpp:237]     Train net output #1: loss = 0.0348999 (* 1 = 0.0348999 loss)
I1203 19:53:11.853266 21228 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1203 19:53:20.222236 21228 solver.cpp:218] Iteration 97100 (11.9487 iter/s, 8.36912s/100 iters), loss = 0.0537558
I1203 19:53:20.222236 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:53:20.222236 21228 solver.cpp:237]     Train net output #1: loss = 0.0537559 (* 1 = 0.0537559 loss)
I1203 19:53:20.222236 21228 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1203 19:53:28.587157 21228 solver.cpp:218] Iteration 97200 (11.9554 iter/s, 8.36439s/100 iters), loss = 0.0467075
I1203 19:53:28.587157 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:53:28.587157 21228 solver.cpp:237]     Train net output #1: loss = 0.0467076 (* 1 = 0.0467076 loss)
I1203 19:53:28.587157 21228 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1203 19:53:36.973291 21228 solver.cpp:218] Iteration 97300 (11.9248 iter/s, 8.3859s/100 iters), loss = 0.0219058
I1203 19:53:36.974292 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:53:36.974292 21228 solver.cpp:237]     Train net output #1: loss = 0.0219059 (* 1 = 0.0219059 loss)
I1203 19:53:36.974292 21228 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1203 19:53:45.369668 21228 solver.cpp:218] Iteration 97400 (11.9119 iter/s, 8.39498s/100 iters), loss = 0.0442182
I1203 19:53:45.369668 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:53:45.369668 21228 solver.cpp:237]     Train net output #1: loss = 0.0442182 (* 1 = 0.0442182 loss)
I1203 19:53:45.369668 21228 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1203 19:53:53.315917 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:53:53.644484 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.caffemodel
I1203 19:53:53.678483 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.solverstate
I1203 19:53:53.686483 21228 solver.cpp:330] Iteration 97500, Testing net (#0)
I1203 19:53:53.686483 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:53:55.409385 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:53:55.477890 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9266
I1203 19:53:55.477890 21228 solver.cpp:397]     Test net output #1: loss = 0.24107 (* 1 = 0.24107 loss)
I1203 19:53:55.555845 21228 solver.cpp:218] Iteration 97500 (9.81743 iter/s, 10.186s/100 iters), loss = 0.0471388
I1203 19:53:55.556345 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:53:55.556345 21228 solver.cpp:237]     Train net output #1: loss = 0.0471389 (* 1 = 0.0471389 loss)
I1203 19:53:55.556345 21228 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1203 19:54:03.943928 21228 solver.cpp:218] Iteration 97600 (11.9231 iter/s, 8.38711s/100 iters), loss = 0.0773019
I1203 19:54:03.943928 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:54:03.943928 21228 solver.cpp:237]     Train net output #1: loss = 0.0773019 (* 1 = 0.0773019 loss)
I1203 19:54:03.943928 21228 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1203 19:54:12.338565 21228 solver.cpp:218] Iteration 97700 (11.9132 iter/s, 8.39402s/100 iters), loss = 0.0325408
I1203 19:54:12.338565 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:54:12.338565 21228 solver.cpp:237]     Train net output #1: loss = 0.0325409 (* 1 = 0.0325409 loss)
I1203 19:54:12.338565 21228 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1203 19:54:20.692798 21228 solver.cpp:218] Iteration 97800 (11.9704 iter/s, 8.35397s/100 iters), loss = 0.031485
I1203 19:54:20.692798 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:54:20.692798 21228 solver.cpp:237]     Train net output #1: loss = 0.0314851 (* 1 = 0.0314851 loss)
I1203 19:54:20.692798 21228 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1203 19:54:29.074985 21228 solver.cpp:218] Iteration 97900 (11.9301 iter/s, 8.38219s/100 iters), loss = 0.0326078
I1203 19:54:29.074985 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:54:29.074985 21228 solver.cpp:237]     Train net output #1: loss = 0.0326079 (* 1 = 0.0326079 loss)
I1203 19:54:29.075985 21228 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1203 19:54:37.091204 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:54:37.422003 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.caffemodel
I1203 19:54:37.455904 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.solverstate
I1203 19:54:37.461905 21228 solver.cpp:330] Iteration 98000, Testing net (#0)
I1203 19:54:37.461905 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:54:39.190109 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:54:39.259146 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9266
I1203 19:54:39.259146 21228 solver.cpp:397]     Test net output #1: loss = 0.241472 (* 1 = 0.241472 loss)
I1203 19:54:39.336182 21228 solver.cpp:218] Iteration 98000 (9.74612 iter/s, 10.2605s/100 iters), loss = 0.0518767
I1203 19:54:39.336182 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:54:39.336182 21228 solver.cpp:237]     Train net output #1: loss = 0.0518768 (* 1 = 0.0518768 loss)
I1203 19:54:39.336182 21228 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1203 19:54:47.776406 21228 solver.cpp:218] Iteration 98100 (11.8493 iter/s, 8.43931s/100 iters), loss = 0.0902069
I1203 19:54:47.776406 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 19:54:47.776406 21228 solver.cpp:237]     Train net output #1: loss = 0.090207 (* 1 = 0.090207 loss)
I1203 19:54:47.776406 21228 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1203 19:54:56.129750 21228 solver.cpp:218] Iteration 98200 (11.9722 iter/s, 8.35266s/100 iters), loss = 0.0710327
I1203 19:54:56.129750 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:54:56.129750 21228 solver.cpp:237]     Train net output #1: loss = 0.0710327 (* 1 = 0.0710327 loss)
I1203 19:54:56.129750 21228 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1203 19:55:04.525724 21228 solver.cpp:218] Iteration 98300 (11.9104 iter/s, 8.39602s/100 iters), loss = 0.0395549
I1203 19:55:04.525724 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:55:04.525724 21228 solver.cpp:237]     Train net output #1: loss = 0.039555 (* 1 = 0.039555 loss)
I1203 19:55:04.525724 21228 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1203 19:55:12.927217 21228 solver.cpp:218] Iteration 98400 (11.9041 iter/s, 8.40048s/100 iters), loss = 0.0362856
I1203 19:55:12.927217 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:55:12.927217 21228 solver.cpp:237]     Train net output #1: loss = 0.0362856 (* 1 = 0.0362856 loss)
I1203 19:55:12.927217 21228 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1203 19:55:20.914755 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:55:21.246796 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.caffemodel
I1203 19:55:21.282800 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.solverstate
I1203 19:55:21.289801 21228 solver.cpp:330] Iteration 98500, Testing net (#0)
I1203 19:55:21.289801 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:55:23.015956 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:55:23.084972 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9287
I1203 19:55:23.084972 21228 solver.cpp:397]     Test net output #1: loss = 0.238164 (* 1 = 0.238164 loss)
I1203 19:55:23.162992 21228 solver.cpp:218] Iteration 98500 (9.76979 iter/s, 10.2356s/100 iters), loss = 0.0399858
I1203 19:55:23.163992 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:55:23.163992 21228 solver.cpp:237]     Train net output #1: loss = 0.0399859 (* 1 = 0.0399859 loss)
I1203 19:55:23.163992 21228 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1203 19:55:31.526010 21228 solver.cpp:218] Iteration 98600 (11.9588 iter/s, 8.36202s/100 iters), loss = 0.0668324
I1203 19:55:31.526010 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 19:55:31.526010 21228 solver.cpp:237]     Train net output #1: loss = 0.0668325 (* 1 = 0.0668325 loss)
I1203 19:55:31.526010 21228 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1203 19:55:39.905828 21228 solver.cpp:218] Iteration 98700 (11.9343 iter/s, 8.37918s/100 iters), loss = 0.03985
I1203 19:55:39.905828 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:55:39.905828 21228 solver.cpp:237]     Train net output #1: loss = 0.0398501 (* 1 = 0.0398501 loss)
I1203 19:55:39.905828 21228 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1203 19:55:48.296778 21228 solver.cpp:218] Iteration 98800 (11.9186 iter/s, 8.39023s/100 iters), loss = 0.0173134
I1203 19:55:48.296778 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:55:48.296778 21228 solver.cpp:237]     Train net output #1: loss = 0.0173134 (* 1 = 0.0173134 loss)
I1203 19:55:48.296778 21228 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1203 19:55:56.693771 21228 solver.cpp:218] Iteration 98900 (11.9096 iter/s, 8.3966s/100 iters), loss = 0.0303059
I1203 19:55:56.693771 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:55:56.693771 21228 solver.cpp:237]     Train net output #1: loss = 0.030306 (* 1 = 0.030306 loss)
I1203 19:55:56.693771 21228 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1203 19:56:04.669203 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:56:05.008376 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.caffemodel
I1203 19:56:05.042372 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.solverstate
I1203 19:56:05.049381 21228 solver.cpp:330] Iteration 99000, Testing net (#0)
I1203 19:56:05.049885 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:56:06.776979 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:56:06.845983 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9303
I1203 19:56:06.845983 21228 solver.cpp:397]     Test net output #1: loss = 0.233799 (* 1 = 0.233799 loss)
I1203 19:56:06.923985 21228 solver.cpp:218] Iteration 99000 (9.77581 iter/s, 10.2293s/100 iters), loss = 0.0446176
I1203 19:56:06.923985 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:56:06.923985 21228 solver.cpp:237]     Train net output #1: loss = 0.0446176 (* 1 = 0.0446176 loss)
I1203 19:56:06.923985 21228 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1203 19:56:15.322166 21228 solver.cpp:218] Iteration 99100 (11.9082 iter/s, 8.39757s/100 iters), loss = 0.0440099
I1203 19:56:15.322166 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 19:56:15.322166 21228 solver.cpp:237]     Train net output #1: loss = 0.0440099 (* 1 = 0.0440099 loss)
I1203 19:56:15.322166 21228 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1203 19:56:23.715916 21228 solver.cpp:218] Iteration 99200 (11.9136 iter/s, 8.39378s/100 iters), loss = 0.0241275
I1203 19:56:23.715916 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:56:23.715916 21228 solver.cpp:237]     Train net output #1: loss = 0.0241276 (* 1 = 0.0241276 loss)
I1203 19:56:23.715916 21228 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1203 19:56:32.158792 21228 solver.cpp:218] Iteration 99300 (11.8452 iter/s, 8.44225s/100 iters), loss = 0.0207297
I1203 19:56:32.158792 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:56:32.158792 21228 solver.cpp:237]     Train net output #1: loss = 0.0207297 (* 1 = 0.0207297 loss)
I1203 19:56:32.158792 21228 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1203 19:56:40.524453 21228 solver.cpp:218] Iteration 99400 (11.9549 iter/s, 8.36475s/100 iters), loss = 0.0195306
I1203 19:56:40.524453 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:56:40.524453 21228 solver.cpp:237]     Train net output #1: loss = 0.0195306 (* 1 = 0.0195306 loss)
I1203 19:56:40.524453 21228 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1203 19:56:48.544706 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:56:48.874459 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.caffemodel
I1203 19:56:48.913458 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.solverstate
I1203 19:56:48.920459 21228 solver.cpp:330] Iteration 99500, Testing net (#0)
I1203 19:56:48.920459 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:56:50.666584 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:56:50.733583 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9302
I1203 19:56:50.733583 21228 solver.cpp:397]     Test net output #1: loss = 0.234181 (* 1 = 0.234181 loss)
I1203 19:56:50.812587 21228 solver.cpp:218] Iteration 99500 (9.72097 iter/s, 10.287s/100 iters), loss = 0.0282411
I1203 19:56:50.812587 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:56:50.812587 21228 solver.cpp:237]     Train net output #1: loss = 0.0282412 (* 1 = 0.0282412 loss)
I1203 19:56:50.812587 21228 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1203 19:56:59.272578 21228 solver.cpp:218] Iteration 99600 (11.8207 iter/s, 8.45975s/100 iters), loss = 0.0427836
I1203 19:56:59.272578 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:56:59.272578 21228 solver.cpp:237]     Train net output #1: loss = 0.0427836 (* 1 = 0.0427836 loss)
I1203 19:56:59.272578 21228 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1203 19:57:07.675928 21228 solver.cpp:218] Iteration 99700 (11.9005 iter/s, 8.40299s/100 iters), loss = 0.0266753
I1203 19:57:07.675928 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:57:07.675928 21228 solver.cpp:237]     Train net output #1: loss = 0.0266753 (* 1 = 0.0266753 loss)
I1203 19:57:07.675928 21228 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1203 19:57:16.063199 21228 solver.cpp:218] Iteration 99800 (11.9238 iter/s, 8.38656s/100 iters), loss = 0.0223885
I1203 19:57:16.063199 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:57:16.063199 21228 solver.cpp:237]     Train net output #1: loss = 0.0223885 (* 1 = 0.0223885 loss)
I1203 19:57:16.063199 21228 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1203 19:57:24.542001 21228 solver.cpp:218] Iteration 99900 (11.7951 iter/s, 8.47812s/100 iters), loss = 0.0175471
I1203 19:57:24.542001 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:57:24.542001 21228 solver.cpp:237]     Train net output #1: loss = 0.0175472 (* 1 = 0.0175472 loss)
I1203 19:57:24.542001 21228 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1203 19:57:32.728312 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:57:33.059211 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.caffemodel
I1203 19:57:33.091722 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.solverstate
I1203 19:57:33.097720 21228 solver.cpp:330] Iteration 100000, Testing net (#0)
I1203 19:57:33.098718 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:57:34.820962 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:57:34.888968 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9284
I1203 19:57:34.888968 21228 solver.cpp:397]     Test net output #1: loss = 0.239666 (* 1 = 0.239666 loss)
I1203 19:57:34.964973 21228 solver.cpp:218] Iteration 100000 (9.59434 iter/s, 10.4228s/100 iters), loss = 0.0290382
I1203 19:57:34.964973 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:57:34.964973 21228 solver.cpp:237]     Train net output #1: loss = 0.0290383 (* 1 = 0.0290383 loss)
I1203 19:57:34.964973 21228 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1203 19:57:43.357487 21228 solver.cpp:218] Iteration 100100 (11.9171 iter/s, 8.39129s/100 iters), loss = 0.0295213
I1203 19:57:43.357487 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:57:43.357487 21228 solver.cpp:237]     Train net output #1: loss = 0.0295213 (* 1 = 0.0295213 loss)
I1203 19:57:43.357487 21228 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1203 19:57:51.890300 21228 solver.cpp:218] Iteration 100200 (11.721 iter/s, 8.53173s/100 iters), loss = 0.037235
I1203 19:57:51.890300 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:57:51.890300 21228 solver.cpp:237]     Train net output #1: loss = 0.037235 (* 1 = 0.037235 loss)
I1203 19:57:51.890300 21228 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1203 19:58:00.300685 21228 solver.cpp:218] Iteration 100300 (11.8907 iter/s, 8.4099s/100 iters), loss = 0.015233
I1203 19:58:00.300685 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:58:00.300685 21228 solver.cpp:237]     Train net output #1: loss = 0.015233 (* 1 = 0.015233 loss)
I1203 19:58:00.300685 21228 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1203 19:58:08.664324 21228 solver.cpp:218] Iteration 100400 (11.9574 iter/s, 8.36299s/100 iters), loss = 0.0240925
I1203 19:58:08.664324 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:58:08.664324 21228 solver.cpp:237]     Train net output #1: loss = 0.0240926 (* 1 = 0.0240926 loss)
I1203 19:58:08.664324 21228 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1203 19:58:16.588949 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:58:16.920986 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.caffemodel
I1203 19:58:16.955986 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.solverstate
I1203 19:58:16.961987 21228 solver.cpp:330] Iteration 100500, Testing net (#0)
I1203 19:58:16.962988 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:58:18.684085 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:58:18.752086 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9292
I1203 19:58:18.752086 21228 solver.cpp:397]     Test net output #1: loss = 0.240815 (* 1 = 0.240815 loss)
I1203 19:58:18.831109 21228 solver.cpp:218] Iteration 100500 (9.83614 iter/s, 10.1666s/100 iters), loss = 0.0389407
I1203 19:58:18.831109 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:58:18.831109 21228 solver.cpp:237]     Train net output #1: loss = 0.0389407 (* 1 = 0.0389407 loss)
I1203 19:58:18.831109 21228 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1203 19:58:27.165035 21228 solver.cpp:218] Iteration 100600 (12.0002 iter/s, 8.33317s/100 iters), loss = 0.0347349
I1203 19:58:27.165035 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:58:27.165539 21228 solver.cpp:237]     Train net output #1: loss = 0.0347349 (* 1 = 0.0347349 loss)
I1203 19:58:27.165539 21228 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1203 19:58:35.570359 21228 solver.cpp:218] Iteration 100700 (11.8983 iter/s, 8.40456s/100 iters), loss = 0.0183433
I1203 19:58:35.570359 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:58:35.570359 21228 solver.cpp:237]     Train net output #1: loss = 0.0183433 (* 1 = 0.0183433 loss)
I1203 19:58:35.570359 21228 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1203 19:58:43.967860 21228 solver.cpp:218] Iteration 100800 (11.909 iter/s, 8.397s/100 iters), loss = 0.0279934
I1203 19:58:43.967860 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:58:43.967860 21228 solver.cpp:237]     Train net output #1: loss = 0.0279934 (* 1 = 0.0279934 loss)
I1203 19:58:43.967860 21228 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1203 19:58:52.340391 21228 solver.cpp:218] Iteration 100900 (11.9438 iter/s, 8.37257s/100 iters), loss = 0.0193932
I1203 19:58:52.340391 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:58:52.340391 21228 solver.cpp:237]     Train net output #1: loss = 0.0193933 (* 1 = 0.0193933 loss)
I1203 19:58:52.340391 21228 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1203 19:59:00.366976 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:59:00.698995 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.caffemodel
I1203 19:59:00.727996 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.solverstate
I1203 19:59:00.733994 21228 solver.cpp:330] Iteration 101000, Testing net (#0)
I1203 19:59:00.733994 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:59:02.461238 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:59:02.530258 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9305
I1203 19:59:02.530258 21228 solver.cpp:397]     Test net output #1: loss = 0.238447 (* 1 = 0.238447 loss)
I1203 19:59:02.606266 21228 solver.cpp:218] Iteration 101000 (9.74186 iter/s, 10.265s/100 iters), loss = 0.0239041
I1203 19:59:02.606266 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:59:02.606266 21228 solver.cpp:237]     Train net output #1: loss = 0.0239041 (* 1 = 0.0239041 loss)
I1203 19:59:02.606266 21228 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1203 19:59:10.957613 21228 solver.cpp:218] Iteration 101100 (11.9751 iter/s, 8.35066s/100 iters), loss = 0.032471
I1203 19:59:10.957613 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:59:10.957613 21228 solver.cpp:237]     Train net output #1: loss = 0.032471 (* 1 = 0.032471 loss)
I1203 19:59:10.957613 21228 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1203 19:59:19.304849 21228 solver.cpp:218] Iteration 101200 (11.9806 iter/s, 8.34686s/100 iters), loss = 0.0289787
I1203 19:59:19.304849 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:59:19.304849 21228 solver.cpp:237]     Train net output #1: loss = 0.0289787 (* 1 = 0.0289787 loss)
I1203 19:59:19.304849 21228 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1203 19:59:27.669298 21228 solver.cpp:218] Iteration 101300 (11.9568 iter/s, 8.36342s/100 iters), loss = 0.016112
I1203 19:59:27.669298 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:59:27.669298 21228 solver.cpp:237]     Train net output #1: loss = 0.016112 (* 1 = 0.016112 loss)
I1203 19:59:27.669298 21228 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1203 19:59:36.018015 21228 solver.cpp:218] Iteration 101400 (11.9778 iter/s, 8.34878s/100 iters), loss = 0.0160215
I1203 19:59:36.018015 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:59:36.018015 21228 solver.cpp:237]     Train net output #1: loss = 0.0160216 (* 1 = 0.0160216 loss)
I1203 19:59:36.018015 21228 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1203 19:59:43.967895 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:59:44.300917 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.caffemodel
I1203 19:59:44.336920 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.solverstate
I1203 19:59:44.342921 21228 solver.cpp:330] Iteration 101500, Testing net (#0)
I1203 19:59:44.342921 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 19:59:46.070222 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 19:59:46.139230 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9307
I1203 19:59:46.139230 21228 solver.cpp:397]     Test net output #1: loss = 0.238333 (* 1 = 0.238333 loss)
I1203 19:59:46.217248 21228 solver.cpp:218] Iteration 101500 (9.8055 iter/s, 10.1984s/100 iters), loss = 0.0254813
I1203 19:59:46.217248 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 19:59:46.217248 21228 solver.cpp:237]     Train net output #1: loss = 0.0254814 (* 1 = 0.0254814 loss)
I1203 19:59:46.217248 21228 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1203 19:59:54.570798 21228 solver.cpp:218] Iteration 101600 (11.9719 iter/s, 8.35289s/100 iters), loss = 0.0450429
I1203 19:59:54.570798 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 19:59:54.570798 21228 solver.cpp:237]     Train net output #1: loss = 0.0450429 (* 1 = 0.0450429 loss)
I1203 19:59:54.570798 21228 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1203 20:00:02.986434 21228 solver.cpp:218] Iteration 101700 (11.8832 iter/s, 8.41527s/100 iters), loss = 0.0525756
I1203 20:00:02.986434 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:00:02.986434 21228 solver.cpp:237]     Train net output #1: loss = 0.0525757 (* 1 = 0.0525757 loss)
I1203 20:00:02.986434 21228 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1203 20:00:11.506990 21228 solver.cpp:218] Iteration 101800 (11.7374 iter/s, 8.51978s/100 iters), loss = 0.0181638
I1203 20:00:11.506990 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:00:11.506990 21228 solver.cpp:237]     Train net output #1: loss = 0.0181638 (* 1 = 0.0181638 loss)
I1203 20:00:11.506990 21228 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1203 20:00:19.985625 21228 solver.cpp:218] Iteration 101900 (11.7947 iter/s, 8.47837s/100 iters), loss = 0.0163006
I1203 20:00:19.985625 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:00:19.985625 21228 solver.cpp:237]     Train net output #1: loss = 0.0163007 (* 1 = 0.0163007 loss)
I1203 20:00:19.985625 21228 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1203 20:00:27.893843 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:00:28.218108 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.caffemodel
I1203 20:00:28.260094 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.solverstate
I1203 20:00:28.267112 21228 solver.cpp:330] Iteration 102000, Testing net (#0)
I1203 20:00:28.267112 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:00:29.963843 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:00:30.029986 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9299
I1203 20:00:30.029986 21228 solver.cpp:397]     Test net output #1: loss = 0.239756 (* 1 = 0.239756 loss)
I1203 20:00:30.105499 21228 solver.cpp:218] Iteration 102000 (9.88255 iter/s, 10.1188s/100 iters), loss = 0.0361749
I1203 20:00:30.105499 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:00:30.105499 21228 solver.cpp:237]     Train net output #1: loss = 0.036175 (* 1 = 0.036175 loss)
I1203 20:00:30.105499 21228 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1203 20:00:38.195271 21228 solver.cpp:218] Iteration 102100 (12.3619 iter/s, 8.08938s/100 iters), loss = 0.0389965
I1203 20:00:38.195271 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:00:38.195271 21228 solver.cpp:237]     Train net output #1: loss = 0.0389965 (* 1 = 0.0389965 loss)
I1203 20:00:38.195271 21228 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1203 20:00:46.363142 21228 solver.cpp:218] Iteration 102200 (12.2439 iter/s, 8.16735s/100 iters), loss = 0.0263098
I1203 20:00:46.363642 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:00:46.363642 21228 solver.cpp:237]     Train net output #1: loss = 0.0263098 (* 1 = 0.0263098 loss)
I1203 20:00:46.363642 21228 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1203 20:00:54.617584 21228 solver.cpp:218] Iteration 102300 (12.1153 iter/s, 8.25405s/100 iters), loss = 0.0161979
I1203 20:00:54.617584 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:00:54.617584 21228 solver.cpp:237]     Train net output #1: loss = 0.016198 (* 1 = 0.016198 loss)
I1203 20:00:54.617584 21228 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1203 20:01:02.783915 21228 solver.cpp:218] Iteration 102400 (12.2468 iter/s, 8.1654s/100 iters), loss = 0.0217315
I1203 20:01:02.783915 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:01:02.783915 21228 solver.cpp:237]     Train net output #1: loss = 0.0217315 (* 1 = 0.0217315 loss)
I1203 20:01:02.783915 21228 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1203 20:01:10.486930 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:01:10.803467 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.caffemodel
I1203 20:01:10.843466 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.solverstate
I1203 20:01:10.850467 21228 solver.cpp:330] Iteration 102500, Testing net (#0)
I1203 20:01:10.850467 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:01:12.529599 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:01:12.596602 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9304
I1203 20:01:12.596602 21228 solver.cpp:397]     Test net output #1: loss = 0.238869 (* 1 = 0.238869 loss)
I1203 20:01:12.670605 21228 solver.cpp:218] Iteration 102500 (10.1146 iter/s, 9.88674s/100 iters), loss = 0.0258941
I1203 20:01:12.671607 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:01:12.671607 21228 solver.cpp:237]     Train net output #1: loss = 0.0258941 (* 1 = 0.0258941 loss)
I1203 20:01:12.671607 21228 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1203 20:01:20.728705 21228 solver.cpp:218] Iteration 102600 (12.4114 iter/s, 8.05713s/100 iters), loss = 0.051699
I1203 20:01:20.728705 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:01:20.728705 21228 solver.cpp:237]     Train net output #1: loss = 0.051699 (* 1 = 0.051699 loss)
I1203 20:01:20.728705 21228 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1203 20:01:28.871819 21228 solver.cpp:218] Iteration 102700 (12.2806 iter/s, 8.14295s/100 iters), loss = 0.0382153
I1203 20:01:28.871819 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:01:28.871819 21228 solver.cpp:237]     Train net output #1: loss = 0.0382154 (* 1 = 0.0382154 loss)
I1203 20:01:28.872818 21228 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1203 20:01:37.076913 21228 solver.cpp:218] Iteration 102800 (12.1888 iter/s, 8.20424s/100 iters), loss = 0.0286551
I1203 20:01:37.076913 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:01:37.076913 21228 solver.cpp:237]     Train net output #1: loss = 0.0286552 (* 1 = 0.0286552 loss)
I1203 20:01:37.076913 21228 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1203 20:01:45.251503 21228 solver.cpp:218] Iteration 102900 (12.2339 iter/s, 8.17402s/100 iters), loss = 0.0273313
I1203 20:01:45.251503 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:01:45.251503 21228 solver.cpp:237]     Train net output #1: loss = 0.0273313 (* 1 = 0.0273313 loss)
I1203 20:01:45.251503 21228 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1203 20:01:52.931103 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:01:53.250133 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.caffemodel
I1203 20:01:53.291133 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.solverstate
I1203 20:01:53.297638 21228 solver.cpp:330] Iteration 103000, Testing net (#0)
I1203 20:01:53.298138 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:01:54.979251 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:01:55.045254 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9309
I1203 20:01:55.045254 21228 solver.cpp:397]     Test net output #1: loss = 0.238018 (* 1 = 0.238018 loss)
I1203 20:01:55.121276 21228 solver.cpp:218] Iteration 103000 (10.1325 iter/s, 9.86926s/100 iters), loss = 0.0645484
I1203 20:01:55.121276 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:01:55.121276 21228 solver.cpp:237]     Train net output #1: loss = 0.0645485 (* 1 = 0.0645485 loss)
I1203 20:01:55.121276 21228 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1203 20:02:03.241080 21228 solver.cpp:218] Iteration 103100 (12.3165 iter/s, 8.11921s/100 iters), loss = 0.024443
I1203 20:02:03.241080 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:02:03.241080 21228 solver.cpp:237]     Train net output #1: loss = 0.024443 (* 1 = 0.024443 loss)
I1203 20:02:03.241080 21228 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1203 20:02:11.467793 21228 solver.cpp:218] Iteration 103200 (12.1567 iter/s, 8.22589s/100 iters), loss = 0.0219374
I1203 20:02:11.467793 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:02:11.467793 21228 solver.cpp:237]     Train net output #1: loss = 0.0219375 (* 1 = 0.0219375 loss)
I1203 20:02:11.467793 21228 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1203 20:02:19.800046 21228 solver.cpp:218] Iteration 103300 (12.0025 iter/s, 8.33158s/100 iters), loss = 0.0175266
I1203 20:02:19.800046 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:02:19.800046 21228 solver.cpp:237]     Train net output #1: loss = 0.0175266 (* 1 = 0.0175266 loss)
I1203 20:02:19.800046 21228 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1203 20:02:28.132875 21228 solver.cpp:218] Iteration 103400 (12.0014 iter/s, 8.33237s/100 iters), loss = 0.0129605
I1203 20:02:28.132875 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:02:28.132875 21228 solver.cpp:237]     Train net output #1: loss = 0.0129606 (* 1 = 0.0129606 loss)
I1203 20:02:28.132875 21228 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1203 20:02:36.058220 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:02:36.390219 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.caffemodel
I1203 20:02:36.430719 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.solverstate
I1203 20:02:36.437222 21228 solver.cpp:330] Iteration 103500, Testing net (#0)
I1203 20:02:36.437721 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:02:38.159720 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:02:38.228219 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1203 20:02:38.228219 21228 solver.cpp:397]     Test net output #1: loss = 0.236657 (* 1 = 0.236657 loss)
I1203 20:02:38.304718 21228 solver.cpp:218] Iteration 103500 (9.83165 iter/s, 10.1712s/100 iters), loss = 0.0236587
I1203 20:02:38.304718 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:02:38.304718 21228 solver.cpp:237]     Train net output #1: loss = 0.0236588 (* 1 = 0.0236588 loss)
I1203 20:02:38.304718 21228 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1203 20:02:46.632194 21228 solver.cpp:218] Iteration 103600 (12.0089 iter/s, 8.32719s/100 iters), loss = 0.0550282
I1203 20:02:46.632194 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:02:46.632695 21228 solver.cpp:237]     Train net output #1: loss = 0.0550282 (* 1 = 0.0550282 loss)
I1203 20:02:46.632695 21228 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1203 20:02:54.972080 21228 solver.cpp:218] Iteration 103700 (11.9916 iter/s, 8.33914s/100 iters), loss = 0.0410599
I1203 20:02:54.972080 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:02:54.972080 21228 solver.cpp:237]     Train net output #1: loss = 0.0410599 (* 1 = 0.0410599 loss)
I1203 20:02:54.972080 21228 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1203 20:03:03.372525 21228 solver.cpp:218] Iteration 103800 (11.9051 iter/s, 8.39976s/100 iters), loss = 0.0201285
I1203 20:03:03.372525 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:03:03.372525 21228 solver.cpp:237]     Train net output #1: loss = 0.0201286 (* 1 = 0.0201286 loss)
I1203 20:03:03.372525 21228 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1203 20:03:11.749053 21228 solver.cpp:218] Iteration 103900 (11.9391 iter/s, 8.37582s/100 iters), loss = 0.0299793
I1203 20:03:11.749053 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:03:11.749053 21228 solver.cpp:237]     Train net output #1: loss = 0.0299794 (* 1 = 0.0299794 loss)
I1203 20:03:11.749053 21228 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1203 20:03:19.604574 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:03:19.925565 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.caffemodel
I1203 20:03:19.960582 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.solverstate
I1203 20:03:19.967584 21228 solver.cpp:330] Iteration 104000, Testing net (#0)
I1203 20:03:19.967584 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:03:21.655066 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:03:21.721565 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9323
I1203 20:03:21.721565 21228 solver.cpp:397]     Test net output #1: loss = 0.235374 (* 1 = 0.235374 loss)
I1203 20:03:21.796567 21228 solver.cpp:218] Iteration 104000 (9.95325 iter/s, 10.047s/100 iters), loss = 0.0325772
I1203 20:03:21.796567 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:03:21.796567 21228 solver.cpp:237]     Train net output #1: loss = 0.0325773 (* 1 = 0.0325773 loss)
I1203 20:03:21.796567 21228 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1203 20:03:30.019145 21228 solver.cpp:218] Iteration 104100 (12.1626 iter/s, 8.22193s/100 iters), loss = 0.0824925
I1203 20:03:30.019145 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:03:30.019145 21228 solver.cpp:237]     Train net output #1: loss = 0.0824925 (* 1 = 0.0824925 loss)
I1203 20:03:30.019145 21228 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1203 20:03:38.150784 21228 solver.cpp:218] Iteration 104200 (12.298 iter/s, 8.13143s/100 iters), loss = 0.0190379
I1203 20:03:38.150784 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:03:38.150784 21228 solver.cpp:237]     Train net output #1: loss = 0.0190379 (* 1 = 0.0190379 loss)
I1203 20:03:38.150784 21228 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1203 20:03:46.228150 21228 solver.cpp:218] Iteration 104300 (12.3806 iter/s, 8.07717s/100 iters), loss = 0.0150904
I1203 20:03:46.228150 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:03:46.228150 21228 solver.cpp:237]     Train net output #1: loss = 0.0150904 (* 1 = 0.0150904 loss)
I1203 20:03:46.228150 21228 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1203 20:03:54.321205 21228 solver.cpp:218] Iteration 104400 (12.3574 iter/s, 8.09229s/100 iters), loss = 0.0178098
I1203 20:03:54.321205 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:03:54.321205 21228 solver.cpp:237]     Train net output #1: loss = 0.0178099 (* 1 = 0.0178099 loss)
I1203 20:03:54.321205 21228 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1203 20:04:02.139694 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:04:02.458742 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.caffemodel
I1203 20:04:02.497751 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.solverstate
I1203 20:04:02.504751 21228 solver.cpp:330] Iteration 104500, Testing net (#0)
I1203 20:04:02.504751 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:04:04.210927 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:04:04.277927 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9318
I1203 20:04:04.277927 21228 solver.cpp:397]     Test net output #1: loss = 0.236722 (* 1 = 0.236722 loss)
I1203 20:04:04.353940 21228 solver.cpp:218] Iteration 104500 (9.96789 iter/s, 10.0322s/100 iters), loss = 0.0187451
I1203 20:04:04.353940 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:04:04.353940 21228 solver.cpp:237]     Train net output #1: loss = 0.0187452 (* 1 = 0.0187452 loss)
I1203 20:04:04.353940 21228 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1203 20:04:12.447029 21228 solver.cpp:218] Iteration 104600 (12.3568 iter/s, 8.09268s/100 iters), loss = 0.0444959
I1203 20:04:12.447029 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:04:12.447029 21228 solver.cpp:237]     Train net output #1: loss = 0.044496 (* 1 = 0.044496 loss)
I1203 20:04:12.447029 21228 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1203 20:04:20.643965 21228 solver.cpp:218] Iteration 104700 (12.2007 iter/s, 8.19624s/100 iters), loss = 0.0270259
I1203 20:04:20.643965 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:04:20.643965 21228 solver.cpp:237]     Train net output #1: loss = 0.0270259 (* 1 = 0.0270259 loss)
I1203 20:04:20.643965 21228 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1203 20:04:28.790771 21228 solver.cpp:218] Iteration 104800 (12.2755 iter/s, 8.14631s/100 iters), loss = 0.0192162
I1203 20:04:28.790771 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:04:28.790771 21228 solver.cpp:237]     Train net output #1: loss = 0.0192163 (* 1 = 0.0192163 loss)
I1203 20:04:28.790771 21228 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1203 20:04:36.913666 21228 solver.cpp:218] Iteration 104900 (12.3119 iter/s, 8.12225s/100 iters), loss = 0.0231545
I1203 20:04:36.913666 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:04:36.913666 21228 solver.cpp:237]     Train net output #1: loss = 0.0231546 (* 1 = 0.0231546 loss)
I1203 20:04:36.913666 21228 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1203 20:04:44.636567 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:04:44.953588 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.caffemodel
I1203 20:04:44.983587 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.solverstate
I1203 20:04:44.990092 21228 solver.cpp:330] Iteration 105000, Testing net (#0)
I1203 20:04:44.990593 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:04:46.674711 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:04:46.740715 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1203 20:04:46.740715 21228 solver.cpp:397]     Test net output #1: loss = 0.236319 (* 1 = 0.236319 loss)
I1203 20:04:46.816720 21228 solver.cpp:218] Iteration 105000 (10.098 iter/s, 9.903s/100 iters), loss = 0.0287667
I1203 20:04:46.816720 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:04:46.816720 21228 solver.cpp:237]     Train net output #1: loss = 0.0287668 (* 1 = 0.0287668 loss)
I1203 20:04:46.816720 21228 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1203 20:04:54.948101 21228 solver.cpp:218] Iteration 105100 (12.299 iter/s, 8.13074s/100 iters), loss = 0.0410854
I1203 20:04:54.948101 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:04:54.948101 21228 solver.cpp:237]     Train net output #1: loss = 0.0410855 (* 1 = 0.0410855 loss)
I1203 20:04:54.948101 21228 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1203 20:05:03.095587 21228 solver.cpp:218] Iteration 105200 (12.2747 iter/s, 8.14682s/100 iters), loss = 0.0225598
I1203 20:05:03.096088 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:05:03.096088 21228 solver.cpp:237]     Train net output #1: loss = 0.0225599 (* 1 = 0.0225599 loss)
I1203 20:05:03.096088 21228 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1203 20:05:11.222880 21228 solver.cpp:218] Iteration 105300 (12.3053 iter/s, 8.12661s/100 iters), loss = 0.0138538
I1203 20:05:11.222880 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:05:11.222880 21228 solver.cpp:237]     Train net output #1: loss = 0.0138539 (* 1 = 0.0138539 loss)
I1203 20:05:11.222880 21228 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1203 20:05:19.465734 21228 solver.cpp:218] Iteration 105400 (12.1322 iter/s, 8.24252s/100 iters), loss = 0.0232924
I1203 20:05:19.465734 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:05:19.465734 21228 solver.cpp:237]     Train net output #1: loss = 0.0232925 (* 1 = 0.0232925 loss)
I1203 20:05:19.465734 21228 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1203 20:05:27.284576 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:05:27.603710 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.caffemodel
I1203 20:05:27.638700 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.solverstate
I1203 20:05:27.644701 21228 solver.cpp:330] Iteration 105500, Testing net (#0)
I1203 20:05:27.645702 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:05:29.333631 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:05:29.400169 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1203 20:05:29.400169 21228 solver.cpp:397]     Test net output #1: loss = 0.23971 (* 1 = 0.23971 loss)
I1203 20:05:29.474689 21228 solver.cpp:218] Iteration 105500 (9.99129 iter/s, 10.0087s/100 iters), loss = 0.022351
I1203 20:05:29.474689 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:05:29.474689 21228 solver.cpp:237]     Train net output #1: loss = 0.0223511 (* 1 = 0.0223511 loss)
I1203 20:05:29.474689 21228 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1203 20:05:37.561451 21228 solver.cpp:218] Iteration 105600 (12.3678 iter/s, 8.08548s/100 iters), loss = 0.0445835
I1203 20:05:37.561451 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:05:37.561451 21228 solver.cpp:237]     Train net output #1: loss = 0.0445836 (* 1 = 0.0445836 loss)
I1203 20:05:37.561451 21228 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1203 20:05:45.629263 21228 solver.cpp:218] Iteration 105700 (12.3947 iter/s, 8.06796s/100 iters), loss = 0.0588313
I1203 20:05:45.629263 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 20:05:45.629263 21228 solver.cpp:237]     Train net output #1: loss = 0.0588314 (* 1 = 0.0588314 loss)
I1203 20:05:45.629263 21228 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1203 20:05:53.792033 21228 solver.cpp:218] Iteration 105800 (12.2517 iter/s, 8.16212s/100 iters), loss = 0.0125446
I1203 20:05:53.792033 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:05:53.792033 21228 solver.cpp:237]     Train net output #1: loss = 0.0125446 (* 1 = 0.0125446 loss)
I1203 20:05:53.792033 21228 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1203 20:06:02.019932 21228 solver.cpp:218] Iteration 105900 (12.1548 iter/s, 8.22718s/100 iters), loss = 0.0222464
I1203 20:06:02.019932 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:06:02.019932 21228 solver.cpp:237]     Train net output #1: loss = 0.0222465 (* 1 = 0.0222465 loss)
I1203 20:06:02.019932 21228 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1203 20:06:09.902410 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:06:10.220942 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.caffemodel
I1203 20:06:10.264942 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.solverstate
I1203 20:06:10.270943 21228 solver.cpp:330] Iteration 106000, Testing net (#0)
I1203 20:06:10.271944 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:06:11.975071 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:06:12.043081 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9318
I1203 20:06:12.043081 21228 solver.cpp:397]     Test net output #1: loss = 0.238823 (* 1 = 0.238823 loss)
I1203 20:06:12.117087 21228 solver.cpp:218] Iteration 106000 (9.9045 iter/s, 10.0964s/100 iters), loss = 0.0214177
I1203 20:06:12.117087 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:06:12.117087 21228 solver.cpp:237]     Train net output #1: loss = 0.0214178 (* 1 = 0.0214178 loss)
I1203 20:06:12.117087 21228 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1203 20:06:20.286057 21228 solver.cpp:218] Iteration 106100 (12.2415 iter/s, 8.16891s/100 iters), loss = 0.0460181
I1203 20:06:20.287058 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:06:20.287058 21228 solver.cpp:237]     Train net output #1: loss = 0.0460182 (* 1 = 0.0460182 loss)
I1203 20:06:20.287058 21228 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1203 20:06:28.368614 21228 solver.cpp:218] Iteration 106200 (12.3742 iter/s, 8.0813s/100 iters), loss = 0.0382102
I1203 20:06:28.368614 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:06:28.368614 21228 solver.cpp:237]     Train net output #1: loss = 0.0382102 (* 1 = 0.0382102 loss)
I1203 20:06:28.368614 21228 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1203 20:06:36.491964 21228 solver.cpp:218] Iteration 106300 (12.3106 iter/s, 8.12306s/100 iters), loss = 0.0187553
I1203 20:06:36.492465 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:06:36.492465 21228 solver.cpp:237]     Train net output #1: loss = 0.0187554 (* 1 = 0.0187554 loss)
I1203 20:06:36.492465 21228 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1203 20:06:44.726225 21228 solver.cpp:218] Iteration 106400 (12.1453 iter/s, 8.23365s/100 iters), loss = 0.0129737
I1203 20:06:44.726225 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:06:44.726727 21228 solver.cpp:237]     Train net output #1: loss = 0.0129738 (* 1 = 0.0129738 loss)
I1203 20:06:44.726727 21228 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1203 20:06:52.617175 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:06:52.947715 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.caffemodel
I1203 20:06:52.977715 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.solverstate
I1203 20:06:52.984715 21228 solver.cpp:330] Iteration 106500, Testing net (#0)
I1203 20:06:52.984715 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:06:54.680862 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:06:54.747872 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1203 20:06:54.747872 21228 solver.cpp:397]     Test net output #1: loss = 0.237282 (* 1 = 0.237282 loss)
I1203 20:06:54.823374 21228 solver.cpp:218] Iteration 106500 (9.90458 iter/s, 10.0963s/100 iters), loss = 0.0455498
I1203 20:06:54.823374 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:06:54.823374 21228 solver.cpp:237]     Train net output #1: loss = 0.0455499 (* 1 = 0.0455499 loss)
I1203 20:06:54.823374 21228 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1203 20:07:03.150892 21228 solver.cpp:218] Iteration 106600 (12.0086 iter/s, 8.32738s/100 iters), loss = 0.0756005
I1203 20:07:03.150892 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:07:03.150892 21228 solver.cpp:237]     Train net output #1: loss = 0.0756005 (* 1 = 0.0756005 loss)
I1203 20:07:03.150892 21228 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1203 20:07:11.489688 21228 solver.cpp:218] Iteration 106700 (11.9931 iter/s, 8.33816s/100 iters), loss = 0.0189519
I1203 20:07:11.489688 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:07:11.489688 21228 solver.cpp:237]     Train net output #1: loss = 0.018952 (* 1 = 0.018952 loss)
I1203 20:07:11.489688 21228 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1203 20:07:19.738659 21228 solver.cpp:218] Iteration 106800 (12.1233 iter/s, 8.24855s/100 iters), loss = 0.020853
I1203 20:07:19.738659 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:07:19.738659 21228 solver.cpp:237]     Train net output #1: loss = 0.020853 (* 1 = 0.020853 loss)
I1203 20:07:19.738659 21228 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1203 20:07:28.071841 21228 solver.cpp:218] Iteration 106900 (12.0017 iter/s, 8.33212s/100 iters), loss = 0.0208109
I1203 20:07:28.071841 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:07:28.071841 21228 solver.cpp:237]     Train net output #1: loss = 0.020811 (* 1 = 0.020811 loss)
I1203 20:07:28.071841 21228 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1203 20:07:35.882552 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:07:36.207586 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.caffemodel
I1203 20:07:36.247594 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.solverstate
I1203 20:07:36.253592 21228 solver.cpp:330] Iteration 107000, Testing net (#0)
I1203 20:07:36.253592 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:07:37.949244 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:07:38.018244 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1203 20:07:38.018244 21228 solver.cpp:397]     Test net output #1: loss = 0.235812 (* 1 = 0.235812 loss)
I1203 20:07:38.094249 21228 solver.cpp:218] Iteration 107000 (9.97773 iter/s, 10.0223s/100 iters), loss = 0.0201025
I1203 20:07:38.095250 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:07:38.095250 21228 solver.cpp:237]     Train net output #1: loss = 0.0201026 (* 1 = 0.0201026 loss)
I1203 20:07:38.095250 21228 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1203 20:07:46.295150 21228 solver.cpp:218] Iteration 107100 (12.1954 iter/s, 8.19982s/100 iters), loss = 0.0182157
I1203 20:07:46.295150 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:07:46.295150 21228 solver.cpp:237]     Train net output #1: loss = 0.0182158 (* 1 = 0.0182158 loss)
I1203 20:07:46.295150 21228 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1203 20:07:54.584913 21228 solver.cpp:218] Iteration 107200 (12.0636 iter/s, 8.28937s/100 iters), loss = 0.0403107
I1203 20:07:54.584913 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:07:54.584913 21228 solver.cpp:237]     Train net output #1: loss = 0.0403107 (* 1 = 0.0403107 loss)
I1203 20:07:54.584913 21228 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1203 20:08:02.849056 21228 solver.cpp:218] Iteration 107300 (12.102 iter/s, 8.26309s/100 iters), loss = 0.0358206
I1203 20:08:02.849056 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:08:02.849056 21228 solver.cpp:237]     Train net output #1: loss = 0.0358206 (* 1 = 0.0358206 loss)
I1203 20:08:02.849056 21228 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1203 20:08:11.157534 21228 solver.cpp:218] Iteration 107400 (12.0368 iter/s, 8.30788s/100 iters), loss = 0.0198794
I1203 20:08:11.157534 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:08:11.157534 21228 solver.cpp:237]     Train net output #1: loss = 0.0198794 (* 1 = 0.0198794 loss)
I1203 20:08:11.157534 21228 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1203 20:08:18.986618 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:08:19.318476 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.caffemodel
I1203 20:08:19.360486 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.solverstate
I1203 20:08:19.367486 21228 solver.cpp:330] Iteration 107500, Testing net (#0)
I1203 20:08:19.367486 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:08:21.085827 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:08:21.154836 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9311
I1203 20:08:21.154836 21228 solver.cpp:397]     Test net output #1: loss = 0.23773 (* 1 = 0.23773 loss)
I1203 20:08:21.231839 21228 solver.cpp:218] Iteration 107500 (9.92701 iter/s, 10.0735s/100 iters), loss = 0.0190921
I1203 20:08:21.231839 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:08:21.231839 21228 solver.cpp:237]     Train net output #1: loss = 0.0190922 (* 1 = 0.0190922 loss)
I1203 20:08:21.231839 21228 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1203 20:08:29.546337 21228 solver.cpp:218] Iteration 107600 (12.0268 iter/s, 8.31478s/100 iters), loss = 0.0233866
I1203 20:08:29.546337 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:08:29.546337 21228 solver.cpp:237]     Train net output #1: loss = 0.0233867 (* 1 = 0.0233867 loss)
I1203 20:08:29.546337 21228 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1203 20:08:37.855073 21228 solver.cpp:218] Iteration 107700 (12.0371 iter/s, 8.30763s/100 iters), loss = 0.0259281
I1203 20:08:37.855073 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:08:37.855073 21228 solver.cpp:237]     Train net output #1: loss = 0.0259281 (* 1 = 0.0259281 loss)
I1203 20:08:37.855073 21228 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1203 20:08:46.060868 21228 solver.cpp:218] Iteration 107800 (12.1875 iter/s, 8.20513s/100 iters), loss = 0.0105914
I1203 20:08:46.060868 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:08:46.060868 21228 solver.cpp:237]     Train net output #1: loss = 0.0105915 (* 1 = 0.0105915 loss)
I1203 20:08:46.060868 21228 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1203 20:08:54.248762 21228 solver.cpp:218] Iteration 107900 (12.213 iter/s, 8.18802s/100 iters), loss = 0.0127814
I1203 20:08:54.248762 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:08:54.248762 21228 solver.cpp:237]     Train net output #1: loss = 0.0127815 (* 1 = 0.0127815 loss)
I1203 20:08:54.248762 21228 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1203 20:09:02.158303 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:09:02.483312 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.caffemodel
I1203 20:09:02.524312 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.solverstate
I1203 20:09:02.531312 21228 solver.cpp:330] Iteration 108000, Testing net (#0)
I1203 20:09:02.531312 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:09:04.229523 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:09:04.297535 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9314
I1203 20:09:04.297535 21228 solver.cpp:397]     Test net output #1: loss = 0.23529 (* 1 = 0.23529 loss)
I1203 20:09:04.372555 21228 solver.cpp:218] Iteration 108000 (9.87825 iter/s, 10.1233s/100 iters), loss = 0.0291095
I1203 20:09:04.372555 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:09:04.372555 21228 solver.cpp:237]     Train net output #1: loss = 0.0291095 (* 1 = 0.0291095 loss)
I1203 20:09:04.372555 21228 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1203 20:09:12.673288 21228 solver.cpp:218] Iteration 108100 (12.0481 iter/s, 8.30007s/100 iters), loss = 0.0339424
I1203 20:09:12.673288 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:09:12.673288 21228 solver.cpp:237]     Train net output #1: loss = 0.0339425 (* 1 = 0.0339425 loss)
I1203 20:09:12.673288 21228 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1203 20:09:20.865463 21228 solver.cpp:218] Iteration 108200 (12.2078 iter/s, 8.1915s/100 iters), loss = 0.0218779
I1203 20:09:20.865463 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:09:20.865463 21228 solver.cpp:237]     Train net output #1: loss = 0.0218779 (* 1 = 0.0218779 loss)
I1203 20:09:20.865463 21228 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1203 20:09:29.077641 21228 solver.cpp:218] Iteration 108300 (12.1782 iter/s, 8.21142s/100 iters), loss = 0.0127052
I1203 20:09:29.077641 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:09:29.077641 21228 solver.cpp:237]     Train net output #1: loss = 0.0127053 (* 1 = 0.0127053 loss)
I1203 20:09:29.077641 21228 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1203 20:09:37.261752 21228 solver.cpp:218] Iteration 108400 (12.2197 iter/s, 8.18353s/100 iters), loss = 0.01112
I1203 20:09:37.261752 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:09:37.261752 21228 solver.cpp:237]     Train net output #1: loss = 0.0111201 (* 1 = 0.0111201 loss)
I1203 20:09:37.261752 21228 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1203 20:09:45.055166 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:09:45.383715 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.caffemodel
I1203 20:09:45.412219 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.solverstate
I1203 20:09:45.418217 21228 solver.cpp:330] Iteration 108500, Testing net (#0)
I1203 20:09:45.418217 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:09:47.129372 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:09:47.196877 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1203 20:09:47.196877 21228 solver.cpp:397]     Test net output #1: loss = 0.234784 (* 1 = 0.234784 loss)
I1203 20:09:47.272382 21228 solver.cpp:218] Iteration 108500 (9.98958 iter/s, 10.0104s/100 iters), loss = 0.024628
I1203 20:09:47.272382 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:09:47.272382 21228 solver.cpp:237]     Train net output #1: loss = 0.024628 (* 1 = 0.024628 loss)
I1203 20:09:47.272382 21228 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1203 20:09:55.584466 21228 solver.cpp:218] Iteration 108600 (12.0318 iter/s, 8.3113s/100 iters), loss = 0.0166165
I1203 20:09:55.584466 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:09:55.584466 21228 solver.cpp:237]     Train net output #1: loss = 0.0166165 (* 1 = 0.0166165 loss)
I1203 20:09:55.584466 21228 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1203 20:10:04.135457 21228 solver.cpp:218] Iteration 108700 (11.6945 iter/s, 8.55104s/100 iters), loss = 0.0311916
I1203 20:10:04.135457 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:10:04.136456 21228 solver.cpp:237]     Train net output #1: loss = 0.0311917 (* 1 = 0.0311917 loss)
I1203 20:10:04.136456 21228 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1203 20:10:12.476959 21228 solver.cpp:218] Iteration 108800 (11.9903 iter/s, 8.34006s/100 iters), loss = 0.0188384
I1203 20:10:12.476959 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:10:12.476959 21228 solver.cpp:237]     Train net output #1: loss = 0.0188384 (* 1 = 0.0188384 loss)
I1203 20:10:12.476959 21228 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1203 20:10:20.811971 21228 solver.cpp:218] Iteration 108900 (11.9985 iter/s, 8.33436s/100 iters), loss = 0.0370825
I1203 20:10:20.811971 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:10:20.811971 21228 solver.cpp:237]     Train net output #1: loss = 0.0370825 (* 1 = 0.0370825 loss)
I1203 20:10:20.811971 21228 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1203 20:10:28.712837 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:10:29.042855 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.caffemodel
I1203 20:10:29.072857 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.solverstate
I1203 20:10:29.079859 21228 solver.cpp:330] Iteration 109000, Testing net (#0)
I1203 20:10:29.079859 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:10:30.787014 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:10:30.857023 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1203 20:10:30.857023 21228 solver.cpp:397]     Test net output #1: loss = 0.235465 (* 1 = 0.235465 loss)
I1203 20:10:30.935029 21228 solver.cpp:218] Iteration 109000 (9.87867 iter/s, 10.1228s/100 iters), loss = 0.0152442
I1203 20:10:30.935029 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:10:30.935029 21228 solver.cpp:237]     Train net output #1: loss = 0.0152443 (* 1 = 0.0152443 loss)
I1203 20:10:30.935029 21228 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1203 20:10:39.235105 21228 solver.cpp:218] Iteration 109100 (12.0491 iter/s, 8.29936s/100 iters), loss = 0.0437903
I1203 20:10:39.235105 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:10:39.235105 21228 solver.cpp:237]     Train net output #1: loss = 0.0437904 (* 1 = 0.0437904 loss)
I1203 20:10:39.235105 21228 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1203 20:10:47.547963 21228 solver.cpp:218] Iteration 109200 (12.0302 iter/s, 8.31238s/100 iters), loss = 0.0229898
I1203 20:10:47.547963 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:10:47.547963 21228 solver.cpp:237]     Train net output #1: loss = 0.0229899 (* 1 = 0.0229899 loss)
I1203 20:10:47.547963 21228 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1203 20:10:55.840178 21228 solver.cpp:218] Iteration 109300 (12.0606 iter/s, 8.29144s/100 iters), loss = 0.0194153
I1203 20:10:55.840178 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:10:55.840178 21228 solver.cpp:237]     Train net output #1: loss = 0.0194154 (* 1 = 0.0194154 loss)
I1203 20:10:55.840178 21228 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1203 20:11:04.176249 21228 solver.cpp:218] Iteration 109400 (11.9959 iter/s, 8.33619s/100 iters), loss = 0.0225142
I1203 20:11:04.177250 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:11:04.177250 21228 solver.cpp:237]     Train net output #1: loss = 0.0225143 (* 1 = 0.0225143 loss)
I1203 20:11:04.177250 21228 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1203 20:11:12.093303 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:11:12.426625 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.caffemodel
I1203 20:11:12.456625 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.solverstate
I1203 20:11:12.463625 21228 solver.cpp:330] Iteration 109500, Testing net (#0)
I1203 20:11:12.463625 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:11:14.197778 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:11:14.263783 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 20:11:14.263783 21228 solver.cpp:397]     Test net output #1: loss = 0.240262 (* 1 = 0.240262 loss)
I1203 20:11:14.338814 21228 solver.cpp:218] Iteration 109500 (9.84107 iter/s, 10.1615s/100 iters), loss = 0.014795
I1203 20:11:14.338814 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:11:14.338814 21228 solver.cpp:237]     Train net output #1: loss = 0.014795 (* 1 = 0.014795 loss)
I1203 20:11:14.338814 21228 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1203 20:11:22.679946 21228 solver.cpp:218] Iteration 109600 (11.9897 iter/s, 8.3405s/100 iters), loss = 0.0409401
I1203 20:11:22.679946 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:11:22.679946 21228 solver.cpp:237]     Train net output #1: loss = 0.0409401 (* 1 = 0.0409401 loss)
I1203 20:11:22.679946 21228 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1203 20:11:31.008661 21228 solver.cpp:218] Iteration 109700 (12.008 iter/s, 8.32777s/100 iters), loss = 0.0224304
I1203 20:11:31.008661 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:11:31.008661 21228 solver.cpp:237]     Train net output #1: loss = 0.0224305 (* 1 = 0.0224305 loss)
I1203 20:11:31.008661 21228 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1203 20:11:39.347569 21228 solver.cpp:218] Iteration 109800 (11.9922 iter/s, 8.33876s/100 iters), loss = 0.0209481
I1203 20:11:39.347569 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:11:39.347569 21228 solver.cpp:237]     Train net output #1: loss = 0.0209481 (* 1 = 0.0209481 loss)
I1203 20:11:39.347569 21228 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1203 20:11:47.577975 21228 solver.cpp:218] Iteration 109900 (12.1514 iter/s, 8.22953s/100 iters), loss = 0.0129122
I1203 20:11:47.578475 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:11:47.578475 21228 solver.cpp:237]     Train net output #1: loss = 0.0129122 (* 1 = 0.0129122 loss)
I1203 20:11:47.578475 21228 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1203 20:11:55.299212 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:11:55.618233 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.caffemodel
I1203 20:11:55.657234 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.solverstate
I1203 20:11:55.663234 21228 solver.cpp:330] Iteration 110000, Testing net (#0)
I1203 20:11:55.663234 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:11:57.354365 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:11:57.421371 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9356
I1203 20:11:57.421371 21228 solver.cpp:397]     Test net output #1: loss = 0.233736 (* 1 = 0.233736 loss)
I1203 20:11:57.497392 21228 solver.cpp:218] Iteration 110000 (10.082 iter/s, 9.91869s/100 iters), loss = 0.0314345
I1203 20:11:57.497392 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:11:57.497392 21228 solver.cpp:237]     Train net output #1: loss = 0.0314346 (* 1 = 0.0314346 loss)
I1203 20:11:57.497392 21228 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1203 20:12:05.582746 21228 solver.cpp:218] Iteration 110100 (12.369 iter/s, 8.08474s/100 iters), loss = 0.0126148
I1203 20:12:05.582746 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:12:05.582746 21228 solver.cpp:237]     Train net output #1: loss = 0.0126148 (* 1 = 0.0126148 loss)
I1203 20:12:05.582746 21228 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1203 20:12:13.708634 21228 solver.cpp:218] Iteration 110200 (12.3067 iter/s, 8.12569s/100 iters), loss = 0.0199626
I1203 20:12:13.708634 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:12:13.708634 21228 solver.cpp:237]     Train net output #1: loss = 0.0199627 (* 1 = 0.0199627 loss)
I1203 20:12:13.708634 21228 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1203 20:12:22.034045 21228 solver.cpp:218] Iteration 110300 (12.0128 iter/s, 8.32445s/100 iters), loss = 0.0135455
I1203 20:12:22.034045 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:12:22.034045 21228 solver.cpp:237]     Train net output #1: loss = 0.0135456 (* 1 = 0.0135456 loss)
I1203 20:12:22.034045 21228 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1203 20:12:30.141088 21228 solver.cpp:218] Iteration 110400 (12.3349 iter/s, 8.10705s/100 iters), loss = 0.0155026
I1203 20:12:30.141088 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:12:30.141088 21228 solver.cpp:237]     Train net output #1: loss = 0.0155026 (* 1 = 0.0155026 loss)
I1203 20:12:30.141088 21228 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1203 20:12:37.900916 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:12:38.217952 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.caffemodel
I1203 20:12:38.245950 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.solverstate
I1203 20:12:38.251950 21228 solver.cpp:330] Iteration 110500, Testing net (#0)
I1203 20:12:38.251950 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:12:39.946077 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:12:40.014089 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1203 20:12:40.014089 21228 solver.cpp:397]     Test net output #1: loss = 0.236607 (* 1 = 0.236607 loss)
I1203 20:12:40.090090 21228 solver.cpp:218] Iteration 110500 (10.0522 iter/s, 9.94811s/100 iters), loss = 0.016714
I1203 20:12:40.090090 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:12:40.090090 21228 solver.cpp:237]     Train net output #1: loss = 0.016714 (* 1 = 0.016714 loss)
I1203 20:12:40.090090 21228 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1203 20:12:48.321995 21228 solver.cpp:218] Iteration 110600 (12.148 iter/s, 8.23183s/100 iters), loss = 0.015188
I1203 20:12:48.321995 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:12:48.321995 21228 solver.cpp:237]     Train net output #1: loss = 0.0151881 (* 1 = 0.0151881 loss)
I1203 20:12:48.321995 21228 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1203 20:12:56.516008 21228 solver.cpp:218] Iteration 110700 (12.2045 iter/s, 8.19367s/100 iters), loss = 0.0247518
I1203 20:12:56.516008 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:12:56.516008 21228 solver.cpp:237]     Train net output #1: loss = 0.0247518 (* 1 = 0.0247518 loss)
I1203 20:12:56.516008 21228 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1203 20:13:04.679067 21228 solver.cpp:218] Iteration 110800 (12.2518 iter/s, 8.16205s/100 iters), loss = 0.0177522
I1203 20:13:04.679067 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:04.679067 21228 solver.cpp:237]     Train net output #1: loss = 0.0177522 (* 1 = 0.0177522 loss)
I1203 20:13:04.679067 21228 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1203 20:13:12.857319 21228 solver.cpp:218] Iteration 110900 (12.2281 iter/s, 8.17785s/100 iters), loss = 0.0149392
I1203 20:13:12.857319 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:12.857319 21228 solver.cpp:237]     Train net output #1: loss = 0.0149392 (* 1 = 0.0149392 loss)
I1203 20:13:12.857319 21228 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1203 20:13:20.637832 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:13:20.964359 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.caffemodel
I1203 20:13:21.004360 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.solverstate
I1203 20:13:21.011360 21228 solver.cpp:330] Iteration 111000, Testing net (#0)
I1203 20:13:21.011360 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:13:22.712491 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:13:22.779497 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1203 20:13:22.779497 21228 solver.cpp:397]     Test net output #1: loss = 0.235821 (* 1 = 0.235821 loss)
I1203 20:13:22.858507 21228 solver.cpp:218] Iteration 111000 (9.9995 iter/s, 10.0005s/100 iters), loss = 0.0173455
I1203 20:13:22.858507 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:22.858507 21228 solver.cpp:237]     Train net output #1: loss = 0.0173455 (* 1 = 0.0173455 loss)
I1203 20:13:22.858507 21228 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1203 20:13:30.933867 21228 solver.cpp:218] Iteration 111100 (12.3839 iter/s, 8.07501s/100 iters), loss = 0.0204718
I1203 20:13:30.934368 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:30.934368 21228 solver.cpp:237]     Train net output #1: loss = 0.0204718 (* 1 = 0.0204718 loss)
I1203 20:13:30.934368 21228 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1203 20:13:39.019481 21228 solver.cpp:218] Iteration 111200 (12.368 iter/s, 8.08541s/100 iters), loss = 0.012134
I1203 20:13:39.019481 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:39.019481 21228 solver.cpp:237]     Train net output #1: loss = 0.0121341 (* 1 = 0.0121341 loss)
I1203 20:13:39.019481 21228 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1203 20:13:47.093881 21228 solver.cpp:218] Iteration 111300 (12.3861 iter/s, 8.0736s/100 iters), loss = 0.0155273
I1203 20:13:47.093881 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:47.093881 21228 solver.cpp:237]     Train net output #1: loss = 0.0155274 (* 1 = 0.0155274 loss)
I1203 20:13:47.093881 21228 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1203 20:13:55.181687 21228 solver.cpp:218] Iteration 111400 (12.3651 iter/s, 8.08725s/100 iters), loss = 0.0196503
I1203 20:13:55.181687 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:13:55.181687 21228 solver.cpp:237]     Train net output #1: loss = 0.0196503 (* 1 = 0.0196503 loss)
I1203 20:13:55.181687 21228 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1203 20:14:02.864464 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:14:03.184511 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.caffemodel
I1203 20:14:03.226511 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.solverstate
I1203 20:14:03.233512 21228 solver.cpp:330] Iteration 111500, Testing net (#0)
I1203 20:14:03.233512 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:14:04.919646 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:14:04.987655 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1203 20:14:04.987655 21228 solver.cpp:397]     Test net output #1: loss = 0.238408 (* 1 = 0.238408 loss)
I1203 20:14:05.062662 21228 solver.cpp:218] Iteration 111500 (10.1214 iter/s, 9.88004s/100 iters), loss = 0.0166
I1203 20:14:05.062662 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:14:05.062662 21228 solver.cpp:237]     Train net output #1: loss = 0.0166 (* 1 = 0.0166 loss)
I1203 20:14:05.062662 21228 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1203 20:14:13.139528 21228 solver.cpp:218] Iteration 111600 (12.3809 iter/s, 8.07694s/100 iters), loss = 0.0242635
I1203 20:14:13.139528 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:14:13.139528 21228 solver.cpp:237]     Train net output #1: loss = 0.0242635 (* 1 = 0.0242635 loss)
I1203 20:14:13.139528 21228 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1203 20:14:21.209307 21228 solver.cpp:218] Iteration 111700 (12.3938 iter/s, 8.06858s/100 iters), loss = 0.0222006
I1203 20:14:21.209307 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:14:21.209307 21228 solver.cpp:237]     Train net output #1: loss = 0.0222006 (* 1 = 0.0222006 loss)
I1203 20:14:21.209307 21228 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1203 20:14:29.283008 21228 solver.cpp:218] Iteration 111800 (12.3861 iter/s, 8.07359s/100 iters), loss = 0.0152298
I1203 20:14:29.283008 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:14:29.283008 21228 solver.cpp:237]     Train net output #1: loss = 0.0152298 (* 1 = 0.0152298 loss)
I1203 20:14:29.283008 21228 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1203 20:14:37.346490 21228 solver.cpp:218] Iteration 111900 (12.402 iter/s, 8.06325s/100 iters), loss = 0.0222509
I1203 20:14:37.346490 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:14:37.346490 21228 solver.cpp:237]     Train net output #1: loss = 0.0222509 (* 1 = 0.0222509 loss)
I1203 20:14:37.346490 21228 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1203 20:14:45.017432 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:14:45.338451 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.caffemodel
I1203 20:14:45.369460 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.solverstate
I1203 20:14:45.376461 21228 solver.cpp:330] Iteration 112000, Testing net (#0)
I1203 20:14:45.376461 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:14:47.063097 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:14:47.130601 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 20:14:47.130601 21228 solver.cpp:397]     Test net output #1: loss = 0.240413 (* 1 = 0.240413 loss)
I1203 20:14:47.205607 21228 solver.cpp:218] Iteration 112000 (10.1441 iter/s, 9.85794s/100 iters), loss = 0.0200262
I1203 20:14:47.205607 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:14:47.205607 21228 solver.cpp:237]     Train net output #1: loss = 0.0200262 (* 1 = 0.0200262 loss)
I1203 20:14:47.205607 21228 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1203 20:14:55.284852 21228 solver.cpp:218] Iteration 112100 (12.378 iter/s, 8.07885s/100 iters), loss = 0.0340919
I1203 20:14:55.284852 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:14:55.284852 21228 solver.cpp:237]     Train net output #1: loss = 0.0340919 (* 1 = 0.0340919 loss)
I1203 20:14:55.284852 21228 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1203 20:15:03.366936 21228 solver.cpp:218] Iteration 112200 (12.3736 iter/s, 8.0817s/100 iters), loss = 0.0295461
I1203 20:15:03.367436 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:15:03.367436 21228 solver.cpp:237]     Train net output #1: loss = 0.0295461 (* 1 = 0.0295461 loss)
I1203 20:15:03.367436 21228 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1203 20:15:11.439790 21228 solver.cpp:218] Iteration 112300 (12.388 iter/s, 8.0723s/100 iters), loss = 0.01062
I1203 20:15:11.439790 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:15:11.439790 21228 solver.cpp:237]     Train net output #1: loss = 0.01062 (* 1 = 0.01062 loss)
I1203 20:15:11.439790 21228 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1203 20:15:19.511351 21228 solver.cpp:218] Iteration 112400 (12.3899 iter/s, 8.07109s/100 iters), loss = 0.0144151
I1203 20:15:19.511351 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:15:19.511351 21228 solver.cpp:237]     Train net output #1: loss = 0.0144151 (* 1 = 0.0144151 loss)
I1203 20:15:19.511351 21228 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1203 20:15:27.189867 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:15:27.507894 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.caffemodel
I1203 20:15:27.548893 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.solverstate
I1203 20:15:27.556895 21228 solver.cpp:330] Iteration 112500, Testing net (#0)
I1203 20:15:27.557894 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:15:29.241042 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:15:29.309051 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1203 20:15:29.309051 21228 solver.cpp:397]     Test net output #1: loss = 0.240945 (* 1 = 0.240945 loss)
I1203 20:15:29.385056 21228 solver.cpp:218] Iteration 112500 (10.1287 iter/s, 9.87289s/100 iters), loss = 0.0321086
I1203 20:15:29.385056 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:15:29.385056 21228 solver.cpp:237]     Train net output #1: loss = 0.0321086 (* 1 = 0.0321086 loss)
I1203 20:15:29.385056 21228 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1203 20:15:37.467613 21228 solver.cpp:218] Iteration 112600 (12.3729 iter/s, 8.08217s/100 iters), loss = 0.0548172
I1203 20:15:37.467613 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:15:37.467613 21228 solver.cpp:237]     Train net output #1: loss = 0.0548172 (* 1 = 0.0548172 loss)
I1203 20:15:37.467613 21228 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1203 20:15:45.539957 21228 solver.cpp:218] Iteration 112700 (12.388 iter/s, 8.07231s/100 iters), loss = 0.0278792
I1203 20:15:45.539957 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:15:45.539957 21228 solver.cpp:237]     Train net output #1: loss = 0.0278793 (* 1 = 0.0278793 loss)
I1203 20:15:45.539957 21228 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1203 20:15:53.613050 21228 solver.cpp:218] Iteration 112800 (12.3886 iter/s, 8.07194s/100 iters), loss = 0.0220027
I1203 20:15:53.613050 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:15:53.613050 21228 solver.cpp:237]     Train net output #1: loss = 0.0220027 (* 1 = 0.0220027 loss)
I1203 20:15:53.613050 21228 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1203 20:16:01.688876 21228 solver.cpp:218] Iteration 112900 (12.3832 iter/s, 8.07543s/100 iters), loss = 0.0214953
I1203 20:16:01.688876 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:16:01.688876 21228 solver.cpp:237]     Train net output #1: loss = 0.0214953 (* 1 = 0.0214953 loss)
I1203 20:16:01.688876 21228 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1203 20:16:09.370069 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:16:09.690341 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.caffemodel
I1203 20:16:09.730360 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.solverstate
I1203 20:16:09.736356 21228 solver.cpp:330] Iteration 113000, Testing net (#0)
I1203 20:16:09.737356 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:16:11.421322 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:16:11.487967 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1203 20:16:11.487967 21228 solver.cpp:397]     Test net output #1: loss = 0.238093 (* 1 = 0.238093 loss)
I1203 20:16:11.563186 21228 solver.cpp:218] Iteration 113000 (10.1272 iter/s, 9.87435s/100 iters), loss = 0.0136283
I1203 20:16:11.563186 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:16:11.563186 21228 solver.cpp:237]     Train net output #1: loss = 0.0136283 (* 1 = 0.0136283 loss)
I1203 20:16:11.563186 21228 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1203 20:16:19.644140 21228 solver.cpp:218] Iteration 113100 (12.3759 iter/s, 8.08025s/100 iters), loss = 0.0402901
I1203 20:16:19.644140 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:16:19.644140 21228 solver.cpp:237]     Train net output #1: loss = 0.0402901 (* 1 = 0.0402901 loss)
I1203 20:16:19.644140 21228 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1203 20:16:27.719867 21228 solver.cpp:218] Iteration 113200 (12.3837 iter/s, 8.0751s/100 iters), loss = 0.0387388
I1203 20:16:27.719867 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:16:27.719867 21228 solver.cpp:237]     Train net output #1: loss = 0.0387389 (* 1 = 0.0387389 loss)
I1203 20:16:27.719867 21228 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1203 20:16:35.803601 21228 solver.cpp:218] Iteration 113300 (12.3718 iter/s, 8.08288s/100 iters), loss = 0.0320622
I1203 20:16:35.803601 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:16:35.803601 21228 solver.cpp:237]     Train net output #1: loss = 0.0320622 (* 1 = 0.0320622 loss)
I1203 20:16:35.803601 21228 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1203 20:16:43.879328 21228 solver.cpp:218] Iteration 113400 (12.3839 iter/s, 8.07502s/100 iters), loss = 0.0172031
I1203 20:16:43.879328 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:16:43.879328 21228 solver.cpp:237]     Train net output #1: loss = 0.0172032 (* 1 = 0.0172032 loss)
I1203 20:16:43.879328 21228 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1203 20:16:51.579377 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:16:51.899408 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.caffemodel
I1203 20:16:51.936413 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.solverstate
I1203 20:16:51.943411 21228 solver.cpp:330] Iteration 113500, Testing net (#0)
I1203 20:16:51.943411 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:16:53.627360 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:16:53.693366 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 20:16:53.694365 21228 solver.cpp:397]     Test net output #1: loss = 0.239574 (* 1 = 0.239574 loss)
I1203 20:16:53.767868 21228 solver.cpp:218] Iteration 113500 (10.1131 iter/s, 9.88816s/100 iters), loss = 0.0171945
I1203 20:16:53.767868 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:16:53.767868 21228 solver.cpp:237]     Train net output #1: loss = 0.0171945 (* 1 = 0.0171945 loss)
I1203 20:16:53.767868 21228 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1203 20:17:01.846170 21228 solver.cpp:218] Iteration 113600 (12.379 iter/s, 8.07818s/100 iters), loss = 0.0275841
I1203 20:17:01.846170 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:17:01.846170 21228 solver.cpp:237]     Train net output #1: loss = 0.0275841 (* 1 = 0.0275841 loss)
I1203 20:17:01.846170 21228 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1203 20:17:09.921932 21228 solver.cpp:218] Iteration 113700 (12.3835 iter/s, 8.07524s/100 iters), loss = 0.0163065
I1203 20:17:09.921932 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:17:09.921932 21228 solver.cpp:237]     Train net output #1: loss = 0.0163065 (* 1 = 0.0163065 loss)
I1203 20:17:09.921932 21228 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1203 20:17:17.993430 21228 solver.cpp:218] Iteration 113800 (12.3902 iter/s, 8.07088s/100 iters), loss = 0.014928
I1203 20:17:17.993932 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:17:17.993932 21228 solver.cpp:237]     Train net output #1: loss = 0.014928 (* 1 = 0.014928 loss)
I1203 20:17:17.993932 21228 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1203 20:17:26.065791 21228 solver.cpp:218] Iteration 113900 (12.3881 iter/s, 8.07226s/100 iters), loss = 0.0357905
I1203 20:17:26.065791 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:17:26.065791 21228 solver.cpp:237]     Train net output #1: loss = 0.0357905 (* 1 = 0.0357905 loss)
I1203 20:17:26.065791 21228 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1203 20:17:33.747578 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:17:34.068604 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.caffemodel
I1203 20:17:34.108600 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.solverstate
I1203 20:17:34.115602 21228 solver.cpp:330] Iteration 114000, Testing net (#0)
I1203 20:17:34.115602 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:17:35.799724 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:17:35.867723 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 20:17:35.867723 21228 solver.cpp:397]     Test net output #1: loss = 0.240678 (* 1 = 0.240678 loss)
I1203 20:17:35.942730 21228 solver.cpp:218] Iteration 114000 (10.1259 iter/s, 9.87568s/100 iters), loss = 0.0128332
I1203 20:17:35.942730 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:17:35.942730 21228 solver.cpp:237]     Train net output #1: loss = 0.0128332 (* 1 = 0.0128332 loss)
I1203 20:17:35.942730 21228 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1203 20:17:44.013502 21228 solver.cpp:218] Iteration 114100 (12.3914 iter/s, 8.07013s/100 iters), loss = 0.0470739
I1203 20:17:44.013502 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:17:44.013502 21228 solver.cpp:237]     Train net output #1: loss = 0.0470739 (* 1 = 0.0470739 loss)
I1203 20:17:44.013502 21228 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1203 20:17:52.081965 21228 solver.cpp:218] Iteration 114200 (12.3946 iter/s, 8.06804s/100 iters), loss = 0.0184138
I1203 20:17:52.081965 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:17:52.081965 21228 solver.cpp:237]     Train net output #1: loss = 0.0184138 (* 1 = 0.0184138 loss)
I1203 20:17:52.081965 21228 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1203 20:18:00.152254 21228 solver.cpp:218] Iteration 114300 (12.3915 iter/s, 8.07007s/100 iters), loss = 0.0169748
I1203 20:18:00.152254 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:18:00.152254 21228 solver.cpp:237]     Train net output #1: loss = 0.0169747 (* 1 = 0.0169747 loss)
I1203 20:18:00.152254 21228 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1203 20:18:08.236119 21228 solver.cpp:218] Iteration 114400 (12.3708 iter/s, 8.08355s/100 iters), loss = 0.0217496
I1203 20:18:08.236119 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:18:08.236119 21228 solver.cpp:237]     Train net output #1: loss = 0.0217496 (* 1 = 0.0217496 loss)
I1203 20:18:08.236119 21228 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1203 20:18:15.916369 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:18:16.236385 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.caffemodel
I1203 20:18:16.276393 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.solverstate
I1203 20:18:16.283393 21228 solver.cpp:330] Iteration 114500, Testing net (#0)
I1203 20:18:16.283393 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:18:17.969525 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:18:18.035528 21228 solver.cpp:397]     Test net output #0: accuracy = 0.936
I1203 20:18:18.035528 21228 solver.cpp:397]     Test net output #1: loss = 0.237644 (* 1 = 0.237644 loss)
I1203 20:18:18.110536 21228 solver.cpp:218] Iteration 114500 (10.1278 iter/s, 9.87382s/100 iters), loss = 0.0151498
I1203 20:18:18.110536 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:18:18.110536 21228 solver.cpp:237]     Train net output #1: loss = 0.0151497 (* 1 = 0.0151497 loss)
I1203 20:18:18.110536 21228 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1203 20:18:26.196369 21228 solver.cpp:218] Iteration 114600 (12.368 iter/s, 8.0854s/100 iters), loss = 0.0172748
I1203 20:18:26.196369 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:18:26.196369 21228 solver.cpp:237]     Train net output #1: loss = 0.0172748 (* 1 = 0.0172748 loss)
I1203 20:18:26.196369 21228 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1203 20:18:34.276168 21228 solver.cpp:218] Iteration 114700 (12.3774 iter/s, 8.07921s/100 iters), loss = 0.0175986
I1203 20:18:34.276168 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:18:34.276168 21228 solver.cpp:237]     Train net output #1: loss = 0.0175986 (* 1 = 0.0175986 loss)
I1203 20:18:34.276168 21228 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1203 20:18:42.355804 21228 solver.cpp:218] Iteration 114800 (12.3783 iter/s, 8.07866s/100 iters), loss = 0.0171866
I1203 20:18:42.355804 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:18:42.355804 21228 solver.cpp:237]     Train net output #1: loss = 0.0171866 (* 1 = 0.0171866 loss)
I1203 20:18:42.355804 21228 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1203 20:18:50.429034 21228 solver.cpp:218] Iteration 114900 (12.387 iter/s, 8.073s/100 iters), loss = 0.0493393
I1203 20:18:50.429034 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:18:50.429034 21228 solver.cpp:237]     Train net output #1: loss = 0.0493393 (* 1 = 0.0493393 loss)
I1203 20:18:50.429034 21228 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1203 20:18:58.119176 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:18:58.437209 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.caffemodel
I1203 20:18:58.477231 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.solverstate
I1203 20:18:58.483232 21228 solver.cpp:330] Iteration 115000, Testing net (#0)
I1203 20:18:58.483232 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:19:00.168586 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:19:00.235585 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9358
I1203 20:19:00.235585 21228 solver.cpp:397]     Test net output #1: loss = 0.242027 (* 1 = 0.242027 loss)
I1203 20:19:00.311597 21228 solver.cpp:218] Iteration 115000 (10.1196 iter/s, 9.88179s/100 iters), loss = 0.0299595
I1203 20:19:00.311597 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:19:00.311597 21228 solver.cpp:237]     Train net output #1: loss = 0.0299595 (* 1 = 0.0299595 loss)
I1203 20:19:00.311597 21228 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1203 20:19:08.393414 21228 solver.cpp:218] Iteration 115100 (12.3731 iter/s, 8.08205s/100 iters), loss = 0.0231758
I1203 20:19:08.394414 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:19:08.394414 21228 solver.cpp:237]     Train net output #1: loss = 0.0231758 (* 1 = 0.0231758 loss)
I1203 20:19:08.394414 21228 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1203 20:19:16.479228 21228 solver.cpp:218] Iteration 115200 (12.3695 iter/s, 8.08439s/100 iters), loss = 0.0261424
I1203 20:19:16.479228 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:19:16.479228 21228 solver.cpp:237]     Train net output #1: loss = 0.0261424 (* 1 = 0.0261424 loss)
I1203 20:19:16.479228 21228 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1203 20:19:24.578065 21228 solver.cpp:218] Iteration 115300 (12.3478 iter/s, 8.09863s/100 iters), loss = 0.0129842
I1203 20:19:24.578065 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:19:24.578065 21228 solver.cpp:237]     Train net output #1: loss = 0.0129842 (* 1 = 0.0129842 loss)
I1203 20:19:24.578065 21228 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1203 20:19:32.666867 21228 solver.cpp:218] Iteration 115400 (12.3628 iter/s, 8.08881s/100 iters), loss = 0.0108264
I1203 20:19:32.666867 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:19:32.666867 21228 solver.cpp:237]     Train net output #1: loss = 0.0108264 (* 1 = 0.0108264 loss)
I1203 20:19:32.666867 21228 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1203 20:19:40.362615 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:19:40.681635 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.caffemodel
I1203 20:19:40.721635 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.solverstate
I1203 20:19:40.727636 21228 solver.cpp:330] Iteration 115500, Testing net (#0)
I1203 20:19:40.728636 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:19:42.413779 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:19:42.480792 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9361
I1203 20:19:42.480792 21228 solver.cpp:397]     Test net output #1: loss = 0.23574 (* 1 = 0.23574 loss)
I1203 20:19:42.556805 21228 solver.cpp:218] Iteration 115500 (10.1123 iter/s, 9.88891s/100 iters), loss = 0.0185598
I1203 20:19:42.556805 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:19:42.556805 21228 solver.cpp:237]     Train net output #1: loss = 0.0185598 (* 1 = 0.0185598 loss)
I1203 20:19:42.556805 21228 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1203 20:19:50.633630 21228 solver.cpp:218] Iteration 115600 (12.3817 iter/s, 8.07641s/100 iters), loss = 0.0288474
I1203 20:19:50.633630 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:19:50.633630 21228 solver.cpp:237]     Train net output #1: loss = 0.0288474 (* 1 = 0.0288474 loss)
I1203 20:19:50.633630 21228 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1203 20:19:58.706499 21228 solver.cpp:218] Iteration 115700 (12.3878 iter/s, 8.07248s/100 iters), loss = 0.0137684
I1203 20:19:58.706499 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:19:58.706499 21228 solver.cpp:237]     Train net output #1: loss = 0.0137684 (* 1 = 0.0137684 loss)
I1203 20:19:58.706499 21228 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1203 20:20:06.830657 21228 solver.cpp:218] Iteration 115800 (12.3099 iter/s, 8.12353s/100 iters), loss = 0.0628208
I1203 20:20:06.830657 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:20:06.830657 21228 solver.cpp:237]     Train net output #1: loss = 0.0628208 (* 1 = 0.0628208 loss)
I1203 20:20:06.830657 21228 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1203 20:20:14.894403 21228 solver.cpp:218] Iteration 115900 (12.4024 iter/s, 8.06293s/100 iters), loss = 0.0121585
I1203 20:20:14.894403 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:20:14.894403 21228 solver.cpp:237]     Train net output #1: loss = 0.0121584 (* 1 = 0.0121584 loss)
I1203 20:20:14.894403 21228 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1203 20:20:22.554106 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:20:22.873126 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.caffemodel
I1203 20:20:22.913130 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.solverstate
I1203 20:20:22.920130 21228 solver.cpp:330] Iteration 116000, Testing net (#0)
I1203 20:20:22.920130 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:20:24.602262 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:20:24.669263 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1203 20:20:24.669263 21228 solver.cpp:397]     Test net output #1: loss = 0.241538 (* 1 = 0.241538 loss)
I1203 20:20:24.743276 21228 solver.cpp:218] Iteration 116000 (10.1533 iter/s, 9.84904s/100 iters), loss = 0.0192193
I1203 20:20:24.743276 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:20:24.743276 21228 solver.cpp:237]     Train net output #1: loss = 0.0192193 (* 1 = 0.0192193 loss)
I1203 20:20:24.743276 21228 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1203 20:20:32.802026 21228 solver.cpp:218] Iteration 116100 (12.41 iter/s, 8.05799s/100 iters), loss = 0.0253592
I1203 20:20:32.802026 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:20:32.802026 21228 solver.cpp:237]     Train net output #1: loss = 0.0253592 (* 1 = 0.0253592 loss)
I1203 20:20:32.802026 21228 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1203 20:20:40.864796 21228 solver.cpp:218] Iteration 116200 (12.4041 iter/s, 8.06184s/100 iters), loss = 0.0163024
I1203 20:20:40.864796 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:20:40.864796 21228 solver.cpp:237]     Train net output #1: loss = 0.0163023 (* 1 = 0.0163023 loss)
I1203 20:20:40.864796 21228 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1203 20:20:48.913619 21228 solver.cpp:218] Iteration 116300 (12.4235 iter/s, 8.04925s/100 iters), loss = 0.00911023
I1203 20:20:48.913619 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:20:48.914620 21228 solver.cpp:237]     Train net output #1: loss = 0.0091102 (* 1 = 0.0091102 loss)
I1203 20:20:48.914620 21228 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1203 20:20:56.976059 21228 solver.cpp:218] Iteration 116400 (12.4049 iter/s, 8.06132s/100 iters), loss = 0.0151154
I1203 20:20:56.976059 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:20:56.976059 21228 solver.cpp:237]     Train net output #1: loss = 0.0151154 (* 1 = 0.0151154 loss)
I1203 20:20:56.976059 21228 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1203 20:21:04.647574 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:21:04.965593 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.caffemodel
I1203 20:21:05.005596 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.solverstate
I1203 20:21:05.012097 21228 solver.cpp:330] Iteration 116500, Testing net (#0)
I1203 20:21:05.012097 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:21:06.694725 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:21:06.761729 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 20:21:06.761729 21228 solver.cpp:397]     Test net output #1: loss = 0.240477 (* 1 = 0.240477 loss)
I1203 20:21:06.837749 21228 solver.cpp:218] Iteration 116500 (10.1411 iter/s, 9.86086s/100 iters), loss = 0.0178928
I1203 20:21:06.837749 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:21:06.837749 21228 solver.cpp:237]     Train net output #1: loss = 0.0178927 (* 1 = 0.0178927 loss)
I1203 20:21:06.837749 21228 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1203 20:21:14.900528 21228 solver.cpp:218] Iteration 116600 (12.4035 iter/s, 8.06222s/100 iters), loss = 0.0176906
I1203 20:21:14.900528 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:21:14.900528 21228 solver.cpp:237]     Train net output #1: loss = 0.0176906 (* 1 = 0.0176906 loss)
I1203 20:21:14.900528 21228 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1203 20:21:22.981283 21228 solver.cpp:218] Iteration 116700 (12.3758 iter/s, 8.08026s/100 iters), loss = 0.0123245
I1203 20:21:22.981283 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:21:22.981283 21228 solver.cpp:237]     Train net output #1: loss = 0.0123245 (* 1 = 0.0123245 loss)
I1203 20:21:22.981283 21228 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1203 20:21:31.048421 21228 solver.cpp:218] Iteration 116800 (12.3968 iter/s, 8.0666s/100 iters), loss = 0.0182175
I1203 20:21:31.048421 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:21:31.048421 21228 solver.cpp:237]     Train net output #1: loss = 0.0182175 (* 1 = 0.0182175 loss)
I1203 20:21:31.048421 21228 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1203 20:21:39.113157 21228 solver.cpp:218] Iteration 116900 (12.3996 iter/s, 8.06475s/100 iters), loss = 0.0188253
I1203 20:21:39.113157 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:21:39.113157 21228 solver.cpp:237]     Train net output #1: loss = 0.0188253 (* 1 = 0.0188253 loss)
I1203 20:21:39.113157 21228 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1203 20:21:46.775544 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:21:47.096117 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.caffemodel
I1203 20:21:47.135706 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.solverstate
I1203 20:21:47.142705 21228 solver.cpp:330] Iteration 117000, Testing net (#0)
I1203 20:21:47.142705 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:21:48.825554 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:21:48.891554 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1203 20:21:48.892555 21228 solver.cpp:397]     Test net output #1: loss = 0.23987 (* 1 = 0.23987 loss)
I1203 20:21:48.967005 21228 solver.cpp:218] Iteration 117000 (10.1494 iter/s, 9.8528s/100 iters), loss = 0.0146539
I1203 20:21:48.967005 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:21:48.967005 21228 solver.cpp:237]     Train net output #1: loss = 0.0146539 (* 1 = 0.0146539 loss)
I1203 20:21:48.967005 21228 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1203 20:21:57.034234 21228 solver.cpp:218] Iteration 117100 (12.3973 iter/s, 8.0663s/100 iters), loss = 0.0243903
I1203 20:21:57.034234 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:21:57.034234 21228 solver.cpp:237]     Train net output #1: loss = 0.0243903 (* 1 = 0.0243903 loss)
I1203 20:21:57.034234 21228 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1203 20:22:05.094193 21228 solver.cpp:218] Iteration 117200 (12.4063 iter/s, 8.06043s/100 iters), loss = 0.0253405
I1203 20:22:05.095193 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:22:05.095193 21228 solver.cpp:237]     Train net output #1: loss = 0.0253405 (* 1 = 0.0253405 loss)
I1203 20:22:05.095193 21228 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1203 20:22:13.161419 21228 solver.cpp:218] Iteration 117300 (12.398 iter/s, 8.06585s/100 iters), loss = 0.0151066
I1203 20:22:13.161419 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:22:13.161419 21228 solver.cpp:237]     Train net output #1: loss = 0.0151066 (* 1 = 0.0151066 loss)
I1203 20:22:13.161419 21228 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1203 20:22:21.223147 21228 solver.cpp:218] Iteration 117400 (12.4041 iter/s, 8.06187s/100 iters), loss = 0.0105605
I1203 20:22:21.223147 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:22:21.223147 21228 solver.cpp:237]     Train net output #1: loss = 0.0105605 (* 1 = 0.0105605 loss)
I1203 20:22:21.223147 21228 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1203 20:22:28.890108 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:22:29.210129 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.caffemodel
I1203 20:22:29.249128 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.solverstate
I1203 20:22:29.257638 21228 solver.cpp:330] Iteration 117500, Testing net (#0)
I1203 20:22:29.257638 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:22:30.940263 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:22:31.006264 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9361
I1203 20:22:31.006264 21228 solver.cpp:397]     Test net output #1: loss = 0.238882 (* 1 = 0.238882 loss)
I1203 20:22:31.082270 21228 solver.cpp:218] Iteration 117500 (10.1434 iter/s, 9.85861s/100 iters), loss = 0.0263804
I1203 20:22:31.082270 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:22:31.082270 21228 solver.cpp:237]     Train net output #1: loss = 0.0263804 (* 1 = 0.0263804 loss)
I1203 20:22:31.082270 21228 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1203 20:22:39.140002 21228 solver.cpp:218] Iteration 117600 (12.4111 iter/s, 8.05729s/100 iters), loss = 0.0386077
I1203 20:22:39.140002 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:22:39.140002 21228 solver.cpp:237]     Train net output #1: loss = 0.0386077 (* 1 = 0.0386077 loss)
I1203 20:22:39.140002 21228 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1203 20:22:47.205945 21228 solver.cpp:218] Iteration 117700 (12.3994 iter/s, 8.0649s/100 iters), loss = 0.0190636
I1203 20:22:47.205945 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:22:47.205945 21228 solver.cpp:237]     Train net output #1: loss = 0.0190635 (* 1 = 0.0190635 loss)
I1203 20:22:47.205945 21228 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1203 20:22:55.263725 21228 solver.cpp:218] Iteration 117800 (12.4111 iter/s, 8.05733s/100 iters), loss = 0.0195712
I1203 20:22:55.263725 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:22:55.263725 21228 solver.cpp:237]     Train net output #1: loss = 0.0195712 (* 1 = 0.0195712 loss)
I1203 20:22:55.263725 21228 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1203 20:23:03.331418 21228 solver.cpp:218] Iteration 117900 (12.3964 iter/s, 8.06688s/100 iters), loss = 0.0107147
I1203 20:23:03.331418 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:23:03.331418 21228 solver.cpp:237]     Train net output #1: loss = 0.0107147 (* 1 = 0.0107147 loss)
I1203 20:23:03.331418 21228 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1203 20:23:11.006428 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:23:11.328614 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.caffemodel
I1203 20:23:11.367615 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.solverstate
I1203 20:23:11.373610 21228 solver.cpp:330] Iteration 118000, Testing net (#0)
I1203 20:23:11.373610 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:23:13.056701 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:23:13.124732 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1203 20:23:13.124732 21228 solver.cpp:397]     Test net output #1: loss = 0.23845 (* 1 = 0.23845 loss)
I1203 20:23:13.198734 21228 solver.cpp:218] Iteration 118000 (10.1348 iter/s, 9.86697s/100 iters), loss = 0.0216256
I1203 20:23:13.198734 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:23:13.198734 21228 solver.cpp:237]     Train net output #1: loss = 0.0216256 (* 1 = 0.0216256 loss)
I1203 20:23:13.198734 21228 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1203 20:23:21.253036 21228 solver.cpp:218] Iteration 118100 (12.4158 iter/s, 8.05426s/100 iters), loss = 0.0134326
I1203 20:23:21.253036 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:23:21.253036 21228 solver.cpp:237]     Train net output #1: loss = 0.0134326 (* 1 = 0.0134326 loss)
I1203 20:23:21.253036 21228 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1203 20:23:29.312717 21228 solver.cpp:218] Iteration 118200 (12.4084 iter/s, 8.05909s/100 iters), loss = 0.029551
I1203 20:23:29.312717 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:23:29.312717 21228 solver.cpp:237]     Train net output #1: loss = 0.029551 (* 1 = 0.029551 loss)
I1203 20:23:29.312717 21228 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1203 20:23:37.369542 21228 solver.cpp:218] Iteration 118300 (12.4133 iter/s, 8.05586s/100 iters), loss = 0.015524
I1203 20:23:37.369542 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:23:37.369542 21228 solver.cpp:237]     Train net output #1: loss = 0.0155239 (* 1 = 0.0155239 loss)
I1203 20:23:37.369542 21228 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1203 20:23:45.429246 21228 solver.cpp:218] Iteration 118400 (12.4073 iter/s, 8.05979s/100 iters), loss = 0.0123065
I1203 20:23:45.429246 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:23:45.429246 21228 solver.cpp:237]     Train net output #1: loss = 0.0123065 (* 1 = 0.0123065 loss)
I1203 20:23:45.429246 21228 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1203 20:23:53.100343 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:23:53.418370 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.caffemodel
I1203 20:23:53.459372 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.solverstate
I1203 20:23:53.466373 21228 solver.cpp:330] Iteration 118500, Testing net (#0)
I1203 20:23:53.466373 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:23:55.151492 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:23:55.218497 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1203 20:23:55.218497 21228 solver.cpp:397]     Test net output #1: loss = 0.238696 (* 1 = 0.238696 loss)
I1203 20:23:55.292505 21228 solver.cpp:218] Iteration 118500 (10.1395 iter/s, 9.86245s/100 iters), loss = 0.0139696
I1203 20:23:55.292505 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:23:55.292505 21228 solver.cpp:237]     Train net output #1: loss = 0.0139696 (* 1 = 0.0139696 loss)
I1203 20:23:55.292505 21228 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1203 20:24:03.388137 21228 solver.cpp:218] Iteration 118600 (12.3536 iter/s, 8.0948s/100 iters), loss = 0.0218821
I1203 20:24:03.388638 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:03.388638 21228 solver.cpp:237]     Train net output #1: loss = 0.021882 (* 1 = 0.021882 loss)
I1203 20:24:03.388638 21228 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1203 20:24:11.569227 21228 solver.cpp:218] Iteration 118700 (12.2243 iter/s, 8.18041s/100 iters), loss = 0.0196528
I1203 20:24:11.569227 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:11.569227 21228 solver.cpp:237]     Train net output #1: loss = 0.0196527 (* 1 = 0.0196527 loss)
I1203 20:24:11.569227 21228 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1203 20:24:19.780442 21228 solver.cpp:218] Iteration 118800 (12.1789 iter/s, 8.21091s/100 iters), loss = 0.0120455
I1203 20:24:19.780442 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:19.780442 21228 solver.cpp:237]     Train net output #1: loss = 0.0120455 (* 1 = 0.0120455 loss)
I1203 20:24:19.780442 21228 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1203 20:24:28.052827 21228 solver.cpp:218] Iteration 118900 (12.0893 iter/s, 8.2718s/100 iters), loss = 0.0136863
I1203 20:24:28.052827 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:28.052827 21228 solver.cpp:237]     Train net output #1: loss = 0.0136863 (* 1 = 0.0136863 loss)
I1203 20:24:28.052827 21228 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1203 20:24:35.920143 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:24:36.248164 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.caffemodel
I1203 20:24:36.290169 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.solverstate
I1203 20:24:36.297168 21228 solver.cpp:330] Iteration 119000, Testing net (#0)
I1203 20:24:36.297168 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:24:37.997663 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:24:38.064167 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9363
I1203 20:24:38.064167 21228 solver.cpp:397]     Test net output #1: loss = 0.237057 (* 1 = 0.237057 loss)
I1203 20:24:38.140177 21228 solver.cpp:218] Iteration 119000 (9.91451 iter/s, 10.0862s/100 iters), loss = 0.0186581
I1203 20:24:38.140177 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:38.140177 21228 solver.cpp:237]     Train net output #1: loss = 0.018658 (* 1 = 0.018658 loss)
I1203 20:24:38.140177 21228 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1203 20:24:46.376329 21228 solver.cpp:218] Iteration 119100 (12.1417 iter/s, 8.23608s/100 iters), loss = 0.0213943
I1203 20:24:46.376329 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:46.376329 21228 solver.cpp:237]     Train net output #1: loss = 0.0213943 (* 1 = 0.0213943 loss)
I1203 20:24:46.376329 21228 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1203 20:24:54.628574 21228 solver.cpp:218] Iteration 119200 (12.1193 iter/s, 8.2513s/100 iters), loss = 0.023363
I1203 20:24:54.628574 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:24:54.628574 21228 solver.cpp:237]     Train net output #1: loss = 0.0233629 (* 1 = 0.0233629 loss)
I1203 20:24:54.628574 21228 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1203 20:25:02.877012 21228 solver.cpp:218] Iteration 119300 (12.1247 iter/s, 8.24762s/100 iters), loss = 0.0105094
I1203 20:25:02.877012 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:25:02.877012 21228 solver.cpp:237]     Train net output #1: loss = 0.0105093 (* 1 = 0.0105093 loss)
I1203 20:25:02.877012 21228 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1203 20:25:11.201776 21228 solver.cpp:218] Iteration 119400 (12.0129 iter/s, 8.32442s/100 iters), loss = 0.0152118
I1203 20:25:11.201776 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:25:11.201776 21228 solver.cpp:237]     Train net output #1: loss = 0.0152118 (* 1 = 0.0152118 loss)
I1203 20:25:11.201776 21228 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1203 20:25:19.144717 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:25:19.475718 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.caffemodel
I1203 20:25:19.505717 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.solverstate
I1203 20:25:19.512226 21228 solver.cpp:330] Iteration 119500, Testing net (#0)
I1203 20:25:19.512226 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:25:21.237718 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:25:21.306216 21228 solver.cpp:397]     Test net output #0: accuracy = 0.936
I1203 20:25:21.306216 21228 solver.cpp:397]     Test net output #1: loss = 0.240848 (* 1 = 0.240848 loss)
I1203 20:25:21.384294 21228 solver.cpp:218] Iteration 119500 (9.82238 iter/s, 10.1808s/100 iters), loss = 0.0142369
I1203 20:25:21.384798 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:25:21.384798 21228 solver.cpp:237]     Train net output #1: loss = 0.0142368 (* 1 = 0.0142368 loss)
I1203 20:25:21.384798 21228 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1203 20:25:29.749001 21228 solver.cpp:218] Iteration 119600 (11.9566 iter/s, 8.36356s/100 iters), loss = 0.0183755
I1203 20:25:29.749001 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:25:29.749001 21228 solver.cpp:237]     Train net output #1: loss = 0.0183755 (* 1 = 0.0183755 loss)
I1203 20:25:29.749001 21228 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1203 20:25:38.108228 21228 solver.cpp:218] Iteration 119700 (11.9631 iter/s, 8.35902s/100 iters), loss = 0.0183957
I1203 20:25:38.108728 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:25:38.108728 21228 solver.cpp:237]     Train net output #1: loss = 0.0183957 (* 1 = 0.0183957 loss)
I1203 20:25:38.108728 21228 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1203 20:25:46.442165 21228 solver.cpp:218] Iteration 119800 (12.0002 iter/s, 8.33321s/100 iters), loss = 0.0102107
I1203 20:25:46.442165 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:25:46.442165 21228 solver.cpp:237]     Train net output #1: loss = 0.0102106 (* 1 = 0.0102106 loss)
I1203 20:25:46.442165 21228 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1203 20:25:54.776510 21228 solver.cpp:218] Iteration 119900 (11.9994 iter/s, 8.33374s/100 iters), loss = 0.0227594
I1203 20:25:54.776510 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:25:54.776510 21228 solver.cpp:237]     Train net output #1: loss = 0.0227593 (* 1 = 0.0227593 loss)
I1203 20:25:54.776510 21228 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1203 20:26:02.637583 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:26:02.965081 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.caffemodel
I1203 20:26:03.009081 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.solverstate
I1203 20:26:03.015583 21228 solver.cpp:330] Iteration 120000, Testing net (#0)
I1203 20:26:03.015583 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:26:04.725082 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:26:04.794081 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1203 20:26:04.794081 21228 solver.cpp:397]     Test net output #1: loss = 0.242749 (* 1 = 0.242749 loss)
I1203 20:26:04.870581 21228 solver.cpp:218] Iteration 120000 (9.90735 iter/s, 10.0935s/100 iters), loss = 0.0289878
I1203 20:26:04.870581 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:26:04.870581 21228 solver.cpp:237]     Train net output #1: loss = 0.0289878 (* 1 = 0.0289878 loss)
I1203 20:26:04.870581 21228 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1203 20:26:13.106581 21228 solver.cpp:218] Iteration 120100 (12.1424 iter/s, 8.23559s/100 iters), loss = 0.023421
I1203 20:26:13.106581 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:26:13.106581 21228 solver.cpp:237]     Train net output #1: loss = 0.0234209 (* 1 = 0.0234209 loss)
I1203 20:26:13.106581 21228 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1203 20:26:21.362440 21228 solver.cpp:218] Iteration 120200 (12.1133 iter/s, 8.25536s/100 iters), loss = 0.014988
I1203 20:26:21.362440 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:26:21.362440 21228 solver.cpp:237]     Train net output #1: loss = 0.014988 (* 1 = 0.014988 loss)
I1203 20:26:21.362440 21228 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1203 20:26:29.616032 21228 solver.cpp:218] Iteration 120300 (12.1161 iter/s, 8.25348s/100 iters), loss = 0.0107542
I1203 20:26:29.616032 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:26:29.616032 21228 solver.cpp:237]     Train net output #1: loss = 0.0107541 (* 1 = 0.0107541 loss)
I1203 20:26:29.616032 21228 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1203 20:26:37.931255 21228 solver.cpp:218] Iteration 120400 (12.0279 iter/s, 8.314s/100 iters), loss = 0.0127491
I1203 20:26:37.931255 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:26:37.931255 21228 solver.cpp:237]     Train net output #1: loss = 0.0127491 (* 1 = 0.0127491 loss)
I1203 20:26:37.931255 21228 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1203 20:26:45.867969 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:26:46.195508 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.caffemodel
I1203 20:26:46.238507 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.solverstate
I1203 20:26:46.245508 21228 solver.cpp:330] Iteration 120500, Testing net (#0)
I1203 20:26:46.245508 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:26:47.966182 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:26:48.035686 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1203 20:26:48.035686 21228 solver.cpp:397]     Test net output #1: loss = 0.240756 (* 1 = 0.240756 loss)
I1203 20:26:48.112694 21228 solver.cpp:218] Iteration 120500 (9.82208 iter/s, 10.1811s/100 iters), loss = 0.0147081
I1203 20:26:48.112694 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:26:48.112694 21228 solver.cpp:237]     Train net output #1: loss = 0.014708 (* 1 = 0.014708 loss)
I1203 20:26:48.112694 21228 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1203 20:26:56.373632 21228 solver.cpp:218] Iteration 120600 (12.1061 iter/s, 8.26028s/100 iters), loss = 0.0223131
I1203 20:26:56.373632 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:26:56.373632 21228 solver.cpp:237]     Train net output #1: loss = 0.0223131 (* 1 = 0.0223131 loss)
I1203 20:26:56.373632 21228 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1203 20:27:04.725078 21228 solver.cpp:218] Iteration 120700 (11.9752 iter/s, 8.35057s/100 iters), loss = 0.0200439
I1203 20:27:04.725078 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:27:04.725078 21228 solver.cpp:237]     Train net output #1: loss = 0.0200439 (* 1 = 0.0200439 loss)
I1203 20:27:04.725078 21228 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1203 20:27:13.175654 21228 solver.cpp:218] Iteration 120800 (11.8339 iter/s, 8.45029s/100 iters), loss = 0.0129528
I1203 20:27:13.175654 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:27:13.175654 21228 solver.cpp:237]     Train net output #1: loss = 0.0129528 (* 1 = 0.0129528 loss)
I1203 20:27:13.175654 21228 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1203 20:27:21.537139 21228 solver.cpp:218] Iteration 120900 (11.9608 iter/s, 8.36063s/100 iters), loss = 0.0161064
I1203 20:27:21.537139 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:27:21.537139 21228 solver.cpp:237]     Train net output #1: loss = 0.0161064 (* 1 = 0.0161064 loss)
I1203 20:27:21.537139 21228 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1203 20:27:29.462152 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:27:29.792146 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.caffemodel
I1203 20:27:29.821131 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.solverstate
I1203 20:27:29.827632 21228 solver.cpp:330] Iteration 121000, Testing net (#0)
I1203 20:27:29.827632 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:27:31.551635 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:27:31.620136 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1203 20:27:31.620136 21228 solver.cpp:397]     Test net output #1: loss = 0.241962 (* 1 = 0.241962 loss)
I1203 20:27:31.697643 21228 solver.cpp:218] Iteration 121000 (9.84244 iter/s, 10.1601s/100 iters), loss = 0.0246737
I1203 20:27:31.697643 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:27:31.697643 21228 solver.cpp:237]     Train net output #1: loss = 0.0246737 (* 1 = 0.0246737 loss)
I1203 20:27:31.697643 21228 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1203 20:27:40.032084 21228 solver.cpp:218] Iteration 121100 (11.9995 iter/s, 8.3337s/100 iters), loss = 0.018599
I1203 20:27:40.032084 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:27:40.032084 21228 solver.cpp:237]     Train net output #1: loss = 0.018599 (* 1 = 0.018599 loss)
I1203 20:27:40.032084 21228 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1203 20:27:48.378526 21228 solver.cpp:218] Iteration 121200 (11.9815 iter/s, 8.34623s/100 iters), loss = 0.0216875
I1203 20:27:48.378526 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:27:48.378526 21228 solver.cpp:237]     Train net output #1: loss = 0.0216875 (* 1 = 0.0216875 loss)
I1203 20:27:48.378526 21228 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1203 20:27:56.711666 21228 solver.cpp:218] Iteration 121300 (12.0011 iter/s, 8.33255s/100 iters), loss = 0.0104248
I1203 20:27:56.711666 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:27:56.711666 21228 solver.cpp:237]     Train net output #1: loss = 0.0104248 (* 1 = 0.0104248 loss)
I1203 20:27:56.711666 21228 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1203 20:28:05.055222 21228 solver.cpp:218] Iteration 121400 (11.9863 iter/s, 8.34284s/100 iters), loss = 0.0121362
I1203 20:28:05.055222 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:28:05.055222 21228 solver.cpp:237]     Train net output #1: loss = 0.0121361 (* 1 = 0.0121361 loss)
I1203 20:28:05.055222 21228 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1203 20:28:12.995012 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:28:13.327013 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.caffemodel
I1203 20:28:13.367013 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.solverstate
I1203 20:28:13.374013 21228 solver.cpp:330] Iteration 121500, Testing net (#0)
I1203 20:28:13.374013 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:28:15.092511 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:28:15.161512 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1203 20:28:15.161512 21228 solver.cpp:397]     Test net output #1: loss = 0.243475 (* 1 = 0.243475 loss)
I1203 20:28:15.239012 21228 solver.cpp:218] Iteration 121500 (9.81979 iter/s, 10.1835s/100 iters), loss = 0.0344193
I1203 20:28:15.239012 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:28:15.239511 21228 solver.cpp:237]     Train net output #1: loss = 0.0344193 (* 1 = 0.0344193 loss)
I1203 20:28:15.239511 21228 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1203 20:28:23.718192 21228 solver.cpp:218] Iteration 121600 (11.7947 iter/s, 8.47842s/100 iters), loss = 0.0203878
I1203 20:28:23.718192 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:28:23.718192 21228 solver.cpp:237]     Train net output #1: loss = 0.0203878 (* 1 = 0.0203878 loss)
I1203 20:28:23.718192 21228 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1203 20:28:32.128654 21228 solver.cpp:218] Iteration 121700 (11.891 iter/s, 8.40971s/100 iters), loss = 0.0178968
I1203 20:28:32.128654 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:28:32.128654 21228 solver.cpp:237]     Train net output #1: loss = 0.0178968 (* 1 = 0.0178968 loss)
I1203 20:28:32.128654 21228 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1203 20:28:40.621153 21228 solver.cpp:218] Iteration 121800 (11.7754 iter/s, 8.49227s/100 iters), loss = 0.0164283
I1203 20:28:40.621153 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:28:40.621153 21228 solver.cpp:237]     Train net output #1: loss = 0.0164283 (* 1 = 0.0164283 loss)
I1203 20:28:40.621153 21228 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1203 20:28:49.120327 21228 solver.cpp:218] Iteration 121900 (11.767 iter/s, 8.49831s/100 iters), loss = 0.0121463
I1203 20:28:49.120327 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:28:49.120327 21228 solver.cpp:237]     Train net output #1: loss = 0.0121463 (* 1 = 0.0121463 loss)
I1203 20:28:49.120327 21228 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1203 20:28:57.266794 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:28:57.600795 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.caffemodel
I1203 20:28:57.645793 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.solverstate
I1203 20:28:57.652293 21228 solver.cpp:330] Iteration 122000, Testing net (#0)
I1203 20:28:57.652293 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:28:59.379294 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:28:59.449795 21228 solver.cpp:397]     Test net output #0: accuracy = 0.936
I1203 20:28:59.449795 21228 solver.cpp:397]     Test net output #1: loss = 0.237136 (* 1 = 0.237136 loss)
I1203 20:28:59.528293 21228 solver.cpp:218] Iteration 122000 (9.60854 iter/s, 10.4074s/100 iters), loss = 0.016581
I1203 20:28:59.528293 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:28:59.528293 21228 solver.cpp:237]     Train net output #1: loss = 0.016581 (* 1 = 0.016581 loss)
I1203 20:28:59.528293 21228 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1203 20:29:07.921849 21228 solver.cpp:218] Iteration 122100 (11.9141 iter/s, 8.3934s/100 iters), loss = 0.0254666
I1203 20:29:07.921849 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:07.921849 21228 solver.cpp:237]     Train net output #1: loss = 0.0254666 (* 1 = 0.0254666 loss)
I1203 20:29:07.921849 21228 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1203 20:29:16.306044 21228 solver.cpp:218] Iteration 122200 (11.9284 iter/s, 8.38333s/100 iters), loss = 0.0141593
I1203 20:29:16.306044 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:16.306044 21228 solver.cpp:237]     Train net output #1: loss = 0.0141592 (* 1 = 0.0141592 loss)
I1203 20:29:16.306044 21228 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1203 20:29:24.670286 21228 solver.cpp:218] Iteration 122300 (11.9564 iter/s, 8.36372s/100 iters), loss = 0.0134581
I1203 20:29:24.670286 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:24.670286 21228 solver.cpp:237]     Train net output #1: loss = 0.0134581 (* 1 = 0.0134581 loss)
I1203 20:29:24.670286 21228 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1203 20:29:33.026208 21228 solver.cpp:218] Iteration 122400 (11.9686 iter/s, 8.3552s/100 iters), loss = 0.0151163
I1203 20:29:33.026208 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:33.026208 21228 solver.cpp:237]     Train net output #1: loss = 0.0151162 (* 1 = 0.0151162 loss)
I1203 20:29:33.026208 21228 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1203 20:29:40.997018 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:29:41.328021 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.caffemodel
I1203 20:29:41.360519 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.solverstate
I1203 20:29:41.367038 21228 solver.cpp:330] Iteration 122500, Testing net (#0)
I1203 20:29:41.367519 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:29:43.093017 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:29:43.162037 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1203 20:29:43.162037 21228 solver.cpp:397]     Test net output #1: loss = 0.243602 (* 1 = 0.243602 loss)
I1203 20:29:43.238538 21228 solver.cpp:218] Iteration 122500 (9.79238 iter/s, 10.212s/100 iters), loss = 0.0208079
I1203 20:29:43.238538 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:43.238538 21228 solver.cpp:237]     Train net output #1: loss = 0.0208079 (* 1 = 0.0208079 loss)
I1203 20:29:43.238538 21228 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1203 20:29:51.577553 21228 solver.cpp:218] Iteration 122600 (11.9931 iter/s, 8.33815s/100 iters), loss = 0.0164606
I1203 20:29:51.577553 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:51.577553 21228 solver.cpp:237]     Train net output #1: loss = 0.0164605 (* 1 = 0.0164605 loss)
I1203 20:29:51.577553 21228 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1203 20:29:59.912051 21228 solver.cpp:218] Iteration 122700 (11.999 iter/s, 8.33402s/100 iters), loss = 0.0144781
I1203 20:29:59.912051 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:29:59.912051 21228 solver.cpp:237]     Train net output #1: loss = 0.014478 (* 1 = 0.014478 loss)
I1203 20:29:59.912051 21228 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1203 20:30:08.216722 21228 solver.cpp:218] Iteration 122800 (12.0421 iter/s, 8.30423s/100 iters), loss = 0.00951596
I1203 20:30:08.216722 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:30:08.216722 21228 solver.cpp:237]     Train net output #1: loss = 0.00951591 (* 1 = 0.00951591 loss)
I1203 20:30:08.216722 21228 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1203 20:30:16.569862 21228 solver.cpp:218] Iteration 122900 (11.9723 iter/s, 8.35258s/100 iters), loss = 0.0122965
I1203 20:30:16.569862 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:30:16.569862 21228 solver.cpp:237]     Train net output #1: loss = 0.0122964 (* 1 = 0.0122964 loss)
I1203 20:30:16.569862 21228 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1203 20:30:24.481441 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:30:24.813460 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.caffemodel
I1203 20:30:24.849967 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.solverstate
I1203 20:30:24.855967 21228 solver.cpp:330] Iteration 123000, Testing net (#0)
I1203 20:30:24.856467 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:30:26.585645 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:30:26.654649 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1203 20:30:26.654649 21228 solver.cpp:397]     Test net output #1: loss = 0.243237 (* 1 = 0.243237 loss)
I1203 20:30:26.730651 21228 solver.cpp:218] Iteration 123000 (9.84156 iter/s, 10.161s/100 iters), loss = 0.0166143
I1203 20:30:26.730651 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:30:26.730651 21228 solver.cpp:237]     Train net output #1: loss = 0.0166143 (* 1 = 0.0166143 loss)
I1203 20:30:26.730651 21228 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1203 20:30:35.000932 21228 solver.cpp:218] Iteration 123100 (12.0922 iter/s, 8.26982s/100 iters), loss = 0.0250625
I1203 20:30:35.000932 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:30:35.001933 21228 solver.cpp:237]     Train net output #1: loss = 0.0250625 (* 1 = 0.0250625 loss)
I1203 20:30:35.001933 21228 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1203 20:30:43.291173 21228 solver.cpp:218] Iteration 123200 (12.0636 iter/s, 8.28943s/100 iters), loss = 0.017699
I1203 20:30:43.291173 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:30:43.291173 21228 solver.cpp:237]     Train net output #1: loss = 0.017699 (* 1 = 0.017699 loss)
I1203 20:30:43.291173 21228 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1203 20:30:51.501509 21228 solver.cpp:218] Iteration 123300 (12.1807 iter/s, 8.20971s/100 iters), loss = 0.0108618
I1203 20:30:51.501509 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:30:51.501509 21228 solver.cpp:237]     Train net output #1: loss = 0.0108617 (* 1 = 0.0108617 loss)
I1203 20:30:51.501509 21228 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1203 20:30:59.748786 21228 solver.cpp:218] Iteration 123400 (12.1254 iter/s, 8.24717s/100 iters), loss = 0.00988953
I1203 20:30:59.748786 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:30:59.748786 21228 solver.cpp:237]     Train net output #1: loss = 0.00988948 (* 1 = 0.00988948 loss)
I1203 20:30:59.748786 21228 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1203 20:31:07.622534 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:31:07.952553 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.caffemodel
I1203 20:31:07.982054 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.solverstate
I1203 20:31:07.988054 21228 solver.cpp:330] Iteration 123500, Testing net (#0)
I1203 20:31:07.988556 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:31:09.714716 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:31:09.784222 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1203 20:31:09.784222 21228 solver.cpp:397]     Test net output #1: loss = 0.242905 (* 1 = 0.242905 loss)
I1203 20:31:09.863732 21228 solver.cpp:218] Iteration 123500 (9.88688 iter/s, 10.1144s/100 iters), loss = 0.0160551
I1203 20:31:09.864733 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:31:09.864733 21228 solver.cpp:237]     Train net output #1: loss = 0.0160551 (* 1 = 0.0160551 loss)
I1203 20:31:09.864733 21228 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1203 20:31:18.160922 21228 solver.cpp:218] Iteration 123600 (12.0544 iter/s, 8.29569s/100 iters), loss = 0.011535
I1203 20:31:18.160922 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:31:18.160922 21228 solver.cpp:237]     Train net output #1: loss = 0.0115349 (* 1 = 0.0115349 loss)
I1203 20:31:18.160922 21228 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1203 20:31:26.366986 21228 solver.cpp:218] Iteration 123700 (12.1865 iter/s, 8.2058s/100 iters), loss = 0.0106971
I1203 20:31:26.366986 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:31:26.366986 21228 solver.cpp:237]     Train net output #1: loss = 0.010697 (* 1 = 0.010697 loss)
I1203 20:31:26.366986 21228 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1203 20:31:34.633980 21228 solver.cpp:218] Iteration 123800 (12.0971 iter/s, 8.26648s/100 iters), loss = 0.0103776
I1203 20:31:34.633980 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:31:34.633980 21228 solver.cpp:237]     Train net output #1: loss = 0.0103775 (* 1 = 0.0103775 loss)
I1203 20:31:34.633980 21228 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1203 20:31:42.901621 21228 solver.cpp:218] Iteration 123900 (12.0964 iter/s, 8.26691s/100 iters), loss = 0.0134082
I1203 20:31:42.901621 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:31:42.901621 21228 solver.cpp:237]     Train net output #1: loss = 0.0134082 (* 1 = 0.0134082 loss)
I1203 20:31:42.901621 21228 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1203 20:31:50.786000 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:31:51.106067 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.caffemodel
I1203 20:31:51.148067 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.solverstate
I1203 20:31:51.154067 21228 solver.cpp:330] Iteration 124000, Testing net (#0)
I1203 20:31:51.155067 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:31:52.840191 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:31:52.907197 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9363
I1203 20:31:52.907197 21228 solver.cpp:397]     Test net output #1: loss = 0.237885 (* 1 = 0.237885 loss)
I1203 20:31:52.982198 21228 solver.cpp:218] Iteration 124000 (9.92016 iter/s, 10.0805s/100 iters), loss = 0.0206645
I1203 20:31:52.982198 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:31:52.982198 21228 solver.cpp:237]     Train net output #1: loss = 0.0206644 (* 1 = 0.0206644 loss)
I1203 20:31:52.982198 21228 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1203 20:32:01.255004 21228 solver.cpp:218] Iteration 124100 (12.0889 iter/s, 8.27208s/100 iters), loss = 0.022753
I1203 20:32:01.255004 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:32:01.255004 21228 solver.cpp:237]     Train net output #1: loss = 0.022753 (* 1 = 0.022753 loss)
I1203 20:32:01.255004 21228 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1203 20:32:09.591970 21228 solver.cpp:218] Iteration 124200 (11.9962 iter/s, 8.33595s/100 iters), loss = 0.0168325
I1203 20:32:09.591970 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:32:09.591970 21228 solver.cpp:237]     Train net output #1: loss = 0.0168324 (* 1 = 0.0168324 loss)
I1203 20:32:09.591970 21228 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1203 20:32:17.852272 21228 solver.cpp:218] Iteration 124300 (12.1062 iter/s, 8.26024s/100 iters), loss = 0.00966686
I1203 20:32:17.852272 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:32:17.852272 21228 solver.cpp:237]     Train net output #1: loss = 0.00966681 (* 1 = 0.00966681 loss)
I1203 20:32:17.852272 21228 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1203 20:32:26.185923 21228 solver.cpp:218] Iteration 124400 (12 iter/s, 8.33336s/100 iters), loss = 0.0182687
I1203 20:32:26.185923 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:32:26.185923 21228 solver.cpp:237]     Train net output #1: loss = 0.0182686 (* 1 = 0.0182686 loss)
I1203 20:32:26.185923 21228 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1203 20:32:34.145628 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:32:34.479665 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.caffemodel
I1203 20:32:34.521677 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.solverstate
I1203 20:32:34.530678 21228 solver.cpp:330] Iteration 124500, Testing net (#0)
I1203 20:32:34.530678 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:32:36.232825 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:32:36.301828 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1203 20:32:36.301828 21228 solver.cpp:397]     Test net output #1: loss = 0.238993 (* 1 = 0.238993 loss)
I1203 20:32:36.376833 21228 solver.cpp:218] Iteration 124500 (9.81362 iter/s, 10.1899s/100 iters), loss = 0.013366
I1203 20:32:36.376833 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:32:36.376833 21228 solver.cpp:237]     Train net output #1: loss = 0.013366 (* 1 = 0.013366 loss)
I1203 20:32:36.376833 21228 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1203 20:32:44.511085 21228 solver.cpp:218] Iteration 124600 (12.2946 iter/s, 8.13367s/100 iters), loss = 0.0266818
I1203 20:32:44.511085 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:32:44.511085 21228 solver.cpp:237]     Train net output #1: loss = 0.0266817 (* 1 = 0.0266817 loss)
I1203 20:32:44.511085 21228 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1203 20:32:52.688288 21228 solver.cpp:218] Iteration 124700 (12.2294 iter/s, 8.17703s/100 iters), loss = 0.0278685
I1203 20:32:52.688288 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:32:52.688288 21228 solver.cpp:237]     Train net output #1: loss = 0.0278685 (* 1 = 0.0278685 loss)
I1203 20:32:52.688288 21228 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1203 20:33:00.853091 21228 solver.cpp:218] Iteration 124800 (12.2486 iter/s, 8.16422s/100 iters), loss = 0.0112758
I1203 20:33:00.853091 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:33:00.853091 21228 solver.cpp:237]     Train net output #1: loss = 0.0112757 (* 1 = 0.0112757 loss)
I1203 20:33:00.853091 21228 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1203 20:33:09.065248 21228 solver.cpp:218] Iteration 124900 (12.1777 iter/s, 8.21174s/100 iters), loss = 0.0151342
I1203 20:33:09.065248 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:33:09.065248 21228 solver.cpp:237]     Train net output #1: loss = 0.0151341 (* 1 = 0.0151341 loss)
I1203 20:33:09.065248 21228 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1203 20:33:16.789199 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:33:17.121278 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.caffemodel
I1203 20:33:17.158277 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.solverstate
I1203 20:33:17.165277 21228 solver.cpp:330] Iteration 125000, Testing net (#0)
I1203 20:33:17.165277 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:33:18.887647 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:33:18.955652 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9363
I1203 20:33:18.955652 21228 solver.cpp:397]     Test net output #1: loss = 0.238271 (* 1 = 0.238271 loss)
I1203 20:33:19.032660 21228 solver.cpp:218] Iteration 125000 (10.0337 iter/s, 9.96639s/100 iters), loss = 0.0118697
I1203 20:33:19.032660 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:33:19.032660 21228 solver.cpp:237]     Train net output #1: loss = 0.0118697 (* 1 = 0.0118697 loss)
I1203 20:33:19.032660 21228 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1203 20:33:27.342449 21228 solver.cpp:218] Iteration 125100 (12.0347 iter/s, 8.30927s/100 iters), loss = 0.0431865
I1203 20:33:27.342449 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:33:27.342449 21228 solver.cpp:237]     Train net output #1: loss = 0.0431865 (* 1 = 0.0431865 loss)
I1203 20:33:27.342449 21228 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1203 20:33:35.673810 21228 solver.cpp:218] Iteration 125200 (12.0039 iter/s, 8.33062s/100 iters), loss = 0.015795
I1203 20:33:35.673810 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:33:35.673810 21228 solver.cpp:237]     Train net output #1: loss = 0.0157949 (* 1 = 0.0157949 loss)
I1203 20:33:35.673810 21228 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1203 20:33:43.965790 21228 solver.cpp:218] Iteration 125300 (12.0604 iter/s, 8.29158s/100 iters), loss = 0.0103304
I1203 20:33:43.965790 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:33:43.965790 21228 solver.cpp:237]     Train net output #1: loss = 0.0103304 (* 1 = 0.0103304 loss)
I1203 20:33:43.965790 21228 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1203 20:33:52.251433 21228 solver.cpp:218] Iteration 125400 (12.0702 iter/s, 8.28485s/100 iters), loss = 0.0149793
I1203 20:33:52.251433 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:33:52.251433 21228 solver.cpp:237]     Train net output #1: loss = 0.0149793 (* 1 = 0.0149793 loss)
I1203 20:33:52.251433 21228 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1203 20:34:00.114822 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:34:00.444849 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.caffemodel
I1203 20:34:00.488859 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.solverstate
I1203 20:34:00.495860 21228 solver.cpp:330] Iteration 125500, Testing net (#0)
I1203 20:34:00.495860 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:34:02.211026 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:34:02.281040 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1203 20:34:02.281040 21228 solver.cpp:397]     Test net output #1: loss = 0.241079 (* 1 = 0.241079 loss)
I1203 20:34:02.358037 21228 solver.cpp:218] Iteration 125500 (9.89501 iter/s, 10.1061s/100 iters), loss = 0.016296
I1203 20:34:02.358037 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:34:02.358037 21228 solver.cpp:237]     Train net output #1: loss = 0.0162959 (* 1 = 0.0162959 loss)
I1203 20:34:02.358037 21228 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1203 20:34:10.623714 21228 solver.cpp:218] Iteration 125600 (12.0988 iter/s, 8.2653s/100 iters), loss = 0.0146443
I1203 20:34:10.623714 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:34:10.623714 21228 solver.cpp:237]     Train net output #1: loss = 0.0146443 (* 1 = 0.0146443 loss)
I1203 20:34:10.623714 21228 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1203 20:34:18.832927 21228 solver.cpp:218] Iteration 125700 (12.1821 iter/s, 8.20875s/100 iters), loss = 0.0108184
I1203 20:34:18.832927 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:34:18.832927 21228 solver.cpp:237]     Train net output #1: loss = 0.0108184 (* 1 = 0.0108184 loss)
I1203 20:34:18.832927 21228 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1203 20:34:27.045975 21228 solver.cpp:218] Iteration 125800 (12.1763 iter/s, 8.2127s/100 iters), loss = 0.0218187
I1203 20:34:27.045975 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:34:27.045975 21228 solver.cpp:237]     Train net output #1: loss = 0.0218186 (* 1 = 0.0218186 loss)
I1203 20:34:27.045975 21228 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1203 20:34:35.211364 21228 solver.cpp:218] Iteration 125900 (12.2474 iter/s, 8.165s/100 iters), loss = 0.0145672
I1203 20:34:35.211364 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:34:35.211364 21228 solver.cpp:237]     Train net output #1: loss = 0.0145671 (* 1 = 0.0145671 loss)
I1203 20:34:35.211364 21228 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1203 20:34:43.031343 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:34:43.354454 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.caffemodel
I1203 20:34:43.390146 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.solverstate
I1203 20:34:43.398144 21228 solver.cpp:330] Iteration 126000, Testing net (#0)
I1203 20:34:43.398144 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:34:45.120395 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:34:45.186900 21228 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1203 20:34:45.186900 21228 solver.cpp:397]     Test net output #1: loss = 0.245661 (* 1 = 0.245661 loss)
I1203 20:34:45.262398 21228 solver.cpp:218] Iteration 126000 (9.95029 iter/s, 10.05s/100 iters), loss = 0.0172855
I1203 20:34:45.262398 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:34:45.262398 21228 solver.cpp:237]     Train net output #1: loss = 0.0172855 (* 1 = 0.0172855 loss)
I1203 20:34:45.262398 21228 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1203 20:34:53.412688 21228 solver.cpp:218] Iteration 126100 (12.2689 iter/s, 8.15067s/100 iters), loss = 0.0165552
I1203 20:34:53.413688 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:34:53.413688 21228 solver.cpp:237]     Train net output #1: loss = 0.0165552 (* 1 = 0.0165552 loss)
I1203 20:34:53.413688 21228 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1203 20:35:01.594980 21228 solver.cpp:218] Iteration 126200 (12.223 iter/s, 8.18132s/100 iters), loss = 0.0150548
I1203 20:35:01.594980 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:01.594980 21228 solver.cpp:237]     Train net output #1: loss = 0.0150548 (* 1 = 0.0150548 loss)
I1203 20:35:01.594980 21228 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1203 20:35:09.728137 21228 solver.cpp:218] Iteration 126300 (12.2969 iter/s, 8.13211s/100 iters), loss = 0.00927476
I1203 20:35:09.728137 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:09.728137 21228 solver.cpp:237]     Train net output #1: loss = 0.00927473 (* 1 = 0.00927473 loss)
I1203 20:35:09.728137 21228 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1203 20:35:17.900120 21228 solver.cpp:218] Iteration 126400 (12.2374 iter/s, 8.17166s/100 iters), loss = 0.0105541
I1203 20:35:17.900120 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:17.900120 21228 solver.cpp:237]     Train net output #1: loss = 0.010554 (* 1 = 0.010554 loss)
I1203 20:35:17.900120 21228 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1203 20:35:25.648463 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:35:25.969961 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.caffemodel
I1203 20:35:26.010962 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.solverstate
I1203 20:35:26.017966 21228 solver.cpp:330] Iteration 126500, Testing net (#0)
I1203 20:35:26.018463 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:35:27.709095 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:35:27.776099 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9356
I1203 20:35:27.776099 21228 solver.cpp:397]     Test net output #1: loss = 0.240674 (* 1 = 0.240674 loss)
I1203 20:35:27.853108 21228 solver.cpp:218] Iteration 126500 (10.048 iter/s, 9.95222s/100 iters), loss = 0.0189041
I1203 20:35:27.853108 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:27.853108 21228 solver.cpp:237]     Train net output #1: loss = 0.0189041 (* 1 = 0.0189041 loss)
I1203 20:35:27.853108 21228 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1203 20:35:36.026887 21228 solver.cpp:218] Iteration 126600 (12.2345 iter/s, 8.17362s/100 iters), loss = 0.0151449
I1203 20:35:36.027389 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:36.027389 21228 solver.cpp:237]     Train net output #1: loss = 0.0151448 (* 1 = 0.0151448 loss)
I1203 20:35:36.027389 21228 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1203 20:35:44.157821 21228 solver.cpp:218] Iteration 126700 (12.2991 iter/s, 8.1307s/100 iters), loss = 0.0121921
I1203 20:35:44.157821 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:44.157821 21228 solver.cpp:237]     Train net output #1: loss = 0.0121921 (* 1 = 0.0121921 loss)
I1203 20:35:44.157821 21228 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1203 20:35:52.333668 21228 solver.cpp:218] Iteration 126800 (12.233 iter/s, 8.17458s/100 iters), loss = 0.00916848
I1203 20:35:52.333668 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:35:52.333668 21228 solver.cpp:237]     Train net output #1: loss = 0.00916845 (* 1 = 0.00916845 loss)
I1203 20:35:52.333668 21228 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1203 20:36:00.430932 21228 solver.cpp:218] Iteration 126900 (12.3505 iter/s, 8.09685s/100 iters), loss = 0.0126168
I1203 20:36:00.430932 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:36:00.430932 21228 solver.cpp:237]     Train net output #1: loss = 0.0126168 (* 1 = 0.0126168 loss)
I1203 20:36:00.430932 21228 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1203 20:36:08.116855 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:36:08.434352 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.caffemodel
I1203 20:36:08.473409 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.solverstate
I1203 20:36:08.480410 21228 solver.cpp:330] Iteration 127000, Testing net (#0)
I1203 20:36:08.480410 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:36:10.170547 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:36:10.236549 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1203 20:36:10.236549 21228 solver.cpp:397]     Test net output #1: loss = 0.242234 (* 1 = 0.242234 loss)
I1203 20:36:10.311592 21228 solver.cpp:218] Iteration 127000 (10.1212 iter/s, 9.88027s/100 iters), loss = 0.0149524
I1203 20:36:10.311592 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:36:10.311592 21228 solver.cpp:237]     Train net output #1: loss = 0.0149524 (* 1 = 0.0149524 loss)
I1203 20:36:10.311592 21228 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1203 20:36:18.439158 21228 solver.cpp:218] Iteration 127100 (12.3046 iter/s, 8.12704s/100 iters), loss = 0.0174465
I1203 20:36:18.439158 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:36:18.439158 21228 solver.cpp:237]     Train net output #1: loss = 0.0174464 (* 1 = 0.0174464 loss)
I1203 20:36:18.439158 21228 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1203 20:36:26.664582 21228 solver.cpp:218] Iteration 127200 (12.1588 iter/s, 8.22452s/100 iters), loss = 0.0293187
I1203 20:36:26.664582 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:36:26.664582 21228 solver.cpp:237]     Train net output #1: loss = 0.0293187 (* 1 = 0.0293187 loss)
I1203 20:36:26.664582 21228 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1203 20:36:34.747539 21228 solver.cpp:218] Iteration 127300 (12.3723 iter/s, 8.08259s/100 iters), loss = 0.0111358
I1203 20:36:34.747539 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:36:34.747539 21228 solver.cpp:237]     Train net output #1: loss = 0.0111358 (* 1 = 0.0111358 loss)
I1203 20:36:34.747539 21228 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1203 20:36:42.947547 21228 solver.cpp:218] Iteration 127400 (12.1952 iter/s, 8.19997s/100 iters), loss = 0.013194
I1203 20:36:42.947547 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:36:42.947547 21228 solver.cpp:237]     Train net output #1: loss = 0.0131939 (* 1 = 0.0131939 loss)
I1203 20:36:42.947547 21228 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1203 20:36:50.713601 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:36:51.038887 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.caffemodel
I1203 20:36:51.068892 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.solverstate
I1203 20:36:51.075891 21228 solver.cpp:330] Iteration 127500, Testing net (#0)
I1203 20:36:51.075891 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:36:52.800058 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:36:52.867063 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1203 20:36:52.867063 21228 solver.cpp:397]     Test net output #1: loss = 0.242433 (* 1 = 0.242433 loss)
I1203 20:36:52.942078 21228 solver.cpp:218] Iteration 127500 (10.0062 iter/s, 9.99382s/100 iters), loss = 0.0209699
I1203 20:36:52.942078 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:36:52.942078 21228 solver.cpp:237]     Train net output #1: loss = 0.0209699 (* 1 = 0.0209699 loss)
I1203 20:36:52.942078 21228 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1203 20:37:01.004217 21228 solver.cpp:218] Iteration 127600 (12.4056 iter/s, 8.06089s/100 iters), loss = 0.0159577
I1203 20:37:01.004217 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:37:01.004217 21228 solver.cpp:237]     Train net output #1: loss = 0.0159577 (* 1 = 0.0159577 loss)
I1203 20:37:01.004217 21228 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1203 20:37:09.157297 21228 solver.cpp:218] Iteration 127700 (12.2648 iter/s, 8.15338s/100 iters), loss = 0.023388
I1203 20:37:09.158298 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:37:09.158298 21228 solver.cpp:237]     Train net output #1: loss = 0.0233879 (* 1 = 0.0233879 loss)
I1203 20:37:09.158298 21228 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1203 20:37:17.216992 21228 solver.cpp:218] Iteration 127800 (12.4088 iter/s, 8.05881s/100 iters), loss = 0.01257
I1203 20:37:17.216992 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:37:17.216992 21228 solver.cpp:237]     Train net output #1: loss = 0.01257 (* 1 = 0.01257 loss)
I1203 20:37:17.216992 21228 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1203 20:37:25.337523 21228 solver.cpp:218] Iteration 127900 (12.316 iter/s, 8.11955s/100 iters), loss = 0.0116923
I1203 20:37:25.337523 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:37:25.337523 21228 solver.cpp:237]     Train net output #1: loss = 0.0116922 (* 1 = 0.0116922 loss)
I1203 20:37:25.337523 21228 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1203 20:37:33.046187 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:37:33.361989 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.caffemodel
I1203 20:37:33.398989 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.solverstate
I1203 20:37:33.404989 21228 solver.cpp:330] Iteration 128000, Testing net (#0)
I1203 20:37:33.404989 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:37:35.080107 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:37:35.147111 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1203 20:37:35.147111 21228 solver.cpp:397]     Test net output #1: loss = 0.24475 (* 1 = 0.24475 loss)
I1203 20:37:35.221117 21228 solver.cpp:218] Iteration 128000 (10.1175 iter/s, 9.88384s/100 iters), loss = 0.0197223
I1203 20:37:35.222115 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:37:35.222115 21228 solver.cpp:237]     Train net output #1: loss = 0.0197222 (* 1 = 0.0197222 loss)
I1203 20:37:35.222115 21228 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1203 20:37:43.349498 21228 solver.cpp:218] Iteration 128100 (12.3043 iter/s, 8.12725s/100 iters), loss = 0.0347953
I1203 20:37:43.349498 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:37:43.349498 21228 solver.cpp:237]     Train net output #1: loss = 0.0347952 (* 1 = 0.0347952 loss)
I1203 20:37:43.349498 21228 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1203 20:37:51.449930 21228 solver.cpp:218] Iteration 128200 (12.3458 iter/s, 8.09992s/100 iters), loss = 0.0254438
I1203 20:37:51.449930 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:37:51.449930 21228 solver.cpp:237]     Train net output #1: loss = 0.0254437 (* 1 = 0.0254437 loss)
I1203 20:37:51.449930 21228 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1203 20:37:59.678108 21228 solver.cpp:218] Iteration 128300 (12.1542 iter/s, 8.2276s/100 iters), loss = 0.0254922
I1203 20:37:59.678108 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:37:59.678108 21228 solver.cpp:237]     Train net output #1: loss = 0.0254922 (* 1 = 0.0254922 loss)
I1203 20:37:59.678108 21228 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1203 20:38:07.851712 21228 solver.cpp:218] Iteration 128400 (12.2353 iter/s, 8.17307s/100 iters), loss = 0.0126004
I1203 20:38:07.851712 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:38:07.851712 21228 solver.cpp:237]     Train net output #1: loss = 0.0126004 (* 1 = 0.0126004 loss)
I1203 20:38:07.851712 21228 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1203 20:38:15.549980 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:38:15.866564 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.caffemodel
I1203 20:38:15.896572 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.solverstate
I1203 20:38:15.902572 21228 solver.cpp:330] Iteration 128500, Testing net (#0)
I1203 20:38:15.902572 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:38:17.583665 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:38:17.650672 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1203 20:38:17.650672 21228 solver.cpp:397]     Test net output #1: loss = 0.244162 (* 1 = 0.244162 loss)
I1203 20:38:17.724175 21228 solver.cpp:218] Iteration 128500 (10.13 iter/s, 9.87168s/100 iters), loss = 0.0152163
I1203 20:38:17.724175 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:38:17.724175 21228 solver.cpp:237]     Train net output #1: loss = 0.0152163 (* 1 = 0.0152163 loss)
I1203 20:38:17.724175 21228 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1203 20:38:25.902638 21228 solver.cpp:218] Iteration 128600 (12.2276 iter/s, 8.1782s/100 iters), loss = 0.0152835
I1203 20:38:25.902638 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:38:25.902638 21228 solver.cpp:237]     Train net output #1: loss = 0.0152834 (* 1 = 0.0152834 loss)
I1203 20:38:25.902638 21228 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1203 20:38:34.120291 21228 solver.cpp:218] Iteration 128700 (12.1697 iter/s, 8.21712s/100 iters), loss = 0.0171061
I1203 20:38:34.120291 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:38:34.120291 21228 solver.cpp:237]     Train net output #1: loss = 0.017106 (* 1 = 0.017106 loss)
I1203 20:38:34.120291 21228 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1203 20:38:42.281388 21228 solver.cpp:218] Iteration 128800 (12.254 iter/s, 8.16059s/100 iters), loss = 0.0105519
I1203 20:38:42.281388 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:38:42.281388 21228 solver.cpp:237]     Train net output #1: loss = 0.0105519 (* 1 = 0.0105519 loss)
I1203 20:38:42.281890 21228 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1203 20:38:50.424631 21228 solver.cpp:218] Iteration 128900 (12.281 iter/s, 8.14263s/100 iters), loss = 0.0107549
I1203 20:38:50.424631 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:38:50.424631 21228 solver.cpp:237]     Train net output #1: loss = 0.0107548 (* 1 = 0.0107548 loss)
I1203 20:38:50.424631 21228 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1203 20:38:58.135036 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:38:58.453091 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.caffemodel
I1203 20:38:58.492090 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.solverstate
I1203 20:38:58.499092 21228 solver.cpp:330] Iteration 129000, Testing net (#0)
I1203 20:38:58.499092 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:39:00.177660 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:39:00.243695 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9361
I1203 20:39:00.243695 21228 solver.cpp:397]     Test net output #1: loss = 0.241535 (* 1 = 0.241535 loss)
I1203 20:39:00.318699 21228 solver.cpp:218] Iteration 129000 (10.107 iter/s, 9.89411s/100 iters), loss = 0.0121744
I1203 20:39:00.319699 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:00.319699 21228 solver.cpp:237]     Train net output #1: loss = 0.0121743 (* 1 = 0.0121743 loss)
I1203 20:39:00.319699 21228 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1203 20:39:08.440569 21228 solver.cpp:218] Iteration 129100 (12.3141 iter/s, 8.12075s/100 iters), loss = 0.0280957
I1203 20:39:08.440569 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:39:08.440569 21228 solver.cpp:237]     Train net output #1: loss = 0.0280956 (* 1 = 0.0280956 loss)
I1203 20:39:08.440569 21228 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1203 20:39:16.819414 21228 solver.cpp:218] Iteration 129200 (11.9351 iter/s, 8.37864s/100 iters), loss = 0.0140175
I1203 20:39:16.819414 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:16.819414 21228 solver.cpp:237]     Train net output #1: loss = 0.0140175 (* 1 = 0.0140175 loss)
I1203 20:39:16.819414 21228 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1203 20:39:25.043179 21228 solver.cpp:218] Iteration 129300 (12.1615 iter/s, 8.22266s/100 iters), loss = 0.00839439
I1203 20:39:25.043179 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:25.043179 21228 solver.cpp:237]     Train net output #1: loss = 0.00839434 (* 1 = 0.00839434 loss)
I1203 20:39:25.043179 21228 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1203 20:39:33.225409 21228 solver.cpp:218] Iteration 129400 (12.2217 iter/s, 8.18216s/100 iters), loss = 0.0149799
I1203 20:39:33.225409 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:33.225409 21228 solver.cpp:237]     Train net output #1: loss = 0.0149798 (* 1 = 0.0149798 loss)
I1203 20:39:33.225409 21228 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1203 20:39:41.007362 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:39:41.332397 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.caffemodel
I1203 20:39:41.374397 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.solverstate
I1203 20:39:41.381397 21228 solver.cpp:330] Iteration 129500, Testing net (#0)
I1203 20:39:41.381397 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:39:43.103595 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:39:43.172600 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1203 20:39:43.172600 21228 solver.cpp:397]     Test net output #1: loss = 0.24503 (* 1 = 0.24503 loss)
I1203 20:39:43.250608 21228 solver.cpp:218] Iteration 129500 (9.97599 iter/s, 10.0241s/100 iters), loss = 0.0128526
I1203 20:39:43.250608 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:43.250608 21228 solver.cpp:237]     Train net output #1: loss = 0.0128525 (* 1 = 0.0128525 loss)
I1203 20:39:43.250608 21228 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1203 20:39:51.518524 21228 solver.cpp:218] Iteration 129600 (12.0954 iter/s, 8.26761s/100 iters), loss = 0.0144194
I1203 20:39:51.518524 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:51.518524 21228 solver.cpp:237]     Train net output #1: loss = 0.0144194 (* 1 = 0.0144194 loss)
I1203 20:39:51.518524 21228 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1203 20:39:59.691408 21228 solver.cpp:218] Iteration 129700 (12.2365 iter/s, 8.17226s/100 iters), loss = 0.0112018
I1203 20:39:59.691408 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:39:59.691408 21228 solver.cpp:237]     Train net output #1: loss = 0.0112018 (* 1 = 0.0112018 loss)
I1203 20:39:59.691408 21228 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1203 20:40:07.916451 21228 solver.cpp:218] Iteration 129800 (12.1588 iter/s, 8.22449s/100 iters), loss = 0.0119747
I1203 20:40:07.916451 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:40:07.916451 21228 solver.cpp:237]     Train net output #1: loss = 0.0119747 (* 1 = 0.0119747 loss)
I1203 20:40:07.916451 21228 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1203 20:40:16.128562 21228 solver.cpp:218] Iteration 129900 (12.1777 iter/s, 8.2117s/100 iters), loss = 0.0124029
I1203 20:40:16.128562 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:40:16.128562 21228 solver.cpp:237]     Train net output #1: loss = 0.0124029 (* 1 = 0.0124029 loss)
I1203 20:40:16.128562 21228 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1203 20:40:23.934516 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:40:24.255584 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.caffemodel
I1203 20:40:24.297585 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.solverstate
I1203 20:40:24.304584 21228 solver.cpp:330] Iteration 130000, Testing net (#0)
I1203 20:40:24.304584 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:40:26.011730 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:40:26.079738 21228 solver.cpp:397]     Test net output #0: accuracy = 0.936
I1203 20:40:26.079738 21228 solver.cpp:397]     Test net output #1: loss = 0.247451 (* 1 = 0.247451 loss)
I1203 20:40:26.157759 21228 solver.cpp:218] Iteration 130000 (9.97152 iter/s, 10.0286s/100 iters), loss = 0.0154341
I1203 20:40:26.157759 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:40:26.157759 21228 solver.cpp:237]     Train net output #1: loss = 0.015434 (* 1 = 0.015434 loss)
I1203 20:40:26.157759 21228 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1203 20:40:34.209445 21228 solver.cpp:218] Iteration 130100 (12.42 iter/s, 8.05151s/100 iters), loss = 0.0306829
I1203 20:40:34.209445 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:40:34.209445 21228 solver.cpp:237]     Train net output #1: loss = 0.0306829 (* 1 = 0.0306829 loss)
I1203 20:40:34.209445 21228 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1203 20:40:42.310227 21228 solver.cpp:218] Iteration 130200 (12.3461 iter/s, 8.09973s/100 iters), loss = 0.0145024
I1203 20:40:42.310227 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:40:42.310227 21228 solver.cpp:237]     Train net output #1: loss = 0.0145023 (* 1 = 0.0145023 loss)
I1203 20:40:42.310227 21228 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1203 20:40:50.459497 21228 solver.cpp:218] Iteration 130300 (12.2719 iter/s, 8.14871s/100 iters), loss = 0.0362513
I1203 20:40:50.459497 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:40:50.459497 21228 solver.cpp:237]     Train net output #1: loss = 0.0362513 (* 1 = 0.0362513 loss)
I1203 20:40:50.459497 21228 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1203 20:40:58.623728 21228 solver.cpp:218] Iteration 130400 (12.2484 iter/s, 8.16435s/100 iters), loss = 0.0170917
I1203 20:40:58.623728 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:40:58.623728 21228 solver.cpp:237]     Train net output #1: loss = 0.0170917 (* 1 = 0.0170917 loss)
I1203 20:40:58.623728 21228 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1203 20:41:06.312559 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:41:06.629401 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.caffemodel
I1203 20:41:06.659421 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.solverstate
I1203 20:41:06.665421 21228 solver.cpp:330] Iteration 130500, Testing net (#0)
I1203 20:41:06.665421 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:41:08.348767 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:41:08.415783 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1203 20:41:08.416282 21228 solver.cpp:397]     Test net output #1: loss = 0.244075 (* 1 = 0.244075 loss)
I1203 20:41:08.489804 21228 solver.cpp:218] Iteration 130500 (10.1363 iter/s, 9.86554s/100 iters), loss = 0.0238772
I1203 20:41:08.489804 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:08.489804 21228 solver.cpp:237]     Train net output #1: loss = 0.0238772 (* 1 = 0.0238772 loss)
I1203 20:41:08.489804 21228 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1203 20:41:16.562180 21228 solver.cpp:218] Iteration 130600 (12.3896 iter/s, 8.07127s/100 iters), loss = 0.0171255
I1203 20:41:16.562180 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:16.562180 21228 solver.cpp:237]     Train net output #1: loss = 0.0171254 (* 1 = 0.0171254 loss)
I1203 20:41:16.562180 21228 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1203 20:41:24.638140 21228 solver.cpp:218] Iteration 130700 (12.3835 iter/s, 8.07528s/100 iters), loss = 0.0140881
I1203 20:41:24.638140 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:24.638140 21228 solver.cpp:237]     Train net output #1: loss = 0.014088 (* 1 = 0.014088 loss)
I1203 20:41:24.638140 21228 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1203 20:41:32.703943 21228 solver.cpp:218] Iteration 130800 (12.3982 iter/s, 8.06569s/100 iters), loss = 0.00880739
I1203 20:41:32.703943 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:32.703943 21228 solver.cpp:237]     Train net output #1: loss = 0.00880734 (* 1 = 0.00880734 loss)
I1203 20:41:32.703943 21228 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1203 20:41:40.759687 21228 solver.cpp:218] Iteration 130900 (12.4142 iter/s, 8.0553s/100 iters), loss = 0.00889574
I1203 20:41:40.759687 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:40.759687 21228 solver.cpp:237]     Train net output #1: loss = 0.00889568 (* 1 = 0.00889568 loss)
I1203 20:41:40.759687 21228 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1203 20:41:48.464889 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:41:48.788933 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.caffemodel
I1203 20:41:48.829941 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.solverstate
I1203 20:41:48.836941 21228 solver.cpp:330] Iteration 131000, Testing net (#0)
I1203 20:41:48.836941 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:41:50.531101 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:41:50.598100 21228 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1203 20:41:50.598100 21228 solver.cpp:397]     Test net output #1: loss = 0.243563 (* 1 = 0.243563 loss)
I1203 20:41:50.672123 21228 solver.cpp:218] Iteration 131000 (10.0887 iter/s, 9.91212s/100 iters), loss = 0.0161446
I1203 20:41:50.672123 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:50.672123 21228 solver.cpp:237]     Train net output #1: loss = 0.0161445 (* 1 = 0.0161445 loss)
I1203 20:41:50.672123 21228 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1203 20:41:59.013231 21228 solver.cpp:218] Iteration 131100 (11.9898 iter/s, 8.34042s/100 iters), loss = 0.0194524
I1203 20:41:59.013231 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:41:59.013231 21228 solver.cpp:237]     Train net output #1: loss = 0.0194524 (* 1 = 0.0194524 loss)
I1203 20:41:59.013231 21228 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1203 20:42:07.255506 21228 solver.cpp:218] Iteration 131200 (12.1346 iter/s, 8.24089s/100 iters), loss = 0.00989627
I1203 20:42:07.255506 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:07.255506 21228 solver.cpp:237]     Train net output #1: loss = 0.00989622 (* 1 = 0.00989622 loss)
I1203 20:42:07.255506 21228 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1203 20:42:15.712828 21228 solver.cpp:218] Iteration 131300 (11.8243 iter/s, 8.45713s/100 iters), loss = 0.011668
I1203 20:42:15.712828 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:15.712828 21228 solver.cpp:237]     Train net output #1: loss = 0.0116679 (* 1 = 0.0116679 loss)
I1203 20:42:15.712828 21228 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1203 20:42:24.089758 21228 solver.cpp:218] Iteration 131400 (11.9381 iter/s, 8.37653s/100 iters), loss = 0.0197044
I1203 20:42:24.089758 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:24.089758 21228 solver.cpp:237]     Train net output #1: loss = 0.0197043 (* 1 = 0.0197043 loss)
I1203 20:42:24.089758 21228 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1203 20:42:32.047924 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:42:32.368898 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.caffemodel
I1203 20:42:32.397894 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.solverstate
I1203 20:42:32.403894 21228 solver.cpp:330] Iteration 131500, Testing net (#0)
I1203 20:42:32.403894 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:42:34.140499 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:42:34.210541 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1203 20:42:34.210541 21228 solver.cpp:397]     Test net output #1: loss = 0.245173 (* 1 = 0.245173 loss)
I1203 20:42:34.288524 21228 solver.cpp:218] Iteration 131500 (9.80608 iter/s, 10.1978s/100 iters), loss = 0.0156368
I1203 20:42:34.288524 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:34.288524 21228 solver.cpp:237]     Train net output #1: loss = 0.0156367 (* 1 = 0.0156367 loss)
I1203 20:42:34.288524 21228 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1203 20:42:42.680109 21228 solver.cpp:218] Iteration 131600 (11.9169 iter/s, 8.39141s/100 iters), loss = 0.0161179
I1203 20:42:42.680109 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:42.680109 21228 solver.cpp:237]     Train net output #1: loss = 0.0161178 (* 1 = 0.0161178 loss)
I1203 20:42:42.680109 21228 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1203 20:42:51.060140 21228 solver.cpp:218] Iteration 131700 (11.9348 iter/s, 8.37884s/100 iters), loss = 0.0159136
I1203 20:42:51.060140 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:51.060140 21228 solver.cpp:237]     Train net output #1: loss = 0.0159136 (* 1 = 0.0159136 loss)
I1203 20:42:51.060140 21228 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1203 20:42:59.489785 21228 solver.cpp:218] Iteration 131800 (11.8628 iter/s, 8.42974s/100 iters), loss = 0.0136708
I1203 20:42:59.490777 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:42:59.490777 21228 solver.cpp:237]     Train net output #1: loss = 0.0136708 (* 1 = 0.0136708 loss)
I1203 20:42:59.490777 21228 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1203 20:43:07.857652 21228 solver.cpp:218] Iteration 131900 (11.9518 iter/s, 8.36694s/100 iters), loss = 0.0102055
I1203 20:43:07.857652 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:43:07.857652 21228 solver.cpp:237]     Train net output #1: loss = 0.0102054 (* 1 = 0.0102054 loss)
I1203 20:43:07.857652 21228 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1203 20:43:15.858016 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:43:16.216081 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.caffemodel
I1203 20:43:16.252081 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.solverstate
I1203 20:43:16.258083 21228 solver.cpp:330] Iteration 132000, Testing net (#0)
I1203 20:43:16.258083 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:43:17.976260 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:43:18.046273 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1203 20:43:18.046273 21228 solver.cpp:397]     Test net output #1: loss = 0.247853 (* 1 = 0.247853 loss)
I1203 20:43:18.122272 21228 solver.cpp:218] Iteration 132000 (9.74246 iter/s, 10.2644s/100 iters), loss = 0.0120112
I1203 20:43:18.122272 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:43:18.122272 21228 solver.cpp:237]     Train net output #1: loss = 0.0120111 (* 1 = 0.0120111 loss)
I1203 20:43:18.122272 21228 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1203 20:43:26.522822 21228 solver.cpp:218] Iteration 132100 (11.9053 iter/s, 8.39959s/100 iters), loss = 0.0180837
I1203 20:43:26.522822 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:43:26.522822 21228 solver.cpp:237]     Train net output #1: loss = 0.0180837 (* 1 = 0.0180837 loss)
I1203 20:43:26.522822 21228 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1203 20:43:34.841051 21228 solver.cpp:218] Iteration 132200 (12.0223 iter/s, 8.31788s/100 iters), loss = 0.0193084
I1203 20:43:34.841051 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:43:34.841051 21228 solver.cpp:237]     Train net output #1: loss = 0.0193083 (* 1 = 0.0193083 loss)
I1203 20:43:34.841051 21228 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1203 20:43:43.162636 21228 solver.cpp:218] Iteration 132300 (12.018 iter/s, 8.32085s/100 iters), loss = 0.0120259
I1203 20:43:43.162636 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:43:43.162636 21228 solver.cpp:237]     Train net output #1: loss = 0.0120259 (* 1 = 0.0120259 loss)
I1203 20:43:43.162636 21228 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1203 20:43:51.453290 21228 solver.cpp:218] Iteration 132400 (12.0633 iter/s, 8.28958s/100 iters), loss = 0.0104211
I1203 20:43:51.453290 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:43:51.453290 21228 solver.cpp:237]     Train net output #1: loss = 0.0104211 (* 1 = 0.0104211 loss)
I1203 20:43:51.453290 21228 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1203 20:43:59.369467 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:43:59.694005 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.caffemodel
I1203 20:43:59.722508 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.solverstate
I1203 20:43:59.728509 21228 solver.cpp:330] Iteration 132500, Testing net (#0)
I1203 20:43:59.728509 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:44:01.455653 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:44:01.525663 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1203 20:44:01.525663 21228 solver.cpp:397]     Test net output #1: loss = 0.244849 (* 1 = 0.244849 loss)
I1203 20:44:01.604166 21228 solver.cpp:218] Iteration 132500 (9.8518 iter/s, 10.1504s/100 iters), loss = 0.0152141
I1203 20:44:01.604166 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:44:01.604166 21228 solver.cpp:237]     Train net output #1: loss = 0.015214 (* 1 = 0.015214 loss)
I1203 20:44:01.604166 21228 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1203 20:44:10.030966 21228 solver.cpp:218] Iteration 132600 (11.8672 iter/s, 8.42661s/100 iters), loss = 0.0218163
I1203 20:44:10.030966 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:44:10.030966 21228 solver.cpp:237]     Train net output #1: loss = 0.0218162 (* 1 = 0.0218162 loss)
I1203 20:44:10.030966 21228 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1203 20:44:18.348165 21228 solver.cpp:218] Iteration 132700 (12.0246 iter/s, 8.31628s/100 iters), loss = 0.0140143
I1203 20:44:18.348165 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:44:18.348165 21228 solver.cpp:237]     Train net output #1: loss = 0.0140142 (* 1 = 0.0140142 loss)
I1203 20:44:18.348165 21228 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1203 20:44:26.716102 21228 solver.cpp:218] Iteration 132800 (11.9512 iter/s, 8.36733s/100 iters), loss = 0.0077632
I1203 20:44:26.716102 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:44:26.716102 21228 solver.cpp:237]     Train net output #1: loss = 0.00776313 (* 1 = 0.00776313 loss)
I1203 20:44:26.716102 21228 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1203 20:44:35.132983 21228 solver.cpp:218] Iteration 132900 (11.881 iter/s, 8.41683s/100 iters), loss = 0.012296
I1203 20:44:35.132983 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:44:35.132983 21228 solver.cpp:237]     Train net output #1: loss = 0.0122959 (* 1 = 0.0122959 loss)
I1203 20:44:35.132983 21228 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1203 20:44:43.079809 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:44:43.412637 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.caffemodel
I1203 20:44:43.454141 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.solverstate
I1203 20:44:43.461143 21228 solver.cpp:330] Iteration 133000, Testing net (#0)
I1203 20:44:43.461143 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:44:45.180294 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:44:45.249307 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1203 20:44:45.249307 21228 solver.cpp:397]     Test net output #1: loss = 0.246782 (* 1 = 0.246782 loss)
I1203 20:44:45.328333 21228 solver.cpp:218] Iteration 133000 (9.80977 iter/s, 10.1939s/100 iters), loss = 0.0149115
I1203 20:44:45.328333 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:44:45.328333 21228 solver.cpp:237]     Train net output #1: loss = 0.0149114 (* 1 = 0.0149114 loss)
I1203 20:44:45.328333 21228 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1203 20:44:53.729194 21228 solver.cpp:218] Iteration 133100 (11.9038 iter/s, 8.40066s/100 iters), loss = 0.0110941
I1203 20:44:53.729194 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:44:53.729194 21228 solver.cpp:237]     Train net output #1: loss = 0.0110941 (* 1 = 0.0110941 loss)
I1203 20:44:53.729194 21228 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1203 20:45:02.139674 21228 solver.cpp:218] Iteration 133200 (11.8909 iter/s, 8.40982s/100 iters), loss = 0.0195028
I1203 20:45:02.139674 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:02.139674 21228 solver.cpp:237]     Train net output #1: loss = 0.0195027 (* 1 = 0.0195027 loss)
I1203 20:45:02.139674 21228 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1203 20:45:10.453919 21228 solver.cpp:218] Iteration 133300 (12.0281 iter/s, 8.31386s/100 iters), loss = 0.0165848
I1203 20:45:10.453919 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:10.453919 21228 solver.cpp:237]     Train net output #1: loss = 0.0165847 (* 1 = 0.0165847 loss)
I1203 20:45:10.453919 21228 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1203 20:45:18.782119 21228 solver.cpp:218] Iteration 133400 (12.0085 iter/s, 8.3274s/100 iters), loss = 0.0103602
I1203 20:45:18.782119 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:18.782119 21228 solver.cpp:237]     Train net output #1: loss = 0.0103601 (* 1 = 0.0103601 loss)
I1203 20:45:18.782119 21228 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1203 20:45:26.697659 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:45:27.030153 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.caffemodel
I1203 20:45:27.074151 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.solverstate
I1203 20:45:27.080152 21228 solver.cpp:330] Iteration 133500, Testing net (#0)
I1203 20:45:27.080152 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:45:28.808593 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:45:28.878562 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1203 20:45:28.878562 21228 solver.cpp:397]     Test net output #1: loss = 0.246371 (* 1 = 0.246371 loss)
I1203 20:45:28.959530 21228 solver.cpp:218] Iteration 133500 (9.82651 iter/s, 10.1765s/100 iters), loss = 0.012653
I1203 20:45:28.959530 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:28.959530 21228 solver.cpp:237]     Train net output #1: loss = 0.0126529 (* 1 = 0.0126529 loss)
I1203 20:45:28.959530 21228 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1203 20:45:37.330852 21228 solver.cpp:218] Iteration 133600 (11.9465 iter/s, 8.37064s/100 iters), loss = 0.0176291
I1203 20:45:37.330852 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:37.330852 21228 solver.cpp:237]     Train net output #1: loss = 0.017629 (* 1 = 0.017629 loss)
I1203 20:45:37.330852 21228 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1203 20:45:45.657340 21228 solver.cpp:218] Iteration 133700 (12.01 iter/s, 8.32639s/100 iters), loss = 0.0113222
I1203 20:45:45.657340 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:45.657340 21228 solver.cpp:237]     Train net output #1: loss = 0.0113221 (* 1 = 0.0113221 loss)
I1203 20:45:45.657340 21228 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1203 20:45:53.948146 21228 solver.cpp:218] Iteration 133800 (12.0618 iter/s, 8.29062s/100 iters), loss = 0.0122185
I1203 20:45:53.949147 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:45:53.949147 21228 solver.cpp:237]     Train net output #1: loss = 0.0122185 (* 1 = 0.0122185 loss)
I1203 20:45:53.949147 21228 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1203 20:46:02.269444 21228 solver.cpp:218] Iteration 133900 (12.0195 iter/s, 8.31979s/100 iters), loss = 0.0141794
I1203 20:46:02.269444 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:02.269444 21228 solver.cpp:237]     Train net output #1: loss = 0.0141794 (* 1 = 0.0141794 loss)
I1203 20:46:02.269444 21228 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1203 20:46:10.179903 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:46:10.508937 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.caffemodel
I1203 20:46:10.551945 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.solverstate
I1203 20:46:10.558944 21228 solver.cpp:330] Iteration 134000, Testing net (#0)
I1203 20:46:10.558944 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:46:12.270102 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:46:12.339105 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9368
I1203 20:46:12.339105 21228 solver.cpp:397]     Test net output #1: loss = 0.243984 (* 1 = 0.243984 loss)
I1203 20:46:12.415107 21228 solver.cpp:218] Iteration 134000 (9.85686 iter/s, 10.1452s/100 iters), loss = 0.0220324
I1203 20:46:12.415107 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:12.415107 21228 solver.cpp:237]     Train net output #1: loss = 0.0220323 (* 1 = 0.0220323 loss)
I1203 20:46:12.415107 21228 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1203 20:46:20.789240 21228 solver.cpp:218] Iteration 134100 (11.9426 iter/s, 8.37336s/100 iters), loss = 0.0266128
I1203 20:46:20.789240 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:20.789240 21228 solver.cpp:237]     Train net output #1: loss = 0.0266127 (* 1 = 0.0266127 loss)
I1203 20:46:20.789240 21228 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1203 20:46:29.125510 21228 solver.cpp:218] Iteration 134200 (11.9958 iter/s, 8.33626s/100 iters), loss = 0.014723
I1203 20:46:29.125510 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:29.125510 21228 solver.cpp:237]     Train net output #1: loss = 0.0147229 (* 1 = 0.0147229 loss)
I1203 20:46:29.125510 21228 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1203 20:46:37.448650 21228 solver.cpp:218] Iteration 134300 (12.0159 iter/s, 8.32228s/100 iters), loss = 0.0089974
I1203 20:46:37.448650 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:37.448650 21228 solver.cpp:237]     Train net output #1: loss = 0.00899733 (* 1 = 0.00899733 loss)
I1203 20:46:37.448650 21228 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1203 20:46:45.860263 21228 solver.cpp:218] Iteration 134400 (11.8884 iter/s, 8.41158s/100 iters), loss = 0.0189866
I1203 20:46:45.860263 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:45.860263 21228 solver.cpp:237]     Train net output #1: loss = 0.0189865 (* 1 = 0.0189865 loss)
I1203 20:46:45.860263 21228 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1203 20:46:53.761286 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:46:54.084553 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.caffemodel
I1203 20:46:54.114552 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.solverstate
I1203 20:46:54.121553 21228 solver.cpp:330] Iteration 134500, Testing net (#0)
I1203 20:46:54.121553 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:46:55.852522 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:46:55.920542 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 20:46:55.920542 21228 solver.cpp:397]     Test net output #1: loss = 0.241767 (* 1 = 0.241767 loss)
I1203 20:46:55.997061 21228 solver.cpp:218] Iteration 134500 (9.86558 iter/s, 10.1363s/100 iters), loss = 0.0119787
I1203 20:46:55.997061 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:46:55.997061 21228 solver.cpp:237]     Train net output #1: loss = 0.0119786 (* 1 = 0.0119786 loss)
I1203 20:46:55.997061 21228 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1203 20:47:04.359215 21228 solver.cpp:218] Iteration 134600 (11.9603 iter/s, 8.36101s/100 iters), loss = 0.0128367
I1203 20:47:04.359215 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:04.359215 21228 solver.cpp:237]     Train net output #1: loss = 0.0128366 (* 1 = 0.0128366 loss)
I1203 20:47:04.359215 21228 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1203 20:47:12.761813 21228 solver.cpp:218] Iteration 134700 (11.9022 iter/s, 8.40184s/100 iters), loss = 0.0142045
I1203 20:47:12.761813 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:12.761813 21228 solver.cpp:237]     Train net output #1: loss = 0.0142044 (* 1 = 0.0142044 loss)
I1203 20:47:12.761813 21228 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1203 20:47:21.095485 21228 solver.cpp:218] Iteration 134800 (11.9993 iter/s, 8.33381s/100 iters), loss = 0.0110453
I1203 20:47:21.095485 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:21.095485 21228 solver.cpp:237]     Train net output #1: loss = 0.0110452 (* 1 = 0.0110452 loss)
I1203 20:47:21.095485 21228 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1203 20:47:29.418524 21228 solver.cpp:218] Iteration 134900 (12.0156 iter/s, 8.32251s/100 iters), loss = 0.0105235
I1203 20:47:29.418524 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:29.418524 21228 solver.cpp:237]     Train net output #1: loss = 0.0105235 (* 1 = 0.0105235 loss)
I1203 20:47:29.418524 21228 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1203 20:47:37.278039 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:47:37.609068 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.caffemodel
I1203 20:47:37.644068 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.solverstate
I1203 20:47:37.650068 21228 solver.cpp:330] Iteration 135000, Testing net (#0)
I1203 20:47:37.650068 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:47:39.356231 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:47:39.426236 21228 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1203 20:47:39.426236 21228 solver.cpp:397]     Test net output #1: loss = 0.247171 (* 1 = 0.247171 loss)
I1203 20:47:39.502256 21228 solver.cpp:218] Iteration 135000 (9.91741 iter/s, 10.0833s/100 iters), loss = 0.0234954
I1203 20:47:39.502256 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:39.502256 21228 solver.cpp:237]     Train net output #1: loss = 0.0234953 (* 1 = 0.0234953 loss)
I1203 20:47:39.502256 21228 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1203 20:47:47.799407 21228 solver.cpp:218] Iteration 135100 (12.0531 iter/s, 8.29664s/100 iters), loss = 0.0170291
I1203 20:47:47.800408 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:47.800408 21228 solver.cpp:237]     Train net output #1: loss = 0.017029 (* 1 = 0.017029 loss)
I1203 20:47:47.800408 21228 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1203 20:47:56.085321 21228 solver.cpp:218] Iteration 135200 (12.0706 iter/s, 8.28457s/100 iters), loss = 0.0127803
I1203 20:47:56.085321 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:47:56.085321 21228 solver.cpp:237]     Train net output #1: loss = 0.0127803 (* 1 = 0.0127803 loss)
I1203 20:47:56.085321 21228 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1203 20:48:04.352654 21228 solver.cpp:218] Iteration 135300 (12.0963 iter/s, 8.26702s/100 iters), loss = 0.00820266
I1203 20:48:04.352654 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:04.352654 21228 solver.cpp:237]     Train net output #1: loss = 0.00820259 (* 1 = 0.00820259 loss)
I1203 20:48:04.352654 21228 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1203 20:48:12.624935 21228 solver.cpp:218] Iteration 135400 (12.0896 iter/s, 8.27158s/100 iters), loss = 0.0191338
I1203 20:48:12.624935 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:12.624935 21228 solver.cpp:237]     Train net output #1: loss = 0.0191337 (* 1 = 0.0191337 loss)
I1203 20:48:12.624935 21228 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1203 20:48:20.514811 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:48:20.851838 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.caffemodel
I1203 20:48:20.893842 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.solverstate
I1203 20:48:20.899857 21228 solver.cpp:330] Iteration 135500, Testing net (#0)
I1203 20:48:20.899857 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:48:22.647668 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:48:22.717489 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9359
I1203 20:48:22.717489 21228 solver.cpp:397]     Test net output #1: loss = 0.249068 (* 1 = 0.249068 loss)
I1203 20:48:22.795491 21228 solver.cpp:218] Iteration 135500 (9.83285 iter/s, 10.17s/100 iters), loss = 0.0141992
I1203 20:48:22.795992 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:22.795992 21228 solver.cpp:237]     Train net output #1: loss = 0.0141991 (* 1 = 0.0141991 loss)
I1203 20:48:22.795992 21228 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1203 20:48:31.177398 21228 solver.cpp:218] Iteration 135600 (11.9308 iter/s, 8.38165s/100 iters), loss = 0.0134276
I1203 20:48:31.177398 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:31.177398 21228 solver.cpp:237]     Train net output #1: loss = 0.0134275 (* 1 = 0.0134275 loss)
I1203 20:48:31.177398 21228 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1203 20:48:39.595659 21228 solver.cpp:218] Iteration 135700 (11.8809 iter/s, 8.41685s/100 iters), loss = 0.0157138
I1203 20:48:39.595659 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:39.595659 21228 solver.cpp:237]     Train net output #1: loss = 0.0157137 (* 1 = 0.0157137 loss)
I1203 20:48:39.595659 21228 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1203 20:48:47.851640 21228 solver.cpp:218] Iteration 135800 (12.1129 iter/s, 8.25564s/100 iters), loss = 0.0138551
I1203 20:48:47.851640 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:47.851640 21228 solver.cpp:237]     Train net output #1: loss = 0.0138551 (* 1 = 0.0138551 loss)
I1203 20:48:47.851640 21228 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1203 20:48:56.165071 21228 solver.cpp:218] Iteration 135900 (12.0295 iter/s, 8.3129s/100 iters), loss = 0.0144503
I1203 20:48:56.165071 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:48:56.165071 21228 solver.cpp:237]     Train net output #1: loss = 0.0144502 (* 1 = 0.0144502 loss)
I1203 20:48:56.165071 21228 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1203 20:49:04.097594 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:49:04.427117 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.caffemodel
I1203 20:49:04.462117 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.solverstate
I1203 20:49:04.468117 21228 solver.cpp:330] Iteration 136000, Testing net (#0)
I1203 20:49:04.469117 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:49:06.180433 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:49:06.248440 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1203 20:49:06.248440 21228 solver.cpp:397]     Test net output #1: loss = 0.245889 (* 1 = 0.245889 loss)
I1203 20:49:06.326447 21228 solver.cpp:218] Iteration 136000 (9.84107 iter/s, 10.1615s/100 iters), loss = 0.0210433
I1203 20:49:06.327447 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:49:06.327447 21228 solver.cpp:237]     Train net output #1: loss = 0.0210432 (* 1 = 0.0210432 loss)
I1203 20:49:06.327447 21228 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1203 20:49:14.679522 21228 solver.cpp:218] Iteration 136100 (11.9732 iter/s, 8.35199s/100 iters), loss = 0.0160783
I1203 20:49:14.679522 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:49:14.679522 21228 solver.cpp:237]     Train net output #1: loss = 0.0160783 (* 1 = 0.0160783 loss)
I1203 20:49:14.679522 21228 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1203 20:49:23.098106 21228 solver.cpp:218] Iteration 136200 (11.879 iter/s, 8.41821s/100 iters), loss = 0.0296588
I1203 20:49:23.098106 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:49:23.098106 21228 solver.cpp:237]     Train net output #1: loss = 0.0296587 (* 1 = 0.0296587 loss)
I1203 20:49:23.098106 21228 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1203 20:49:31.369879 21228 solver.cpp:218] Iteration 136300 (12.0906 iter/s, 8.27087s/100 iters), loss = 0.0117961
I1203 20:49:31.369879 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:49:31.369879 21228 solver.cpp:237]     Train net output #1: loss = 0.0117961 (* 1 = 0.0117961 loss)
I1203 20:49:31.369879 21228 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1203 20:49:39.700595 21228 solver.cpp:218] Iteration 136400 (12.004 iter/s, 8.33055s/100 iters), loss = 0.0130437
I1203 20:49:39.700595 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:49:39.700595 21228 solver.cpp:237]     Train net output #1: loss = 0.0130437 (* 1 = 0.0130437 loss)
I1203 20:49:39.700595 21228 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1203 20:49:47.610965 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:49:47.929991 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.caffemodel
I1203 20:49:47.959990 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.solverstate
I1203 20:49:47.965991 21228 solver.cpp:330] Iteration 136500, Testing net (#0)
I1203 20:49:47.965991 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:49:49.696183 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:49:49.764189 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9365
I1203 20:49:49.764189 21228 solver.cpp:397]     Test net output #1: loss = 0.246307 (* 1 = 0.246307 loss)
I1203 20:49:49.841203 21228 solver.cpp:218] Iteration 136500 (9.86176 iter/s, 10.1402s/100 iters), loss = 0.025192
I1203 20:49:49.841203 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:49:49.841203 21228 solver.cpp:237]     Train net output #1: loss = 0.0251919 (* 1 = 0.0251919 loss)
I1203 20:49:49.841203 21228 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1203 20:49:58.137607 21228 solver.cpp:218] Iteration 136600 (12.0541 iter/s, 8.29594s/100 iters), loss = 0.0369381
I1203 20:49:58.138608 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 20:49:58.138608 21228 solver.cpp:237]     Train net output #1: loss = 0.036938 (* 1 = 0.036938 loss)
I1203 20:49:58.138608 21228 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1203 20:50:06.610574 21228 solver.cpp:218] Iteration 136700 (11.8036 iter/s, 8.47201s/100 iters), loss = 0.0169872
I1203 20:50:06.610574 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:50:06.610574 21228 solver.cpp:237]     Train net output #1: loss = 0.0169871 (* 1 = 0.0169871 loss)
I1203 20:50:06.610574 21228 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1203 20:50:14.910101 21228 solver.cpp:218] Iteration 136800 (12.0499 iter/s, 8.29882s/100 iters), loss = 0.0115213
I1203 20:50:14.910101 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:50:14.910101 21228 solver.cpp:237]     Train net output #1: loss = 0.0115213 (* 1 = 0.0115213 loss)
I1203 20:50:14.910101 21228 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1203 20:50:23.247997 21228 solver.cpp:218] Iteration 136900 (11.9947 iter/s, 8.33698s/100 iters), loss = 0.0185296
I1203 20:50:23.247997 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:50:23.247997 21228 solver.cpp:237]     Train net output #1: loss = 0.0185295 (* 1 = 0.0185295 loss)
I1203 20:50:23.247997 21228 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1203 20:50:31.091836 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:50:31.421463 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.caffemodel
I1203 20:50:31.457473 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.solverstate
I1203 20:50:31.463471 21228 solver.cpp:330] Iteration 137000, Testing net (#0)
I1203 20:50:31.463471 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:50:33.172507 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:50:33.240013 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1203 20:50:33.240013 21228 solver.cpp:397]     Test net output #1: loss = 0.246947 (* 1 = 0.246947 loss)
I1203 20:50:33.319017 21228 solver.cpp:218] Iteration 137000 (9.92964 iter/s, 10.0709s/100 iters), loss = 0.0135884
I1203 20:50:33.319017 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:50:33.319017 21228 solver.cpp:237]     Train net output #1: loss = 0.0135883 (* 1 = 0.0135883 loss)
I1203 20:50:33.319017 21228 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1203 20:50:41.606261 21228 solver.cpp:218] Iteration 137100 (12.0676 iter/s, 8.28662s/100 iters), loss = 0.0265269
I1203 20:50:41.606261 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:50:41.606261 21228 solver.cpp:237]     Train net output #1: loss = 0.0265268 (* 1 = 0.0265268 loss)
I1203 20:50:41.606261 21228 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1203 20:50:49.901899 21228 solver.cpp:218] Iteration 137200 (12.0551 iter/s, 8.29522s/100 iters), loss = 0.0119349
I1203 20:50:49.901899 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:50:49.901899 21228 solver.cpp:237]     Train net output #1: loss = 0.0119348 (* 1 = 0.0119348 loss)
I1203 20:50:49.901899 21228 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1203 20:50:58.200501 21228 solver.cpp:218] Iteration 137300 (12.0509 iter/s, 8.29813s/100 iters), loss = 0.0086965
I1203 20:50:58.200501 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:50:58.200501 21228 solver.cpp:237]     Train net output #1: loss = 0.00869643 (* 1 = 0.00869643 loss)
I1203 20:50:58.200501 21228 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1203 20:51:06.505264 21228 solver.cpp:218] Iteration 137400 (12.0424 iter/s, 8.30397s/100 iters), loss = 0.0372585
I1203 20:51:06.505264 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:51:06.505264 21228 solver.cpp:237]     Train net output #1: loss = 0.0372584 (* 1 = 0.0372584 loss)
I1203 20:51:06.505264 21228 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1203 20:51:14.367776 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:51:14.687042 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.caffemodel
I1203 20:51:14.730057 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.solverstate
I1203 20:51:14.736057 21228 solver.cpp:330] Iteration 137500, Testing net (#0)
I1203 20:51:14.736057 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:51:16.459579 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:51:16.527590 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1203 20:51:16.527590 21228 solver.cpp:397]     Test net output #1: loss = 0.244585 (* 1 = 0.244585 loss)
I1203 20:51:16.604589 21228 solver.cpp:218] Iteration 137500 (9.90183 iter/s, 10.0991s/100 iters), loss = 0.0255686
I1203 20:51:16.604589 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:51:16.604589 21228 solver.cpp:237]     Train net output #1: loss = 0.0255686 (* 1 = 0.0255686 loss)
I1203 20:51:16.604589 21228 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1203 20:51:24.935175 21228 solver.cpp:218] Iteration 137600 (12.0055 iter/s, 8.32949s/100 iters), loss = 0.0333533
I1203 20:51:24.935175 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:51:24.935175 21228 solver.cpp:237]     Train net output #1: loss = 0.0333532 (* 1 = 0.0333532 loss)
I1203 20:51:24.935175 21228 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1203 20:51:33.367895 21228 solver.cpp:218] Iteration 137700 (11.8584 iter/s, 8.43284s/100 iters), loss = 0.0137983
I1203 20:51:33.368896 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:51:33.368896 21228 solver.cpp:237]     Train net output #1: loss = 0.0137982 (* 1 = 0.0137982 loss)
I1203 20:51:33.368896 21228 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1203 20:51:41.651420 21228 solver.cpp:218] Iteration 137800 (12.0737 iter/s, 8.28249s/100 iters), loss = 0.0192129
I1203 20:51:41.651921 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:51:41.651921 21228 solver.cpp:237]     Train net output #1: loss = 0.0192128 (* 1 = 0.0192128 loss)
I1203 20:51:41.651921 21228 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1203 20:51:49.936278 21228 solver.cpp:218] Iteration 137900 (12.0716 iter/s, 8.2839s/100 iters), loss = 0.0174559
I1203 20:51:49.936278 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:51:49.936278 21228 solver.cpp:237]     Train net output #1: loss = 0.0174559 (* 1 = 0.0174559 loss)
I1203 20:51:49.936278 21228 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1203 20:51:57.765977 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:51:58.094514 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.caffemodel
I1203 20:51:58.129515 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.solverstate
I1203 20:51:58.135529 21228 solver.cpp:330] Iteration 138000, Testing net (#0)
I1203 20:51:58.135529 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:51:59.842646 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:51:59.910653 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1203 20:51:59.910653 21228 solver.cpp:397]     Test net output #1: loss = 0.249589 (* 1 = 0.249589 loss)
I1203 20:51:59.985656 21228 solver.cpp:218] Iteration 138000 (9.95134 iter/s, 10.0489s/100 iters), loss = 0.0147853
I1203 20:51:59.985656 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:51:59.985656 21228 solver.cpp:237]     Train net output #1: loss = 0.0147852 (* 1 = 0.0147852 loss)
I1203 20:51:59.985656 21228 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1203 20:52:08.263844 21228 solver.cpp:218] Iteration 138100 (12.0805 iter/s, 8.27777s/100 iters), loss = 0.0139993
I1203 20:52:08.263844 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:08.263844 21228 solver.cpp:237]     Train net output #1: loss = 0.0139993 (* 1 = 0.0139993 loss)
I1203 20:52:08.263844 21228 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1203 20:52:16.515269 21228 solver.cpp:218] Iteration 138200 (12.1201 iter/s, 8.25073s/100 iters), loss = 0.0121275
I1203 20:52:16.515269 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:16.515269 21228 solver.cpp:237]     Train net output #1: loss = 0.0121274 (* 1 = 0.0121274 loss)
I1203 20:52:16.515269 21228 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1203 20:52:24.773622 21228 solver.cpp:218] Iteration 138300 (12.1097 iter/s, 8.25784s/100 iters), loss = 0.00838439
I1203 20:52:24.773622 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:24.773622 21228 solver.cpp:237]     Train net output #1: loss = 0.00838431 (* 1 = 0.00838431 loss)
I1203 20:52:24.773622 21228 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1203 20:52:33.029527 21228 solver.cpp:218] Iteration 138400 (12.1137 iter/s, 8.25513s/100 iters), loss = 0.011041
I1203 20:52:33.029527 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:33.029527 21228 solver.cpp:237]     Train net output #1: loss = 0.0110409 (* 1 = 0.0110409 loss)
I1203 20:52:33.029527 21228 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1203 20:52:40.915172 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:52:41.244186 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.caffemodel
I1203 20:52:41.285200 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.solverstate
I1203 20:52:41.292201 21228 solver.cpp:330] Iteration 138500, Testing net (#0)
I1203 20:52:41.292201 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:52:43.004416 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:52:43.072919 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9365
I1203 20:52:43.072919 21228 solver.cpp:397]     Test net output #1: loss = 0.244918 (* 1 = 0.244918 loss)
I1203 20:52:43.151423 21228 solver.cpp:218] Iteration 138500 (9.87946 iter/s, 10.122s/100 iters), loss = 0.0149201
I1203 20:52:43.151423 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:43.151423 21228 solver.cpp:237]     Train net output #1: loss = 0.01492 (* 1 = 0.01492 loss)
I1203 20:52:43.151423 21228 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1203 20:52:51.406363 21228 solver.cpp:218] Iteration 138600 (12.1152 iter/s, 8.25407s/100 iters), loss = 0.0148017
I1203 20:52:51.406363 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:51.406363 21228 solver.cpp:237]     Train net output #1: loss = 0.0148017 (* 1 = 0.0148017 loss)
I1203 20:52:51.406363 21228 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1203 20:52:59.655038 21228 solver.cpp:218] Iteration 138700 (12.1237 iter/s, 8.24831s/100 iters), loss = 0.0185555
I1203 20:52:59.655038 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:52:59.655038 21228 solver.cpp:237]     Train net output #1: loss = 0.0185555 (* 1 = 0.0185555 loss)
I1203 20:52:59.655038 21228 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1203 20:53:07.919667 21228 solver.cpp:218] Iteration 138800 (12.1008 iter/s, 8.2639s/100 iters), loss = 0.0144776
I1203 20:53:07.919667 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:07.919667 21228 solver.cpp:237]     Train net output #1: loss = 0.0144775 (* 1 = 0.0144775 loss)
I1203 20:53:07.919667 21228 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1203 20:53:16.218560 21228 solver.cpp:218] Iteration 138900 (12.0499 iter/s, 8.29884s/100 iters), loss = 0.0166426
I1203 20:53:16.218560 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:16.219561 21228 solver.cpp:237]     Train net output #1: loss = 0.0166425 (* 1 = 0.0166425 loss)
I1203 20:53:16.219561 21228 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1203 20:53:24.100070 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:53:24.425330 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.caffemodel
I1203 20:53:24.469329 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.solverstate
I1203 20:53:24.475864 21228 solver.cpp:330] Iteration 139000, Testing net (#0)
I1203 20:53:24.475864 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:53:26.212335 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:53:26.282821 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9368
I1203 20:53:26.282821 21228 solver.cpp:397]     Test net output #1: loss = 0.24385 (* 1 = 0.24385 loss)
I1203 20:53:26.363325 21228 solver.cpp:218] Iteration 139000 (9.85836 iter/s, 10.1437s/100 iters), loss = 0.0122224
I1203 20:53:26.363325 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:26.363325 21228 solver.cpp:237]     Train net output #1: loss = 0.0122223 (* 1 = 0.0122223 loss)
I1203 20:53:26.363325 21228 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1203 20:53:34.722715 21228 solver.cpp:218] Iteration 139100 (11.9633 iter/s, 8.3589s/100 iters), loss = 0.0165625
I1203 20:53:34.722715 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:34.722715 21228 solver.cpp:237]     Train net output #1: loss = 0.0165624 (* 1 = 0.0165624 loss)
I1203 20:53:34.722715 21228 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1203 20:53:42.984194 21228 solver.cpp:218] Iteration 139200 (12.1059 iter/s, 8.26046s/100 iters), loss = 0.0141003
I1203 20:53:42.984194 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:42.984194 21228 solver.cpp:237]     Train net output #1: loss = 0.0141002 (* 1 = 0.0141002 loss)
I1203 20:53:42.984194 21228 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1203 20:53:51.246289 21228 solver.cpp:218] Iteration 139300 (12.1037 iter/s, 8.26193s/100 iters), loss = 0.0191106
I1203 20:53:51.246289 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:51.246289 21228 solver.cpp:237]     Train net output #1: loss = 0.0191105 (* 1 = 0.0191105 loss)
I1203 20:53:51.246289 21228 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1203 20:53:59.707512 21228 solver.cpp:218] Iteration 139400 (11.8194 iter/s, 8.46064s/100 iters), loss = 0.0144734
I1203 20:53:59.707512 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:53:59.707512 21228 solver.cpp:237]     Train net output #1: loss = 0.0144734 (* 1 = 0.0144734 loss)
I1203 20:53:59.707512 21228 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1203 20:54:07.615662 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:54:07.962407 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.caffemodel
I1203 20:54:07.993407 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.solverstate
I1203 20:54:08.001408 21228 solver.cpp:330] Iteration 139500, Testing net (#0)
I1203 20:54:08.001408 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:54:09.735612 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:54:09.805807 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9367
I1203 20:54:09.806320 21228 solver.cpp:397]     Test net output #1: loss = 0.24548 (* 1 = 0.24548 loss)
I1203 20:54:09.886998 21228 solver.cpp:218] Iteration 139500 (9.82387 iter/s, 10.1793s/100 iters), loss = 0.011969
I1203 20:54:09.886998 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:54:09.886998 21228 solver.cpp:237]     Train net output #1: loss = 0.0119689 (* 1 = 0.0119689 loss)
I1203 20:54:09.886998 21228 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1203 20:54:18.378885 21228 solver.cpp:218] Iteration 139600 (11.7768 iter/s, 8.49124s/100 iters), loss = 0.0122876
I1203 20:54:18.378885 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:54:18.378885 21228 solver.cpp:237]     Train net output #1: loss = 0.0122875 (* 1 = 0.0122875 loss)
I1203 20:54:18.378885 21228 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1203 20:54:26.658776 21228 solver.cpp:218] Iteration 139700 (12.0784 iter/s, 8.27924s/100 iters), loss = 0.0191318
I1203 20:54:26.658776 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:54:26.658776 21228 solver.cpp:237]     Train net output #1: loss = 0.0191317 (* 1 = 0.0191317 loss)
I1203 20:54:26.658776 21228 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1203 20:54:34.940592 21228 solver.cpp:218] Iteration 139800 (12.0762 iter/s, 8.28077s/100 iters), loss = 0.0122943
I1203 20:54:34.940592 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:54:34.940592 21228 solver.cpp:237]     Train net output #1: loss = 0.0122942 (* 1 = 0.0122942 loss)
I1203 20:54:34.940592 21228 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1203 20:54:43.244652 21228 solver.cpp:218] Iteration 139900 (12.0431 iter/s, 8.30354s/100 iters), loss = 0.0101609
I1203 20:54:43.244652 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:54:43.245152 21228 solver.cpp:237]     Train net output #1: loss = 0.0101608 (* 1 = 0.0101608 loss)
I1203 20:54:43.245152 21228 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1203 20:54:51.136427 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:54:51.465467 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.caffemodel
I1203 20:54:51.507467 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.solverstate
I1203 20:54:51.515467 21228 solver.cpp:330] Iteration 140000, Testing net (#0)
I1203 20:54:51.515467 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:54:53.239612 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:54:53.307620 21228 solver.cpp:397]     Test net output #0: accuracy = 0.936
I1203 20:54:53.307620 21228 solver.cpp:397]     Test net output #1: loss = 0.247892 (* 1 = 0.247892 loss)
I1203 20:54:53.381625 21228 solver.cpp:218] Iteration 140000 (9.86525 iter/s, 10.1366s/100 iters), loss = 0.0161477
I1203 20:54:53.381625 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:54:53.381625 21228 solver.cpp:237]     Train net output #1: loss = 0.0161476 (* 1 = 0.0161476 loss)
I1203 20:54:53.381625 21228 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1203 20:55:01.731153 21228 solver.cpp:218] Iteration 140100 (11.9784 iter/s, 8.34837s/100 iters), loss = 0.0159051
I1203 20:55:01.731153 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:01.731153 21228 solver.cpp:237]     Train net output #1: loss = 0.0159051 (* 1 = 0.0159051 loss)
I1203 20:55:01.731153 21228 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1203 20:55:10.038975 21228 solver.cpp:218] Iteration 140200 (12.0373 iter/s, 8.30752s/100 iters), loss = 0.0122218
I1203 20:55:10.038975 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:10.038975 21228 solver.cpp:237]     Train net output #1: loss = 0.0122217 (* 1 = 0.0122217 loss)
I1203 20:55:10.038975 21228 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1203 20:55:18.334879 21228 solver.cpp:218] Iteration 140300 (12.0542 iter/s, 8.29587s/100 iters), loss = 0.0105317
I1203 20:55:18.335878 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:18.335878 21228 solver.cpp:237]     Train net output #1: loss = 0.0105316 (* 1 = 0.0105316 loss)
I1203 20:55:18.335878 21228 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1203 20:55:26.854104 21228 solver.cpp:218] Iteration 140400 (11.7389 iter/s, 8.51868s/100 iters), loss = 0.0143456
I1203 20:55:26.855104 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:26.855104 21228 solver.cpp:237]     Train net output #1: loss = 0.0143456 (* 1 = 0.0143456 loss)
I1203 20:55:26.855104 21228 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1203 20:55:34.808043 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:55:35.141620 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.caffemodel
I1203 20:55:35.173127 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.solverstate
I1203 20:55:35.180133 21228 solver.cpp:330] Iteration 140500, Testing net (#0)
I1203 20:55:35.180133 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:55:36.902884 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:55:36.973398 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9369
I1203 20:55:36.973398 21228 solver.cpp:397]     Test net output #1: loss = 0.243726 (* 1 = 0.243726 loss)
I1203 20:55:37.050904 21228 solver.cpp:218] Iteration 140500 (9.80791 iter/s, 10.1958s/100 iters), loss = 0.0125621
I1203 20:55:37.050904 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:37.050904 21228 solver.cpp:237]     Train net output #1: loss = 0.012562 (* 1 = 0.012562 loss)
I1203 20:55:37.050904 21228 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1203 20:55:45.395133 21228 solver.cpp:218] Iteration 140600 (11.9858 iter/s, 8.34322s/100 iters), loss = 0.0204788
I1203 20:55:45.395133 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:45.395133 21228 solver.cpp:237]     Train net output #1: loss = 0.0204787 (* 1 = 0.0204787 loss)
I1203 20:55:45.395133 21228 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1203 20:55:53.677245 21228 solver.cpp:218] Iteration 140700 (12.0749 iter/s, 8.28164s/100 iters), loss = 0.0186996
I1203 20:55:53.677245 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:55:53.677245 21228 solver.cpp:237]     Train net output #1: loss = 0.0186995 (* 1 = 0.0186995 loss)
I1203 20:55:53.677245 21228 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1203 20:56:02.115772 21228 solver.cpp:218] Iteration 140800 (11.8502 iter/s, 8.4387s/100 iters), loss = 0.0161291
I1203 20:56:02.115772 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:02.115772 21228 solver.cpp:237]     Train net output #1: loss = 0.016129 (* 1 = 0.016129 loss)
I1203 20:56:02.115772 21228 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1203 20:56:10.425331 21228 solver.cpp:218] Iteration 140900 (12.035 iter/s, 8.30906s/100 iters), loss = 0.013007
I1203 20:56:10.425331 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:10.426332 21228 solver.cpp:237]     Train net output #1: loss = 0.013007 (* 1 = 0.013007 loss)
I1203 20:56:10.426332 21228 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1203 20:56:18.294163 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:56:18.626176 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.caffemodel
I1203 20:56:18.664176 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.solverstate
I1203 20:56:18.671185 21228 solver.cpp:330] Iteration 141000, Testing net (#0)
I1203 20:56:18.671185 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:56:20.427254 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:56:20.497488 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1203 20:56:20.497987 21228 solver.cpp:397]     Test net output #1: loss = 0.248168 (* 1 = 0.248168 loss)
I1203 20:56:20.577486 21228 solver.cpp:218] Iteration 141000 (9.85139 iter/s, 10.1509s/100 iters), loss = 0.0115737
I1203 20:56:20.577486 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:20.577486 21228 solver.cpp:237]     Train net output #1: loss = 0.0115736 (* 1 = 0.0115736 loss)
I1203 20:56:20.577486 21228 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1203 20:56:28.977414 21228 solver.cpp:218] Iteration 141100 (11.9053 iter/s, 8.39964s/100 iters), loss = 0.0187213
I1203 20:56:28.977916 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:28.977916 21228 solver.cpp:237]     Train net output #1: loss = 0.0187213 (* 1 = 0.0187213 loss)
I1203 20:56:28.977916 21228 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1203 20:56:37.319350 21228 solver.cpp:218] Iteration 141200 (11.9883 iter/s, 8.34146s/100 iters), loss = 0.011147
I1203 20:56:37.319350 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:37.319350 21228 solver.cpp:237]     Train net output #1: loss = 0.011147 (* 1 = 0.011147 loss)
I1203 20:56:37.319350 21228 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1203 20:56:45.584472 21228 solver.cpp:218] Iteration 141300 (12.1001 iter/s, 8.26441s/100 iters), loss = 0.0109919
I1203 20:56:45.584975 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:45.584975 21228 solver.cpp:237]     Train net output #1: loss = 0.0109919 (* 1 = 0.0109919 loss)
I1203 20:56:45.584975 21228 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1203 20:56:53.994633 21228 solver.cpp:218] Iteration 141400 (11.8918 iter/s, 8.40918s/100 iters), loss = 0.0107469
I1203 20:56:53.994633 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:56:53.994633 21228 solver.cpp:237]     Train net output #1: loss = 0.0107468 (* 1 = 0.0107468 loss)
I1203 20:56:53.994633 21228 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1203 20:57:01.883503 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:57:02.209758 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.caffemodel
I1203 20:57:02.242769 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.solverstate
I1203 20:57:02.250761 21228 solver.cpp:330] Iteration 141500, Testing net (#0)
I1203 20:57:02.250761 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:57:03.961530 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:57:04.030555 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1203 20:57:04.030555 21228 solver.cpp:397]     Test net output #1: loss = 0.250034 (* 1 = 0.250034 loss)
I1203 20:57:04.108587 21228 solver.cpp:218] Iteration 141500 (9.88777 iter/s, 10.1135s/100 iters), loss = 0.0103094
I1203 20:57:04.108587 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:57:04.108587 21228 solver.cpp:237]     Train net output #1: loss = 0.0103093 (* 1 = 0.0103093 loss)
I1203 20:57:04.108587 21228 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1203 20:57:12.413952 21228 solver.cpp:218] Iteration 141600 (12.0406 iter/s, 8.30523s/100 iters), loss = 0.0446605
I1203 20:57:12.413952 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:57:12.413952 21228 solver.cpp:237]     Train net output #1: loss = 0.0446605 (* 1 = 0.0446605 loss)
I1203 20:57:12.413952 21228 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1203 20:57:20.811975 21228 solver.cpp:218] Iteration 141700 (11.9089 iter/s, 8.39705s/100 iters), loss = 0.0126014
I1203 20:57:20.811975 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:57:20.811975 21228 solver.cpp:237]     Train net output #1: loss = 0.0126013 (* 1 = 0.0126013 loss)
I1203 20:57:20.811975 21228 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1203 20:57:29.133738 21228 solver.cpp:218] Iteration 141800 (12.0171 iter/s, 8.32148s/100 iters), loss = 0.0115071
I1203 20:57:29.133738 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:57:29.133738 21228 solver.cpp:237]     Train net output #1: loss = 0.011507 (* 1 = 0.011507 loss)
I1203 20:57:29.133738 21228 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1203 20:57:37.468327 21228 solver.cpp:218] Iteration 141900 (11.9988 iter/s, 8.33416s/100 iters), loss = 0.0122299
I1203 20:57:37.468327 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:57:37.468327 21228 solver.cpp:237]     Train net output #1: loss = 0.0122299 (* 1 = 0.0122299 loss)
I1203 20:57:37.468327 21228 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1203 20:57:45.376422 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:57:45.707625 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.caffemodel
I1203 20:57:45.749625 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.solverstate
I1203 20:57:45.756625 21228 solver.cpp:330] Iteration 142000, Testing net (#0)
I1203 20:57:45.756625 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:57:47.477321 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:57:47.543822 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1203 20:57:47.543822 21228 solver.cpp:397]     Test net output #1: loss = 0.247317 (* 1 = 0.247317 loss)
I1203 20:57:47.617321 21228 solver.cpp:218] Iteration 142000 (9.85413 iter/s, 10.148s/100 iters), loss = 0.0191021
I1203 20:57:47.617821 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:57:47.617821 21228 solver.cpp:237]     Train net output #1: loss = 0.019102 (* 1 = 0.019102 loss)
I1203 20:57:47.617821 21228 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1203 20:57:55.933109 21228 solver.cpp:218] Iteration 142100 (12.0265 iter/s, 8.31499s/100 iters), loss = 0.0240512
I1203 20:57:55.933109 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:57:55.933109 21228 solver.cpp:237]     Train net output #1: loss = 0.0240511 (* 1 = 0.0240511 loss)
I1203 20:57:55.933109 21228 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1203 20:58:04.295929 21228 solver.cpp:218] Iteration 142200 (11.9582 iter/s, 8.36245s/100 iters), loss = 0.0163356
I1203 20:58:04.295929 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:04.295929 21228 solver.cpp:237]     Train net output #1: loss = 0.0163355 (* 1 = 0.0163355 loss)
I1203 20:58:04.295929 21228 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1203 20:58:12.591086 21228 solver.cpp:218] Iteration 142300 (12.0562 iter/s, 8.29449s/100 iters), loss = 0.0180878
I1203 20:58:12.591086 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:12.591086 21228 solver.cpp:237]     Train net output #1: loss = 0.0180877 (* 1 = 0.0180877 loss)
I1203 20:58:12.591086 21228 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1203 20:58:20.867796 21228 solver.cpp:218] Iteration 142400 (12.0821 iter/s, 8.27669s/100 iters), loss = 0.0108283
I1203 20:58:20.867796 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:20.867796 21228 solver.cpp:237]     Train net output #1: loss = 0.0108282 (* 1 = 0.0108282 loss)
I1203 20:58:20.867796 21228 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1203 20:58:28.737406 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:58:29.070443 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.caffemodel
I1203 20:58:29.115063 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.solverstate
I1203 20:58:29.122063 21228 solver.cpp:330] Iteration 142500, Testing net (#0)
I1203 20:58:29.122063 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:58:30.826783 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:58:30.896286 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9375
I1203 20:58:30.896286 21228 solver.cpp:397]     Test net output #1: loss = 0.244048 (* 1 = 0.244048 loss)
I1203 20:58:30.973788 21228 solver.cpp:218] Iteration 142500 (9.89613 iter/s, 10.105s/100 iters), loss = 0.0149073
I1203 20:58:30.973788 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:30.973788 21228 solver.cpp:237]     Train net output #1: loss = 0.0149073 (* 1 = 0.0149073 loss)
I1203 20:58:30.973788 21228 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1203 20:58:39.247567 21228 solver.cpp:218] Iteration 142600 (12.0868 iter/s, 8.27352s/100 iters), loss = 0.0109657
I1203 20:58:39.247567 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:39.247567 21228 solver.cpp:237]     Train net output #1: loss = 0.0109656 (* 1 = 0.0109656 loss)
I1203 20:58:39.247567 21228 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1203 20:58:47.522356 21228 solver.cpp:218] Iteration 142700 (12.0856 iter/s, 8.27433s/100 iters), loss = 0.0162777
I1203 20:58:47.522356 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:47.522356 21228 solver.cpp:237]     Train net output #1: loss = 0.0162777 (* 1 = 0.0162777 loss)
I1203 20:58:47.522356 21228 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1203 20:58:55.791746 21228 solver.cpp:218] Iteration 142800 (12.0942 iter/s, 8.26845s/100 iters), loss = 0.0165869
I1203 20:58:55.791746 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:58:55.791746 21228 solver.cpp:237]     Train net output #1: loss = 0.0165868 (* 1 = 0.0165868 loss)
I1203 20:58:55.791746 21228 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1203 20:59:04.053567 21228 solver.cpp:218] Iteration 142900 (12.1034 iter/s, 8.26214s/100 iters), loss = 0.0101125
I1203 20:59:04.054569 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:59:04.054569 21228 solver.cpp:237]     Train net output #1: loss = 0.0101125 (* 1 = 0.0101125 loss)
I1203 20:59:04.054569 21228 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1203 20:59:11.914182 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:59:12.240211 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.caffemodel
I1203 20:59:12.268210 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.solverstate
I1203 20:59:12.275209 21228 solver.cpp:330] Iteration 143000, Testing net (#0)
I1203 20:59:12.275209 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:59:14.006165 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:59:14.074172 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9358
I1203 20:59:14.074172 21228 solver.cpp:397]     Test net output #1: loss = 0.244512 (* 1 = 0.244512 loss)
I1203 20:59:14.152182 21228 solver.cpp:218] Iteration 143000 (9.90382 iter/s, 10.0971s/100 iters), loss = 0.0208615
I1203 20:59:14.152182 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 20:59:14.152182 21228 solver.cpp:237]     Train net output #1: loss = 0.0208614 (* 1 = 0.0208614 loss)
I1203 20:59:14.152182 21228 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1203 20:59:22.429661 21228 solver.cpp:218] Iteration 143100 (12.0813 iter/s, 8.27724s/100 iters), loss = 0.0135401
I1203 20:59:22.429661 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:59:22.429661 21228 solver.cpp:237]     Train net output #1: loss = 0.01354 (* 1 = 0.01354 loss)
I1203 20:59:22.429661 21228 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1203 20:59:30.693841 21228 solver.cpp:218] Iteration 143200 (12.1012 iter/s, 8.26361s/100 iters), loss = 0.014099
I1203 20:59:30.693841 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:59:30.693841 21228 solver.cpp:237]     Train net output #1: loss = 0.0140989 (* 1 = 0.0140989 loss)
I1203 20:59:30.693841 21228 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1203 20:59:38.968473 21228 solver.cpp:218] Iteration 143300 (12.0863 iter/s, 8.27384s/100 iters), loss = 0.0110286
I1203 20:59:38.968473 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:59:38.968473 21228 solver.cpp:237]     Train net output #1: loss = 0.0110286 (* 1 = 0.0110286 loss)
I1203 20:59:38.968473 21228 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1203 20:59:47.250578 21228 solver.cpp:218] Iteration 143400 (12.0744 iter/s, 8.28197s/100 iters), loss = 0.0135598
I1203 20:59:47.250578 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:59:47.250578 21228 solver.cpp:237]     Train net output #1: loss = 0.0135597 (* 1 = 0.0135597 loss)
I1203 20:59:47.250578 21228 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1203 20:59:55.098032 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:59:55.427561 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.caffemodel
I1203 20:59:55.469060 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.solverstate
I1203 20:59:55.477061 21228 solver.cpp:330] Iteration 143500, Testing net (#0)
I1203 20:59:55.477061 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 20:59:57.187130 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 20:59:57.256201 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1203 20:59:57.256201 21228 solver.cpp:397]     Test net output #1: loss = 0.248273 (* 1 = 0.248273 loss)
I1203 20:59:57.334218 21228 solver.cpp:218] Iteration 143500 (9.91781 iter/s, 10.0829s/100 iters), loss = 0.0151534
I1203 20:59:57.334218 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 20:59:57.334218 21228 solver.cpp:237]     Train net output #1: loss = 0.0151533 (* 1 = 0.0151533 loss)
I1203 20:59:57.334218 21228 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1203 21:00:05.623643 21228 solver.cpp:218] Iteration 143600 (12.0649 iter/s, 8.28853s/100 iters), loss = 0.012293
I1203 21:00:05.623643 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:00:05.623643 21228 solver.cpp:237]     Train net output #1: loss = 0.0122929 (* 1 = 0.0122929 loss)
I1203 21:00:05.623643 21228 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1203 21:00:13.915033 21228 solver.cpp:218] Iteration 143700 (12.0602 iter/s, 8.29171s/100 iters), loss = 0.024478
I1203 21:00:13.915033 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:00:13.915033 21228 solver.cpp:237]     Train net output #1: loss = 0.024478 (* 1 = 0.024478 loss)
I1203 21:00:13.916034 21228 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1203 21:00:22.183845 21228 solver.cpp:218] Iteration 143800 (12.0958 iter/s, 8.26733s/100 iters), loss = 0.0115828
I1203 21:00:22.183845 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:00:22.183845 21228 solver.cpp:237]     Train net output #1: loss = 0.0115828 (* 1 = 0.0115828 loss)
I1203 21:00:22.183845 21228 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1203 21:00:30.421296 21228 solver.cpp:218] Iteration 143900 (12.1401 iter/s, 8.23717s/100 iters), loss = 0.0138186
I1203 21:00:30.421296 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:00:30.421296 21228 solver.cpp:237]     Train net output #1: loss = 0.0138185 (* 1 = 0.0138185 loss)
I1203 21:00:30.421296 21228 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1203 21:00:38.288187 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:00:38.609215 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.caffemodel
I1203 21:00:38.651224 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.solverstate
I1203 21:00:38.657225 21228 solver.cpp:330] Iteration 144000, Testing net (#0)
I1203 21:00:38.658224 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:00:40.380942 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:00:40.450443 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9356
I1203 21:00:40.450443 21228 solver.cpp:397]     Test net output #1: loss = 0.247923 (* 1 = 0.247923 loss)
I1203 21:00:40.528448 21228 solver.cpp:218] Iteration 144000 (9.89451 iter/s, 10.1066s/100 iters), loss = 0.0144684
I1203 21:00:40.528949 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:00:40.528949 21228 solver.cpp:237]     Train net output #1: loss = 0.0144684 (* 1 = 0.0144684 loss)
I1203 21:00:40.528949 21228 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1203 21:00:48.791008 21228 solver.cpp:218] Iteration 144100 (12.104 iter/s, 8.26176s/100 iters), loss = 0.0319286
I1203 21:00:48.791008 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:00:48.791008 21228 solver.cpp:237]     Train net output #1: loss = 0.0319285 (* 1 = 0.0319285 loss)
I1203 21:00:48.791008 21228 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1203 21:00:57.048358 21228 solver.cpp:218] Iteration 144200 (12.1113 iter/s, 8.25678s/100 iters), loss = 0.0156582
I1203 21:00:57.048358 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:00:57.048358 21228 solver.cpp:237]     Train net output #1: loss = 0.0156581 (* 1 = 0.0156581 loss)
I1203 21:00:57.048358 21228 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1203 21:01:05.325515 21228 solver.cpp:218] Iteration 144300 (12.0821 iter/s, 8.27671s/100 iters), loss = 0.0126914
I1203 21:01:05.325515 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:05.325515 21228 solver.cpp:237]     Train net output #1: loss = 0.0126914 (* 1 = 0.0126914 loss)
I1203 21:01:05.325515 21228 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1203 21:01:13.588464 21228 solver.cpp:218] Iteration 144400 (12.1025 iter/s, 8.26278s/100 iters), loss = 0.0116182
I1203 21:01:13.588464 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:13.588464 21228 solver.cpp:237]     Train net output #1: loss = 0.0116181 (* 1 = 0.0116181 loss)
I1203 21:01:13.588464 21228 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1203 21:01:21.429924 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:01:21.758101 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.caffemodel
I1203 21:01:21.790099 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.solverstate
I1203 21:01:21.797102 21228 solver.cpp:330] Iteration 144500, Testing net (#0)
I1203 21:01:21.797102 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:01:23.519364 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:01:23.585377 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1203 21:01:23.585377 21228 solver.cpp:397]     Test net output #1: loss = 0.251807 (* 1 = 0.251807 loss)
I1203 21:01:23.660398 21228 solver.cpp:218] Iteration 144500 (9.92915 iter/s, 10.0714s/100 iters), loss = 0.0124206
I1203 21:01:23.660398 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:23.660398 21228 solver.cpp:237]     Train net output #1: loss = 0.0124205 (* 1 = 0.0124205 loss)
I1203 21:01:23.660398 21228 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1203 21:01:31.946362 21228 solver.cpp:218] Iteration 144600 (12.0705 iter/s, 8.28465s/100 iters), loss = 0.0151828
I1203 21:01:31.946362 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:31.946362 21228 solver.cpp:237]     Train net output #1: loss = 0.0151828 (* 1 = 0.0151828 loss)
I1203 21:01:31.946362 21228 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1203 21:01:40.217620 21228 solver.cpp:218] Iteration 144700 (12.0909 iter/s, 8.27069s/100 iters), loss = 0.0100953
I1203 21:01:40.217620 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:40.217620 21228 solver.cpp:237]     Train net output #1: loss = 0.0100952 (* 1 = 0.0100952 loss)
I1203 21:01:40.217620 21228 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1203 21:01:48.483145 21228 solver.cpp:218] Iteration 144800 (12.0997 iter/s, 8.26467s/100 iters), loss = 0.00994346
I1203 21:01:48.483145 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:48.483145 21228 solver.cpp:237]     Train net output #1: loss = 0.00994338 (* 1 = 0.00994338 loss)
I1203 21:01:48.483145 21228 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1203 21:01:56.747514 21228 solver.cpp:218] Iteration 144900 (12.1003 iter/s, 8.26426s/100 iters), loss = 0.0145998
I1203 21:01:56.747514 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:01:56.748015 21228 solver.cpp:237]     Train net output #1: loss = 0.0145997 (* 1 = 0.0145997 loss)
I1203 21:01:56.748015 21228 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1203 21:02:04.627341 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:02:04.957887 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.caffemodel
I1203 21:02:05.000391 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.solverstate
I1203 21:02:05.007391 21228 solver.cpp:330] Iteration 145000, Testing net (#0)
I1203 21:02:05.007391 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:02:06.716104 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:02:06.784111 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1203 21:02:06.784111 21228 solver.cpp:397]     Test net output #1: loss = 0.249673 (* 1 = 0.249673 loss)
I1203 21:02:06.861114 21228 solver.cpp:218] Iteration 145000 (9.88831 iter/s, 10.113s/100 iters), loss = 0.0143164
I1203 21:02:06.861615 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:02:06.861615 21228 solver.cpp:237]     Train net output #1: loss = 0.0143164 (* 1 = 0.0143164 loss)
I1203 21:02:06.861615 21228 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1203 21:02:15.113746 21228 solver.cpp:218] Iteration 145100 (12.1182 iter/s, 8.25204s/100 iters), loss = 0.011606
I1203 21:02:15.113746 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:02:15.113746 21228 solver.cpp:237]     Train net output #1: loss = 0.0116059 (* 1 = 0.0116059 loss)
I1203 21:02:15.113746 21228 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1203 21:02:23.397730 21228 solver.cpp:218] Iteration 145200 (12.0729 iter/s, 8.28298s/100 iters), loss = 0.0116265
I1203 21:02:23.397730 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:02:23.397730 21228 solver.cpp:237]     Train net output #1: loss = 0.0116264 (* 1 = 0.0116264 loss)
I1203 21:02:23.397730 21228 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1203 21:02:31.681637 21228 solver.cpp:218] Iteration 145300 (12.0718 iter/s, 8.2838s/100 iters), loss = 0.00880259
I1203 21:02:31.681637 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:02:31.681637 21228 solver.cpp:237]     Train net output #1: loss = 0.00880252 (* 1 = 0.00880252 loss)
I1203 21:02:31.681637 21228 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1203 21:02:39.932720 21228 solver.cpp:218] Iteration 145400 (12.1202 iter/s, 8.25071s/100 iters), loss = 0.0123936
I1203 21:02:39.932720 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:02:39.932720 21228 solver.cpp:237]     Train net output #1: loss = 0.0123935 (* 1 = 0.0123935 loss)
I1203 21:02:39.932720 21228 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1203 21:02:47.808187 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:02:48.131640 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.caffemodel
I1203 21:02:48.165644 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.solverstate
I1203 21:02:48.171655 21228 solver.cpp:330] Iteration 145500, Testing net (#0)
I1203 21:02:48.172144 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:02:49.901309 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:02:49.970314 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1203 21:02:49.970314 21228 solver.cpp:397]     Test net output #1: loss = 0.248374 (* 1 = 0.248374 loss)
I1203 21:02:50.047317 21228 solver.cpp:218] Iteration 145500 (9.88782 iter/s, 10.1135s/100 iters), loss = 0.0173288
I1203 21:02:50.047317 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:02:50.047317 21228 solver.cpp:237]     Train net output #1: loss = 0.0173287 (* 1 = 0.0173287 loss)
I1203 21:02:50.047317 21228 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1203 21:02:58.308197 21228 solver.cpp:218] Iteration 145600 (12.1057 iter/s, 8.26057s/100 iters), loss = 0.0311295
I1203 21:02:58.308197 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:02:58.308197 21228 solver.cpp:237]     Train net output #1: loss = 0.0311295 (* 1 = 0.0311295 loss)
I1203 21:02:58.308197 21228 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1203 21:03:06.579551 21228 solver.cpp:218] Iteration 145700 (12.0907 iter/s, 8.27079s/100 iters), loss = 0.0114887
I1203 21:03:06.579551 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:06.579551 21228 solver.cpp:237]     Train net output #1: loss = 0.0114886 (* 1 = 0.0114886 loss)
I1203 21:03:06.579551 21228 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1203 21:03:14.849269 21228 solver.cpp:218] Iteration 145800 (12.0938 iter/s, 8.2687s/100 iters), loss = 0.012771
I1203 21:03:14.849269 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:14.849269 21228 solver.cpp:237]     Train net output #1: loss = 0.0127709 (* 1 = 0.0127709 loss)
I1203 21:03:14.849269 21228 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1203 21:03:23.135454 21228 solver.cpp:218] Iteration 145900 (12.0683 iter/s, 8.28614s/100 iters), loss = 0.0094624
I1203 21:03:23.135454 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:23.135454 21228 solver.cpp:237]     Train net output #1: loss = 0.00946233 (* 1 = 0.00946233 loss)
I1203 21:03:23.135454 21228 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1203 21:03:30.985121 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:03:31.317163 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.caffemodel
I1203 21:03:31.360163 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.solverstate
I1203 21:03:31.367163 21228 solver.cpp:330] Iteration 146000, Testing net (#0)
I1203 21:03:31.367163 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:03:33.075609 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:03:33.144632 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9356
I1203 21:03:33.144632 21228 solver.cpp:397]     Test net output #1: loss = 0.248149 (* 1 = 0.248149 loss)
I1203 21:03:33.221328 21228 solver.cpp:218] Iteration 146000 (9.91568 iter/s, 10.085s/100 iters), loss = 0.0160397
I1203 21:03:33.221328 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:33.221328 21228 solver.cpp:237]     Train net output #1: loss = 0.0160396 (* 1 = 0.0160396 loss)
I1203 21:03:33.221328 21228 sgd_solver.cpp:105] Iteration 146000, lr = 0.001
I1203 21:03:41.488620 21228 solver.cpp:218] Iteration 146100 (12.096 iter/s, 8.2672s/100 iters), loss = 0.0170427
I1203 21:03:41.488620 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:41.488620 21228 solver.cpp:237]     Train net output #1: loss = 0.0170426 (* 1 = 0.0170426 loss)
I1203 21:03:41.488620 21228 sgd_solver.cpp:105] Iteration 146100, lr = 0.001
I1203 21:03:49.739660 21228 solver.cpp:218] Iteration 146200 (12.1212 iter/s, 8.25004s/100 iters), loss = 0.0256088
I1203 21:03:49.739660 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:49.739660 21228 solver.cpp:237]     Train net output #1: loss = 0.0256087 (* 1 = 0.0256087 loss)
I1203 21:03:49.739660 21228 sgd_solver.cpp:105] Iteration 146200, lr = 0.001
I1203 21:03:57.993754 21228 solver.cpp:218] Iteration 146300 (12.1164 iter/s, 8.25327s/100 iters), loss = 0.00827446
I1203 21:03:57.993754 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:03:57.993754 21228 solver.cpp:237]     Train net output #1: loss = 0.00827438 (* 1 = 0.00827438 loss)
I1203 21:03:57.993754 21228 sgd_solver.cpp:105] Iteration 146300, lr = 0.001
I1203 21:04:06.249902 21228 solver.cpp:218] Iteration 146400 (12.1123 iter/s, 8.25606s/100 iters), loss = 0.0105054
I1203 21:04:06.250901 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:06.250901 21228 solver.cpp:237]     Train net output #1: loss = 0.0105053 (* 1 = 0.0105053 loss)
I1203 21:04:06.250901 21228 sgd_solver.cpp:105] Iteration 146400, lr = 0.001
I1203 21:04:14.124650 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:04:14.444183 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146500.caffemodel
I1203 21:04:14.485183 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146500.solverstate
I1203 21:04:14.492182 21228 solver.cpp:330] Iteration 146500, Testing net (#0)
I1203 21:04:14.492182 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:04:16.210667 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:04:16.278681 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9358
I1203 21:04:16.279683 21228 solver.cpp:397]     Test net output #1: loss = 0.250009 (* 1 = 0.250009 loss)
I1203 21:04:16.355702 21228 solver.cpp:218] Iteration 146500 (9.89626 iter/s, 10.1048s/100 iters), loss = 0.0145232
I1203 21:04:16.355702 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:16.355702 21228 solver.cpp:237]     Train net output #1: loss = 0.0145231 (* 1 = 0.0145231 loss)
I1203 21:04:16.355702 21228 sgd_solver.cpp:105] Iteration 146500, lr = 0.001
I1203 21:04:24.614156 21228 solver.cpp:218] Iteration 146600 (12.1097 iter/s, 8.25782s/100 iters), loss = 0.0154837
I1203 21:04:24.614655 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:24.614655 21228 solver.cpp:237]     Train net output #1: loss = 0.0154836 (* 1 = 0.0154836 loss)
I1203 21:04:24.614655 21228 sgd_solver.cpp:105] Iteration 146600, lr = 0.001
I1203 21:04:32.855391 21228 solver.cpp:218] Iteration 146700 (12.1355 iter/s, 8.24028s/100 iters), loss = 0.0124545
I1203 21:04:32.855391 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:32.855391 21228 solver.cpp:237]     Train net output #1: loss = 0.0124544 (* 1 = 0.0124544 loss)
I1203 21:04:32.855391 21228 sgd_solver.cpp:105] Iteration 146700, lr = 0.001
I1203 21:04:41.136320 21228 solver.cpp:218] Iteration 146800 (12.0768 iter/s, 8.28035s/100 iters), loss = 0.0125592
I1203 21:04:41.136320 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:41.136320 21228 solver.cpp:237]     Train net output #1: loss = 0.0125591 (* 1 = 0.0125591 loss)
I1203 21:04:41.136320 21228 sgd_solver.cpp:105] Iteration 146800, lr = 0.001
I1203 21:04:49.414629 21228 solver.cpp:218] Iteration 146900 (12.0802 iter/s, 8.27799s/100 iters), loss = 0.0110604
I1203 21:04:49.414629 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:49.414629 21228 solver.cpp:237]     Train net output #1: loss = 0.0110603 (* 1 = 0.0110603 loss)
I1203 21:04:49.414629 21228 sgd_solver.cpp:105] Iteration 146900, lr = 0.001
I1203 21:04:57.263492 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:04:57.594537 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147000.caffemodel
I1203 21:04:57.628545 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147000.solverstate
I1203 21:04:57.636543 21228 solver.cpp:330] Iteration 147000, Testing net (#0)
I1203 21:04:57.636543 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:04:59.359853 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:04:59.427848 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1203 21:04:59.427848 21228 solver.cpp:397]     Test net output #1: loss = 0.246858 (* 1 = 0.246858 loss)
I1203 21:04:59.502851 21228 solver.cpp:218] Iteration 147000 (9.91339 iter/s, 10.0874s/100 iters), loss = 0.0109257
I1203 21:04:59.502851 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:04:59.502851 21228 solver.cpp:237]     Train net output #1: loss = 0.0109256 (* 1 = 0.0109256 loss)
I1203 21:04:59.502851 21228 sgd_solver.cpp:105] Iteration 147000, lr = 0.001
I1203 21:05:07.774338 21228 solver.cpp:218] Iteration 147100 (12.0896 iter/s, 8.27158s/100 iters), loss = 0.0128765
I1203 21:05:07.774338 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:07.774338 21228 solver.cpp:237]     Train net output #1: loss = 0.0128764 (* 1 = 0.0128764 loss)
I1203 21:05:07.774338 21228 sgd_solver.cpp:105] Iteration 147100, lr = 0.001
I1203 21:05:16.026963 21228 solver.cpp:218] Iteration 147200 (12.1179 iter/s, 8.25229s/100 iters), loss = 0.0134188
I1203 21:05:16.027964 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:16.027964 21228 solver.cpp:237]     Train net output #1: loss = 0.0134188 (* 1 = 0.0134188 loss)
I1203 21:05:16.027964 21228 sgd_solver.cpp:105] Iteration 147200, lr = 0.001
I1203 21:05:24.285831 21228 solver.cpp:218] Iteration 147300 (12.1099 iter/s, 8.2577s/100 iters), loss = 0.0102605
I1203 21:05:24.285831 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:24.285831 21228 solver.cpp:237]     Train net output #1: loss = 0.0102604 (* 1 = 0.0102604 loss)
I1203 21:05:24.285831 21228 sgd_solver.cpp:105] Iteration 147300, lr = 0.001
I1203 21:05:32.568488 21228 solver.cpp:218] Iteration 147400 (12.0735 iter/s, 8.28263s/100 iters), loss = 0.0140186
I1203 21:05:32.568488 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:32.568488 21228 solver.cpp:237]     Train net output #1: loss = 0.0140185 (* 1 = 0.0140185 loss)
I1203 21:05:32.568488 21228 sgd_solver.cpp:105] Iteration 147400, lr = 0.001
I1203 21:05:40.432535 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:05:40.760581 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147500.caffemodel
I1203 21:05:40.803584 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147500.solverstate
I1203 21:05:40.810084 21228 solver.cpp:330] Iteration 147500, Testing net (#0)
I1203 21:05:40.810084 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:05:42.520031 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:05:42.588030 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1203 21:05:42.588030 21228 solver.cpp:397]     Test net output #1: loss = 0.248987 (* 1 = 0.248987 loss)
I1203 21:05:42.668051 21228 solver.cpp:218] Iteration 147500 (9.90253 iter/s, 10.0984s/100 iters), loss = 0.0117621
I1203 21:05:42.668051 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:42.668051 21228 solver.cpp:237]     Train net output #1: loss = 0.011762 (* 1 = 0.011762 loss)
I1203 21:05:42.668051 21228 sgd_solver.cpp:105] Iteration 147500, lr = 0.001
I1203 21:05:50.933387 21228 solver.cpp:218] Iteration 147600 (12.0991 iter/s, 8.26508s/100 iters), loss = 0.0126362
I1203 21:05:50.933387 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:50.933387 21228 solver.cpp:237]     Train net output #1: loss = 0.0126361 (* 1 = 0.0126361 loss)
I1203 21:05:50.933387 21228 sgd_solver.cpp:105] Iteration 147600, lr = 0.001
I1203 21:05:59.217664 21228 solver.cpp:218] Iteration 147700 (12.072 iter/s, 8.28363s/100 iters), loss = 0.0115723
I1203 21:05:59.218166 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:05:59.218166 21228 solver.cpp:237]     Train net output #1: loss = 0.0115722 (* 1 = 0.0115722 loss)
I1203 21:05:59.218166 21228 sgd_solver.cpp:105] Iteration 147700, lr = 0.001
I1203 21:06:07.500877 21228 solver.cpp:218] Iteration 147800 (12.0729 iter/s, 8.28302s/100 iters), loss = 0.00973097
I1203 21:06:07.500877 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:07.500877 21228 solver.cpp:237]     Train net output #1: loss = 0.00973089 (* 1 = 0.00973089 loss)
I1203 21:06:07.500877 21228 sgd_solver.cpp:105] Iteration 147800, lr = 0.001
I1203 21:06:15.762748 21228 solver.cpp:218] Iteration 147900 (12.1051 iter/s, 8.26098s/100 iters), loss = 0.0109528
I1203 21:06:15.762748 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:15.762748 21228 solver.cpp:237]     Train net output #1: loss = 0.0109527 (* 1 = 0.0109527 loss)
I1203 21:06:15.762748 21228 sgd_solver.cpp:105] Iteration 147900, lr = 0.001
I1203 21:06:23.638787 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:06:23.958405 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148000.caffemodel
I1203 21:06:23.998391 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148000.solverstate
I1203 21:06:24.005391 21228 solver.cpp:330] Iteration 148000, Testing net (#0)
I1203 21:06:24.005391 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:06:25.735220 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:06:25.803225 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1203 21:06:25.803225 21228 solver.cpp:397]     Test net output #1: loss = 0.247464 (* 1 = 0.247464 loss)
I1203 21:06:25.880265 21228 solver.cpp:218] Iteration 148000 (9.88438 iter/s, 10.117s/100 iters), loss = 0.0129969
I1203 21:06:25.880265 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:25.880265 21228 solver.cpp:237]     Train net output #1: loss = 0.0129968 (* 1 = 0.0129968 loss)
I1203 21:06:25.880265 21228 sgd_solver.cpp:105] Iteration 148000, lr = 0.001
I1203 21:06:34.125824 21228 solver.cpp:218] Iteration 148100 (12.129 iter/s, 8.24469s/100 iters), loss = 0.0174371
I1203 21:06:34.126323 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:34.126323 21228 solver.cpp:237]     Train net output #1: loss = 0.0174371 (* 1 = 0.0174371 loss)
I1203 21:06:34.126323 21228 sgd_solver.cpp:105] Iteration 148100, lr = 0.001
I1203 21:06:42.392608 21228 solver.cpp:218] Iteration 148200 (12.0974 iter/s, 8.26627s/100 iters), loss = 0.00942204
I1203 21:06:42.392608 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:42.392608 21228 solver.cpp:237]     Train net output #1: loss = 0.00942196 (* 1 = 0.00942196 loss)
I1203 21:06:42.392608 21228 sgd_solver.cpp:105] Iteration 148200, lr = 0.001
I1203 21:06:50.659229 21228 solver.cpp:218] Iteration 148300 (12.0971 iter/s, 8.26644s/100 iters), loss = 0.0196142
I1203 21:06:50.659229 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:50.659229 21228 solver.cpp:237]     Train net output #1: loss = 0.0196141 (* 1 = 0.0196141 loss)
I1203 21:06:50.659229 21228 sgd_solver.cpp:105] Iteration 148300, lr = 0.001
I1203 21:06:58.941527 21228 solver.cpp:218] Iteration 148400 (12.0755 iter/s, 8.28124s/100 iters), loss = 0.0121201
I1203 21:06:58.941527 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:06:58.941527 21228 solver.cpp:237]     Train net output #1: loss = 0.01212 (* 1 = 0.01212 loss)
I1203 21:06:58.941527 21228 sgd_solver.cpp:105] Iteration 148400, lr = 0.001
I1203 21:07:06.811414 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:07:07.142468 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148500.caffemodel
I1203 21:07:07.186470 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148500.solverstate
I1203 21:07:07.193472 21228 solver.cpp:330] Iteration 148500, Testing net (#0)
I1203 21:07:07.193472 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:07:08.903187 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:07:08.970695 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9361
I1203 21:07:08.970695 21228 solver.cpp:397]     Test net output #1: loss = 0.243996 (* 1 = 0.243996 loss)
I1203 21:07:09.047709 21228 solver.cpp:218] Iteration 148500 (9.89524 iter/s, 10.1059s/100 iters), loss = 0.0219649
I1203 21:07:09.047709 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:07:09.047709 21228 solver.cpp:237]     Train net output #1: loss = 0.0219648 (* 1 = 0.0219648 loss)
I1203 21:07:09.047709 21228 sgd_solver.cpp:105] Iteration 148500, lr = 0.001
I1203 21:07:17.326764 21228 solver.cpp:218] Iteration 148600 (12.0804 iter/s, 8.27784s/100 iters), loss = 0.019742
I1203 21:07:17.326764 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:07:17.326764 21228 solver.cpp:237]     Train net output #1: loss = 0.019742 (* 1 = 0.019742 loss)
I1203 21:07:17.326764 21228 sgd_solver.cpp:105] Iteration 148600, lr = 0.001
I1203 21:07:25.596683 21228 solver.cpp:218] Iteration 148700 (12.0924 iter/s, 8.26964s/100 iters), loss = 0.0159405
I1203 21:07:25.596683 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:07:25.596683 21228 solver.cpp:237]     Train net output #1: loss = 0.0159404 (* 1 = 0.0159404 loss)
I1203 21:07:25.596683 21228 sgd_solver.cpp:105] Iteration 148700, lr = 0.001
I1203 21:07:33.856184 21228 solver.cpp:218] Iteration 148800 (12.1082 iter/s, 8.25887s/100 iters), loss = 0.0258367
I1203 21:07:33.856184 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:07:33.856184 21228 solver.cpp:237]     Train net output #1: loss = 0.0258366 (* 1 = 0.0258366 loss)
I1203 21:07:33.856184 21228 sgd_solver.cpp:105] Iteration 148800, lr = 0.001
I1203 21:07:42.108222 21228 solver.cpp:218] Iteration 148900 (12.1194 iter/s, 8.25126s/100 iters), loss = 0.0105933
I1203 21:07:42.108222 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:07:42.108222 21228 solver.cpp:237]     Train net output #1: loss = 0.0105932 (* 1 = 0.0105932 loss)
I1203 21:07:42.108222 21228 sgd_solver.cpp:105] Iteration 148900, lr = 0.001
I1203 21:07:49.970791 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:07:50.296815 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149000.caffemodel
I1203 21:07:50.340320 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149000.solverstate
I1203 21:07:50.346825 21228 solver.cpp:330] Iteration 149000, Testing net (#0)
I1203 21:07:50.346825 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:07:52.059943 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:07:52.128942 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 21:07:52.128942 21228 solver.cpp:397]     Test net output #1: loss = 0.252533 (* 1 = 0.252533 loss)
I1203 21:07:52.205950 21228 solver.cpp:218] Iteration 149000 (9.90324 iter/s, 10.0977s/100 iters), loss = 0.0122697
I1203 21:07:52.206949 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:07:52.206949 21228 solver.cpp:237]     Train net output #1: loss = 0.0122696 (* 1 = 0.0122696 loss)
I1203 21:07:52.206949 21228 sgd_solver.cpp:105] Iteration 149000, lr = 0.001
I1203 21:08:00.471621 21228 solver.cpp:218] Iteration 149100 (12.1003 iter/s, 8.26424s/100 iters), loss = 0.0238877
I1203 21:08:00.471621 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:08:00.471621 21228 solver.cpp:237]     Train net output #1: loss = 0.0238877 (* 1 = 0.0238877 loss)
I1203 21:08:00.471621 21228 sgd_solver.cpp:105] Iteration 149100, lr = 0.001
I1203 21:08:08.725611 21228 solver.cpp:218] Iteration 149200 (12.1152 iter/s, 8.25409s/100 iters), loss = 0.0101191
I1203 21:08:08.725611 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:08:08.725611 21228 solver.cpp:237]     Train net output #1: loss = 0.010119 (* 1 = 0.010119 loss)
I1203 21:08:08.725611 21228 sgd_solver.cpp:105] Iteration 149200, lr = 0.001
I1203 21:08:17.010107 21228 solver.cpp:218] Iteration 149300 (12.0718 iter/s, 8.28377s/100 iters), loss = 0.0108809
I1203 21:08:17.010107 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:08:17.010107 21228 solver.cpp:237]     Train net output #1: loss = 0.0108809 (* 1 = 0.0108809 loss)
I1203 21:08:17.010107 21228 sgd_solver.cpp:105] Iteration 149300, lr = 0.001
I1203 21:08:25.268461 21228 solver.cpp:218] Iteration 149400 (12.1093 iter/s, 8.25815s/100 iters), loss = 0.0129042
I1203 21:08:25.268461 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:08:25.269443 21228 solver.cpp:237]     Train net output #1: loss = 0.0129041 (* 1 = 0.0129041 loss)
I1203 21:08:25.269443 21228 sgd_solver.cpp:105] Iteration 149400, lr = 0.001
I1203 21:08:33.116488 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:08:33.445533 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149500.caffemodel
I1203 21:08:33.477538 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149500.solverstate
I1203 21:08:33.484539 21228 solver.cpp:330] Iteration 149500, Testing net (#0)
I1203 21:08:33.484539 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:08:35.216182 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:08:35.283186 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9363
I1203 21:08:35.283186 21228 solver.cpp:397]     Test net output #1: loss = 0.245048 (* 1 = 0.245048 loss)
I1203 21:08:35.358192 21228 solver.cpp:218] Iteration 149500 (9.91175 iter/s, 10.089s/100 iters), loss = 0.013723
I1203 21:08:35.358192 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:08:35.358192 21228 solver.cpp:237]     Train net output #1: loss = 0.0137229 (* 1 = 0.0137229 loss)
I1203 21:08:35.358192 21228 sgd_solver.cpp:105] Iteration 149500, lr = 0.001
I1203 21:08:43.696209 21228 solver.cpp:218] Iteration 149600 (11.9942 iter/s, 8.33737s/100 iters), loss = 0.0114441
I1203 21:08:43.696209 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:08:43.696209 21228 solver.cpp:237]     Train net output #1: loss = 0.011444 (* 1 = 0.011444 loss)
I1203 21:08:43.696209 21228 sgd_solver.cpp:105] Iteration 149600, lr = 0.001
I1203 21:08:51.987093 21228 solver.cpp:218] Iteration 149700 (12.0626 iter/s, 8.29011s/100 iters), loss = 0.0149326
I1203 21:08:51.987093 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:08:51.987093 21228 solver.cpp:237]     Train net output #1: loss = 0.0149325 (* 1 = 0.0149325 loss)
I1203 21:08:51.987093 21228 sgd_solver.cpp:105] Iteration 149700, lr = 0.001
I1203 21:09:00.336140 21228 solver.cpp:218] Iteration 149800 (11.9788 iter/s, 8.34809s/100 iters), loss = 0.0115553
I1203 21:09:00.336140 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:09:00.336140 21228 solver.cpp:237]     Train net output #1: loss = 0.0115552 (* 1 = 0.0115552 loss)
I1203 21:09:00.336140 21228 sgd_solver.cpp:105] Iteration 149800, lr = 0.001
I1203 21:09:08.537629 21228 solver.cpp:218] Iteration 149900 (12.1939 iter/s, 8.20085s/100 iters), loss = 0.0122572
I1203 21:09:08.537629 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:09:08.537629 21228 solver.cpp:237]     Train net output #1: loss = 0.0122572 (* 1 = 0.0122572 loss)
I1203 21:09:08.537629 21228 sgd_solver.cpp:105] Iteration 149900, lr = 0.001
I1203 21:09:16.353998 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:09:16.682499 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150000.caffemodel
I1203 21:09:16.717998 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150000.solverstate
I1203 21:09:16.724998 21228 solver.cpp:330] Iteration 150000, Testing net (#0)
I1203 21:09:16.725497 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:09:18.470024 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:09:18.540524 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1203 21:09:18.540524 21228 solver.cpp:397]     Test net output #1: loss = 0.255496 (* 1 = 0.255496 loss)
I1203 21:09:18.618525 21228 solver.cpp:218] Iteration 150000 (9.92039 iter/s, 10.0803s/100 iters), loss = 0.0170789
I1203 21:09:18.618525 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:09:18.618525 21228 solver.cpp:237]     Train net output #1: loss = 0.0170788 (* 1 = 0.0170788 loss)
I1203 21:09:18.618525 21228 sgd_solver.cpp:105] Iteration 150000, lr = 0.001
I1203 21:09:26.875311 21228 solver.cpp:218] Iteration 150100 (12.1124 iter/s, 8.25603s/100 iters), loss = 0.0106936
I1203 21:09:26.875311 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:09:26.875311 21228 solver.cpp:237]     Train net output #1: loss = 0.0106936 (* 1 = 0.0106936 loss)
I1203 21:09:26.875311 21228 sgd_solver.cpp:105] Iteration 150100, lr = 0.001
I1203 21:09:34.972170 21228 solver.cpp:218] Iteration 150200 (12.351 iter/s, 8.0965s/100 iters), loss = 0.0283252
I1203 21:09:34.972170 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:09:34.972170 21228 solver.cpp:237]     Train net output #1: loss = 0.0283252 (* 1 = 0.0283252 loss)
I1203 21:09:34.972170 21228 sgd_solver.cpp:105] Iteration 150200, lr = 0.001
I1203 21:09:43.075469 21228 solver.cpp:218] Iteration 150300 (12.3411 iter/s, 8.10301s/100 iters), loss = 0.00883022
I1203 21:09:43.075469 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:09:43.075469 21228 solver.cpp:237]     Train net output #1: loss = 0.00883015 (* 1 = 0.00883015 loss)
I1203 21:09:43.075469 21228 sgd_solver.cpp:105] Iteration 150300, lr = 0.001
I1203 21:09:51.173343 21228 solver.cpp:218] Iteration 150400 (12.3494 iter/s, 8.09758s/100 iters), loss = 0.0105647
I1203 21:09:51.173343 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:09:51.174345 21228 solver.cpp:237]     Train net output #1: loss = 0.0105646 (* 1 = 0.0105646 loss)
I1203 21:09:51.174345 21228 sgd_solver.cpp:105] Iteration 150400, lr = 0.001
I1203 21:09:58.868145 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:09:59.190179 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150500.caffemodel
I1203 21:09:59.231182 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150500.solverstate
I1203 21:09:59.237684 21228 solver.cpp:330] Iteration 150500, Testing net (#0)
I1203 21:09:59.238183 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:10:00.945329 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:10:01.012326 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 21:10:01.012326 21228 solver.cpp:397]     Test net output #1: loss = 0.246514 (* 1 = 0.246514 loss)
I1203 21:10:01.088332 21228 solver.cpp:218] Iteration 150500 (10.0864 iter/s, 9.91433s/100 iters), loss = 0.0175869
I1203 21:10:01.088332 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:01.088332 21228 solver.cpp:237]     Train net output #1: loss = 0.0175868 (* 1 = 0.0175868 loss)
I1203 21:10:01.088332 21228 sgd_solver.cpp:105] Iteration 150500, lr = 0.001
I1203 21:10:09.198557 21228 solver.cpp:218] Iteration 150600 (12.332 iter/s, 8.109s/100 iters), loss = 0.0132253
I1203 21:10:09.198557 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:09.198557 21228 solver.cpp:237]     Train net output #1: loss = 0.0132252 (* 1 = 0.0132252 loss)
I1203 21:10:09.198557 21228 sgd_solver.cpp:105] Iteration 150600, lr = 0.001
I1203 21:10:17.268383 21228 solver.cpp:218] Iteration 150700 (12.392 iter/s, 8.06974s/100 iters), loss = 0.0165808
I1203 21:10:17.268383 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:17.268383 21228 solver.cpp:237]     Train net output #1: loss = 0.0165807 (* 1 = 0.0165807 loss)
I1203 21:10:17.268383 21228 sgd_solver.cpp:105] Iteration 150700, lr = 0.001
I1203 21:10:25.351122 21228 solver.cpp:218] Iteration 150800 (12.3734 iter/s, 8.08184s/100 iters), loss = 0.00847567
I1203 21:10:25.351122 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:25.351122 21228 solver.cpp:237]     Train net output #1: loss = 0.0084756 (* 1 = 0.0084756 loss)
I1203 21:10:25.351122 21228 sgd_solver.cpp:105] Iteration 150800, lr = 0.001
I1203 21:10:33.431965 21228 solver.cpp:218] Iteration 150900 (12.3753 iter/s, 8.08062s/100 iters), loss = 0.0116695
I1203 21:10:33.431965 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:33.431965 21228 solver.cpp:237]     Train net output #1: loss = 0.0116694 (* 1 = 0.0116694 loss)
I1203 21:10:33.431965 21228 sgd_solver.cpp:105] Iteration 150900, lr = 0.001
I1203 21:10:41.112730 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:10:41.431747 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151000.caffemodel
I1203 21:10:41.465749 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151000.solverstate
I1203 21:10:41.472750 21228 solver.cpp:330] Iteration 151000, Testing net (#0)
I1203 21:10:41.472750 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:10:43.164352 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:10:43.230855 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9363
I1203 21:10:43.230855 21228 solver.cpp:397]     Test net output #1: loss = 0.246388 (* 1 = 0.246388 loss)
I1203 21:10:43.305862 21228 solver.cpp:218] Iteration 151000 (10.1284 iter/s, 9.87326s/100 iters), loss = 0.014465
I1203 21:10:43.305862 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:43.305862 21228 solver.cpp:237]     Train net output #1: loss = 0.014465 (* 1 = 0.014465 loss)
I1203 21:10:43.305862 21228 sgd_solver.cpp:105] Iteration 151000, lr = 0.001
I1203 21:10:51.381553 21228 solver.cpp:218] Iteration 151100 (12.3826 iter/s, 8.07585s/100 iters), loss = 0.0164157
I1203 21:10:51.382553 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:51.382553 21228 solver.cpp:237]     Train net output #1: loss = 0.0164156 (* 1 = 0.0164156 loss)
I1203 21:10:51.382553 21228 sgd_solver.cpp:105] Iteration 151100, lr = 0.001
I1203 21:10:59.456933 21228 solver.cpp:218] Iteration 151200 (12.3847 iter/s, 8.07447s/100 iters), loss = 0.0104892
I1203 21:10:59.456933 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:10:59.456933 21228 solver.cpp:237]     Train net output #1: loss = 0.0104891 (* 1 = 0.0104891 loss)
I1203 21:10:59.456933 21228 sgd_solver.cpp:105] Iteration 151200, lr = 0.001
I1203 21:11:07.529664 21228 solver.cpp:218] Iteration 151300 (12.3883 iter/s, 8.07216s/100 iters), loss = 0.0115525
I1203 21:11:07.529664 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:07.529664 21228 solver.cpp:237]     Train net output #1: loss = 0.0115524 (* 1 = 0.0115524 loss)
I1203 21:11:07.529664 21228 sgd_solver.cpp:105] Iteration 151300, lr = 0.001
I1203 21:11:15.607404 21228 solver.cpp:218] Iteration 151400 (12.3802 iter/s, 8.07744s/100 iters), loss = 0.00999648
I1203 21:11:15.607404 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:15.607404 21228 solver.cpp:237]     Train net output #1: loss = 0.0099964 (* 1 = 0.0099964 loss)
I1203 21:11:15.607404 21228 sgd_solver.cpp:105] Iteration 151400, lr = 0.001
I1203 21:11:23.287394 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:11:23.608412 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151500.caffemodel
I1203 21:11:23.648412 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151500.solverstate
I1203 21:11:23.655413 21228 solver.cpp:330] Iteration 151500, Testing net (#0)
I1203 21:11:23.655413 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:11:25.343533 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:11:25.411542 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1203 21:11:25.411542 21228 solver.cpp:397]     Test net output #1: loss = 0.248239 (* 1 = 0.248239 loss)
I1203 21:11:25.486548 21228 solver.cpp:218] Iteration 151500 (10.1233 iter/s, 9.87821s/100 iters), loss = 0.0127688
I1203 21:11:25.486548 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:25.486548 21228 solver.cpp:237]     Train net output #1: loss = 0.0127687 (* 1 = 0.0127687 loss)
I1203 21:11:25.486548 21228 sgd_solver.cpp:105] Iteration 151500, lr = 0.001
I1203 21:11:33.574932 21228 solver.cpp:218] Iteration 151600 (12.3645 iter/s, 8.08769s/100 iters), loss = 0.0129179
I1203 21:11:33.574932 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:33.574932 21228 solver.cpp:237]     Train net output #1: loss = 0.0129178 (* 1 = 0.0129178 loss)
I1203 21:11:33.574932 21228 sgd_solver.cpp:105] Iteration 151600, lr = 0.001
I1203 21:11:41.645251 21228 solver.cpp:218] Iteration 151700 (12.3912 iter/s, 8.07022s/100 iters), loss = 0.0131903
I1203 21:11:41.645251 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:41.645251 21228 solver.cpp:237]     Train net output #1: loss = 0.0131902 (* 1 = 0.0131902 loss)
I1203 21:11:41.645251 21228 sgd_solver.cpp:105] Iteration 151700, lr = 0.001
I1203 21:11:49.728539 21228 solver.cpp:218] Iteration 151800 (12.3721 iter/s, 8.08272s/100 iters), loss = 0.0106043
I1203 21:11:49.728539 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:49.728539 21228 solver.cpp:237]     Train net output #1: loss = 0.0106042 (* 1 = 0.0106042 loss)
I1203 21:11:49.728539 21228 sgd_solver.cpp:105] Iteration 151800, lr = 0.001
I1203 21:11:57.806324 21228 solver.cpp:218] Iteration 151900 (12.3809 iter/s, 8.07695s/100 iters), loss = 0.00914131
I1203 21:11:57.806324 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:11:57.806324 21228 solver.cpp:237]     Train net output #1: loss = 0.00914122 (* 1 = 0.00914122 loss)
I1203 21:11:57.806324 21228 sgd_solver.cpp:105] Iteration 151900, lr = 0.001
I1203 21:12:05.486685 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:12:05.805208 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152000.caffemodel
I1203 21:12:05.845208 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152000.solverstate
I1203 21:12:05.852208 21228 solver.cpp:330] Iteration 152000, Testing net (#0)
I1203 21:12:05.852208 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:12:07.539324 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:12:07.606331 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1203 21:12:07.606331 21228 solver.cpp:397]     Test net output #1: loss = 0.250863 (* 1 = 0.250863 loss)
I1203 21:12:07.681833 21228 solver.cpp:218] Iteration 152000 (10.1265 iter/s, 9.87508s/100 iters), loss = 0.0137607
I1203 21:12:07.681833 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:12:07.681833 21228 solver.cpp:237]     Train net output #1: loss = 0.0137606 (* 1 = 0.0137606 loss)
I1203 21:12:07.681833 21228 sgd_solver.cpp:105] Iteration 152000, lr = 0.001
I1203 21:12:15.761167 21228 solver.cpp:218] Iteration 152100 (12.3781 iter/s, 8.07877s/100 iters), loss = 0.0160257
I1203 21:12:15.761167 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:12:15.761167 21228 solver.cpp:237]     Train net output #1: loss = 0.0160256 (* 1 = 0.0160256 loss)
I1203 21:12:15.761167 21228 sgd_solver.cpp:105] Iteration 152100, lr = 0.001
I1203 21:12:23.832082 21228 solver.cpp:218] Iteration 152200 (12.3906 iter/s, 8.07064s/100 iters), loss = 0.0114911
I1203 21:12:23.832082 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:12:23.832082 21228 solver.cpp:237]     Train net output #1: loss = 0.011491 (* 1 = 0.011491 loss)
I1203 21:12:23.832082 21228 sgd_solver.cpp:105] Iteration 152200, lr = 0.001
I1203 21:12:31.901101 21228 solver.cpp:218] Iteration 152300 (12.3942 iter/s, 8.0683s/100 iters), loss = 0.0142689
I1203 21:12:31.901101 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:12:31.901101 21228 solver.cpp:237]     Train net output #1: loss = 0.0142688 (* 1 = 0.0142688 loss)
I1203 21:12:31.901101 21228 sgd_solver.cpp:105] Iteration 152300, lr = 0.001
I1203 21:12:39.968827 21228 solver.cpp:218] Iteration 152400 (12.3953 iter/s, 8.06755s/100 iters), loss = 0.00992571
I1203 21:12:39.968827 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:12:39.968827 21228 solver.cpp:237]     Train net output #1: loss = 0.00992562 (* 1 = 0.00992562 loss)
I1203 21:12:39.968827 21228 sgd_solver.cpp:105] Iteration 152400, lr = 0.001
I1203 21:12:47.650497 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:12:47.968528 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152500.caffemodel
I1203 21:12:48.008535 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152500.solverstate
I1203 21:12:48.015537 21228 solver.cpp:330] Iteration 152500, Testing net (#0)
I1203 21:12:48.015537 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:12:49.700659 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:12:49.767658 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 21:12:49.767658 21228 solver.cpp:397]     Test net output #1: loss = 0.245576 (* 1 = 0.245576 loss)
I1203 21:12:49.842664 21228 solver.cpp:218] Iteration 152500 (10.1285 iter/s, 9.87309s/100 iters), loss = 0.0153094
I1203 21:12:49.842664 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:12:49.842664 21228 solver.cpp:237]     Train net output #1: loss = 0.0153093 (* 1 = 0.0153093 loss)
I1203 21:12:49.842664 21228 sgd_solver.cpp:105] Iteration 152500, lr = 0.001
I1203 21:12:57.934568 21228 solver.cpp:218] Iteration 152600 (12.3589 iter/s, 8.09134s/100 iters), loss = 0.0254152
I1203 21:12:57.934568 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:12:57.934568 21228 solver.cpp:237]     Train net output #1: loss = 0.0254151 (* 1 = 0.0254151 loss)
I1203 21:12:57.934568 21228 sgd_solver.cpp:105] Iteration 152600, lr = 0.001
I1203 21:13:06.017377 21228 solver.cpp:218] Iteration 152700 (12.3717 iter/s, 8.08298s/100 iters), loss = 0.0107571
I1203 21:13:06.017377 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:13:06.017377 21228 solver.cpp:237]     Train net output #1: loss = 0.010757 (* 1 = 0.010757 loss)
I1203 21:13:06.017377 21228 sgd_solver.cpp:105] Iteration 152700, lr = 0.001
I1203 21:13:14.094596 21228 solver.cpp:218] Iteration 152800 (12.3819 iter/s, 8.07629s/100 iters), loss = 0.0213597
I1203 21:13:14.095098 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:13:14.095098 21228 solver.cpp:237]     Train net output #1: loss = 0.0213596 (* 1 = 0.0213596 loss)
I1203 21:13:14.095098 21228 sgd_solver.cpp:105] Iteration 152800, lr = 0.001
I1203 21:13:22.168340 21228 solver.cpp:218] Iteration 152900 (12.3863 iter/s, 8.07343s/100 iters), loss = 0.0122505
I1203 21:13:22.168340 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:13:22.168340 21228 solver.cpp:237]     Train net output #1: loss = 0.0122504 (* 1 = 0.0122504 loss)
I1203 21:13:22.168340 21228 sgd_solver.cpp:105] Iteration 152900, lr = 0.001
I1203 21:13:29.844800 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:13:30.164818 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153000.caffemodel
I1203 21:13:30.208825 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153000.solverstate
I1203 21:13:30.214825 21228 solver.cpp:330] Iteration 153000, Testing net (#0)
I1203 21:13:30.215826 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:13:31.898941 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:13:31.965942 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 21:13:31.965942 21228 solver.cpp:397]     Test net output #1: loss = 0.248541 (* 1 = 0.248541 loss)
I1203 21:13:32.040964 21228 solver.cpp:218] Iteration 153000 (10.1301 iter/s, 9.87154s/100 iters), loss = 0.03667
I1203 21:13:32.040964 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 21:13:32.040964 21228 solver.cpp:237]     Train net output #1: loss = 0.0366699 (* 1 = 0.0366699 loss)
I1203 21:13:32.040964 21228 sgd_solver.cpp:46] MultiStep Status: Iteration 153000, step = 3
I1203 21:13:32.040964 21228 sgd_solver.cpp:105] Iteration 153000, lr = 0.0001
I1203 21:13:40.145984 21228 solver.cpp:218] Iteration 153100 (12.3385 iter/s, 8.10472s/100 iters), loss = 0.0228643
I1203 21:13:40.145984 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:13:40.145984 21228 solver.cpp:237]     Train net output #1: loss = 0.0228642 (* 1 = 0.0228642 loss)
I1203 21:13:40.145984 21228 sgd_solver.cpp:105] Iteration 153100, lr = 0.0001
I1203 21:13:48.325042 21228 solver.cpp:218] Iteration 153200 (12.2273 iter/s, 8.17842s/100 iters), loss = 0.0154139
I1203 21:13:48.325042 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:13:48.325042 21228 solver.cpp:237]     Train net output #1: loss = 0.0154138 (* 1 = 0.0154138 loss)
I1203 21:13:48.325042 21228 sgd_solver.cpp:105] Iteration 153200, lr = 0.0001
I1203 21:13:56.397028 21228 solver.cpp:218] Iteration 153300 (12.3894 iter/s, 8.07143s/100 iters), loss = 0.011438
I1203 21:13:56.397028 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:13:56.397028 21228 solver.cpp:237]     Train net output #1: loss = 0.0114379 (* 1 = 0.0114379 loss)
I1203 21:13:56.397028 21228 sgd_solver.cpp:105] Iteration 153300, lr = 0.0001
I1203 21:14:04.633087 21228 solver.cpp:218] Iteration 153400 (12.1415 iter/s, 8.23621s/100 iters), loss = 0.0116095
I1203 21:14:04.633087 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:14:04.633087 21228 solver.cpp:237]     Train net output #1: loss = 0.0116094 (* 1 = 0.0116094 loss)
I1203 21:14:04.633087 21228 sgd_solver.cpp:105] Iteration 153400, lr = 0.0001
I1203 21:14:12.362943 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:14:12.679971 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153500.caffemodel
I1203 21:14:12.719475 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153500.solverstate
I1203 21:14:12.725978 21228 solver.cpp:330] Iteration 153500, Testing net (#0)
I1203 21:14:12.725978 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:14:14.414961 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:14:14.480963 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9367
I1203 21:14:14.480963 21228 solver.cpp:397]     Test net output #1: loss = 0.24505 (* 1 = 0.24505 loss)
I1203 21:14:14.554970 21228 solver.cpp:218] Iteration 153500 (10.0797 iter/s, 9.92096s/100 iters), loss = 0.0131649
I1203 21:14:14.554970 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:14:14.554970 21228 solver.cpp:237]     Train net output #1: loss = 0.0131648 (* 1 = 0.0131648 loss)
I1203 21:14:14.554970 21228 sgd_solver.cpp:105] Iteration 153500, lr = 0.0001
I1203 21:14:22.724068 21228 solver.cpp:218] Iteration 153600 (12.2422 iter/s, 8.16848s/100 iters), loss = 0.036096
I1203 21:14:22.724068 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:14:22.724068 21228 solver.cpp:237]     Train net output #1: loss = 0.0360959 (* 1 = 0.0360959 loss)
I1203 21:14:22.724068 21228 sgd_solver.cpp:105] Iteration 153600, lr = 0.0001
I1203 21:14:30.801002 21228 solver.cpp:218] Iteration 153700 (12.3815 iter/s, 8.07656s/100 iters), loss = 0.0106575
I1203 21:14:30.801002 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:14:30.801002 21228 solver.cpp:237]     Train net output #1: loss = 0.0106574 (* 1 = 0.0106574 loss)
I1203 21:14:30.801002 21228 sgd_solver.cpp:105] Iteration 153700, lr = 0.0001
I1203 21:14:38.995183 21228 solver.cpp:218] Iteration 153800 (12.2042 iter/s, 8.19387s/100 iters), loss = 0.0140261
I1203 21:14:38.995183 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:14:38.995183 21228 solver.cpp:237]     Train net output #1: loss = 0.014026 (* 1 = 0.014026 loss)
I1203 21:14:38.995183 21228 sgd_solver.cpp:105] Iteration 153800, lr = 0.0001
I1203 21:14:47.169248 21228 solver.cpp:218] Iteration 153900 (12.2341 iter/s, 8.17385s/100 iters), loss = 0.0140779
I1203 21:14:47.169248 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:14:47.169248 21228 solver.cpp:237]     Train net output #1: loss = 0.0140778 (* 1 = 0.0140778 loss)
I1203 21:14:47.169248 21228 sgd_solver.cpp:105] Iteration 153900, lr = 0.0001
I1203 21:14:55.016091 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:14:55.333120 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154000.caffemodel
I1203 21:14:55.376622 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154000.solverstate
I1203 21:14:55.383623 21228 solver.cpp:330] Iteration 154000, Testing net (#0)
I1203 21:14:55.383623 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:14:57.078248 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:14:57.146250 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9364
I1203 21:14:57.146250 21228 solver.cpp:397]     Test net output #1: loss = 0.243289 (* 1 = 0.243289 loss)
I1203 21:14:57.221256 21228 solver.cpp:218] Iteration 154000 (9.94941 iter/s, 10.0508s/100 iters), loss = 0.0128783
I1203 21:14:57.221256 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:14:57.221256 21228 solver.cpp:237]     Train net output #1: loss = 0.0128782 (* 1 = 0.0128782 loss)
I1203 21:14:57.221256 21228 sgd_solver.cpp:105] Iteration 154000, lr = 0.0001
I1203 21:15:05.449414 21228 solver.cpp:218] Iteration 154100 (12.1531 iter/s, 8.22835s/100 iters), loss = 0.0118427
I1203 21:15:05.450414 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:05.450414 21228 solver.cpp:237]     Train net output #1: loss = 0.0118426 (* 1 = 0.0118426 loss)
I1203 21:15:05.450414 21228 sgd_solver.cpp:105] Iteration 154100, lr = 0.0001
I1203 21:15:13.683464 21228 solver.cpp:218] Iteration 154200 (12.1467 iter/s, 8.23271s/100 iters), loss = 0.0126238
I1203 21:15:13.683464 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:13.683464 21228 solver.cpp:237]     Train net output #1: loss = 0.0126237 (* 1 = 0.0126237 loss)
I1203 21:15:13.683464 21228 sgd_solver.cpp:105] Iteration 154200, lr = 0.0001
I1203 21:15:21.760051 21228 solver.cpp:218] Iteration 154300 (12.3821 iter/s, 8.07617s/100 iters), loss = 0.011656
I1203 21:15:21.760051 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:21.760051 21228 solver.cpp:237]     Train net output #1: loss = 0.0116559 (* 1 = 0.0116559 loss)
I1203 21:15:21.760051 21228 sgd_solver.cpp:105] Iteration 154300, lr = 0.0001
I1203 21:15:29.887490 21228 solver.cpp:218] Iteration 154400 (12.305 iter/s, 8.12676s/100 iters), loss = 0.0136178
I1203 21:15:29.887490 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:29.887490 21228 solver.cpp:237]     Train net output #1: loss = 0.0136177 (* 1 = 0.0136177 loss)
I1203 21:15:29.887490 21228 sgd_solver.cpp:105] Iteration 154400, lr = 0.0001
I1203 21:15:37.809857 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:15:38.131877 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154500.caffemodel
I1203 21:15:38.171878 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154500.solverstate
I1203 21:15:38.180878 21228 solver.cpp:330] Iteration 154500, Testing net (#0)
I1203 21:15:38.180878 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:15:39.868949 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:15:39.935955 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1203 21:15:39.935955 21228 solver.cpp:397]     Test net output #1: loss = 0.24313 (* 1 = 0.24313 loss)
I1203 21:15:40.010958 21228 solver.cpp:218] Iteration 154500 (9.87849 iter/s, 10.123s/100 iters), loss = 0.0135436
I1203 21:15:40.010958 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:40.010958 21228 solver.cpp:237]     Train net output #1: loss = 0.0135435 (* 1 = 0.0135435 loss)
I1203 21:15:40.010958 21228 sgd_solver.cpp:105] Iteration 154500, lr = 0.0001
I1203 21:15:48.163374 21228 solver.cpp:218] Iteration 154600 (12.2663 iter/s, 8.15245s/100 iters), loss = 0.0191837
I1203 21:15:48.163374 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:48.163374 21228 solver.cpp:237]     Train net output #1: loss = 0.0191836 (* 1 = 0.0191836 loss)
I1203 21:15:48.163374 21228 sgd_solver.cpp:105] Iteration 154600, lr = 0.0001
I1203 21:15:56.235484 21228 solver.cpp:218] Iteration 154700 (12.3892 iter/s, 8.07153s/100 iters), loss = 0.011878
I1203 21:15:56.235484 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:15:56.235484 21228 solver.cpp:237]     Train net output #1: loss = 0.0118779 (* 1 = 0.0118779 loss)
I1203 21:15:56.235484 21228 sgd_solver.cpp:105] Iteration 154700, lr = 0.0001
I1203 21:16:04.308830 21228 solver.cpp:218] Iteration 154800 (12.3877 iter/s, 8.07254s/100 iters), loss = 0.0103009
I1203 21:16:04.308830 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:04.308830 21228 solver.cpp:237]     Train net output #1: loss = 0.0103008 (* 1 = 0.0103008 loss)
I1203 21:16:04.308830 21228 sgd_solver.cpp:105] Iteration 154800, lr = 0.0001
I1203 21:16:12.369572 21228 solver.cpp:218] Iteration 154900 (12.4068 iter/s, 8.06008s/100 iters), loss = 0.00999464
I1203 21:16:12.369572 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:12.369572 21228 solver.cpp:237]     Train net output #1: loss = 0.00999454 (* 1 = 0.00999454 loss)
I1203 21:16:12.369572 21228 sgd_solver.cpp:105] Iteration 154900, lr = 0.0001
I1203 21:16:20.035284 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:16:20.357803 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155000.caffemodel
I1203 21:16:20.397306 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155000.solverstate
I1203 21:16:20.403306 21228 solver.cpp:330] Iteration 155000, Testing net (#0)
I1203 21:16:20.403306 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:16:22.088425 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:16:22.155927 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9364
I1203 21:16:22.155927 21228 solver.cpp:397]     Test net output #1: loss = 0.243643 (* 1 = 0.243643 loss)
I1203 21:16:22.230429 21228 solver.cpp:218] Iteration 155000 (10.1416 iter/s, 9.86039s/100 iters), loss = 0.0159598
I1203 21:16:22.230429 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:22.230429 21228 solver.cpp:237]     Train net output #1: loss = 0.0159597 (* 1 = 0.0159597 loss)
I1203 21:16:22.230429 21228 sgd_solver.cpp:105] Iteration 155000, lr = 0.0001
I1203 21:16:30.297232 21228 solver.cpp:218] Iteration 155100 (12.3966 iter/s, 8.06674s/100 iters), loss = 0.0162039
I1203 21:16:30.297232 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:30.297232 21228 solver.cpp:237]     Train net output #1: loss = 0.0162038 (* 1 = 0.0162038 loss)
I1203 21:16:30.297232 21228 sgd_solver.cpp:105] Iteration 155100, lr = 0.0001
I1203 21:16:38.368014 21228 solver.cpp:218] Iteration 155200 (12.3911 iter/s, 8.07033s/100 iters), loss = 0.0119017
I1203 21:16:38.368014 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:38.368014 21228 solver.cpp:237]     Train net output #1: loss = 0.0119016 (* 1 = 0.0119016 loss)
I1203 21:16:38.368014 21228 sgd_solver.cpp:105] Iteration 155200, lr = 0.0001
I1203 21:16:46.442914 21228 solver.cpp:218] Iteration 155300 (12.3856 iter/s, 8.07391s/100 iters), loss = 0.0128062
I1203 21:16:46.442914 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:46.443415 21228 solver.cpp:237]     Train net output #1: loss = 0.0128061 (* 1 = 0.0128061 loss)
I1203 21:16:46.443415 21228 sgd_solver.cpp:105] Iteration 155300, lr = 0.0001
I1203 21:16:54.534667 21228 solver.cpp:218] Iteration 155400 (12.3585 iter/s, 8.09159s/100 iters), loss = 0.0266097
I1203 21:16:54.534667 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:16:54.534667 21228 solver.cpp:237]     Train net output #1: loss = 0.0266096 (* 1 = 0.0266096 loss)
I1203 21:16:54.534667 21228 sgd_solver.cpp:105] Iteration 155400, lr = 0.0001
I1203 21:17:02.200938 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:17:02.520500 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155500.caffemodel
I1203 21:17:02.548002 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155500.solverstate
I1203 21:17:02.555003 21228 solver.cpp:330] Iteration 155500, Testing net (#0)
I1203 21:17:02.555003 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:17:04.242138 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:17:04.308640 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1203 21:17:04.308640 21228 solver.cpp:397]     Test net output #1: loss = 0.243219 (* 1 = 0.243219 loss)
I1203 21:17:04.384147 21228 solver.cpp:218] Iteration 155500 (10.1532 iter/s, 9.84916s/100 iters), loss = 0.0130345
I1203 21:17:04.384147 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:04.385149 21228 solver.cpp:237]     Train net output #1: loss = 0.0130344 (* 1 = 0.0130344 loss)
I1203 21:17:04.385149 21228 sgd_solver.cpp:105] Iteration 155500, lr = 0.0001
I1203 21:17:12.455489 21228 solver.cpp:218] Iteration 155600 (12.3911 iter/s, 8.07032s/100 iters), loss = 0.0152331
I1203 21:17:12.455991 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:12.455991 21228 solver.cpp:237]     Train net output #1: loss = 0.015233 (* 1 = 0.015233 loss)
I1203 21:17:12.455991 21228 sgd_solver.cpp:105] Iteration 155600, lr = 0.0001
I1203 21:17:20.526582 21228 solver.cpp:218] Iteration 155700 (12.3901 iter/s, 8.07099s/100 iters), loss = 0.0164721
I1203 21:17:20.526582 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:20.526582 21228 solver.cpp:237]     Train net output #1: loss = 0.016472 (* 1 = 0.016472 loss)
I1203 21:17:20.527582 21228 sgd_solver.cpp:105] Iteration 155700, lr = 0.0001
I1203 21:17:28.603399 21228 solver.cpp:218] Iteration 155800 (12.3823 iter/s, 8.07606s/100 iters), loss = 0.0091853
I1203 21:17:28.603399 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:28.603399 21228 solver.cpp:237]     Train net output #1: loss = 0.0091852 (* 1 = 0.0091852 loss)
I1203 21:17:28.603399 21228 sgd_solver.cpp:105] Iteration 155800, lr = 0.0001
I1203 21:17:36.679162 21228 solver.cpp:218] Iteration 155900 (12.3837 iter/s, 8.07512s/100 iters), loss = 0.0127901
I1203 21:17:36.679162 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:36.679162 21228 solver.cpp:237]     Train net output #1: loss = 0.01279 (* 1 = 0.01279 loss)
I1203 21:17:36.679162 21228 sgd_solver.cpp:105] Iteration 155900, lr = 0.0001
I1203 21:17:44.357867 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:17:44.673892 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156000.caffemodel
I1203 21:17:44.712891 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156000.solverstate
I1203 21:17:44.719893 21228 solver.cpp:330] Iteration 156000, Testing net (#0)
I1203 21:17:44.719893 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:17:46.405925 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:17:46.472929 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9361
I1203 21:17:46.472929 21228 solver.cpp:397]     Test net output #1: loss = 0.242892 (* 1 = 0.242892 loss)
I1203 21:17:46.546928 21228 solver.cpp:218] Iteration 156000 (10.1346 iter/s, 9.86719s/100 iters), loss = 0.0103485
I1203 21:17:46.546928 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:46.546928 21228 solver.cpp:237]     Train net output #1: loss = 0.0103483 (* 1 = 0.0103483 loss)
I1203 21:17:46.546928 21228 sgd_solver.cpp:105] Iteration 156000, lr = 0.0001
I1203 21:17:54.619174 21228 solver.cpp:218] Iteration 156100 (12.3892 iter/s, 8.07152s/100 iters), loss = 0.0174766
I1203 21:17:54.619174 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:17:54.619174 21228 solver.cpp:237]     Train net output #1: loss = 0.0174765 (* 1 = 0.0174765 loss)
I1203 21:17:54.619174 21228 sgd_solver.cpp:105] Iteration 156100, lr = 0.0001
I1203 21:18:02.698040 21228 solver.cpp:218] Iteration 156200 (12.378 iter/s, 8.07885s/100 iters), loss = 0.0152318
I1203 21:18:02.698040 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:18:02.698040 21228 solver.cpp:237]     Train net output #1: loss = 0.0152317 (* 1 = 0.0152317 loss)
I1203 21:18:02.698040 21228 sgd_solver.cpp:105] Iteration 156200, lr = 0.0001
I1203 21:18:10.780879 21228 solver.cpp:218] Iteration 156300 (12.3735 iter/s, 8.0818s/100 iters), loss = 0.0102749
I1203 21:18:10.780879 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:18:10.780879 21228 solver.cpp:237]     Train net output #1: loss = 0.0102748 (* 1 = 0.0102748 loss)
I1203 21:18:10.780879 21228 sgd_solver.cpp:105] Iteration 156300, lr = 0.0001
I1203 21:18:18.847868 21228 solver.cpp:218] Iteration 156400 (12.3957 iter/s, 8.0673s/100 iters), loss = 0.010911
I1203 21:18:18.848840 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:18:18.848840 21228 solver.cpp:237]     Train net output #1: loss = 0.0109109 (* 1 = 0.0109109 loss)
I1203 21:18:18.848840 21228 sgd_solver.cpp:105] Iteration 156400, lr = 0.0001
I1203 21:18:26.537438 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:18:26.858348 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156500.caffemodel
I1203 21:18:26.897348 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156500.solverstate
I1203 21:18:26.904343 21228 solver.cpp:330] Iteration 156500, Testing net (#0)
I1203 21:18:26.904343 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:18:28.589002 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:18:28.655827 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9372
I1203 21:18:28.656827 21228 solver.cpp:397]     Test net output #1: loss = 0.243125 (* 1 = 0.243125 loss)
I1203 21:18:28.730839 21228 solver.cpp:218] Iteration 156500 (10.1197 iter/s, 9.88167s/100 iters), loss = 0.0141387
I1203 21:18:28.730839 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:18:28.730839 21228 solver.cpp:237]     Train net output #1: loss = 0.0141386 (* 1 = 0.0141386 loss)
I1203 21:18:28.730839 21228 sgd_solver.cpp:105] Iteration 156500, lr = 0.0001
I1203 21:18:36.798465 21228 solver.cpp:218] Iteration 156600 (12.3966 iter/s, 8.06673s/100 iters), loss = 0.0303851
I1203 21:18:36.798465 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:18:36.798465 21228 solver.cpp:237]     Train net output #1: loss = 0.030385 (* 1 = 0.030385 loss)
I1203 21:18:36.798465 21228 sgd_solver.cpp:105] Iteration 156600, lr = 0.0001
I1203 21:18:44.957295 21228 solver.cpp:218] Iteration 156700 (12.2565 iter/s, 8.15893s/100 iters), loss = 0.012926
I1203 21:18:44.957295 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:18:44.957295 21228 solver.cpp:237]     Train net output #1: loss = 0.0129259 (* 1 = 0.0129259 loss)
I1203 21:18:44.957295 21228 sgd_solver.cpp:105] Iteration 156700, lr = 0.0001
I1203 21:18:53.149281 21228 solver.cpp:218] Iteration 156800 (12.2079 iter/s, 8.1914s/100 iters), loss = 0.0135802
I1203 21:18:53.149281 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:18:53.149281 21228 solver.cpp:237]     Train net output #1: loss = 0.0135801 (* 1 = 0.0135801 loss)
I1203 21:18:53.149281 21228 sgd_solver.cpp:105] Iteration 156800, lr = 0.0001
I1203 21:19:01.235685 21228 solver.cpp:218] Iteration 156900 (12.3678 iter/s, 8.0855s/100 iters), loss = 0.0111797
I1203 21:19:01.235685 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:01.235685 21228 solver.cpp:237]     Train net output #1: loss = 0.0111796 (* 1 = 0.0111796 loss)
I1203 21:19:01.235685 21228 sgd_solver.cpp:105] Iteration 156900, lr = 0.0001
I1203 21:19:09.012672 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:19:09.351024 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157000.caffemodel
I1203 21:19:09.381026 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157000.solverstate
I1203 21:19:09.388033 21228 solver.cpp:330] Iteration 157000, Testing net (#0)
I1203 21:19:09.388033 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:19:11.103094 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:19:11.170099 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9369
I1203 21:19:11.170099 21228 solver.cpp:397]     Test net output #1: loss = 0.242985 (* 1 = 0.242985 loss)
I1203 21:19:11.245103 21228 solver.cpp:218] Iteration 157000 (9.99031 iter/s, 10.0097s/100 iters), loss = 0.0200461
I1203 21:19:11.246106 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:11.246106 21228 solver.cpp:237]     Train net output #1: loss = 0.020046 (* 1 = 0.020046 loss)
I1203 21:19:11.246106 21228 sgd_solver.cpp:105] Iteration 157000, lr = 0.0001
I1203 21:19:19.331044 21228 solver.cpp:218] Iteration 157100 (12.3691 iter/s, 8.08464s/100 iters), loss = 0.0114808
I1203 21:19:19.331044 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:19.331044 21228 solver.cpp:237]     Train net output #1: loss = 0.0114807 (* 1 = 0.0114807 loss)
I1203 21:19:19.331044 21228 sgd_solver.cpp:105] Iteration 157100, lr = 0.0001
I1203 21:19:27.539963 21228 solver.cpp:218] Iteration 157200 (12.1824 iter/s, 8.20855s/100 iters), loss = 0.0112944
I1203 21:19:27.539963 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:27.539963 21228 solver.cpp:237]     Train net output #1: loss = 0.0112943 (* 1 = 0.0112943 loss)
I1203 21:19:27.539963 21228 sgd_solver.cpp:105] Iteration 157200, lr = 0.0001
I1203 21:19:35.734484 21228 solver.cpp:218] Iteration 157300 (12.2043 iter/s, 8.19383s/100 iters), loss = 0.0117078
I1203 21:19:35.734484 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:35.734484 21228 solver.cpp:237]     Train net output #1: loss = 0.0117076 (* 1 = 0.0117076 loss)
I1203 21:19:35.734985 21228 sgd_solver.cpp:105] Iteration 157300, lr = 0.0001
I1203 21:19:43.827726 21228 solver.cpp:218] Iteration 157400 (12.3569 iter/s, 8.09266s/100 iters), loss = 0.0127162
I1203 21:19:43.827726 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:43.827726 21228 solver.cpp:237]     Train net output #1: loss = 0.0127161 (* 1 = 0.0127161 loss)
I1203 21:19:43.827726 21228 sgd_solver.cpp:105] Iteration 157400, lr = 0.0001
I1203 21:19:51.553478 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:19:51.873495 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157500.caffemodel
I1203 21:19:51.913496 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157500.solverstate
I1203 21:19:51.920496 21228 solver.cpp:330] Iteration 157500, Testing net (#0)
I1203 21:19:51.920496 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:19:53.625886 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:19:53.691889 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9368
I1203 21:19:53.691889 21228 solver.cpp:397]     Test net output #1: loss = 0.24279 (* 1 = 0.24279 loss)
I1203 21:19:53.767894 21228 solver.cpp:218] Iteration 157500 (10.0605 iter/s, 9.93982s/100 iters), loss = 0.0142167
I1203 21:19:53.767894 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:19:53.767894 21228 solver.cpp:237]     Train net output #1: loss = 0.0142166 (* 1 = 0.0142166 loss)
I1203 21:19:53.767894 21228 sgd_solver.cpp:105] Iteration 157500, lr = 0.0001
I1203 21:20:01.905671 21228 solver.cpp:218] Iteration 157600 (12.2896 iter/s, 8.13695s/100 iters), loss = 0.0205856
I1203 21:20:01.905671 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:01.905671 21228 solver.cpp:237]     Train net output #1: loss = 0.0205855 (* 1 = 0.0205855 loss)
I1203 21:20:01.905671 21228 sgd_solver.cpp:105] Iteration 157600, lr = 0.0001
I1203 21:20:09.996393 21228 solver.cpp:218] Iteration 157700 (12.3602 iter/s, 8.09047s/100 iters), loss = 0.0132613
I1203 21:20:09.996393 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:09.996393 21228 solver.cpp:237]     Train net output #1: loss = 0.0132612 (* 1 = 0.0132612 loss)
I1203 21:20:09.996393 21228 sgd_solver.cpp:105] Iteration 157700, lr = 0.0001
I1203 21:20:18.069617 21228 solver.cpp:218] Iteration 157800 (12.3877 iter/s, 8.07256s/100 iters), loss = 0.0122154
I1203 21:20:18.069617 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:18.069617 21228 solver.cpp:237]     Train net output #1: loss = 0.0122153 (* 1 = 0.0122153 loss)
I1203 21:20:18.069617 21228 sgd_solver.cpp:105] Iteration 157800, lr = 0.0001
I1203 21:20:26.191051 21228 solver.cpp:218] Iteration 157900 (12.3142 iter/s, 8.1207s/100 iters), loss = 0.0102727
I1203 21:20:26.191051 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:26.191051 21228 solver.cpp:237]     Train net output #1: loss = 0.0102726 (* 1 = 0.0102726 loss)
I1203 21:20:26.191051 21228 sgd_solver.cpp:105] Iteration 157900, lr = 0.0001
I1203 21:20:33.923424 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:20:34.244444 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158000.caffemodel
I1203 21:20:34.284445 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158000.solverstate
I1203 21:20:34.290444 21228 solver.cpp:330] Iteration 158000, Testing net (#0)
I1203 21:20:34.291445 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:20:35.973572 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:20:36.040580 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9364
I1203 21:20:36.040580 21228 solver.cpp:397]     Test net output #1: loss = 0.242974 (* 1 = 0.242974 loss)
I1203 21:20:36.114583 21228 solver.cpp:218] Iteration 158000 (10.0773 iter/s, 9.92332s/100 iters), loss = 0.0144293
I1203 21:20:36.114583 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:36.114583 21228 solver.cpp:237]     Train net output #1: loss = 0.0144292 (* 1 = 0.0144292 loss)
I1203 21:20:36.114583 21228 sgd_solver.cpp:105] Iteration 158000, lr = 0.0001
I1203 21:20:44.189231 21228 solver.cpp:218] Iteration 158100 (12.3848 iter/s, 8.0744s/100 iters), loss = 0.0154885
I1203 21:20:44.189231 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:44.189231 21228 solver.cpp:237]     Train net output #1: loss = 0.0154884 (* 1 = 0.0154884 loss)
I1203 21:20:44.189231 21228 sgd_solver.cpp:105] Iteration 158100, lr = 0.0001
I1203 21:20:52.269209 21228 solver.cpp:218] Iteration 158200 (12.3777 iter/s, 8.07902s/100 iters), loss = 0.0210285
I1203 21:20:52.269209 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:20:52.269209 21228 solver.cpp:237]     Train net output #1: loss = 0.0210284 (* 1 = 0.0210284 loss)
I1203 21:20:52.269209 21228 sgd_solver.cpp:105] Iteration 158200, lr = 0.0001
I1203 21:21:00.409005 21228 solver.cpp:218] Iteration 158300 (12.2858 iter/s, 8.13951s/100 iters), loss = 0.012281
I1203 21:21:00.409005 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:00.409005 21228 solver.cpp:237]     Train net output #1: loss = 0.0122809 (* 1 = 0.0122809 loss)
I1203 21:21:00.409005 21228 sgd_solver.cpp:105] Iteration 158300, lr = 0.0001
I1203 21:21:08.488780 21228 solver.cpp:218] Iteration 158400 (12.3776 iter/s, 8.07908s/100 iters), loss = 0.0131756
I1203 21:21:08.488780 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:08.488780 21228 solver.cpp:237]     Train net output #1: loss = 0.0131755 (* 1 = 0.0131755 loss)
I1203 21:21:08.488780 21228 sgd_solver.cpp:105] Iteration 158400, lr = 0.0001
I1203 21:21:16.248128 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:21:16.568159 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158500.caffemodel
I1203 21:21:16.605159 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158500.solverstate
I1203 21:21:16.611665 21228 solver.cpp:330] Iteration 158500, Testing net (#0)
I1203 21:21:16.612165 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:21:18.299293 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:21:18.367298 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 21:21:18.367298 21228 solver.cpp:397]     Test net output #1: loss = 0.243367 (* 1 = 0.243367 loss)
I1203 21:21:18.442303 21228 solver.cpp:218] Iteration 158500 (10.047 iter/s, 9.95319s/100 iters), loss = 0.0106136
I1203 21:21:18.442303 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:18.442303 21228 solver.cpp:237]     Train net output #1: loss = 0.0106135 (* 1 = 0.0106135 loss)
I1203 21:21:18.442303 21228 sgd_solver.cpp:105] Iteration 158500, lr = 0.0001
I1203 21:21:26.511193 21228 solver.cpp:218] Iteration 158600 (12.3945 iter/s, 8.06809s/100 iters), loss = 0.0237124
I1203 21:21:26.511193 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:26.511193 21228 solver.cpp:237]     Train net output #1: loss = 0.0237123 (* 1 = 0.0237123 loss)
I1203 21:21:26.511193 21228 sgd_solver.cpp:105] Iteration 158600, lr = 0.0001
I1203 21:21:34.669945 21228 solver.cpp:218] Iteration 158700 (12.2574 iter/s, 8.15837s/100 iters), loss = 0.0133305
I1203 21:21:34.669945 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:34.669945 21228 solver.cpp:237]     Train net output #1: loss = 0.0133304 (* 1 = 0.0133304 loss)
I1203 21:21:34.669945 21228 sgd_solver.cpp:105] Iteration 158700, lr = 0.0001
I1203 21:21:42.893105 21228 solver.cpp:218] Iteration 158800 (12.162 iter/s, 8.22234s/100 iters), loss = 0.0100478
I1203 21:21:42.893105 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:42.893105 21228 solver.cpp:237]     Train net output #1: loss = 0.0100477 (* 1 = 0.0100477 loss)
I1203 21:21:42.893105 21228 sgd_solver.cpp:105] Iteration 158800, lr = 0.0001
I1203 21:21:50.976137 21228 solver.cpp:218] Iteration 158900 (12.3713 iter/s, 8.08321s/100 iters), loss = 0.00968339
I1203 21:21:50.977138 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:21:50.977138 21228 solver.cpp:237]     Train net output #1: loss = 0.0096833 (* 1 = 0.0096833 loss)
I1203 21:21:50.977138 21228 sgd_solver.cpp:105] Iteration 158900, lr = 0.0001
I1203 21:21:58.664898 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:21:58.984987 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159000.caffemodel
I1203 21:21:59.027987 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159000.solverstate
I1203 21:21:59.034987 21228 solver.cpp:330] Iteration 159000, Testing net (#0)
I1203 21:21:59.034987 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:22:00.719105 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:22:00.787114 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9361
I1203 21:22:00.787114 21228 solver.cpp:397]     Test net output #1: loss = 0.244144 (* 1 = 0.244144 loss)
I1203 21:22:00.862617 21228 solver.cpp:218] Iteration 159000 (10.1162 iter/s, 9.88514s/100 iters), loss = 0.0176014
I1203 21:22:00.862617 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:00.862617 21228 solver.cpp:237]     Train net output #1: loss = 0.0176013 (* 1 = 0.0176013 loss)
I1203 21:22:00.862617 21228 sgd_solver.cpp:105] Iteration 159000, lr = 0.0001
I1203 21:22:09.021462 21228 solver.cpp:218] Iteration 159100 (12.2562 iter/s, 8.15912s/100 iters), loss = 0.0175177
I1203 21:22:09.021462 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:09.022464 21228 solver.cpp:237]     Train net output #1: loss = 0.0175176 (* 1 = 0.0175176 loss)
I1203 21:22:09.022464 21228 sgd_solver.cpp:105] Iteration 159100, lr = 0.0001
I1203 21:22:17.163871 21228 solver.cpp:218] Iteration 159200 (12.2828 iter/s, 8.14146s/100 iters), loss = 0.0121436
I1203 21:22:17.164371 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:17.164371 21228 solver.cpp:237]     Train net output #1: loss = 0.0121435 (* 1 = 0.0121435 loss)
I1203 21:22:17.164371 21228 sgd_solver.cpp:105] Iteration 159200, lr = 0.0001
I1203 21:22:25.312770 21228 solver.cpp:218] Iteration 159300 (12.2719 iter/s, 8.14869s/100 iters), loss = 0.0101339
I1203 21:22:25.312770 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:25.312770 21228 solver.cpp:237]     Train net output #1: loss = 0.0101338 (* 1 = 0.0101338 loss)
I1203 21:22:25.312770 21228 sgd_solver.cpp:105] Iteration 159300, lr = 0.0001
I1203 21:22:33.409088 21228 solver.cpp:218] Iteration 159400 (12.3519 iter/s, 8.09594s/100 iters), loss = 0.0142215
I1203 21:22:33.409088 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:33.409088 21228 solver.cpp:237]     Train net output #1: loss = 0.0142214 (* 1 = 0.0142214 loss)
I1203 21:22:33.409088 21228 sgd_solver.cpp:105] Iteration 159400, lr = 0.0001
I1203 21:22:41.229969 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:22:41.555989 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159500.caffemodel
I1203 21:22:41.595998 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159500.solverstate
I1203 21:22:41.601997 21228 solver.cpp:330] Iteration 159500, Testing net (#0)
I1203 21:22:41.602998 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:22:43.311305 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:22:43.378310 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9363
I1203 21:22:43.378310 21228 solver.cpp:397]     Test net output #1: loss = 0.244066 (* 1 = 0.244066 loss)
I1203 21:22:43.452309 21228 solver.cpp:218] Iteration 159500 (9.95805 iter/s, 10.0421s/100 iters), loss = 0.0119511
I1203 21:22:43.452309 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:43.452309 21228 solver.cpp:237]     Train net output #1: loss = 0.011951 (* 1 = 0.011951 loss)
I1203 21:22:43.452309 21228 sgd_solver.cpp:105] Iteration 159500, lr = 0.0001
I1203 21:22:51.592413 21228 solver.cpp:218] Iteration 159600 (12.2859 iter/s, 8.13942s/100 iters), loss = 0.0158656
I1203 21:22:51.592413 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:51.592413 21228 solver.cpp:237]     Train net output #1: loss = 0.0158655 (* 1 = 0.0158655 loss)
I1203 21:22:51.592413 21228 sgd_solver.cpp:105] Iteration 159600, lr = 0.0001
I1203 21:22:59.719574 21228 solver.cpp:218] Iteration 159700 (12.3049 iter/s, 8.12687s/100 iters), loss = 0.014243
I1203 21:22:59.719574 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:22:59.719574 21228 solver.cpp:237]     Train net output #1: loss = 0.0142429 (* 1 = 0.0142429 loss)
I1203 21:22:59.719574 21228 sgd_solver.cpp:105] Iteration 159700, lr = 0.0001
I1203 21:23:07.836236 21228 solver.cpp:218] Iteration 159800 (12.3208 iter/s, 8.11635s/100 iters), loss = 0.00957854
I1203 21:23:07.836236 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:07.836236 21228 solver.cpp:237]     Train net output #1: loss = 0.00957846 (* 1 = 0.00957846 loss)
I1203 21:23:07.836236 21228 sgd_solver.cpp:105] Iteration 159800, lr = 0.0001
I1203 21:23:15.975181 21228 solver.cpp:218] Iteration 159900 (12.2882 iter/s, 8.13788s/100 iters), loss = 0.0126939
I1203 21:23:15.975181 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:15.975181 21228 solver.cpp:237]     Train net output #1: loss = 0.0126938 (* 1 = 0.0126938 loss)
I1203 21:23:15.975181 21228 sgd_solver.cpp:105] Iteration 159900, lr = 0.0001
I1203 21:23:23.666214 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:23:24.004245 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160000.caffemodel
I1203 21:23:24.048244 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160000.solverstate
I1203 21:23:24.075245 21228 solver.cpp:330] Iteration 160000, Testing net (#0)
I1203 21:23:24.075245 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:23:25.800086 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:23:25.866590 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9364
I1203 21:23:25.866590 21228 solver.cpp:397]     Test net output #1: loss = 0.243791 (* 1 = 0.243791 loss)
I1203 21:23:25.940595 21228 solver.cpp:218] Iteration 160000 (10.0344 iter/s, 9.9657s/100 iters), loss = 0.0119516
I1203 21:23:25.940595 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:25.940595 21228 solver.cpp:237]     Train net output #1: loss = 0.0119515 (* 1 = 0.0119515 loss)
I1203 21:23:25.940595 21228 sgd_solver.cpp:105] Iteration 160000, lr = 0.0001
I1203 21:23:34.120328 21228 solver.cpp:218] Iteration 160100 (12.2261 iter/s, 8.1792s/100 iters), loss = 0.0138702
I1203 21:23:34.120328 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:34.120328 21228 solver.cpp:237]     Train net output #1: loss = 0.0138701 (* 1 = 0.0138701 loss)
I1203 21:23:34.120328 21228 sgd_solver.cpp:105] Iteration 160100, lr = 0.0001
I1203 21:23:42.407121 21228 solver.cpp:218] Iteration 160200 (12.0687 iter/s, 8.28591s/100 iters), loss = 0.0176998
I1203 21:23:42.407121 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:42.407121 21228 solver.cpp:237]     Train net output #1: loss = 0.0176997 (* 1 = 0.0176997 loss)
I1203 21:23:42.407121 21228 sgd_solver.cpp:105] Iteration 160200, lr = 0.0001
I1203 21:23:50.538525 21228 solver.cpp:218] Iteration 160300 (12.2989 iter/s, 8.13079s/100 iters), loss = 0.0079341
I1203 21:23:50.538525 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:50.538525 21228 solver.cpp:237]     Train net output #1: loss = 0.00793402 (* 1 = 0.00793402 loss)
I1203 21:23:50.538525 21228 sgd_solver.cpp:105] Iteration 160300, lr = 0.0001
I1203 21:23:58.661942 21228 solver.cpp:218] Iteration 160400 (12.3105 iter/s, 8.12317s/100 iters), loss = 0.0118028
I1203 21:23:58.661942 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:23:58.661942 21228 solver.cpp:237]     Train net output #1: loss = 0.0118027 (* 1 = 0.0118027 loss)
I1203 21:23:58.661942 21228 sgd_solver.cpp:105] Iteration 160400, lr = 0.0001
I1203 21:24:06.356477 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:24:06.675498 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160500.caffemodel
I1203 21:24:06.706497 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160500.solverstate
I1203 21:24:06.713001 21228 solver.cpp:330] Iteration 160500, Testing net (#0)
I1203 21:24:06.713001 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:24:08.402055 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:24:08.469055 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1203 21:24:08.469055 21228 solver.cpp:397]     Test net output #1: loss = 0.243535 (* 1 = 0.243535 loss)
I1203 21:24:08.546063 21228 solver.cpp:218] Iteration 160500 (10.1185 iter/s, 9.88288s/100 iters), loss = 0.0113641
I1203 21:24:08.546063 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:08.546063 21228 solver.cpp:237]     Train net output #1: loss = 0.011364 (* 1 = 0.011364 loss)
I1203 21:24:08.546063 21228 sgd_solver.cpp:105] Iteration 160500, lr = 0.0001
I1203 21:24:16.753180 21228 solver.cpp:218] Iteration 160600 (12.1841 iter/s, 8.20743s/100 iters), loss = 0.0154702
I1203 21:24:16.754180 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:16.754180 21228 solver.cpp:237]     Train net output #1: loss = 0.0154701 (* 1 = 0.0154701 loss)
I1203 21:24:16.754180 21228 sgd_solver.cpp:105] Iteration 160600, lr = 0.0001
I1203 21:24:24.829084 21228 solver.cpp:218] Iteration 160700 (12.3838 iter/s, 8.07505s/100 iters), loss = 0.0119202
I1203 21:24:24.829084 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:24.829084 21228 solver.cpp:237]     Train net output #1: loss = 0.0119201 (* 1 = 0.0119201 loss)
I1203 21:24:24.829084 21228 sgd_solver.cpp:105] Iteration 160700, lr = 0.0001
I1203 21:24:32.928733 21228 solver.cpp:218] Iteration 160800 (12.3474 iter/s, 8.09888s/100 iters), loss = 0.0108334
I1203 21:24:32.928733 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:32.928733 21228 solver.cpp:237]     Train net output #1: loss = 0.0108333 (* 1 = 0.0108333 loss)
I1203 21:24:32.928733 21228 sgd_solver.cpp:105] Iteration 160800, lr = 0.0001
I1203 21:24:41.013504 21228 solver.cpp:218] Iteration 160900 (12.3695 iter/s, 8.08437s/100 iters), loss = 0.0114589
I1203 21:24:41.013504 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:41.013504 21228 solver.cpp:237]     Train net output #1: loss = 0.0114588 (* 1 = 0.0114588 loss)
I1203 21:24:41.013504 21228 sgd_solver.cpp:105] Iteration 160900, lr = 0.0001
I1203 21:24:48.719709 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:24:49.038229 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161000.caffemodel
I1203 21:24:49.079229 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161000.solverstate
I1203 21:24:49.099236 21228 solver.cpp:330] Iteration 161000, Testing net (#0)
I1203 21:24:49.100236 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:24:50.781363 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:24:50.848371 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9362
I1203 21:24:50.848371 21228 solver.cpp:397]     Test net output #1: loss = 0.243666 (* 1 = 0.243666 loss)
I1203 21:24:50.922392 21228 solver.cpp:218] Iteration 161000 (10.0928 iter/s, 9.90801s/100 iters), loss = 0.0124148
I1203 21:24:50.922392 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:50.922392 21228 solver.cpp:237]     Train net output #1: loss = 0.0124147 (* 1 = 0.0124147 loss)
I1203 21:24:50.922392 21228 sgd_solver.cpp:105] Iteration 161000, lr = 0.0001
I1203 21:24:59.076081 21228 solver.cpp:218] Iteration 161100 (12.2639 iter/s, 8.154s/100 iters), loss = 0.0151048
I1203 21:24:59.076081 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:24:59.077082 21228 solver.cpp:237]     Train net output #1: loss = 0.0151047 (* 1 = 0.0151047 loss)
I1203 21:24:59.077082 21228 sgd_solver.cpp:105] Iteration 161100, lr = 0.0001
I1203 21:25:07.167135 21228 solver.cpp:218] Iteration 161200 (12.3615 iter/s, 8.08965s/100 iters), loss = 0.0198371
I1203 21:25:07.167135 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:07.167135 21228 solver.cpp:237]     Train net output #1: loss = 0.019837 (* 1 = 0.019837 loss)
I1203 21:25:07.167135 21228 sgd_solver.cpp:105] Iteration 161200, lr = 0.0001
I1203 21:25:15.247921 21228 solver.cpp:218] Iteration 161300 (12.3751 iter/s, 8.08076s/100 iters), loss = 0.00870442
I1203 21:25:15.247921 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:15.247921 21228 solver.cpp:237]     Train net output #1: loss = 0.00870433 (* 1 = 0.00870433 loss)
I1203 21:25:15.247921 21228 sgd_solver.cpp:105] Iteration 161300, lr = 0.0001
I1203 21:25:23.342864 21228 solver.cpp:218] Iteration 161400 (12.3545 iter/s, 8.09421s/100 iters), loss = 0.0112022
I1203 21:25:23.342864 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:23.342864 21228 solver.cpp:237]     Train net output #1: loss = 0.0112021 (* 1 = 0.0112021 loss)
I1203 21:25:23.342864 21228 sgd_solver.cpp:105] Iteration 161400, lr = 0.0001
I1203 21:25:31.056768 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:25:31.376788 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161500.caffemodel
I1203 21:25:31.416795 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161500.solverstate
I1203 21:25:31.423795 21228 solver.cpp:330] Iteration 161500, Testing net (#0)
I1203 21:25:31.423795 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:25:33.134215 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:25:33.204718 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9368
I1203 21:25:33.204718 21228 solver.cpp:397]     Test net output #1: loss = 0.244031 (* 1 = 0.244031 loss)
I1203 21:25:33.280223 21228 solver.cpp:218] Iteration 161500 (10.063 iter/s, 9.93743s/100 iters), loss = 0.0137135
I1203 21:25:33.281224 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:33.281224 21228 solver.cpp:237]     Train net output #1: loss = 0.0137134 (* 1 = 0.0137134 loss)
I1203 21:25:33.281224 21228 sgd_solver.cpp:105] Iteration 161500, lr = 0.0001
I1203 21:25:41.474174 21228 solver.cpp:218] Iteration 161600 (12.2049 iter/s, 8.1934s/100 iters), loss = 0.0229907
I1203 21:25:41.475174 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:41.475174 21228 solver.cpp:237]     Train net output #1: loss = 0.0229906 (* 1 = 0.0229906 loss)
I1203 21:25:41.475174 21228 sgd_solver.cpp:105] Iteration 161600, lr = 0.0001
I1203 21:25:49.703519 21228 solver.cpp:218] Iteration 161700 (12.1534 iter/s, 8.22812s/100 iters), loss = 0.0116185
I1203 21:25:49.703519 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:49.703519 21228 solver.cpp:237]     Train net output #1: loss = 0.0116184 (* 1 = 0.0116184 loss)
I1203 21:25:49.703519 21228 sgd_solver.cpp:105] Iteration 161700, lr = 0.0001
I1203 21:25:57.841753 21228 solver.cpp:218] Iteration 161800 (12.2886 iter/s, 8.13762s/100 iters), loss = 0.0109671
I1203 21:25:57.841753 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:25:57.841753 21228 solver.cpp:237]     Train net output #1: loss = 0.010967 (* 1 = 0.010967 loss)
I1203 21:25:57.841753 21228 sgd_solver.cpp:105] Iteration 161800, lr = 0.0001
I1203 21:26:06.034270 21228 solver.cpp:218] Iteration 161900 (12.2063 iter/s, 8.1925s/100 iters), loss = 0.0143891
I1203 21:26:06.034270 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:06.034270 21228 solver.cpp:237]     Train net output #1: loss = 0.014389 (* 1 = 0.014389 loss)
I1203 21:26:06.034270 21228 sgd_solver.cpp:105] Iteration 161900, lr = 0.0001
I1203 21:26:13.736047 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:26:14.055085 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162000.caffemodel
I1203 21:26:14.091086 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162000.solverstate
I1203 21:26:14.108103 21228 solver.cpp:330] Iteration 162000, Testing net (#0)
I1203 21:26:14.108603 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:26:15.803397 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:26:15.870399 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9365
I1203 21:26:15.870399 21228 solver.cpp:397]     Test net output #1: loss = 0.243532 (* 1 = 0.243532 loss)
I1203 21:26:15.947405 21228 solver.cpp:218] Iteration 162000 (10.0887 iter/s, 9.91207s/100 iters), loss = 0.0148903
I1203 21:26:15.947405 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:15.947405 21228 solver.cpp:237]     Train net output #1: loss = 0.0148902 (* 1 = 0.0148902 loss)
I1203 21:26:15.947405 21228 sgd_solver.cpp:105] Iteration 162000, lr = 0.0001
I1203 21:26:24.180289 21228 solver.cpp:218] Iteration 162100 (12.147 iter/s, 8.23248s/100 iters), loss = 0.00964977
I1203 21:26:24.180289 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:24.180289 21228 solver.cpp:237]     Train net output #1: loss = 0.00964967 (* 1 = 0.00964967 loss)
I1203 21:26:24.180289 21228 sgd_solver.cpp:105] Iteration 162100, lr = 0.0001
I1203 21:26:32.324180 21228 solver.cpp:218] Iteration 162200 (12.2799 iter/s, 8.14337s/100 iters), loss = 0.0117584
I1203 21:26:32.324180 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:32.324180 21228 solver.cpp:237]     Train net output #1: loss = 0.0117583 (* 1 = 0.0117583 loss)
I1203 21:26:32.324180 21228 sgd_solver.cpp:105] Iteration 162200, lr = 0.0001
I1203 21:26:40.418628 21228 solver.cpp:218] Iteration 162300 (12.3554 iter/s, 8.09361s/100 iters), loss = 0.0105356
I1203 21:26:40.418628 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:40.418628 21228 solver.cpp:237]     Train net output #1: loss = 0.0105355 (* 1 = 0.0105355 loss)
I1203 21:26:40.418628 21228 sgd_solver.cpp:105] Iteration 162300, lr = 0.0001
I1203 21:26:48.502403 21228 solver.cpp:218] Iteration 162400 (12.3706 iter/s, 8.08366s/100 iters), loss = 0.00946869
I1203 21:26:48.502403 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:48.502403 21228 solver.cpp:237]     Train net output #1: loss = 0.00946859 (* 1 = 0.00946859 loss)
I1203 21:26:48.502403 21228 sgd_solver.cpp:105] Iteration 162400, lr = 0.0001
I1203 21:26:56.185025 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:26:56.504043 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162500.caffemodel
I1203 21:26:56.544050 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162500.solverstate
I1203 21:26:56.551050 21228 solver.cpp:330] Iteration 162500, Testing net (#0)
I1203 21:26:56.551050 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:26:58.240170 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:26:58.307940 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9358
I1203 21:26:58.307940 21228 solver.cpp:397]     Test net output #1: loss = 0.24345 (* 1 = 0.24345 loss)
I1203 21:26:58.383466 21228 solver.cpp:218] Iteration 162500 (10.1211 iter/s, 9.88038s/100 iters), loss = 0.0099682
I1203 21:26:58.383466 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:26:58.383466 21228 solver.cpp:237]     Train net output #1: loss = 0.0099681 (* 1 = 0.0099681 loss)
I1203 21:26:58.383466 21228 sgd_solver.cpp:105] Iteration 162500, lr = 0.0001
I1203 21:27:06.460588 21228 solver.cpp:218] Iteration 162600 (12.3814 iter/s, 8.07661s/100 iters), loss = 0.0123944
I1203 21:27:06.460588 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:27:06.460588 21228 solver.cpp:237]     Train net output #1: loss = 0.0123943 (* 1 = 0.0123943 loss)
I1203 21:27:06.460588 21228 sgd_solver.cpp:105] Iteration 162600, lr = 0.0001
I1203 21:27:14.520944 21228 solver.cpp:218] Iteration 162700 (12.4072 iter/s, 8.05985s/100 iters), loss = 0.011652
I1203 21:27:14.520944 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:27:14.520944 21228 solver.cpp:237]     Train net output #1: loss = 0.0116519 (* 1 = 0.0116519 loss)
I1203 21:27:14.520944 21228 sgd_solver.cpp:105] Iteration 162700, lr = 0.0001
I1203 21:27:22.646963 21228 solver.cpp:218] Iteration 162800 (12.3068 iter/s, 8.12558s/100 iters), loss = 0.0115342
I1203 21:27:22.646963 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:27:22.646963 21228 solver.cpp:237]     Train net output #1: loss = 0.0115341 (* 1 = 0.0115341 loss)
I1203 21:27:22.646963 21228 sgd_solver.cpp:105] Iteration 162800, lr = 0.0001
I1203 21:27:30.718391 21228 solver.cpp:218] Iteration 162900 (12.3903 iter/s, 8.0708s/100 iters), loss = 0.0111507
I1203 21:27:30.718391 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:27:30.718391 21228 solver.cpp:237]     Train net output #1: loss = 0.0111506 (* 1 = 0.0111506 loss)
I1203 21:27:30.718391 21228 sgd_solver.cpp:105] Iteration 162900, lr = 0.0001
I1203 21:27:38.441601 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:27:38.759618 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163000.caffemodel
I1203 21:27:38.793618 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163000.solverstate
I1203 21:27:38.824635 21228 solver.cpp:330] Iteration 163000, Testing net (#0)
I1203 21:27:38.825135 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:27:40.508759 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:27:40.574766 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9364
I1203 21:27:40.574766 21228 solver.cpp:397]     Test net output #1: loss = 0.243603 (* 1 = 0.243603 loss)
I1203 21:27:40.652591 21228 solver.cpp:218] Iteration 163000 (10.0663 iter/s, 9.9341s/100 iters), loss = 0.0104362
I1203 21:27:40.652591 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:27:40.652591 21228 solver.cpp:237]     Train net output #1: loss = 0.0104361 (* 1 = 0.0104361 loss)
I1203 21:27:40.652591 21228 sgd_solver.cpp:105] Iteration 163000, lr = 0.0001
I1203 21:27:48.766834 21228 solver.cpp:218] Iteration 163100 (12.3256 iter/s, 8.11319s/100 iters), loss = 0.0410036
I1203 21:27:48.766834 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:27:48.766834 21228 solver.cpp:237]     Train net output #1: loss = 0.0410035 (* 1 = 0.0410035 loss)
I1203 21:27:48.766834 21228 sgd_solver.cpp:105] Iteration 163100, lr = 0.0001
I1203 21:27:56.864748 21228 solver.cpp:218] Iteration 163200 (12.349 iter/s, 8.09784s/100 iters), loss = 0.011855
I1203 21:27:56.864748 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:27:56.864748 21228 solver.cpp:237]     Train net output #1: loss = 0.0118549 (* 1 = 0.0118549 loss)
I1203 21:27:56.864748 21228 sgd_solver.cpp:105] Iteration 163200, lr = 0.0001
I1203 21:28:04.989157 21228 solver.cpp:218] Iteration 163300 (12.3104 iter/s, 8.12324s/100 iters), loss = 0.0190673
I1203 21:28:04.989157 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:04.989157 21228 solver.cpp:237]     Train net output #1: loss = 0.0190673 (* 1 = 0.0190673 loss)
I1203 21:28:04.989157 21228 sgd_solver.cpp:105] Iteration 163300, lr = 0.0001
I1203 21:28:13.205860 21228 solver.cpp:218] Iteration 163400 (12.171 iter/s, 8.21625s/100 iters), loss = 0.0159873
I1203 21:28:13.205860 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:13.205860 21228 solver.cpp:237]     Train net output #1: loss = 0.0159872 (* 1 = 0.0159872 loss)
I1203 21:28:13.205860 21228 sgd_solver.cpp:105] Iteration 163400, lr = 0.0001
I1203 21:28:20.898087 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:28:21.218772 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163500.caffemodel
I1203 21:28:21.261314 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163500.solverstate
I1203 21:28:21.267329 21228 solver.cpp:330] Iteration 163500, Testing net (#0)
I1203 21:28:21.267329 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:28:22.954779 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:28:23.021792 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9359
I1203 21:28:23.021792 21228 solver.cpp:397]     Test net output #1: loss = 0.243909 (* 1 = 0.243909 loss)
I1203 21:28:23.095818 21228 solver.cpp:218] Iteration 163500 (10.1116 iter/s, 9.8896s/100 iters), loss = 0.0103715
I1203 21:28:23.095818 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:23.095818 21228 solver.cpp:237]     Train net output #1: loss = 0.0103714 (* 1 = 0.0103714 loss)
I1203 21:28:23.095818 21228 sgd_solver.cpp:105] Iteration 163500, lr = 0.0001
I1203 21:28:31.174391 21228 solver.cpp:218] Iteration 163600 (12.3787 iter/s, 8.0784s/100 iters), loss = 0.0225258
I1203 21:28:31.174391 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:31.174391 21228 solver.cpp:237]     Train net output #1: loss = 0.0225257 (* 1 = 0.0225257 loss)
I1203 21:28:31.174391 21228 sgd_solver.cpp:105] Iteration 163600, lr = 0.0001
I1203 21:28:39.329044 21228 solver.cpp:218] Iteration 163700 (12.263 iter/s, 8.1546s/100 iters), loss = 0.0103829
I1203 21:28:39.330044 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:39.330044 21228 solver.cpp:237]     Train net output #1: loss = 0.0103828 (* 1 = 0.0103828 loss)
I1203 21:28:39.330044 21228 sgd_solver.cpp:105] Iteration 163700, lr = 0.0001
I1203 21:28:47.445466 21228 solver.cpp:218] Iteration 163800 (12.3224 iter/s, 8.11529s/100 iters), loss = 0.0159619
I1203 21:28:47.445466 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:47.445466 21228 solver.cpp:237]     Train net output #1: loss = 0.0159618 (* 1 = 0.0159618 loss)
I1203 21:28:47.445466 21228 sgd_solver.cpp:105] Iteration 163800, lr = 0.0001
I1203 21:28:55.511775 21228 solver.cpp:218] Iteration 163900 (12.3974 iter/s, 8.06621s/100 iters), loss = 0.0146427
I1203 21:28:55.511775 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:28:55.511775 21228 solver.cpp:237]     Train net output #1: loss = 0.0146426 (* 1 = 0.0146426 loss)
I1203 21:28:55.511775 21228 sgd_solver.cpp:105] Iteration 163900, lr = 0.0001
I1203 21:29:03.196710 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:29:03.516747 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164000.caffemodel
I1203 21:29:03.556751 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164000.solverstate
I1203 21:29:03.591778 21228 solver.cpp:330] Iteration 164000, Testing net (#0)
I1203 21:29:03.591778 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:29:05.276185 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:29:05.342177 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9368
I1203 21:29:05.342177 21228 solver.cpp:397]     Test net output #1: loss = 0.243287 (* 1 = 0.243287 loss)
I1203 21:29:05.419183 21228 solver.cpp:218] Iteration 164000 (10.0939 iter/s, 9.90699s/100 iters), loss = 0.0103666
I1203 21:29:05.419183 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:29:05.419183 21228 solver.cpp:237]     Train net output #1: loss = 0.0103665 (* 1 = 0.0103665 loss)
I1203 21:29:05.420183 21228 sgd_solver.cpp:105] Iteration 164000, lr = 0.0001
I1203 21:29:13.500077 21228 solver.cpp:218] Iteration 164100 (12.3756 iter/s, 8.0804s/100 iters), loss = 0.0186112
I1203 21:29:13.501077 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:29:13.501077 21228 solver.cpp:237]     Train net output #1: loss = 0.0186111 (* 1 = 0.0186111 loss)
I1203 21:29:13.501077 21228 sgd_solver.cpp:105] Iteration 164100, lr = 0.0001
I1203 21:29:21.608041 21228 solver.cpp:218] Iteration 164200 (12.3355 iter/s, 8.10667s/100 iters), loss = 0.0189138
I1203 21:29:21.608041 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:29:21.608041 21228 solver.cpp:237]     Train net output #1: loss = 0.0189137 (* 1 = 0.0189137 loss)
I1203 21:29:21.608041 21228 sgd_solver.cpp:105] Iteration 164200, lr = 0.0001
I1203 21:29:29.818045 21228 solver.cpp:218] Iteration 164300 (12.1799 iter/s, 8.21022s/100 iters), loss = 0.00919758
I1203 21:29:29.818045 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:29:29.818045 21228 solver.cpp:237]     Train net output #1: loss = 0.00919749 (* 1 = 0.00919749 loss)
I1203 21:29:29.818045 21228 sgd_solver.cpp:105] Iteration 164300, lr = 0.0001
I1203 21:29:37.913193 21228 solver.cpp:218] Iteration 164400 (12.354 iter/s, 8.09454s/100 iters), loss = 0.0137488
I1203 21:29:37.913193 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:29:37.913193 21228 solver.cpp:237]     Train net output #1: loss = 0.0137487 (* 1 = 0.0137487 loss)
I1203 21:29:37.913193 21228 sgd_solver.cpp:105] Iteration 164400, lr = 0.0001
I1203 21:29:45.614106 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:29:45.938128 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164500.caffemodel
I1203 21:29:45.968125 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164500.solverstate
I1203 21:29:45.974126 21228 solver.cpp:330] Iteration 164500, Testing net (#0)
I1203 21:29:45.975126 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:29:47.662030 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:29:47.727038 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9367
I1203 21:29:47.728039 21228 solver.cpp:397]     Test net output #1: loss = 0.243671 (* 1 = 0.243671 loss)
I1203 21:29:47.801719 21228 solver.cpp:218] Iteration 164500 (10.1137 iter/s, 9.8876s/100 iters), loss = 0.0174449
I1203 21:29:47.801719 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:29:47.801719 21228 solver.cpp:237]     Train net output #1: loss = 0.0174449 (* 1 = 0.0174449 loss)
I1203 21:29:47.801719 21228 sgd_solver.cpp:105] Iteration 164500, lr = 0.0001
I1203 21:29:55.883934 21228 solver.cpp:218] Iteration 164600 (12.3728 iter/s, 8.08227s/100 iters), loss = 0.0280224
I1203 21:29:55.884933 21228 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 21:29:55.884933 21228 solver.cpp:237]     Train net output #1: loss = 0.0280223 (* 1 = 0.0280223 loss)
I1203 21:29:55.884933 21228 sgd_solver.cpp:105] Iteration 164600, lr = 0.0001
I1203 21:30:04.000277 21228 solver.cpp:218] Iteration 164700 (12.3228 iter/s, 8.11506s/100 iters), loss = 0.013454
I1203 21:30:04.000277 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:04.000277 21228 solver.cpp:237]     Train net output #1: loss = 0.0134539 (* 1 = 0.0134539 loss)
I1203 21:30:04.000277 21228 sgd_solver.cpp:105] Iteration 164700, lr = 0.0001
I1203 21:30:12.081112 21228 solver.cpp:218] Iteration 164800 (12.3749 iter/s, 8.08091s/100 iters), loss = 0.00957609
I1203 21:30:12.081112 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:12.081112 21228 solver.cpp:237]     Train net output #1: loss = 0.00957601 (* 1 = 0.00957601 loss)
I1203 21:30:12.081112 21228 sgd_solver.cpp:105] Iteration 164800, lr = 0.0001
I1203 21:30:20.151424 21228 solver.cpp:218] Iteration 164900 (12.3926 iter/s, 8.06933s/100 iters), loss = 0.016489
I1203 21:30:20.151424 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:20.151424 21228 solver.cpp:237]     Train net output #1: loss = 0.016489 (* 1 = 0.016489 loss)
I1203 21:30:20.151424 21228 sgd_solver.cpp:105] Iteration 164900, lr = 0.0001
I1203 21:30:27.838402 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:30:28.159935 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165000.caffemodel
I1203 21:30:28.202438 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165000.solverstate
I1203 21:30:28.233438 21228 solver.cpp:330] Iteration 165000, Testing net (#0)
I1203 21:30:28.233438 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:30:29.920559 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:30:29.987566 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9371
I1203 21:30:29.987566 21228 solver.cpp:397]     Test net output #1: loss = 0.242881 (* 1 = 0.242881 loss)
I1203 21:30:30.062067 21228 solver.cpp:218] Iteration 165000 (10.0908 iter/s, 9.91002s/100 iters), loss = 0.0114747
I1203 21:30:30.062067 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:30.062067 21228 solver.cpp:237]     Train net output #1: loss = 0.0114746 (* 1 = 0.0114746 loss)
I1203 21:30:30.062067 21228 sgd_solver.cpp:105] Iteration 165000, lr = 0.0001
I1203 21:30:38.223274 21228 solver.cpp:218] Iteration 165100 (12.2535 iter/s, 8.16094s/100 iters), loss = 0.0139367
I1203 21:30:38.223274 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:38.223274 21228 solver.cpp:237]     Train net output #1: loss = 0.0139366 (* 1 = 0.0139366 loss)
I1203 21:30:38.223274 21228 sgd_solver.cpp:105] Iteration 165100, lr = 0.0001
I1203 21:30:46.369678 21228 solver.cpp:218] Iteration 165200 (12.2771 iter/s, 8.14526s/100 iters), loss = 0.013845
I1203 21:30:46.369678 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:46.369678 21228 solver.cpp:237]     Train net output #1: loss = 0.0138449 (* 1 = 0.0138449 loss)
I1203 21:30:46.369678 21228 sgd_solver.cpp:105] Iteration 165200, lr = 0.0001
I1203 21:30:54.529906 21228 solver.cpp:218] Iteration 165300 (12.2547 iter/s, 8.16014s/100 iters), loss = 0.0114238
I1203 21:30:54.529906 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:30:54.529906 21228 solver.cpp:237]     Train net output #1: loss = 0.0114237 (* 1 = 0.0114237 loss)
I1203 21:30:54.529906 21228 sgd_solver.cpp:105] Iteration 165300, lr = 0.0001
I1203 21:31:02.718293 21228 solver.cpp:218] Iteration 165400 (12.2137 iter/s, 8.1875s/100 iters), loss = 0.00915009
I1203 21:31:02.718293 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:31:02.718293 21228 solver.cpp:237]     Train net output #1: loss = 0.00915 (* 1 = 0.00915 loss)
I1203 21:31:02.718293 21228 sgd_solver.cpp:105] Iteration 165400, lr = 0.0001
I1203 21:31:10.536916 10440 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:31:10.856938 21228 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165500.caffemodel
I1203 21:31:10.893946 21228 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165500.solverstate
I1203 21:31:10.899946 21228 solver.cpp:330] Iteration 165500, Testing net (#0)
I1203 21:31:10.899946 21228 net.cpp:676] Ignoring source layer accuracy_training
I1203 21:31:12.599530 21128 data_layer.cpp:73] Restarting data prefetching from start.
I1203 21:31:12.672230 21228 solver.cpp:397]     Test net output #0: accuracy = 0.9367
I1203 21:31:12.672230 21228 solver.cpp:397]     Test net output #1: loss = 0.242879 (* 1 = 0.242879 loss)
I1203 21:31:12.746243 21228 solver.cpp:218] Iteration 165500 (9.97271 iter/s, 10.0274s/100 iters), loss = 0.0108462
I1203 21:31:12.746243 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:31:12.746243 21228 solver.cpp:237]     Train net output #1: loss = 0.0108461 (* 1 = 0.0108461 loss)
I1203 21:31:12.746243 21228 sgd_solver.cpp:105] Iteration 165500, lr = 0.0001
I1203 21:31:20.888455 21228 solver.cpp:218] Iteration 165600 (12.282 iter/s, 8.142s/100 iters), loss = 0.0133634
I1203 21:31:20.888455 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:31:20.888455 21228 solver.cpp:237]     Train net output #1: loss = 0.0133633 (* 1 = 0.0133633 loss)
I1203 21:31:20.888455 21228 sgd_solver.cpp:105] Iteration 165600, lr = 0.0001
I1203 21:31:28.996191 21228 solver.cpp:218] Iteration 165700 (12.3355 iter/s, 8.10671s/100 iters), loss = 0.0173397
I1203 21:31:28.996191 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:31:28.996191 21228 solver.cpp:237]     Train net output #1: loss = 0.0173396 (* 1 = 0.0173396 loss)
I1203 21:31:28.996191 21228 sgd_solver.cpp:105] Iteration 165700, lr = 0.0001
I1203 21:31:37.092092 21228 solver.cpp:218] Iteration 165800 (12.3523 iter/s, 8.09568s/100 iters), loss = 0.0135275
I1203 21:31:37.092092 21228 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 21:31:37.092092 21228 solver.cpp:237]     Train net output #1: loss = 0.0135274 (* 1 = 0.0135274 loss)
