
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt --snapshot=examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate 
I1211 22:42:13.068787 17660 caffe.cpp:219] Using GPUs 0
I1211 22:42:13.293334 17660 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1211 22:42:13.628033 17660 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 22:42:13.647032 17660 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/resnet32_with3pooling"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 195000
stepvalue: 220000
stepvalue: 270000
type: "AdaDelta"
I1211 22:42:13.648032 17660 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 22:42:13.651039 17660 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 22:42:13.651039 17660 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 22:42:13.651039 17660 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1211 22:42:13.651039 17660 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1211 22:42:13.651538 17660 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy_training"
  include
I1211 22:42:13.733551 17660 layer_factory.cpp:58] Creating layer cifar
I1211 22:42:13.740540 17660 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I1211 22:42:13.742539 17660 net.cpp:84] Creating Layer cifar
I1211 22:42:13.742539 17660 net.cpp:380] cifar -> data
I1211 22:42:13.742539 17660 net.cpp:380] cifar -> label
I1211 22:42:13.743540 17660 data_layer.cpp:45] output data size: 100,3,32,32
I1211 22:42:13.749560 17660 net.cpp:122] Setting up cifar
I1211 22:42:13.749560 17660 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 22:42:13.749560 17660 net.cpp:129] Top shape: 100 (100)
I1211 22:42:13.749560 17660 net.cpp:137] Memory required for data: 1229200
I1211 22:42:13.749560 17660 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 22:42:13.749560 17660 net.cpp:84] Creating Layer label_cifar_1_split
I1211 22:42:13.749560 17660 net.cpp:406] label_cifar_1_split <- label
I1211 22:42:13.749560 17660 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 22:42:13.749560 17660 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 22:42:13.749560 17660 net.cpp:122] Setting up label_cifar_1_split
I1211 22:42:13.749560 17660 net.cpp:129] Top shape: 100 (100)
I1211 22:42:13.749560 17660 net.cpp:129] Top shape: 100 (100)
I1211 22:42:13.749560 17660 net.cpp:137] Memory required for data: 1230000
I1211 22:42:13.749560 17660 layer_factory.cpp:58] Creating layer first_conv
I1211 22:42:13.749560 17660 net.cpp:84] Creating Layer first_conv
I1211 22:42:13.749560 17660 net.cpp:406] first_conv <- data
I1211 22:42:13.749560 17660 net.cpp:380] first_conv -> first_conv
I1211 22:42:13.751569 12884 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 22:42:14.134789 17660 net.cpp:122] Setting up first_conv
I1211 22:42:14.134789 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.134789 17660 net.cpp:137] Memory required for data: 7783600
I1211 22:42:14.134789 17660 layer_factory.cpp:58] Creating layer first_conv_bn
I1211 22:42:14.134789 17660 net.cpp:84] Creating Layer first_conv_bn
I1211 22:42:14.134789 17660 net.cpp:406] first_conv_bn <- first_conv
I1211 22:42:14.134789 17660 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1211 22:42:14.135787 17660 net.cpp:122] Setting up first_conv_bn
I1211 22:42:14.135787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.135787 17660 net.cpp:137] Memory required for data: 14337200
I1211 22:42:14.135787 17660 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 22:42:14.135787 17660 net.cpp:84] Creating Layer first_conv_scale
I1211 22:42:14.135787 17660 net.cpp:406] first_conv_scale <- first_conv
I1211 22:42:14.135787 17660 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1211 22:42:14.135787 17660 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 22:42:14.135787 17660 net.cpp:122] Setting up first_conv_scale
I1211 22:42:14.135787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.135787 17660 net.cpp:137] Memory required for data: 20890800
I1211 22:42:14.135787 17660 layer_factory.cpp:58] Creating layer first_conv_relu
I1211 22:42:14.135787 17660 net.cpp:84] Creating Layer first_conv_relu
I1211 22:42:14.135787 17660 net.cpp:406] first_conv_relu <- first_conv
I1211 22:42:14.135787 17660 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1211 22:42:14.136787 17660 net.cpp:122] Setting up first_conv_relu
I1211 22:42:14.136787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.136787 17660 net.cpp:137] Memory required for data: 27444400
I1211 22:42:14.136787 17660 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1211 22:42:14.136787 17660 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1211 22:42:14.136787 17660 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1211 22:42:14.136787 17660 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1211 22:42:14.137787 17660 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1211 22:42:14.137787 17660 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1211 22:42:14.137787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.137787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.137787 17660 net.cpp:137] Memory required for data: 40551600
I1211 22:42:14.137787 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1211 22:42:14.137787 17660 net.cpp:84] Creating Layer group0_block0_conv0
I1211 22:42:14.137787 17660 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1211 22:42:14.137787 17660 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1211 22:42:14.140786 17660 net.cpp:122] Setting up group0_block0_conv0
I1211 22:42:14.140786 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.140786 17660 net.cpp:137] Memory required for data: 47105200
I1211 22:42:14.140786 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1211 22:42:14.140786 17660 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1211 22:42:14.140786 17660 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1211 22:42:14.140786 17660 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1211 22:42:14.141788 17660 net.cpp:122] Setting up group0_block0_conv0_bn
I1211 22:42:14.141788 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.141788 17660 net.cpp:137] Memory required for data: 53658800
I1211 22:42:14.141788 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 22:42:14.141788 17660 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1211 22:42:14.141788 17660 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1211 22:42:14.141788 17660 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1211 22:42:14.141788 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 22:42:14.141788 17660 net.cpp:122] Setting up group0_block0_conv0_scale
I1211 22:42:14.141788 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.141788 17660 net.cpp:137] Memory required for data: 60212400
I1211 22:42:14.141788 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1211 22:42:14.141788 17660 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1211 22:42:14.141788 17660 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1211 22:42:14.141788 17660 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1211 22:42:14.142786 17660 net.cpp:122] Setting up group0_block0_conv0_relu
I1211 22:42:14.142786 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.142786 17660 net.cpp:137] Memory required for data: 66766000
I1211 22:42:14.142786 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1211 22:42:14.142786 17660 net.cpp:84] Creating Layer group0_block0_conv1
I1211 22:42:14.142786 17660 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1211 22:42:14.142786 17660 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1211 22:42:14.145787 17660 net.cpp:122] Setting up group0_block0_conv1
I1211 22:42:14.145787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.145787 17660 net.cpp:137] Memory required for data: 73319600
I1211 22:42:14.145787 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1211 22:42:14.145787 17660 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1211 22:42:14.145787 17660 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1211 22:42:14.145787 17660 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1211 22:42:14.145787 17660 net.cpp:122] Setting up group0_block0_conv1_bn
I1211 22:42:14.145787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.145787 17660 net.cpp:137] Memory required for data: 79873200
I1211 22:42:14.145787 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 22:42:14.145787 17660 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1211 22:42:14.145787 17660 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1211 22:42:14.145787 17660 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1211 22:42:14.145787 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 22:42:14.145787 17660 net.cpp:122] Setting up group0_block0_conv1_scale
I1211 22:42:14.145787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.145787 17660 net.cpp:137] Memory required for data: 86426800
I1211 22:42:14.145787 17660 layer_factory.cpp:58] Creating layer group0_block0_sum
I1211 22:42:14.145787 17660 net.cpp:84] Creating Layer group0_block0_sum
I1211 22:42:14.145787 17660 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1211 22:42:14.145787 17660 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1211 22:42:14.145787 17660 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1211 22:42:14.146786 17660 net.cpp:122] Setting up group0_block0_sum
I1211 22:42:14.146786 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.146786 17660 net.cpp:137] Memory required for data: 92980400
I1211 22:42:14.146786 17660 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1211 22:42:14.146786 17660 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1211 22:42:14.146786 17660 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1211 22:42:14.146786 17660 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1211 22:42:14.146786 17660 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1211 22:42:14.146786 17660 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1211 22:42:14.146786 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.146786 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.146786 17660 net.cpp:137] Memory required for data: 106087600
I1211 22:42:14.146786 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1211 22:42:14.146786 17660 net.cpp:84] Creating Layer group0_block1_conv0
I1211 22:42:14.146786 17660 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1211 22:42:14.146786 17660 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1211 22:42:14.148787 17660 net.cpp:122] Setting up group0_block1_conv0
I1211 22:42:14.148787 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.148787 17660 net.cpp:137] Memory required for data: 112641200
I1211 22:42:14.148787 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1211 22:42:14.148787 17660 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1211 22:42:14.148787 17660 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1211 22:42:14.148787 17660 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1211 22:42:14.149292 17660 net.cpp:122] Setting up group0_block1_conv0_bn
I1211 22:42:14.149292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.149292 17660 net.cpp:137] Memory required for data: 119194800
I1211 22:42:14.149292 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 22:42:14.149292 17660 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1211 22:42:14.149292 17660 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1211 22:42:14.149292 17660 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1211 22:42:14.149292 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 22:42:14.149292 17660 net.cpp:122] Setting up group0_block1_conv0_scale
I1211 22:42:14.149292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.149292 17660 net.cpp:137] Memory required for data: 125748400
I1211 22:42:14.149292 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1211 22:42:14.149292 17660 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1211 22:42:14.149292 17660 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1211 22:42:14.149292 17660 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1211 22:42:14.149792 17660 net.cpp:122] Setting up group0_block1_conv0_relu
I1211 22:42:14.149792 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.149792 17660 net.cpp:137] Memory required for data: 132302000
I1211 22:42:14.149792 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1211 22:42:14.149792 17660 net.cpp:84] Creating Layer group0_block1_conv1
I1211 22:42:14.149792 17660 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1211 22:42:14.149792 17660 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1211 22:42:14.151793 17660 net.cpp:122] Setting up group0_block1_conv1
I1211 22:42:14.151793 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.151793 17660 net.cpp:137] Memory required for data: 138855600
I1211 22:42:14.151793 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1211 22:42:14.151793 17660 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1211 22:42:14.151793 17660 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1211 22:42:14.151793 17660 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1211 22:42:14.151793 17660 net.cpp:122] Setting up group0_block1_conv1_bn
I1211 22:42:14.152292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.152292 17660 net.cpp:137] Memory required for data: 145409200
I1211 22:42:14.152292 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 22:42:14.152292 17660 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1211 22:42:14.152292 17660 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1211 22:42:14.152292 17660 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1211 22:42:14.152292 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 22:42:14.152292 17660 net.cpp:122] Setting up group0_block1_conv1_scale
I1211 22:42:14.152292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.152292 17660 net.cpp:137] Memory required for data: 151962800
I1211 22:42:14.152292 17660 layer_factory.cpp:58] Creating layer group0_block1_sum
I1211 22:42:14.152292 17660 net.cpp:84] Creating Layer group0_block1_sum
I1211 22:42:14.152292 17660 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1211 22:42:14.152292 17660 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1211 22:42:14.152292 17660 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1211 22:42:14.152292 17660 net.cpp:122] Setting up group0_block1_sum
I1211 22:42:14.152292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.152292 17660 net.cpp:137] Memory required for data: 158516400
I1211 22:42:14.152292 17660 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1211 22:42:14.152292 17660 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1211 22:42:14.152292 17660 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1211 22:42:14.152292 17660 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1211 22:42:14.152292 17660 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1211 22:42:14.152292 17660 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1211 22:42:14.152292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.152292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.152292 17660 net.cpp:137] Memory required for data: 171623600
I1211 22:42:14.152292 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1211 22:42:14.152791 17660 net.cpp:84] Creating Layer group0_block2_conv0
I1211 22:42:14.152791 17660 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1211 22:42:14.152791 17660 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1211 22:42:14.154292 17660 net.cpp:122] Setting up group0_block2_conv0
I1211 22:42:14.154292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.154292 17660 net.cpp:137] Memory required for data: 178177200
I1211 22:42:14.154292 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1211 22:42:14.154292 17660 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1211 22:42:14.154292 17660 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1211 22:42:14.154292 17660 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1211 22:42:14.154795 17660 net.cpp:122] Setting up group0_block2_conv0_bn
I1211 22:42:14.154795 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.154795 17660 net.cpp:137] Memory required for data: 184730800
I1211 22:42:14.154795 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 22:42:14.154795 17660 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1211 22:42:14.154795 17660 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1211 22:42:14.154795 17660 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1211 22:42:14.154795 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 22:42:14.154795 17660 net.cpp:122] Setting up group0_block2_conv0_scale
I1211 22:42:14.155294 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.155294 17660 net.cpp:137] Memory required for data: 191284400
I1211 22:42:14.155294 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1211 22:42:14.155294 17660 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1211 22:42:14.155294 17660 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1211 22:42:14.155294 17660 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1211 22:42:14.155294 17660 net.cpp:122] Setting up group0_block2_conv0_relu
I1211 22:42:14.155294 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.155294 17660 net.cpp:137] Memory required for data: 197838000
I1211 22:42:14.155792 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1211 22:42:14.155792 17660 net.cpp:84] Creating Layer group0_block2_conv1
I1211 22:42:14.155792 17660 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1211 22:42:14.155792 17660 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1211 22:42:14.157793 17660 net.cpp:122] Setting up group0_block2_conv1
I1211 22:42:14.157793 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.157793 17660 net.cpp:137] Memory required for data: 204391600
I1211 22:42:14.158294 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1211 22:42:14.158294 17660 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1211 22:42:14.158294 17660 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1211 22:42:14.158294 17660 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1211 22:42:14.158294 17660 net.cpp:122] Setting up group0_block2_conv1_bn
I1211 22:42:14.158294 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.158294 17660 net.cpp:137] Memory required for data: 210945200
I1211 22:42:14.158294 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 22:42:14.158294 17660 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1211 22:42:14.158294 17660 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1211 22:42:14.158294 17660 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1211 22:42:14.158793 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 22:42:14.158793 17660 net.cpp:122] Setting up group0_block2_conv1_scale
I1211 22:42:14.158793 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.158793 17660 net.cpp:137] Memory required for data: 217498800
I1211 22:42:14.158793 17660 layer_factory.cpp:58] Creating layer group0_block2_sum
I1211 22:42:14.158793 17660 net.cpp:84] Creating Layer group0_block2_sum
I1211 22:42:14.158793 17660 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1211 22:42:14.158793 17660 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1211 22:42:14.158793 17660 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1211 22:42:14.159292 17660 net.cpp:122] Setting up group0_block2_sum
I1211 22:42:14.159292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.159292 17660 net.cpp:137] Memory required for data: 224052400
I1211 22:42:14.159292 17660 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1211 22:42:14.159292 17660 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1211 22:42:14.159292 17660 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1211 22:42:14.159292 17660 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1211 22:42:14.159292 17660 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1211 22:42:14.159292 17660 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1211 22:42:14.159292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.159292 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.159292 17660 net.cpp:137] Memory required for data: 237159600
I1211 22:42:14.159792 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1211 22:42:14.159792 17660 net.cpp:84] Creating Layer group0_block3_conv0
I1211 22:42:14.159792 17660 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1211 22:42:14.159792 17660 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1211 22:42:14.161293 17660 net.cpp:122] Setting up group0_block3_conv0
I1211 22:42:14.161792 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.161792 17660 net.cpp:137] Memory required for data: 243713200
I1211 22:42:14.161792 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1211 22:42:14.161792 17660 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1211 22:42:14.161792 17660 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1211 22:42:14.161792 17660 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1211 22:42:14.161792 17660 net.cpp:122] Setting up group0_block3_conv0_bn
I1211 22:42:14.161792 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.161792 17660 net.cpp:137] Memory required for data: 250266800
I1211 22:42:14.161792 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 22:42:14.161792 17660 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1211 22:42:14.161792 17660 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1211 22:42:14.161792 17660 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1211 22:42:14.161792 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 22:42:14.162294 17660 net.cpp:122] Setting up group0_block3_conv0_scale
I1211 22:42:14.162294 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.162294 17660 net.cpp:137] Memory required for data: 256820400
I1211 22:42:14.162294 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1211 22:42:14.162294 17660 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1211 22:42:14.162294 17660 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1211 22:42:14.162294 17660 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1211 22:42:14.162792 17660 net.cpp:122] Setting up group0_block3_conv0_relu
I1211 22:42:14.162792 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.162792 17660 net.cpp:137] Memory required for data: 263374000
I1211 22:42:14.162792 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1211 22:42:14.162792 17660 net.cpp:84] Creating Layer group0_block3_conv1
I1211 22:42:14.162792 17660 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1211 22:42:14.162792 17660 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1211 22:42:14.164793 17660 net.cpp:122] Setting up group0_block3_conv1
I1211 22:42:14.164793 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.164793 17660 net.cpp:137] Memory required for data: 269927600
I1211 22:42:14.164793 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1211 22:42:14.164793 17660 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1211 22:42:14.164793 17660 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1211 22:42:14.164793 17660 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1211 22:42:14.164793 17660 net.cpp:122] Setting up group0_block3_conv1_bn
I1211 22:42:14.164793 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.164793 17660 net.cpp:137] Memory required for data: 276481200
I1211 22:42:14.164793 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 22:42:14.164793 17660 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1211 22:42:14.164793 17660 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1211 22:42:14.164793 17660 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1211 22:42:14.164793 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 22:42:14.164793 17660 net.cpp:122] Setting up group0_block3_conv1_scale
I1211 22:42:14.164793 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.164793 17660 net.cpp:137] Memory required for data: 283034800
I1211 22:42:14.164793 17660 layer_factory.cpp:58] Creating layer group0_block3_sum
I1211 22:42:14.164793 17660 net.cpp:84] Creating Layer group0_block3_sum
I1211 22:42:14.164793 17660 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1211 22:42:14.164793 17660 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1211 22:42:14.164793 17660 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1211 22:42:14.165798 17660 net.cpp:122] Setting up group0_block3_sum
I1211 22:42:14.165798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.165798 17660 net.cpp:137] Memory required for data: 289588400
I1211 22:42:14.165798 17660 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1211 22:42:14.165798 17660 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1211 22:42:14.165798 17660 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1211 22:42:14.165798 17660 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1211 22:42:14.165798 17660 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1211 22:42:14.165798 17660 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1211 22:42:14.165798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.165798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.165798 17660 net.cpp:137] Memory required for data: 302695600
I1211 22:42:14.165798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1211 22:42:14.165798 17660 net.cpp:84] Creating Layer group0_block4_conv0
I1211 22:42:14.165798 17660 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1211 22:42:14.165798 17660 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1211 22:42:14.167800 17660 net.cpp:122] Setting up group0_block4_conv0
I1211 22:42:14.167800 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.167800 17660 net.cpp:137] Memory required for data: 309249200
I1211 22:42:14.167800 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1211 22:42:14.167800 17660 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1211 22:42:14.167800 17660 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1211 22:42:14.167800 17660 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1211 22:42:14.167800 17660 net.cpp:122] Setting up group0_block4_conv0_bn
I1211 22:42:14.168798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.168798 17660 net.cpp:137] Memory required for data: 315802800
I1211 22:42:14.168798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 22:42:14.168798 17660 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1211 22:42:14.168798 17660 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1211 22:42:14.168798 17660 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1211 22:42:14.168798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 22:42:14.168798 17660 net.cpp:122] Setting up group0_block4_conv0_scale
I1211 22:42:14.168798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.168798 17660 net.cpp:137] Memory required for data: 322356400
I1211 22:42:14.168798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1211 22:42:14.168798 17660 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1211 22:42:14.168798 17660 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1211 22:42:14.168798 17660 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1211 22:42:14.168798 17660 net.cpp:122] Setting up group0_block4_conv0_relu
I1211 22:42:14.168798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.168798 17660 net.cpp:137] Memory required for data: 328910000
I1211 22:42:14.168798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1211 22:42:14.168798 17660 net.cpp:84] Creating Layer group0_block4_conv1
I1211 22:42:14.168798 17660 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1211 22:42:14.168798 17660 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1211 22:42:14.170800 17660 net.cpp:122] Setting up group0_block4_conv1
I1211 22:42:14.170800 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.170800 17660 net.cpp:137] Memory required for data: 335463600
I1211 22:42:14.170800 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1211 22:42:14.170800 17660 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1211 22:42:14.170800 17660 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1211 22:42:14.170800 17660 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1211 22:42:14.171798 17660 net.cpp:122] Setting up group0_block4_conv1_bn
I1211 22:42:14.171798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.171798 17660 net.cpp:137] Memory required for data: 342017200
I1211 22:42:14.171798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 22:42:14.171798 17660 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1211 22:42:14.171798 17660 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1211 22:42:14.171798 17660 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1211 22:42:14.171798 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 22:42:14.171798 17660 net.cpp:122] Setting up group0_block4_conv1_scale
I1211 22:42:14.171798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.171798 17660 net.cpp:137] Memory required for data: 348570800
I1211 22:42:14.171798 17660 layer_factory.cpp:58] Creating layer group0_block4_sum
I1211 22:42:14.171798 17660 net.cpp:84] Creating Layer group0_block4_sum
I1211 22:42:14.171798 17660 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1211 22:42:14.171798 17660 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1211 22:42:14.171798 17660 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1211 22:42:14.171798 17660 net.cpp:122] Setting up group0_block4_sum
I1211 22:42:14.171798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.171798 17660 net.cpp:137] Memory required for data: 355124400
I1211 22:42:14.171798 17660 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1211 22:42:14.171798 17660 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1211 22:42:14.171798 17660 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1211 22:42:14.171798 17660 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1211 22:42:14.171798 17660 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1211 22:42:14.171798 17660 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1211 22:42:14.171798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.171798 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.171798 17660 net.cpp:137] Memory required for data: 368231600
I1211 22:42:14.171798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1211 22:42:14.171798 17660 net.cpp:84] Creating Layer group1_block0_conv0
I1211 22:42:14.171798 17660 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1211 22:42:14.171798 17660 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1211 22:42:14.174798 17660 net.cpp:122] Setting up group1_block0_conv0
I1211 22:42:14.174798 17660 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1211 22:42:14.174798 17660 net.cpp:137] Memory required for data: 381338800
I1211 22:42:14.174798 17660 layer_factory.cpp:58] Creating layer pool1
I1211 22:42:14.174798 17660 net.cpp:84] Creating Layer pool1
I1211 22:42:14.174798 17660 net.cpp:406] pool1 <- group1_block0_conv0
I1211 22:42:14.174798 17660 net.cpp:380] pool1 -> pool1
I1211 22:42:14.174798 17660 net.cpp:122] Setting up pool1
I1211 22:42:14.174798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.174798 17660 net.cpp:137] Memory required for data: 384615600
I1211 22:42:14.174798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1211 22:42:14.174798 17660 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1211 22:42:14.174798 17660 net.cpp:406] group1_block0_conv0_bn <- pool1
I1211 22:42:14.174798 17660 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1211 22:42:14.175798 17660 net.cpp:122] Setting up group1_block0_conv0_bn
I1211 22:42:14.175798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.175798 17660 net.cpp:137] Memory required for data: 387892400
I1211 22:42:14.175798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 22:42:14.175798 17660 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1211 22:42:14.175798 17660 net.cpp:406] group1_block0_conv0_scale <- pool1
I1211 22:42:14.175798 17660 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1211 22:42:14.175798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 22:42:14.175798 17660 net.cpp:122] Setting up group1_block0_conv0_scale
I1211 22:42:14.175798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.175798 17660 net.cpp:137] Memory required for data: 391169200
I1211 22:42:14.175798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1211 22:42:14.175798 17660 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1211 22:42:14.175798 17660 net.cpp:406] group1_block0_conv0_relu <- pool1
I1211 22:42:14.175798 17660 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1211 22:42:14.175798 17660 net.cpp:122] Setting up group1_block0_conv0_relu
I1211 22:42:14.175798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.175798 17660 net.cpp:137] Memory required for data: 394446000
I1211 22:42:14.175798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1211 22:42:14.175798 17660 net.cpp:84] Creating Layer group1_block0_conv1
I1211 22:42:14.175798 17660 net.cpp:406] group1_block0_conv1 <- pool1
I1211 22:42:14.175798 17660 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1211 22:42:14.177798 17660 net.cpp:122] Setting up group1_block0_conv1
I1211 22:42:14.178798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.178798 17660 net.cpp:137] Memory required for data: 397722800
I1211 22:42:14.178798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1211 22:42:14.178798 17660 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1211 22:42:14.178798 17660 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1211 22:42:14.178798 17660 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1211 22:42:14.178798 17660 net.cpp:122] Setting up group1_block0_conv1_bn
I1211 22:42:14.178798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.178798 17660 net.cpp:137] Memory required for data: 400999600
I1211 22:42:14.178798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 22:42:14.178798 17660 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1211 22:42:14.178798 17660 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1211 22:42:14.178798 17660 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1211 22:42:14.178798 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 22:42:14.178798 17660 net.cpp:122] Setting up group1_block0_conv1_scale
I1211 22:42:14.178798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.178798 17660 net.cpp:137] Memory required for data: 404276400
I1211 22:42:14.178798 17660 layer_factory.cpp:58] Creating layer group1_block0_proj
I1211 22:42:14.178798 17660 net.cpp:84] Creating Layer group1_block0_proj
I1211 22:42:14.178798 17660 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1211 22:42:14.178798 17660 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1211 22:42:14.180797 17660 net.cpp:122] Setting up group1_block0_proj
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1211 22:42:14.181797 17660 net.cpp:137] Memory required for data: 416577200
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer pool2
I1211 22:42:14.181797 17660 net.cpp:84] Creating Layer pool2
I1211 22:42:14.181797 17660 net.cpp:406] pool2 <- group1_block0_proj
I1211 22:42:14.181797 17660 net.cpp:380] pool2 -> pool2
I1211 22:42:14.181797 17660 net.cpp:122] Setting up pool2
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.181797 17660 net.cpp:137] Memory required for data: 419854000
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1211 22:42:14.181797 17660 net.cpp:84] Creating Layer group1_block0_proj_bn
I1211 22:42:14.181797 17660 net.cpp:406] group1_block0_proj_bn <- pool2
I1211 22:42:14.181797 17660 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1211 22:42:14.181797 17660 net.cpp:122] Setting up group1_block0_proj_bn
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.181797 17660 net.cpp:137] Memory required for data: 423130800
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 22:42:14.181797 17660 net.cpp:84] Creating Layer group1_block0_proj_scale
I1211 22:42:14.181797 17660 net.cpp:406] group1_block0_proj_scale <- pool2
I1211 22:42:14.181797 17660 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 22:42:14.181797 17660 net.cpp:122] Setting up group1_block0_proj_scale
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.181797 17660 net.cpp:137] Memory required for data: 426407600
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer group1_block0_sum
I1211 22:42:14.181797 17660 net.cpp:84] Creating Layer group1_block0_sum
I1211 22:42:14.181797 17660 net.cpp:406] group1_block0_sum <- pool2
I1211 22:42:14.181797 17660 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1211 22:42:14.181797 17660 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1211 22:42:14.181797 17660 net.cpp:122] Setting up group1_block0_sum
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.181797 17660 net.cpp:137] Memory required for data: 429684400
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1211 22:42:14.181797 17660 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1211 22:42:14.181797 17660 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1211 22:42:14.181797 17660 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1211 22:42:14.181797 17660 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1211 22:42:14.181797 17660 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.181797 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.181797 17660 net.cpp:137] Memory required for data: 436238000
I1211 22:42:14.181797 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1211 22:42:14.181797 17660 net.cpp:84] Creating Layer group1_block1_conv0
I1211 22:42:14.181797 17660 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1211 22:42:14.181797 17660 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1211 22:42:14.184798 17660 net.cpp:122] Setting up group1_block1_conv0
I1211 22:42:14.184798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.184798 17660 net.cpp:137] Memory required for data: 439514800
I1211 22:42:14.184798 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1211 22:42:14.184798 17660 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1211 22:42:14.184798 17660 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1211 22:42:14.184798 17660 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1211 22:42:14.184798 17660 net.cpp:122] Setting up group1_block1_conv0_bn
I1211 22:42:14.184798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.184798 17660 net.cpp:137] Memory required for data: 442791600
I1211 22:42:14.184798 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 22:42:14.184798 17660 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1211 22:42:14.184798 17660 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1211 22:42:14.184798 17660 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1211 22:42:14.184798 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 22:42:14.184798 17660 net.cpp:122] Setting up group1_block1_conv0_scale
I1211 22:42:14.184798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.184798 17660 net.cpp:137] Memory required for data: 446068400
I1211 22:42:14.184798 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1211 22:42:14.184798 17660 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1211 22:42:14.184798 17660 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1211 22:42:14.185798 17660 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1211 22:42:14.185798 17660 net.cpp:122] Setting up group1_block1_conv0_relu
I1211 22:42:14.185798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.185798 17660 net.cpp:137] Memory required for data: 449345200
I1211 22:42:14.185798 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1211 22:42:14.185798 17660 net.cpp:84] Creating Layer group1_block1_conv1
I1211 22:42:14.185798 17660 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1211 22:42:14.185798 17660 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1211 22:42:14.187799 17660 net.cpp:122] Setting up group1_block1_conv1
I1211 22:42:14.187799 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.187799 17660 net.cpp:137] Memory required for data: 452622000
I1211 22:42:14.187799 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1211 22:42:14.187799 17660 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1211 22:42:14.187799 17660 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1211 22:42:14.187799 17660 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1211 22:42:14.188801 17660 net.cpp:122] Setting up group1_block1_conv1_bn
I1211 22:42:14.188801 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.188801 17660 net.cpp:137] Memory required for data: 455898800
I1211 22:42:14.188801 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 22:42:14.188801 17660 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1211 22:42:14.188801 17660 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1211 22:42:14.188801 17660 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1211 22:42:14.188801 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 22:42:14.188801 17660 net.cpp:122] Setting up group1_block1_conv1_scale
I1211 22:42:14.188801 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.188801 17660 net.cpp:137] Memory required for data: 459175600
I1211 22:42:14.188801 17660 layer_factory.cpp:58] Creating layer group1_block1_sum
I1211 22:42:14.188801 17660 net.cpp:84] Creating Layer group1_block1_sum
I1211 22:42:14.188801 17660 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1211 22:42:14.188801 17660 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1211 22:42:14.188801 17660 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1211 22:42:14.188801 17660 net.cpp:122] Setting up group1_block1_sum
I1211 22:42:14.188801 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.188801 17660 net.cpp:137] Memory required for data: 462452400
I1211 22:42:14.188801 17660 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1211 22:42:14.188801 17660 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1211 22:42:14.188801 17660 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1211 22:42:14.188801 17660 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1211 22:42:14.188801 17660 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1211 22:42:14.188801 17660 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1211 22:42:14.188801 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.188801 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.188801 17660 net.cpp:137] Memory required for data: 469006000
I1211 22:42:14.188801 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1211 22:42:14.188801 17660 net.cpp:84] Creating Layer group1_block2_conv0
I1211 22:42:14.188801 17660 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1211 22:42:14.188801 17660 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1211 22:42:14.190798 17660 net.cpp:122] Setting up group1_block2_conv0
I1211 22:42:14.190798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.190798 17660 net.cpp:137] Memory required for data: 472282800
I1211 22:42:14.190798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1211 22:42:14.190798 17660 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1211 22:42:14.190798 17660 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1211 22:42:14.191798 17660 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1211 22:42:14.191798 17660 net.cpp:122] Setting up group1_block2_conv0_bn
I1211 22:42:14.191798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.191798 17660 net.cpp:137] Memory required for data: 475559600
I1211 22:42:14.191798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 22:42:14.191798 17660 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1211 22:42:14.191798 17660 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1211 22:42:14.191798 17660 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1211 22:42:14.191798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 22:42:14.191798 17660 net.cpp:122] Setting up group1_block2_conv0_scale
I1211 22:42:14.191798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.191798 17660 net.cpp:137] Memory required for data: 478836400
I1211 22:42:14.191798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1211 22:42:14.191798 17660 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1211 22:42:14.191798 17660 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1211 22:42:14.191798 17660 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1211 22:42:14.191798 17660 net.cpp:122] Setting up group1_block2_conv0_relu
I1211 22:42:14.191798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.191798 17660 net.cpp:137] Memory required for data: 482113200
I1211 22:42:14.191798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1211 22:42:14.192797 17660 net.cpp:84] Creating Layer group1_block2_conv1
I1211 22:42:14.192797 17660 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1211 22:42:14.192797 17660 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1211 22:42:14.194798 17660 net.cpp:122] Setting up group1_block2_conv1
I1211 22:42:14.194798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.194798 17660 net.cpp:137] Memory required for data: 485390000
I1211 22:42:14.194798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1211 22:42:14.194798 17660 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1211 22:42:14.194798 17660 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1211 22:42:14.194798 17660 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1211 22:42:14.195798 17660 net.cpp:122] Setting up group1_block2_conv1_bn
I1211 22:42:14.195798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.195798 17660 net.cpp:137] Memory required for data: 488666800
I1211 22:42:14.195798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 22:42:14.195798 17660 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1211 22:42:14.195798 17660 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1211 22:42:14.195798 17660 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1211 22:42:14.195798 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 22:42:14.195798 17660 net.cpp:122] Setting up group1_block2_conv1_scale
I1211 22:42:14.195798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.195798 17660 net.cpp:137] Memory required for data: 491943600
I1211 22:42:14.195798 17660 layer_factory.cpp:58] Creating layer group1_block2_sum
I1211 22:42:14.195798 17660 net.cpp:84] Creating Layer group1_block2_sum
I1211 22:42:14.195798 17660 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1211 22:42:14.195798 17660 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1211 22:42:14.195798 17660 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1211 22:42:14.195798 17660 net.cpp:122] Setting up group1_block2_sum
I1211 22:42:14.195798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.195798 17660 net.cpp:137] Memory required for data: 495220400
I1211 22:42:14.195798 17660 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1211 22:42:14.195798 17660 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1211 22:42:14.195798 17660 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1211 22:42:14.195798 17660 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1211 22:42:14.195798 17660 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1211 22:42:14.195798 17660 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1211 22:42:14.195798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.195798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.195798 17660 net.cpp:137] Memory required for data: 501774000
I1211 22:42:14.195798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1211 22:42:14.195798 17660 net.cpp:84] Creating Layer group1_block3_conv0
I1211 22:42:14.195798 17660 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1211 22:42:14.195798 17660 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1211 22:42:14.197798 17660 net.cpp:122] Setting up group1_block3_conv0
I1211 22:42:14.197798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.197798 17660 net.cpp:137] Memory required for data: 505050800
I1211 22:42:14.197798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1211 22:42:14.197798 17660 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1211 22:42:14.197798 17660 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1211 22:42:14.197798 17660 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1211 22:42:14.197798 17660 net.cpp:122] Setting up group1_block3_conv0_bn
I1211 22:42:14.197798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.197798 17660 net.cpp:137] Memory required for data: 508327600
I1211 22:42:14.197798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 22:42:14.197798 17660 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1211 22:42:14.197798 17660 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1211 22:42:14.197798 17660 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1211 22:42:14.197798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 22:42:14.198798 17660 net.cpp:122] Setting up group1_block3_conv0_scale
I1211 22:42:14.198798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.198798 17660 net.cpp:137] Memory required for data: 511604400
I1211 22:42:14.198798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1211 22:42:14.198798 17660 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1211 22:42:14.198798 17660 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1211 22:42:14.198798 17660 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1211 22:42:14.199798 17660 net.cpp:122] Setting up group1_block3_conv0_relu
I1211 22:42:14.199798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.199798 17660 net.cpp:137] Memory required for data: 514881200
I1211 22:42:14.199798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1211 22:42:14.199798 17660 net.cpp:84] Creating Layer group1_block3_conv1
I1211 22:42:14.199798 17660 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1211 22:42:14.199798 17660 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1211 22:42:14.200798 17660 net.cpp:122] Setting up group1_block3_conv1
I1211 22:42:14.200798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.200798 17660 net.cpp:137] Memory required for data: 518158000
I1211 22:42:14.200798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1211 22:42:14.200798 17660 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1211 22:42:14.200798 17660 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1211 22:42:14.200798 17660 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1211 22:42:14.201798 17660 net.cpp:122] Setting up group1_block3_conv1_bn
I1211 22:42:14.201798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.201798 17660 net.cpp:137] Memory required for data: 521434800
I1211 22:42:14.201798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 22:42:14.201798 17660 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1211 22:42:14.201798 17660 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1211 22:42:14.201798 17660 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1211 22:42:14.201798 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 22:42:14.201798 17660 net.cpp:122] Setting up group1_block3_conv1_scale
I1211 22:42:14.201798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.201798 17660 net.cpp:137] Memory required for data: 524711600
I1211 22:42:14.201798 17660 layer_factory.cpp:58] Creating layer group1_block3_sum
I1211 22:42:14.201798 17660 net.cpp:84] Creating Layer group1_block3_sum
I1211 22:42:14.201798 17660 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1211 22:42:14.201798 17660 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1211 22:42:14.201798 17660 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1211 22:42:14.201798 17660 net.cpp:122] Setting up group1_block3_sum
I1211 22:42:14.201798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.201798 17660 net.cpp:137] Memory required for data: 527988400
I1211 22:42:14.201798 17660 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1211 22:42:14.201798 17660 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1211 22:42:14.201798 17660 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1211 22:42:14.201798 17660 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1211 22:42:14.201798 17660 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1211 22:42:14.201798 17660 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1211 22:42:14.201798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.201798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.201798 17660 net.cpp:137] Memory required for data: 534542000
I1211 22:42:14.201798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1211 22:42:14.201798 17660 net.cpp:84] Creating Layer group1_block4_conv0
I1211 22:42:14.201798 17660 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1211 22:42:14.201798 17660 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1211 22:42:14.204798 17660 net.cpp:122] Setting up group1_block4_conv0
I1211 22:42:14.204798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.204798 17660 net.cpp:137] Memory required for data: 537818800
I1211 22:42:14.204798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1211 22:42:14.204798 17660 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1211 22:42:14.204798 17660 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1211 22:42:14.204798 17660 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1211 22:42:14.204798 17660 net.cpp:122] Setting up group1_block4_conv0_bn
I1211 22:42:14.204798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.204798 17660 net.cpp:137] Memory required for data: 541095600
I1211 22:42:14.204798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 22:42:14.204798 17660 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1211 22:42:14.204798 17660 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1211 22:42:14.204798 17660 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1211 22:42:14.204798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 22:42:14.204798 17660 net.cpp:122] Setting up group1_block4_conv0_scale
I1211 22:42:14.204798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.205798 17660 net.cpp:137] Memory required for data: 544372400
I1211 22:42:14.205798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1211 22:42:14.205798 17660 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1211 22:42:14.205798 17660 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1211 22:42:14.205798 17660 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1211 22:42:14.205798 17660 net.cpp:122] Setting up group1_block4_conv0_relu
I1211 22:42:14.205798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.205798 17660 net.cpp:137] Memory required for data: 547649200
I1211 22:42:14.205798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1211 22:42:14.206799 17660 net.cpp:84] Creating Layer group1_block4_conv1
I1211 22:42:14.206799 17660 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1211 22:42:14.206799 17660 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1211 22:42:14.207798 17660 net.cpp:122] Setting up group1_block4_conv1
I1211 22:42:14.207798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.207798 17660 net.cpp:137] Memory required for data: 550926000
I1211 22:42:14.207798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1211 22:42:14.207798 17660 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1211 22:42:14.207798 17660 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1211 22:42:14.207798 17660 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1211 22:42:14.207798 17660 net.cpp:122] Setting up group1_block4_conv1_bn
I1211 22:42:14.207798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.207798 17660 net.cpp:137] Memory required for data: 554202800
I1211 22:42:14.207798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 22:42:14.207798 17660 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1211 22:42:14.207798 17660 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1211 22:42:14.207798 17660 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1211 22:42:14.207798 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 22:42:14.208798 17660 net.cpp:122] Setting up group1_block4_conv1_scale
I1211 22:42:14.208798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.208798 17660 net.cpp:137] Memory required for data: 557479600
I1211 22:42:14.208798 17660 layer_factory.cpp:58] Creating layer group1_block4_sum
I1211 22:42:14.208798 17660 net.cpp:84] Creating Layer group1_block4_sum
I1211 22:42:14.208798 17660 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1211 22:42:14.208798 17660 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1211 22:42:14.208798 17660 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1211 22:42:14.208798 17660 net.cpp:122] Setting up group1_block4_sum
I1211 22:42:14.208798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.208798 17660 net.cpp:137] Memory required for data: 560756400
I1211 22:42:14.208798 17660 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1211 22:42:14.208798 17660 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1211 22:42:14.208798 17660 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1211 22:42:14.208798 17660 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1211 22:42:14.208798 17660 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1211 22:42:14.208798 17660 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1211 22:42:14.208798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.208798 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.208798 17660 net.cpp:137] Memory required for data: 567310000
I1211 22:42:14.208798 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1211 22:42:14.208798 17660 net.cpp:84] Creating Layer group2_block0_conv0
I1211 22:42:14.208798 17660 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1211 22:42:14.208798 17660 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1211 22:42:14.211798 17660 net.cpp:122] Setting up group2_block0_conv0
I1211 22:42:14.211798 17660 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1211 22:42:14.211798 17660 net.cpp:137] Memory required for data: 573863600
I1211 22:42:14.211798 17660 layer_factory.cpp:58] Creating layer pool3
I1211 22:42:14.211798 17660 net.cpp:84] Creating Layer pool3
I1211 22:42:14.211798 17660 net.cpp:406] pool3 <- group2_block0_conv0
I1211 22:42:14.211798 17660 net.cpp:380] pool3 -> pool3
I1211 22:42:14.212797 17660 net.cpp:122] Setting up pool3
I1211 22:42:14.212797 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.212797 17660 net.cpp:137] Memory required for data: 575502000
I1211 22:42:14.212797 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1211 22:42:14.212797 17660 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1211 22:42:14.212797 17660 net.cpp:406] group2_block0_conv0_bn <- pool3
I1211 22:42:14.212797 17660 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1211 22:42:14.212797 17660 net.cpp:122] Setting up group2_block0_conv0_bn
I1211 22:42:14.212797 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.212797 17660 net.cpp:137] Memory required for data: 577140400
I1211 22:42:14.212797 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 22:42:14.212797 17660 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1211 22:42:14.212797 17660 net.cpp:406] group2_block0_conv0_scale <- pool3
I1211 22:42:14.212797 17660 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1211 22:42:14.212797 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 22:42:14.212797 17660 net.cpp:122] Setting up group2_block0_conv0_scale
I1211 22:42:14.212797 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.212797 17660 net.cpp:137] Memory required for data: 578778800
I1211 22:42:14.212797 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1211 22:42:14.212797 17660 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1211 22:42:14.212797 17660 net.cpp:406] group2_block0_conv0_relu <- pool3
I1211 22:42:14.212797 17660 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1211 22:42:14.213798 17660 net.cpp:122] Setting up group2_block0_conv0_relu
I1211 22:42:14.213798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.213798 17660 net.cpp:137] Memory required for data: 580417200
I1211 22:42:14.213798 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1211 22:42:14.213798 17660 net.cpp:84] Creating Layer group2_block0_conv1
I1211 22:42:14.213798 17660 net.cpp:406] group2_block0_conv1 <- pool3
I1211 22:42:14.213798 17660 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1211 22:42:14.216799 17660 net.cpp:122] Setting up group2_block0_conv1
I1211 22:42:14.216799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.216799 17660 net.cpp:137] Memory required for data: 582055600
I1211 22:42:14.216799 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1211 22:42:14.216799 17660 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1211 22:42:14.216799 17660 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1211 22:42:14.216799 17660 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1211 22:42:14.216799 17660 net.cpp:122] Setting up group2_block0_conv1_bn
I1211 22:42:14.216799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.216799 17660 net.cpp:137] Memory required for data: 583694000
I1211 22:42:14.216799 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 22:42:14.216799 17660 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1211 22:42:14.216799 17660 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1211 22:42:14.216799 17660 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1211 22:42:14.216799 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 22:42:14.217798 17660 net.cpp:122] Setting up group2_block0_conv1_scale
I1211 22:42:14.217798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.217798 17660 net.cpp:137] Memory required for data: 585332400
I1211 22:42:14.217798 17660 layer_factory.cpp:58] Creating layer group2_block0_proj
I1211 22:42:14.217798 17660 net.cpp:84] Creating Layer group2_block0_proj
I1211 22:42:14.217798 17660 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1211 22:42:14.217798 17660 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1211 22:42:14.219799 17660 net.cpp:122] Setting up group2_block0_proj
I1211 22:42:14.219799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.219799 17660 net.cpp:137] Memory required for data: 586970800
I1211 22:42:14.219799 17660 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1211 22:42:14.219799 17660 net.cpp:84] Creating Layer group2_block0_proj_bn
I1211 22:42:14.219799 17660 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1211 22:42:14.219799 17660 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1211 22:42:14.220799 17660 net.cpp:122] Setting up group2_block0_proj_bn
I1211 22:42:14.220799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.220799 17660 net.cpp:137] Memory required for data: 588609200
I1211 22:42:14.220799 17660 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 22:42:14.220799 17660 net.cpp:84] Creating Layer group2_block0_proj_scale
I1211 22:42:14.220799 17660 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1211 22:42:14.220799 17660 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1211 22:42:14.220799 17660 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 22:42:14.220799 17660 net.cpp:122] Setting up group2_block0_proj_scale
I1211 22:42:14.220799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.220799 17660 net.cpp:137] Memory required for data: 590247600
I1211 22:42:14.220799 17660 layer_factory.cpp:58] Creating layer group2_block0_sum
I1211 22:42:14.220799 17660 net.cpp:84] Creating Layer group2_block0_sum
I1211 22:42:14.220799 17660 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1211 22:42:14.220799 17660 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1211 22:42:14.220799 17660 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1211 22:42:14.220799 17660 net.cpp:122] Setting up group2_block0_sum
I1211 22:42:14.220799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.220799 17660 net.cpp:137] Memory required for data: 591886000
I1211 22:42:14.220799 17660 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1211 22:42:14.220799 17660 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1211 22:42:14.220799 17660 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1211 22:42:14.220799 17660 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1211 22:42:14.220799 17660 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1211 22:42:14.220799 17660 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1211 22:42:14.220799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.220799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.220799 17660 net.cpp:137] Memory required for data: 595162800
I1211 22:42:14.220799 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1211 22:42:14.220799 17660 net.cpp:84] Creating Layer group2_block1_conv0
I1211 22:42:14.220799 17660 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1211 22:42:14.220799 17660 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1211 22:42:14.223799 17660 net.cpp:122] Setting up group2_block1_conv0
I1211 22:42:14.223799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.223799 17660 net.cpp:137] Memory required for data: 596801200
I1211 22:42:14.223799 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1211 22:42:14.223799 17660 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1211 22:42:14.223799 17660 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1211 22:42:14.223799 17660 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1211 22:42:14.223799 17660 net.cpp:122] Setting up group2_block1_conv0_bn
I1211 22:42:14.224798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.224798 17660 net.cpp:137] Memory required for data: 598439600
I1211 22:42:14.224798 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 22:42:14.224798 17660 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1211 22:42:14.224798 17660 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1211 22:42:14.224798 17660 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1211 22:42:14.224798 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 22:42:14.224798 17660 net.cpp:122] Setting up group2_block1_conv0_scale
I1211 22:42:14.224798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.224798 17660 net.cpp:137] Memory required for data: 600078000
I1211 22:42:14.224798 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1211 22:42:14.224798 17660 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1211 22:42:14.224798 17660 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1211 22:42:14.224798 17660 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1211 22:42:14.225797 17660 net.cpp:122] Setting up group2_block1_conv0_relu
I1211 22:42:14.225797 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.225797 17660 net.cpp:137] Memory required for data: 601716400
I1211 22:42:14.225797 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1211 22:42:14.225797 17660 net.cpp:84] Creating Layer group2_block1_conv1
I1211 22:42:14.225797 17660 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1211 22:42:14.225797 17660 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1211 22:42:14.228799 17660 net.cpp:122] Setting up group2_block1_conv1
I1211 22:42:14.228799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.228799 17660 net.cpp:137] Memory required for data: 603354800
I1211 22:42:14.228799 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1211 22:42:14.228799 17660 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1211 22:42:14.228799 17660 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1211 22:42:14.228799 17660 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1211 22:42:14.228799 17660 net.cpp:122] Setting up group2_block1_conv1_bn
I1211 22:42:14.228799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.228799 17660 net.cpp:137] Memory required for data: 604993200
I1211 22:42:14.228799 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 22:42:14.228799 17660 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1211 22:42:14.228799 17660 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1211 22:42:14.228799 17660 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1211 22:42:14.228799 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 22:42:14.228799 17660 net.cpp:122] Setting up group2_block1_conv1_scale
I1211 22:42:14.228799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.228799 17660 net.cpp:137] Memory required for data: 606631600
I1211 22:42:14.228799 17660 layer_factory.cpp:58] Creating layer group2_block1_sum
I1211 22:42:14.228799 17660 net.cpp:84] Creating Layer group2_block1_sum
I1211 22:42:14.228799 17660 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1211 22:42:14.228799 17660 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1211 22:42:14.228799 17660 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1211 22:42:14.228799 17660 net.cpp:122] Setting up group2_block1_sum
I1211 22:42:14.228799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.228799 17660 net.cpp:137] Memory required for data: 608270000
I1211 22:42:14.228799 17660 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1211 22:42:14.228799 17660 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1211 22:42:14.228799 17660 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1211 22:42:14.228799 17660 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1211 22:42:14.228799 17660 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1211 22:42:14.229799 17660 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1211 22:42:14.229799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.229799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.229799 17660 net.cpp:137] Memory required for data: 611546800
I1211 22:42:14.229799 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1211 22:42:14.229799 17660 net.cpp:84] Creating Layer group2_block2_conv0
I1211 22:42:14.229799 17660 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1211 22:42:14.229799 17660 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1211 22:42:14.231798 17660 net.cpp:122] Setting up group2_block2_conv0
I1211 22:42:14.231798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.232803 17660 net.cpp:137] Memory required for data: 613185200
I1211 22:42:14.232803 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1211 22:42:14.232803 17660 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1211 22:42:14.232803 17660 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1211 22:42:14.232803 17660 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1211 22:42:14.232803 17660 net.cpp:122] Setting up group2_block2_conv0_bn
I1211 22:42:14.232803 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.232803 17660 net.cpp:137] Memory required for data: 614823600
I1211 22:42:14.232803 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 22:42:14.232803 17660 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1211 22:42:14.232803 17660 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1211 22:42:14.232803 17660 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1211 22:42:14.232803 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 22:42:14.232803 17660 net.cpp:122] Setting up group2_block2_conv0_scale
I1211 22:42:14.232803 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.232803 17660 net.cpp:137] Memory required for data: 616462000
I1211 22:42:14.232803 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1211 22:42:14.232803 17660 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1211 22:42:14.232803 17660 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1211 22:42:14.232803 17660 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1211 22:42:14.233798 17660 net.cpp:122] Setting up group2_block2_conv0_relu
I1211 22:42:14.233798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.233798 17660 net.cpp:137] Memory required for data: 618100400
I1211 22:42:14.233798 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1211 22:42:14.233798 17660 net.cpp:84] Creating Layer group2_block2_conv1
I1211 22:42:14.233798 17660 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1211 22:42:14.233798 17660 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1211 22:42:14.236798 17660 net.cpp:122] Setting up group2_block2_conv1
I1211 22:42:14.236798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.236798 17660 net.cpp:137] Memory required for data: 619738800
I1211 22:42:14.236798 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1211 22:42:14.236798 17660 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1211 22:42:14.236798 17660 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1211 22:42:14.236798 17660 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1211 22:42:14.236798 17660 net.cpp:122] Setting up group2_block2_conv1_bn
I1211 22:42:14.237798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.237798 17660 net.cpp:137] Memory required for data: 621377200
I1211 22:42:14.237798 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 22:42:14.237798 17660 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1211 22:42:14.237798 17660 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1211 22:42:14.237798 17660 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1211 22:42:14.237798 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 22:42:14.237798 17660 net.cpp:122] Setting up group2_block2_conv1_scale
I1211 22:42:14.237798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.237798 17660 net.cpp:137] Memory required for data: 623015600
I1211 22:42:14.237798 17660 layer_factory.cpp:58] Creating layer group2_block2_sum
I1211 22:42:14.237798 17660 net.cpp:84] Creating Layer group2_block2_sum
I1211 22:42:14.237798 17660 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1211 22:42:14.237798 17660 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1211 22:42:14.237798 17660 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1211 22:42:14.237798 17660 net.cpp:122] Setting up group2_block2_sum
I1211 22:42:14.237798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.237798 17660 net.cpp:137] Memory required for data: 624654000
I1211 22:42:14.237798 17660 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1211 22:42:14.237798 17660 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1211 22:42:14.237798 17660 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1211 22:42:14.237798 17660 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1211 22:42:14.237798 17660 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1211 22:42:14.237798 17660 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1211 22:42:14.237798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.237798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.237798 17660 net.cpp:137] Memory required for data: 627930800
I1211 22:42:14.237798 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1211 22:42:14.237798 17660 net.cpp:84] Creating Layer group2_block3_conv0
I1211 22:42:14.237798 17660 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1211 22:42:14.237798 17660 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1211 22:42:14.240798 17660 net.cpp:122] Setting up group2_block3_conv0
I1211 22:42:14.240798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.240798 17660 net.cpp:137] Memory required for data: 629569200
I1211 22:42:14.240798 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1211 22:42:14.240798 17660 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1211 22:42:14.240798 17660 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1211 22:42:14.240798 17660 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1211 22:42:14.240798 17660 net.cpp:122] Setting up group2_block3_conv0_bn
I1211 22:42:14.240798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.240798 17660 net.cpp:137] Memory required for data: 631207600
I1211 22:42:14.240798 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 22:42:14.240798 17660 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1211 22:42:14.240798 17660 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1211 22:42:14.240798 17660 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1211 22:42:14.240798 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 22:42:14.241798 17660 net.cpp:122] Setting up group2_block3_conv0_scale
I1211 22:42:14.241798 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.241798 17660 net.cpp:137] Memory required for data: 632846000
I1211 22:42:14.241798 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1211 22:42:14.241798 17660 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1211 22:42:14.241798 17660 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1211 22:42:14.241798 17660 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1211 22:42:14.242799 17660 net.cpp:122] Setting up group2_block3_conv0_relu
I1211 22:42:14.242799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.242799 17660 net.cpp:137] Memory required for data: 634484400
I1211 22:42:14.242799 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1211 22:42:14.242799 17660 net.cpp:84] Creating Layer group2_block3_conv1
I1211 22:42:14.242799 17660 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1211 22:42:14.242799 17660 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1211 22:42:14.244799 17660 net.cpp:122] Setting up group2_block3_conv1
I1211 22:42:14.244799 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.244799 17660 net.cpp:137] Memory required for data: 636122800
I1211 22:42:14.244799 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1211 22:42:14.244799 17660 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1211 22:42:14.244799 17660 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1211 22:42:14.245801 17660 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1211 22:42:14.245801 17660 net.cpp:122] Setting up group2_block3_conv1_bn
I1211 22:42:14.245801 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.245801 17660 net.cpp:137] Memory required for data: 637761200
I1211 22:42:14.245801 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 22:42:14.245801 17660 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1211 22:42:14.245801 17660 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1211 22:42:14.245801 17660 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1211 22:42:14.245801 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 22:42:14.245801 17660 net.cpp:122] Setting up group2_block3_conv1_scale
I1211 22:42:14.245801 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.245801 17660 net.cpp:137] Memory required for data: 639399600
I1211 22:42:14.245801 17660 layer_factory.cpp:58] Creating layer group2_block3_sum
I1211 22:42:14.245801 17660 net.cpp:84] Creating Layer group2_block3_sum
I1211 22:42:14.245801 17660 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1211 22:42:14.245801 17660 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1211 22:42:14.245801 17660 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1211 22:42:14.245801 17660 net.cpp:122] Setting up group2_block3_sum
I1211 22:42:14.245801 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.245801 17660 net.cpp:137] Memory required for data: 641038000
I1211 22:42:14.245801 17660 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1211 22:42:14.245801 17660 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1211 22:42:14.245801 17660 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1211 22:42:14.245801 17660 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1211 22:42:14.245801 17660 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1211 22:42:14.245801 17660 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1211 22:42:14.245801 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.245801 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.245801 17660 net.cpp:137] Memory required for data: 644314800
I1211 22:42:14.245801 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1211 22:42:14.246799 17660 net.cpp:84] Creating Layer group2_block4_conv0
I1211 22:42:14.246799 17660 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1211 22:42:14.246799 17660 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1211 22:42:14.249806 17660 net.cpp:122] Setting up group2_block4_conv0
I1211 22:42:14.249806 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.249806 17660 net.cpp:137] Memory required for data: 645953200
I1211 22:42:14.249806 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1211 22:42:14.249806 17660 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1211 22:42:14.249806 17660 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1211 22:42:14.249806 17660 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1211 22:42:14.250306 17660 net.cpp:122] Setting up group2_block4_conv0_bn
I1211 22:42:14.250306 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.250306 17660 net.cpp:137] Memory required for data: 647591600
I1211 22:42:14.250306 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 22:42:14.250306 17660 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1211 22:42:14.250306 17660 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1211 22:42:14.250306 17660 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1211 22:42:14.250306 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 22:42:14.250805 17660 net.cpp:122] Setting up group2_block4_conv0_scale
I1211 22:42:14.250805 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.250805 17660 net.cpp:137] Memory required for data: 649230000
I1211 22:42:14.250805 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1211 22:42:14.250805 17660 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1211 22:42:14.250805 17660 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1211 22:42:14.250805 17660 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1211 22:42:14.250805 17660 net.cpp:122] Setting up group2_block4_conv0_relu
I1211 22:42:14.250805 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.250805 17660 net.cpp:137] Memory required for data: 650868400
I1211 22:42:14.250805 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1211 22:42:14.250805 17660 net.cpp:84] Creating Layer group2_block4_conv1
I1211 22:42:14.250805 17660 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1211 22:42:14.250805 17660 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1211 22:42:14.253806 17660 net.cpp:122] Setting up group2_block4_conv1
I1211 22:42:14.253806 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.253806 17660 net.cpp:137] Memory required for data: 652506800
I1211 22:42:14.253806 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1211 22:42:14.253806 17660 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1211 22:42:14.253806 17660 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1211 22:42:14.254307 17660 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1211 22:42:14.254307 17660 net.cpp:122] Setting up group2_block4_conv1_bn
I1211 22:42:14.254307 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.254307 17660 net.cpp:137] Memory required for data: 654145200
I1211 22:42:14.254307 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 22:42:14.254307 17660 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1211 22:42:14.254307 17660 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1211 22:42:14.254307 17660 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1211 22:42:14.254808 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 22:42:14.254808 17660 net.cpp:122] Setting up group2_block4_conv1_scale
I1211 22:42:14.254808 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.254808 17660 net.cpp:137] Memory required for data: 655783600
I1211 22:42:14.254808 17660 layer_factory.cpp:58] Creating layer group2_block4_sum
I1211 22:42:14.254808 17660 net.cpp:84] Creating Layer group2_block4_sum
I1211 22:42:14.254808 17660 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1211 22:42:14.254808 17660 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1211 22:42:14.254808 17660 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1211 22:42:14.254808 17660 net.cpp:122] Setting up group2_block4_sum
I1211 22:42:14.254808 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.254808 17660 net.cpp:137] Memory required for data: 657422000
I1211 22:42:14.254808 17660 layer_factory.cpp:58] Creating layer global_avg_pool
I1211 22:42:14.254808 17660 net.cpp:84] Creating Layer global_avg_pool
I1211 22:42:14.254808 17660 net.cpp:406] global_avg_pool <- group2_block4_sum
I1211 22:42:14.254808 17660 net.cpp:380] global_avg_pool -> global_avg_pool
I1211 22:42:14.255306 17660 net.cpp:122] Setting up global_avg_pool
I1211 22:42:14.255306 17660 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1211 22:42:14.255306 17660 net.cpp:137] Memory required for data: 657447600
I1211 22:42:14.255306 17660 layer_factory.cpp:58] Creating layer fc
I1211 22:42:14.255805 17660 net.cpp:84] Creating Layer fc
I1211 22:42:14.255805 17660 net.cpp:406] fc <- global_avg_pool
I1211 22:42:14.255805 17660 net.cpp:380] fc -> fc
I1211 22:42:14.255805 17660 net.cpp:122] Setting up fc
I1211 22:42:14.255805 17660 net.cpp:129] Top shape: 100 10 (1000)
I1211 22:42:14.255805 17660 net.cpp:137] Memory required for data: 657451600
I1211 22:42:14.255805 17660 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1211 22:42:14.255805 17660 net.cpp:84] Creating Layer fc_fc_0_split
I1211 22:42:14.255805 17660 net.cpp:406] fc_fc_0_split <- fc
I1211 22:42:14.255805 17660 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1211 22:42:14.255805 17660 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1211 22:42:14.255805 17660 net.cpp:122] Setting up fc_fc_0_split
I1211 22:42:14.256305 17660 net.cpp:129] Top shape: 100 10 (1000)
I1211 22:42:14.256305 17660 net.cpp:129] Top shape: 100 10 (1000)
I1211 22:42:14.256305 17660 net.cpp:137] Memory required for data: 657459600
I1211 22:42:14.256305 17660 layer_factory.cpp:58] Creating layer accuracy_training
I1211 22:42:14.256305 17660 net.cpp:84] Creating Layer accuracy_training
I1211 22:42:14.256305 17660 net.cpp:406] accuracy_training <- fc_fc_0_split_0
I1211 22:42:14.256305 17660 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1211 22:42:14.256305 17660 net.cpp:380] accuracy_training -> accuracy_training
I1211 22:42:14.256305 17660 net.cpp:122] Setting up accuracy_training
I1211 22:42:14.256305 17660 net.cpp:129] Top shape: (1)
I1211 22:42:14.256305 17660 net.cpp:137] Memory required for data: 657459604
I1211 22:42:14.256305 17660 layer_factory.cpp:58] Creating layer loss
I1211 22:42:14.256305 17660 net.cpp:84] Creating Layer loss
I1211 22:42:14.256305 17660 net.cpp:406] loss <- fc_fc_0_split_1
I1211 22:42:14.256305 17660 net.cpp:406] loss <- label_cifar_1_split_1
I1211 22:42:14.256305 17660 net.cpp:380] loss -> loss
I1211 22:42:14.256305 17660 layer_factory.cpp:58] Creating layer loss
I1211 22:42:14.256806 17660 net.cpp:122] Setting up loss
I1211 22:42:14.256806 17660 net.cpp:129] Top shape: (1)
I1211 22:42:14.256806 17660 net.cpp:132]     with loss weight 1
I1211 22:42:14.256806 17660 net.cpp:137] Memory required for data: 657459608
I1211 22:42:14.256806 17660 net.cpp:198] loss needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:200] accuracy_training does not need backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] fc_fc_0_split needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] fc needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] global_avg_pool needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_sum needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_conv1 needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1211 22:42:14.256806 17660 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block4_conv0 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_sum needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv1 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block3_conv0 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_sum needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv1 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block2_conv0 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_sum needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv1 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block1_conv0 needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block0_sum needs backward computation.
I1211 22:42:14.257308 17660 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_proj needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv1 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] pool3 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group2_block0_conv0 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_sum needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv1 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block4_conv0 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_sum needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv1 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block3_conv0 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_sum needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_conv1 needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1211 22:42:14.257805 17660 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block2_conv0 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_sum needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv1 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block1_conv0 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_sum needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] pool2 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_proj needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv1 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] pool1 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group1_block0_conv0 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_sum needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_conv1 needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1211 22:42:14.258304 17660 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block4_conv0 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_sum needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv1 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block3_conv0 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_sum needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv1 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block2_conv0 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_sum needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv1 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block1_conv0 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_sum needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv1 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] group0_block0_conv0 needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] first_conv_relu needs backward computation.
I1211 22:42:14.258805 17660 net.cpp:198] first_conv_scale needs backward computation.
I1211 22:42:14.259306 17660 net.cpp:198] first_conv_bn needs backward computation.
I1211 22:42:14.259306 17660 net.cpp:198] first_conv needs backward computation.
I1211 22:42:14.259306 17660 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 22:42:14.259306 17660 net.cpp:200] cifar does not need backward computation.
I1211 22:42:14.259306 17660 net.cpp:242] This network produces output accuracy_training
I1211 22:42:14.259306 17660 net.cpp:242] This network produces output loss
I1211 22:42:14.259306 17660 net.cpp:255] Network initialization done.
I1211 22:42:14.260807 17660 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 22:42:14.260807 17660 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 22:42:14.260807 17660 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1211 22:42:14.261306 17660 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1211 22:42:14.261306 17660 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1211 22:42:14.261806 17660 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "Soft
I1211 22:42:14.262805 17660 layer_factory.cpp:58] Creating layer cifar
I1211 22:42:14.270814 17660 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I1211 22:42:14.272814 17660 net.cpp:84] Creating Layer cifar
I1211 22:42:14.272814 17660 net.cpp:380] cifar -> data
I1211 22:42:14.272814 17660 net.cpp:380] cifar -> label
I1211 22:42:14.272814 17660 data_layer.cpp:45] output data size: 100,3,32,32
I1211 22:42:14.279814 17660 net.cpp:122] Setting up cifar
I1211 22:42:14.279814 17660 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1211 22:42:14.279814 17660 net.cpp:129] Top shape: 100 (100)
I1211 22:42:14.279814 17660 net.cpp:137] Memory required for data: 1229200
I1211 22:42:14.279814 17660 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1211 22:42:14.279814 17660 net.cpp:84] Creating Layer label_cifar_1_split
I1211 22:42:14.279814 17660 net.cpp:406] label_cifar_1_split <- label
I1211 22:42:14.279814 17660 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1211 22:42:14.279814 17660 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1211 22:42:14.279814 17660 net.cpp:122] Setting up label_cifar_1_split
I1211 22:42:14.280813 17660 net.cpp:129] Top shape: 100 (100)
I1211 22:42:14.280813 17660 net.cpp:129] Top shape: 100 (100)
I1211 22:42:14.280813 17660 net.cpp:137] Memory required for data: 1230000
I1211 22:42:14.280813 17660 layer_factory.cpp:58] Creating layer first_conv
I1211 22:42:14.280813 17660 net.cpp:84] Creating Layer first_conv
I1211 22:42:14.280813 17660 net.cpp:406] first_conv <- data
I1211 22:42:14.280813 17660 net.cpp:380] first_conv -> first_conv
I1211 22:42:14.281814 22400 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1211 22:42:14.283814 17660 net.cpp:122] Setting up first_conv
I1211 22:42:14.283814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.283814 17660 net.cpp:137] Memory required for data: 7783600
I1211 22:42:14.283814 17660 layer_factory.cpp:58] Creating layer first_conv_bn
I1211 22:42:14.283814 17660 net.cpp:84] Creating Layer first_conv_bn
I1211 22:42:14.283814 17660 net.cpp:406] first_conv_bn <- first_conv
I1211 22:42:14.283814 17660 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1211 22:42:14.283814 17660 net.cpp:122] Setting up first_conv_bn
I1211 22:42:14.283814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.283814 17660 net.cpp:137] Memory required for data: 14337200
I1211 22:42:14.283814 17660 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 22:42:14.283814 17660 net.cpp:84] Creating Layer first_conv_scale
I1211 22:42:14.283814 17660 net.cpp:406] first_conv_scale <- first_conv
I1211 22:42:14.283814 17660 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1211 22:42:14.283814 17660 layer_factory.cpp:58] Creating layer first_conv_scale
I1211 22:42:14.284816 17660 net.cpp:122] Setting up first_conv_scale
I1211 22:42:14.284816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.284816 17660 net.cpp:137] Memory required for data: 20890800
I1211 22:42:14.284816 17660 layer_factory.cpp:58] Creating layer first_conv_relu
I1211 22:42:14.284816 17660 net.cpp:84] Creating Layer first_conv_relu
I1211 22:42:14.284816 17660 net.cpp:406] first_conv_relu <- first_conv
I1211 22:42:14.284816 17660 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1211 22:42:14.284816 17660 net.cpp:122] Setting up first_conv_relu
I1211 22:42:14.284816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.284816 17660 net.cpp:137] Memory required for data: 27444400
I1211 22:42:14.285815 17660 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1211 22:42:14.285815 17660 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1211 22:42:14.285815 17660 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1211 22:42:14.285815 17660 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1211 22:42:14.285815 17660 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1211 22:42:14.285815 17660 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1211 22:42:14.285815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.285815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.285815 17660 net.cpp:137] Memory required for data: 40551600
I1211 22:42:14.285815 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1211 22:42:14.285815 17660 net.cpp:84] Creating Layer group0_block0_conv0
I1211 22:42:14.285815 17660 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1211 22:42:14.285815 17660 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1211 22:42:14.288815 17660 net.cpp:122] Setting up group0_block0_conv0
I1211 22:42:14.288815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.288815 17660 net.cpp:137] Memory required for data: 47105200
I1211 22:42:14.288815 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1211 22:42:14.288815 17660 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1211 22:42:14.288815 17660 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1211 22:42:14.288815 17660 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1211 22:42:14.289815 17660 net.cpp:122] Setting up group0_block0_conv0_bn
I1211 22:42:14.289815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.289815 17660 net.cpp:137] Memory required for data: 53658800
I1211 22:42:14.289815 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 22:42:14.289815 17660 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1211 22:42:14.289815 17660 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1211 22:42:14.289815 17660 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1211 22:42:14.289815 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1211 22:42:14.289815 17660 net.cpp:122] Setting up group0_block0_conv0_scale
I1211 22:42:14.289815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.289815 17660 net.cpp:137] Memory required for data: 60212400
I1211 22:42:14.289815 17660 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1211 22:42:14.289815 17660 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1211 22:42:14.289815 17660 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1211 22:42:14.289815 17660 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1211 22:42:14.291816 17660 net.cpp:122] Setting up group0_block0_conv0_relu
I1211 22:42:14.291816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.291816 17660 net.cpp:137] Memory required for data: 66766000
I1211 22:42:14.291816 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1211 22:42:14.291816 17660 net.cpp:84] Creating Layer group0_block0_conv1
I1211 22:42:14.291816 17660 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1211 22:42:14.291816 17660 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1211 22:42:14.294816 17660 net.cpp:122] Setting up group0_block0_conv1
I1211 22:42:14.294816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.294816 17660 net.cpp:137] Memory required for data: 73319600
I1211 22:42:14.294816 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1211 22:42:14.294816 17660 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1211 22:42:14.294816 17660 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1211 22:42:14.294816 17660 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1211 22:42:14.295814 17660 net.cpp:122] Setting up group0_block0_conv1_bn
I1211 22:42:14.295814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.295814 17660 net.cpp:137] Memory required for data: 79873200
I1211 22:42:14.295814 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 22:42:14.295814 17660 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1211 22:42:14.295814 17660 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1211 22:42:14.295814 17660 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1211 22:42:14.295814 17660 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1211 22:42:14.295814 17660 net.cpp:122] Setting up group0_block0_conv1_scale
I1211 22:42:14.295814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.295814 17660 net.cpp:137] Memory required for data: 86426800
I1211 22:42:14.295814 17660 layer_factory.cpp:58] Creating layer group0_block0_sum
I1211 22:42:14.295814 17660 net.cpp:84] Creating Layer group0_block0_sum
I1211 22:42:14.295814 17660 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1211 22:42:14.295814 17660 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1211 22:42:14.295814 17660 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1211 22:42:14.295814 17660 net.cpp:122] Setting up group0_block0_sum
I1211 22:42:14.296815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.296815 17660 net.cpp:137] Memory required for data: 92980400
I1211 22:42:14.296815 17660 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1211 22:42:14.296815 17660 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1211 22:42:14.296815 17660 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1211 22:42:14.296815 17660 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1211 22:42:14.296815 17660 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1211 22:42:14.296815 17660 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1211 22:42:14.296815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.296815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.296815 17660 net.cpp:137] Memory required for data: 106087600
I1211 22:42:14.296815 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1211 22:42:14.296815 17660 net.cpp:84] Creating Layer group0_block1_conv0
I1211 22:42:14.296815 17660 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1211 22:42:14.296815 17660 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1211 22:42:14.297814 17660 net.cpp:122] Setting up group0_block1_conv0
I1211 22:42:14.298815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.298815 17660 net.cpp:137] Memory required for data: 112641200
I1211 22:42:14.298815 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1211 22:42:14.298815 17660 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1211 22:42:14.298815 17660 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1211 22:42:14.298815 17660 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1211 22:42:14.298815 17660 net.cpp:122] Setting up group0_block1_conv0_bn
I1211 22:42:14.298815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.298815 17660 net.cpp:137] Memory required for data: 119194800
I1211 22:42:14.298815 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 22:42:14.298815 17660 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1211 22:42:14.298815 17660 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1211 22:42:14.298815 17660 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1211 22:42:14.298815 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1211 22:42:14.299814 17660 net.cpp:122] Setting up group0_block1_conv0_scale
I1211 22:42:14.299814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.299814 17660 net.cpp:137] Memory required for data: 125748400
I1211 22:42:14.299814 17660 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1211 22:42:14.299814 17660 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1211 22:42:14.299814 17660 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1211 22:42:14.299814 17660 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1211 22:42:14.300815 17660 net.cpp:122] Setting up group0_block1_conv0_relu
I1211 22:42:14.300815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.300815 17660 net.cpp:137] Memory required for data: 132302000
I1211 22:42:14.300815 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1211 22:42:14.300815 17660 net.cpp:84] Creating Layer group0_block1_conv1
I1211 22:42:14.300815 17660 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1211 22:42:14.300815 17660 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1211 22:42:14.303814 17660 net.cpp:122] Setting up group0_block1_conv1
I1211 22:42:14.303814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.303814 17660 net.cpp:137] Memory required for data: 138855600
I1211 22:42:14.303814 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1211 22:42:14.303814 17660 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1211 22:42:14.303814 17660 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1211 22:42:14.303814 17660 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1211 22:42:14.303814 17660 net.cpp:122] Setting up group0_block1_conv1_bn
I1211 22:42:14.303814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.303814 17660 net.cpp:137] Memory required for data: 145409200
I1211 22:42:14.303814 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 22:42:14.303814 17660 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1211 22:42:14.303814 17660 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1211 22:42:14.304816 17660 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1211 22:42:14.304816 17660 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1211 22:42:14.304816 17660 net.cpp:122] Setting up group0_block1_conv1_scale
I1211 22:42:14.304816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.304816 17660 net.cpp:137] Memory required for data: 151962800
I1211 22:42:14.304816 17660 layer_factory.cpp:58] Creating layer group0_block1_sum
I1211 22:42:14.304816 17660 net.cpp:84] Creating Layer group0_block1_sum
I1211 22:42:14.304816 17660 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1211 22:42:14.304816 17660 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1211 22:42:14.304816 17660 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1211 22:42:14.304816 17660 net.cpp:122] Setting up group0_block1_sum
I1211 22:42:14.304816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.304816 17660 net.cpp:137] Memory required for data: 158516400
I1211 22:42:14.304816 17660 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1211 22:42:14.304816 17660 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1211 22:42:14.304816 17660 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1211 22:42:14.304816 17660 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1211 22:42:14.304816 17660 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1211 22:42:14.304816 17660 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1211 22:42:14.304816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.304816 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.304816 17660 net.cpp:137] Memory required for data: 171623600
I1211 22:42:14.304816 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1211 22:42:14.304816 17660 net.cpp:84] Creating Layer group0_block2_conv0
I1211 22:42:14.304816 17660 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1211 22:42:14.304816 17660 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1211 22:42:14.305815 17660 net.cpp:122] Setting up group0_block2_conv0
I1211 22:42:14.305815 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.305815 17660 net.cpp:137] Memory required for data: 178177200
I1211 22:42:14.305815 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1211 22:42:14.305815 17660 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1211 22:42:14.305815 17660 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1211 22:42:14.305815 17660 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1211 22:42:14.306814 17660 net.cpp:122] Setting up group0_block2_conv0_bn
I1211 22:42:14.306814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.306814 17660 net.cpp:137] Memory required for data: 184730800
I1211 22:42:14.306814 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 22:42:14.306814 17660 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1211 22:42:14.306814 17660 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1211 22:42:14.306814 17660 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1211 22:42:14.306814 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1211 22:42:14.306814 17660 net.cpp:122] Setting up group0_block2_conv0_scale
I1211 22:42:14.306814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.306814 17660 net.cpp:137] Memory required for data: 191284400
I1211 22:42:14.306814 17660 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1211 22:42:14.306814 17660 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1211 22:42:14.306814 17660 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1211 22:42:14.306814 17660 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1211 22:42:14.307813 17660 net.cpp:122] Setting up group0_block2_conv0_relu
I1211 22:42:14.307813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.307813 17660 net.cpp:137] Memory required for data: 197838000
I1211 22:42:14.307813 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1211 22:42:14.307813 17660 net.cpp:84] Creating Layer group0_block2_conv1
I1211 22:42:14.307813 17660 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1211 22:42:14.307813 17660 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1211 22:42:14.308814 17660 net.cpp:122] Setting up group0_block2_conv1
I1211 22:42:14.308814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.308814 17660 net.cpp:137] Memory required for data: 204391600
I1211 22:42:14.308814 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1211 22:42:14.308814 17660 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1211 22:42:14.308814 17660 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1211 22:42:14.308814 17660 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1211 22:42:14.308814 17660 net.cpp:122] Setting up group0_block2_conv1_bn
I1211 22:42:14.308814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.308814 17660 net.cpp:137] Memory required for data: 210945200
I1211 22:42:14.308814 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 22:42:14.308814 17660 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1211 22:42:14.308814 17660 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1211 22:42:14.308814 17660 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1211 22:42:14.308814 17660 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1211 22:42:14.309813 17660 net.cpp:122] Setting up group0_block2_conv1_scale
I1211 22:42:14.309813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.309813 17660 net.cpp:137] Memory required for data: 217498800
I1211 22:42:14.309813 17660 layer_factory.cpp:58] Creating layer group0_block2_sum
I1211 22:42:14.309813 17660 net.cpp:84] Creating Layer group0_block2_sum
I1211 22:42:14.309813 17660 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1211 22:42:14.309813 17660 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1211 22:42:14.309813 17660 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1211 22:42:14.309813 17660 net.cpp:122] Setting up group0_block2_sum
I1211 22:42:14.309813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.309813 17660 net.cpp:137] Memory required for data: 224052400
I1211 22:42:14.309813 17660 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1211 22:42:14.309813 17660 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1211 22:42:14.309813 17660 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1211 22:42:14.309813 17660 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1211 22:42:14.309813 17660 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1211 22:42:14.309813 17660 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1211 22:42:14.309813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.309813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.309813 17660 net.cpp:137] Memory required for data: 237159600
I1211 22:42:14.309813 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1211 22:42:14.309813 17660 net.cpp:84] Creating Layer group0_block3_conv0
I1211 22:42:14.309813 17660 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1211 22:42:14.309813 17660 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1211 22:42:14.310812 17660 net.cpp:122] Setting up group0_block3_conv0
I1211 22:42:14.310812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.310812 17660 net.cpp:137] Memory required for data: 243713200
I1211 22:42:14.310812 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1211 22:42:14.310812 17660 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1211 22:42:14.310812 17660 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1211 22:42:14.310812 17660 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1211 22:42:14.310812 17660 net.cpp:122] Setting up group0_block3_conv0_bn
I1211 22:42:14.310812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.310812 17660 net.cpp:137] Memory required for data: 250266800
I1211 22:42:14.310812 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 22:42:14.310812 17660 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1211 22:42:14.310812 17660 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1211 22:42:14.310812 17660 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1211 22:42:14.310812 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1211 22:42:14.310812 17660 net.cpp:122] Setting up group0_block3_conv0_scale
I1211 22:42:14.310812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.310812 17660 net.cpp:137] Memory required for data: 256820400
I1211 22:42:14.310812 17660 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1211 22:42:14.311813 17660 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1211 22:42:14.311813 17660 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1211 22:42:14.311813 17660 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1211 22:42:14.311813 17660 net.cpp:122] Setting up group0_block3_conv0_relu
I1211 22:42:14.311813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.311813 17660 net.cpp:137] Memory required for data: 263374000
I1211 22:42:14.311813 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1211 22:42:14.311813 17660 net.cpp:84] Creating Layer group0_block3_conv1
I1211 22:42:14.311813 17660 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1211 22:42:14.311813 17660 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1211 22:42:14.313813 17660 net.cpp:122] Setting up group0_block3_conv1
I1211 22:42:14.313813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.313813 17660 net.cpp:137] Memory required for data: 269927600
I1211 22:42:14.313813 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1211 22:42:14.313813 17660 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1211 22:42:14.313813 17660 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1211 22:42:14.313813 17660 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1211 22:42:14.313813 17660 net.cpp:122] Setting up group0_block3_conv1_bn
I1211 22:42:14.313813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.313813 17660 net.cpp:137] Memory required for data: 276481200
I1211 22:42:14.313813 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 22:42:14.313813 17660 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1211 22:42:14.313813 17660 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1211 22:42:14.313813 17660 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1211 22:42:14.313813 17660 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1211 22:42:14.313813 17660 net.cpp:122] Setting up group0_block3_conv1_scale
I1211 22:42:14.313813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.313813 17660 net.cpp:137] Memory required for data: 283034800
I1211 22:42:14.313813 17660 layer_factory.cpp:58] Creating layer group0_block3_sum
I1211 22:42:14.313813 17660 net.cpp:84] Creating Layer group0_block3_sum
I1211 22:42:14.313813 17660 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1211 22:42:14.313813 17660 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1211 22:42:14.313813 17660 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1211 22:42:14.313813 17660 net.cpp:122] Setting up group0_block3_sum
I1211 22:42:14.314813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.314813 17660 net.cpp:137] Memory required for data: 289588400
I1211 22:42:14.314813 17660 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1211 22:42:14.314813 17660 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1211 22:42:14.314813 17660 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1211 22:42:14.314813 17660 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1211 22:42:14.314813 17660 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1211 22:42:14.314813 17660 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1211 22:42:14.314813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.314813 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.314813 17660 net.cpp:137] Memory required for data: 302695600
I1211 22:42:14.314813 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1211 22:42:14.314813 17660 net.cpp:84] Creating Layer group0_block4_conv0
I1211 22:42:14.314813 17660 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1211 22:42:14.314813 17660 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1211 22:42:14.315812 17660 net.cpp:122] Setting up group0_block4_conv0
I1211 22:42:14.315812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.315812 17660 net.cpp:137] Memory required for data: 309249200
I1211 22:42:14.315812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1211 22:42:14.315812 17660 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1211 22:42:14.315812 17660 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1211 22:42:14.315812 17660 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1211 22:42:14.315812 17660 net.cpp:122] Setting up group0_block4_conv0_bn
I1211 22:42:14.315812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.315812 17660 net.cpp:137] Memory required for data: 315802800
I1211 22:42:14.315812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 22:42:14.315812 17660 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1211 22:42:14.315812 17660 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1211 22:42:14.315812 17660 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1211 22:42:14.315812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1211 22:42:14.315812 17660 net.cpp:122] Setting up group0_block4_conv0_scale
I1211 22:42:14.315812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.315812 17660 net.cpp:137] Memory required for data: 322356400
I1211 22:42:14.315812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1211 22:42:14.316812 17660 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1211 22:42:14.316812 17660 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1211 22:42:14.316812 17660 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1211 22:42:14.316812 17660 net.cpp:122] Setting up group0_block4_conv0_relu
I1211 22:42:14.316812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.316812 17660 net.cpp:137] Memory required for data: 328910000
I1211 22:42:14.316812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1211 22:42:14.316812 17660 net.cpp:84] Creating Layer group0_block4_conv1
I1211 22:42:14.316812 17660 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1211 22:42:14.316812 17660 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1211 22:42:14.317812 17660 net.cpp:122] Setting up group0_block4_conv1
I1211 22:42:14.317812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.317812 17660 net.cpp:137] Memory required for data: 335463600
I1211 22:42:14.317812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1211 22:42:14.317812 17660 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1211 22:42:14.317812 17660 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1211 22:42:14.317812 17660 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1211 22:42:14.317812 17660 net.cpp:122] Setting up group0_block4_conv1_bn
I1211 22:42:14.317812 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.317812 17660 net.cpp:137] Memory required for data: 342017200
I1211 22:42:14.317812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 22:42:14.317812 17660 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1211 22:42:14.317812 17660 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1211 22:42:14.317812 17660 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1211 22:42:14.317812 17660 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1211 22:42:14.318814 17660 net.cpp:122] Setting up group0_block4_conv1_scale
I1211 22:42:14.318814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.318814 17660 net.cpp:137] Memory required for data: 348570800
I1211 22:42:14.318814 17660 layer_factory.cpp:58] Creating layer group0_block4_sum
I1211 22:42:14.318814 17660 net.cpp:84] Creating Layer group0_block4_sum
I1211 22:42:14.318814 17660 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1211 22:42:14.318814 17660 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1211 22:42:14.318814 17660 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1211 22:42:14.318814 17660 net.cpp:122] Setting up group0_block4_sum
I1211 22:42:14.318814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.318814 17660 net.cpp:137] Memory required for data: 355124400
I1211 22:42:14.318814 17660 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1211 22:42:14.318814 17660 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1211 22:42:14.318814 17660 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1211 22:42:14.318814 17660 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1211 22:42:14.318814 17660 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1211 22:42:14.318814 17660 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1211 22:42:14.318814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.318814 17660 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1211 22:42:14.318814 17660 net.cpp:137] Memory required for data: 368231600
I1211 22:42:14.318814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1211 22:42:14.318814 17660 net.cpp:84] Creating Layer group1_block0_conv0
I1211 22:42:14.318814 17660 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1211 22:42:14.318814 17660 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1211 22:42:14.320814 17660 net.cpp:122] Setting up group1_block0_conv0
I1211 22:42:14.320814 17660 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1211 22:42:14.320814 17660 net.cpp:137] Memory required for data: 381338800
I1211 22:42:14.320814 17660 layer_factory.cpp:58] Creating layer pool1
I1211 22:42:14.320814 17660 net.cpp:84] Creating Layer pool1
I1211 22:42:14.320814 17660 net.cpp:406] pool1 <- group1_block0_conv0
I1211 22:42:14.320814 17660 net.cpp:380] pool1 -> pool1
I1211 22:42:14.320814 17660 net.cpp:122] Setting up pool1
I1211 22:42:14.320814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.320814 17660 net.cpp:137] Memory required for data: 384615600
I1211 22:42:14.320814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1211 22:42:14.320814 17660 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1211 22:42:14.320814 17660 net.cpp:406] group1_block0_conv0_bn <- pool1
I1211 22:42:14.320814 17660 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1211 22:42:14.320814 17660 net.cpp:122] Setting up group1_block0_conv0_bn
I1211 22:42:14.320814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.320814 17660 net.cpp:137] Memory required for data: 387892400
I1211 22:42:14.320814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 22:42:14.320814 17660 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1211 22:42:14.320814 17660 net.cpp:406] group1_block0_conv0_scale <- pool1
I1211 22:42:14.320814 17660 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1211 22:42:14.320814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1211 22:42:14.321816 17660 net.cpp:122] Setting up group1_block0_conv0_scale
I1211 22:42:14.321816 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.321816 17660 net.cpp:137] Memory required for data: 391169200
I1211 22:42:14.321816 17660 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1211 22:42:14.321816 17660 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1211 22:42:14.321816 17660 net.cpp:406] group1_block0_conv0_relu <- pool1
I1211 22:42:14.321816 17660 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1211 22:42:14.321816 17660 net.cpp:122] Setting up group1_block0_conv0_relu
I1211 22:42:14.321816 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.321816 17660 net.cpp:137] Memory required for data: 394446000
I1211 22:42:14.321816 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1211 22:42:14.321816 17660 net.cpp:84] Creating Layer group1_block0_conv1
I1211 22:42:14.321816 17660 net.cpp:406] group1_block0_conv1 <- pool1
I1211 22:42:14.321816 17660 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1211 22:42:14.323814 17660 net.cpp:122] Setting up group1_block0_conv1
I1211 22:42:14.323814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.323814 17660 net.cpp:137] Memory required for data: 397722800
I1211 22:42:14.323814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1211 22:42:14.323814 17660 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1211 22:42:14.323814 17660 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1211 22:42:14.323814 17660 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1211 22:42:14.323814 17660 net.cpp:122] Setting up group1_block0_conv1_bn
I1211 22:42:14.323814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.323814 17660 net.cpp:137] Memory required for data: 400999600
I1211 22:42:14.323814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 22:42:14.323814 17660 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1211 22:42:14.323814 17660 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1211 22:42:14.323814 17660 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1211 22:42:14.323814 17660 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1211 22:42:14.324815 17660 net.cpp:122] Setting up group1_block0_conv1_scale
I1211 22:42:14.324815 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.324815 17660 net.cpp:137] Memory required for data: 404276400
I1211 22:42:14.324815 17660 layer_factory.cpp:58] Creating layer group1_block0_proj
I1211 22:42:14.324815 17660 net.cpp:84] Creating Layer group1_block0_proj
I1211 22:42:14.324815 17660 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1211 22:42:14.324815 17660 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1211 22:42:14.325814 17660 net.cpp:122] Setting up group1_block0_proj
I1211 22:42:14.325814 17660 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1211 22:42:14.325814 17660 net.cpp:137] Memory required for data: 416577200
I1211 22:42:14.325814 17660 layer_factory.cpp:58] Creating layer pool2
I1211 22:42:14.325814 17660 net.cpp:84] Creating Layer pool2
I1211 22:42:14.325814 17660 net.cpp:406] pool2 <- group1_block0_proj
I1211 22:42:14.325814 17660 net.cpp:380] pool2 -> pool2
I1211 22:42:14.325814 17660 net.cpp:122] Setting up pool2
I1211 22:42:14.325814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.325814 17660 net.cpp:137] Memory required for data: 419854000
I1211 22:42:14.325814 17660 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1211 22:42:14.325814 17660 net.cpp:84] Creating Layer group1_block0_proj_bn
I1211 22:42:14.325814 17660 net.cpp:406] group1_block0_proj_bn <- pool2
I1211 22:42:14.325814 17660 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1211 22:42:14.325814 17660 net.cpp:122] Setting up group1_block0_proj_bn
I1211 22:42:14.325814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.325814 17660 net.cpp:137] Memory required for data: 423130800
I1211 22:42:14.325814 17660 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 22:42:14.325814 17660 net.cpp:84] Creating Layer group1_block0_proj_scale
I1211 22:42:14.326813 17660 net.cpp:406] group1_block0_proj_scale <- pool2
I1211 22:42:14.326813 17660 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1211 22:42:14.326813 17660 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1211 22:42:14.326813 17660 net.cpp:122] Setting up group1_block0_proj_scale
I1211 22:42:14.326813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.326813 17660 net.cpp:137] Memory required for data: 426407600
I1211 22:42:14.326813 17660 layer_factory.cpp:58] Creating layer group1_block0_sum
I1211 22:42:14.326813 17660 net.cpp:84] Creating Layer group1_block0_sum
I1211 22:42:14.326813 17660 net.cpp:406] group1_block0_sum <- pool2
I1211 22:42:14.326813 17660 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1211 22:42:14.326813 17660 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1211 22:42:14.326813 17660 net.cpp:122] Setting up group1_block0_sum
I1211 22:42:14.326813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.326813 17660 net.cpp:137] Memory required for data: 429684400
I1211 22:42:14.326813 17660 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1211 22:42:14.326813 17660 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1211 22:42:14.326813 17660 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1211 22:42:14.326813 17660 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1211 22:42:14.326813 17660 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1211 22:42:14.326813 17660 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1211 22:42:14.326813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.326813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.326813 17660 net.cpp:137] Memory required for data: 436238000
I1211 22:42:14.326813 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1211 22:42:14.326813 17660 net.cpp:84] Creating Layer group1_block1_conv0
I1211 22:42:14.326813 17660 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1211 22:42:14.326813 17660 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1211 22:42:14.327813 17660 net.cpp:122] Setting up group1_block1_conv0
I1211 22:42:14.327813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.327813 17660 net.cpp:137] Memory required for data: 439514800
I1211 22:42:14.327813 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1211 22:42:14.327813 17660 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1211 22:42:14.327813 17660 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1211 22:42:14.327813 17660 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1211 22:42:14.328812 17660 net.cpp:122] Setting up group1_block1_conv0_bn
I1211 22:42:14.328812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.328812 17660 net.cpp:137] Memory required for data: 442791600
I1211 22:42:14.328812 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 22:42:14.328812 17660 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1211 22:42:14.328812 17660 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1211 22:42:14.328812 17660 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1211 22:42:14.328812 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1211 22:42:14.328812 17660 net.cpp:122] Setting up group1_block1_conv0_scale
I1211 22:42:14.328812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.328812 17660 net.cpp:137] Memory required for data: 446068400
I1211 22:42:14.328812 17660 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1211 22:42:14.328812 17660 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1211 22:42:14.328812 17660 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1211 22:42:14.328812 17660 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1211 22:42:14.328812 17660 net.cpp:122] Setting up group1_block1_conv0_relu
I1211 22:42:14.328812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.328812 17660 net.cpp:137] Memory required for data: 449345200
I1211 22:42:14.328812 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1211 22:42:14.328812 17660 net.cpp:84] Creating Layer group1_block1_conv1
I1211 22:42:14.328812 17660 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1211 22:42:14.328812 17660 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1211 22:42:14.329813 17660 net.cpp:122] Setting up group1_block1_conv1
I1211 22:42:14.329813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.329813 17660 net.cpp:137] Memory required for data: 452622000
I1211 22:42:14.329813 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1211 22:42:14.329813 17660 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1211 22:42:14.330812 17660 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1211 22:42:14.330812 17660 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1211 22:42:14.330812 17660 net.cpp:122] Setting up group1_block1_conv1_bn
I1211 22:42:14.330812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.330812 17660 net.cpp:137] Memory required for data: 455898800
I1211 22:42:14.330812 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 22:42:14.330812 17660 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1211 22:42:14.330812 17660 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1211 22:42:14.330812 17660 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1211 22:42:14.330812 17660 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1211 22:42:14.330812 17660 net.cpp:122] Setting up group1_block1_conv1_scale
I1211 22:42:14.330812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.330812 17660 net.cpp:137] Memory required for data: 459175600
I1211 22:42:14.330812 17660 layer_factory.cpp:58] Creating layer group1_block1_sum
I1211 22:42:14.330812 17660 net.cpp:84] Creating Layer group1_block1_sum
I1211 22:42:14.330812 17660 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1211 22:42:14.330812 17660 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1211 22:42:14.330812 17660 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1211 22:42:14.330812 17660 net.cpp:122] Setting up group1_block1_sum
I1211 22:42:14.330812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.330812 17660 net.cpp:137] Memory required for data: 462452400
I1211 22:42:14.330812 17660 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1211 22:42:14.330812 17660 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1211 22:42:14.330812 17660 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1211 22:42:14.330812 17660 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1211 22:42:14.330812 17660 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1211 22:42:14.330812 17660 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1211 22:42:14.330812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.330812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.330812 17660 net.cpp:137] Memory required for data: 469006000
I1211 22:42:14.330812 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1211 22:42:14.330812 17660 net.cpp:84] Creating Layer group1_block2_conv0
I1211 22:42:14.330812 17660 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1211 22:42:14.330812 17660 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1211 22:42:14.332813 17660 net.cpp:122] Setting up group1_block2_conv0
I1211 22:42:14.332813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.332813 17660 net.cpp:137] Memory required for data: 472282800
I1211 22:42:14.332813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1211 22:42:14.332813 17660 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1211 22:42:14.332813 17660 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1211 22:42:14.332813 17660 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1211 22:42:14.332813 17660 net.cpp:122] Setting up group1_block2_conv0_bn
I1211 22:42:14.332813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.332813 17660 net.cpp:137] Memory required for data: 475559600
I1211 22:42:14.332813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 22:42:14.332813 17660 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1211 22:42:14.332813 17660 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1211 22:42:14.332813 17660 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1211 22:42:14.332813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1211 22:42:14.332813 17660 net.cpp:122] Setting up group1_block2_conv0_scale
I1211 22:42:14.332813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.332813 17660 net.cpp:137] Memory required for data: 478836400
I1211 22:42:14.332813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1211 22:42:14.332813 17660 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1211 22:42:14.332813 17660 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1211 22:42:14.332813 17660 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1211 22:42:14.332813 17660 net.cpp:122] Setting up group1_block2_conv0_relu
I1211 22:42:14.332813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.332813 17660 net.cpp:137] Memory required for data: 482113200
I1211 22:42:14.332813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1211 22:42:14.332813 17660 net.cpp:84] Creating Layer group1_block2_conv1
I1211 22:42:14.332813 17660 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1211 22:42:14.332813 17660 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1211 22:42:14.334813 17660 net.cpp:122] Setting up group1_block2_conv1
I1211 22:42:14.334813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.334813 17660 net.cpp:137] Memory required for data: 485390000
I1211 22:42:14.334813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1211 22:42:14.334813 17660 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1211 22:42:14.334813 17660 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1211 22:42:14.334813 17660 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1211 22:42:14.334813 17660 net.cpp:122] Setting up group1_block2_conv1_bn
I1211 22:42:14.334813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.334813 17660 net.cpp:137] Memory required for data: 488666800
I1211 22:42:14.334813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 22:42:14.334813 17660 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1211 22:42:14.334813 17660 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1211 22:42:14.334813 17660 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1211 22:42:14.334813 17660 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1211 22:42:14.334813 17660 net.cpp:122] Setting up group1_block2_conv1_scale
I1211 22:42:14.334813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.334813 17660 net.cpp:137] Memory required for data: 491943600
I1211 22:42:14.334813 17660 layer_factory.cpp:58] Creating layer group1_block2_sum
I1211 22:42:14.334813 17660 net.cpp:84] Creating Layer group1_block2_sum
I1211 22:42:14.334813 17660 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1211 22:42:14.334813 17660 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1211 22:42:14.334813 17660 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1211 22:42:14.334813 17660 net.cpp:122] Setting up group1_block2_sum
I1211 22:42:14.334813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.334813 17660 net.cpp:137] Memory required for data: 495220400
I1211 22:42:14.334813 17660 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1211 22:42:14.334813 17660 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1211 22:42:14.334813 17660 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1211 22:42:14.334813 17660 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1211 22:42:14.334813 17660 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1211 22:42:14.334813 17660 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1211 22:42:14.334813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.334813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.334813 17660 net.cpp:137] Memory required for data: 501774000
I1211 22:42:14.334813 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1211 22:42:14.334813 17660 net.cpp:84] Creating Layer group1_block3_conv0
I1211 22:42:14.334813 17660 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1211 22:42:14.334813 17660 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1211 22:42:14.336812 17660 net.cpp:122] Setting up group1_block3_conv0
I1211 22:42:14.336812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.336812 17660 net.cpp:137] Memory required for data: 505050800
I1211 22:42:14.336812 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1211 22:42:14.336812 17660 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1211 22:42:14.336812 17660 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1211 22:42:14.336812 17660 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1211 22:42:14.336812 17660 net.cpp:122] Setting up group1_block3_conv0_bn
I1211 22:42:14.336812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.336812 17660 net.cpp:137] Memory required for data: 508327600
I1211 22:42:14.336812 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 22:42:14.336812 17660 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1211 22:42:14.336812 17660 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1211 22:42:14.336812 17660 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1211 22:42:14.336812 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1211 22:42:14.336812 17660 net.cpp:122] Setting up group1_block3_conv0_scale
I1211 22:42:14.336812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.336812 17660 net.cpp:137] Memory required for data: 511604400
I1211 22:42:14.336812 17660 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1211 22:42:14.336812 17660 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1211 22:42:14.336812 17660 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1211 22:42:14.336812 17660 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1211 22:42:14.337813 17660 net.cpp:122] Setting up group1_block3_conv0_relu
I1211 22:42:14.337813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.337813 17660 net.cpp:137] Memory required for data: 514881200
I1211 22:42:14.337813 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1211 22:42:14.337813 17660 net.cpp:84] Creating Layer group1_block3_conv1
I1211 22:42:14.337813 17660 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1211 22:42:14.337813 17660 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1211 22:42:14.338814 17660 net.cpp:122] Setting up group1_block3_conv1
I1211 22:42:14.338814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.338814 17660 net.cpp:137] Memory required for data: 518158000
I1211 22:42:14.338814 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1211 22:42:14.338814 17660 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1211 22:42:14.338814 17660 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1211 22:42:14.338814 17660 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1211 22:42:14.338814 17660 net.cpp:122] Setting up group1_block3_conv1_bn
I1211 22:42:14.338814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.338814 17660 net.cpp:137] Memory required for data: 521434800
I1211 22:42:14.338814 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 22:42:14.338814 17660 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1211 22:42:14.338814 17660 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1211 22:42:14.338814 17660 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1211 22:42:14.338814 17660 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1211 22:42:14.339812 17660 net.cpp:122] Setting up group1_block3_conv1_scale
I1211 22:42:14.339812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.339812 17660 net.cpp:137] Memory required for data: 524711600
I1211 22:42:14.339812 17660 layer_factory.cpp:58] Creating layer group1_block3_sum
I1211 22:42:14.339812 17660 net.cpp:84] Creating Layer group1_block3_sum
I1211 22:42:14.339812 17660 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1211 22:42:14.339812 17660 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1211 22:42:14.339812 17660 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1211 22:42:14.339812 17660 net.cpp:122] Setting up group1_block3_sum
I1211 22:42:14.339812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.339812 17660 net.cpp:137] Memory required for data: 527988400
I1211 22:42:14.339812 17660 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1211 22:42:14.339812 17660 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1211 22:42:14.339812 17660 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1211 22:42:14.339812 17660 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1211 22:42:14.339812 17660 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1211 22:42:14.339812 17660 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1211 22:42:14.339812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.339812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.339812 17660 net.cpp:137] Memory required for data: 534542000
I1211 22:42:14.339812 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1211 22:42:14.339812 17660 net.cpp:84] Creating Layer group1_block4_conv0
I1211 22:42:14.339812 17660 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1211 22:42:14.339812 17660 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1211 22:42:14.340813 17660 net.cpp:122] Setting up group1_block4_conv0
I1211 22:42:14.340813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.340813 17660 net.cpp:137] Memory required for data: 537818800
I1211 22:42:14.340813 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1211 22:42:14.341814 17660 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1211 22:42:14.341814 17660 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1211 22:42:14.341814 17660 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1211 22:42:14.341814 17660 net.cpp:122] Setting up group1_block4_conv0_bn
I1211 22:42:14.341814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.341814 17660 net.cpp:137] Memory required for data: 541095600
I1211 22:42:14.341814 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 22:42:14.341814 17660 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1211 22:42:14.341814 17660 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1211 22:42:14.341814 17660 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1211 22:42:14.341814 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1211 22:42:14.341814 17660 net.cpp:122] Setting up group1_block4_conv0_scale
I1211 22:42:14.341814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.341814 17660 net.cpp:137] Memory required for data: 544372400
I1211 22:42:14.341814 17660 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1211 22:42:14.341814 17660 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1211 22:42:14.341814 17660 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1211 22:42:14.341814 17660 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1211 22:42:14.341814 17660 net.cpp:122] Setting up group1_block4_conv0_relu
I1211 22:42:14.341814 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.341814 17660 net.cpp:137] Memory required for data: 547649200
I1211 22:42:14.341814 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1211 22:42:14.341814 17660 net.cpp:84] Creating Layer group1_block4_conv1
I1211 22:42:14.341814 17660 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1211 22:42:14.341814 17660 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1211 22:42:14.343812 17660 net.cpp:122] Setting up group1_block4_conv1
I1211 22:42:14.343812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.343812 17660 net.cpp:137] Memory required for data: 550926000
I1211 22:42:14.343812 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1211 22:42:14.343812 17660 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1211 22:42:14.343812 17660 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1211 22:42:14.343812 17660 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1211 22:42:14.343812 17660 net.cpp:122] Setting up group1_block4_conv1_bn
I1211 22:42:14.343812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.343812 17660 net.cpp:137] Memory required for data: 554202800
I1211 22:42:14.343812 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 22:42:14.343812 17660 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1211 22:42:14.343812 17660 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1211 22:42:14.343812 17660 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1211 22:42:14.343812 17660 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1211 22:42:14.343812 17660 net.cpp:122] Setting up group1_block4_conv1_scale
I1211 22:42:14.343812 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.343812 17660 net.cpp:137] Memory required for data: 557479600
I1211 22:42:14.343812 17660 layer_factory.cpp:58] Creating layer group1_block4_sum
I1211 22:42:14.343812 17660 net.cpp:84] Creating Layer group1_block4_sum
I1211 22:42:14.343812 17660 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1211 22:42:14.343812 17660 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1211 22:42:14.343812 17660 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1211 22:42:14.344813 17660 net.cpp:122] Setting up group1_block4_sum
I1211 22:42:14.344813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.344813 17660 net.cpp:137] Memory required for data: 560756400
I1211 22:42:14.344813 17660 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1211 22:42:14.344813 17660 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1211 22:42:14.344813 17660 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1211 22:42:14.344813 17660 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1211 22:42:14.344813 17660 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1211 22:42:14.344813 17660 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1211 22:42:14.344813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.344813 17660 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1211 22:42:14.344813 17660 net.cpp:137] Memory required for data: 567310000
I1211 22:42:14.344813 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1211 22:42:14.344813 17660 net.cpp:84] Creating Layer group2_block0_conv0
I1211 22:42:14.344813 17660 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1211 22:42:14.344813 17660 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1211 22:42:14.345813 17660 net.cpp:122] Setting up group2_block0_conv0
I1211 22:42:14.345813 17660 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1211 22:42:14.345813 17660 net.cpp:137] Memory required for data: 573863600
I1211 22:42:14.345813 17660 layer_factory.cpp:58] Creating layer pool3
I1211 22:42:14.345813 17660 net.cpp:84] Creating Layer pool3
I1211 22:42:14.345813 17660 net.cpp:406] pool3 <- group2_block0_conv0
I1211 22:42:14.345813 17660 net.cpp:380] pool3 -> pool3
I1211 22:42:14.345813 17660 net.cpp:122] Setting up pool3
I1211 22:42:14.345813 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.345813 17660 net.cpp:137] Memory required for data: 575502000
I1211 22:42:14.345813 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1211 22:42:14.345813 17660 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1211 22:42:14.345813 17660 net.cpp:406] group2_block0_conv0_bn <- pool3
I1211 22:42:14.345813 17660 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1211 22:42:14.345813 17660 net.cpp:122] Setting up group2_block0_conv0_bn
I1211 22:42:14.346813 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.346813 17660 net.cpp:137] Memory required for data: 577140400
I1211 22:42:14.346813 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 22:42:14.346813 17660 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1211 22:42:14.346813 17660 net.cpp:406] group2_block0_conv0_scale <- pool3
I1211 22:42:14.346813 17660 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1211 22:42:14.346813 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1211 22:42:14.346813 17660 net.cpp:122] Setting up group2_block0_conv0_scale
I1211 22:42:14.346813 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.346813 17660 net.cpp:137] Memory required for data: 578778800
I1211 22:42:14.346813 17660 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1211 22:42:14.346813 17660 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1211 22:42:14.346813 17660 net.cpp:406] group2_block0_conv0_relu <- pool3
I1211 22:42:14.346813 17660 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1211 22:42:14.346813 17660 net.cpp:122] Setting up group2_block0_conv0_relu
I1211 22:42:14.346813 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.346813 17660 net.cpp:137] Memory required for data: 580417200
I1211 22:42:14.346813 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1211 22:42:14.346813 17660 net.cpp:84] Creating Layer group2_block0_conv1
I1211 22:42:14.346813 17660 net.cpp:406] group2_block0_conv1 <- pool3
I1211 22:42:14.346813 17660 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1211 22:42:14.348812 17660 net.cpp:122] Setting up group2_block0_conv1
I1211 22:42:14.348812 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.348812 17660 net.cpp:137] Memory required for data: 582055600
I1211 22:42:14.348812 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1211 22:42:14.348812 17660 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1211 22:42:14.348812 17660 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1211 22:42:14.348812 17660 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1211 22:42:14.348812 17660 net.cpp:122] Setting up group2_block0_conv1_bn
I1211 22:42:14.348812 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.348812 17660 net.cpp:137] Memory required for data: 583694000
I1211 22:42:14.348812 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 22:42:14.349316 17660 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1211 22:42:14.349316 17660 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1211 22:42:14.349316 17660 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1211 22:42:14.349316 17660 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1211 22:42:14.349316 17660 net.cpp:122] Setting up group2_block0_conv1_scale
I1211 22:42:14.349316 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.349316 17660 net.cpp:137] Memory required for data: 585332400
I1211 22:42:14.349316 17660 layer_factory.cpp:58] Creating layer group2_block0_proj
I1211 22:42:14.349316 17660 net.cpp:84] Creating Layer group2_block0_proj
I1211 22:42:14.349316 17660 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1211 22:42:14.349316 17660 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1211 22:42:14.350816 17660 net.cpp:122] Setting up group2_block0_proj
I1211 22:42:14.350816 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.350816 17660 net.cpp:137] Memory required for data: 586970800
I1211 22:42:14.350816 17660 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1211 22:42:14.350816 17660 net.cpp:84] Creating Layer group2_block0_proj_bn
I1211 22:42:14.350816 17660 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1211 22:42:14.350816 17660 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1211 22:42:14.350816 17660 net.cpp:122] Setting up group2_block0_proj_bn
I1211 22:42:14.350816 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.350816 17660 net.cpp:137] Memory required for data: 588609200
I1211 22:42:14.350816 17660 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 22:42:14.350816 17660 net.cpp:84] Creating Layer group2_block0_proj_scale
I1211 22:42:14.350816 17660 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1211 22:42:14.350816 17660 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1211 22:42:14.350816 17660 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1211 22:42:14.351316 17660 net.cpp:122] Setting up group2_block0_proj_scale
I1211 22:42:14.351316 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.351316 17660 net.cpp:137] Memory required for data: 590247600
I1211 22:42:14.351316 17660 layer_factory.cpp:58] Creating layer group2_block0_sum
I1211 22:42:14.351316 17660 net.cpp:84] Creating Layer group2_block0_sum
I1211 22:42:14.351316 17660 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1211 22:42:14.351316 17660 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1211 22:42:14.351316 17660 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1211 22:42:14.351316 17660 net.cpp:122] Setting up group2_block0_sum
I1211 22:42:14.351316 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.351316 17660 net.cpp:137] Memory required for data: 591886000
I1211 22:42:14.351316 17660 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1211 22:42:14.351316 17660 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1211 22:42:14.351316 17660 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1211 22:42:14.351316 17660 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1211 22:42:14.351316 17660 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1211 22:42:14.351316 17660 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1211 22:42:14.351316 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.351316 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.351316 17660 net.cpp:137] Memory required for data: 595162800
I1211 22:42:14.351316 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1211 22:42:14.351316 17660 net.cpp:84] Creating Layer group2_block1_conv0
I1211 22:42:14.351316 17660 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1211 22:42:14.351316 17660 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1211 22:42:14.353317 17660 net.cpp:122] Setting up group2_block1_conv0
I1211 22:42:14.353317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.353317 17660 net.cpp:137] Memory required for data: 596801200
I1211 22:42:14.353317 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1211 22:42:14.353317 17660 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1211 22:42:14.353317 17660 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1211 22:42:14.353317 17660 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1211 22:42:14.353317 17660 net.cpp:122] Setting up group2_block1_conv0_bn
I1211 22:42:14.353317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.353317 17660 net.cpp:137] Memory required for data: 598439600
I1211 22:42:14.353317 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 22:42:14.353317 17660 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1211 22:42:14.353317 17660 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1211 22:42:14.353317 17660 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1211 22:42:14.353317 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1211 22:42:14.353817 17660 net.cpp:122] Setting up group2_block1_conv0_scale
I1211 22:42:14.353817 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.353817 17660 net.cpp:137] Memory required for data: 600078000
I1211 22:42:14.353817 17660 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1211 22:42:14.353817 17660 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1211 22:42:14.353817 17660 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1211 22:42:14.353817 17660 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1211 22:42:14.353817 17660 net.cpp:122] Setting up group2_block1_conv0_relu
I1211 22:42:14.353817 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.353817 17660 net.cpp:137] Memory required for data: 601716400
I1211 22:42:14.353817 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1211 22:42:14.353817 17660 net.cpp:84] Creating Layer group2_block1_conv1
I1211 22:42:14.353817 17660 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1211 22:42:14.354316 17660 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1211 22:42:14.356317 17660 net.cpp:122] Setting up group2_block1_conv1
I1211 22:42:14.356317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.356317 17660 net.cpp:137] Memory required for data: 603354800
I1211 22:42:14.356317 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1211 22:42:14.356317 17660 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1211 22:42:14.356317 17660 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1211 22:42:14.356317 17660 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1211 22:42:14.356818 17660 net.cpp:122] Setting up group2_block1_conv1_bn
I1211 22:42:14.356818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.356818 17660 net.cpp:137] Memory required for data: 604993200
I1211 22:42:14.356818 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 22:42:14.356818 17660 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1211 22:42:14.356818 17660 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1211 22:42:14.356818 17660 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1211 22:42:14.356818 17660 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1211 22:42:14.356818 17660 net.cpp:122] Setting up group2_block1_conv1_scale
I1211 22:42:14.356818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.356818 17660 net.cpp:137] Memory required for data: 606631600
I1211 22:42:14.356818 17660 layer_factory.cpp:58] Creating layer group2_block1_sum
I1211 22:42:14.356818 17660 net.cpp:84] Creating Layer group2_block1_sum
I1211 22:42:14.356818 17660 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1211 22:42:14.356818 17660 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1211 22:42:14.356818 17660 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1211 22:42:14.356818 17660 net.cpp:122] Setting up group2_block1_sum
I1211 22:42:14.356818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.356818 17660 net.cpp:137] Memory required for data: 608270000
I1211 22:42:14.356818 17660 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1211 22:42:14.356818 17660 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1211 22:42:14.356818 17660 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1211 22:42:14.356818 17660 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1211 22:42:14.356818 17660 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1211 22:42:14.357319 17660 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1211 22:42:14.357319 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.357319 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.357319 17660 net.cpp:137] Memory required for data: 611546800
I1211 22:42:14.357319 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1211 22:42:14.357319 17660 net.cpp:84] Creating Layer group2_block2_conv0
I1211 22:42:14.357319 17660 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1211 22:42:14.357319 17660 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1211 22:42:14.359318 17660 net.cpp:122] Setting up group2_block2_conv0
I1211 22:42:14.359318 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.359318 17660 net.cpp:137] Memory required for data: 613185200
I1211 22:42:14.359318 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1211 22:42:14.359318 17660 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1211 22:42:14.359318 17660 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1211 22:42:14.359818 17660 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1211 22:42:14.359818 17660 net.cpp:122] Setting up group2_block2_conv0_bn
I1211 22:42:14.359818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.359818 17660 net.cpp:137] Memory required for data: 614823600
I1211 22:42:14.359818 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 22:42:14.359818 17660 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1211 22:42:14.359818 17660 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1211 22:42:14.359818 17660 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1211 22:42:14.359818 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1211 22:42:14.359818 17660 net.cpp:122] Setting up group2_block2_conv0_scale
I1211 22:42:14.359818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.359818 17660 net.cpp:137] Memory required for data: 616462000
I1211 22:42:14.359818 17660 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1211 22:42:14.359818 17660 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1211 22:42:14.359818 17660 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1211 22:42:14.359818 17660 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1211 22:42:14.360318 17660 net.cpp:122] Setting up group2_block2_conv0_relu
I1211 22:42:14.360318 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.360318 17660 net.cpp:137] Memory required for data: 618100400
I1211 22:42:14.360318 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1211 22:42:14.360318 17660 net.cpp:84] Creating Layer group2_block2_conv1
I1211 22:42:14.360318 17660 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1211 22:42:14.360318 17660 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1211 22:42:14.362818 17660 net.cpp:122] Setting up group2_block2_conv1
I1211 22:42:14.362818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.362818 17660 net.cpp:137] Memory required for data: 619738800
I1211 22:42:14.362818 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1211 22:42:14.362818 17660 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1211 22:42:14.362818 17660 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1211 22:42:14.362818 17660 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1211 22:42:14.362818 17660 net.cpp:122] Setting up group2_block2_conv1_bn
I1211 22:42:14.362818 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.362818 17660 net.cpp:137] Memory required for data: 621377200
I1211 22:42:14.362818 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 22:42:14.362818 17660 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1211 22:42:14.362818 17660 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1211 22:42:14.362818 17660 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1211 22:42:14.362818 17660 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1211 22:42:14.363317 17660 net.cpp:122] Setting up group2_block2_conv1_scale
I1211 22:42:14.363317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.363317 17660 net.cpp:137] Memory required for data: 623015600
I1211 22:42:14.363317 17660 layer_factory.cpp:58] Creating layer group2_block2_sum
I1211 22:42:14.363317 17660 net.cpp:84] Creating Layer group2_block2_sum
I1211 22:42:14.363317 17660 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1211 22:42:14.363317 17660 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1211 22:42:14.363317 17660 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1211 22:42:14.363317 17660 net.cpp:122] Setting up group2_block2_sum
I1211 22:42:14.363317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.363317 17660 net.cpp:137] Memory required for data: 624654000
I1211 22:42:14.363317 17660 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1211 22:42:14.363317 17660 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1211 22:42:14.363317 17660 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1211 22:42:14.363317 17660 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1211 22:42:14.363317 17660 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1211 22:42:14.363317 17660 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1211 22:42:14.363317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.363317 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.363317 17660 net.cpp:137] Memory required for data: 627930800
I1211 22:42:14.363317 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1211 22:42:14.363317 17660 net.cpp:84] Creating Layer group2_block3_conv0
I1211 22:42:14.363317 17660 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1211 22:42:14.363317 17660 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1211 22:42:14.364819 17660 net.cpp:122] Setting up group2_block3_conv0
I1211 22:42:14.364819 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.364819 17660 net.cpp:137] Memory required for data: 629569200
I1211 22:42:14.364819 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1211 22:42:14.365826 17660 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1211 22:42:14.365826 17660 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1211 22:42:14.365826 17660 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1211 22:42:14.365826 17660 net.cpp:122] Setting up group2_block3_conv0_bn
I1211 22:42:14.365826 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.365826 17660 net.cpp:137] Memory required for data: 631207600
I1211 22:42:14.365826 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 22:42:14.365826 17660 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1211 22:42:14.365826 17660 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1211 22:42:14.365826 17660 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1211 22:42:14.365826 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1211 22:42:14.365826 17660 net.cpp:122] Setting up group2_block3_conv0_scale
I1211 22:42:14.365826 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.365826 17660 net.cpp:137] Memory required for data: 632846000
I1211 22:42:14.365826 17660 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1211 22:42:14.365826 17660 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1211 22:42:14.365826 17660 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1211 22:42:14.365826 17660 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1211 22:42:14.365826 17660 net.cpp:122] Setting up group2_block3_conv0_relu
I1211 22:42:14.365826 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.365826 17660 net.cpp:137] Memory required for data: 634484400
I1211 22:42:14.365826 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1211 22:42:14.365826 17660 net.cpp:84] Creating Layer group2_block3_conv1
I1211 22:42:14.365826 17660 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1211 22:42:14.365826 17660 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1211 22:42:14.367828 17660 net.cpp:122] Setting up group2_block3_conv1
I1211 22:42:14.367828 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.367828 17660 net.cpp:137] Memory required for data: 636122800
I1211 22:42:14.367828 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1211 22:42:14.367828 17660 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1211 22:42:14.367828 17660 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1211 22:42:14.367828 17660 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1211 22:42:14.367828 17660 net.cpp:122] Setting up group2_block3_conv1_bn
I1211 22:42:14.367828 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.367828 17660 net.cpp:137] Memory required for data: 637761200
I1211 22:42:14.367828 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 22:42:14.367828 17660 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1211 22:42:14.367828 17660 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1211 22:42:14.367828 17660 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1211 22:42:14.367828 17660 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1211 22:42:14.367828 17660 net.cpp:122] Setting up group2_block3_conv1_scale
I1211 22:42:14.367828 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.367828 17660 net.cpp:137] Memory required for data: 639399600
I1211 22:42:14.367828 17660 layer_factory.cpp:58] Creating layer group2_block3_sum
I1211 22:42:14.367828 17660 net.cpp:84] Creating Layer group2_block3_sum
I1211 22:42:14.368827 17660 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1211 22:42:14.368827 17660 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1211 22:42:14.368827 17660 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1211 22:42:14.368827 17660 net.cpp:122] Setting up group2_block3_sum
I1211 22:42:14.368827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.368827 17660 net.cpp:137] Memory required for data: 641038000
I1211 22:42:14.368827 17660 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1211 22:42:14.368827 17660 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1211 22:42:14.368827 17660 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1211 22:42:14.368827 17660 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1211 22:42:14.368827 17660 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1211 22:42:14.368827 17660 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1211 22:42:14.368827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.368827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.368827 17660 net.cpp:137] Memory required for data: 644314800
I1211 22:42:14.368827 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1211 22:42:14.368827 17660 net.cpp:84] Creating Layer group2_block4_conv0
I1211 22:42:14.368827 17660 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1211 22:42:14.368827 17660 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1211 22:42:14.370827 17660 net.cpp:122] Setting up group2_block4_conv0
I1211 22:42:14.370827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.370827 17660 net.cpp:137] Memory required for data: 645953200
I1211 22:42:14.370827 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1211 22:42:14.370827 17660 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1211 22:42:14.370827 17660 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1211 22:42:14.370827 17660 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1211 22:42:14.370827 17660 net.cpp:122] Setting up group2_block4_conv0_bn
I1211 22:42:14.370827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.370827 17660 net.cpp:137] Memory required for data: 647591600
I1211 22:42:14.370827 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 22:42:14.370827 17660 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1211 22:42:14.370827 17660 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1211 22:42:14.370827 17660 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1211 22:42:14.370827 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1211 22:42:14.371827 17660 net.cpp:122] Setting up group2_block4_conv0_scale
I1211 22:42:14.371827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.371827 17660 net.cpp:137] Memory required for data: 649230000
I1211 22:42:14.371827 17660 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1211 22:42:14.371827 17660 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1211 22:42:14.371827 17660 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1211 22:42:14.371827 17660 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1211 22:42:14.371827 17660 net.cpp:122] Setting up group2_block4_conv0_relu
I1211 22:42:14.371827 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.371827 17660 net.cpp:137] Memory required for data: 650868400
I1211 22:42:14.371827 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1211 22:42:14.371827 17660 net.cpp:84] Creating Layer group2_block4_conv1
I1211 22:42:14.371827 17660 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1211 22:42:14.371827 17660 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1211 22:42:14.373826 17660 net.cpp:122] Setting up group2_block4_conv1
I1211 22:42:14.373826 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.373826 17660 net.cpp:137] Memory required for data: 652506800
I1211 22:42:14.373826 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1211 22:42:14.373826 17660 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1211 22:42:14.373826 17660 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1211 22:42:14.373826 17660 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1211 22:42:14.373826 17660 net.cpp:122] Setting up group2_block4_conv1_bn
I1211 22:42:14.373826 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.373826 17660 net.cpp:137] Memory required for data: 654145200
I1211 22:42:14.373826 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 22:42:14.373826 17660 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1211 22:42:14.373826 17660 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1211 22:42:14.373826 17660 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1211 22:42:14.373826 17660 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1211 22:42:14.374825 17660 net.cpp:122] Setting up group2_block4_conv1_scale
I1211 22:42:14.374825 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.374825 17660 net.cpp:137] Memory required for data: 655783600
I1211 22:42:14.374825 17660 layer_factory.cpp:58] Creating layer group2_block4_sum
I1211 22:42:14.374825 17660 net.cpp:84] Creating Layer group2_block4_sum
I1211 22:42:14.374825 17660 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1211 22:42:14.374825 17660 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1211 22:42:14.374825 17660 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1211 22:42:14.374825 17660 net.cpp:122] Setting up group2_block4_sum
I1211 22:42:14.374825 17660 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1211 22:42:14.374825 17660 net.cpp:137] Memory required for data: 657422000
I1211 22:42:14.374825 17660 layer_factory.cpp:58] Creating layer global_avg_pool
I1211 22:42:14.374825 17660 net.cpp:84] Creating Layer global_avg_pool
I1211 22:42:14.374825 17660 net.cpp:406] global_avg_pool <- group2_block4_sum
I1211 22:42:14.374825 17660 net.cpp:380] global_avg_pool -> global_avg_pool
I1211 22:42:14.375825 17660 net.cpp:122] Setting up global_avg_pool
I1211 22:42:14.375825 17660 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1211 22:42:14.375825 17660 net.cpp:137] Memory required for data: 657447600
I1211 22:42:14.375825 17660 layer_factory.cpp:58] Creating layer fc
I1211 22:42:14.375825 17660 net.cpp:84] Creating Layer fc
I1211 22:42:14.375825 17660 net.cpp:406] fc <- global_avg_pool
I1211 22:42:14.375825 17660 net.cpp:380] fc -> fc
I1211 22:42:14.375825 17660 net.cpp:122] Setting up fc
I1211 22:42:14.375825 17660 net.cpp:129] Top shape: 100 10 (1000)
I1211 22:42:14.375825 17660 net.cpp:137] Memory required for data: 657451600
I1211 22:42:14.375825 17660 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1211 22:42:14.375825 17660 net.cpp:84] Creating Layer fc_fc_0_split
I1211 22:42:14.375825 17660 net.cpp:406] fc_fc_0_split <- fc
I1211 22:42:14.375825 17660 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1211 22:42:14.375825 17660 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1211 22:42:14.375825 17660 net.cpp:122] Setting up fc_fc_0_split
I1211 22:42:14.375825 17660 net.cpp:129] Top shape: 100 10 (1000)
I1211 22:42:14.375825 17660 net.cpp:129] Top shape: 100 10 (1000)
I1211 22:42:14.375825 17660 net.cpp:137] Memory required for data: 657459600
I1211 22:42:14.375825 17660 layer_factory.cpp:58] Creating layer accuracy
I1211 22:42:14.375825 17660 net.cpp:84] Creating Layer accuracy
I1211 22:42:14.375825 17660 net.cpp:406] accuracy <- fc_fc_0_split_0
I1211 22:42:14.375825 17660 net.cpp:406] accuracy <- label_cifar_1_split_0
I1211 22:42:14.375825 17660 net.cpp:380] accuracy -> accuracy
I1211 22:42:14.375825 17660 net.cpp:122] Setting up accuracy
I1211 22:42:14.375825 17660 net.cpp:129] Top shape: (1)
I1211 22:42:14.375825 17660 net.cpp:137] Memory required for data: 657459604
I1211 22:42:14.375825 17660 layer_factory.cpp:58] Creating layer loss
I1211 22:42:14.375825 17660 net.cpp:84] Creating Layer loss
I1211 22:42:14.375825 17660 net.cpp:406] loss <- fc_fc_0_split_1
I1211 22:42:14.375825 17660 net.cpp:406] loss <- label_cifar_1_split_1
I1211 22:42:14.375825 17660 net.cpp:380] loss -> loss
I1211 22:42:14.375825 17660 layer_factory.cpp:58] Creating layer loss
I1211 22:42:14.375825 17660 net.cpp:122] Setting up loss
I1211 22:42:14.376826 17660 net.cpp:129] Top shape: (1)
I1211 22:42:14.376826 17660 net.cpp:132]     with loss weight 1
I1211 22:42:14.376826 17660 net.cpp:137] Memory required for data: 657459608
I1211 22:42:14.376826 17660 net.cpp:198] loss needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:200] accuracy does not need backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] fc_fc_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] fc needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] global_avg_pool needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block4_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block3_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block2_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block1_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_proj needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] pool3 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group2_block0_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block4_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block3_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block2_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block1_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] pool2 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_proj needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] pool1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group1_block0_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block4_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block3_conv0 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_sum needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv1 needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1211 22:42:14.376826 17660 net.cpp:198] group0_block2_conv0 needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_sum needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv1 needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block1_conv0 needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_sum needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv1 needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] group0_block0_conv0 needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] first_conv_relu needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] first_conv_scale needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] first_conv_bn needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:198] first_conv needs backward computation.
I1211 22:42:14.377826 17660 net.cpp:200] label_cifar_1_split does not need backward computation.
I1211 22:42:14.377826 17660 net.cpp:200] cifar does not need backward computation.
I1211 22:42:14.377826 17660 net.cpp:242] This network produces output accuracy
I1211 22:42:14.377826 17660 net.cpp:242] This network produces output loss
I1211 22:42:14.377826 17660 net.cpp:255] Network initialization done.
I1211 22:42:14.377826 17660 solver.cpp:56] Solver scaffolding done.
I1211 22:42:14.392827 17660 caffe.cpp:243] Resuming from examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate
I1211 22:42:16.765803 17660 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/snaps/resnet32_with3pooling_iter_90000.caffemodel
I1211 22:42:16.765803 17660 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1211 22:42:16.765803 17660 sgd_solver.cpp:318] SGDSolver: restoring history
I1211 22:42:16.775801 17660 caffe.cpp:249] Starting Optimization
I1211 22:42:16.775801 17660 solver.cpp:272] Solving CIFAR10_resnet_32_with 3pooling
I1211 22:42:16.775801 17660 solver.cpp:273] Learning Rate Policy: multistep
I1211 22:42:16.779816 17660 solver.cpp:330] Iteration 90000, Testing net (#0)
I1211 22:42:16.783812 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:42:18.618007 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:42:18.685015 17660 solver.cpp:397]     Test net output #0: accuracy = 0.86
I1211 22:42:18.685015 17660 solver.cpp:397]     Test net output #1: loss = 0.45387 (* 1 = 0.45387 loss)
I1211 22:42:18.911041 17660 solver.cpp:218] Iteration 90000 (-nan iter/s, 2.13314s/100 iters), loss = 0.0936573
I1211 22:42:18.911041 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:42:18.911041 17660 solver.cpp:237]     Train net output #1: loss = 0.0936573 (* 1 = 0.0936573 loss)
I1211 22:42:18.911041 17660 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1211 22:42:27.003706 17660 solver.cpp:218] Iteration 90100 (12.3566 iter/s, 8.09287s/100 iters), loss = 0.123529
I1211 22:42:27.003706 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:42:27.003706 17660 solver.cpp:237]     Train net output #1: loss = 0.123529 (* 1 = 0.123529 loss)
I1211 22:42:27.003706 17660 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1211 22:42:35.054222 17660 solver.cpp:218] Iteration 90200 (12.4228 iter/s, 8.04972s/100 iters), loss = 0.14029
I1211 22:42:35.054222 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:42:35.054222 17660 solver.cpp:237]     Train net output #1: loss = 0.14029 (* 1 = 0.14029 loss)
I1211 22:42:35.054222 17660 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1211 22:42:43.110242 17660 solver.cpp:218] Iteration 90300 (12.4144 iter/s, 8.05519s/100 iters), loss = 0.0873167
I1211 22:42:43.110242 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:42:43.110242 17660 solver.cpp:237]     Train net output #1: loss = 0.0873167 (* 1 = 0.0873167 loss)
I1211 22:42:43.110242 17660 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1211 22:42:51.168210 17660 solver.cpp:218] Iteration 90400 (12.4106 iter/s, 8.05764s/100 iters), loss = 0.0562478
I1211 22:42:51.168210 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:42:51.168210 17660 solver.cpp:237]     Train net output #1: loss = 0.0562477 (* 1 = 0.0562477 loss)
I1211 22:42:51.168210 17660 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1211 22:42:58.822477 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:42:59.145603 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.caffemodel
I1211 22:42:59.184602 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.solverstate
I1211 22:42:59.191606 17660 solver.cpp:330] Iteration 90500, Testing net (#0)
I1211 22:42:59.192605 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:43:00.872766 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:43:00.940774 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8864
I1211 22:43:00.940774 17660 solver.cpp:397]     Test net output #1: loss = 0.363745 (* 1 = 0.363745 loss)
I1211 22:43:01.014775 17660 solver.cpp:218] Iteration 90500 (10.1564 iter/s, 9.84601s/100 iters), loss = 0.0673804
I1211 22:43:01.014775 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:43:01.014775 17660 solver.cpp:237]     Train net output #1: loss = 0.0673804 (* 1 = 0.0673804 loss)
I1211 22:43:01.014775 17660 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1211 22:43:09.082849 17660 solver.cpp:218] Iteration 90600 (12.3952 iter/s, 8.06765s/100 iters), loss = 0.0995562
I1211 22:43:09.083830 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:43:09.083830 17660 solver.cpp:237]     Train net output #1: loss = 0.0995562 (* 1 = 0.0995562 loss)
I1211 22:43:09.083830 17660 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1211 22:43:17.338145 17660 solver.cpp:218] Iteration 90700 (12.1156 iter/s, 8.25379s/100 iters), loss = 0.0678283
I1211 22:43:17.338145 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:43:17.338145 17660 solver.cpp:237]     Train net output #1: loss = 0.0678282 (* 1 = 0.0678282 loss)
I1211 22:43:17.338145 17660 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1211 22:43:25.534634 17660 solver.cpp:218] Iteration 90800 (12.2004 iter/s, 8.19645s/100 iters), loss = 0.139516
I1211 22:43:25.534634 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 22:43:25.534634 17660 solver.cpp:237]     Train net output #1: loss = 0.139516 (* 1 = 0.139516 loss)
I1211 22:43:25.534634 17660 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1211 22:43:33.627415 17660 solver.cpp:218] Iteration 90900 (12.358 iter/s, 8.09189s/100 iters), loss = 0.142061
I1211 22:43:33.627415 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:43:33.627415 17660 solver.cpp:237]     Train net output #1: loss = 0.142061 (* 1 = 0.142061 loss)
I1211 22:43:33.627415 17660 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1211 22:43:41.431195 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:43:41.749187 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.caffemodel
I1211 22:43:41.778187 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.solverstate
I1211 22:43:41.784721 17660 solver.cpp:330] Iteration 91000, Testing net (#0)
I1211 22:43:41.785207 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:43:43.476610 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:43:43.542635 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8786
I1211 22:43:43.543640 17660 solver.cpp:397]     Test net output #1: loss = 0.396079 (* 1 = 0.396079 loss)
I1211 22:43:43.618532 17660 solver.cpp:218] Iteration 91000 (10.0094 iter/s, 9.99064s/100 iters), loss = 0.193129
I1211 22:43:43.618532 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 22:43:43.618532 17660 solver.cpp:237]     Train net output #1: loss = 0.193129 (* 1 = 0.193129 loss)
I1211 22:43:43.618532 17660 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1211 22:43:51.710690 17660 solver.cpp:218] Iteration 91100 (12.3582 iter/s, 8.09179s/100 iters), loss = 0.117575
I1211 22:43:51.710690 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 22:43:51.710690 17660 solver.cpp:237]     Train net output #1: loss = 0.117575 (* 1 = 0.117575 loss)
I1211 22:43:51.710690 17660 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1211 22:43:59.826068 17660 solver.cpp:218] Iteration 91200 (12.3236 iter/s, 8.11449s/100 iters), loss = 0.116179
I1211 22:43:59.826068 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:43:59.826068 17660 solver.cpp:237]     Train net output #1: loss = 0.116179 (* 1 = 0.116179 loss)
I1211 22:43:59.826068 17660 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1211 22:44:07.915212 17660 solver.cpp:218] Iteration 91300 (12.363 iter/s, 8.08865s/100 iters), loss = 0.109598
I1211 22:44:07.915212 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:44:07.915212 17660 solver.cpp:237]     Train net output #1: loss = 0.109598 (* 1 = 0.109598 loss)
I1211 22:44:07.915212 17660 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1211 22:44:16.040380 17660 solver.cpp:218] Iteration 91400 (12.3089 iter/s, 8.12422s/100 iters), loss = 0.0899905
I1211 22:44:16.040380 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:44:16.040380 17660 solver.cpp:237]     Train net output #1: loss = 0.0899905 (* 1 = 0.0899905 loss)
I1211 22:44:16.040380 17660 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1211 22:44:23.739339 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:44:24.060360 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.caffemodel
I1211 22:44:24.097362 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.solverstate
I1211 22:44:24.103869 17660 solver.cpp:330] Iteration 91500, Testing net (#0)
I1211 22:44:24.104369 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:44:25.794556 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:44:25.862561 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8953
I1211 22:44:25.862561 17660 solver.cpp:397]     Test net output #1: loss = 0.342848 (* 1 = 0.342848 loss)
I1211 22:44:25.938577 17660 solver.cpp:218] Iteration 91500 (10.1032 iter/s, 9.89787s/100 iters), loss = 0.139078
I1211 22:44:25.938577 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:44:25.938577 17660 solver.cpp:237]     Train net output #1: loss = 0.139078 (* 1 = 0.139078 loss)
I1211 22:44:25.938577 17660 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1211 22:44:34.063320 17660 solver.cpp:218] Iteration 91600 (12.3091 iter/s, 8.12405s/100 iters), loss = 0.101923
I1211 22:44:34.063320 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:44:34.063320 17660 solver.cpp:237]     Train net output #1: loss = 0.101923 (* 1 = 0.101923 loss)
I1211 22:44:34.063320 17660 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1211 22:44:42.278081 17660 solver.cpp:218] Iteration 91700 (12.1743 iter/s, 8.21405s/100 iters), loss = 0.105305
I1211 22:44:42.278081 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:44:42.278081 17660 solver.cpp:237]     Train net output #1: loss = 0.105305 (* 1 = 0.105305 loss)
I1211 22:44:42.278081 17660 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1211 22:44:50.480727 17660 solver.cpp:218] Iteration 91800 (12.1912 iter/s, 8.20264s/100 iters), loss = 0.0874245
I1211 22:44:50.480727 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:44:50.480727 17660 solver.cpp:237]     Train net output #1: loss = 0.0874244 (* 1 = 0.0874244 loss)
I1211 22:44:50.480727 17660 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1211 22:44:58.608860 17660 solver.cpp:218] Iteration 91900 (12.3033 iter/s, 8.12791s/100 iters), loss = 0.12255
I1211 22:44:58.608860 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:44:58.608860 17660 solver.cpp:237]     Train net output #1: loss = 0.12255 (* 1 = 0.12255 loss)
I1211 22:44:58.608860 17660 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1211 22:45:06.379039 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:45:06.698081 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.caffemodel
I1211 22:45:06.727602 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.solverstate
I1211 22:45:06.734118 17660 solver.cpp:330] Iteration 92000, Testing net (#0)
I1211 22:45:06.734118 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:45:08.426259 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:45:08.493263 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8761
I1211 22:45:08.493263 17660 solver.cpp:397]     Test net output #1: loss = 0.428037 (* 1 = 0.428037 loss)
I1211 22:45:08.568269 17660 solver.cpp:218] Iteration 92000 (10.0417 iter/s, 9.95845s/100 iters), loss = 0.1472
I1211 22:45:08.568269 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 22:45:08.568269 17660 solver.cpp:237]     Train net output #1: loss = 0.1472 (* 1 = 0.1472 loss)
I1211 22:45:08.568269 17660 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1211 22:45:16.778509 17660 solver.cpp:218] Iteration 92100 (12.1812 iter/s, 8.20935s/100 iters), loss = 0.0903602
I1211 22:45:16.778509 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:45:16.778509 17660 solver.cpp:237]     Train net output #1: loss = 0.0903602 (* 1 = 0.0903602 loss)
I1211 22:45:16.778509 17660 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1211 22:45:25.124749 17660 solver.cpp:218] Iteration 92200 (11.9819 iter/s, 8.34594s/100 iters), loss = 0.229067
I1211 22:45:25.124749 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I1211 22:45:25.125249 17660 solver.cpp:237]     Train net output #1: loss = 0.229067 (* 1 = 0.229067 loss)
I1211 22:45:25.125249 17660 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1211 22:45:33.308835 17660 solver.cpp:218] Iteration 92300 (12.2202 iter/s, 8.18315s/100 iters), loss = 0.119871
I1211 22:45:33.308835 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:45:33.308835 17660 solver.cpp:237]     Train net output #1: loss = 0.119871 (* 1 = 0.119871 loss)
I1211 22:45:33.308835 17660 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1211 22:45:41.465307 17660 solver.cpp:218] Iteration 92400 (12.2603 iter/s, 8.15641s/100 iters), loss = 0.16279
I1211 22:45:41.465307 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 22:45:41.465307 17660 solver.cpp:237]     Train net output #1: loss = 0.16279 (* 1 = 0.16279 loss)
I1211 22:45:41.465307 17660 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1211 22:45:49.270268 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:45:49.593473 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.caffemodel
I1211 22:45:49.624469 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.solverstate
I1211 22:45:49.631469 17660 solver.cpp:330] Iteration 92500, Testing net (#0)
I1211 22:45:49.631469 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:45:51.332749 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:45:51.400760 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8729
I1211 22:45:51.400760 17660 solver.cpp:397]     Test net output #1: loss = 0.416964 (* 1 = 0.416964 loss)
I1211 22:45:51.476774 17660 solver.cpp:218] Iteration 92500 (9.98891 iter/s, 10.0111s/100 iters), loss = 0.121251
I1211 22:45:51.477771 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 22:45:51.477771 17660 solver.cpp:237]     Train net output #1: loss = 0.121251 (* 1 = 0.121251 loss)
I1211 22:45:51.477771 17660 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1211 22:45:59.703765 17660 solver.cpp:218] Iteration 92600 (12.1571 iter/s, 8.22562s/100 iters), loss = 0.0951645
I1211 22:45:59.703765 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:45:59.703765 17660 solver.cpp:237]     Train net output #1: loss = 0.0951645 (* 1 = 0.0951645 loss)
I1211 22:45:59.703765 17660 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1211 22:46:07.859913 17660 solver.cpp:218] Iteration 92700 (12.261 iter/s, 8.15592s/100 iters), loss = 0.108552
I1211 22:46:07.859913 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:46:07.859913 17660 solver.cpp:237]     Train net output #1: loss = 0.108552 (* 1 = 0.108552 loss)
I1211 22:46:07.859913 17660 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1211 22:46:16.031816 17660 solver.cpp:218] Iteration 92800 (12.2376 iter/s, 8.17155s/100 iters), loss = 0.0935395
I1211 22:46:16.031816 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:46:16.031816 17660 solver.cpp:237]     Train net output #1: loss = 0.0935395 (* 1 = 0.0935395 loss)
I1211 22:46:16.031816 17660 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1211 22:46:24.224987 17660 solver.cpp:218] Iteration 92900 (12.2065 iter/s, 8.19232s/100 iters), loss = 0.0799428
I1211 22:46:24.224987 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:46:24.224987 17660 solver.cpp:237]     Train net output #1: loss = 0.0799429 (* 1 = 0.0799429 loss)
I1211 22:46:24.224987 17660 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1211 22:46:32.084197 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:46:32.411250 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.caffemodel
I1211 22:46:32.452255 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.solverstate
I1211 22:46:32.459755 17660 solver.cpp:330] Iteration 93000, Testing net (#0)
I1211 22:46:32.460255 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:46:34.152900 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:46:34.221906 17660 solver.cpp:397]     Test net output #0: accuracy = 0.89
I1211 22:46:34.222909 17660 solver.cpp:397]     Test net output #1: loss = 0.369953 (* 1 = 0.369953 loss)
I1211 22:46:34.297541 17660 solver.cpp:218] Iteration 93000 (9.92919 iter/s, 10.0713s/100 iters), loss = 0.125466
I1211 22:46:34.297541 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:46:34.297541 17660 solver.cpp:237]     Train net output #1: loss = 0.125466 (* 1 = 0.125466 loss)
I1211 22:46:34.297541 17660 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1211 22:46:42.535151 17660 solver.cpp:218] Iteration 93100 (12.1403 iter/s, 8.23705s/100 iters), loss = 0.0589677
I1211 22:46:42.535151 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:46:42.535151 17660 solver.cpp:237]     Train net output #1: loss = 0.0589677 (* 1 = 0.0589677 loss)
I1211 22:46:42.535151 17660 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1211 22:46:50.742564 17660 solver.cpp:218] Iteration 93200 (12.1849 iter/s, 8.2069s/100 iters), loss = 0.121607
I1211 22:46:50.742564 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:46:50.742564 17660 solver.cpp:237]     Train net output #1: loss = 0.121607 (* 1 = 0.121607 loss)
I1211 22:46:50.742564 17660 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1211 22:46:59.051728 17660 solver.cpp:218] Iteration 93300 (12.0359 iter/s, 8.30845s/100 iters), loss = 0.150181
I1211 22:46:59.051728 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:46:59.051728 17660 solver.cpp:237]     Train net output #1: loss = 0.150181 (* 1 = 0.150181 loss)
I1211 22:46:59.051728 17660 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1211 22:47:07.280030 17660 solver.cpp:218] Iteration 93400 (12.1544 iter/s, 8.22744s/100 iters), loss = 0.0976601
I1211 22:47:07.280030 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:47:07.280030 17660 solver.cpp:237]     Train net output #1: loss = 0.0976601 (* 1 = 0.0976601 loss)
I1211 22:47:07.280030 17660 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1211 22:47:15.043185 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:47:15.365911 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.caffemodel
I1211 22:47:15.398957 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.solverstate
I1211 22:47:15.404958 17660 solver.cpp:330] Iteration 93500, Testing net (#0)
I1211 22:47:15.404958 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:47:17.106273 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:47:17.174279 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8885
I1211 22:47:17.174279 17660 solver.cpp:397]     Test net output #1: loss = 0.361108 (* 1 = 0.361108 loss)
I1211 22:47:17.250857 17660 solver.cpp:218] Iteration 93500 (10.0298 iter/s, 9.97026s/100 iters), loss = 0.146796
I1211 22:47:17.250857 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:47:17.250857 17660 solver.cpp:237]     Train net output #1: loss = 0.146796 (* 1 = 0.146796 loss)
I1211 22:47:17.250857 17660 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1211 22:47:25.350942 17660 solver.cpp:218] Iteration 93600 (12.3465 iter/s, 8.09946s/100 iters), loss = 0.0535386
I1211 22:47:25.350942 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:47:25.350942 17660 solver.cpp:237]     Train net output #1: loss = 0.0535386 (* 1 = 0.0535386 loss)
I1211 22:47:25.350942 17660 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1211 22:47:33.457479 17660 solver.cpp:218] Iteration 93700 (12.3369 iter/s, 8.10579s/100 iters), loss = 0.10772
I1211 22:47:33.457479 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:47:33.457479 17660 solver.cpp:237]     Train net output #1: loss = 0.10772 (* 1 = 0.10772 loss)
I1211 22:47:33.457479 17660 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1211 22:47:41.677501 17660 solver.cpp:218] Iteration 93800 (12.1663 iter/s, 8.21943s/100 iters), loss = 0.106669
I1211 22:47:41.677501 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:47:41.677501 17660 solver.cpp:237]     Train net output #1: loss = 0.106669 (* 1 = 0.106669 loss)
I1211 22:47:41.677501 17660 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1211 22:47:49.849246 17660 solver.cpp:218] Iteration 93900 (12.2374 iter/s, 8.17168s/100 iters), loss = 0.151158
I1211 22:47:49.850246 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:47:49.850246 17660 solver.cpp:237]     Train net output #1: loss = 0.151158 (* 1 = 0.151158 loss)
I1211 22:47:49.850246 17660 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1211 22:47:57.718987 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:47:58.039038 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.caffemodel
I1211 22:47:58.078039 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.solverstate
I1211 22:47:58.085038 17660 solver.cpp:330] Iteration 94000, Testing net (#0)
I1211 22:47:58.085038 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:47:59.787721 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:47:59.854670 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8748
I1211 22:47:59.854670 17660 solver.cpp:397]     Test net output #1: loss = 0.405777 (* 1 = 0.405777 loss)
I1211 22:47:59.930317 17660 solver.cpp:218] Iteration 94000 (9.92126 iter/s, 10.0794s/100 iters), loss = 0.0866263
I1211 22:47:59.930317 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:47:59.930317 17660 solver.cpp:237]     Train net output #1: loss = 0.0866263 (* 1 = 0.0866263 loss)
I1211 22:47:59.930317 17660 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1211 22:48:08.105762 17660 solver.cpp:218] Iteration 94100 (12.2324 iter/s, 8.17504s/100 iters), loss = 0.123694
I1211 22:48:08.105762 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:48:08.105762 17660 solver.cpp:237]     Train net output #1: loss = 0.123694 (* 1 = 0.123694 loss)
I1211 22:48:08.105762 17660 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1211 22:48:16.327996 17660 solver.cpp:218] Iteration 94200 (12.1619 iter/s, 8.22238s/100 iters), loss = 0.101948
I1211 22:48:16.327996 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:48:16.327996 17660 solver.cpp:237]     Train net output #1: loss = 0.101948 (* 1 = 0.101948 loss)
I1211 22:48:16.327996 17660 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1211 22:48:24.465451 17660 solver.cpp:218] Iteration 94300 (12.2906 iter/s, 8.1363s/100 iters), loss = 0.0993515
I1211 22:48:24.465451 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:48:24.465451 17660 solver.cpp:237]     Train net output #1: loss = 0.0993515 (* 1 = 0.0993515 loss)
I1211 22:48:24.465451 17660 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1211 22:48:32.694028 17660 solver.cpp:218] Iteration 94400 (12.1527 iter/s, 8.22859s/100 iters), loss = 0.0477797
I1211 22:48:32.694028 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:48:32.694028 17660 solver.cpp:237]     Train net output #1: loss = 0.0477796 (* 1 = 0.0477796 loss)
I1211 22:48:32.694028 17660 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1211 22:48:40.487545 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:48:40.809487 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.caffemodel
I1211 22:48:40.840499 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.solverstate
I1211 22:48:40.853497 17660 solver.cpp:330] Iteration 94500, Testing net (#0)
I1211 22:48:40.853497 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:48:42.556514 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:48:42.623520 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8754
I1211 22:48:42.623520 17660 solver.cpp:397]     Test net output #1: loss = 0.408622 (* 1 = 0.408622 loss)
I1211 22:48:42.700520 17660 solver.cpp:218] Iteration 94500 (9.99434 iter/s, 10.0057s/100 iters), loss = 0.0818272
I1211 22:48:42.700520 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:48:42.700520 17660 solver.cpp:237]     Train net output #1: loss = 0.0818271 (* 1 = 0.0818271 loss)
I1211 22:48:42.700520 17660 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1211 22:48:50.923120 17660 solver.cpp:218] Iteration 94600 (12.1628 iter/s, 8.22182s/100 iters), loss = 0.157505
I1211 22:48:50.923120 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1211 22:48:50.923120 17660 solver.cpp:237]     Train net output #1: loss = 0.157505 (* 1 = 0.157505 loss)
I1211 22:48:50.923120 17660 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1211 22:48:59.122386 17660 solver.cpp:218] Iteration 94700 (12.1973 iter/s, 8.19855s/100 iters), loss = 0.179489
I1211 22:48:59.122386 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1211 22:48:59.122386 17660 solver.cpp:237]     Train net output #1: loss = 0.179489 (* 1 = 0.179489 loss)
I1211 22:48:59.122386 17660 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1211 22:49:07.313382 17660 solver.cpp:218] Iteration 94800 (12.2084 iter/s, 8.19107s/100 iters), loss = 0.0977344
I1211 22:49:07.313382 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:49:07.314383 17660 solver.cpp:237]     Train net output #1: loss = 0.0977344 (* 1 = 0.0977344 loss)
I1211 22:49:07.314383 17660 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1211 22:49:15.446449 17660 solver.cpp:218] Iteration 94900 (12.2972 iter/s, 8.13195s/100 iters), loss = 0.100787
I1211 22:49:15.446449 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1211 22:49:15.446449 17660 solver.cpp:237]     Train net output #1: loss = 0.100787 (* 1 = 0.100787 loss)
I1211 22:49:15.446449 17660 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1211 22:49:23.237371 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:49:23.555418 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.caffemodel
I1211 22:49:23.588421 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.solverstate
I1211 22:49:23.594434 17660 solver.cpp:330] Iteration 95000, Testing net (#0)
I1211 22:49:23.594434 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:49:25.293606 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:49:25.360608 17660 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I1211 22:49:25.360608 17660 solver.cpp:397]     Test net output #1: loss = 0.34553 (* 1 = 0.34553 loss)
I1211 22:49:25.437613 17660 solver.cpp:218] Iteration 95000 (10.0089 iter/s, 9.99107s/100 iters), loss = 0.180965
I1211 22:49:25.437613 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1211 22:49:25.437613 17660 solver.cpp:237]     Train net output #1: loss = 0.180965 (* 1 = 0.180965 loss)
I1211 22:49:25.437613 17660 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1211 22:49:25.438613 17660 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1211 22:49:33.560155 17660 solver.cpp:218] Iteration 95100 (12.313 iter/s, 8.1215s/100 iters), loss = 0.0929849
I1211 22:49:33.560155 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:49:33.560155 17660 solver.cpp:237]     Train net output #1: loss = 0.0929849 (* 1 = 0.0929849 loss)
I1211 22:49:33.560155 17660 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1211 22:49:41.667147 17660 solver.cpp:218] Iteration 95200 (12.3357 iter/s, 8.10655s/100 iters), loss = 0.0503574
I1211 22:49:41.667147 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:49:41.667147 17660 solver.cpp:237]     Train net output #1: loss = 0.0503574 (* 1 = 0.0503574 loss)
I1211 22:49:41.667147 17660 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1211 22:49:49.772641 17660 solver.cpp:218] Iteration 95300 (12.3388 iter/s, 8.10455s/100 iters), loss = 0.0573206
I1211 22:49:49.772641 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:49:49.772641 17660 solver.cpp:237]     Train net output #1: loss = 0.0573206 (* 1 = 0.0573206 loss)
I1211 22:49:49.772641 17660 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1211 22:49:57.873072 17660 solver.cpp:218] Iteration 95400 (12.3457 iter/s, 8.10001s/100 iters), loss = 0.0485642
I1211 22:49:57.873072 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:49:57.873072 17660 solver.cpp:237]     Train net output #1: loss = 0.0485641 (* 1 = 0.0485641 loss)
I1211 22:49:57.873072 17660 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1211 22:50:05.585952 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:50:05.907549 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.caffemodel
I1211 22:50:05.939545 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.solverstate
I1211 22:50:05.945545 17660 solver.cpp:330] Iteration 95500, Testing net (#0)
I1211 22:50:05.946547 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:50:07.637300 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:50:07.705359 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9249
I1211 22:50:07.705868 17660 solver.cpp:397]     Test net output #1: loss = 0.243725 (* 1 = 0.243725 loss)
I1211 22:50:07.780371 17660 solver.cpp:218] Iteration 95500 (10.0941 iter/s, 9.90679s/100 iters), loss = 0.0539049
I1211 22:50:07.780371 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:50:07.780371 17660 solver.cpp:237]     Train net output #1: loss = 0.0539049 (* 1 = 0.0539049 loss)
I1211 22:50:07.780371 17660 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1211 22:50:15.856267 17660 solver.cpp:218] Iteration 95600 (12.3831 iter/s, 8.07552s/100 iters), loss = 0.0896295
I1211 22:50:15.856267 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:50:15.856776 17660 solver.cpp:237]     Train net output #1: loss = 0.0896295 (* 1 = 0.0896295 loss)
I1211 22:50:15.856776 17660 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1211 22:50:23.958995 17660 solver.cpp:218] Iteration 95700 (12.3431 iter/s, 8.10172s/100 iters), loss = 0.0532456
I1211 22:50:23.958995 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:50:23.958995 17660 solver.cpp:237]     Train net output #1: loss = 0.0532456 (* 1 = 0.0532456 loss)
I1211 22:50:23.958995 17660 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1211 22:50:32.064585 17660 solver.cpp:218] Iteration 95800 (12.3368 iter/s, 8.10583s/100 iters), loss = 0.0401864
I1211 22:50:32.064585 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:50:32.064585 17660 solver.cpp:237]     Train net output #1: loss = 0.0401864 (* 1 = 0.0401864 loss)
I1211 22:50:32.064585 17660 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1211 22:50:40.148954 17660 solver.cpp:218] Iteration 95900 (12.3709 iter/s, 8.08348s/100 iters), loss = 0.0342865
I1211 22:50:40.148954 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:50:40.148954 17660 solver.cpp:237]     Train net output #1: loss = 0.0342865 (* 1 = 0.0342865 loss)
I1211 22:50:40.148954 17660 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1211 22:50:47.837115 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:50:48.158432 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.caffemodel
I1211 22:50:48.192481 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.solverstate
I1211 22:50:48.199476 17660 solver.cpp:330] Iteration 96000, Testing net (#0)
I1211 22:50:48.199476 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:50:49.888257 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:50:49.954255 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9275
I1211 22:50:49.955257 17660 solver.cpp:397]     Test net output #1: loss = 0.239697 (* 1 = 0.239697 loss)
I1211 22:50:50.029412 17660 solver.cpp:218] Iteration 96000 (10.122 iter/s, 9.87944s/100 iters), loss = 0.0662276
I1211 22:50:50.029412 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:50:50.029412 17660 solver.cpp:237]     Train net output #1: loss = 0.0662276 (* 1 = 0.0662276 loss)
I1211 22:50:50.029412 17660 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1211 22:50:58.146277 17660 solver.cpp:218] Iteration 96100 (12.3213 iter/s, 8.11605s/100 iters), loss = 0.0907092
I1211 22:50:58.146277 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:50:58.146277 17660 solver.cpp:237]     Train net output #1: loss = 0.0907092 (* 1 = 0.0907092 loss)
I1211 22:50:58.146277 17660 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1211 22:51:06.257396 17660 solver.cpp:218] Iteration 96200 (12.3293 iter/s, 8.11077s/100 iters), loss = 0.0422611
I1211 22:51:06.257396 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:51:06.257396 17660 solver.cpp:237]     Train net output #1: loss = 0.0422611 (* 1 = 0.0422611 loss)
I1211 22:51:06.257396 17660 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1211 22:51:14.371412 17660 solver.cpp:218] Iteration 96300 (12.3251 iter/s, 8.11355s/100 iters), loss = 0.0282279
I1211 22:51:14.371412 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:51:14.371412 17660 solver.cpp:237]     Train net output #1: loss = 0.0282279 (* 1 = 0.0282279 loss)
I1211 22:51:14.371917 17660 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1211 22:51:22.483639 17660 solver.cpp:218] Iteration 96400 (12.3282 iter/s, 8.1115s/100 iters), loss = 0.0340805
I1211 22:51:22.483639 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:51:22.483639 17660 solver.cpp:237]     Train net output #1: loss = 0.0340805 (* 1 = 0.0340805 loss)
I1211 22:51:22.483639 17660 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1211 22:51:30.175673 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:51:30.498842 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.caffemodel
I1211 22:51:30.529860 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.solverstate
I1211 22:51:30.535854 17660 solver.cpp:330] Iteration 96500, Testing net (#0)
I1211 22:51:30.535854 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:51:32.224293 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:51:32.292784 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9308
I1211 22:51:32.292784 17660 solver.cpp:397]     Test net output #1: loss = 0.234473 (* 1 = 0.234473 loss)
I1211 22:51:32.367292 17660 solver.cpp:218] Iteration 96500 (10.1186 iter/s, 9.88283s/100 iters), loss = 0.0325404
I1211 22:51:32.367292 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:51:32.367292 17660 solver.cpp:237]     Train net output #1: loss = 0.0325404 (* 1 = 0.0325404 loss)
I1211 22:51:32.367292 17660 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1211 22:51:40.489964 17660 solver.cpp:218] Iteration 96600 (12.3121 iter/s, 8.12211s/100 iters), loss = 0.0390148
I1211 22:51:40.489964 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:51:40.489964 17660 solver.cpp:237]     Train net output #1: loss = 0.0390148 (* 1 = 0.0390148 loss)
I1211 22:51:40.489964 17660 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1211 22:51:48.599825 17660 solver.cpp:218] Iteration 96700 (12.3315 iter/s, 8.10932s/100 iters), loss = 0.0471594
I1211 22:51:48.599825 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:51:48.599825 17660 solver.cpp:237]     Train net output #1: loss = 0.0471594 (* 1 = 0.0471594 loss)
I1211 22:51:48.599825 17660 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1211 22:51:56.707237 17660 solver.cpp:218] Iteration 96800 (12.3349 iter/s, 8.1071s/100 iters), loss = 0.0240897
I1211 22:51:56.707237 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:51:56.707237 17660 solver.cpp:237]     Train net output #1: loss = 0.0240897 (* 1 = 0.0240897 loss)
I1211 22:51:56.707237 17660 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1211 22:52:04.823971 17660 solver.cpp:218] Iteration 96900 (12.3213 iter/s, 8.11603s/100 iters), loss = 0.0410403
I1211 22:52:04.823971 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:52:04.823971 17660 solver.cpp:237]     Train net output #1: loss = 0.0410403 (* 1 = 0.0410403 loss)
I1211 22:52:04.823971 17660 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1211 22:52:12.534039 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:52:12.855741 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.caffemodel
I1211 22:52:12.886746 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.solverstate
I1211 22:52:12.892743 17660 solver.cpp:330] Iteration 97000, Testing net (#0)
I1211 22:52:12.892743 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:52:14.582432 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:52:14.650127 17660 solver.cpp:397]     Test net output #0: accuracy = 0.93
I1211 22:52:14.650127 17660 solver.cpp:397]     Test net output #1: loss = 0.237172 (* 1 = 0.237172 loss)
I1211 22:52:14.725695 17660 solver.cpp:218] Iteration 97000 (10.0992 iter/s, 9.90177s/100 iters), loss = 0.0238037
I1211 22:52:14.725695 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:52:14.725695 17660 solver.cpp:237]     Train net output #1: loss = 0.0238037 (* 1 = 0.0238037 loss)
I1211 22:52:14.725695 17660 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1211 22:52:22.826699 17660 solver.cpp:218] Iteration 97100 (12.3456 iter/s, 8.10005s/100 iters), loss = 0.0344021
I1211 22:52:22.826699 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:52:22.826699 17660 solver.cpp:237]     Train net output #1: loss = 0.0344021 (* 1 = 0.0344021 loss)
I1211 22:52:22.826699 17660 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1211 22:52:30.915218 17660 solver.cpp:218] Iteration 97200 (12.364 iter/s, 8.088s/100 iters), loss = 0.0469934
I1211 22:52:30.915719 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:52:30.915719 17660 solver.cpp:237]     Train net output #1: loss = 0.0469934 (* 1 = 0.0469934 loss)
I1211 22:52:30.915719 17660 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1211 22:52:39.062381 17660 solver.cpp:218] Iteration 97300 (12.2752 iter/s, 8.14654s/100 iters), loss = 0.0191912
I1211 22:52:39.062381 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:52:39.062381 17660 solver.cpp:237]     Train net output #1: loss = 0.0191912 (* 1 = 0.0191912 loss)
I1211 22:52:39.062381 17660 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1211 22:52:47.169136 17660 solver.cpp:218] Iteration 97400 (12.3366 iter/s, 8.10599s/100 iters), loss = 0.0332326
I1211 22:52:47.169136 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:52:47.169136 17660 solver.cpp:237]     Train net output #1: loss = 0.0332326 (* 1 = 0.0332326 loss)
I1211 22:52:47.169136 17660 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1211 22:52:54.879904 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:52:55.200317 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.caffemodel
I1211 22:52:55.233819 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.solverstate
I1211 22:52:55.240823 17660 solver.cpp:330] Iteration 97500, Testing net (#0)
I1211 22:52:55.240823 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:52:56.937033 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:52:57.003165 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9314
I1211 22:52:57.004165 17660 solver.cpp:397]     Test net output #1: loss = 0.237605 (* 1 = 0.237605 loss)
I1211 22:52:57.079269 17660 solver.cpp:218] Iteration 97500 (10.091 iter/s, 9.90978s/100 iters), loss = 0.0257965
I1211 22:52:57.079269 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:52:57.079269 17660 solver.cpp:237]     Train net output #1: loss = 0.0257965 (* 1 = 0.0257965 loss)
I1211 22:52:57.079269 17660 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1211 22:53:05.182543 17660 solver.cpp:218] Iteration 97600 (12.3419 iter/s, 8.10248s/100 iters), loss = 0.0540666
I1211 22:53:05.182543 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:53:05.182543 17660 solver.cpp:237]     Train net output #1: loss = 0.0540666 (* 1 = 0.0540666 loss)
I1211 22:53:05.182543 17660 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1211 22:53:13.285374 17660 solver.cpp:218] Iteration 97700 (12.3416 iter/s, 8.10269s/100 iters), loss = 0.0614811
I1211 22:53:13.285374 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:53:13.285374 17660 solver.cpp:237]     Train net output #1: loss = 0.0614811 (* 1 = 0.0614811 loss)
I1211 22:53:13.285374 17660 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1211 22:53:21.383002 17660 solver.cpp:218] Iteration 97800 (12.3505 iter/s, 8.09685s/100 iters), loss = 0.0412915
I1211 22:53:21.383002 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:53:21.383002 17660 solver.cpp:237]     Train net output #1: loss = 0.0412915 (* 1 = 0.0412915 loss)
I1211 22:53:21.383002 17660 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1211 22:53:29.465119 17660 solver.cpp:218] Iteration 97900 (12.3739 iter/s, 8.08156s/100 iters), loss = 0.0275847
I1211 22:53:29.465119 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:53:29.465119 17660 solver.cpp:237]     Train net output #1: loss = 0.0275847 (* 1 = 0.0275847 loss)
I1211 22:53:29.465119 17660 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1211 22:53:37.170553 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:53:37.490600 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.caffemodel
I1211 22:53:37.519619 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.solverstate
I1211 22:53:37.525619 17660 solver.cpp:330] Iteration 98000, Testing net (#0)
I1211 22:53:37.525619 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:53:39.218943 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:53:39.285485 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 22:53:39.285485 17660 solver.cpp:397]     Test net output #1: loss = 0.231725 (* 1 = 0.231725 loss)
I1211 22:53:39.362066 17660 solver.cpp:218] Iteration 98000 (10.1041 iter/s, 9.89699s/100 iters), loss = 0.029555
I1211 22:53:39.362066 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:53:39.362066 17660 solver.cpp:237]     Train net output #1: loss = 0.029555 (* 1 = 0.029555 loss)
I1211 22:53:39.362066 17660 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1211 22:53:47.464316 17660 solver.cpp:218] Iteration 98100 (12.3431 iter/s, 8.10168s/100 iters), loss = 0.0514252
I1211 22:53:47.464316 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:53:47.464316 17660 solver.cpp:237]     Train net output #1: loss = 0.0514252 (* 1 = 0.0514252 loss)
I1211 22:53:47.464316 17660 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1211 22:53:55.566601 17660 solver.cpp:218] Iteration 98200 (12.3439 iter/s, 8.10116s/100 iters), loss = 0.0281487
I1211 22:53:55.566601 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:53:55.566601 17660 solver.cpp:237]     Train net output #1: loss = 0.0281487 (* 1 = 0.0281487 loss)
I1211 22:53:55.566601 17660 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1211 22:54:03.663355 17660 solver.cpp:218] Iteration 98300 (12.3514 iter/s, 8.09627s/100 iters), loss = 0.0461821
I1211 22:54:03.663355 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:54:03.663355 17660 solver.cpp:237]     Train net output #1: loss = 0.0461821 (* 1 = 0.0461821 loss)
I1211 22:54:03.663355 17660 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1211 22:54:11.769996 17660 solver.cpp:218] Iteration 98400 (12.3359 iter/s, 8.10645s/100 iters), loss = 0.0269451
I1211 22:54:11.770496 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:54:11.770496 17660 solver.cpp:237]     Train net output #1: loss = 0.0269451 (* 1 = 0.0269451 loss)
I1211 22:54:11.770496 17660 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1211 22:54:19.477510 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:54:19.798568 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.caffemodel
I1211 22:54:19.829567 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.solverstate
I1211 22:54:19.835566 17660 solver.cpp:330] Iteration 98500, Testing net (#0)
I1211 22:54:19.836566 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:54:21.528683 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:54:21.596690 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1211 22:54:21.596690 17660 solver.cpp:397]     Test net output #1: loss = 0.235118 (* 1 = 0.235118 loss)
I1211 22:54:21.672194 17660 solver.cpp:218] Iteration 98500 (10.0994 iter/s, 9.90155s/100 iters), loss = 0.0384767
I1211 22:54:21.672194 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:54:21.672695 17660 solver.cpp:237]     Train net output #1: loss = 0.0384767 (* 1 = 0.0384767 loss)
I1211 22:54:21.672695 17660 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1211 22:54:29.777613 17660 solver.cpp:218] Iteration 98600 (12.3387 iter/s, 8.10458s/100 iters), loss = 0.0689654
I1211 22:54:29.777613 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:54:29.777613 17660 solver.cpp:237]     Train net output #1: loss = 0.0689654 (* 1 = 0.0689654 loss)
I1211 22:54:29.777613 17660 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1211 22:54:37.870496 17660 solver.cpp:218] Iteration 98700 (12.3575 iter/s, 8.09222s/100 iters), loss = 0.046173
I1211 22:54:37.870496 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:54:37.870496 17660 solver.cpp:237]     Train net output #1: loss = 0.046173 (* 1 = 0.046173 loss)
I1211 22:54:37.870496 17660 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1211 22:54:45.955960 17660 solver.cpp:218] Iteration 98800 (12.3682 iter/s, 8.08526s/100 iters), loss = 0.0142482
I1211 22:54:45.955960 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:54:45.955960 17660 solver.cpp:237]     Train net output #1: loss = 0.0142482 (* 1 = 0.0142482 loss)
I1211 22:54:45.955960 17660 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1211 22:54:54.054107 17660 solver.cpp:218] Iteration 98900 (12.3488 iter/s, 8.09798s/100 iters), loss = 0.0256787
I1211 22:54:54.054107 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:54:54.054107 17660 solver.cpp:237]     Train net output #1: loss = 0.0256787 (* 1 = 0.0256787 loss)
I1211 22:54:54.054107 17660 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1211 22:55:01.738688 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:55:02.060715 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.caffemodel
I1211 22:55:02.100265 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.solverstate
I1211 22:55:02.106279 17660 solver.cpp:330] Iteration 99000, Testing net (#0)
I1211 22:55:02.106279 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:55:03.798421 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:55:03.866422 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1211 22:55:03.866422 17660 solver.cpp:397]     Test net output #1: loss = 0.238555 (* 1 = 0.238555 loss)
I1211 22:55:03.940444 17660 solver.cpp:218] Iteration 99000 (10.1157 iter/s, 9.88561s/100 iters), loss = 0.020174
I1211 22:55:03.940444 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:55:03.940444 17660 solver.cpp:237]     Train net output #1: loss = 0.020174 (* 1 = 0.020174 loss)
I1211 22:55:03.940444 17660 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1211 22:55:12.164533 17660 solver.cpp:218] Iteration 99100 (12.1604 iter/s, 8.22342s/100 iters), loss = 0.0355392
I1211 22:55:12.164533 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:55:12.164533 17660 solver.cpp:237]     Train net output #1: loss = 0.0355392 (* 1 = 0.0355392 loss)
I1211 22:55:12.164533 17660 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1211 22:55:20.170338 17660 solver.cpp:218] Iteration 99200 (12.4915 iter/s, 8.00545s/100 iters), loss = 0.0532679
I1211 22:55:20.170338 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:55:20.170338 17660 solver.cpp:237]     Train net output #1: loss = 0.0532679 (* 1 = 0.0532679 loss)
I1211 22:55:20.170338 17660 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1211 22:55:28.218308 17660 solver.cpp:218] Iteration 99300 (12.427 iter/s, 8.047s/100 iters), loss = 0.042313
I1211 22:55:28.218308 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:55:28.218308 17660 solver.cpp:237]     Train net output #1: loss = 0.042313 (* 1 = 0.042313 loss)
I1211 22:55:28.218308 17660 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1211 22:55:36.304589 17660 solver.cpp:218] Iteration 99400 (12.3676 iter/s, 8.08563s/100 iters), loss = 0.0265502
I1211 22:55:36.304589 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:55:36.304589 17660 solver.cpp:237]     Train net output #1: loss = 0.0265502 (* 1 = 0.0265502 loss)
I1211 22:55:36.304589 17660 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1211 22:55:43.991618 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:55:44.310693 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.caffemodel
I1211 22:55:44.339680 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.solverstate
I1211 22:55:44.346678 17660 solver.cpp:330] Iteration 99500, Testing net (#0)
I1211 22:55:44.346678 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:55:46.034895 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:55:46.101900 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1211 22:55:46.101900 17660 solver.cpp:397]     Test net output #1: loss = 0.237429 (* 1 = 0.237429 loss)
I1211 22:55:46.175904 17660 solver.cpp:218] Iteration 99500 (10.1307 iter/s, 9.87096s/100 iters), loss = 0.0580017
I1211 22:55:46.175904 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:55:46.175904 17660 solver.cpp:237]     Train net output #1: loss = 0.0580017 (* 1 = 0.0580017 loss)
I1211 22:55:46.175904 17660 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1211 22:55:54.185328 17660 solver.cpp:218] Iteration 99600 (12.4857 iter/s, 8.00919s/100 iters), loss = 0.0347688
I1211 22:55:54.185328 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:55:54.186336 17660 solver.cpp:237]     Train net output #1: loss = 0.0347688 (* 1 = 0.0347688 loss)
I1211 22:55:54.186336 17660 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1211 22:56:02.213289 17660 solver.cpp:218] Iteration 99700 (12.4577 iter/s, 8.02714s/100 iters), loss = 0.0463502
I1211 22:56:02.213289 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:56:02.213289 17660 solver.cpp:237]     Train net output #1: loss = 0.0463502 (* 1 = 0.0463502 loss)
I1211 22:56:02.213289 17660 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1211 22:56:10.259197 17660 solver.cpp:218] Iteration 99800 (12.4295 iter/s, 8.04537s/100 iters), loss = 0.0195521
I1211 22:56:10.259197 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:56:10.259197 17660 solver.cpp:237]     Train net output #1: loss = 0.0195521 (* 1 = 0.0195521 loss)
I1211 22:56:10.259197 17660 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1211 22:56:18.280251 17660 solver.cpp:218] Iteration 99900 (12.4688 iter/s, 8.02005s/100 iters), loss = 0.0440777
I1211 22:56:18.280251 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:56:18.280251 17660 solver.cpp:237]     Train net output #1: loss = 0.0440777 (* 1 = 0.0440777 loss)
I1211 22:56:18.280251 17660 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1211 22:56:25.921272 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:56:26.240310 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.caffemodel
I1211 22:56:26.272817 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.solverstate
I1211 22:56:26.279356 17660 solver.cpp:330] Iteration 100000, Testing net (#0)
I1211 22:56:26.279356 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:56:27.968484 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:56:28.035501 17660 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 22:56:28.035501 17660 solver.cpp:397]     Test net output #1: loss = 0.239093 (* 1 = 0.239093 loss)
I1211 22:56:28.111495 17660 solver.cpp:218] Iteration 100000 (10.1721 iter/s, 9.83079s/100 iters), loss = 0.0212772
I1211 22:56:28.111495 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:56:28.111495 17660 solver.cpp:237]     Train net output #1: loss = 0.0212772 (* 1 = 0.0212772 loss)
I1211 22:56:28.111495 17660 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1211 22:56:36.159523 17660 solver.cpp:218] Iteration 100100 (12.4267 iter/s, 8.0472s/100 iters), loss = 0.0222852
I1211 22:56:36.159523 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:56:36.159523 17660 solver.cpp:237]     Train net output #1: loss = 0.0222852 (* 1 = 0.0222852 loss)
I1211 22:56:36.159523 17660 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1211 22:56:44.268528 17660 solver.cpp:218] Iteration 100200 (12.3333 iter/s, 8.1081s/100 iters), loss = 0.0330199
I1211 22:56:44.268528 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:56:44.268528 17660 solver.cpp:237]     Train net output #1: loss = 0.0330199 (* 1 = 0.0330199 loss)
I1211 22:56:44.268528 17660 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1211 22:56:52.550413 17660 solver.cpp:218] Iteration 100300 (12.0749 iter/s, 8.28166s/100 iters), loss = 0.0389988
I1211 22:56:52.550413 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:56:52.550413 17660 solver.cpp:237]     Train net output #1: loss = 0.0389988 (* 1 = 0.0389988 loss)
I1211 22:56:52.550413 17660 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1211 22:57:00.655222 17660 solver.cpp:218] Iteration 100400 (12.3398 iter/s, 8.10386s/100 iters), loss = 0.0211146
I1211 22:57:00.655222 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:57:00.655222 17660 solver.cpp:237]     Train net output #1: loss = 0.0211146 (* 1 = 0.0211146 loss)
I1211 22:57:00.655222 17660 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1211 22:57:08.384789 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:57:08.702384 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.caffemodel
I1211 22:57:08.737396 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.solverstate
I1211 22:57:08.743396 17660 solver.cpp:330] Iteration 100500, Testing net (#0)
I1211 22:57:08.743396 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:57:10.447250 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:57:10.515259 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1211 22:57:10.515259 17660 solver.cpp:397]     Test net output #1: loss = 0.236338 (* 1 = 0.236338 loss)
I1211 22:57:10.592540 17660 solver.cpp:218] Iteration 100500 (10.0632 iter/s, 9.93723s/100 iters), loss = 0.029908
I1211 22:57:10.592540 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:57:10.592540 17660 solver.cpp:237]     Train net output #1: loss = 0.029908 (* 1 = 0.029908 loss)
I1211 22:57:10.592540 17660 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1211 22:57:18.713152 17660 solver.cpp:218] Iteration 100600 (12.3146 iter/s, 8.12047s/100 iters), loss = 0.0377276
I1211 22:57:18.714154 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:57:18.714154 17660 solver.cpp:237]     Train net output #1: loss = 0.0377276 (* 1 = 0.0377276 loss)
I1211 22:57:18.714154 17660 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1211 22:57:26.770756 17660 solver.cpp:218] Iteration 100700 (12.4127 iter/s, 8.05625s/100 iters), loss = 0.0318116
I1211 22:57:26.770756 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:57:26.770756 17660 solver.cpp:237]     Train net output #1: loss = 0.0318116 (* 1 = 0.0318116 loss)
I1211 22:57:26.770756 17660 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1211 22:57:34.836815 17660 solver.cpp:218] Iteration 100800 (12.3985 iter/s, 8.06549s/100 iters), loss = 0.0239661
I1211 22:57:34.836815 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:57:34.836815 17660 solver.cpp:237]     Train net output #1: loss = 0.0239661 (* 1 = 0.0239661 loss)
I1211 22:57:34.836815 17660 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1211 22:57:42.977669 17660 solver.cpp:218] Iteration 100900 (12.2844 iter/s, 8.14041s/100 iters), loss = 0.0337935
I1211 22:57:42.977669 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:57:42.977669 17660 solver.cpp:237]     Train net output #1: loss = 0.0337935 (* 1 = 0.0337935 loss)
I1211 22:57:42.977669 17660 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1211 22:57:50.874034 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:57:51.195068 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.caffemodel
I1211 22:57:51.224069 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.solverstate
I1211 22:57:51.230069 17660 solver.cpp:330] Iteration 101000, Testing net (#0)
I1211 22:57:51.230069 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:57:52.936300 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:57:53.005307 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 22:57:53.005307 17660 solver.cpp:397]     Test net output #1: loss = 0.237174 (* 1 = 0.237174 loss)
I1211 22:57:53.081321 17660 solver.cpp:218] Iteration 101000 (9.89747 iter/s, 10.1036s/100 iters), loss = 0.0352497
I1211 22:57:53.081321 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:57:53.081321 17660 solver.cpp:237]     Train net output #1: loss = 0.0352497 (* 1 = 0.0352497 loss)
I1211 22:57:53.081321 17660 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1211 22:58:01.197798 17660 solver.cpp:218] Iteration 101100 (12.3214 iter/s, 8.11597s/100 iters), loss = 0.0698391
I1211 22:58:01.197798 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:58:01.197798 17660 solver.cpp:237]     Train net output #1: loss = 0.0698391 (* 1 = 0.0698391 loss)
I1211 22:58:01.197798 17660 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1211 22:58:09.417721 17660 solver.cpp:218] Iteration 101200 (12.1668 iter/s, 8.21906s/100 iters), loss = 0.036787
I1211 22:58:09.417721 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 22:58:09.417721 17660 solver.cpp:237]     Train net output #1: loss = 0.036787 (* 1 = 0.036787 loss)
I1211 22:58:09.417721 17660 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1211 22:58:17.563405 17660 solver.cpp:218] Iteration 101300 (12.2768 iter/s, 8.14546s/100 iters), loss = 0.0176396
I1211 22:58:17.563405 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:58:17.563405 17660 solver.cpp:237]     Train net output #1: loss = 0.0176396 (* 1 = 0.0176396 loss)
I1211 22:58:17.563405 17660 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1211 22:58:25.636364 17660 solver.cpp:218] Iteration 101400 (12.3889 iter/s, 8.07173s/100 iters), loss = 0.0237019
I1211 22:58:25.636364 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:58:25.636364 17660 solver.cpp:237]     Train net output #1: loss = 0.0237019 (* 1 = 0.0237019 loss)
I1211 22:58:25.636364 17660 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1211 22:58:33.364563 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:58:33.682793 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.caffemodel
I1211 22:58:33.716795 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.solverstate
I1211 22:58:33.722803 17660 solver.cpp:330] Iteration 101500, Testing net (#0)
I1211 22:58:33.722803 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:58:35.407384 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:58:35.475891 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 22:58:35.475891 17660 solver.cpp:397]     Test net output #1: loss = 0.238563 (* 1 = 0.238563 loss)
I1211 22:58:35.549904 17660 solver.cpp:218] Iteration 101500 (10.0871 iter/s, 9.91369s/100 iters), loss = 0.0296348
I1211 22:58:35.549904 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:58:35.549904 17660 solver.cpp:237]     Train net output #1: loss = 0.0296349 (* 1 = 0.0296349 loss)
I1211 22:58:35.549904 17660 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1211 22:58:43.729349 17660 solver.cpp:218] Iteration 101600 (12.2271 iter/s, 8.17852s/100 iters), loss = 0.0356297
I1211 22:58:43.729349 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:58:43.729349 17660 solver.cpp:237]     Train net output #1: loss = 0.0356297 (* 1 = 0.0356297 loss)
I1211 22:58:43.729349 17660 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1211 22:58:51.878907 17660 solver.cpp:218] Iteration 101700 (12.2716 iter/s, 8.14887s/100 iters), loss = 0.0567138
I1211 22:58:51.878907 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1211 22:58:51.878907 17660 solver.cpp:237]     Train net output #1: loss = 0.0567138 (* 1 = 0.0567138 loss)
I1211 22:58:51.878907 17660 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1211 22:59:00.054973 17660 solver.cpp:218] Iteration 101800 (12.2314 iter/s, 8.17566s/100 iters), loss = 0.0251912
I1211 22:59:00.054973 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:59:00.054973 17660 solver.cpp:237]     Train net output #1: loss = 0.0251912 (* 1 = 0.0251912 loss)
I1211 22:59:00.054973 17660 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1211 22:59:08.199080 17660 solver.cpp:218] Iteration 101900 (12.2798 iter/s, 8.14344s/100 iters), loss = 0.0325264
I1211 22:59:08.199080 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:59:08.199080 17660 solver.cpp:237]     Train net output #1: loss = 0.0325264 (* 1 = 0.0325264 loss)
I1211 22:59:08.199080 17660 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1211 22:59:15.934559 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:59:16.254169 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.caffemodel
I1211 22:59:16.285676 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.solverstate
I1211 22:59:16.292179 17660 solver.cpp:330] Iteration 102000, Testing net (#0)
I1211 22:59:16.292179 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 22:59:17.976321 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:59:18.042321 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1211 22:59:18.043323 17660 solver.cpp:397]     Test net output #1: loss = 0.235974 (* 1 = 0.235974 loss)
I1211 22:59:18.118340 17660 solver.cpp:218] Iteration 102000 (10.0822 iter/s, 9.91846s/100 iters), loss = 0.0321942
I1211 22:59:18.118340 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:59:18.118340 17660 solver.cpp:237]     Train net output #1: loss = 0.0321942 (* 1 = 0.0321942 loss)
I1211 22:59:18.118340 17660 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1211 22:59:26.241210 17660 solver.cpp:218] Iteration 102100 (12.3116 iter/s, 8.12239s/100 iters), loss = 0.0314945
I1211 22:59:26.241210 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:59:26.241210 17660 solver.cpp:237]     Train net output #1: loss = 0.0314945 (* 1 = 0.0314945 loss)
I1211 22:59:26.241210 17660 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1211 22:59:34.410176 17660 solver.cpp:218] Iteration 102200 (12.2427 iter/s, 8.16815s/100 iters), loss = 0.0605443
I1211 22:59:34.410176 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 22:59:34.410176 17660 solver.cpp:237]     Train net output #1: loss = 0.0605443 (* 1 = 0.0605443 loss)
I1211 22:59:34.410176 17660 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1211 22:59:42.677248 17660 solver.cpp:218] Iteration 102300 (12.0971 iter/s, 8.26643s/100 iters), loss = 0.0124186
I1211 22:59:42.677248 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:59:42.677248 17660 solver.cpp:237]     Train net output #1: loss = 0.0124186 (* 1 = 0.0124186 loss)
I1211 22:59:42.677248 17660 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1211 22:59:50.917217 17660 solver.cpp:218] Iteration 102400 (12.137 iter/s, 8.23924s/100 iters), loss = 0.0198975
I1211 22:59:50.917217 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 22:59:50.917217 17660 solver.cpp:237]     Train net output #1: loss = 0.0198975 (* 1 = 0.0198975 loss)
I1211 22:59:50.917217 17660 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1211 22:59:58.678997 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 22:59:58.998543 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.caffemodel
I1211 22:59:59.026545 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.solverstate
I1211 22:59:59.033545 17660 solver.cpp:330] Iteration 102500, Testing net (#0)
I1211 22:59:59.033545 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:00:00.753762 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:00:00.823789 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 23:00:00.823789 17660 solver.cpp:397]     Test net output #1: loss = 0.237981 (* 1 = 0.237981 loss)
I1211 23:00:00.902802 17660 solver.cpp:218] Iteration 102500 (10.0148 iter/s, 9.98525s/100 iters), loss = 0.0294856
I1211 23:00:00.902802 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:00.902802 17660 solver.cpp:237]     Train net output #1: loss = 0.0294856 (* 1 = 0.0294856 loss)
I1211 23:00:00.902802 17660 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1211 23:00:09.165565 17660 solver.cpp:218] Iteration 102600 (12.1038 iter/s, 8.26184s/100 iters), loss = 0.021989
I1211 23:00:09.165565 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:09.165565 17660 solver.cpp:237]     Train net output #1: loss = 0.021989 (* 1 = 0.021989 loss)
I1211 23:00:09.165565 17660 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1211 23:00:17.217389 17660 solver.cpp:218] Iteration 102700 (12.4202 iter/s, 8.05139s/100 iters), loss = 0.0212101
I1211 23:00:17.217389 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:17.217389 17660 solver.cpp:237]     Train net output #1: loss = 0.0212101 (* 1 = 0.0212101 loss)
I1211 23:00:17.217389 17660 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1211 23:00:25.320070 17660 solver.cpp:218] Iteration 102800 (12.3416 iter/s, 8.10269s/100 iters), loss = 0.0153094
I1211 23:00:25.320070 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:25.320070 17660 solver.cpp:237]     Train net output #1: loss = 0.0153094 (* 1 = 0.0153094 loss)
I1211 23:00:25.320070 17660 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1211 23:00:33.586570 17660 solver.cpp:218] Iteration 102900 (12.0986 iter/s, 8.26544s/100 iters), loss = 0.0232328
I1211 23:00:33.586570 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:33.586570 17660 solver.cpp:237]     Train net output #1: loss = 0.0232328 (* 1 = 0.0232328 loss)
I1211 23:00:33.586570 17660 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1211 23:00:41.279597 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:00:41.595624 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.caffemodel
I1211 23:00:41.624625 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.solverstate
I1211 23:00:41.630625 17660 solver.cpp:330] Iteration 103000, Testing net (#0)
I1211 23:00:41.630625 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:00:43.342831 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:00:43.413839 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1211 23:00:43.413839 17660 solver.cpp:397]     Test net output #1: loss = 0.235625 (* 1 = 0.235625 loss)
I1211 23:00:43.490849 17660 solver.cpp:218] Iteration 103000 (10.0964 iter/s, 9.9045s/100 iters), loss = 0.0236956
I1211 23:00:43.490849 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:43.490849 17660 solver.cpp:237]     Train net output #1: loss = 0.0236956 (* 1 = 0.0236956 loss)
I1211 23:00:43.490849 17660 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1211 23:00:51.696358 17660 solver.cpp:218] Iteration 103100 (12.1889 iter/s, 8.20419s/100 iters), loss = 0.0253611
I1211 23:00:51.696358 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:00:51.696358 17660 solver.cpp:237]     Train net output #1: loss = 0.0253611 (* 1 = 0.0253611 loss)
I1211 23:00:51.696358 17660 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1211 23:00:59.944032 17660 solver.cpp:218] Iteration 103200 (12.1255 iter/s, 8.24709s/100 iters), loss = 0.0403957
I1211 23:00:59.944032 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:00:59.944032 17660 solver.cpp:237]     Train net output #1: loss = 0.0403956 (* 1 = 0.0403956 loss)
I1211 23:00:59.944032 17660 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1211 23:01:08.155577 17660 solver.cpp:218] Iteration 103300 (12.1784 iter/s, 8.21126s/100 iters), loss = 0.0139672
I1211 23:01:08.155577 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:01:08.155577 17660 solver.cpp:237]     Train net output #1: loss = 0.0139672 (* 1 = 0.0139672 loss)
I1211 23:01:08.155577 17660 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1211 23:01:16.455896 17660 solver.cpp:218] Iteration 103400 (12.0489 iter/s, 8.29949s/100 iters), loss = 0.0206416
I1211 23:01:16.455896 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:01:16.455896 17660 solver.cpp:237]     Train net output #1: loss = 0.0206416 (* 1 = 0.0206416 loss)
I1211 23:01:16.455896 17660 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1211 23:01:24.238246 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:01:24.559360 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.caffemodel
I1211 23:01:24.592885 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.solverstate
I1211 23:01:24.599381 17660 solver.cpp:330] Iteration 103500, Testing net (#0)
I1211 23:01:24.599381 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:01:26.293512 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:01:26.360030 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1211 23:01:26.360030 17660 solver.cpp:397]     Test net output #1: loss = 0.23541 (* 1 = 0.23541 loss)
I1211 23:01:26.436612 17660 solver.cpp:218] Iteration 103500 (10.0199 iter/s, 9.98015s/100 iters), loss = 0.019315
I1211 23:01:26.436612 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:01:26.436612 17660 solver.cpp:237]     Train net output #1: loss = 0.0193149 (* 1 = 0.0193149 loss)
I1211 23:01:26.436612 17660 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1211 23:01:34.654541 17660 solver.cpp:218] Iteration 103600 (12.1694 iter/s, 8.21734s/100 iters), loss = 0.0296658
I1211 23:01:34.654541 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:01:34.654541 17660 solver.cpp:237]     Train net output #1: loss = 0.0296657 (* 1 = 0.0296657 loss)
I1211 23:01:34.654541 17660 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1211 23:01:42.881345 17660 solver.cpp:218] Iteration 103700 (12.1556 iter/s, 8.22669s/100 iters), loss = 0.0188448
I1211 23:01:42.881345 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:01:42.881345 17660 solver.cpp:237]     Train net output #1: loss = 0.0188448 (* 1 = 0.0188448 loss)
I1211 23:01:42.881345 17660 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1211 23:01:51.115022 17660 solver.cpp:218] Iteration 103800 (12.1463 iter/s, 8.23298s/100 iters), loss = 0.0183705
I1211 23:01:51.115022 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:01:51.115022 17660 solver.cpp:237]     Train net output #1: loss = 0.0183705 (* 1 = 0.0183705 loss)
I1211 23:01:51.115022 17660 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1211 23:01:59.195483 17660 solver.cpp:218] Iteration 103900 (12.3766 iter/s, 8.07976s/100 iters), loss = 0.0138246
I1211 23:01:59.195483 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:01:59.195986 17660 solver.cpp:237]     Train net output #1: loss = 0.0138245 (* 1 = 0.0138245 loss)
I1211 23:01:59.195986 17660 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1211 23:02:06.921068 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:02:07.250102 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.caffemodel
I1211 23:02:07.285105 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.solverstate
I1211 23:02:07.292101 17660 solver.cpp:330] Iteration 104000, Testing net (#0)
I1211 23:02:07.292101 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:02:08.994573 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:02:09.060582 17660 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1211 23:02:09.060582 17660 solver.cpp:397]     Test net output #1: loss = 0.240069 (* 1 = 0.240069 loss)
I1211 23:02:09.135603 17660 solver.cpp:218] Iteration 104000 (10.0604 iter/s, 9.93996s/100 iters), loss = 0.0291646
I1211 23:02:09.135603 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:02:09.135603 17660 solver.cpp:237]     Train net output #1: loss = 0.0291645 (* 1 = 0.0291645 loss)
I1211 23:02:09.135603 17660 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1211 23:02:17.232753 17660 solver.cpp:218] Iteration 104100 (12.3515 iter/s, 8.0962s/100 iters), loss = 0.0440309
I1211 23:02:17.232753 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 23:02:17.232753 17660 solver.cpp:237]     Train net output #1: loss = 0.0440309 (* 1 = 0.0440309 loss)
I1211 23:02:17.232753 17660 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1211 23:02:25.356812 17660 solver.cpp:218] Iteration 104200 (12.3091 iter/s, 8.12408s/100 iters), loss = 0.0368331
I1211 23:02:25.357811 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:02:25.357811 17660 solver.cpp:237]     Train net output #1: loss = 0.0368331 (* 1 = 0.0368331 loss)
I1211 23:02:25.357811 17660 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1211 23:02:33.503887 17660 solver.cpp:218] Iteration 104300 (12.276 iter/s, 8.14594s/100 iters), loss = 0.0228836
I1211 23:02:33.503887 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:02:33.503887 17660 solver.cpp:237]     Train net output #1: loss = 0.0228836 (* 1 = 0.0228836 loss)
I1211 23:02:33.503887 17660 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1211 23:02:41.665828 17660 solver.cpp:218] Iteration 104400 (12.2528 iter/s, 8.16142s/100 iters), loss = 0.0164551
I1211 23:02:41.665828 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:02:41.665828 17660 solver.cpp:237]     Train net output #1: loss = 0.0164551 (* 1 = 0.0164551 loss)
I1211 23:02:41.665828 17660 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1211 23:02:49.325994 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:02:49.647528 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.caffemodel
I1211 23:02:49.676528 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.solverstate
I1211 23:02:49.682529 17660 solver.cpp:330] Iteration 104500, Testing net (#0)
I1211 23:02:49.682529 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:02:51.367679 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:02:51.435685 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1211 23:02:51.435685 17660 solver.cpp:397]     Test net output #1: loss = 0.237258 (* 1 = 0.237258 loss)
I1211 23:02:51.510684 17660 solver.cpp:218] Iteration 104500 (10.1575 iter/s, 9.84494s/100 iters), loss = 0.0208099
I1211 23:02:51.511685 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:02:51.511685 17660 solver.cpp:237]     Train net output #1: loss = 0.0208099 (* 1 = 0.0208099 loss)
I1211 23:02:51.511685 17660 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1211 23:02:59.582651 17660 solver.cpp:218] Iteration 104600 (12.3897 iter/s, 8.07124s/100 iters), loss = 0.01792
I1211 23:02:59.582651 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:02:59.582651 17660 solver.cpp:237]     Train net output #1: loss = 0.01792 (* 1 = 0.01792 loss)
I1211 23:02:59.582651 17660 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1211 23:03:07.677551 17660 solver.cpp:218] Iteration 104700 (12.3553 iter/s, 8.09372s/100 iters), loss = 0.0273677
I1211 23:03:07.677551 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:03:07.677551 17660 solver.cpp:237]     Train net output #1: loss = 0.0273677 (* 1 = 0.0273677 loss)
I1211 23:03:07.677551 17660 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1211 23:03:15.926051 17660 solver.cpp:218] Iteration 104800 (12.1242 iter/s, 8.24796s/100 iters), loss = 0.0351631
I1211 23:03:15.926051 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:03:15.926051 17660 solver.cpp:237]     Train net output #1: loss = 0.0351631 (* 1 = 0.0351631 loss)
I1211 23:03:15.926051 17660 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1211 23:03:23.992599 17660 solver.cpp:218] Iteration 104900 (12.3972 iter/s, 8.06634s/100 iters), loss = 0.0218091
I1211 23:03:23.992599 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:03:23.992599 17660 solver.cpp:237]     Train net output #1: loss = 0.0218091 (* 1 = 0.0218091 loss)
I1211 23:03:23.992599 17660 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1211 23:03:31.713953 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:03:32.042068 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.caffemodel
I1211 23:03:32.073112 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.solverstate
I1211 23:03:32.080111 17660 solver.cpp:330] Iteration 105000, Testing net (#0)
I1211 23:03:32.081123 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:03:33.792959 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:03:33.859997 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1211 23:03:33.859997 17660 solver.cpp:397]     Test net output #1: loss = 0.239605 (* 1 = 0.239605 loss)
I1211 23:03:33.935986 17660 solver.cpp:218] Iteration 105000 (10.0573 iter/s, 9.94304s/100 iters), loss = 0.0281202
I1211 23:03:33.935986 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:03:33.935986 17660 solver.cpp:237]     Train net output #1: loss = 0.0281202 (* 1 = 0.0281202 loss)
I1211 23:03:33.935986 17660 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1211 23:03:42.207629 17660 solver.cpp:218] Iteration 105100 (12.0903 iter/s, 8.27107s/100 iters), loss = 0.0134897
I1211 23:03:42.207629 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:03:42.207629 17660 solver.cpp:237]     Train net output #1: loss = 0.0134897 (* 1 = 0.0134897 loss)
I1211 23:03:42.207629 17660 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1211 23:03:50.577766 17660 solver.cpp:218] Iteration 105200 (11.9486 iter/s, 8.36921s/100 iters), loss = 0.0304242
I1211 23:03:50.577766 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:03:50.577766 17660 solver.cpp:237]     Train net output #1: loss = 0.0304241 (* 1 = 0.0304241 loss)
I1211 23:03:50.577766 17660 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1211 23:03:58.795162 17660 solver.cpp:218] Iteration 105300 (12.1698 iter/s, 8.21706s/100 iters), loss = 0.0137146
I1211 23:03:58.796164 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:03:58.796164 17660 solver.cpp:237]     Train net output #1: loss = 0.0137146 (* 1 = 0.0137146 loss)
I1211 23:03:58.796164 17660 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1211 23:04:06.954943 17660 solver.cpp:218] Iteration 105400 (12.2569 iter/s, 8.15866s/100 iters), loss = 0.0197857
I1211 23:04:06.955436 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:04:06.955436 17660 solver.cpp:237]     Train net output #1: loss = 0.0197856 (* 1 = 0.0197856 loss)
I1211 23:04:06.955436 17660 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1211 23:04:14.720130 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:04:15.043052 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.caffemodel
I1211 23:04:15.072057 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.solverstate
I1211 23:04:15.079138 17660 solver.cpp:330] Iteration 105500, Testing net (#0)
I1211 23:04:15.079138 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:04:16.777570 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:04:16.843569 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1211 23:04:16.843569 17660 solver.cpp:397]     Test net output #1: loss = 0.236727 (* 1 = 0.236727 loss)
I1211 23:04:16.920130 17660 solver.cpp:218] Iteration 105500 (10.0353 iter/s, 9.96484s/100 iters), loss = 0.0137973
I1211 23:04:16.920130 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:04:16.920130 17660 solver.cpp:237]     Train net output #1: loss = 0.0137973 (* 1 = 0.0137973 loss)
I1211 23:04:16.920130 17660 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1211 23:04:25.080457 17660 solver.cpp:218] Iteration 105600 (12.2561 iter/s, 8.15918s/100 iters), loss = 0.0316491
I1211 23:04:25.080457 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:04:25.080457 17660 solver.cpp:237]     Train net output #1: loss = 0.0316491 (* 1 = 0.0316491 loss)
I1211 23:04:25.080457 17660 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1211 23:04:33.180276 17660 solver.cpp:218] Iteration 105700 (12.3457 iter/s, 8.1s/100 iters), loss = 0.0167292
I1211 23:04:33.180276 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:04:33.180276 17660 solver.cpp:237]     Train net output #1: loss = 0.0167291 (* 1 = 0.0167291 loss)
I1211 23:04:33.180276 17660 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1211 23:04:41.286916 17660 solver.cpp:218] Iteration 105800 (12.3374 iter/s, 8.10546s/100 iters), loss = 0.01943
I1211 23:04:41.286916 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:04:41.286916 17660 solver.cpp:237]     Train net output #1: loss = 0.01943 (* 1 = 0.01943 loss)
I1211 23:04:41.286916 17660 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1211 23:04:49.357810 17660 solver.cpp:218] Iteration 105900 (12.39 iter/s, 8.07105s/100 iters), loss = 0.0144763
I1211 23:04:49.357810 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:04:49.357810 17660 solver.cpp:237]     Train net output #1: loss = 0.0144763 (* 1 = 0.0144763 loss)
I1211 23:04:49.357810 17660 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1211 23:04:57.023810 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:04:57.343833 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.caffemodel
I1211 23:04:57.371847 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.solverstate
I1211 23:04:57.377866 17660 solver.cpp:330] Iteration 106000, Testing net (#0)
I1211 23:04:57.378355 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:04:59.062086 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:04:59.129094 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 23:04:59.129094 17660 solver.cpp:397]     Test net output #1: loss = 0.240286 (* 1 = 0.240286 loss)
I1211 23:04:59.203117 17660 solver.cpp:218] Iteration 106000 (10.1579 iter/s, 9.84458s/100 iters), loss = 0.0150409
I1211 23:04:59.203117 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:04:59.203117 17660 solver.cpp:237]     Train net output #1: loss = 0.0150409 (* 1 = 0.0150409 loss)
I1211 23:04:59.203117 17660 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1211 23:05:07.296178 17660 solver.cpp:218] Iteration 106100 (12.3579 iter/s, 8.09202s/100 iters), loss = 0.0306111
I1211 23:05:07.296178 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:05:07.296178 17660 solver.cpp:237]     Train net output #1: loss = 0.0306111 (* 1 = 0.0306111 loss)
I1211 23:05:07.296178 17660 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1211 23:05:15.358283 17660 solver.cpp:218] Iteration 106200 (12.4048 iter/s, 8.06138s/100 iters), loss = 0.0428381
I1211 23:05:15.358283 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:05:15.358283 17660 solver.cpp:237]     Train net output #1: loss = 0.0428381 (* 1 = 0.0428381 loss)
I1211 23:05:15.358283 17660 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1211 23:05:23.433714 17660 solver.cpp:218] Iteration 106300 (12.3837 iter/s, 8.07511s/100 iters), loss = 0.0172214
I1211 23:05:23.433714 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:05:23.433714 17660 solver.cpp:237]     Train net output #1: loss = 0.0172214 (* 1 = 0.0172214 loss)
I1211 23:05:23.433714 17660 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1211 23:05:31.511000 17660 solver.cpp:218] Iteration 106400 (12.3808 iter/s, 8.07702s/100 iters), loss = 0.0161076
I1211 23:05:31.511000 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:05:31.511000 17660 solver.cpp:237]     Train net output #1: loss = 0.0161076 (* 1 = 0.0161076 loss)
I1211 23:05:31.511000 17660 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1211 23:05:39.188516 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:05:39.508554 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.caffemodel
I1211 23:05:39.537554 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.solverstate
I1211 23:05:39.543555 17660 solver.cpp:330] Iteration 106500, Testing net (#0)
I1211 23:05:39.544555 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:05:41.232738 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:05:41.300249 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9356
I1211 23:05:41.300249 17660 solver.cpp:397]     Test net output #1: loss = 0.242516 (* 1 = 0.242516 loss)
I1211 23:05:41.376756 17660 solver.cpp:218] Iteration 106500 (10.1365 iter/s, 9.86539s/100 iters), loss = 0.0346709
I1211 23:05:41.376756 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:05:41.376756 17660 solver.cpp:237]     Train net output #1: loss = 0.0346708 (* 1 = 0.0346708 loss)
I1211 23:05:41.376756 17660 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1211 23:05:49.507036 17660 solver.cpp:218] Iteration 106600 (12.3015 iter/s, 8.12909s/100 iters), loss = 0.0338135
I1211 23:05:49.507036 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:05:49.507036 17660 solver.cpp:237]     Train net output #1: loss = 0.0338135 (* 1 = 0.0338135 loss)
I1211 23:05:49.507036 17660 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1211 23:05:57.583154 17660 solver.cpp:218] Iteration 106700 (12.3829 iter/s, 8.07566s/100 iters), loss = 0.038498
I1211 23:05:57.583154 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:05:57.583154 17660 solver.cpp:237]     Train net output #1: loss = 0.038498 (* 1 = 0.038498 loss)
I1211 23:05:57.583154 17660 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1211 23:06:05.649909 17660 solver.cpp:218] Iteration 106800 (12.3964 iter/s, 8.06687s/100 iters), loss = 0.0129026
I1211 23:06:05.649909 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:05.649909 17660 solver.cpp:237]     Train net output #1: loss = 0.0129025 (* 1 = 0.0129025 loss)
I1211 23:06:05.649909 17660 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1211 23:06:13.732993 17660 solver.cpp:218] Iteration 106900 (12.3728 iter/s, 8.08224s/100 iters), loss = 0.0162856
I1211 23:06:13.732993 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:13.732993 17660 solver.cpp:237]     Train net output #1: loss = 0.0162856 (* 1 = 0.0162856 loss)
I1211 23:06:13.732993 17660 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1211 23:06:21.526872 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:06:21.852421 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.caffemodel
I1211 23:06:21.886420 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.solverstate
I1211 23:06:21.892422 17660 solver.cpp:330] Iteration 107000, Testing net (#0)
I1211 23:06:21.892422 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:06:23.589372 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:06:23.657377 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1211 23:06:23.657377 17660 solver.cpp:397]     Test net output #1: loss = 0.249849 (* 1 = 0.249849 loss)
I1211 23:06:23.732383 17660 solver.cpp:218] Iteration 107000 (10.0012 iter/s, 9.99884s/100 iters), loss = 0.0176812
I1211 23:06:23.732383 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:23.732383 17660 solver.cpp:237]     Train net output #1: loss = 0.0176811 (* 1 = 0.0176811 loss)
I1211 23:06:23.732383 17660 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1211 23:06:31.844003 17660 solver.cpp:218] Iteration 107100 (12.329 iter/s, 8.11093s/100 iters), loss = 0.020884
I1211 23:06:31.844003 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:31.844003 17660 solver.cpp:237]     Train net output #1: loss = 0.0208839 (* 1 = 0.0208839 loss)
I1211 23:06:31.844003 17660 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1211 23:06:39.912955 17660 solver.cpp:218] Iteration 107200 (12.3944 iter/s, 8.06814s/100 iters), loss = 0.0249919
I1211 23:06:39.912955 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:39.912955 17660 solver.cpp:237]     Train net output #1: loss = 0.0249919 (* 1 = 0.0249919 loss)
I1211 23:06:39.912955 17660 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1211 23:06:47.990608 17660 solver.cpp:218] Iteration 107300 (12.3806 iter/s, 8.07714s/100 iters), loss = 0.0117929
I1211 23:06:47.990608 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:47.990608 17660 solver.cpp:237]     Train net output #1: loss = 0.0117929 (* 1 = 0.0117929 loss)
I1211 23:06:47.990608 17660 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1211 23:06:56.064715 17660 solver.cpp:218] Iteration 107400 (12.3862 iter/s, 8.07347s/100 iters), loss = 0.0192222
I1211 23:06:56.064715 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:06:56.064715 17660 solver.cpp:237]     Train net output #1: loss = 0.0192222 (* 1 = 0.0192222 loss)
I1211 23:06:56.064715 17660 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1211 23:07:03.727834 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:07:04.047955 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.caffemodel
I1211 23:07:04.080958 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.solverstate
I1211 23:07:04.086961 17660 solver.cpp:330] Iteration 107500, Testing net (#0)
I1211 23:07:04.086961 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:07:05.777458 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:07:05.845468 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1211 23:07:05.845468 17660 solver.cpp:397]     Test net output #1: loss = 0.243756 (* 1 = 0.243756 loss)
I1211 23:07:05.920464 17660 solver.cpp:218] Iteration 107500 (10.1468 iter/s, 9.85529s/100 iters), loss = 0.0186858
I1211 23:07:05.920464 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:07:05.920464 17660 solver.cpp:237]     Train net output #1: loss = 0.0186858 (* 1 = 0.0186858 loss)
I1211 23:07:05.920464 17660 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1211 23:07:14.006429 17660 solver.cpp:218] Iteration 107600 (12.3682 iter/s, 8.08523s/100 iters), loss = 0.0183918
I1211 23:07:14.006429 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:07:14.006429 17660 solver.cpp:237]     Train net output #1: loss = 0.0183918 (* 1 = 0.0183918 loss)
I1211 23:07:14.006429 17660 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1211 23:07:22.151481 17660 solver.cpp:218] Iteration 107700 (12.2779 iter/s, 8.14473s/100 iters), loss = 0.0428183
I1211 23:07:22.151481 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:07:22.151481 17660 solver.cpp:237]     Train net output #1: loss = 0.0428183 (* 1 = 0.0428183 loss)
I1211 23:07:22.151481 17660 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1211 23:07:30.229298 17660 solver.cpp:218] Iteration 107800 (12.3802 iter/s, 8.07743s/100 iters), loss = 0.0416301
I1211 23:07:30.229298 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:07:30.229298 17660 solver.cpp:237]     Train net output #1: loss = 0.04163 (* 1 = 0.04163 loss)
I1211 23:07:30.229298 17660 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1211 23:07:38.310317 17660 solver.cpp:218] Iteration 107900 (12.3757 iter/s, 8.08038s/100 iters), loss = 0.0137097
I1211 23:07:38.310317 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:07:38.310317 17660 solver.cpp:237]     Train net output #1: loss = 0.0137097 (* 1 = 0.0137097 loss)
I1211 23:07:38.310317 17660 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1211 23:07:46.058568 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:07:46.376314 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.caffemodel
I1211 23:07:46.413316 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.solverstate
I1211 23:07:46.419328 17660 solver.cpp:330] Iteration 108000, Testing net (#0)
I1211 23:07:46.420330 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:07:48.105893 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:07:48.172401 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9323
I1211 23:07:48.173401 17660 solver.cpp:397]     Test net output #1: loss = 0.245235 (* 1 = 0.245235 loss)
I1211 23:07:48.249109 17660 solver.cpp:218] Iteration 108000 (10.0621 iter/s, 9.93825s/100 iters), loss = 0.0173605
I1211 23:07:48.249109 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:07:48.249109 17660 solver.cpp:237]     Train net output #1: loss = 0.0173605 (* 1 = 0.0173605 loss)
I1211 23:07:48.249109 17660 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1211 23:07:56.387004 17660 solver.cpp:218] Iteration 108100 (12.2883 iter/s, 8.13781s/100 iters), loss = 0.0164999
I1211 23:07:56.387004 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:07:56.387004 17660 solver.cpp:237]     Train net output #1: loss = 0.0164999 (* 1 = 0.0164999 loss)
I1211 23:07:56.387004 17660 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1211 23:08:04.483220 17660 solver.cpp:218] Iteration 108200 (12.3526 iter/s, 8.09549s/100 iters), loss = 0.0247066
I1211 23:08:04.483220 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:08:04.483220 17660 solver.cpp:237]     Train net output #1: loss = 0.0247065 (* 1 = 0.0247065 loss)
I1211 23:08:04.483220 17660 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1211 23:08:12.629115 17660 solver.cpp:218] Iteration 108300 (12.2776 iter/s, 8.14491s/100 iters), loss = 0.01578
I1211 23:08:12.629115 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:08:12.629115 17660 solver.cpp:237]     Train net output #1: loss = 0.0157799 (* 1 = 0.0157799 loss)
I1211 23:08:12.629115 17660 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1211 23:08:20.769850 17660 solver.cpp:218] Iteration 108400 (12.2846 iter/s, 8.14024s/100 iters), loss = 0.0243037
I1211 23:08:20.769850 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:08:20.769850 17660 solver.cpp:237]     Train net output #1: loss = 0.0243037 (* 1 = 0.0243037 loss)
I1211 23:08:20.769850 17660 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1211 23:08:28.450388 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:08:28.767431 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.caffemodel
I1211 23:08:28.797430 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.solverstate
I1211 23:08:28.803431 17660 solver.cpp:330] Iteration 108500, Testing net (#0)
I1211 23:08:28.804431 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:08:30.487612 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:08:30.554126 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1211 23:08:30.554126 17660 solver.cpp:397]     Test net output #1: loss = 0.241811 (* 1 = 0.241811 loss)
I1211 23:08:30.629638 17660 solver.cpp:218] Iteration 108500 (10.1429 iter/s, 9.85907s/100 iters), loss = 0.0154812
I1211 23:08:30.629638 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:08:30.629638 17660 solver.cpp:237]     Train net output #1: loss = 0.0154812 (* 1 = 0.0154812 loss)
I1211 23:08:30.629638 17660 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1211 23:08:38.730374 17660 solver.cpp:218] Iteration 108600 (12.3444 iter/s, 8.10083s/100 iters), loss = 0.0192754
I1211 23:08:38.731366 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:08:38.731366 17660 solver.cpp:237]     Train net output #1: loss = 0.0192753 (* 1 = 0.0192753 loss)
I1211 23:08:38.731366 17660 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1211 23:08:46.797304 17660 solver.cpp:218] Iteration 108700 (12.3974 iter/s, 8.06623s/100 iters), loss = 0.0151518
I1211 23:08:46.797304 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:08:46.797304 17660 solver.cpp:237]     Train net output #1: loss = 0.0151518 (* 1 = 0.0151518 loss)
I1211 23:08:46.797304 17660 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1211 23:08:54.889082 17660 solver.cpp:218] Iteration 108800 (12.3602 iter/s, 8.09046s/100 iters), loss = 0.0198057
I1211 23:08:54.889082 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:08:54.889082 17660 solver.cpp:237]     Train net output #1: loss = 0.0198056 (* 1 = 0.0198056 loss)
I1211 23:08:54.889082 17660 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1211 23:09:02.960595 17660 solver.cpp:218] Iteration 108900 (12.3896 iter/s, 8.07131s/100 iters), loss = 0.0112452
I1211 23:09:02.960595 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:09:02.960595 17660 solver.cpp:237]     Train net output #1: loss = 0.0112452 (* 1 = 0.0112452 loss)
I1211 23:09:02.960595 17660 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1211 23:09:10.661911 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:09:10.981963 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.caffemodel
I1211 23:09:11.016963 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.solverstate
I1211 23:09:11.022977 17660 solver.cpp:330] Iteration 109000, Testing net (#0)
I1211 23:09:11.023967 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:09:12.716106 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:09:12.783109 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1211 23:09:12.783109 17660 solver.cpp:397]     Test net output #1: loss = 0.241075 (* 1 = 0.241075 loss)
I1211 23:09:12.860112 17660 solver.cpp:218] Iteration 109000 (10.1024 iter/s, 9.89865s/100 iters), loss = 0.020877
I1211 23:09:12.860112 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:09:12.860112 17660 solver.cpp:237]     Train net output #1: loss = 0.020877 (* 1 = 0.020877 loss)
I1211 23:09:12.860112 17660 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1211 23:09:20.927224 17660 solver.cpp:218] Iteration 109100 (12.3959 iter/s, 8.06719s/100 iters), loss = 0.0518985
I1211 23:09:20.927224 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:09:20.927224 17660 solver.cpp:237]     Train net output #1: loss = 0.0518985 (* 1 = 0.0518985 loss)
I1211 23:09:20.927224 17660 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1211 23:09:29.023403 17660 solver.cpp:218] Iteration 109200 (12.3527 iter/s, 8.09541s/100 iters), loss = 0.0128311
I1211 23:09:29.023403 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:09:29.023403 17660 solver.cpp:237]     Train net output #1: loss = 0.012831 (* 1 = 0.012831 loss)
I1211 23:09:29.023403 17660 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1211 23:09:37.103433 17660 solver.cpp:218] Iteration 109300 (12.3762 iter/s, 8.08s/100 iters), loss = 0.0187537
I1211 23:09:37.104434 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:09:37.104434 17660 solver.cpp:237]     Train net output #1: loss = 0.0187536 (* 1 = 0.0187536 loss)
I1211 23:09:37.104434 17660 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1211 23:09:45.233024 17660 solver.cpp:218] Iteration 109400 (12.3021 iter/s, 8.12867s/100 iters), loss = 0.0135746
I1211 23:09:45.233024 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:09:45.233024 17660 solver.cpp:237]     Train net output #1: loss = 0.0135746 (* 1 = 0.0135746 loss)
I1211 23:09:45.233024 17660 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1211 23:09:52.988191 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:09:53.308301 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.caffemodel
I1211 23:09:53.342303 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.solverstate
I1211 23:09:53.348304 17660 solver.cpp:330] Iteration 109500, Testing net (#0)
I1211 23:09:53.349304 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:09:55.043465 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:09:55.110476 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 23:09:55.110476 17660 solver.cpp:397]     Test net output #1: loss = 0.240337 (* 1 = 0.240337 loss)
I1211 23:09:55.185477 17660 solver.cpp:218] Iteration 109500 (10.0487 iter/s, 9.95156s/100 iters), loss = 0.0156047
I1211 23:09:55.185477 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:09:55.185477 17660 solver.cpp:237]     Train net output #1: loss = 0.0156047 (* 1 = 0.0156047 loss)
I1211 23:09:55.185477 17660 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1211 23:10:03.326360 17660 solver.cpp:218] Iteration 109600 (12.2839 iter/s, 8.14072s/100 iters), loss = 0.0128329
I1211 23:10:03.326360 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:10:03.326360 17660 solver.cpp:237]     Train net output #1: loss = 0.0128329 (* 1 = 0.0128329 loss)
I1211 23:10:03.326360 17660 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1211 23:10:11.464026 17660 solver.cpp:218] Iteration 109700 (12.2897 iter/s, 8.13692s/100 iters), loss = 0.0168554
I1211 23:10:11.464026 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:10:11.464026 17660 solver.cpp:237]     Train net output #1: loss = 0.0168554 (* 1 = 0.0168554 loss)
I1211 23:10:11.464026 17660 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1211 23:10:19.566102 17660 solver.cpp:218] Iteration 109800 (12.3432 iter/s, 8.1016s/100 iters), loss = 0.0157579
I1211 23:10:19.566102 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:10:19.566102 17660 solver.cpp:237]     Train net output #1: loss = 0.0157579 (* 1 = 0.0157579 loss)
I1211 23:10:19.566102 17660 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1211 23:10:27.719560 17660 solver.cpp:218] Iteration 109900 (12.2655 iter/s, 8.15293s/100 iters), loss = 0.014908
I1211 23:10:27.719560 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:10:27.719560 17660 solver.cpp:237]     Train net output #1: loss = 0.014908 (* 1 = 0.014908 loss)
I1211 23:10:27.719560 17660 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1211 23:10:35.387300 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:10:35.707980 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.caffemodel
I1211 23:10:35.749485 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.solverstate
I1211 23:10:35.755486 17660 solver.cpp:330] Iteration 110000, Testing net (#0)
I1211 23:10:35.755486 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:10:37.445026 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:10:37.512032 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 23:10:37.512032 17660 solver.cpp:397]     Test net output #1: loss = 0.243887 (* 1 = 0.243887 loss)
I1211 23:10:37.588575 17660 solver.cpp:218] Iteration 110000 (10.133 iter/s, 9.8687s/100 iters), loss = 0.0139869
I1211 23:10:37.588575 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:10:37.588575 17660 solver.cpp:237]     Train net output #1: loss = 0.0139869 (* 1 = 0.0139869 loss)
I1211 23:10:37.588575 17660 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1211 23:10:45.686810 17660 solver.cpp:218] Iteration 110100 (12.349 iter/s, 8.09783s/100 iters), loss = 0.0108124
I1211 23:10:45.686810 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:10:45.687809 17660 solver.cpp:237]     Train net output #1: loss = 0.0108124 (* 1 = 0.0108124 loss)
I1211 23:10:45.687809 17660 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1211 23:10:53.784454 17660 solver.cpp:218] Iteration 110200 (12.3517 iter/s, 8.09603s/100 iters), loss = 0.0247689
I1211 23:10:53.784454 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:10:53.784454 17660 solver.cpp:237]     Train net output #1: loss = 0.0247689 (* 1 = 0.0247689 loss)
I1211 23:10:53.784454 17660 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1211 23:11:01.903772 17660 solver.cpp:218] Iteration 110300 (12.3169 iter/s, 8.11892s/100 iters), loss = 0.0135894
I1211 23:11:01.903772 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:11:01.903772 17660 solver.cpp:237]     Train net output #1: loss = 0.0135893 (* 1 = 0.0135893 loss)
I1211 23:11:01.903772 17660 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1211 23:11:09.988602 17660 solver.cpp:218] Iteration 110400 (12.3699 iter/s, 8.08414s/100 iters), loss = 0.0290146
I1211 23:11:09.988602 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:11:09.988602 17660 solver.cpp:237]     Train net output #1: loss = 0.0290146 (* 1 = 0.0290146 loss)
I1211 23:11:09.988602 17660 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1211 23:11:17.704672 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:11:18.023747 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.caffemodel
I1211 23:11:18.053746 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.solverstate
I1211 23:11:18.059746 17660 solver.cpp:330] Iteration 110500, Testing net (#0)
I1211 23:11:18.060745 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:11:19.748008 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:11:19.816010 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 23:11:19.816010 17660 solver.cpp:397]     Test net output #1: loss = 0.245259 (* 1 = 0.245259 loss)
I1211 23:11:19.890013 17660 solver.cpp:218] Iteration 110500 (10.0994 iter/s, 9.90154s/100 iters), loss = 0.0265469
I1211 23:11:19.890013 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:11:19.890013 17660 solver.cpp:237]     Train net output #1: loss = 0.0265469 (* 1 = 0.0265469 loss)
I1211 23:11:19.891014 17660 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1211 23:11:27.979285 17660 solver.cpp:218] Iteration 110600 (12.3632 iter/s, 8.0885s/100 iters), loss = 0.0163228
I1211 23:11:27.979285 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:11:27.979285 17660 solver.cpp:237]     Train net output #1: loss = 0.0163228 (* 1 = 0.0163228 loss)
I1211 23:11:27.979285 17660 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1211 23:11:36.094481 17660 solver.cpp:218] Iteration 110700 (12.3246 iter/s, 8.11383s/100 iters), loss = 0.0244898
I1211 23:11:36.094481 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:11:36.094481 17660 solver.cpp:237]     Train net output #1: loss = 0.0244898 (* 1 = 0.0244898 loss)
I1211 23:11:36.094481 17660 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1211 23:11:44.205934 17660 solver.cpp:218] Iteration 110800 (12.3284 iter/s, 8.11134s/100 iters), loss = 0.0172471
I1211 23:11:44.205934 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:11:44.205934 17660 solver.cpp:237]     Train net output #1: loss = 0.0172471 (* 1 = 0.0172471 loss)
I1211 23:11:44.205934 17660 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1211 23:11:52.368062 17660 solver.cpp:218] Iteration 110900 (12.2525 iter/s, 8.16158s/100 iters), loss = 0.0132285
I1211 23:11:52.368062 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:11:52.368062 17660 solver.cpp:237]     Train net output #1: loss = 0.0132284 (* 1 = 0.0132284 loss)
I1211 23:11:52.368062 17660 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1211 23:12:00.123728 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:12:00.448053 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.caffemodel
I1211 23:12:00.487053 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.solverstate
I1211 23:12:00.493052 17660 solver.cpp:330] Iteration 111000, Testing net (#0)
I1211 23:12:00.493052 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:12:02.185973 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:12:02.252997 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1211 23:12:02.252997 17660 solver.cpp:397]     Test net output #1: loss = 0.24459 (* 1 = 0.24459 loss)
I1211 23:12:02.329504 17660 solver.cpp:218] Iteration 111000 (10.0396 iter/s, 9.96052s/100 iters), loss = 0.0180245
I1211 23:12:02.329504 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:12:02.329504 17660 solver.cpp:237]     Train net output #1: loss = 0.0180245 (* 1 = 0.0180245 loss)
I1211 23:12:02.329504 17660 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1211 23:12:10.495673 17660 solver.cpp:218] Iteration 111100 (12.2453 iter/s, 8.16638s/100 iters), loss = 0.0251653
I1211 23:12:10.495673 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:12:10.495673 17660 solver.cpp:237]     Train net output #1: loss = 0.0251653 (* 1 = 0.0251653 loss)
I1211 23:12:10.495673 17660 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1211 23:12:18.675879 17660 solver.cpp:218] Iteration 111200 (12.2259 iter/s, 8.17933s/100 iters), loss = 0.0147661
I1211 23:12:18.675879 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:12:18.675879 17660 solver.cpp:237]     Train net output #1: loss = 0.014766 (* 1 = 0.014766 loss)
I1211 23:12:18.675879 17660 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1211 23:12:26.838310 17660 solver.cpp:218] Iteration 111300 (12.2523 iter/s, 8.16175s/100 iters), loss = 0.0191756
I1211 23:12:26.838310 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:12:26.838809 17660 solver.cpp:237]     Train net output #1: loss = 0.0191756 (* 1 = 0.0191756 loss)
I1211 23:12:26.838809 17660 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1211 23:12:35.073709 17660 solver.cpp:218] Iteration 111400 (12.1437 iter/s, 8.23474s/100 iters), loss = 0.0247466
I1211 23:12:35.073709 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:12:35.073709 17660 solver.cpp:237]     Train net output #1: loss = 0.0247466 (* 1 = 0.0247466 loss)
I1211 23:12:35.073709 17660 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1211 23:12:42.876469 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:12:43.214218 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.caffemodel
I1211 23:12:43.244225 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.solverstate
I1211 23:12:43.250726 17660 solver.cpp:330] Iteration 111500, Testing net (#0)
I1211 23:12:43.251229 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:12:44.970535 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:12:45.039039 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1211 23:12:45.039039 17660 solver.cpp:397]     Test net output #1: loss = 0.244141 (* 1 = 0.244141 loss)
I1211 23:12:45.113076 17660 solver.cpp:218] Iteration 111500 (9.9615 iter/s, 10.0387s/100 iters), loss = 0.0151862
I1211 23:12:45.113076 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:12:45.113076 17660 solver.cpp:237]     Train net output #1: loss = 0.0151862 (* 1 = 0.0151862 loss)
I1211 23:12:45.113076 17660 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1211 23:12:53.335942 17660 solver.cpp:218] Iteration 111600 (12.1623 iter/s, 8.22215s/100 iters), loss = 0.0267207
I1211 23:12:53.335942 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:12:53.335942 17660 solver.cpp:237]     Train net output #1: loss = 0.0267207 (* 1 = 0.0267207 loss)
I1211 23:12:53.335942 17660 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1211 23:13:01.647511 17660 solver.cpp:218] Iteration 111700 (12.0317 iter/s, 8.31139s/100 iters), loss = 0.0355208
I1211 23:13:01.648011 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 23:13:01.648011 17660 solver.cpp:237]     Train net output #1: loss = 0.0355207 (* 1 = 0.0355207 loss)
I1211 23:13:01.648011 17660 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1211 23:13:09.943230 17660 solver.cpp:218] Iteration 111800 (12.0556 iter/s, 8.29488s/100 iters), loss = 0.01277
I1211 23:13:09.943230 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:13:09.943230 17660 solver.cpp:237]     Train net output #1: loss = 0.01277 (* 1 = 0.01277 loss)
I1211 23:13:09.943230 17660 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1211 23:13:18.194921 17660 solver.cpp:218] Iteration 111900 (12.1195 iter/s, 8.25117s/100 iters), loss = 0.0134459
I1211 23:13:18.194921 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:13:18.194921 17660 solver.cpp:237]     Train net output #1: loss = 0.0134458 (* 1 = 0.0134458 loss)
I1211 23:13:18.194921 17660 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1211 23:13:26.039832 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:13:26.358089 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.caffemodel
I1211 23:13:26.386102 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.solverstate
I1211 23:13:26.393103 17660 solver.cpp:330] Iteration 112000, Testing net (#0)
I1211 23:13:26.393103 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:13:28.118597 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:13:28.188611 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1211 23:13:28.188611 17660 solver.cpp:397]     Test net output #1: loss = 0.243882 (* 1 = 0.243882 loss)
I1211 23:13:28.270629 17660 solver.cpp:218] Iteration 112000 (9.9253 iter/s, 10.0753s/100 iters), loss = 0.0169337
I1211 23:13:28.270629 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:13:28.270629 17660 solver.cpp:237]     Train net output #1: loss = 0.0169337 (* 1 = 0.0169337 loss)
I1211 23:13:28.270629 17660 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1211 23:13:36.516631 17660 solver.cpp:218] Iteration 112100 (12.1282 iter/s, 8.24523s/100 iters), loss = 0.0157894
I1211 23:13:36.516631 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:13:36.516631 17660 solver.cpp:237]     Train net output #1: loss = 0.0157894 (* 1 = 0.0157894 loss)
I1211 23:13:36.516631 17660 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1211 23:13:44.596948 17660 solver.cpp:218] Iteration 112200 (12.3759 iter/s, 8.08023s/100 iters), loss = 0.0182929
I1211 23:13:44.596948 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:13:44.596948 17660 solver.cpp:237]     Train net output #1: loss = 0.0182929 (* 1 = 0.0182929 loss)
I1211 23:13:44.596948 17660 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1211 23:13:52.736706 17660 solver.cpp:218] Iteration 112300 (12.2864 iter/s, 8.13908s/100 iters), loss = 0.01264
I1211 23:13:52.736706 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:13:52.736706 17660 solver.cpp:237]     Train net output #1: loss = 0.01264 (* 1 = 0.01264 loss)
I1211 23:13:52.736706 17660 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1211 23:14:00.909057 17660 solver.cpp:218] Iteration 112400 (12.2377 iter/s, 8.17144s/100 iters), loss = 0.0186986
I1211 23:14:00.909057 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:00.909057 17660 solver.cpp:237]     Train net output #1: loss = 0.0186986 (* 1 = 0.0186986 loss)
I1211 23:14:00.909057 17660 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1211 23:14:08.719769 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:14:09.041306 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.caffemodel
I1211 23:14:09.074810 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.solverstate
I1211 23:14:09.081310 17660 solver.cpp:330] Iteration 112500, Testing net (#0)
I1211 23:14:09.081810 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:14:10.778966 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:14:10.844970 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 23:14:10.845970 17660 solver.cpp:397]     Test net output #1: loss = 0.242082 (* 1 = 0.242082 loss)
I1211 23:14:10.919975 17660 solver.cpp:218] Iteration 112500 (9.9891 iter/s, 10.0109s/100 iters), loss = 0.0278854
I1211 23:14:10.919975 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:10.919975 17660 solver.cpp:237]     Train net output #1: loss = 0.0278854 (* 1 = 0.0278854 loss)
I1211 23:14:10.919975 17660 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1211 23:14:19.110007 17660 solver.cpp:218] Iteration 112600 (12.2111 iter/s, 8.18929s/100 iters), loss = 0.0147759
I1211 23:14:19.110007 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:19.110007 17660 solver.cpp:237]     Train net output #1: loss = 0.0147759 (* 1 = 0.0147759 loss)
I1211 23:14:19.110007 17660 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1211 23:14:27.194304 17660 solver.cpp:218] Iteration 112700 (12.3703 iter/s, 8.0839s/100 iters), loss = 0.0152843
I1211 23:14:27.194304 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:27.194304 17660 solver.cpp:237]     Train net output #1: loss = 0.0152843 (* 1 = 0.0152843 loss)
I1211 23:14:27.194304 17660 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1211 23:14:35.322335 17660 solver.cpp:218] Iteration 112800 (12.3041 iter/s, 8.12739s/100 iters), loss = 0.00980547
I1211 23:14:35.322335 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:35.322335 17660 solver.cpp:237]     Train net output #1: loss = 0.00980544 (* 1 = 0.00980544 loss)
I1211 23:14:35.322335 17660 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1211 23:14:43.489068 17660 solver.cpp:218] Iteration 112900 (12.2465 iter/s, 8.16562s/100 iters), loss = 0.0143108
I1211 23:14:43.489068 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:43.489068 17660 solver.cpp:237]     Train net output #1: loss = 0.0143107 (* 1 = 0.0143107 loss)
I1211 23:14:43.489068 17660 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1211 23:14:51.383471 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:14:51.711990 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.caffemodel
I1211 23:14:51.747989 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.solverstate
I1211 23:14:51.754988 17660 solver.cpp:330] Iteration 113000, Testing net (#0)
I1211 23:14:51.754988 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:14:53.493028 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:14:53.560626 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 23:14:53.560626 17660 solver.cpp:397]     Test net output #1: loss = 0.244441 (* 1 = 0.244441 loss)
I1211 23:14:53.635169 17660 solver.cpp:218] Iteration 113000 (9.85594 iter/s, 10.1462s/100 iters), loss = 0.019597
I1211 23:14:53.635169 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:14:53.635169 17660 solver.cpp:237]     Train net output #1: loss = 0.019597 (* 1 = 0.019597 loss)
I1211 23:14:53.635169 17660 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1211 23:15:01.905962 17660 solver.cpp:218] Iteration 113100 (12.0913 iter/s, 8.27042s/100 iters), loss = 0.0193751
I1211 23:15:01.905962 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:01.906956 17660 solver.cpp:237]     Train net output #1: loss = 0.019375 (* 1 = 0.019375 loss)
I1211 23:15:01.906956 17660 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1211 23:15:10.152290 17660 solver.cpp:218] Iteration 113200 (12.1276 iter/s, 8.24568s/100 iters), loss = 0.0151842
I1211 23:15:10.152290 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:10.152290 17660 solver.cpp:237]     Train net output #1: loss = 0.0151842 (* 1 = 0.0151842 loss)
I1211 23:15:10.152290 17660 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1211 23:15:18.224057 17660 solver.cpp:218] Iteration 113300 (12.3908 iter/s, 8.0705s/100 iters), loss = 0.0112319
I1211 23:15:18.224057 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:18.224057 17660 solver.cpp:237]     Train net output #1: loss = 0.0112318 (* 1 = 0.0112318 loss)
I1211 23:15:18.224057 17660 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1211 23:15:26.297847 17660 solver.cpp:218] Iteration 113400 (12.3852 iter/s, 8.07414s/100 iters), loss = 0.0153661
I1211 23:15:26.298842 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:26.298842 17660 solver.cpp:237]     Train net output #1: loss = 0.015366 (* 1 = 0.015366 loss)
I1211 23:15:26.298842 17660 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1211 23:15:33.962664 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:15:34.283421 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.caffemodel
I1211 23:15:34.348419 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.solverstate
I1211 23:15:34.354423 17660 solver.cpp:330] Iteration 113500, Testing net (#0)
I1211 23:15:34.354423 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:15:36.055320 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:15:36.121330 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9357
I1211 23:15:36.121330 17660 solver.cpp:397]     Test net output #1: loss = 0.24382 (* 1 = 0.24382 loss)
I1211 23:15:36.196341 17660 solver.cpp:218] Iteration 113500 (10.1038 iter/s, 9.8973s/100 iters), loss = 0.0138936
I1211 23:15:36.196341 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:36.196341 17660 solver.cpp:237]     Train net output #1: loss = 0.0138935 (* 1 = 0.0138935 loss)
I1211 23:15:36.196341 17660 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1211 23:15:44.308864 17660 solver.cpp:218] Iteration 113600 (12.3279 iter/s, 8.11168s/100 iters), loss = 0.0148132
I1211 23:15:44.308864 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:44.308864 17660 solver.cpp:237]     Train net output #1: loss = 0.0148132 (* 1 = 0.0148132 loss)
I1211 23:15:44.308864 17660 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1211 23:15:52.530642 17660 solver.cpp:218] Iteration 113700 (12.163 iter/s, 8.22167s/100 iters), loss = 0.022166
I1211 23:15:52.530642 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:15:52.530642 17660 solver.cpp:237]     Train net output #1: loss = 0.0221659 (* 1 = 0.0221659 loss)
I1211 23:15:52.530642 17660 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1211 23:16:00.806895 17660 solver.cpp:218] Iteration 113800 (12.0842 iter/s, 8.27528s/100 iters), loss = 0.0198075
I1211 23:16:00.806895 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:16:00.806895 17660 solver.cpp:237]     Train net output #1: loss = 0.0198074 (* 1 = 0.0198074 loss)
I1211 23:16:00.806895 17660 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1211 23:16:08.933889 17660 solver.cpp:218] Iteration 113900 (12.3048 iter/s, 8.12691s/100 iters), loss = 0.0139733
I1211 23:16:08.933889 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:16:08.933889 17660 solver.cpp:237]     Train net output #1: loss = 0.0139732 (* 1 = 0.0139732 loss)
I1211 23:16:08.933889 17660 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1211 23:16:16.699913 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:16:17.035450 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.caffemodel
I1211 23:16:17.092463 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.solverstate
I1211 23:16:17.100463 17660 solver.cpp:330] Iteration 114000, Testing net (#0)
I1211 23:16:17.101465 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:16:18.822269 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:16:18.889757 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1211 23:16:18.889757 17660 solver.cpp:397]     Test net output #1: loss = 0.25281 (* 1 = 0.25281 loss)
I1211 23:16:18.964275 17660 solver.cpp:218] Iteration 114000 (9.96998 iter/s, 10.0301s/100 iters), loss = 0.0184777
I1211 23:16:18.964275 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:16:18.964275 17660 solver.cpp:237]     Train net output #1: loss = 0.0184776 (* 1 = 0.0184776 loss)
I1211 23:16:18.964275 17660 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1211 23:16:27.093063 17660 solver.cpp:218] Iteration 114100 (12.3036 iter/s, 8.12772s/100 iters), loss = 0.0300254
I1211 23:16:27.093063 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:16:27.093063 17660 solver.cpp:237]     Train net output #1: loss = 0.0300254 (* 1 = 0.0300254 loss)
I1211 23:16:27.093063 17660 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1211 23:16:35.206779 17660 solver.cpp:218] Iteration 114200 (12.3251 iter/s, 8.1135s/100 iters), loss = 0.0620555
I1211 23:16:35.206779 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:16:35.206779 17660 solver.cpp:237]     Train net output #1: loss = 0.0620554 (* 1 = 0.0620554 loss)
I1211 23:16:35.206779 17660 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1211 23:16:43.380713 17660 solver.cpp:218] Iteration 114300 (12.2357 iter/s, 8.17277s/100 iters), loss = 0.0161152
I1211 23:16:43.380713 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:16:43.380713 17660 solver.cpp:237]     Train net output #1: loss = 0.0161152 (* 1 = 0.0161152 loss)
I1211 23:16:43.380713 17660 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1211 23:16:51.637614 17660 solver.cpp:218] Iteration 114400 (12.1113 iter/s, 8.25673s/100 iters), loss = 0.014474
I1211 23:16:51.637614 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:16:51.637614 17660 solver.cpp:237]     Train net output #1: loss = 0.0144739 (* 1 = 0.0144739 loss)
I1211 23:16:51.637614 17660 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1211 23:16:59.370764 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:16:59.687902 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.caffemodel
I1211 23:16:59.722405 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.solverstate
I1211 23:16:59.757403 17660 solver.cpp:330] Iteration 114500, Testing net (#0)
I1211 23:16:59.757403 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:17:01.476609 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:17:01.545624 17660 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1211 23:17:01.546624 17660 solver.cpp:397]     Test net output #1: loss = 0.242426 (* 1 = 0.242426 loss)
I1211 23:17:01.622648 17660 solver.cpp:218] Iteration 114500 (10.0156 iter/s, 9.98445s/100 iters), loss = 0.0184919
I1211 23:17:01.622648 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:17:01.622648 17660 solver.cpp:237]     Train net output #1: loss = 0.0184918 (* 1 = 0.0184918 loss)
I1211 23:17:01.622648 17660 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1211 23:17:09.777117 17660 solver.cpp:218] Iteration 114600 (12.2638 iter/s, 8.1541s/100 iters), loss = 0.0197451
I1211 23:17:09.777117 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:17:09.777117 17660 solver.cpp:237]     Train net output #1: loss = 0.019745 (* 1 = 0.019745 loss)
I1211 23:17:09.777117 17660 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1211 23:17:17.929275 17660 solver.cpp:218] Iteration 114700 (12.2675 iter/s, 8.15164s/100 iters), loss = 0.0415232
I1211 23:17:17.929275 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:17:17.929275 17660 solver.cpp:237]     Train net output #1: loss = 0.0415232 (* 1 = 0.0415232 loss)
I1211 23:17:17.929275 17660 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1211 23:17:26.005764 17660 solver.cpp:218] Iteration 114800 (12.3832 iter/s, 8.07543s/100 iters), loss = 0.0106701
I1211 23:17:26.005764 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:17:26.005764 17660 solver.cpp:237]     Train net output #1: loss = 0.01067 (* 1 = 0.01067 loss)
I1211 23:17:26.005764 17660 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1211 23:17:34.357080 17660 solver.cpp:218] Iteration 114900 (11.9737 iter/s, 8.35163s/100 iters), loss = 0.0219084
I1211 23:17:34.358081 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:17:34.358081 17660 solver.cpp:237]     Train net output #1: loss = 0.0219084 (* 1 = 0.0219084 loss)
I1211 23:17:34.358081 17660 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1211 23:17:42.118227 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:17:42.435775 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.caffemodel
I1211 23:17:42.488773 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.solverstate
I1211 23:17:42.495774 17660 solver.cpp:330] Iteration 115000, Testing net (#0)
I1211 23:17:42.495774 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:17:44.182981 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:17:44.249989 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 23:17:44.249989 17660 solver.cpp:397]     Test net output #1: loss = 0.245625 (* 1 = 0.245625 loss)
I1211 23:17:44.324993 17660 solver.cpp:218] Iteration 115000 (10.0337 iter/s, 9.96641s/100 iters), loss = 0.0218989
I1211 23:17:44.324993 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:17:44.324993 17660 solver.cpp:237]     Train net output #1: loss = 0.0218989 (* 1 = 0.0218989 loss)
I1211 23:17:44.324993 17660 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1211 23:17:52.404295 17660 solver.cpp:218] Iteration 115100 (12.3774 iter/s, 8.07927s/100 iters), loss = 0.0166833
I1211 23:17:52.404295 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:17:52.404295 17660 solver.cpp:237]     Train net output #1: loss = 0.0166833 (* 1 = 0.0166833 loss)
I1211 23:17:52.404295 17660 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1211 23:18:00.601299 17660 solver.cpp:218] Iteration 115200 (12.2005 iter/s, 8.19641s/100 iters), loss = 0.011192
I1211 23:18:00.601299 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:18:00.601299 17660 solver.cpp:237]     Train net output #1: loss = 0.0111919 (* 1 = 0.0111919 loss)
I1211 23:18:00.601299 17660 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1211 23:18:08.692582 17660 solver.cpp:218] Iteration 115300 (12.3603 iter/s, 8.09044s/100 iters), loss = 0.0111158
I1211 23:18:08.692582 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:18:08.692582 17660 solver.cpp:237]     Train net output #1: loss = 0.0111157 (* 1 = 0.0111157 loss)
I1211 23:18:08.692582 17660 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1211 23:18:16.812980 17660 solver.cpp:218] Iteration 115400 (12.3159 iter/s, 8.1196s/100 iters), loss = 0.0176363
I1211 23:18:16.812980 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:18:16.812980 17660 solver.cpp:237]     Train net output #1: loss = 0.0176362 (* 1 = 0.0176362 loss)
I1211 23:18:16.812980 17660 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1211 23:18:24.509727 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:18:24.828794 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.caffemodel
I1211 23:18:24.867533 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.solverstate
I1211 23:18:24.873517 17660 solver.cpp:330] Iteration 115500, Testing net (#0)
I1211 23:18:24.873517 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:18:26.572543 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:18:26.643050 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9366
I1211 23:18:26.643050 17660 solver.cpp:397]     Test net output #1: loss = 0.240449 (* 1 = 0.240449 loss)
I1211 23:18:26.723054 17660 solver.cpp:218] Iteration 115500 (10.0907 iter/s, 9.91012s/100 iters), loss = 0.0281501
I1211 23:18:26.723054 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:18:26.723054 17660 solver.cpp:237]     Train net output #1: loss = 0.02815 (* 1 = 0.02815 loss)
I1211 23:18:26.723054 17660 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1211 23:18:34.823194 17660 solver.cpp:218] Iteration 115600 (12.3475 iter/s, 8.09883s/100 iters), loss = 0.0400561
I1211 23:18:34.823194 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:18:34.823194 17660 solver.cpp:237]     Train net output #1: loss = 0.040056 (* 1 = 0.040056 loss)
I1211 23:18:34.823194 17660 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1211 23:18:42.932059 17660 solver.cpp:218] Iteration 115700 (12.3317 iter/s, 8.10917s/100 iters), loss = 0.0213104
I1211 23:18:42.932059 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:18:42.932059 17660 solver.cpp:237]     Train net output #1: loss = 0.0213103 (* 1 = 0.0213103 loss)
I1211 23:18:42.932059 17660 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1211 23:18:51.025889 17660 solver.cpp:218] Iteration 115800 (12.3568 iter/s, 8.09269s/100 iters), loss = 0.0149663
I1211 23:18:51.025889 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:18:51.025889 17660 solver.cpp:237]     Train net output #1: loss = 0.0149662 (* 1 = 0.0149662 loss)
I1211 23:18:51.025889 17660 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1211 23:18:59.208741 17660 solver.cpp:218] Iteration 115900 (12.2216 iter/s, 8.18224s/100 iters), loss = 0.0142497
I1211 23:18:59.208741 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:18:59.208741 17660 solver.cpp:237]     Train net output #1: loss = 0.0142497 (* 1 = 0.0142497 loss)
I1211 23:18:59.208741 17660 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1211 23:19:06.932207 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:19:07.259256 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.caffemodel
I1211 23:19:07.317257 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.solverstate
I1211 23:19:07.324259 17660 solver.cpp:330] Iteration 116000, Testing net (#0)
I1211 23:19:07.324259 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:19:09.021417 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:19:09.087424 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1211 23:19:09.087424 17660 solver.cpp:397]     Test net output #1: loss = 0.244477 (* 1 = 0.244477 loss)
I1211 23:19:09.164448 17660 solver.cpp:218] Iteration 116000 (10.0446 iter/s, 9.95562s/100 iters), loss = 0.0143427
I1211 23:19:09.164448 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:19:09.164448 17660 solver.cpp:237]     Train net output #1: loss = 0.0143426 (* 1 = 0.0143426 loss)
I1211 23:19:09.164448 17660 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1211 23:19:17.312255 17660 solver.cpp:218] Iteration 116100 (12.275 iter/s, 8.14664s/100 iters), loss = 0.0113116
I1211 23:19:17.312255 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:19:17.312255 17660 solver.cpp:237]     Train net output #1: loss = 0.0113116 (* 1 = 0.0113116 loss)
I1211 23:19:17.312255 17660 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1211 23:19:25.471104 17660 solver.cpp:218] Iteration 116200 (12.2568 iter/s, 8.15874s/100 iters), loss = 0.0164491
I1211 23:19:25.471104 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:19:25.471104 17660 solver.cpp:237]     Train net output #1: loss = 0.0164491 (* 1 = 0.0164491 loss)
I1211 23:19:25.471104 17660 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1211 23:19:33.581233 17660 solver.cpp:218] Iteration 116300 (12.3307 iter/s, 8.10986s/100 iters), loss = 0.0211697
I1211 23:19:33.581233 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:19:33.581233 17660 solver.cpp:237]     Train net output #1: loss = 0.0211697 (* 1 = 0.0211697 loss)
I1211 23:19:33.581233 17660 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1211 23:19:41.713253 17660 solver.cpp:218] Iteration 116400 (12.2979 iter/s, 8.13148s/100 iters), loss = 0.0140456
I1211 23:19:41.713253 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:19:41.713253 17660 solver.cpp:237]     Train net output #1: loss = 0.0140455 (* 1 = 0.0140455 loss)
I1211 23:19:41.713253 17660 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1211 23:19:49.494849 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:19:49.823982 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.caffemodel
I1211 23:19:49.868988 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.solverstate
I1211 23:19:49.874987 17660 solver.cpp:330] Iteration 116500, Testing net (#0)
I1211 23:19:49.875488 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:19:51.601624 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:19:51.670138 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 23:19:51.670138 17660 solver.cpp:397]     Test net output #1: loss = 0.249248 (* 1 = 0.249248 loss)
I1211 23:19:51.748704 17660 solver.cpp:218] Iteration 116500 (9.96543 iter/s, 10.0347s/100 iters), loss = 0.0172543
I1211 23:19:51.748704 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:19:51.748704 17660 solver.cpp:237]     Train net output #1: loss = 0.0172543 (* 1 = 0.0172543 loss)
I1211 23:19:51.748704 17660 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1211 23:20:00.056360 17660 solver.cpp:218] Iteration 116600 (12.0387 iter/s, 8.30656s/100 iters), loss = 0.0153523
I1211 23:20:00.056360 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:00.056360 17660 solver.cpp:237]     Train net output #1: loss = 0.0153522 (* 1 = 0.0153522 loss)
I1211 23:20:00.056360 17660 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1211 23:20:08.231969 17660 solver.cpp:218] Iteration 116700 (12.2311 iter/s, 8.17589s/100 iters), loss = 0.018632
I1211 23:20:08.231969 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:08.232971 17660 solver.cpp:237]     Train net output #1: loss = 0.018632 (* 1 = 0.018632 loss)
I1211 23:20:08.232971 17660 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1211 23:20:16.451833 17660 solver.cpp:218] Iteration 116800 (12.1667 iter/s, 8.21913s/100 iters), loss = 0.0153088
I1211 23:20:16.451833 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:16.451833 17660 solver.cpp:237]     Train net output #1: loss = 0.0153087 (* 1 = 0.0153087 loss)
I1211 23:20:16.451833 17660 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1211 23:20:24.610127 17660 solver.cpp:218] Iteration 116900 (12.2581 iter/s, 8.15786s/100 iters), loss = 0.0102488
I1211 23:20:24.610127 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:24.610127 17660 solver.cpp:237]     Train net output #1: loss = 0.0102487 (* 1 = 0.0102487 loss)
I1211 23:20:24.610127 17660 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1211 23:20:32.341403 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:20:32.664125 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.caffemodel
I1211 23:20:32.721199 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.solverstate
I1211 23:20:32.728199 17660 solver.cpp:330] Iteration 117000, Testing net (#0)
I1211 23:20:32.728199 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:20:34.417347 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:20:34.484853 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 23:20:34.484853 17660 solver.cpp:397]     Test net output #1: loss = 0.248334 (* 1 = 0.248334 loss)
I1211 23:20:34.558460 17660 solver.cpp:218] Iteration 117000 (10.0527 iter/s, 9.9476s/100 iters), loss = 0.0259801
I1211 23:20:34.558460 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:34.558460 17660 solver.cpp:237]     Train net output #1: loss = 0.02598 (* 1 = 0.02598 loss)
I1211 23:20:34.558460 17660 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1211 23:20:42.669481 17660 solver.cpp:218] Iteration 117100 (12.3303 iter/s, 8.11009s/100 iters), loss = 0.0205913
I1211 23:20:42.669481 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:42.669481 17660 solver.cpp:237]     Train net output #1: loss = 0.0205912 (* 1 = 0.0205912 loss)
I1211 23:20:42.669481 17660 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1211 23:20:50.751299 17660 solver.cpp:218] Iteration 117200 (12.3743 iter/s, 8.08126s/100 iters), loss = 0.0151713
I1211 23:20:50.751299 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:50.751299 17660 solver.cpp:237]     Train net output #1: loss = 0.0151712 (* 1 = 0.0151712 loss)
I1211 23:20:50.751299 17660 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1211 23:20:58.863389 17660 solver.cpp:218] Iteration 117300 (12.3284 iter/s, 8.11136s/100 iters), loss = 0.0111645
I1211 23:20:58.863389 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:20:58.863389 17660 solver.cpp:237]     Train net output #1: loss = 0.0111644 (* 1 = 0.0111644 loss)
I1211 23:20:58.863389 17660 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1211 23:21:07.090131 17660 solver.cpp:218] Iteration 117400 (12.1553 iter/s, 8.22684s/100 iters), loss = 0.0160355
I1211 23:21:07.090131 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:21:07.090131 17660 solver.cpp:237]     Train net output #1: loss = 0.0160354 (* 1 = 0.0160354 loss)
I1211 23:21:07.090131 17660 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1211 23:21:15.015904 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:21:15.344830 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.caffemodel
I1211 23:21:15.374830 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.solverstate
I1211 23:21:15.381831 17660 solver.cpp:330] Iteration 117500, Testing net (#0)
I1211 23:21:15.381831 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:21:17.079082 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:21:17.145709 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1211 23:21:17.145709 17660 solver.cpp:397]     Test net output #1: loss = 0.245054 (* 1 = 0.245054 loss)
I1211 23:21:17.221825 17660 solver.cpp:218] Iteration 117500 (9.87063 iter/s, 10.1311s/100 iters), loss = 0.0168293
I1211 23:21:17.221825 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:21:17.222827 17660 solver.cpp:237]     Train net output #1: loss = 0.0168292 (* 1 = 0.0168292 loss)
I1211 23:21:17.222827 17660 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1211 23:21:25.345372 17660 solver.cpp:218] Iteration 117600 (12.3117 iter/s, 8.12239s/100 iters), loss = 0.0119071
I1211 23:21:25.345372 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:21:25.345372 17660 solver.cpp:237]     Train net output #1: loss = 0.011907 (* 1 = 0.011907 loss)
I1211 23:21:25.345372 17660 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1211 23:21:33.504194 17660 solver.cpp:218] Iteration 117700 (12.258 iter/s, 8.15795s/100 iters), loss = 0.0187123
I1211 23:21:33.504194 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:21:33.504194 17660 solver.cpp:237]     Train net output #1: loss = 0.0187122 (* 1 = 0.0187122 loss)
I1211 23:21:33.504194 17660 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1211 23:21:41.679695 17660 solver.cpp:218] Iteration 117800 (12.2319 iter/s, 8.17532s/100 iters), loss = 0.0260172
I1211 23:21:41.679695 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:21:41.679695 17660 solver.cpp:237]     Train net output #1: loss = 0.0260171 (* 1 = 0.0260171 loss)
I1211 23:21:41.679695 17660 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1211 23:21:49.791759 17660 solver.cpp:218] Iteration 117900 (12.3284 iter/s, 8.11133s/100 iters), loss = 0.0113262
I1211 23:21:49.791759 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:21:49.791759 17660 solver.cpp:237]     Train net output #1: loss = 0.0113261 (* 1 = 0.0113261 loss)
I1211 23:21:49.791759 17660 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1211 23:21:57.504417 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:21:57.820969 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.caffemodel
I1211 23:21:57.873474 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.solverstate
I1211 23:21:57.879474 17660 solver.cpp:330] Iteration 118000, Testing net (#0)
I1211 23:21:57.879474 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:21:59.574671 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:21:59.640678 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 23:21:59.640678 17660 solver.cpp:397]     Test net output #1: loss = 0.243392 (* 1 = 0.243392 loss)
I1211 23:21:59.718183 17660 solver.cpp:218] Iteration 118000 (10.0747 iter/s, 9.92585s/100 iters), loss = 0.0115757
I1211 23:21:59.718183 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:21:59.718183 17660 solver.cpp:237]     Train net output #1: loss = 0.0115757 (* 1 = 0.0115757 loss)
I1211 23:21:59.718183 17660 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1211 23:22:07.846560 17660 solver.cpp:218] Iteration 118100 (12.3022 iter/s, 8.12862s/100 iters), loss = 0.0181972
I1211 23:22:07.846560 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:07.847555 17660 solver.cpp:237]     Train net output #1: loss = 0.0181971 (* 1 = 0.0181971 loss)
I1211 23:22:07.847555 17660 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1211 23:22:15.934274 17660 solver.cpp:218] Iteration 118200 (12.3667 iter/s, 8.08621s/100 iters), loss = 0.0132912
I1211 23:22:15.934274 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:15.934274 17660 solver.cpp:237]     Train net output #1: loss = 0.0132911 (* 1 = 0.0132911 loss)
I1211 23:22:15.934274 17660 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1211 23:22:23.994300 17660 solver.cpp:218] Iteration 118300 (12.4074 iter/s, 8.05968s/100 iters), loss = 0.0100125
I1211 23:22:23.994300 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:23.994300 17660 solver.cpp:237]     Train net output #1: loss = 0.0100124 (* 1 = 0.0100124 loss)
I1211 23:22:23.994300 17660 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1211 23:22:32.054397 17660 solver.cpp:218] Iteration 118400 (12.4075 iter/s, 8.05963s/100 iters), loss = 0.0155677
I1211 23:22:32.054397 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:32.054397 17660 solver.cpp:237]     Train net output #1: loss = 0.0155677 (* 1 = 0.0155677 loss)
I1211 23:22:32.054397 17660 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1211 23:22:39.829695 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:22:40.147641 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.caffemodel
I1211 23:22:40.184636 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.solverstate
I1211 23:22:40.191637 17660 solver.cpp:330] Iteration 118500, Testing net (#0)
I1211 23:22:40.191637 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:22:41.884346 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:22:41.953358 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 23:22:41.953358 17660 solver.cpp:397]     Test net output #1: loss = 0.247594 (* 1 = 0.247594 loss)
I1211 23:22:42.031864 17660 solver.cpp:218] Iteration 118500 (10.023 iter/s, 9.97706s/100 iters), loss = 0.0162483
I1211 23:22:42.032366 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:42.032366 17660 solver.cpp:237]     Train net output #1: loss = 0.0162483 (* 1 = 0.0162483 loss)
I1211 23:22:42.032366 17660 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1211 23:22:50.259914 17660 solver.cpp:218] Iteration 118600 (12.1536 iter/s, 8.22803s/100 iters), loss = 0.0127849
I1211 23:22:50.260915 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:50.260915 17660 solver.cpp:237]     Train net output #1: loss = 0.0127848 (* 1 = 0.0127848 loss)
I1211 23:22:50.260915 17660 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1211 23:22:58.480252 17660 solver.cpp:218] Iteration 118700 (12.1658 iter/s, 8.21974s/100 iters), loss = 0.0238341
I1211 23:22:58.480252 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:22:58.481253 17660 solver.cpp:237]     Train net output #1: loss = 0.023834 (* 1 = 0.023834 loss)
I1211 23:22:58.481253 17660 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1211 23:23:06.602416 17660 solver.cpp:218] Iteration 118800 (12.3129 iter/s, 8.12156s/100 iters), loss = 0.0113438
I1211 23:23:06.602416 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:06.602416 17660 solver.cpp:237]     Train net output #1: loss = 0.0113437 (* 1 = 0.0113437 loss)
I1211 23:23:06.602416 17660 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1211 23:23:14.722303 17660 solver.cpp:218] Iteration 118900 (12.3171 iter/s, 8.11882s/100 iters), loss = 0.00892705
I1211 23:23:14.722303 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:14.722303 17660 solver.cpp:237]     Train net output #1: loss = 0.00892696 (* 1 = 0.00892696 loss)
I1211 23:23:14.722303 17660 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1211 23:23:22.467941 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:23:22.788969 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.caffemodel
I1211 23:23:22.850971 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.solverstate
I1211 23:23:22.857980 17660 solver.cpp:330] Iteration 119000, Testing net (#0)
I1211 23:23:22.857980 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:23:24.562168 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:23:24.629170 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1211 23:23:24.629170 17660 solver.cpp:397]     Test net output #1: loss = 0.248576 (* 1 = 0.248576 loss)
I1211 23:23:24.705178 17660 solver.cpp:218] Iteration 119000 (10.0178 iter/s, 9.98221s/100 iters), loss = 0.0156346
I1211 23:23:24.705178 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:24.705178 17660 solver.cpp:237]     Train net output #1: loss = 0.0156346 (* 1 = 0.0156346 loss)
I1211 23:23:24.705178 17660 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1211 23:23:32.785706 17660 solver.cpp:218] Iteration 119100 (12.3758 iter/s, 8.08032s/100 iters), loss = 0.0156792
I1211 23:23:32.785706 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:32.785706 17660 solver.cpp:237]     Train net output #1: loss = 0.0156791 (* 1 = 0.0156791 loss)
I1211 23:23:32.785706 17660 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1211 23:23:40.890014 17660 solver.cpp:218] Iteration 119200 (12.3407 iter/s, 8.10329s/100 iters), loss = 0.0207285
I1211 23:23:40.890014 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:40.890014 17660 solver.cpp:237]     Train net output #1: loss = 0.0207284 (* 1 = 0.0207284 loss)
I1211 23:23:40.890014 17660 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1211 23:23:48.990088 17660 solver.cpp:218] Iteration 119300 (12.346 iter/s, 8.09977s/100 iters), loss = 0.0144946
I1211 23:23:48.990088 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:48.990088 17660 solver.cpp:237]     Train net output #1: loss = 0.0144945 (* 1 = 0.0144945 loss)
I1211 23:23:48.990088 17660 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1211 23:23:57.075981 17660 solver.cpp:218] Iteration 119400 (12.3686 iter/s, 8.085s/100 iters), loss = 0.0131903
I1211 23:23:57.075981 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:23:57.075981 17660 solver.cpp:237]     Train net output #1: loss = 0.0131902 (* 1 = 0.0131902 loss)
I1211 23:23:57.075981 17660 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1211 23:24:04.832621 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:24:05.156644 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.caffemodel
I1211 23:24:05.195655 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.solverstate
I1211 23:24:05.201655 17660 solver.cpp:330] Iteration 119500, Testing net (#0)
I1211 23:24:05.201655 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:24:06.911818 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:24:06.980324 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1211 23:24:06.980324 17660 solver.cpp:397]     Test net output #1: loss = 0.250656 (* 1 = 0.250656 loss)
I1211 23:24:07.054826 17660 solver.cpp:218] Iteration 119500 (10.0213 iter/s, 9.9787s/100 iters), loss = 0.0163372
I1211 23:24:07.054826 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:24:07.054826 17660 solver.cpp:237]     Train net output #1: loss = 0.0163371 (* 1 = 0.0163371 loss)
I1211 23:24:07.054826 17660 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1211 23:24:15.328577 17660 solver.cpp:218] Iteration 119600 (12.0871 iter/s, 8.27328s/100 iters), loss = 0.0131049
I1211 23:24:15.328577 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:24:15.328577 17660 solver.cpp:237]     Train net output #1: loss = 0.0131048 (* 1 = 0.0131048 loss)
I1211 23:24:15.328577 17660 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1211 23:24:23.625085 17660 solver.cpp:218] Iteration 119700 (12.0537 iter/s, 8.29619s/100 iters), loss = 0.0178726
I1211 23:24:23.625085 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:24:23.625085 17660 solver.cpp:237]     Train net output #1: loss = 0.0178725 (* 1 = 0.0178725 loss)
I1211 23:24:23.625085 17660 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1211 23:24:31.803901 17660 solver.cpp:218] Iteration 119800 (12.2275 iter/s, 8.17831s/100 iters), loss = 0.0359683
I1211 23:24:31.803901 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:24:31.803901 17660 solver.cpp:237]     Train net output #1: loss = 0.0359682 (* 1 = 0.0359682 loss)
I1211 23:24:31.803901 17660 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1211 23:24:39.911309 17660 solver.cpp:218] Iteration 119900 (12.3361 iter/s, 8.10632s/100 iters), loss = 0.0195565
I1211 23:24:39.911309 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:24:39.911309 17660 solver.cpp:237]     Train net output #1: loss = 0.0195564 (* 1 = 0.0195564 loss)
I1211 23:24:39.911309 17660 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1211 23:24:47.857616 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:24:48.179155 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.caffemodel
I1211 23:24:48.234359 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.solverstate
I1211 23:24:48.240351 17660 solver.cpp:330] Iteration 120000, Testing net (#0)
I1211 23:24:48.241351 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:24:49.923687 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:24:49.991705 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 23:24:49.991705 17660 solver.cpp:397]     Test net output #1: loss = 0.254013 (* 1 = 0.254013 loss)
I1211 23:24:50.066217 17660 solver.cpp:218] Iteration 120000 (9.84769 iter/s, 10.1547s/100 iters), loss = 0.0206498
I1211 23:24:50.066217 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:24:50.066217 17660 solver.cpp:237]     Train net output #1: loss = 0.0206497 (* 1 = 0.0206497 loss)
I1211 23:24:50.066217 17660 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1211 23:24:58.310205 17660 solver.cpp:218] Iteration 120100 (12.1306 iter/s, 8.2436s/100 iters), loss = 0.0330254
I1211 23:24:58.310205 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:24:58.310205 17660 solver.cpp:237]     Train net output #1: loss = 0.0330253 (* 1 = 0.0330253 loss)
I1211 23:24:58.310205 17660 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1211 23:25:06.542706 17660 solver.cpp:218] Iteration 120200 (12.1478 iter/s, 8.23196s/100 iters), loss = 0.0151279
I1211 23:25:06.542706 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:25:06.542706 17660 solver.cpp:237]     Train net output #1: loss = 0.0151278 (* 1 = 0.0151278 loss)
I1211 23:25:06.542706 17660 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1211 23:25:14.781282 17660 solver.cpp:218] Iteration 120300 (12.1398 iter/s, 8.23737s/100 iters), loss = 0.0128441
I1211 23:25:14.781282 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:25:14.781282 17660 solver.cpp:237]     Train net output #1: loss = 0.012844 (* 1 = 0.012844 loss)
I1211 23:25:14.781282 17660 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1211 23:25:22.909634 17660 solver.cpp:218] Iteration 120400 (12.3025 iter/s, 8.12845s/100 iters), loss = 0.0128635
I1211 23:25:22.909634 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:25:22.909634 17660 solver.cpp:237]     Train net output #1: loss = 0.0128634 (* 1 = 0.0128634 loss)
I1211 23:25:22.909634 17660 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1211 23:25:30.742305 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:25:31.076287 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.caffemodel
I1211 23:25:31.114825 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.solverstate
I1211 23:25:31.120831 17660 solver.cpp:330] Iteration 120500, Testing net (#0)
I1211 23:25:31.121829 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:25:32.840164 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:25:32.906167 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 23:25:32.906167 17660 solver.cpp:397]     Test net output #1: loss = 0.250962 (* 1 = 0.250962 loss)
I1211 23:25:32.983172 17660 solver.cpp:218] Iteration 120500 (9.9283 iter/s, 10.0722s/100 iters), loss = 0.0149276
I1211 23:25:32.983172 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:25:32.983172 17660 solver.cpp:237]     Train net output #1: loss = 0.0149275 (* 1 = 0.0149275 loss)
I1211 23:25:32.983172 17660 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1211 23:25:41.251363 17660 solver.cpp:218] Iteration 120600 (12.0941 iter/s, 8.26847s/100 iters), loss = 0.0298272
I1211 23:25:41.251363 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:25:41.252364 17660 solver.cpp:237]     Train net output #1: loss = 0.0298271 (* 1 = 0.0298271 loss)
I1211 23:25:41.252364 17660 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1211 23:25:49.493111 17660 solver.cpp:218] Iteration 120700 (12.1353 iter/s, 8.24045s/100 iters), loss = 0.0405351
I1211 23:25:49.493111 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:25:49.493111 17660 solver.cpp:237]     Train net output #1: loss = 0.040535 (* 1 = 0.040535 loss)
I1211 23:25:49.493111 17660 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1211 23:25:57.640915 17660 solver.cpp:218] Iteration 120800 (12.2735 iter/s, 8.14765s/100 iters), loss = 0.00957485
I1211 23:25:57.640915 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:25:57.640915 17660 solver.cpp:237]     Train net output #1: loss = 0.00957475 (* 1 = 0.00957475 loss)
I1211 23:25:57.641912 17660 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1211 23:26:05.834089 17660 solver.cpp:218] Iteration 120900 (12.2066 iter/s, 8.19226s/100 iters), loss = 0.0195579
I1211 23:26:05.834089 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:26:05.834089 17660 solver.cpp:237]     Train net output #1: loss = 0.0195578 (* 1 = 0.0195578 loss)
I1211 23:26:05.834089 17660 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1211 23:26:13.609880 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:26:13.932947 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.caffemodel
I1211 23:26:13.988945 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.solverstate
I1211 23:26:13.994946 17660 solver.cpp:330] Iteration 121000, Testing net (#0)
I1211 23:26:13.995946 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:26:15.690018 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:26:15.758030 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 23:26:15.758030 17660 solver.cpp:397]     Test net output #1: loss = 0.251013 (* 1 = 0.251013 loss)
I1211 23:26:15.832037 17660 solver.cpp:218] Iteration 121000 (10.0021 iter/s, 9.99787s/100 iters), loss = 0.0356419
I1211 23:26:15.833037 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:26:15.833037 17660 solver.cpp:237]     Train net output #1: loss = 0.0356418 (* 1 = 0.0356418 loss)
I1211 23:26:15.833037 17660 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1211 23:26:23.968894 17660 solver.cpp:218] Iteration 121100 (12.2917 iter/s, 8.13557s/100 iters), loss = 0.0136187
I1211 23:26:23.968894 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:26:23.968894 17660 solver.cpp:237]     Train net output #1: loss = 0.0136186 (* 1 = 0.0136186 loss)
I1211 23:26:23.968894 17660 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1211 23:26:32.028611 17660 solver.cpp:218] Iteration 121200 (12.408 iter/s, 8.05935s/100 iters), loss = 0.0304502
I1211 23:26:32.028611 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:26:32.028611 17660 solver.cpp:237]     Train net output #1: loss = 0.0304501 (* 1 = 0.0304501 loss)
I1211 23:26:32.028611 17660 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1211 23:26:40.108724 17660 solver.cpp:218] Iteration 121300 (12.3773 iter/s, 8.07929s/100 iters), loss = 0.0117869
I1211 23:26:40.108724 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:26:40.108724 17660 solver.cpp:237]     Train net output #1: loss = 0.0117868 (* 1 = 0.0117868 loss)
I1211 23:26:40.108724 17660 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1211 23:26:48.275733 17660 solver.cpp:218] Iteration 121400 (12.2448 iter/s, 8.1667s/100 iters), loss = 0.0139743
I1211 23:26:48.275733 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:26:48.275733 17660 solver.cpp:237]     Train net output #1: loss = 0.0139742 (* 1 = 0.0139742 loss)
I1211 23:26:48.275733 17660 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1211 23:26:56.026336 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:26:56.349586 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.caffemodel
I1211 23:26:56.381568 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.solverstate
I1211 23:26:56.387573 17660 solver.cpp:330] Iteration 121500, Testing net (#0)
I1211 23:26:56.387573 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:26:58.101784 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:26:58.168792 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1211 23:26:58.168792 17660 solver.cpp:397]     Test net output #1: loss = 0.247893 (* 1 = 0.247893 loss)
I1211 23:26:58.245800 17660 solver.cpp:218] Iteration 121500 (10.0302 iter/s, 9.9699s/100 iters), loss = 0.0151314
I1211 23:26:58.245800 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:26:58.245800 17660 solver.cpp:237]     Train net output #1: loss = 0.0151313 (* 1 = 0.0151313 loss)
I1211 23:26:58.245800 17660 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1211 23:27:06.501989 17660 solver.cpp:218] Iteration 121600 (12.113 iter/s, 8.25558s/100 iters), loss = 0.0130897
I1211 23:27:06.501989 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:27:06.501989 17660 solver.cpp:237]     Train net output #1: loss = 0.0130896 (* 1 = 0.0130896 loss)
I1211 23:27:06.501989 17660 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1211 23:27:14.764755 17660 solver.cpp:218] Iteration 121700 (12.103 iter/s, 8.26241s/100 iters), loss = 0.0257799
I1211 23:27:14.764755 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:27:14.764755 17660 solver.cpp:237]     Train net output #1: loss = 0.0257798 (* 1 = 0.0257798 loss)
I1211 23:27:14.764755 17660 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1211 23:27:23.048355 17660 solver.cpp:218] Iteration 121800 (12.0725 iter/s, 8.28326s/100 iters), loss = 0.0140565
I1211 23:27:23.049355 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:27:23.049355 17660 solver.cpp:237]     Train net output #1: loss = 0.0140564 (* 1 = 0.0140564 loss)
I1211 23:27:23.049355 17660 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1211 23:27:31.294868 17660 solver.cpp:218] Iteration 121900 (12.1276 iter/s, 8.24566s/100 iters), loss = 0.0134526
I1211 23:27:31.294868 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:27:31.294868 17660 solver.cpp:237]     Train net output #1: loss = 0.0134525 (* 1 = 0.0134525 loss)
I1211 23:27:31.294868 17660 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1211 23:27:39.185729 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:27:39.525341 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.caffemodel
I1211 23:27:39.584352 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.solverstate
I1211 23:27:39.591352 17660 solver.cpp:330] Iteration 122000, Testing net (#0)
I1211 23:27:39.591352 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:27:41.322378 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:27:41.392886 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1211 23:27:41.392886 17660 solver.cpp:397]     Test net output #1: loss = 0.247783 (* 1 = 0.247783 loss)
I1211 23:27:41.470417 17660 solver.cpp:218] Iteration 122000 (9.82857 iter/s, 10.1744s/100 iters), loss = 0.0113684
I1211 23:27:41.470417 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:27:41.470417 17660 solver.cpp:237]     Train net output #1: loss = 0.0113683 (* 1 = 0.0113683 loss)
I1211 23:27:41.470417 17660 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1211 23:27:49.622606 17660 solver.cpp:218] Iteration 122100 (12.2666 iter/s, 8.15223s/100 iters), loss = 0.0231297
I1211 23:27:49.622606 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:27:49.622606 17660 solver.cpp:237]     Train net output #1: loss = 0.0231296 (* 1 = 0.0231296 loss)
I1211 23:27:49.622606 17660 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1211 23:27:57.912541 17660 solver.cpp:218] Iteration 122200 (12.0639 iter/s, 8.2892s/100 iters), loss = 0.0134516
I1211 23:27:57.912541 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:27:57.912541 17660 solver.cpp:237]     Train net output #1: loss = 0.0134515 (* 1 = 0.0134515 loss)
I1211 23:27:57.912541 17660 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1211 23:28:06.301221 17660 solver.cpp:218] Iteration 122300 (11.9218 iter/s, 8.388s/100 iters), loss = 0.0131831
I1211 23:28:06.301221 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:06.301221 17660 solver.cpp:237]     Train net output #1: loss = 0.013183 (* 1 = 0.013183 loss)
I1211 23:28:06.301221 17660 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1211 23:28:14.661628 17660 solver.cpp:218] Iteration 122400 (11.9622 iter/s, 8.35965s/100 iters), loss = 0.0132871
I1211 23:28:14.661628 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:14.661628 17660 solver.cpp:237]     Train net output #1: loss = 0.013287 (* 1 = 0.013287 loss)
I1211 23:28:14.661628 17660 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1211 23:28:22.436220 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:28:22.760766 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.caffemodel
I1211 23:28:22.789271 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.solverstate
I1211 23:28:22.795271 17660 solver.cpp:330] Iteration 122500, Testing net (#0)
I1211 23:28:22.796272 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:28:24.498469 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:28:24.566973 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9365
I1211 23:28:24.566973 17660 solver.cpp:397]     Test net output #1: loss = 0.248262 (* 1 = 0.248262 loss)
I1211 23:28:24.641481 17660 solver.cpp:218] Iteration 122500 (10.0203 iter/s, 9.97973s/100 iters), loss = 0.0286371
I1211 23:28:24.641481 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:24.641481 17660 solver.cpp:237]     Train net output #1: loss = 0.028637 (* 1 = 0.028637 loss)
I1211 23:28:24.641481 17660 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1211 23:28:32.787330 17660 solver.cpp:218] Iteration 122600 (12.2777 iter/s, 8.14487s/100 iters), loss = 0.0174705
I1211 23:28:32.787330 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:32.787330 17660 solver.cpp:237]     Train net output #1: loss = 0.0174704 (* 1 = 0.0174704 loss)
I1211 23:28:32.787330 17660 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1211 23:28:40.902375 17660 solver.cpp:218] Iteration 122700 (12.3227 iter/s, 8.11513s/100 iters), loss = 0.0195672
I1211 23:28:40.902375 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:40.902375 17660 solver.cpp:237]     Train net output #1: loss = 0.0195671 (* 1 = 0.0195671 loss)
I1211 23:28:40.902375 17660 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1211 23:28:49.113984 17660 solver.cpp:218] Iteration 122800 (12.1789 iter/s, 8.21092s/100 iters), loss = 0.0111838
I1211 23:28:49.113984 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:49.113984 17660 solver.cpp:237]     Train net output #1: loss = 0.0111837 (* 1 = 0.0111837 loss)
I1211 23:28:49.113984 17660 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1211 23:28:57.263579 17660 solver.cpp:218] Iteration 122900 (12.2722 iter/s, 8.14848s/100 iters), loss = 0.0149192
I1211 23:28:57.263579 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:28:57.263579 17660 solver.cpp:237]     Train net output #1: loss = 0.0149191 (* 1 = 0.0149191 loss)
I1211 23:28:57.263579 17660 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1211 23:29:05.037453 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:29:05.357480 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.caffemodel
I1211 23:29:05.409488 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.solverstate
I1211 23:29:05.415489 17660 solver.cpp:330] Iteration 123000, Testing net (#0)
I1211 23:29:05.415489 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:29:07.122687 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:29:07.191699 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 23:29:07.191699 17660 solver.cpp:397]     Test net output #1: loss = 0.250351 (* 1 = 0.250351 loss)
I1211 23:29:07.268218 17660 solver.cpp:218] Iteration 123000 (9.99595 iter/s, 10.004s/100 iters), loss = 0.018516
I1211 23:29:07.268218 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:07.268218 17660 solver.cpp:237]     Train net output #1: loss = 0.0185159 (* 1 = 0.0185159 loss)
I1211 23:29:07.268218 17660 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1211 23:29:15.451789 17660 solver.cpp:218] Iteration 123100 (12.2195 iter/s, 8.18361s/100 iters), loss = 0.0125138
I1211 23:29:15.451789 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:15.451789 17660 solver.cpp:237]     Train net output #1: loss = 0.0125137 (* 1 = 0.0125137 loss)
I1211 23:29:15.451789 17660 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1211 23:29:23.548912 17660 solver.cpp:218] Iteration 123200 (12.3504 iter/s, 8.09688s/100 iters), loss = 0.0143491
I1211 23:29:23.548912 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:23.548912 17660 solver.cpp:237]     Train net output #1: loss = 0.014349 (* 1 = 0.014349 loss)
I1211 23:29:23.548912 17660 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1211 23:29:31.712594 17660 solver.cpp:218] Iteration 123300 (12.2508 iter/s, 8.16274s/100 iters), loss = 0.0132969
I1211 23:29:31.712594 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:31.712594 17660 solver.cpp:237]     Train net output #1: loss = 0.0132968 (* 1 = 0.0132968 loss)
I1211 23:29:31.712594 17660 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1211 23:29:39.939095 17660 solver.cpp:218] Iteration 123400 (12.1559 iter/s, 8.22649s/100 iters), loss = 0.0175818
I1211 23:29:39.939095 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:39.939095 17660 solver.cpp:237]     Train net output #1: loss = 0.0175817 (* 1 = 0.0175817 loss)
I1211 23:29:39.939095 17660 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1211 23:29:47.680866 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:29:47.999896 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.caffemodel
I1211 23:29:48.029896 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.solverstate
I1211 23:29:48.035897 17660 solver.cpp:330] Iteration 123500, Testing net (#0)
I1211 23:29:48.036898 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:29:49.722074 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:29:49.789577 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 23:29:49.790077 17660 solver.cpp:397]     Test net output #1: loss = 0.250199 (* 1 = 0.250199 loss)
I1211 23:29:49.864078 17660 solver.cpp:218] Iteration 123500 (10.0765 iter/s, 9.92411s/100 iters), loss = 0.0295157
I1211 23:29:49.864078 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:49.864078 17660 solver.cpp:237]     Train net output #1: loss = 0.0295156 (* 1 = 0.0295156 loss)
I1211 23:29:49.864078 17660 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1211 23:29:58.002173 17660 solver.cpp:218] Iteration 123600 (12.2892 iter/s, 8.13722s/100 iters), loss = 0.0174487
I1211 23:29:58.002173 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:29:58.002173 17660 solver.cpp:237]     Train net output #1: loss = 0.0174486 (* 1 = 0.0174486 loss)
I1211 23:29:58.002173 17660 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1211 23:30:06.090190 17660 solver.cpp:218] Iteration 123700 (12.3647 iter/s, 8.08754s/100 iters), loss = 0.0192737
I1211 23:30:06.090190 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:30:06.090190 17660 solver.cpp:237]     Train net output #1: loss = 0.0192736 (* 1 = 0.0192736 loss)
I1211 23:30:06.090190 17660 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1211 23:30:14.188088 17660 solver.cpp:218] Iteration 123800 (12.3492 iter/s, 8.09768s/100 iters), loss = 0.0135339
I1211 23:30:14.188088 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:30:14.188088 17660 solver.cpp:237]     Train net output #1: loss = 0.0135338 (* 1 = 0.0135338 loss)
I1211 23:30:14.188088 17660 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1211 23:30:22.477890 17660 solver.cpp:218] Iteration 123900 (12.0634 iter/s, 8.28953s/100 iters), loss = 0.0147229
I1211 23:30:22.478890 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:30:22.478890 17660 solver.cpp:237]     Train net output #1: loss = 0.0147228 (* 1 = 0.0147228 loss)
I1211 23:30:22.478890 17660 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1211 23:30:30.276490 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:30:30.598554 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.caffemodel
I1211 23:30:30.649822 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.solverstate
I1211 23:30:30.655823 17660 solver.cpp:330] Iteration 124000, Testing net (#0)
I1211 23:30:30.655823 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:30:32.375576 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:30:32.444380 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1211 23:30:32.444380 17660 solver.cpp:397]     Test net output #1: loss = 0.251566 (* 1 = 0.251566 loss)
I1211 23:30:32.523403 17660 solver.cpp:218] Iteration 124000 (9.95611 iter/s, 10.0441s/100 iters), loss = 0.0119823
I1211 23:30:32.523403 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:30:32.523403 17660 solver.cpp:237]     Train net output #1: loss = 0.0119822 (* 1 = 0.0119822 loss)
I1211 23:30:32.523403 17660 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1211 23:30:40.679358 17660 solver.cpp:218] Iteration 124100 (12.2613 iter/s, 8.15575s/100 iters), loss = 0.0171293
I1211 23:30:40.679358 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:30:40.679358 17660 solver.cpp:237]     Train net output #1: loss = 0.0171291 (* 1 = 0.0171291 loss)
I1211 23:30:40.679358 17660 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1211 23:30:48.876581 17660 solver.cpp:218] Iteration 124200 (12.2005 iter/s, 8.1964s/100 iters), loss = 0.0140611
I1211 23:30:48.876581 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:30:48.876581 17660 solver.cpp:237]     Train net output #1: loss = 0.014061 (* 1 = 0.014061 loss)
I1211 23:30:48.876581 17660 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1211 23:30:57.065747 17660 solver.cpp:218] Iteration 124300 (12.2121 iter/s, 8.18859s/100 iters), loss = 0.0186792
I1211 23:30:57.065747 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:30:57.065747 17660 solver.cpp:237]     Train net output #1: loss = 0.0186791 (* 1 = 0.0186791 loss)
I1211 23:30:57.065747 17660 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1211 23:31:05.244594 17660 solver.cpp:218] Iteration 124400 (12.2266 iter/s, 8.17888s/100 iters), loss = 0.0172647
I1211 23:31:05.244594 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:05.244594 17660 solver.cpp:237]     Train net output #1: loss = 0.0172646 (* 1 = 0.0172646 loss)
I1211 23:31:05.244594 17660 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1211 23:31:13.067987 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:31:13.393230 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.caffemodel
I1211 23:31:13.425734 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.solverstate
I1211 23:31:13.431254 17660 solver.cpp:330] Iteration 124500, Testing net (#0)
I1211 23:31:13.432255 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:31:15.153532 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:31:15.222548 17660 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1211 23:31:15.222548 17660 solver.cpp:397]     Test net output #1: loss = 0.247589 (* 1 = 0.247589 loss)
I1211 23:31:15.299124 17660 solver.cpp:218] Iteration 124500 (9.94674 iter/s, 10.0535s/100 iters), loss = 0.0187027
I1211 23:31:15.299124 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:15.299124 17660 solver.cpp:237]     Train net output #1: loss = 0.0187026 (* 1 = 0.0187026 loss)
I1211 23:31:15.299124 17660 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1211 23:31:23.533632 17660 solver.cpp:218] Iteration 124600 (12.1452 iter/s, 8.23372s/100 iters), loss = 0.0129975
I1211 23:31:23.533632 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:23.533632 17660 solver.cpp:237]     Train net output #1: loss = 0.0129974 (* 1 = 0.0129974 loss)
I1211 23:31:23.533632 17660 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1211 23:31:31.699142 17660 solver.cpp:218] Iteration 124700 (12.2475 iter/s, 8.1649s/100 iters), loss = 0.0100499
I1211 23:31:31.699142 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:31.699142 17660 solver.cpp:237]     Train net output #1: loss = 0.0100497 (* 1 = 0.0100497 loss)
I1211 23:31:31.699142 17660 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1211 23:31:39.821710 17660 solver.cpp:218] Iteration 124800 (12.3124 iter/s, 8.12189s/100 iters), loss = 0.0191972
I1211 23:31:39.821710 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:39.821710 17660 solver.cpp:237]     Train net output #1: loss = 0.0191971 (* 1 = 0.0191971 loss)
I1211 23:31:39.821710 17660 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1211 23:31:47.909029 17660 solver.cpp:218] Iteration 124900 (12.3646 iter/s, 8.08761s/100 iters), loss = 0.016859
I1211 23:31:47.909029 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:47.909029 17660 solver.cpp:237]     Train net output #1: loss = 0.0168589 (* 1 = 0.0168589 loss)
I1211 23:31:47.909029 17660 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1211 23:31:55.588429 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:31:55.907112 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.caffemodel
I1211 23:31:55.967140 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.solverstate
I1211 23:31:55.973125 17660 solver.cpp:330] Iteration 125000, Testing net (#0)
I1211 23:31:55.973125 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:31:57.675251 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:31:57.743758 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1211 23:31:57.743758 17660 solver.cpp:397]     Test net output #1: loss = 0.250074 (* 1 = 0.250074 loss)
I1211 23:31:57.817245 17660 solver.cpp:218] Iteration 125000 (10.0937 iter/s, 9.90719s/100 iters), loss = 0.0153791
I1211 23:31:57.817245 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:31:57.817245 17660 solver.cpp:237]     Train net output #1: loss = 0.015379 (* 1 = 0.015379 loss)
I1211 23:31:57.817245 17660 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1211 23:32:05.935573 17660 solver.cpp:218] Iteration 125100 (12.3192 iter/s, 8.11743s/100 iters), loss = 0.0169446
I1211 23:32:05.935573 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:32:05.935573 17660 solver.cpp:237]     Train net output #1: loss = 0.0169445 (* 1 = 0.0169445 loss)
I1211 23:32:05.935573 17660 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1211 23:32:14.200034 17660 solver.cpp:218] Iteration 125200 (12.1005 iter/s, 8.26409s/100 iters), loss = 0.0115814
I1211 23:32:14.200034 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:32:14.200034 17660 solver.cpp:237]     Train net output #1: loss = 0.0115813 (* 1 = 0.0115813 loss)
I1211 23:32:14.200034 17660 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1211 23:32:22.435946 17660 solver.cpp:218] Iteration 125300 (12.1435 iter/s, 8.23485s/100 iters), loss = 0.0213972
I1211 23:32:22.435946 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:32:22.435946 17660 solver.cpp:237]     Train net output #1: loss = 0.0213971 (* 1 = 0.0213971 loss)
I1211 23:32:22.435946 17660 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1211 23:32:30.580191 17660 solver.cpp:218] Iteration 125400 (12.2789 iter/s, 8.14404s/100 iters), loss = 0.0120944
I1211 23:32:30.580191 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:32:30.580191 17660 solver.cpp:237]     Train net output #1: loss = 0.0120943 (* 1 = 0.0120943 loss)
I1211 23:32:30.580191 17660 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1211 23:32:38.292971 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:32:38.612001 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.caffemodel
I1211 23:32:38.643005 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.solverstate
I1211 23:32:38.699023 17660 solver.cpp:330] Iteration 125500, Testing net (#0)
I1211 23:32:38.699023 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:32:40.389199 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:32:40.456207 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1211 23:32:40.456207 17660 solver.cpp:397]     Test net output #1: loss = 0.254327 (* 1 = 0.254327 loss)
I1211 23:32:40.532205 17660 solver.cpp:218] Iteration 125500 (10.0491 iter/s, 9.9511s/100 iters), loss = 0.0162742
I1211 23:32:40.532205 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:32:40.532205 17660 solver.cpp:237]     Train net output #1: loss = 0.0162741 (* 1 = 0.0162741 loss)
I1211 23:32:40.532205 17660 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1211 23:32:48.617745 17660 solver.cpp:218] Iteration 125600 (12.3688 iter/s, 8.08487s/100 iters), loss = 0.047917
I1211 23:32:48.617745 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:32:48.617745 17660 solver.cpp:237]     Train net output #1: loss = 0.0479169 (* 1 = 0.0479169 loss)
I1211 23:32:48.617745 17660 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1211 23:32:56.723167 17660 solver.cpp:218] Iteration 125700 (12.3379 iter/s, 8.10508s/100 iters), loss = 0.0171112
I1211 23:32:56.723167 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:32:56.723167 17660 solver.cpp:237]     Train net output #1: loss = 0.0171111 (* 1 = 0.0171111 loss)
I1211 23:32:56.723167 17660 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1211 23:33:04.846179 17660 solver.cpp:218] Iteration 125800 (12.3107 iter/s, 8.12301s/100 iters), loss = 0.00943353
I1211 23:33:04.847170 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:33:04.847170 17660 solver.cpp:237]     Train net output #1: loss = 0.00943343 (* 1 = 0.00943343 loss)
I1211 23:33:04.847170 17660 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1211 23:33:12.928535 17660 solver.cpp:218] Iteration 125900 (12.3739 iter/s, 8.08154s/100 iters), loss = 0.01172
I1211 23:33:12.928535 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:33:12.928535 17660 solver.cpp:237]     Train net output #1: loss = 0.0117199 (* 1 = 0.0117199 loss)
I1211 23:33:12.928535 17660 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1211 23:33:20.660226 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:33:20.983604 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.caffemodel
I1211 23:33:21.012605 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.solverstate
I1211 23:33:21.019592 17660 solver.cpp:330] Iteration 126000, Testing net (#0)
I1211 23:33:21.019592 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:33:22.708701 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:33:22.775209 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1211 23:33:22.775209 17660 solver.cpp:397]     Test net output #1: loss = 0.255692 (* 1 = 0.255692 loss)
I1211 23:33:22.850193 17660 solver.cpp:218] Iteration 126000 (10.0794 iter/s, 9.92118s/100 iters), loss = 0.0313015
I1211 23:33:22.850193 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:33:22.850193 17660 solver.cpp:237]     Train net output #1: loss = 0.0313014 (* 1 = 0.0313014 loss)
I1211 23:33:22.850193 17660 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1211 23:33:30.931964 17660 solver.cpp:218] Iteration 126100 (12.3758 iter/s, 8.0803s/100 iters), loss = 0.0131263
I1211 23:33:30.931964 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:33:30.931964 17660 solver.cpp:237]     Train net output #1: loss = 0.0131262 (* 1 = 0.0131262 loss)
I1211 23:33:30.931964 17660 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1211 23:33:39.127188 17660 solver.cpp:218] Iteration 126200 (12.2021 iter/s, 8.19529s/100 iters), loss = 0.0132314
I1211 23:33:39.127188 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:33:39.127188 17660 solver.cpp:237]     Train net output #1: loss = 0.0132313 (* 1 = 0.0132313 loss)
I1211 23:33:39.127188 17660 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1211 23:33:47.218665 17660 solver.cpp:218] Iteration 126300 (12.3601 iter/s, 8.09055s/100 iters), loss = 0.0123758
I1211 23:33:47.218665 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:33:47.218665 17660 solver.cpp:237]     Train net output #1: loss = 0.0123757 (* 1 = 0.0123757 loss)
I1211 23:33:47.218665 17660 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1211 23:33:55.364369 17660 solver.cpp:218] Iteration 126400 (12.2777 iter/s, 8.14485s/100 iters), loss = 0.0122212
I1211 23:33:55.364369 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:33:55.364369 17660 solver.cpp:237]     Train net output #1: loss = 0.0122211 (* 1 = 0.0122211 loss)
I1211 23:33:55.364369 17660 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1211 23:34:03.082620 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:34:03.401692 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.caffemodel
I1211 23:34:03.436718 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.solverstate
I1211 23:34:03.449746 17660 solver.cpp:330] Iteration 126500, Testing net (#0)
I1211 23:34:03.449746 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:34:05.131389 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:34:05.200389 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1211 23:34:05.200389 17660 solver.cpp:397]     Test net output #1: loss = 0.252249 (* 1 = 0.252249 loss)
I1211 23:34:05.274406 17660 solver.cpp:218] Iteration 126500 (10.0904 iter/s, 9.91041s/100 iters), loss = 0.0132009
I1211 23:34:05.275406 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:34:05.275406 17660 solver.cpp:237]     Train net output #1: loss = 0.0132009 (* 1 = 0.0132009 loss)
I1211 23:34:05.275406 17660 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1211 23:34:13.396400 17660 solver.cpp:218] Iteration 126600 (12.3142 iter/s, 8.12068s/100 iters), loss = 0.0113063
I1211 23:34:13.396400 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:34:13.396400 17660 solver.cpp:237]     Train net output #1: loss = 0.0113063 (* 1 = 0.0113063 loss)
I1211 23:34:13.396400 17660 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1211 23:34:21.576696 17660 solver.cpp:218] Iteration 126700 (12.2242 iter/s, 8.18052s/100 iters), loss = 0.01468
I1211 23:34:21.576696 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:34:21.576696 17660 solver.cpp:237]     Train net output #1: loss = 0.0146799 (* 1 = 0.0146799 loss)
I1211 23:34:21.576696 17660 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1211 23:34:29.677949 17660 solver.cpp:218] Iteration 126800 (12.3454 iter/s, 8.10021s/100 iters), loss = 0.0189222
I1211 23:34:29.677949 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:34:29.677949 17660 solver.cpp:237]     Train net output #1: loss = 0.0189221 (* 1 = 0.0189221 loss)
I1211 23:34:29.677949 17660 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1211 23:34:37.851733 17660 solver.cpp:218] Iteration 126900 (12.235 iter/s, 8.17326s/100 iters), loss = 0.0157414
I1211 23:34:37.851733 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:34:37.851733 17660 solver.cpp:237]     Train net output #1: loss = 0.0157413 (* 1 = 0.0157413 loss)
I1211 23:34:37.851733 17660 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1211 23:34:45.580987 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:34:45.904943 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.caffemodel
I1211 23:34:45.933447 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.solverstate
I1211 23:34:45.939450 17660 solver.cpp:330] Iteration 127000, Testing net (#0)
I1211 23:34:45.939450 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:34:47.619611 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:34:47.687631 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1211 23:34:47.687631 17660 solver.cpp:397]     Test net output #1: loss = 0.254608 (* 1 = 0.254608 loss)
I1211 23:34:47.762275 17660 solver.cpp:218] Iteration 127000 (10.091 iter/s, 9.90981s/100 iters), loss = 0.0232463
I1211 23:34:47.762275 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:34:47.762275 17660 solver.cpp:237]     Train net output #1: loss = 0.0232462 (* 1 = 0.0232462 loss)
I1211 23:34:47.762275 17660 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1211 23:34:55.815124 17660 solver.cpp:218] Iteration 127100 (12.4191 iter/s, 8.05211s/100 iters), loss = 0.0177832
I1211 23:34:55.815124 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:34:55.815124 17660 solver.cpp:237]     Train net output #1: loss = 0.0177831 (* 1 = 0.0177831 loss)
I1211 23:34:55.815124 17660 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1211 23:35:04.006368 17660 solver.cpp:218] Iteration 127200 (12.2087 iter/s, 8.19089s/100 iters), loss = 0.0155309
I1211 23:35:04.006368 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:35:04.006368 17660 solver.cpp:237]     Train net output #1: loss = 0.0155309 (* 1 = 0.0155309 loss)
I1211 23:35:04.006368 17660 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1211 23:35:12.224253 17660 solver.cpp:218] Iteration 127300 (12.1689 iter/s, 8.21766s/100 iters), loss = 0.0115125
I1211 23:35:12.224253 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:35:12.224253 17660 solver.cpp:237]     Train net output #1: loss = 0.0115124 (* 1 = 0.0115124 loss)
I1211 23:35:12.224253 17660 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1211 23:35:20.541100 17660 solver.cpp:218] Iteration 127400 (12.0251 iter/s, 8.31593s/100 iters), loss = 0.0124989
I1211 23:35:20.541100 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:35:20.541100 17660 solver.cpp:237]     Train net output #1: loss = 0.0124989 (* 1 = 0.0124989 loss)
I1211 23:35:20.541100 17660 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1211 23:35:28.252970 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:35:28.576498 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.caffemodel
I1211 23:35:28.606498 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.solverstate
I1211 23:35:28.642001 17660 solver.cpp:330] Iteration 127500, Testing net (#0)
I1211 23:35:28.642503 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:35:30.354600 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:35:30.422605 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 23:35:30.422605 17660 solver.cpp:397]     Test net output #1: loss = 0.249302 (* 1 = 0.249302 loss)
I1211 23:35:30.498616 17660 solver.cpp:218] Iteration 127500 (10.0435 iter/s, 9.95665s/100 iters), loss = 0.0231926
I1211 23:35:30.498616 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:35:30.498616 17660 solver.cpp:237]     Train net output #1: loss = 0.0231925 (* 1 = 0.0231925 loss)
I1211 23:35:30.498616 17660 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1211 23:35:38.593312 17660 solver.cpp:218] Iteration 127600 (12.3545 iter/s, 8.09419s/100 iters), loss = 0.012229
I1211 23:35:38.593312 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:35:38.593312 17660 solver.cpp:237]     Train net output #1: loss = 0.0122289 (* 1 = 0.0122289 loss)
I1211 23:35:38.593312 17660 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1211 23:35:46.687917 17660 solver.cpp:218] Iteration 127700 (12.3544 iter/s, 8.09427s/100 iters), loss = 0.0164431
I1211 23:35:46.687917 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:35:46.687917 17660 solver.cpp:237]     Train net output #1: loss = 0.016443 (* 1 = 0.016443 loss)
I1211 23:35:46.687917 17660 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1211 23:35:54.802356 17660 solver.cpp:218] Iteration 127800 (12.3236 iter/s, 8.1145s/100 iters), loss = 0.0112186
I1211 23:35:54.802356 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:35:54.802356 17660 solver.cpp:237]     Train net output #1: loss = 0.0112185 (* 1 = 0.0112185 loss)
I1211 23:35:54.802356 17660 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1211 23:36:02.896687 17660 solver.cpp:218] Iteration 127900 (12.3552 iter/s, 8.09379s/100 iters), loss = 0.0132098
I1211 23:36:02.897702 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:36:02.897702 17660 solver.cpp:237]     Train net output #1: loss = 0.0132097 (* 1 = 0.0132097 loss)
I1211 23:36:02.897702 17660 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1211 23:36:10.619969 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:36:10.945138 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.caffemodel
I1211 23:36:10.975181 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.solverstate
I1211 23:36:10.981181 17660 solver.cpp:330] Iteration 128000, Testing net (#0)
I1211 23:36:10.981181 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:36:12.662947 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:36:12.729259 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 23:36:12.729259 17660 solver.cpp:397]     Test net output #1: loss = 0.248326 (* 1 = 0.248326 loss)
I1211 23:36:12.804510 17660 solver.cpp:218] Iteration 128000 (10.0944 iter/s, 9.90647s/100 iters), loss = 0.024105
I1211 23:36:12.804510 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:36:12.804510 17660 solver.cpp:237]     Train net output #1: loss = 0.0241049 (* 1 = 0.0241049 loss)
I1211 23:36:12.804510 17660 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1211 23:36:20.917636 17660 solver.cpp:218] Iteration 128100 (12.3257 iter/s, 8.11313s/100 iters), loss = 0.0183271
I1211 23:36:20.917636 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:36:20.917636 17660 solver.cpp:237]     Train net output #1: loss = 0.018327 (* 1 = 0.018327 loss)
I1211 23:36:20.917636 17660 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1211 23:36:29.089682 17660 solver.cpp:218] Iteration 128200 (12.2383 iter/s, 8.17108s/100 iters), loss = 0.0248754
I1211 23:36:29.089682 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:36:29.089682 17660 solver.cpp:237]     Train net output #1: loss = 0.0248753 (* 1 = 0.0248753 loss)
I1211 23:36:29.089682 17660 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1211 23:36:37.244184 17660 solver.cpp:218] Iteration 128300 (12.2634 iter/s, 8.15432s/100 iters), loss = 0.0154947
I1211 23:36:37.244184 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:36:37.244184 17660 solver.cpp:237]     Train net output #1: loss = 0.0154946 (* 1 = 0.0154946 loss)
I1211 23:36:37.244184 17660 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1211 23:36:45.394217 17660 solver.cpp:218] Iteration 128400 (12.271 iter/s, 8.14929s/100 iters), loss = 0.0123495
I1211 23:36:45.394217 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:36:45.394217 17660 solver.cpp:237]     Train net output #1: loss = 0.0123494 (* 1 = 0.0123494 loss)
I1211 23:36:45.394217 17660 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1211 23:36:53.234449 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:36:53.566803 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.caffemodel
I1211 23:36:53.604367 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.solverstate
I1211 23:36:53.633368 17660 solver.cpp:330] Iteration 128500, Testing net (#0)
I1211 23:36:53.633368 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:36:55.348713 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:36:55.415658 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1211 23:36:55.415658 17660 solver.cpp:397]     Test net output #1: loss = 0.251476 (* 1 = 0.251476 loss)
I1211 23:36:55.492405 17660 solver.cpp:218] Iteration 128500 (9.90338 iter/s, 10.0976s/100 iters), loss = 0.0154789
I1211 23:36:55.492405 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:36:55.492405 17660 solver.cpp:237]     Train net output #1: loss = 0.0154788 (* 1 = 0.0154788 loss)
I1211 23:36:55.492405 17660 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1211 23:37:03.727197 17660 solver.cpp:218] Iteration 128600 (12.1434 iter/s, 8.23494s/100 iters), loss = 0.00969683
I1211 23:37:03.728197 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:03.728197 17660 solver.cpp:237]     Train net output #1: loss = 0.00969676 (* 1 = 0.00969676 loss)
I1211 23:37:03.728197 17660 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1211 23:37:12.079737 17660 solver.cpp:218] Iteration 128700 (11.9738 iter/s, 8.35157s/100 iters), loss = 0.0132612
I1211 23:37:12.079737 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:12.079737 17660 solver.cpp:237]     Train net output #1: loss = 0.0132611 (* 1 = 0.0132611 loss)
I1211 23:37:12.079737 17660 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1211 23:37:20.374855 17660 solver.cpp:218] Iteration 128800 (12.0567 iter/s, 8.29414s/100 iters), loss = 0.00984679
I1211 23:37:20.374855 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:20.374855 17660 solver.cpp:237]     Train net output #1: loss = 0.00984671 (* 1 = 0.00984671 loss)
I1211 23:37:20.374855 17660 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1211 23:37:28.458325 17660 solver.cpp:218] Iteration 128900 (12.3708 iter/s, 8.08358s/100 iters), loss = 0.0111014
I1211 23:37:28.458325 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:28.458325 17660 solver.cpp:237]     Train net output #1: loss = 0.0111013 (* 1 = 0.0111013 loss)
I1211 23:37:28.458325 17660 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1211 23:37:36.218850 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:37:36.544908 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.caffemodel
I1211 23:37:36.578907 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.solverstate
I1211 23:37:36.584908 17660 solver.cpp:330] Iteration 129000, Testing net (#0)
I1211 23:37:36.585908 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:37:38.284101 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:37:38.351104 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1211 23:37:38.351104 17660 solver.cpp:397]     Test net output #1: loss = 0.250875 (* 1 = 0.250875 loss)
I1211 23:37:38.428109 17660 solver.cpp:218] Iteration 129000 (10.0315 iter/s, 9.9686s/100 iters), loss = 0.0145716
I1211 23:37:38.428109 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:38.428109 17660 solver.cpp:237]     Train net output #1: loss = 0.0145715 (* 1 = 0.0145715 loss)
I1211 23:37:38.428109 17660 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1211 23:37:46.533268 17660 solver.cpp:218] Iteration 129100 (12.3386 iter/s, 8.10466s/100 iters), loss = 0.0223644
I1211 23:37:46.533268 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:46.533268 17660 solver.cpp:237]     Train net output #1: loss = 0.0223644 (* 1 = 0.0223644 loss)
I1211 23:37:46.533268 17660 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1211 23:37:54.743901 17660 solver.cpp:218] Iteration 129200 (12.18 iter/s, 8.21015s/100 iters), loss = 0.0103141
I1211 23:37:54.743901 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:37:54.743901 17660 solver.cpp:237]     Train net output #1: loss = 0.0103141 (* 1 = 0.0103141 loss)
I1211 23:37:54.743901 17660 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1211 23:38:02.988102 17660 solver.cpp:218] Iteration 129300 (12.1295 iter/s, 8.24434s/100 iters), loss = 0.011488
I1211 23:38:02.988102 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:02.989102 17660 solver.cpp:237]     Train net output #1: loss = 0.0114879 (* 1 = 0.0114879 loss)
I1211 23:38:02.989102 17660 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1211 23:38:11.206758 17660 solver.cpp:218] Iteration 129400 (12.1691 iter/s, 8.21755s/100 iters), loss = 0.0111243
I1211 23:38:11.206758 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:11.206758 17660 solver.cpp:237]     Train net output #1: loss = 0.0111242 (* 1 = 0.0111242 loss)
I1211 23:38:11.206758 17660 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1211 23:38:18.934784 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:38:19.254891 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.caffemodel
I1211 23:38:19.283891 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.solverstate
I1211 23:38:19.316408 17660 solver.cpp:330] Iteration 129500, Testing net (#0)
I1211 23:38:19.316910 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:38:21.002086 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:38:21.068092 17660 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 23:38:21.068092 17660 solver.cpp:397]     Test net output #1: loss = 0.254778 (* 1 = 0.254778 loss)
I1211 23:38:21.143102 17660 solver.cpp:218] Iteration 129500 (10.0647 iter/s, 9.93576s/100 iters), loss = 0.0122979
I1211 23:38:21.143102 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:21.143102 17660 solver.cpp:237]     Train net output #1: loss = 0.0122979 (* 1 = 0.0122979 loss)
I1211 23:38:21.143102 17660 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1211 23:38:29.290594 17660 solver.cpp:218] Iteration 129600 (12.2747 iter/s, 8.14682s/100 iters), loss = 0.0112191
I1211 23:38:29.290594 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:29.290594 17660 solver.cpp:237]     Train net output #1: loss = 0.011219 (* 1 = 0.011219 loss)
I1211 23:38:29.290594 17660 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1211 23:38:37.416491 17660 solver.cpp:218] Iteration 129700 (12.3072 iter/s, 8.1253s/100 iters), loss = 0.0206532
I1211 23:38:37.416491 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:37.416491 17660 solver.cpp:237]     Train net output #1: loss = 0.0206531 (* 1 = 0.0206531 loss)
I1211 23:38:37.416491 17660 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1211 23:38:45.524318 17660 solver.cpp:218] Iteration 129800 (12.3344 iter/s, 8.10742s/100 iters), loss = 0.0114896
I1211 23:38:45.524318 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:45.524318 17660 solver.cpp:237]     Train net output #1: loss = 0.0114895 (* 1 = 0.0114895 loss)
I1211 23:38:45.524318 17660 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1211 23:38:53.693570 17660 solver.cpp:218] Iteration 129900 (12.2414 iter/s, 8.16901s/100 iters), loss = 0.0145094
I1211 23:38:53.693570 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:38:53.693570 17660 solver.cpp:237]     Train net output #1: loss = 0.0145093 (* 1 = 0.0145093 loss)
I1211 23:38:53.693570 17660 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1211 23:39:01.435307 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:39:01.759413 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.caffemodel
I1211 23:39:01.790426 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.solverstate
I1211 23:39:01.797431 17660 solver.cpp:330] Iteration 130000, Testing net (#0)
I1211 23:39:01.797431 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:39:03.499100 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:39:03.566100 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1211 23:39:03.566100 17660 solver.cpp:397]     Test net output #1: loss = 0.252933 (* 1 = 0.252933 loss)
I1211 23:39:03.640111 17660 solver.cpp:218] Iteration 130000 (10.054 iter/s, 9.94633s/100 iters), loss = 0.0187263
I1211 23:39:03.640111 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:03.640111 17660 solver.cpp:237]     Train net output #1: loss = 0.0187262 (* 1 = 0.0187262 loss)
I1211 23:39:03.640111 17660 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1211 23:39:11.870740 17660 solver.cpp:218] Iteration 130100 (12.1516 iter/s, 8.22937s/100 iters), loss = 0.014218
I1211 23:39:11.870740 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:11.870740 17660 solver.cpp:237]     Train net output #1: loss = 0.0142179 (* 1 = 0.0142179 loss)
I1211 23:39:11.870740 17660 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1211 23:39:20.415786 17660 solver.cpp:218] Iteration 130200 (11.7024 iter/s, 8.54527s/100 iters), loss = 0.0186366
I1211 23:39:20.415786 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:20.416786 17660 solver.cpp:237]     Train net output #1: loss = 0.0186366 (* 1 = 0.0186366 loss)
I1211 23:39:20.416786 17660 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1211 23:39:28.653359 17660 solver.cpp:218] Iteration 130300 (12.1416 iter/s, 8.23616s/100 iters), loss = 0.0119108
I1211 23:39:28.653359 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:28.653359 17660 solver.cpp:237]     Train net output #1: loss = 0.0119107 (* 1 = 0.0119107 loss)
I1211 23:39:28.653359 17660 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1211 23:39:36.753759 17660 solver.cpp:218] Iteration 130400 (12.3447 iter/s, 8.10061s/100 iters), loss = 0.0102962
I1211 23:39:36.753759 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:36.753759 17660 solver.cpp:237]     Train net output #1: loss = 0.0102961 (* 1 = 0.0102961 loss)
I1211 23:39:36.753759 17660 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1211 23:39:44.510710 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:39:44.834933 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.caffemodel
I1211 23:39:44.876444 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.solverstate
I1211 23:39:44.907444 17660 solver.cpp:330] Iteration 130500, Testing net (#0)
I1211 23:39:44.907444 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:39:46.614527 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:39:46.682543 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 23:39:46.682543 17660 solver.cpp:397]     Test net output #1: loss = 0.248635 (* 1 = 0.248635 loss)
I1211 23:39:46.757395 17660 solver.cpp:218] Iteration 130500 (9.99727 iter/s, 10.0027s/100 iters), loss = 0.0149858
I1211 23:39:46.757395 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:46.757395 17660 solver.cpp:237]     Train net output #1: loss = 0.0149857 (* 1 = 0.0149857 loss)
I1211 23:39:46.757395 17660 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1211 23:39:54.845458 17660 solver.cpp:218] Iteration 130600 (12.3647 iter/s, 8.08751s/100 iters), loss = 0.0213323
I1211 23:39:54.845960 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:39:54.845960 17660 solver.cpp:237]     Train net output #1: loss = 0.0213322 (* 1 = 0.0213322 loss)
I1211 23:39:54.845960 17660 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1211 23:40:02.927387 17660 solver.cpp:218] Iteration 130700 (12.3737 iter/s, 8.08168s/100 iters), loss = 0.0200066
I1211 23:40:02.928388 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:02.928388 17660 solver.cpp:237]     Train net output #1: loss = 0.0200066 (* 1 = 0.0200066 loss)
I1211 23:40:02.928388 17660 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1211 23:40:11.057996 17660 solver.cpp:218] Iteration 130800 (12.3015 iter/s, 8.12907s/100 iters), loss = 0.0164134
I1211 23:40:11.058497 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:11.058497 17660 solver.cpp:237]     Train net output #1: loss = 0.0164133 (* 1 = 0.0164133 loss)
I1211 23:40:11.058497 17660 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1211 23:40:19.206492 17660 solver.cpp:218] Iteration 130900 (12.2733 iter/s, 8.14775s/100 iters), loss = 0.0138315
I1211 23:40:19.206492 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:19.206492 17660 solver.cpp:237]     Train net output #1: loss = 0.0138314 (* 1 = 0.0138314 loss)
I1211 23:40:19.206492 17660 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1211 23:40:26.945159 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:40:27.262686 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.caffemodel
I1211 23:40:27.296682 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.solverstate
I1211 23:40:27.302682 17660 solver.cpp:330] Iteration 131000, Testing net (#0)
I1211 23:40:27.302682 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:40:28.988834 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:40:29.054837 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1211 23:40:29.055337 17660 solver.cpp:397]     Test net output #1: loss = 0.253119 (* 1 = 0.253119 loss)
I1211 23:40:29.129842 17660 solver.cpp:218] Iteration 131000 (10.0781 iter/s, 9.92253s/100 iters), loss = 0.0144165
I1211 23:40:29.129842 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:29.129842 17660 solver.cpp:237]     Train net output #1: loss = 0.0144165 (* 1 = 0.0144165 loss)
I1211 23:40:29.129842 17660 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1211 23:40:37.338076 17660 solver.cpp:218] Iteration 131100 (12.1826 iter/s, 8.20846s/100 iters), loss = 0.0212892
I1211 23:40:37.338076 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:37.338076 17660 solver.cpp:237]     Train net output #1: loss = 0.0212891 (* 1 = 0.0212891 loss)
I1211 23:40:37.338076 17660 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1211 23:40:45.511391 17660 solver.cpp:218] Iteration 131200 (12.2363 iter/s, 8.1724s/100 iters), loss = 0.0150928
I1211 23:40:45.511391 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:45.511391 17660 solver.cpp:237]     Train net output #1: loss = 0.0150927 (* 1 = 0.0150927 loss)
I1211 23:40:45.511391 17660 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1211 23:40:53.887332 17660 solver.cpp:218] Iteration 131300 (11.9403 iter/s, 8.37498s/100 iters), loss = 0.00922243
I1211 23:40:53.887332 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:40:53.887332 17660 solver.cpp:237]     Train net output #1: loss = 0.00922235 (* 1 = 0.00922235 loss)
I1211 23:40:53.887332 17660 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1211 23:41:02.124162 17660 solver.cpp:218] Iteration 131400 (12.1409 iter/s, 8.23664s/100 iters), loss = 0.0134946
I1211 23:41:02.124162 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:02.124162 17660 solver.cpp:237]     Train net output #1: loss = 0.0134945 (* 1 = 0.0134945 loss)
I1211 23:41:02.124162 17660 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1211 23:41:09.991636 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:41:10.318694 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.caffemodel
I1211 23:41:10.350698 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.solverstate
I1211 23:41:10.382737 17660 solver.cpp:330] Iteration 131500, Testing net (#0)
I1211 23:41:10.383718 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:41:12.089200 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:41:12.157218 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 23:41:12.157218 17660 solver.cpp:397]     Test net output #1: loss = 0.25253 (* 1 = 0.25253 loss)
I1211 23:41:12.235424 17660 solver.cpp:218] Iteration 131500 (9.89081 iter/s, 10.1104s/100 iters), loss = 0.0228657
I1211 23:41:12.235424 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:12.235424 17660 solver.cpp:237]     Train net output #1: loss = 0.0228656 (* 1 = 0.0228656 loss)
I1211 23:41:12.235424 17660 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1211 23:41:20.461072 17660 solver.cpp:218] Iteration 131600 (12.158 iter/s, 8.22504s/100 iters), loss = 0.0144319
I1211 23:41:20.461072 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:20.461072 17660 solver.cpp:237]     Train net output #1: loss = 0.0144318 (* 1 = 0.0144318 loss)
I1211 23:41:20.461072 17660 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1211 23:41:28.850009 17660 solver.cpp:218] Iteration 131700 (11.9214 iter/s, 8.38829s/100 iters), loss = 0.0123362
I1211 23:41:28.850009 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:28.850009 17660 solver.cpp:237]     Train net output #1: loss = 0.0123361 (* 1 = 0.0123361 loss)
I1211 23:41:28.850009 17660 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1211 23:41:37.033535 17660 solver.cpp:218] Iteration 131800 (12.2194 iter/s, 8.18372s/100 iters), loss = 0.0181079
I1211 23:41:37.033535 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:37.033535 17660 solver.cpp:237]     Train net output #1: loss = 0.0181078 (* 1 = 0.0181078 loss)
I1211 23:41:37.033535 17660 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1211 23:41:45.301283 17660 solver.cpp:218] Iteration 131900 (12.0961 iter/s, 8.26714s/100 iters), loss = 0.0131613
I1211 23:41:45.301283 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:45.301283 17660 solver.cpp:237]     Train net output #1: loss = 0.0131612 (* 1 = 0.0131612 loss)
I1211 23:41:45.301283 17660 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1211 23:41:52.981611 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:41:53.299631 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.caffemodel
I1211 23:41:53.329640 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.solverstate
I1211 23:41:53.336637 17660 solver.cpp:330] Iteration 132000, Testing net (#0)
I1211 23:41:53.336637 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:41:55.019819 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:41:55.087321 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9323
I1211 23:41:55.087321 17660 solver.cpp:397]     Test net output #1: loss = 0.255754 (* 1 = 0.255754 loss)
I1211 23:41:55.162824 17660 solver.cpp:218] Iteration 132000 (10.1411 iter/s, 9.86085s/100 iters), loss = 0.0241128
I1211 23:41:55.162824 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:41:55.162824 17660 solver.cpp:237]     Train net output #1: loss = 0.0241127 (* 1 = 0.0241127 loss)
I1211 23:41:55.162824 17660 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1211 23:42:03.227650 17660 solver.cpp:218] Iteration 132100 (12.4001 iter/s, 8.06447s/100 iters), loss = 0.0182662
I1211 23:42:03.227650 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:03.227650 17660 solver.cpp:237]     Train net output #1: loss = 0.0182661 (* 1 = 0.0182661 loss)
I1211 23:42:03.227650 17660 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1211 23:42:11.283653 17660 solver.cpp:218] Iteration 132200 (12.4148 iter/s, 8.0549s/100 iters), loss = 0.0107676
I1211 23:42:11.283653 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:11.283653 17660 solver.cpp:237]     Train net output #1: loss = 0.0107675 (* 1 = 0.0107675 loss)
I1211 23:42:11.283653 17660 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1211 23:42:19.378371 17660 solver.cpp:218] Iteration 132300 (12.3545 iter/s, 8.0942s/100 iters), loss = 0.0101874
I1211 23:42:19.378371 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:19.378371 17660 solver.cpp:237]     Train net output #1: loss = 0.0101873 (* 1 = 0.0101873 loss)
I1211 23:42:19.378371 17660 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1211 23:42:27.593675 17660 solver.cpp:218] Iteration 132400 (12.173 iter/s, 8.21491s/100 iters), loss = 0.0122058
I1211 23:42:27.593675 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:27.593675 17660 solver.cpp:237]     Train net output #1: loss = 0.0122057 (* 1 = 0.0122057 loss)
I1211 23:42:27.593675 17660 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1211 23:42:35.688067 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:42:36.022956 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.caffemodel
I1211 23:42:36.054953 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.solverstate
I1211 23:42:36.082957 17660 solver.cpp:330] Iteration 132500, Testing net (#0)
I1211 23:42:36.082957 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:42:37.817284 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:42:37.884690 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 23:42:37.884690 17660 solver.cpp:397]     Test net output #1: loss = 0.257687 (* 1 = 0.257687 loss)
I1211 23:42:37.960220 17660 solver.cpp:218] Iteration 132500 (9.64713 iter/s, 10.3658s/100 iters), loss = 0.0167686
I1211 23:42:37.960220 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:37.960220 17660 solver.cpp:237]     Train net output #1: loss = 0.0167685 (* 1 = 0.0167685 loss)
I1211 23:42:37.960220 17660 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1211 23:42:46.060537 17660 solver.cpp:218] Iteration 132600 (12.3461 iter/s, 8.0997s/100 iters), loss = 0.0177933
I1211 23:42:46.060537 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:46.060537 17660 solver.cpp:237]     Train net output #1: loss = 0.0177932 (* 1 = 0.0177932 loss)
I1211 23:42:46.060537 17660 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1211 23:42:54.159968 17660 solver.cpp:218] Iteration 132700 (12.3479 iter/s, 8.09854s/100 iters), loss = 0.0157067
I1211 23:42:54.159968 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:42:54.159968 17660 solver.cpp:237]     Train net output #1: loss = 0.0157066 (* 1 = 0.0157066 loss)
I1211 23:42:54.159968 17660 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1211 23:43:02.250655 17660 solver.cpp:218] Iteration 132800 (12.3593 iter/s, 8.09107s/100 iters), loss = 0.0112022
I1211 23:43:02.251651 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:02.251651 17660 solver.cpp:237]     Train net output #1: loss = 0.0112021 (* 1 = 0.0112021 loss)
I1211 23:43:02.251651 17660 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1211 23:43:10.314370 17660 solver.cpp:218] Iteration 132900 (12.4027 iter/s, 8.06278s/100 iters), loss = 0.0109592
I1211 23:43:10.314370 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:10.314370 17660 solver.cpp:237]     Train net output #1: loss = 0.0109591 (* 1 = 0.0109591 loss)
I1211 23:43:10.314370 17660 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1211 23:43:18.126266 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:43:18.446331 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.caffemodel
I1211 23:43:18.480326 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.solverstate
I1211 23:43:18.487326 17660 solver.cpp:330] Iteration 133000, Testing net (#0)
I1211 23:43:18.487326 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:43:20.205538 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:43:20.272039 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1211 23:43:20.272039 17660 solver.cpp:397]     Test net output #1: loss = 0.255494 (* 1 = 0.255494 loss)
I1211 23:43:20.347733 17660 solver.cpp:218] Iteration 133000 (9.9671 iter/s, 10.033s/100 iters), loss = 0.0129226
I1211 23:43:20.347733 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:20.347733 17660 solver.cpp:237]     Train net output #1: loss = 0.0129225 (* 1 = 0.0129225 loss)
I1211 23:43:20.347733 17660 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1211 23:43:28.452980 17660 solver.cpp:218] Iteration 133100 (12.3384 iter/s, 8.10477s/100 iters), loss = 0.0143311
I1211 23:43:28.452980 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:28.452980 17660 solver.cpp:237]     Train net output #1: loss = 0.014331 (* 1 = 0.014331 loss)
I1211 23:43:28.452980 17660 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1211 23:43:36.518200 17660 solver.cpp:218] Iteration 133200 (12.4002 iter/s, 8.06437s/100 iters), loss = 0.0239669
I1211 23:43:36.518200 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:36.518200 17660 solver.cpp:237]     Train net output #1: loss = 0.0239668 (* 1 = 0.0239668 loss)
I1211 23:43:36.518200 17660 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1211 23:43:44.586238 17660 solver.cpp:218] Iteration 133300 (12.3961 iter/s, 8.06707s/100 iters), loss = 0.0103582
I1211 23:43:44.586238 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:44.586238 17660 solver.cpp:237]     Train net output #1: loss = 0.0103581 (* 1 = 0.0103581 loss)
I1211 23:43:44.586238 17660 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1211 23:43:52.705910 17660 solver.cpp:218] Iteration 133400 (12.3165 iter/s, 8.11921s/100 iters), loss = 0.0129123
I1211 23:43:52.705910 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:43:52.705910 17660 solver.cpp:237]     Train net output #1: loss = 0.0129122 (* 1 = 0.0129122 loss)
I1211 23:43:52.705910 17660 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1211 23:44:00.454895 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:44:00.791167 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.caffemodel
I1211 23:44:00.830169 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.solverstate
I1211 23:44:00.858222 17660 solver.cpp:330] Iteration 133500, Testing net (#0)
I1211 23:44:00.858222 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:44:02.547868 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:44:02.614367 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 23:44:02.614367 17660 solver.cpp:397]     Test net output #1: loss = 0.253463 (* 1 = 0.253463 loss)
I1211 23:44:02.689375 17660 solver.cpp:218] Iteration 133500 (10.0167 iter/s, 9.98328s/100 iters), loss = 0.0161866
I1211 23:44:02.689375 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:44:02.689375 17660 solver.cpp:237]     Train net output #1: loss = 0.0161865 (* 1 = 0.0161865 loss)
I1211 23:44:02.689375 17660 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1211 23:44:10.791415 17660 solver.cpp:218] Iteration 133600 (12.3437 iter/s, 8.10128s/100 iters), loss = 0.0109446
I1211 23:44:10.791415 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:44:10.791415 17660 solver.cpp:237]     Train net output #1: loss = 0.0109445 (* 1 = 0.0109445 loss)
I1211 23:44:10.791415 17660 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1211 23:44:18.920403 17660 solver.cpp:218] Iteration 133700 (12.3015 iter/s, 8.12908s/100 iters), loss = 0.0118427
I1211 23:44:18.920403 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:44:18.920403 17660 solver.cpp:237]     Train net output #1: loss = 0.0118426 (* 1 = 0.0118426 loss)
I1211 23:44:18.920403 17660 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1211 23:44:27.017956 17660 solver.cpp:218] Iteration 133800 (12.3511 iter/s, 8.09647s/100 iters), loss = 0.00958892
I1211 23:44:27.017956 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:44:27.017956 17660 solver.cpp:237]     Train net output #1: loss = 0.00958882 (* 1 = 0.00958882 loss)
I1211 23:44:27.017956 17660 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1211 23:44:35.127559 17660 solver.cpp:218] Iteration 133900 (12.3317 iter/s, 8.10917s/100 iters), loss = 0.0107544
I1211 23:44:35.127559 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:44:35.127559 17660 solver.cpp:237]     Train net output #1: loss = 0.0107543 (* 1 = 0.0107543 loss)
I1211 23:44:35.127559 17660 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1211 23:44:42.791661 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:44:43.107276 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.caffemodel
I1211 23:44:43.140262 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.solverstate
I1211 23:44:43.146265 17660 solver.cpp:330] Iteration 134000, Testing net (#0)
I1211 23:44:43.147261 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:44:44.829082 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:44:44.896194 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 23:44:44.896194 17660 solver.cpp:397]     Test net output #1: loss = 0.251708 (* 1 = 0.251708 loss)
I1211 23:44:44.970199 17660 solver.cpp:218] Iteration 134000 (10.1605 iter/s, 9.84207s/100 iters), loss = 0.0113669
I1211 23:44:44.970698 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:44:44.970698 17660 solver.cpp:237]     Train net output #1: loss = 0.0113668 (* 1 = 0.0113668 loss)
I1211 23:44:44.970698 17660 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1211 23:44:53.029342 17660 solver.cpp:218] Iteration 134100 (12.4087 iter/s, 8.05887s/100 iters), loss = 0.0208668
I1211 23:44:53.029342 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:44:53.029342 17660 solver.cpp:237]     Train net output #1: loss = 0.0208667 (* 1 = 0.0208667 loss)
I1211 23:44:53.029342 17660 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1211 23:45:01.190495 17660 solver.cpp:218] Iteration 134200 (12.2542 iter/s, 8.16045s/100 iters), loss = 0.0172542
I1211 23:45:01.190495 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:01.190495 17660 solver.cpp:237]     Train net output #1: loss = 0.0172541 (* 1 = 0.0172541 loss)
I1211 23:45:01.190495 17660 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1211 23:45:09.339761 17660 solver.cpp:218] Iteration 134300 (12.2718 iter/s, 8.14878s/100 iters), loss = 0.0118633
I1211 23:45:09.339761 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:09.339761 17660 solver.cpp:237]     Train net output #1: loss = 0.0118632 (* 1 = 0.0118632 loss)
I1211 23:45:09.339761 17660 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1211 23:45:17.538911 17660 solver.cpp:218] Iteration 134400 (12.1966 iter/s, 8.19897s/100 iters), loss = 0.0103899
I1211 23:45:17.539911 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:17.539911 17660 solver.cpp:237]     Train net output #1: loss = 0.0103898 (* 1 = 0.0103898 loss)
I1211 23:45:17.539911 17660 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1211 23:45:25.271544 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:45:25.590075 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.caffemodel
I1211 23:45:25.629580 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.solverstate
I1211 23:45:25.649585 17660 solver.cpp:330] Iteration 134500, Testing net (#0)
I1211 23:45:25.649585 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:45:27.352744 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:45:27.418751 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 23:45:27.418751 17660 solver.cpp:397]     Test net output #1: loss = 0.255485 (* 1 = 0.255485 loss)
I1211 23:45:27.494767 17660 solver.cpp:218] Iteration 134500 (10.0459 iter/s, 9.95436s/100 iters), loss = 0.01526
I1211 23:45:27.494767 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:27.494767 17660 solver.cpp:237]     Train net output #1: loss = 0.0152599 (* 1 = 0.0152599 loss)
I1211 23:45:27.494767 17660 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1211 23:45:35.571856 17660 solver.cpp:218] Iteration 134600 (12.3811 iter/s, 8.07681s/100 iters), loss = 0.0184754
I1211 23:45:35.571856 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:35.571856 17660 solver.cpp:237]     Train net output #1: loss = 0.0184753 (* 1 = 0.0184753 loss)
I1211 23:45:35.571856 17660 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1211 23:45:43.688482 17660 solver.cpp:218] Iteration 134700 (12.3209 iter/s, 8.11632s/100 iters), loss = 0.0227578
I1211 23:45:43.688971 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:45:43.688971 17660 solver.cpp:237]     Train net output #1: loss = 0.0227577 (* 1 = 0.0227577 loss)
I1211 23:45:43.688971 17660 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1211 23:45:51.761034 17660 solver.cpp:218] Iteration 134800 (12.3888 iter/s, 8.07184s/100 iters), loss = 0.0105252
I1211 23:45:51.761034 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:51.761034 17660 solver.cpp:237]     Train net output #1: loss = 0.0105251 (* 1 = 0.0105251 loss)
I1211 23:45:51.761034 17660 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1211 23:45:59.819044 17660 solver.cpp:218] Iteration 134900 (12.411 iter/s, 8.05735s/100 iters), loss = 0.0110174
I1211 23:45:59.819044 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:45:59.819044 17660 solver.cpp:237]     Train net output #1: loss = 0.0110173 (* 1 = 0.0110173 loss)
I1211 23:45:59.819044 17660 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1211 23:46:07.534698 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:46:07.853260 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.caffemodel
I1211 23:46:07.893260 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.solverstate
I1211 23:46:07.899770 17660 solver.cpp:330] Iteration 135000, Testing net (#0)
I1211 23:46:07.900269 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:46:09.599418 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:46:09.666421 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1211 23:46:09.666421 17660 solver.cpp:397]     Test net output #1: loss = 0.254005 (* 1 = 0.254005 loss)
I1211 23:46:09.743429 17660 solver.cpp:218] Iteration 135000 (10.0767 iter/s, 9.92389s/100 iters), loss = 0.0117888
I1211 23:46:09.743429 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:46:09.743429 17660 solver.cpp:237]     Train net output #1: loss = 0.0117887 (* 1 = 0.0117887 loss)
I1211 23:46:09.743429 17660 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1211 23:46:17.859642 17660 solver.cpp:218] Iteration 135100 (12.3217 iter/s, 8.11578s/100 iters), loss = 0.0160866
I1211 23:46:17.859642 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:46:17.859642 17660 solver.cpp:237]     Train net output #1: loss = 0.0160865 (* 1 = 0.0160865 loss)
I1211 23:46:17.859642 17660 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1211 23:46:26.051671 17660 solver.cpp:218] Iteration 135200 (12.2083 iter/s, 8.19115s/100 iters), loss = 0.0100853
I1211 23:46:26.051671 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:46:26.051671 17660 solver.cpp:237]     Train net output #1: loss = 0.0100852 (* 1 = 0.0100852 loss)
I1211 23:46:26.051671 17660 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1211 23:46:34.196981 17660 solver.cpp:218] Iteration 135300 (12.2769 iter/s, 8.1454s/100 iters), loss = 0.022565
I1211 23:46:34.196981 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:46:34.196981 17660 solver.cpp:237]     Train net output #1: loss = 0.0225649 (* 1 = 0.0225649 loss)
I1211 23:46:34.196981 17660 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1211 23:46:42.350548 17660 solver.cpp:218] Iteration 135400 (12.266 iter/s, 8.15259s/100 iters), loss = 0.0120324
I1211 23:46:42.350548 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:46:42.350548 17660 solver.cpp:237]     Train net output #1: loss = 0.0120323 (* 1 = 0.0120323 loss)
I1211 23:46:42.350548 17660 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1211 23:46:50.098742 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:46:50.423280 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.caffemodel
I1211 23:46:50.454784 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.solverstate
I1211 23:46:50.482784 17660 solver.cpp:330] Iteration 135500, Testing net (#0)
I1211 23:46:50.482784 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:46:52.176949 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:46:52.243954 17660 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1211 23:46:52.243954 17660 solver.cpp:397]     Test net output #1: loss = 0.252233 (* 1 = 0.252233 loss)
I1211 23:46:52.321456 17660 solver.cpp:218] Iteration 135500 (10.0298 iter/s, 9.97027s/100 iters), loss = 0.0177044
I1211 23:46:52.321456 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:46:52.321456 17660 solver.cpp:237]     Train net output #1: loss = 0.0177043 (* 1 = 0.0177043 loss)
I1211 23:46:52.321456 17660 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1211 23:47:00.430246 17660 solver.cpp:218] Iteration 135600 (12.3332 iter/s, 8.10817s/100 iters), loss = 0.0138066
I1211 23:47:00.430246 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:47:00.430246 17660 solver.cpp:237]     Train net output #1: loss = 0.0138065 (* 1 = 0.0138065 loss)
I1211 23:47:00.430246 17660 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1211 23:47:08.528702 17660 solver.cpp:218] Iteration 135700 (12.3488 iter/s, 8.09795s/100 iters), loss = 0.032777
I1211 23:47:08.528702 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1211 23:47:08.528702 17660 solver.cpp:237]     Train net output #1: loss = 0.0327768 (* 1 = 0.0327768 loss)
I1211 23:47:08.528702 17660 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1211 23:47:16.653513 17660 solver.cpp:218] Iteration 135800 (12.3075 iter/s, 8.12514s/100 iters), loss = 0.0117879
I1211 23:47:16.653513 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:47:16.653513 17660 solver.cpp:237]     Train net output #1: loss = 0.0117878 (* 1 = 0.0117878 loss)
I1211 23:47:16.653513 17660 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1211 23:47:24.809468 17660 solver.cpp:218] Iteration 135900 (12.2627 iter/s, 8.15479s/100 iters), loss = 0.0105869
I1211 23:47:24.809468 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:47:24.809468 17660 solver.cpp:237]     Train net output #1: loss = 0.0105868 (* 1 = 0.0105868 loss)
I1211 23:47:24.809468 17660 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1211 23:47:32.598006 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:47:32.914032 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.caffemodel
I1211 23:47:32.944039 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.solverstate
I1211 23:47:32.950040 17660 solver.cpp:330] Iteration 136000, Testing net (#0)
I1211 23:47:32.950040 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:47:34.655216 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:47:34.722219 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1211 23:47:34.722219 17660 solver.cpp:397]     Test net output #1: loss = 0.254351 (* 1 = 0.254351 loss)
I1211 23:47:34.799242 17660 solver.cpp:218] Iteration 136000 (10.0105 iter/s, 9.98952s/100 iters), loss = 0.0233317
I1211 23:47:34.799242 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:47:34.799242 17660 solver.cpp:237]     Train net output #1: loss = 0.0233316 (* 1 = 0.0233316 loss)
I1211 23:47:34.799242 17660 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1211 23:47:42.864509 17660 solver.cpp:218] Iteration 136100 (12.4002 iter/s, 8.0644s/100 iters), loss = 0.0129237
I1211 23:47:42.864509 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:47:42.864509 17660 solver.cpp:237]     Train net output #1: loss = 0.0129236 (* 1 = 0.0129236 loss)
I1211 23:47:42.864509 17660 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1211 23:47:50.986871 17660 solver.cpp:218] Iteration 136200 (12.3119 iter/s, 8.12224s/100 iters), loss = 0.0141101
I1211 23:47:50.986871 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:47:50.986871 17660 solver.cpp:237]     Train net output #1: loss = 0.01411 (* 1 = 0.01411 loss)
I1211 23:47:50.986871 17660 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1211 23:47:59.136128 17660 solver.cpp:218] Iteration 136300 (12.2728 iter/s, 8.14811s/100 iters), loss = 0.0100762
I1211 23:47:59.136128 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:47:59.136128 17660 solver.cpp:237]     Train net output #1: loss = 0.0100761 (* 1 = 0.0100761 loss)
I1211 23:47:59.136128 17660 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1211 23:48:07.390110 17660 solver.cpp:218] Iteration 136400 (12.1158 iter/s, 8.25367s/100 iters), loss = 0.0176445
I1211 23:48:07.390110 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:07.390110 17660 solver.cpp:237]     Train net output #1: loss = 0.0176444 (* 1 = 0.0176444 loss)
I1211 23:48:07.390110 17660 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1211 23:48:15.103852 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:48:15.428159 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.caffemodel
I1211 23:48:15.465689 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.solverstate
I1211 23:48:15.499687 17660 solver.cpp:330] Iteration 136500, Testing net (#0)
I1211 23:48:15.500686 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:48:17.243288 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:48:17.311290 17660 solver.cpp:397]     Test net output #0: accuracy = 0.932
I1211 23:48:17.311290 17660 solver.cpp:397]     Test net output #1: loss = 0.254024 (* 1 = 0.254024 loss)
I1211 23:48:17.385303 17660 solver.cpp:218] Iteration 136500 (10.0059 iter/s, 9.99408s/100 iters), loss = 0.0153703
I1211 23:48:17.385303 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:17.385303 17660 solver.cpp:237]     Train net output #1: loss = 0.0153701 (* 1 = 0.0153701 loss)
I1211 23:48:17.385303 17660 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1211 23:48:25.499454 17660 solver.cpp:218] Iteration 136600 (12.3252 iter/s, 8.11343s/100 iters), loss = 0.0142758
I1211 23:48:25.499454 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:25.499454 17660 solver.cpp:237]     Train net output #1: loss = 0.0142757 (* 1 = 0.0142757 loss)
I1211 23:48:25.499454 17660 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1211 23:48:33.718211 17660 solver.cpp:218] Iteration 136700 (12.1686 iter/s, 8.21785s/100 iters), loss = 0.0106386
I1211 23:48:33.718211 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:33.718211 17660 solver.cpp:237]     Train net output #1: loss = 0.0106385 (* 1 = 0.0106385 loss)
I1211 23:48:33.718211 17660 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1211 23:48:41.793321 17660 solver.cpp:218] Iteration 136800 (12.3846 iter/s, 8.07455s/100 iters), loss = 0.0149245
I1211 23:48:41.793321 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:41.793321 17660 solver.cpp:237]     Train net output #1: loss = 0.0149244 (* 1 = 0.0149244 loss)
I1211 23:48:41.793321 17660 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1211 23:48:49.965591 17660 solver.cpp:218] Iteration 136900 (12.2371 iter/s, 8.1719s/100 iters), loss = 0.0114007
I1211 23:48:49.965591 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:49.965591 17660 solver.cpp:237]     Train net output #1: loss = 0.0114006 (* 1 = 0.0114006 loss)
I1211 23:48:49.965591 17660 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1211 23:48:57.694067 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:48:58.014688 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.caffemodel
I1211 23:48:58.044688 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.solverstate
I1211 23:48:58.050689 17660 solver.cpp:330] Iteration 137000, Testing net (#0)
I1211 23:48:58.051692 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:48:59.734233 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:48:59.802251 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1211 23:48:59.802251 17660 solver.cpp:397]     Test net output #1: loss = 0.255108 (* 1 = 0.255108 loss)
I1211 23:48:59.877271 17660 solver.cpp:218] Iteration 137000 (10.09 iter/s, 9.91077s/100 iters), loss = 0.013029
I1211 23:48:59.877271 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:48:59.877271 17660 solver.cpp:237]     Train net output #1: loss = 0.0130289 (* 1 = 0.0130289 loss)
I1211 23:48:59.877271 17660 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1211 23:49:08.093145 17660 solver.cpp:218] Iteration 137100 (12.1719 iter/s, 8.21567s/100 iters), loss = 0.0131473
I1211 23:49:08.093145 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:49:08.093145 17660 solver.cpp:237]     Train net output #1: loss = 0.0131471 (* 1 = 0.0131471 loss)
I1211 23:49:08.093145 17660 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1211 23:49:16.277451 17660 solver.cpp:218] Iteration 137200 (12.2201 iter/s, 8.18323s/100 iters), loss = 0.0157129
I1211 23:49:16.277451 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:49:16.277451 17660 solver.cpp:237]     Train net output #1: loss = 0.0157128 (* 1 = 0.0157128 loss)
I1211 23:49:16.277451 17660 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1211 23:49:24.471225 17660 solver.cpp:218] Iteration 137300 (12.2048 iter/s, 8.19347s/100 iters), loss = 0.0192834
I1211 23:49:24.471225 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:49:24.471225 17660 solver.cpp:237]     Train net output #1: loss = 0.0192833 (* 1 = 0.0192833 loss)
I1211 23:49:24.471225 17660 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1211 23:49:32.622611 17660 solver.cpp:218] Iteration 137400 (12.2689 iter/s, 8.1507s/100 iters), loss = 0.0105364
I1211 23:49:32.622611 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:49:32.622611 17660 solver.cpp:237]     Train net output #1: loss = 0.0105363 (* 1 = 0.0105363 loss)
I1211 23:49:32.622611 17660 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1211 23:49:40.446113 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:49:40.782943 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.caffemodel
I1211 23:49:40.816306 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.solverstate
I1211 23:49:40.850335 17660 solver.cpp:330] Iteration 137500, Testing net (#0)
I1211 23:49:40.850335 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:49:42.580024 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:49:42.648030 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1211 23:49:42.648030 17660 solver.cpp:397]     Test net output #1: loss = 0.249944 (* 1 = 0.249944 loss)
I1211 23:49:42.723702 17660 solver.cpp:218] Iteration 137500 (9.90017 iter/s, 10.1008s/100 iters), loss = 0.0128036
I1211 23:49:42.723702 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:49:42.723702 17660 solver.cpp:237]     Train net output #1: loss = 0.0128035 (* 1 = 0.0128035 loss)
I1211 23:49:42.723702 17660 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1211 23:49:50.970911 17660 solver.cpp:218] Iteration 137600 (12.1265 iter/s, 8.24641s/100 iters), loss = 0.0298273
I1211 23:49:50.970911 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:49:50.970911 17660 solver.cpp:237]     Train net output #1: loss = 0.0298272 (* 1 = 0.0298272 loss)
I1211 23:49:50.970911 17660 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1211 23:49:59.187861 17660 solver.cpp:218] Iteration 137700 (12.1706 iter/s, 8.21652s/100 iters), loss = 0.0147683
I1211 23:49:59.187861 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:49:59.187861 17660 solver.cpp:237]     Train net output #1: loss = 0.0147682 (* 1 = 0.0147682 loss)
I1211 23:49:59.187861 17660 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1211 23:50:07.421756 17660 solver.cpp:218] Iteration 137800 (12.146 iter/s, 8.23317s/100 iters), loss = 0.0084381
I1211 23:50:07.421756 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:07.421756 17660 solver.cpp:237]     Train net output #1: loss = 0.00843799 (* 1 = 0.00843799 loss)
I1211 23:50:07.421756 17660 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1211 23:50:15.515162 17660 solver.cpp:218] Iteration 137900 (12.356 iter/s, 8.09327s/100 iters), loss = 0.0139707
I1211 23:50:15.515162 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:15.515162 17660 solver.cpp:237]     Train net output #1: loss = 0.0139705 (* 1 = 0.0139705 loss)
I1211 23:50:15.515162 17660 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1211 23:50:23.172304 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:50:23.493355 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.caffemodel
I1211 23:50:23.522358 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.solverstate
I1211 23:50:23.528359 17660 solver.cpp:330] Iteration 138000, Testing net (#0)
I1211 23:50:23.528359 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:50:25.208055 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:50:25.275056 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1211 23:50:25.275056 17660 solver.cpp:397]     Test net output #1: loss = 0.254069 (* 1 = 0.254069 loss)
I1211 23:50:25.350078 17660 solver.cpp:218] Iteration 138000 (10.1683 iter/s, 9.83446s/100 iters), loss = 0.0138792
I1211 23:50:25.350078 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:25.350078 17660 solver.cpp:237]     Train net output #1: loss = 0.0138791 (* 1 = 0.0138791 loss)
I1211 23:50:25.350078 17660 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1211 23:50:33.406118 17660 solver.cpp:218] Iteration 138100 (12.4148 iter/s, 8.05491s/100 iters), loss = 0.0101777
I1211 23:50:33.406118 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:33.406118 17660 solver.cpp:237]     Train net output #1: loss = 0.0101776 (* 1 = 0.0101776 loss)
I1211 23:50:33.406118 17660 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1211 23:50:41.485049 17660 solver.cpp:218] Iteration 138200 (12.3788 iter/s, 8.07831s/100 iters), loss = 0.0126058
I1211 23:50:41.485049 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:41.485049 17660 solver.cpp:237]     Train net output #1: loss = 0.0126057 (* 1 = 0.0126057 loss)
I1211 23:50:41.485049 17660 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1211 23:50:49.595226 17660 solver.cpp:218] Iteration 138300 (12.3304 iter/s, 8.11007s/100 iters), loss = 0.0102412
I1211 23:50:49.595226 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:49.595226 17660 solver.cpp:237]     Train net output #1: loss = 0.0102411 (* 1 = 0.0102411 loss)
I1211 23:50:49.595226 17660 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1211 23:50:57.678359 17660 solver.cpp:218] Iteration 138400 (12.3726 iter/s, 8.08241s/100 iters), loss = 0.0165023
I1211 23:50:57.678359 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:50:57.678359 17660 solver.cpp:237]     Train net output #1: loss = 0.0165022 (* 1 = 0.0165022 loss)
I1211 23:50:57.678359 17660 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1211 23:51:05.427196 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:51:05.745333 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.caffemodel
I1211 23:51:05.782330 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.solverstate
I1211 23:51:05.817335 17660 solver.cpp:330] Iteration 138500, Testing net (#0)
I1211 23:51:05.817335 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:51:07.520720 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:51:07.588724 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1211 23:51:07.588724 17660 solver.cpp:397]     Test net output #1: loss = 0.258142 (* 1 = 0.258142 loss)
I1211 23:51:07.663257 17660 solver.cpp:218] Iteration 138500 (10.0154 iter/s, 9.98463s/100 iters), loss = 0.0169163
I1211 23:51:07.663257 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:07.663257 17660 solver.cpp:237]     Train net output #1: loss = 0.0169161 (* 1 = 0.0169161 loss)
I1211 23:51:07.663257 17660 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1211 23:51:15.811877 17660 solver.cpp:218] Iteration 138600 (12.2737 iter/s, 8.14748s/100 iters), loss = 0.0112375
I1211 23:51:15.811877 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:15.811877 17660 solver.cpp:237]     Train net output #1: loss = 0.0112374 (* 1 = 0.0112374 loss)
I1211 23:51:15.811877 17660 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1211 23:51:23.902245 17660 solver.cpp:218] Iteration 138700 (12.3611 iter/s, 8.08987s/100 iters), loss = 0.0297665
I1211 23:51:23.902245 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:23.902245 17660 solver.cpp:237]     Train net output #1: loss = 0.0297664 (* 1 = 0.0297664 loss)
I1211 23:51:23.902245 17660 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1211 23:51:31.983865 17660 solver.cpp:218] Iteration 138800 (12.3744 iter/s, 8.08119s/100 iters), loss = 0.0162071
I1211 23:51:31.983865 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:31.983865 17660 solver.cpp:237]     Train net output #1: loss = 0.0162069 (* 1 = 0.0162069 loss)
I1211 23:51:31.983865 17660 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1211 23:51:40.068869 17660 solver.cpp:218] Iteration 138900 (12.3685 iter/s, 8.08503s/100 iters), loss = 0.0150329
I1211 23:51:40.068869 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:40.068869 17660 solver.cpp:237]     Train net output #1: loss = 0.0150328 (* 1 = 0.0150328 loss)
I1211 23:51:40.068869 17660 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1211 23:51:47.731407 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:51:48.049206 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.caffemodel
I1211 23:51:48.086220 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.solverstate
I1211 23:51:48.091223 17660 solver.cpp:330] Iteration 139000, Testing net (#0)
I1211 23:51:48.092206 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:51:49.780864 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:51:49.847877 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1211 23:51:49.847877 17660 solver.cpp:397]     Test net output #1: loss = 0.253593 (* 1 = 0.253593 loss)
I1211 23:51:49.922878 17660 solver.cpp:218] Iteration 139000 (10.1493 iter/s, 9.85294s/100 iters), loss = 0.0121999
I1211 23:51:49.922878 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:49.922878 17660 solver.cpp:237]     Train net output #1: loss = 0.0121998 (* 1 = 0.0121998 loss)
I1211 23:51:49.922878 17660 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1211 23:51:57.980212 17660 solver.cpp:218] Iteration 139100 (12.4108 iter/s, 8.05749s/100 iters), loss = 0.0119349
I1211 23:51:57.980212 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:51:57.980212 17660 solver.cpp:237]     Train net output #1: loss = 0.0119348 (* 1 = 0.0119348 loss)
I1211 23:51:57.980212 17660 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1211 23:52:06.060191 17660 solver.cpp:218] Iteration 139200 (12.3777 iter/s, 8.07905s/100 iters), loss = 0.0138712
I1211 23:52:06.060191 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:52:06.060191 17660 solver.cpp:237]     Train net output #1: loss = 0.0138711 (* 1 = 0.0138711 loss)
I1211 23:52:06.060191 17660 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1211 23:52:14.171869 17660 solver.cpp:218] Iteration 139300 (12.3289 iter/s, 8.11101s/100 iters), loss = 0.0116495
I1211 23:52:14.171869 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:52:14.171869 17660 solver.cpp:237]     Train net output #1: loss = 0.0116494 (* 1 = 0.0116494 loss)
I1211 23:52:14.171869 17660 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1211 23:52:22.248411 17660 solver.cpp:218] Iteration 139400 (12.3827 iter/s, 8.07577s/100 iters), loss = 0.0148472
I1211 23:52:22.248411 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:52:22.248411 17660 solver.cpp:237]     Train net output #1: loss = 0.0148471 (* 1 = 0.0148471 loss)
I1211 23:52:22.248411 17660 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1211 23:52:29.943598 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:52:30.264925 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.caffemodel
I1211 23:52:30.297929 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.solverstate
I1211 23:52:30.324981 17660 solver.cpp:330] Iteration 139500, Testing net (#0)
I1211 23:52:30.324981 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:52:32.007946 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:52:32.073956 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1211 23:52:32.073956 17660 solver.cpp:397]     Test net output #1: loss = 0.25293 (* 1 = 0.25293 loss)
I1211 23:52:32.149713 17660 solver.cpp:218] Iteration 139500 (10.1002 iter/s, 9.90078s/100 iters), loss = 0.0129963
I1211 23:52:32.149713 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:52:32.149713 17660 solver.cpp:237]     Train net output #1: loss = 0.0129961 (* 1 = 0.0129961 loss)
I1211 23:52:32.149713 17660 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1211 23:52:40.225222 17660 solver.cpp:218] Iteration 139600 (12.3839 iter/s, 8.07503s/100 iters), loss = 0.0136615
I1211 23:52:40.225222 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:52:40.225222 17660 solver.cpp:237]     Train net output #1: loss = 0.0136614 (* 1 = 0.0136614 loss)
I1211 23:52:40.225222 17660 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1211 23:52:48.319399 17660 solver.cpp:218] Iteration 139700 (12.3549 iter/s, 8.09396s/100 iters), loss = 0.036873
I1211 23:52:48.319900 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:52:48.319900 17660 solver.cpp:237]     Train net output #1: loss = 0.0368729 (* 1 = 0.0368729 loss)
I1211 23:52:48.319900 17660 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1211 23:52:56.388414 17660 solver.cpp:218] Iteration 139800 (12.3938 iter/s, 8.06854s/100 iters), loss = 0.0114007
I1211 23:52:56.388414 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:52:56.388414 17660 solver.cpp:237]     Train net output #1: loss = 0.0114006 (* 1 = 0.0114006 loss)
I1211 23:52:56.388414 17660 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1211 23:53:04.454496 17660 solver.cpp:218] Iteration 139900 (12.3981 iter/s, 8.06574s/100 iters), loss = 0.00928289
I1211 23:53:04.454496 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:04.454496 17660 solver.cpp:237]     Train net output #1: loss = 0.00928277 (* 1 = 0.00928277 loss)
I1211 23:53:04.454496 17660 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1211 23:53:12.152369 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:53:12.472425 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.caffemodel
I1211 23:53:12.501425 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.solverstate
I1211 23:53:12.506425 17660 solver.cpp:330] Iteration 140000, Testing net (#0)
I1211 23:53:12.507426 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:53:14.187566 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:53:14.255586 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 23:53:14.256580 17660 solver.cpp:397]     Test net output #1: loss = 0.252889 (* 1 = 0.252889 loss)
I1211 23:53:14.331081 17660 solver.cpp:218] Iteration 140000 (10.1262 iter/s, 9.87541s/100 iters), loss = 0.0143142
I1211 23:53:14.331081 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:14.331081 17660 solver.cpp:237]     Train net output #1: loss = 0.0143141 (* 1 = 0.0143141 loss)
I1211 23:53:14.331081 17660 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1211 23:53:22.449807 17660 solver.cpp:218] Iteration 140100 (12.3178 iter/s, 8.11833s/100 iters), loss = 0.0128313
I1211 23:53:22.449807 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:22.449807 17660 solver.cpp:237]     Train net output #1: loss = 0.0128312 (* 1 = 0.0128312 loss)
I1211 23:53:22.449807 17660 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1211 23:53:30.531467 17660 solver.cpp:218] Iteration 140200 (12.3747 iter/s, 8.08098s/100 iters), loss = 0.0110475
I1211 23:53:30.531467 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:30.531467 17660 solver.cpp:237]     Train net output #1: loss = 0.0110474 (* 1 = 0.0110474 loss)
I1211 23:53:30.531467 17660 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1211 23:53:38.655691 17660 solver.cpp:218] Iteration 140300 (12.3087 iter/s, 8.12435s/100 iters), loss = 0.0110399
I1211 23:53:38.655691 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:38.655691 17660 solver.cpp:237]     Train net output #1: loss = 0.0110398 (* 1 = 0.0110398 loss)
I1211 23:53:38.655691 17660 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1211 23:53:46.811900 17660 solver.cpp:218] Iteration 140400 (12.262 iter/s, 8.15525s/100 iters), loss = 0.0130048
I1211 23:53:46.811900 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:46.811900 17660 solver.cpp:237]     Train net output #1: loss = 0.0130047 (* 1 = 0.0130047 loss)
I1211 23:53:46.811900 17660 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1211 23:53:54.604957 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:53:54.928020 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.caffemodel
I1211 23:53:54.960036 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.solverstate
I1211 23:53:54.991035 17660 solver.cpp:330] Iteration 140500, Testing net (#0)
I1211 23:53:54.992038 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:53:56.681192 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:53:56.749697 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1211 23:53:56.749697 17660 solver.cpp:397]     Test net output #1: loss = 0.256904 (* 1 = 0.256904 loss)
I1211 23:53:56.824203 17660 solver.cpp:218] Iteration 140500 (9.98787 iter/s, 10.0121s/100 iters), loss = 0.016551
I1211 23:53:56.824203 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:53:56.824203 17660 solver.cpp:237]     Train net output #1: loss = 0.0165509 (* 1 = 0.0165509 loss)
I1211 23:53:56.824203 17660 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1211 23:54:04.893018 17660 solver.cpp:218] Iteration 140600 (12.3946 iter/s, 8.06805s/100 iters), loss = 0.00893078
I1211 23:54:04.893018 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:04.893018 17660 solver.cpp:237]     Train net output #1: loss = 0.00893066 (* 1 = 0.00893066 loss)
I1211 23:54:04.893018 17660 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1211 23:54:13.010936 17660 solver.cpp:218] Iteration 140700 (12.3194 iter/s, 8.11731s/100 iters), loss = 0.0132035
I1211 23:54:13.010936 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:13.010936 17660 solver.cpp:237]     Train net output #1: loss = 0.0132033 (* 1 = 0.0132033 loss)
I1211 23:54:13.010936 17660 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1211 23:54:21.149178 17660 solver.cpp:218] Iteration 140800 (12.289 iter/s, 8.13736s/100 iters), loss = 0.0193707
I1211 23:54:21.149178 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:21.149178 17660 solver.cpp:237]     Train net output #1: loss = 0.0193706 (* 1 = 0.0193706 loss)
I1211 23:54:21.149178 17660 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1211 23:54:29.247619 17660 solver.cpp:218] Iteration 140900 (12.3488 iter/s, 8.09796s/100 iters), loss = 0.0109401
I1211 23:54:29.247619 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:29.247619 17660 solver.cpp:237]     Train net output #1: loss = 0.01094 (* 1 = 0.01094 loss)
I1211 23:54:29.247619 17660 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1211 23:54:36.957068 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:54:37.275108 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.caffemodel
I1211 23:54:37.309109 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.solverstate
I1211 23:54:37.341107 17660 solver.cpp:330] Iteration 141000, Testing net (#0)
I1211 23:54:37.341107 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:54:39.026347 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:54:39.093358 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1211 23:54:39.093358 17660 solver.cpp:397]     Test net output #1: loss = 0.256664 (* 1 = 0.256664 loss)
I1211 23:54:39.168362 17660 solver.cpp:218] Iteration 141000 (10.0802 iter/s, 9.92048s/100 iters), loss = 0.0132025
I1211 23:54:39.168362 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:39.168362 17660 solver.cpp:237]     Train net output #1: loss = 0.0132024 (* 1 = 0.0132024 loss)
I1211 23:54:39.168362 17660 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1211 23:54:47.287067 17660 solver.cpp:218] Iteration 141100 (12.3175 iter/s, 8.11852s/100 iters), loss = 0.0167381
I1211 23:54:47.288080 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:47.288080 17660 solver.cpp:237]     Train net output #1: loss = 0.0167379 (* 1 = 0.0167379 loss)
I1211 23:54:47.288080 17660 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1211 23:54:55.421319 17660 solver.cpp:218] Iteration 141200 (12.2958 iter/s, 8.13284s/100 iters), loss = 0.0105179
I1211 23:54:55.421319 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:54:55.421319 17660 solver.cpp:237]     Train net output #1: loss = 0.0105178 (* 1 = 0.0105178 loss)
I1211 23:54:55.421319 17660 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1211 23:55:03.528038 17660 solver.cpp:218] Iteration 141300 (12.3359 iter/s, 8.1064s/100 iters), loss = 0.017883
I1211 23:55:03.528038 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:03.528038 17660 solver.cpp:237]     Train net output #1: loss = 0.0178829 (* 1 = 0.0178829 loss)
I1211 23:55:03.528038 17660 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1211 23:55:11.645241 17660 solver.cpp:218] Iteration 141400 (12.3194 iter/s, 8.11727s/100 iters), loss = 0.0131635
I1211 23:55:11.646240 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:11.646240 17660 solver.cpp:237]     Train net output #1: loss = 0.0131634 (* 1 = 0.0131634 loss)
I1211 23:55:11.646240 17660 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1211 23:55:19.367640 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:55:19.687026 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.caffemodel
I1211 23:55:19.714550 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.solverstate
I1211 23:55:19.721549 17660 solver.cpp:330] Iteration 141500, Testing net (#0)
I1211 23:55:19.721549 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:55:21.402729 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:55:21.470727 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1211 23:55:21.470727 17660 solver.cpp:397]     Test net output #1: loss = 0.257176 (* 1 = 0.257176 loss)
I1211 23:55:21.545234 17660 solver.cpp:218] Iteration 141500 (10.1021 iter/s, 9.89888s/100 iters), loss = 0.00964639
I1211 23:55:21.545234 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:21.545234 17660 solver.cpp:237]     Train net output #1: loss = 0.00964627 (* 1 = 0.00964627 loss)
I1211 23:55:21.545234 17660 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1211 23:55:29.613595 17660 solver.cpp:218] Iteration 141600 (12.3944 iter/s, 8.06813s/100 iters), loss = 0.0211056
I1211 23:55:29.613595 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:29.613595 17660 solver.cpp:237]     Train net output #1: loss = 0.0211054 (* 1 = 0.0211054 loss)
I1211 23:55:29.613595 17660 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1211 23:55:37.727471 17660 solver.cpp:218] Iteration 141700 (12.3261 iter/s, 8.11284s/100 iters), loss = 0.0158488
I1211 23:55:37.727471 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:37.727471 17660 solver.cpp:237]     Train net output #1: loss = 0.0158486 (* 1 = 0.0158486 loss)
I1211 23:55:37.727471 17660 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1211 23:55:45.828197 17660 solver.cpp:218] Iteration 141800 (12.3449 iter/s, 8.10052s/100 iters), loss = 0.0108145
I1211 23:55:45.828197 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:45.828197 17660 solver.cpp:237]     Train net output #1: loss = 0.0108144 (* 1 = 0.0108144 loss)
I1211 23:55:45.828197 17660 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1211 23:55:53.912956 17660 solver.cpp:218] Iteration 141900 (12.3697 iter/s, 8.08428s/100 iters), loss = 0.0125572
I1211 23:55:53.912956 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:55:53.912956 17660 solver.cpp:237]     Train net output #1: loss = 0.0125571 (* 1 = 0.0125571 loss)
I1211 23:55:53.912956 17660 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1211 23:56:01.590124 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:56:01.908177 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.caffemodel
I1211 23:56:01.939177 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.solverstate
I1211 23:56:01.945178 17660 solver.cpp:330] Iteration 142000, Testing net (#0)
I1211 23:56:01.945178 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:56:03.642402 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:56:03.711405 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1211 23:56:03.711405 17660 solver.cpp:397]     Test net output #1: loss = 0.255524 (* 1 = 0.255524 loss)
I1211 23:56:03.787405 17660 solver.cpp:218] Iteration 142000 (10.1283 iter/s, 9.87334s/100 iters), loss = 0.0115544
I1211 23:56:03.787405 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:03.787405 17660 solver.cpp:237]     Train net output #1: loss = 0.0115543 (* 1 = 0.0115543 loss)
I1211 23:56:03.787405 17660 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1211 23:56:11.978796 17660 solver.cpp:218] Iteration 142100 (12.208 iter/s, 8.19133s/100 iters), loss = 0.0145727
I1211 23:56:11.978796 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:11.978796 17660 solver.cpp:237]     Train net output #1: loss = 0.0145725 (* 1 = 0.0145725 loss)
I1211 23:56:11.978796 17660 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1211 23:56:20.147193 17660 solver.cpp:218] Iteration 142200 (12.2437 iter/s, 8.16749s/100 iters), loss = 0.0135143
I1211 23:56:20.147193 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:20.147193 17660 solver.cpp:237]     Train net output #1: loss = 0.0135142 (* 1 = 0.0135142 loss)
I1211 23:56:20.147193 17660 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1211 23:56:28.462199 17660 solver.cpp:218] Iteration 142300 (12.0267 iter/s, 8.31481s/100 iters), loss = 0.0115153
I1211 23:56:28.462199 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:28.462199 17660 solver.cpp:237]     Train net output #1: loss = 0.0115152 (* 1 = 0.0115152 loss)
I1211 23:56:28.462199 17660 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1211 23:56:36.563161 17660 solver.cpp:218] Iteration 142400 (12.3446 iter/s, 8.10074s/100 iters), loss = 0.0103605
I1211 23:56:36.564162 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:36.564162 17660 solver.cpp:237]     Train net output #1: loss = 0.0103604 (* 1 = 0.0103604 loss)
I1211 23:56:36.564162 17660 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1211 23:56:44.297201 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:56:44.618230 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.caffemodel
I1211 23:56:44.648872 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.solverstate
I1211 23:56:44.682885 17660 solver.cpp:330] Iteration 142500, Testing net (#0)
I1211 23:56:44.683876 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:56:46.376559 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:56:46.443567 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1211 23:56:46.443567 17660 solver.cpp:397]     Test net output #1: loss = 0.253875 (* 1 = 0.253875 loss)
I1211 23:56:46.519587 17660 solver.cpp:218] Iteration 142500 (10.0449 iter/s, 9.95533s/100 iters), loss = 0.0153757
I1211 23:56:46.520087 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:46.520087 17660 solver.cpp:237]     Train net output #1: loss = 0.0153756 (* 1 = 0.0153756 loss)
I1211 23:56:46.520087 17660 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1211 23:56:54.641232 17660 solver.cpp:218] Iteration 142600 (12.3134 iter/s, 8.12124s/100 iters), loss = 0.00976358
I1211 23:56:54.641232 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:56:54.641232 17660 solver.cpp:237]     Train net output #1: loss = 0.00976345 (* 1 = 0.00976345 loss)
I1211 23:56:54.641232 17660 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1211 23:57:02.725878 17660 solver.cpp:218] Iteration 142700 (12.3705 iter/s, 8.08378s/100 iters), loss = 0.0110131
I1211 23:57:02.725878 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:02.725878 17660 solver.cpp:237]     Train net output #1: loss = 0.011013 (* 1 = 0.011013 loss)
I1211 23:57:02.725878 17660 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1211 23:57:10.822656 17660 solver.cpp:218] Iteration 142800 (12.3515 iter/s, 8.09621s/100 iters), loss = 0.0138849
I1211 23:57:10.822656 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:10.822656 17660 solver.cpp:237]     Train net output #1: loss = 0.0138847 (* 1 = 0.0138847 loss)
I1211 23:57:10.822656 17660 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1211 23:57:18.893604 17660 solver.cpp:218] Iteration 142900 (12.3911 iter/s, 8.07028s/100 iters), loss = 0.0151668
I1211 23:57:18.893604 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:18.893604 17660 solver.cpp:237]     Train net output #1: loss = 0.0151667 (* 1 = 0.0151667 loss)
I1211 23:57:18.893604 17660 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1211 23:57:26.605978 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:57:26.929021 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.caffemodel
I1211 23:57:26.957028 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.solverstate
I1211 23:57:26.963028 17660 solver.cpp:330] Iteration 143000, Testing net (#0)
I1211 23:57:26.964028 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:57:28.652179 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:57:28.719183 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9305
I1211 23:57:28.719183 17660 solver.cpp:397]     Test net output #1: loss = 0.263987 (* 1 = 0.263987 loss)
I1211 23:57:28.793190 17660 solver.cpp:218] Iteration 143000 (10.1012 iter/s, 9.89979s/100 iters), loss = 0.0168155
I1211 23:57:28.793190 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:28.793190 17660 solver.cpp:237]     Train net output #1: loss = 0.0168154 (* 1 = 0.0168154 loss)
I1211 23:57:28.793190 17660 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1211 23:57:36.871888 17660 solver.cpp:218] Iteration 143100 (12.3796 iter/s, 8.07778s/100 iters), loss = 0.0105849
I1211 23:57:36.871888 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:36.871888 17660 solver.cpp:237]     Train net output #1: loss = 0.0105848 (* 1 = 0.0105848 loss)
I1211 23:57:36.871888 17660 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1211 23:57:45.004842 17660 solver.cpp:218] Iteration 143200 (12.297 iter/s, 8.13206s/100 iters), loss = 0.0101966
I1211 23:57:45.004842 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:45.004842 17660 solver.cpp:237]     Train net output #1: loss = 0.0101965 (* 1 = 0.0101965 loss)
I1211 23:57:45.004842 17660 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1211 23:57:53.175331 17660 solver.cpp:218] Iteration 143300 (12.2396 iter/s, 8.17022s/100 iters), loss = 0.00971847
I1211 23:57:53.175331 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:57:53.175331 17660 solver.cpp:237]     Train net output #1: loss = 0.00971834 (* 1 = 0.00971834 loss)
I1211 23:57:53.175331 17660 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1211 23:58:01.493383 17660 solver.cpp:218] Iteration 143400 (12.0225 iter/s, 8.31773s/100 iters), loss = 0.0102533
I1211 23:58:01.493383 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:01.493383 17660 solver.cpp:237]     Train net output #1: loss = 0.0102531 (* 1 = 0.0102531 loss)
I1211 23:58:01.493383 17660 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1211 23:58:09.211045 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:58:09.529104 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.caffemodel
I1211 23:58:09.557610 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.solverstate
I1211 23:58:09.583137 17660 solver.cpp:330] Iteration 143500, Testing net (#0)
I1211 23:58:09.584144 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:58:11.271323 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:58:11.337318 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1211 23:58:11.337318 17660 solver.cpp:397]     Test net output #1: loss = 0.257953 (* 1 = 0.257953 loss)
I1211 23:58:11.412328 17660 solver.cpp:218] Iteration 143500 (10.083 iter/s, 9.91766s/100 iters), loss = 0.0132799
I1211 23:58:11.412328 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:11.412328 17660 solver.cpp:237]     Train net output #1: loss = 0.0132798 (* 1 = 0.0132798 loss)
I1211 23:58:11.412328 17660 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1211 23:58:19.581637 17660 solver.cpp:218] Iteration 143600 (12.2406 iter/s, 8.1695s/100 iters), loss = 0.0128866
I1211 23:58:19.581637 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:19.581637 17660 solver.cpp:237]     Train net output #1: loss = 0.0128865 (* 1 = 0.0128865 loss)
I1211 23:58:19.581637 17660 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1211 23:58:27.705775 17660 solver.cpp:218] Iteration 143700 (12.3097 iter/s, 8.12366s/100 iters), loss = 0.0196037
I1211 23:58:27.705775 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:27.705775 17660 solver.cpp:237]     Train net output #1: loss = 0.0196036 (* 1 = 0.0196036 loss)
I1211 23:58:27.705775 17660 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1211 23:58:35.780138 17660 solver.cpp:218] Iteration 143800 (12.3866 iter/s, 8.07327s/100 iters), loss = 0.00925786
I1211 23:58:35.780138 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:35.780138 17660 solver.cpp:237]     Train net output #1: loss = 0.00925773 (* 1 = 0.00925773 loss)
I1211 23:58:35.780138 17660 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1211 23:58:43.872326 17660 solver.cpp:218] Iteration 143900 (12.359 iter/s, 8.09126s/100 iters), loss = 0.0114859
I1211 23:58:43.872326 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:43.872326 17660 solver.cpp:237]     Train net output #1: loss = 0.0114857 (* 1 = 0.0114857 loss)
I1211 23:58:43.872326 17660 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1211 23:58:51.550897 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:58:51.870108 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.caffemodel
I1211 23:58:51.899129 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.solverstate
I1211 23:58:51.905127 17660 solver.cpp:330] Iteration 144000, Testing net (#0)
I1211 23:58:51.905127 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:58:53.590201 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:58:53.657189 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1211 23:58:53.657189 17660 solver.cpp:397]     Test net output #1: loss = 0.256525 (* 1 = 0.256525 loss)
I1211 23:58:53.733307 17660 solver.cpp:218] Iteration 144000 (10.1408 iter/s, 9.86111s/100 iters), loss = 0.0148689
I1211 23:58:53.733307 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:58:53.733307 17660 solver.cpp:237]     Train net output #1: loss = 0.0148688 (* 1 = 0.0148688 loss)
I1211 23:58:53.733307 17660 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1211 23:59:01.827787 17660 solver.cpp:218] Iteration 144100 (12.3556 iter/s, 8.09353s/100 iters), loss = 0.029438
I1211 23:59:01.827787 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1211 23:59:01.827787 17660 solver.cpp:237]     Train net output #1: loss = 0.0294379 (* 1 = 0.0294379 loss)
I1211 23:59:01.827787 17660 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1211 23:59:10.039937 17660 solver.cpp:218] Iteration 144200 (12.1774 iter/s, 8.21196s/100 iters), loss = 0.0163876
I1211 23:59:10.039937 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:59:10.039937 17660 solver.cpp:237]     Train net output #1: loss = 0.0163875 (* 1 = 0.0163875 loss)
I1211 23:59:10.039937 17660 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1211 23:59:18.181491 17660 solver.cpp:218] Iteration 144300 (12.2847 iter/s, 8.14018s/100 iters), loss = 0.0126982
I1211 23:59:18.181491 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:59:18.181491 17660 solver.cpp:237]     Train net output #1: loss = 0.012698 (* 1 = 0.012698 loss)
I1211 23:59:18.181491 17660 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1211 23:59:26.358777 17660 solver.cpp:218] Iteration 144400 (12.2298 iter/s, 8.17675s/100 iters), loss = 0.015455
I1211 23:59:26.358777 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:59:26.358777 17660 solver.cpp:237]     Train net output #1: loss = 0.0154549 (* 1 = 0.0154549 loss)
I1211 23:59:26.358777 17660 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1211 23:59:34.144757 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:59:34.464792 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.caffemodel
I1211 23:59:34.493818 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.solverstate
I1211 23:59:34.525023 17660 solver.cpp:330] Iteration 144500, Testing net (#0)
I1211 23:59:34.525023 17660 net.cpp:676] Ignoring source layer accuracy_training
I1211 23:59:36.210882 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1211 23:59:36.278389 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1211 23:59:36.278389 17660 solver.cpp:397]     Test net output #1: loss = 0.252005 (* 1 = 0.252005 loss)
I1211 23:59:36.352757 17660 solver.cpp:218] Iteration 144500 (10.0067 iter/s, 9.99331s/100 iters), loss = 0.013782
I1211 23:59:36.352757 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:59:36.352757 17660 solver.cpp:237]     Train net output #1: loss = 0.0137819 (* 1 = 0.0137819 loss)
I1211 23:59:36.352757 17660 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1211 23:59:44.525902 17660 solver.cpp:218] Iteration 144600 (12.2357 iter/s, 8.1728s/100 iters), loss = 0.010557
I1211 23:59:44.525902 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:59:44.525902 17660 solver.cpp:237]     Train net output #1: loss = 0.0105569 (* 1 = 0.0105569 loss)
I1211 23:59:44.525902 17660 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1211 23:59:52.770334 17660 solver.cpp:218] Iteration 144700 (12.1298 iter/s, 8.24415s/100 iters), loss = 0.00898308
I1211 23:59:52.770334 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1211 23:59:52.770334 17660 solver.cpp:237]     Train net output #1: loss = 0.00898296 (* 1 = 0.00898296 loss)
I1211 23:59:52.770334 17660 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1212 00:00:00.954994 17660 solver.cpp:218] Iteration 144800 (12.2197 iter/s, 8.18348s/100 iters), loss = 0.011396
I1212 00:00:00.954994 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:00:00.954994 17660 solver.cpp:237]     Train net output #1: loss = 0.0113959 (* 1 = 0.0113959 loss)
I1212 00:00:00.954994 17660 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1212 00:00:09.097470 17660 solver.cpp:218] Iteration 144900 (12.2819 iter/s, 8.14205s/100 iters), loss = 0.0142365
I1212 00:00:09.097470 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:00:09.097470 17660 solver.cpp:237]     Train net output #1: loss = 0.0142364 (* 1 = 0.0142364 loss)
I1212 00:00:09.097470 17660 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1212 00:00:16.811581 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:00:17.129580 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.caffemodel
I1212 00:00:17.160106 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.solverstate
I1212 00:00:17.166606 17660 solver.cpp:330] Iteration 145000, Testing net (#0)
I1212 00:00:17.167106 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:00:18.857533 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:00:18.926043 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1212 00:00:18.926043 17660 solver.cpp:397]     Test net output #1: loss = 0.253935 (* 1 = 0.253935 loss)
I1212 00:00:19.002051 17660 solver.cpp:218] Iteration 145000 (10.0967 iter/s, 9.90427s/100 iters), loss = 0.0145217
I1212 00:00:19.002051 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:00:19.002051 17660 solver.cpp:237]     Train net output #1: loss = 0.0145216 (* 1 = 0.0145216 loss)
I1212 00:00:19.002051 17660 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1212 00:00:27.072855 17660 solver.cpp:218] Iteration 145100 (12.3912 iter/s, 8.07025s/100 iters), loss = 0.0194441
I1212 00:00:27.072855 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:00:27.073355 17660 solver.cpp:237]     Train net output #1: loss = 0.0194439 (* 1 = 0.0194439 loss)
I1212 00:00:27.073355 17660 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1212 00:00:35.178195 17660 solver.cpp:218] Iteration 145200 (12.338 iter/s, 8.10505s/100 iters), loss = 0.0110064
I1212 00:00:35.178195 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:00:35.178195 17660 solver.cpp:237]     Train net output #1: loss = 0.0110062 (* 1 = 0.0110062 loss)
I1212 00:00:35.178195 17660 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1212 00:00:43.291600 17660 solver.cpp:218] Iteration 145300 (12.327 iter/s, 8.11225s/100 iters), loss = 0.00999319
I1212 00:00:43.291600 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:00:43.291600 17660 solver.cpp:237]     Train net output #1: loss = 0.00999307 (* 1 = 0.00999307 loss)
I1212 00:00:43.291600 17660 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1212 00:00:51.380864 17660 solver.cpp:218] Iteration 145400 (12.3616 iter/s, 8.08958s/100 iters), loss = 0.0223093
I1212 00:00:51.381865 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:00:51.381865 17660 solver.cpp:237]     Train net output #1: loss = 0.0223092 (* 1 = 0.0223092 loss)
I1212 00:00:51.381865 17660 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1212 00:00:59.067735 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:00:59.390293 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.caffemodel
I1212 00:00:59.426822 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.solverstate
I1212 00:00:59.432818 17660 solver.cpp:330] Iteration 145500, Testing net (#0)
I1212 00:00:59.433809 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:01:01.113947 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:01:01.181946 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1212 00:01:01.181946 17660 solver.cpp:397]     Test net output #1: loss = 0.262347 (* 1 = 0.262347 loss)
I1212 00:01:01.256953 17660 solver.cpp:218] Iteration 145500 (10.1263 iter/s, 9.87523s/100 iters), loss = 0.016607
I1212 00:01:01.256953 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:01.256953 17660 solver.cpp:237]     Train net output #1: loss = 0.0166069 (* 1 = 0.0166069 loss)
I1212 00:01:01.256953 17660 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1212 00:01:09.322389 17660 solver.cpp:218] Iteration 145600 (12.4005 iter/s, 8.06421s/100 iters), loss = 0.0250557
I1212 00:01:09.322389 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:09.322389 17660 solver.cpp:237]     Train net output #1: loss = 0.0250556 (* 1 = 0.0250556 loss)
I1212 00:01:09.322389 17660 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1212 00:01:17.400049 17660 solver.cpp:218] Iteration 145700 (12.3793 iter/s, 8.07801s/100 iters), loss = 0.011137
I1212 00:01:17.400049 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:17.400049 17660 solver.cpp:237]     Train net output #1: loss = 0.0111369 (* 1 = 0.0111369 loss)
I1212 00:01:17.401051 17660 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1212 00:01:25.494941 17660 solver.cpp:218] Iteration 145800 (12.3552 iter/s, 8.09375s/100 iters), loss = 0.0119464
I1212 00:01:25.494941 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:25.494941 17660 solver.cpp:237]     Train net output #1: loss = 0.0119463 (* 1 = 0.0119463 loss)
I1212 00:01:25.494941 17660 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1212 00:01:33.572625 17660 solver.cpp:218] Iteration 145900 (12.3798 iter/s, 8.07771s/100 iters), loss = 0.011365
I1212 00:01:33.572625 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:33.572625 17660 solver.cpp:237]     Train net output #1: loss = 0.0113649 (* 1 = 0.0113649 loss)
I1212 00:01:33.572625 17660 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1212 00:01:41.228700 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:01:41.545943 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.caffemodel
I1212 00:01:41.574031 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.solverstate
I1212 00:01:41.608036 17660 solver.cpp:330] Iteration 146000, Testing net (#0)
I1212 00:01:41.608036 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:01:43.292918 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:01:43.359438 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1212 00:01:43.359938 17660 solver.cpp:397]     Test net output #1: loss = 0.253349 (* 1 = 0.253349 loss)
I1212 00:01:43.436648 17660 solver.cpp:218] Iteration 146000 (10.1392 iter/s, 9.86273s/100 iters), loss = 0.0137347
I1212 00:01:43.436648 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:43.436648 17660 solver.cpp:237]     Train net output #1: loss = 0.0137346 (* 1 = 0.0137346 loss)
I1212 00:01:43.436648 17660 sgd_solver.cpp:105] Iteration 146000, lr = 0.001
I1212 00:01:51.493536 17660 solver.cpp:218] Iteration 146100 (12.4115 iter/s, 8.05706s/100 iters), loss = 0.0111549
I1212 00:01:51.493536 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:51.493536 17660 solver.cpp:237]     Train net output #1: loss = 0.0111548 (* 1 = 0.0111548 loss)
I1212 00:01:51.494536 17660 sgd_solver.cpp:105] Iteration 146100, lr = 0.001
I1212 00:01:59.543303 17660 solver.cpp:218] Iteration 146200 (12.4235 iter/s, 8.04923s/100 iters), loss = 0.00977598
I1212 00:01:59.543303 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:01:59.543303 17660 solver.cpp:237]     Train net output #1: loss = 0.00977587 (* 1 = 0.00977587 loss)
I1212 00:01:59.543303 17660 sgd_solver.cpp:105] Iteration 146200, lr = 0.001
I1212 00:02:07.601655 17660 solver.cpp:218] Iteration 146300 (12.4116 iter/s, 8.05701s/100 iters), loss = 0.0136193
I1212 00:02:07.601655 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:07.601655 17660 solver.cpp:237]     Train net output #1: loss = 0.0136192 (* 1 = 0.0136192 loss)
I1212 00:02:07.601655 17660 sgd_solver.cpp:105] Iteration 146300, lr = 0.001
I1212 00:02:15.656747 17660 solver.cpp:218] Iteration 146400 (12.4151 iter/s, 8.05468s/100 iters), loss = 0.00975557
I1212 00:02:15.656747 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:15.656747 17660 solver.cpp:237]     Train net output #1: loss = 0.00975546 (* 1 = 0.00975546 loss)
I1212 00:02:15.656747 17660 sgd_solver.cpp:105] Iteration 146400, lr = 0.001
I1212 00:02:23.320953 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:02:23.639526 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146500.caffemodel
I1212 00:02:23.669525 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146500.solverstate
I1212 00:02:23.676054 17660 solver.cpp:330] Iteration 146500, Testing net (#0)
I1212 00:02:23.676532 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:02:25.353741 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:02:25.421963 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1212 00:02:25.421963 17660 solver.cpp:397]     Test net output #1: loss = 0.257857 (* 1 = 0.257857 loss)
I1212 00:02:25.497309 17660 solver.cpp:218] Iteration 146500 (10.1623 iter/s, 9.84025s/100 iters), loss = 0.0146401
I1212 00:02:25.497309 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:25.497309 17660 solver.cpp:237]     Train net output #1: loss = 0.01464 (* 1 = 0.01464 loss)
I1212 00:02:25.497309 17660 sgd_solver.cpp:105] Iteration 146500, lr = 0.001
I1212 00:02:33.551841 17660 solver.cpp:218] Iteration 146600 (12.4161 iter/s, 8.05403s/100 iters), loss = 0.0140188
I1212 00:02:33.551841 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:33.551841 17660 solver.cpp:237]     Train net output #1: loss = 0.0140187 (* 1 = 0.0140187 loss)
I1212 00:02:33.551841 17660 sgd_solver.cpp:105] Iteration 146600, lr = 0.001
I1212 00:02:41.601689 17660 solver.cpp:218] Iteration 146700 (12.4233 iter/s, 8.0494s/100 iters), loss = 0.0153284
I1212 00:02:41.601689 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:41.601689 17660 solver.cpp:237]     Train net output #1: loss = 0.0153282 (* 1 = 0.0153282 loss)
I1212 00:02:41.601689 17660 sgd_solver.cpp:105] Iteration 146700, lr = 0.001
I1212 00:02:49.661355 17660 solver.cpp:218] Iteration 146800 (12.4079 iter/s, 8.05941s/100 iters), loss = 0.0107907
I1212 00:02:49.661355 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:49.661355 17660 solver.cpp:237]     Train net output #1: loss = 0.0107905 (* 1 = 0.0107905 loss)
I1212 00:02:49.661355 17660 sgd_solver.cpp:105] Iteration 146800, lr = 0.001
I1212 00:02:57.711313 17660 solver.cpp:218] Iteration 146900 (12.4238 iter/s, 8.04907s/100 iters), loss = 0.0141481
I1212 00:02:57.711313 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:02:57.711313 17660 solver.cpp:237]     Train net output #1: loss = 0.014148 (* 1 = 0.014148 loss)
I1212 00:02:57.711313 17660 sgd_solver.cpp:105] Iteration 146900, lr = 0.001
I1212 00:03:05.368240 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:03:05.687283 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147000.caffemodel
I1212 00:03:05.728307 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147000.solverstate
I1212 00:03:05.742292 17660 solver.cpp:330] Iteration 147000, Testing net (#0)
I1212 00:03:05.742292 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:03:07.426447 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:03:07.493450 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1212 00:03:07.493450 17660 solver.cpp:397]     Test net output #1: loss = 0.254995 (* 1 = 0.254995 loss)
I1212 00:03:07.568451 17660 solver.cpp:218] Iteration 147000 (10.1456 iter/s, 9.85648s/100 iters), loss = 0.0108041
I1212 00:03:07.568451 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:07.568451 17660 solver.cpp:237]     Train net output #1: loss = 0.010804 (* 1 = 0.010804 loss)
I1212 00:03:07.568451 17660 sgd_solver.cpp:105] Iteration 147000, lr = 0.001
I1212 00:03:15.627899 17660 solver.cpp:218] Iteration 147100 (12.4083 iter/s, 8.0591s/100 iters), loss = 0.0158638
I1212 00:03:15.627899 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:15.627899 17660 solver.cpp:237]     Train net output #1: loss = 0.0158637 (* 1 = 0.0158637 loss)
I1212 00:03:15.627899 17660 sgd_solver.cpp:105] Iteration 147100, lr = 0.001
I1212 00:03:23.692219 17660 solver.cpp:218] Iteration 147200 (12.4013 iter/s, 8.06366s/100 iters), loss = 0.0148956
I1212 00:03:23.692219 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:23.692219 17660 solver.cpp:237]     Train net output #1: loss = 0.0148955 (* 1 = 0.0148955 loss)
I1212 00:03:23.692219 17660 sgd_solver.cpp:105] Iteration 147200, lr = 0.001
I1212 00:03:31.752238 17660 solver.cpp:218] Iteration 147300 (12.4077 iter/s, 8.05951s/100 iters), loss = 0.0120103
I1212 00:03:31.752238 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:31.752238 17660 solver.cpp:237]     Train net output #1: loss = 0.0120101 (* 1 = 0.0120101 loss)
I1212 00:03:31.752238 17660 sgd_solver.cpp:105] Iteration 147300, lr = 0.001
I1212 00:03:39.805630 17660 solver.cpp:218] Iteration 147400 (12.4176 iter/s, 8.05309s/100 iters), loss = 0.0131322
I1212 00:03:39.805630 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:39.805630 17660 solver.cpp:237]     Train net output #1: loss = 0.0131321 (* 1 = 0.0131321 loss)
I1212 00:03:39.805630 17660 sgd_solver.cpp:105] Iteration 147400, lr = 0.001
I1212 00:03:47.469528 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:03:47.786646 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147500.caffemodel
I1212 00:03:47.815659 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_147500.solverstate
I1212 00:03:47.821674 17660 solver.cpp:330] Iteration 147500, Testing net (#0)
I1212 00:03:47.821674 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:03:49.503659 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:03:49.569995 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1212 00:03:49.569995 17660 solver.cpp:397]     Test net output #1: loss = 0.250558 (* 1 = 0.250558 loss)
I1212 00:03:49.645537 17660 solver.cpp:218] Iteration 147500 (10.1629 iter/s, 9.83974s/100 iters), loss = 0.0123912
I1212 00:03:49.645537 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:49.645537 17660 solver.cpp:237]     Train net output #1: loss = 0.0123911 (* 1 = 0.0123911 loss)
I1212 00:03:49.645537 17660 sgd_solver.cpp:105] Iteration 147500, lr = 0.001
I1212 00:03:57.696786 17660 solver.cpp:218] Iteration 147600 (12.4215 iter/s, 8.05058s/100 iters), loss = 0.0198239
I1212 00:03:57.696786 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:03:57.696786 17660 solver.cpp:237]     Train net output #1: loss = 0.0198238 (* 1 = 0.0198238 loss)
I1212 00:03:57.696786 17660 sgd_solver.cpp:105] Iteration 147600, lr = 0.001
I1212 00:04:05.752024 17660 solver.cpp:218] Iteration 147700 (12.4147 iter/s, 8.05498s/100 iters), loss = 0.0107376
I1212 00:04:05.752024 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:05.752024 17660 solver.cpp:237]     Train net output #1: loss = 0.0107375 (* 1 = 0.0107375 loss)
I1212 00:04:05.752024 17660 sgd_solver.cpp:105] Iteration 147700, lr = 0.001
I1212 00:04:13.805539 17660 solver.cpp:218] Iteration 147800 (12.4188 iter/s, 8.05232s/100 iters), loss = 0.00929854
I1212 00:04:13.805539 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:13.805539 17660 solver.cpp:237]     Train net output #1: loss = 0.00929842 (* 1 = 0.00929842 loss)
I1212 00:04:13.805539 17660 sgd_solver.cpp:105] Iteration 147800, lr = 0.001
I1212 00:04:21.869096 17660 solver.cpp:218] Iteration 147900 (12.4016 iter/s, 8.06344s/100 iters), loss = 0.0117786
I1212 00:04:21.869096 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:21.869096 17660 solver.cpp:237]     Train net output #1: loss = 0.0117785 (* 1 = 0.0117785 loss)
I1212 00:04:21.869096 17660 sgd_solver.cpp:105] Iteration 147900, lr = 0.001
I1212 00:04:29.529875 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:04:29.850913 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148000.caffemodel
I1212 00:04:29.878912 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148000.solverstate
I1212 00:04:29.908466 17660 solver.cpp:330] Iteration 148000, Testing net (#0)
I1212 00:04:29.908466 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:04:31.588716 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:04:31.655730 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1212 00:04:31.655730 17660 solver.cpp:397]     Test net output #1: loss = 0.253433 (* 1 = 0.253433 loss)
I1212 00:04:31.729744 17660 solver.cpp:218] Iteration 148000 (10.1418 iter/s, 9.86016s/100 iters), loss = 0.0130295
I1212 00:04:31.729744 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:31.729744 17660 solver.cpp:237]     Train net output #1: loss = 0.0130294 (* 1 = 0.0130294 loss)
I1212 00:04:31.729744 17660 sgd_solver.cpp:105] Iteration 148000, lr = 0.001
I1212 00:04:39.789687 17660 solver.cpp:218] Iteration 148100 (12.4083 iter/s, 8.0591s/100 iters), loss = 0.013123
I1212 00:04:39.789687 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:39.789687 17660 solver.cpp:237]     Train net output #1: loss = 0.0131229 (* 1 = 0.0131229 loss)
I1212 00:04:39.789687 17660 sgd_solver.cpp:105] Iteration 148100, lr = 0.001
I1212 00:04:47.839066 17660 solver.cpp:218] Iteration 148200 (12.4244 iter/s, 8.04867s/100 iters), loss = 0.0142197
I1212 00:04:47.839066 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:47.839066 17660 solver.cpp:237]     Train net output #1: loss = 0.0142196 (* 1 = 0.0142196 loss)
I1212 00:04:47.839066 17660 sgd_solver.cpp:105] Iteration 148200, lr = 0.001
I1212 00:04:55.897575 17660 solver.cpp:218] Iteration 148300 (12.4089 iter/s, 8.05873s/100 iters), loss = 0.0104391
I1212 00:04:55.898579 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:04:55.898579 17660 solver.cpp:237]     Train net output #1: loss = 0.0104389 (* 1 = 0.0104389 loss)
I1212 00:04:55.898579 17660 sgd_solver.cpp:105] Iteration 148300, lr = 0.001
I1212 00:05:03.955657 17660 solver.cpp:218] Iteration 148400 (12.4109 iter/s, 8.05745s/100 iters), loss = 0.0140298
I1212 00:05:03.956657 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:05:03.956657 17660 solver.cpp:237]     Train net output #1: loss = 0.0140297 (* 1 = 0.0140297 loss)
I1212 00:05:03.956657 17660 sgd_solver.cpp:105] Iteration 148400, lr = 0.001
I1212 00:05:11.608486 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:05:11.928009 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148500.caffemodel
I1212 00:05:11.956513 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_148500.solverstate
I1212 00:05:11.962513 17660 solver.cpp:330] Iteration 148500, Testing net (#0)
I1212 00:05:11.962513 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:05:13.645669 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:05:13.712668 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1212 00:05:13.712668 17660 solver.cpp:397]     Test net output #1: loss = 0.258857 (* 1 = 0.258857 loss)
I1212 00:05:13.787673 17660 solver.cpp:218] Iteration 148500 (10.1721 iter/s, 9.8308s/100 iters), loss = 0.0466699
I1212 00:05:13.787673 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1212 00:05:13.787673 17660 solver.cpp:237]     Train net output #1: loss = 0.0466698 (* 1 = 0.0466698 loss)
I1212 00:05:13.787673 17660 sgd_solver.cpp:105] Iteration 148500, lr = 0.001
I1212 00:05:21.834969 17660 solver.cpp:218] Iteration 148600 (12.4277 iter/s, 8.04651s/100 iters), loss = 0.0126051
I1212 00:05:21.834969 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:05:21.834969 17660 solver.cpp:237]     Train net output #1: loss = 0.0126049 (* 1 = 0.0126049 loss)
I1212 00:05:21.834969 17660 sgd_solver.cpp:105] Iteration 148600, lr = 0.001
I1212 00:05:29.902297 17660 solver.cpp:218] Iteration 148700 (12.3953 iter/s, 8.06754s/100 iters), loss = 0.0124464
I1212 00:05:29.902297 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:05:29.902297 17660 solver.cpp:237]     Train net output #1: loss = 0.0124463 (* 1 = 0.0124463 loss)
I1212 00:05:29.902297 17660 sgd_solver.cpp:105] Iteration 148700, lr = 0.001
I1212 00:05:37.962220 17660 solver.cpp:218] Iteration 148800 (12.4091 iter/s, 8.05859s/100 iters), loss = 0.00947594
I1212 00:05:37.962220 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:05:37.962220 17660 solver.cpp:237]     Train net output #1: loss = 0.00947582 (* 1 = 0.00947582 loss)
I1212 00:05:37.962220 17660 sgd_solver.cpp:105] Iteration 148800, lr = 0.001
I1212 00:05:46.032789 17660 solver.cpp:218] Iteration 148900 (12.3915 iter/s, 8.07002s/100 iters), loss = 0.0116819
I1212 00:05:46.032789 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:05:46.032789 17660 solver.cpp:237]     Train net output #1: loss = 0.0116817 (* 1 = 0.0116817 loss)
I1212 00:05:46.032789 17660 sgd_solver.cpp:105] Iteration 148900, lr = 0.001
I1212 00:05:53.696101 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:05:54.015220 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149000.caffemodel
I1212 00:05:54.044725 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149000.solverstate
I1212 00:05:54.051232 17660 solver.cpp:330] Iteration 149000, Testing net (#0)
I1212 00:05:54.051232 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:05:55.734515 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:05:55.801519 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1212 00:05:55.801519 17660 solver.cpp:397]     Test net output #1: loss = 0.258712 (* 1 = 0.258712 loss)
I1212 00:05:55.877547 17660 solver.cpp:218] Iteration 149000 (10.1576 iter/s, 9.84481s/100 iters), loss = 0.0140613
I1212 00:05:55.877547 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:05:55.877547 17660 solver.cpp:237]     Train net output #1: loss = 0.0140612 (* 1 = 0.0140612 loss)
I1212 00:05:55.877547 17660 sgd_solver.cpp:105] Iteration 149000, lr = 0.001
I1212 00:06:03.935057 17660 solver.cpp:218] Iteration 149100 (12.4122 iter/s, 8.0566s/100 iters), loss = 0.0134002
I1212 00:06:03.935057 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:03.935057 17660 solver.cpp:237]     Train net output #1: loss = 0.0134 (* 1 = 0.0134 loss)
I1212 00:06:03.935057 17660 sgd_solver.cpp:105] Iteration 149100, lr = 0.001
I1212 00:06:11.976809 17660 solver.cpp:218] Iteration 149200 (12.4351 iter/s, 8.04176s/100 iters), loss = 0.0149894
I1212 00:06:11.977797 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:11.977797 17660 solver.cpp:237]     Train net output #1: loss = 0.0149893 (* 1 = 0.0149893 loss)
I1212 00:06:11.977797 17660 sgd_solver.cpp:105] Iteration 149200, lr = 0.001
I1212 00:06:20.027314 17660 solver.cpp:218] Iteration 149300 (12.4236 iter/s, 8.04918s/100 iters), loss = 0.00903356
I1212 00:06:20.027314 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:20.027314 17660 solver.cpp:237]     Train net output #1: loss = 0.00903344 (* 1 = 0.00903344 loss)
I1212 00:06:20.027314 17660 sgd_solver.cpp:105] Iteration 149300, lr = 0.001
I1212 00:06:28.072202 17660 solver.cpp:218] Iteration 149400 (12.43 iter/s, 8.04505s/100 iters), loss = 0.013684
I1212 00:06:28.072202 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:28.072202 17660 solver.cpp:237]     Train net output #1: loss = 0.0136839 (* 1 = 0.0136839 loss)
I1212 00:06:28.072202 17660 sgd_solver.cpp:105] Iteration 149400, lr = 0.001
I1212 00:06:35.718096 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:06:36.037145 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149500.caffemodel
I1212 00:06:36.094161 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_149500.solverstate
I1212 00:06:36.100162 17660 solver.cpp:330] Iteration 149500, Testing net (#0)
I1212 00:06:36.100162 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:06:37.783987 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:06:37.850494 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1212 00:06:37.850494 17660 solver.cpp:397]     Test net output #1: loss = 0.257493 (* 1 = 0.257493 loss)
I1212 00:06:37.925498 17660 solver.cpp:218] Iteration 149500 (10.1495 iter/s, 9.85266s/100 iters), loss = 0.0130417
I1212 00:06:37.925498 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:37.925498 17660 solver.cpp:237]     Train net output #1: loss = 0.0130416 (* 1 = 0.0130416 loss)
I1212 00:06:37.925498 17660 sgd_solver.cpp:105] Iteration 149500, lr = 0.001
I1212 00:06:45.973929 17660 solver.cpp:218] Iteration 149600 (12.4263 iter/s, 8.04747s/100 iters), loss = 0.016971
I1212 00:06:45.973929 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:45.974431 17660 solver.cpp:237]     Train net output #1: loss = 0.0169709 (* 1 = 0.0169709 loss)
I1212 00:06:45.974431 17660 sgd_solver.cpp:105] Iteration 149600, lr = 0.001
I1212 00:06:54.017393 17660 solver.cpp:218] Iteration 149700 (12.4336 iter/s, 8.04272s/100 iters), loss = 0.0115017
I1212 00:06:54.017393 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:06:54.017393 17660 solver.cpp:237]     Train net output #1: loss = 0.0115016 (* 1 = 0.0115016 loss)
I1212 00:06:54.017393 17660 sgd_solver.cpp:105] Iteration 149700, lr = 0.001
I1212 00:07:02.062114 17660 solver.cpp:218] Iteration 149800 (12.4308 iter/s, 8.04454s/100 iters), loss = 0.0173604
I1212 00:07:02.062114 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:02.062114 17660 solver.cpp:237]     Train net output #1: loss = 0.0173603 (* 1 = 0.0173603 loss)
I1212 00:07:02.062114 17660 sgd_solver.cpp:105] Iteration 149800, lr = 0.001
I1212 00:07:10.114434 17660 solver.cpp:218] Iteration 149900 (12.4202 iter/s, 8.05142s/100 iters), loss = 0.0154919
I1212 00:07:10.114434 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:10.114434 17660 solver.cpp:237]     Train net output #1: loss = 0.0154917 (* 1 = 0.0154917 loss)
I1212 00:07:10.114434 17660 sgd_solver.cpp:105] Iteration 149900, lr = 0.001
I1212 00:07:17.762764 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:07:18.081785 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150000.caffemodel
I1212 00:07:18.111784 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150000.solverstate
I1212 00:07:18.118290 17660 solver.cpp:330] Iteration 150000, Testing net (#0)
I1212 00:07:18.118290 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:07:19.797929 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:07:19.865942 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1212 00:07:19.865942 17660 solver.cpp:397]     Test net output #1: loss = 0.257262 (* 1 = 0.257262 loss)
I1212 00:07:19.941942 17660 solver.cpp:218] Iteration 150000 (10.1759 iter/s, 9.82716s/100 iters), loss = 0.0135348
I1212 00:07:19.941942 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:19.941942 17660 solver.cpp:237]     Train net output #1: loss = 0.0135347 (* 1 = 0.0135347 loss)
I1212 00:07:19.941942 17660 sgd_solver.cpp:105] Iteration 150000, lr = 0.001
I1212 00:07:27.981751 17660 solver.cpp:218] Iteration 150100 (12.4388 iter/s, 8.03933s/100 iters), loss = 0.0101072
I1212 00:07:27.981751 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:27.981751 17660 solver.cpp:237]     Train net output #1: loss = 0.0101071 (* 1 = 0.0101071 loss)
I1212 00:07:27.981751 17660 sgd_solver.cpp:105] Iteration 150100, lr = 0.001
I1212 00:07:36.031683 17660 solver.cpp:218] Iteration 150200 (12.4233 iter/s, 8.04941s/100 iters), loss = 0.00968226
I1212 00:07:36.031683 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:36.031683 17660 solver.cpp:237]     Train net output #1: loss = 0.00968215 (* 1 = 0.00968215 loss)
I1212 00:07:36.032192 17660 sgd_solver.cpp:105] Iteration 150200, lr = 0.001
I1212 00:07:44.086726 17660 solver.cpp:218] Iteration 150300 (12.4159 iter/s, 8.05416s/100 iters), loss = 0.012885
I1212 00:07:44.086726 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:44.086726 17660 solver.cpp:237]     Train net output #1: loss = 0.0128849 (* 1 = 0.0128849 loss)
I1212 00:07:44.086726 17660 sgd_solver.cpp:105] Iteration 150300, lr = 0.001
I1212 00:07:52.140020 17660 solver.cpp:218] Iteration 150400 (12.4174 iter/s, 8.05321s/100 iters), loss = 0.0118914
I1212 00:07:52.140020 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:07:52.140020 17660 solver.cpp:237]     Train net output #1: loss = 0.0118913 (* 1 = 0.0118913 loss)
I1212 00:07:52.140020 17660 sgd_solver.cpp:105] Iteration 150400, lr = 0.001
I1212 00:07:59.793722 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:08:00.114261 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150500.caffemodel
I1212 00:08:00.177261 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_150500.solverstate
I1212 00:08:00.183261 17660 solver.cpp:330] Iteration 150500, Testing net (#0)
I1212 00:08:00.183261 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:08:01.868443 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:08:01.934449 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1212 00:08:01.935451 17660 solver.cpp:397]     Test net output #1: loss = 0.258944 (* 1 = 0.258944 loss)
I1212 00:08:02.009470 17660 solver.cpp:218] Iteration 150500 (10.1327 iter/s, 9.86905s/100 iters), loss = 0.0120294
I1212 00:08:02.009470 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:02.009470 17660 solver.cpp:237]     Train net output #1: loss = 0.0120293 (* 1 = 0.0120293 loss)
I1212 00:08:02.009470 17660 sgd_solver.cpp:105] Iteration 150500, lr = 0.001
I1212 00:08:10.058595 17660 solver.cpp:218] Iteration 150600 (12.4254 iter/s, 8.04805s/100 iters), loss = 0.00970296
I1212 00:08:10.058595 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:10.058595 17660 solver.cpp:237]     Train net output #1: loss = 0.00970285 (* 1 = 0.00970285 loss)
I1212 00:08:10.058595 17660 sgd_solver.cpp:105] Iteration 150600, lr = 0.001
I1212 00:08:18.120056 17660 solver.cpp:218] Iteration 150700 (12.4042 iter/s, 8.06176s/100 iters), loss = 0.0125372
I1212 00:08:18.121055 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:18.121055 17660 solver.cpp:237]     Train net output #1: loss = 0.0125371 (* 1 = 0.0125371 loss)
I1212 00:08:18.121055 17660 sgd_solver.cpp:105] Iteration 150700, lr = 0.001
I1212 00:08:26.164726 17660 solver.cpp:218] Iteration 150800 (12.4316 iter/s, 8.04405s/100 iters), loss = 0.0155896
I1212 00:08:26.164726 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:26.164726 17660 solver.cpp:237]     Train net output #1: loss = 0.0155895 (* 1 = 0.0155895 loss)
I1212 00:08:26.164726 17660 sgd_solver.cpp:105] Iteration 150800, lr = 0.001
I1212 00:08:34.195164 17660 solver.cpp:218] Iteration 150900 (12.4536 iter/s, 8.02982s/100 iters), loss = 0.011748
I1212 00:08:34.195164 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:34.195164 17660 solver.cpp:237]     Train net output #1: loss = 0.0117479 (* 1 = 0.0117479 loss)
I1212 00:08:34.195164 17660 sgd_solver.cpp:105] Iteration 150900, lr = 0.001
I1212 00:08:41.852604 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:08:42.168632 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151000.caffemodel
I1212 00:08:42.196631 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151000.solverstate
I1212 00:08:42.202631 17660 solver.cpp:330] Iteration 151000, Testing net (#0)
I1212 00:08:42.202631 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:08:43.886811 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:08:43.952819 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1212 00:08:43.952819 17660 solver.cpp:397]     Test net output #1: loss = 0.259994 (* 1 = 0.259994 loss)
I1212 00:08:44.027834 17660 solver.cpp:218] Iteration 151000 (10.1707 iter/s, 9.83217s/100 iters), loss = 0.0112002
I1212 00:08:44.028833 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:44.028833 17660 solver.cpp:237]     Train net output #1: loss = 0.0112 (* 1 = 0.0112 loss)
I1212 00:08:44.028833 17660 sgd_solver.cpp:105] Iteration 151000, lr = 0.001
I1212 00:08:52.058295 17660 solver.cpp:218] Iteration 151100 (12.4546 iter/s, 8.02919s/100 iters), loss = 0.0129866
I1212 00:08:52.058295 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:08:52.058295 17660 solver.cpp:237]     Train net output #1: loss = 0.0129865 (* 1 = 0.0129865 loss)
I1212 00:08:52.058295 17660 sgd_solver.cpp:105] Iteration 151100, lr = 0.001
I1212 00:09:00.088726 17660 solver.cpp:218] Iteration 151200 (12.4523 iter/s, 8.03066s/100 iters), loss = 0.0106571
I1212 00:09:00.089726 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:00.089726 17660 solver.cpp:237]     Train net output #1: loss = 0.010657 (* 1 = 0.010657 loss)
I1212 00:09:00.089726 17660 sgd_solver.cpp:105] Iteration 151200, lr = 0.001
I1212 00:09:08.137435 17660 solver.cpp:218] Iteration 151300 (12.4259 iter/s, 8.04768s/100 iters), loss = 0.0172127
I1212 00:09:08.137435 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:08.137435 17660 solver.cpp:237]     Train net output #1: loss = 0.0172126 (* 1 = 0.0172126 loss)
I1212 00:09:08.137435 17660 sgd_solver.cpp:105] Iteration 151300, lr = 0.001
I1212 00:09:16.168246 17660 solver.cpp:218] Iteration 151400 (12.4531 iter/s, 8.03015s/100 iters), loss = 0.011969
I1212 00:09:16.168246 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:16.168246 17660 solver.cpp:237]     Train net output #1: loss = 0.0119689 (* 1 = 0.0119689 loss)
I1212 00:09:16.168246 17660 sgd_solver.cpp:105] Iteration 151400, lr = 0.001
I1212 00:09:23.829512 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:09:24.148048 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151500.caffemodel
I1212 00:09:24.611632 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_151500.solverstate
I1212 00:09:24.617632 17660 solver.cpp:330] Iteration 151500, Testing net (#0)
I1212 00:09:24.617632 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:09:26.310871 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:09:26.377918 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1212 00:09:26.378917 17660 solver.cpp:397]     Test net output #1: loss = 0.254185 (* 1 = 0.254185 loss)
I1212 00:09:26.452431 17660 solver.cpp:218] Iteration 151500 (9.72363 iter/s, 10.2842s/100 iters), loss = 0.0127581
I1212 00:09:26.452431 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:26.452431 17660 solver.cpp:237]     Train net output #1: loss = 0.012758 (* 1 = 0.012758 loss)
I1212 00:09:26.453419 17660 sgd_solver.cpp:105] Iteration 151500, lr = 0.001
I1212 00:09:34.479311 17660 solver.cpp:218] Iteration 151600 (12.459 iter/s, 8.02635s/100 iters), loss = 0.0115768
I1212 00:09:34.479311 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:34.479311 17660 solver.cpp:237]     Train net output #1: loss = 0.0115767 (* 1 = 0.0115767 loss)
I1212 00:09:34.479311 17660 sgd_solver.cpp:105] Iteration 151600, lr = 0.001
I1212 00:09:42.505161 17660 solver.cpp:218] Iteration 151700 (12.4611 iter/s, 8.025s/100 iters), loss = 0.0128566
I1212 00:09:42.505161 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:42.505161 17660 solver.cpp:237]     Train net output #1: loss = 0.0128565 (* 1 = 0.0128565 loss)
I1212 00:09:42.505161 17660 sgd_solver.cpp:105] Iteration 151700, lr = 0.001
I1212 00:09:50.536635 17660 solver.cpp:218] Iteration 151800 (12.4521 iter/s, 8.03079s/100 iters), loss = 0.0167095
I1212 00:09:50.536635 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:09:50.536635 17660 solver.cpp:237]     Train net output #1: loss = 0.0167094 (* 1 = 0.0167094 loss)
I1212 00:09:50.536635 17660 sgd_solver.cpp:105] Iteration 151800, lr = 0.001
I1212 00:09:58.573674 17660 solver.cpp:218] Iteration 151900 (12.4429 iter/s, 8.03673s/100 iters), loss = 0.0132154
I1212 00:09:58.573674 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:09:58.573674 17660 solver.cpp:237]     Train net output #1: loss = 0.0132153 (* 1 = 0.0132153 loss)
I1212 00:09:58.573674 17660 sgd_solver.cpp:105] Iteration 151900, lr = 0.001
I1212 00:10:06.215891 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:10:06.532512 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152000.caffemodel
I1212 00:10:06.560524 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152000.solverstate
I1212 00:10:06.566512 17660 solver.cpp:330] Iteration 152000, Testing net (#0)
I1212 00:10:06.566512 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:10:08.244655 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:10:08.312165 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1212 00:10:08.312165 17660 solver.cpp:397]     Test net output #1: loss = 0.2594 (* 1 = 0.2594 loss)
I1212 00:10:08.388674 17660 solver.cpp:218] Iteration 152000 (10.1889 iter/s, 9.81458s/100 iters), loss = 0.0297854
I1212 00:10:08.388674 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:10:08.388674 17660 solver.cpp:237]     Train net output #1: loss = 0.0297853 (* 1 = 0.0297853 loss)
I1212 00:10:08.388674 17660 sgd_solver.cpp:105] Iteration 152000, lr = 0.001
I1212 00:10:16.428802 17660 solver.cpp:218] Iteration 152100 (12.438 iter/s, 8.03991s/100 iters), loss = 0.0194992
I1212 00:10:16.428802 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:10:16.428802 17660 solver.cpp:237]     Train net output #1: loss = 0.0194991 (* 1 = 0.0194991 loss)
I1212 00:10:16.428802 17660 sgd_solver.cpp:105] Iteration 152100, lr = 0.001
I1212 00:10:24.482628 17660 solver.cpp:218] Iteration 152200 (12.4176 iter/s, 8.05307s/100 iters), loss = 0.0128641
I1212 00:10:24.482628 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:10:24.482628 17660 solver.cpp:237]     Train net output #1: loss = 0.012864 (* 1 = 0.012864 loss)
I1212 00:10:24.482628 17660 sgd_solver.cpp:105] Iteration 152200, lr = 0.001
I1212 00:10:32.521354 17660 solver.cpp:218] Iteration 152300 (12.4412 iter/s, 8.0378s/100 iters), loss = 0.0150662
I1212 00:10:32.521354 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:10:32.521354 17660 solver.cpp:237]     Train net output #1: loss = 0.0150661 (* 1 = 0.0150661 loss)
I1212 00:10:32.521354 17660 sgd_solver.cpp:105] Iteration 152300, lr = 0.001
I1212 00:10:40.568106 17660 solver.cpp:218] Iteration 152400 (12.4287 iter/s, 8.04588s/100 iters), loss = 0.0106889
I1212 00:10:40.568106 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:10:40.568106 17660 solver.cpp:237]     Train net output #1: loss = 0.0106888 (* 1 = 0.0106888 loss)
I1212 00:10:40.568106 17660 sgd_solver.cpp:105] Iteration 152400, lr = 0.001
I1212 00:10:48.215690 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:10:48.535404 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152500.caffemodel
I1212 00:10:48.595414 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_152500.solverstate
I1212 00:10:48.631984 17660 solver.cpp:330] Iteration 152500, Testing net (#0)
I1212 00:10:48.632969 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:10:50.314810 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:10:50.381966 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9299
I1212 00:10:50.381966 17660 solver.cpp:397]     Test net output #1: loss = 0.263605 (* 1 = 0.263605 loss)
I1212 00:10:50.455477 17660 solver.cpp:218] Iteration 152500 (10.1137 iter/s, 9.8876s/100 iters), loss = 0.0117081
I1212 00:10:50.455477 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:10:50.455477 17660 solver.cpp:237]     Train net output #1: loss = 0.011708 (* 1 = 0.011708 loss)
I1212 00:10:50.455477 17660 sgd_solver.cpp:105] Iteration 152500, lr = 0.001
I1212 00:10:58.497637 17660 solver.cpp:218] Iteration 152600 (12.4364 iter/s, 8.0409s/100 iters), loss = 0.0149149
I1212 00:10:58.497637 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:10:58.497637 17660 solver.cpp:237]     Train net output #1: loss = 0.0149148 (* 1 = 0.0149148 loss)
I1212 00:10:58.497637 17660 sgd_solver.cpp:105] Iteration 152600, lr = 0.001
I1212 00:11:06.527032 17660 solver.cpp:218] Iteration 152700 (12.4541 iter/s, 8.02947s/100 iters), loss = 0.0109525
I1212 00:11:06.527032 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:11:06.527032 17660 solver.cpp:237]     Train net output #1: loss = 0.0109524 (* 1 = 0.0109524 loss)
I1212 00:11:06.527032 17660 sgd_solver.cpp:105] Iteration 152700, lr = 0.001
I1212 00:11:14.562741 17660 solver.cpp:218] Iteration 152800 (12.445 iter/s, 8.03533s/100 iters), loss = 0.0152167
I1212 00:11:14.562741 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:11:14.562741 17660 solver.cpp:237]     Train net output #1: loss = 0.0152166 (* 1 = 0.0152166 loss)
I1212 00:11:14.562741 17660 sgd_solver.cpp:105] Iteration 152800, lr = 0.001
I1212 00:11:22.609942 17660 solver.cpp:218] Iteration 152900 (12.4286 iter/s, 8.04595s/100 iters), loss = 0.0126515
I1212 00:11:22.609942 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:11:22.609942 17660 solver.cpp:237]     Train net output #1: loss = 0.0126514 (* 1 = 0.0126514 loss)
I1212 00:11:22.609942 17660 sgd_solver.cpp:105] Iteration 152900, lr = 0.001
I1212 00:11:30.264618 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:11:30.585201 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153000.caffemodel
I1212 00:11:30.613201 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153000.solverstate
I1212 00:11:30.619202 17660 solver.cpp:330] Iteration 153000, Testing net (#0)
I1212 00:11:30.619202 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:11:32.304002 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:11:32.371016 17660 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1212 00:11:32.371016 17660 solver.cpp:397]     Test net output #1: loss = 0.256938 (* 1 = 0.256938 loss)
I1212 00:11:32.445029 17660 solver.cpp:218] Iteration 153000 (10.1673 iter/s, 9.83542s/100 iters), loss = 0.010629
I1212 00:11:32.446022 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:11:32.446022 17660 solver.cpp:237]     Train net output #1: loss = 0.0106289 (* 1 = 0.0106289 loss)
I1212 00:11:32.446022 17660 sgd_solver.cpp:46] MultiStep Status: Iteration 153000, step = 3
I1212 00:11:32.446022 17660 sgd_solver.cpp:105] Iteration 153000, lr = 0.0001
I1212 00:11:40.491441 17660 solver.cpp:218] Iteration 153100 (12.4291 iter/s, 8.04566s/100 iters), loss = 0.0226142
I1212 00:11:40.491441 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:11:40.491441 17660 solver.cpp:237]     Train net output #1: loss = 0.0226141 (* 1 = 0.0226141 loss)
I1212 00:11:40.491441 17660 sgd_solver.cpp:105] Iteration 153100, lr = 0.0001
I1212 00:11:48.535054 17660 solver.cpp:218] Iteration 153200 (12.4342 iter/s, 8.04236s/100 iters), loss = 0.0119125
I1212 00:11:48.535054 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:11:48.535054 17660 solver.cpp:237]     Train net output #1: loss = 0.0119124 (* 1 = 0.0119124 loss)
I1212 00:11:48.535054 17660 sgd_solver.cpp:105] Iteration 153200, lr = 0.0001
I1212 00:11:56.592584 17660 solver.cpp:218] Iteration 153300 (12.4104 iter/s, 8.05773s/100 iters), loss = 0.00943615
I1212 00:11:56.592584 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:11:56.592584 17660 solver.cpp:237]     Train net output #1: loss = 0.00943604 (* 1 = 0.00943604 loss)
I1212 00:11:56.592584 17660 sgd_solver.cpp:105] Iteration 153300, lr = 0.0001
I1212 00:12:04.643991 17660 solver.cpp:218] Iteration 153400 (12.4222 iter/s, 8.05013s/100 iters), loss = 0.0121419
I1212 00:12:04.643991 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:12:04.643991 17660 solver.cpp:237]     Train net output #1: loss = 0.0121418 (* 1 = 0.0121418 loss)
I1212 00:12:04.643991 17660 sgd_solver.cpp:105] Iteration 153400, lr = 0.0001
I1212 00:12:12.290568 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:12:12.606606 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153500.caffemodel
I1212 00:12:12.669603 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_153500.solverstate
I1212 00:12:12.674603 17660 solver.cpp:330] Iteration 153500, Testing net (#0)
I1212 00:12:12.675606 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:12:14.358739 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:12:14.425751 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:12:14.425751 17660 solver.cpp:397]     Test net output #1: loss = 0.25324 (* 1 = 0.25324 loss)
I1212 00:12:14.499763 17660 solver.cpp:218] Iteration 153500 (10.1467 iter/s, 9.85547s/100 iters), loss = 0.0176091
I1212 00:12:14.499763 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:12:14.499763 17660 solver.cpp:237]     Train net output #1: loss = 0.017609 (* 1 = 0.017609 loss)
I1212 00:12:14.499763 17660 sgd_solver.cpp:105] Iteration 153500, lr = 0.0001
I1212 00:12:22.552057 17660 solver.cpp:218] Iteration 153600 (12.4194 iter/s, 8.05192s/100 iters), loss = 0.0241118
I1212 00:12:22.552057 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:12:22.552057 17660 solver.cpp:237]     Train net output #1: loss = 0.0241117 (* 1 = 0.0241117 loss)
I1212 00:12:22.552057 17660 sgd_solver.cpp:105] Iteration 153600, lr = 0.0001
I1212 00:12:30.603243 17660 solver.cpp:218] Iteration 153700 (12.4215 iter/s, 8.05055s/100 iters), loss = 0.0200777
I1212 00:12:30.603243 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:12:30.603243 17660 solver.cpp:237]     Train net output #1: loss = 0.0200776 (* 1 = 0.0200776 loss)
I1212 00:12:30.603243 17660 sgd_solver.cpp:105] Iteration 153700, lr = 0.0001
I1212 00:12:38.656667 17660 solver.cpp:218] Iteration 153800 (12.4179 iter/s, 8.05289s/100 iters), loss = 0.0102438
I1212 00:12:38.656667 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:12:38.656667 17660 solver.cpp:237]     Train net output #1: loss = 0.0102436 (* 1 = 0.0102436 loss)
I1212 00:12:38.656667 17660 sgd_solver.cpp:105] Iteration 153800, lr = 0.0001
I1212 00:12:46.705827 17660 solver.cpp:218] Iteration 153900 (12.4242 iter/s, 8.04882s/100 iters), loss = 0.014878
I1212 00:12:46.731830 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:12:46.731830 17660 solver.cpp:237]     Train net output #1: loss = 0.0148779 (* 1 = 0.0148779 loss)
I1212 00:12:46.731830 17660 sgd_solver.cpp:105] Iteration 153900, lr = 0.0001
I1212 00:12:54.391698 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:12:54.708279 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154000.caffemodel
I1212 00:12:54.736879 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154000.solverstate
I1212 00:12:54.742897 17660 solver.cpp:330] Iteration 154000, Testing net (#0)
I1212 00:12:54.742897 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:12:56.425984 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:12:56.491976 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1212 00:12:56.491976 17660 solver.cpp:397]     Test net output #1: loss = 0.252583 (* 1 = 0.252583 loss)
I1212 00:12:56.569651 17660 solver.cpp:218] Iteration 154000 (10.1661 iter/s, 9.83665s/100 iters), loss = 0.0109863
I1212 00:12:56.569651 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:12:56.569651 17660 solver.cpp:237]     Train net output #1: loss = 0.0109862 (* 1 = 0.0109862 loss)
I1212 00:12:56.569651 17660 sgd_solver.cpp:105] Iteration 154000, lr = 0.0001
I1212 00:13:04.612640 17660 solver.cpp:218] Iteration 154100 (12.4337 iter/s, 8.04265s/100 iters), loss = 0.0112211
I1212 00:13:04.612640 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:04.612640 17660 solver.cpp:237]     Train net output #1: loss = 0.0112209 (* 1 = 0.0112209 loss)
I1212 00:13:04.612640 17660 sgd_solver.cpp:105] Iteration 154100, lr = 0.0001
I1212 00:13:12.667845 17660 solver.cpp:218] Iteration 154200 (12.4154 iter/s, 8.05454s/100 iters), loss = 0.0136373
I1212 00:13:12.667845 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:12.667845 17660 solver.cpp:237]     Train net output #1: loss = 0.0136372 (* 1 = 0.0136372 loss)
I1212 00:13:12.667845 17660 sgd_solver.cpp:105] Iteration 154200, lr = 0.0001
I1212 00:13:20.724335 17660 solver.cpp:218] Iteration 154300 (12.4129 iter/s, 8.0561s/100 iters), loss = 0.00911593
I1212 00:13:20.724335 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:20.724335 17660 solver.cpp:237]     Train net output #1: loss = 0.00911581 (* 1 = 0.00911581 loss)
I1212 00:13:20.724335 17660 sgd_solver.cpp:105] Iteration 154300, lr = 0.0001
I1212 00:13:28.780800 17660 solver.cpp:218] Iteration 154400 (12.4132 iter/s, 8.05593s/100 iters), loss = 0.0101758
I1212 00:13:28.780800 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:28.780800 17660 solver.cpp:237]     Train net output #1: loss = 0.0101757 (* 1 = 0.0101757 loss)
I1212 00:13:28.780800 17660 sgd_solver.cpp:105] Iteration 154400, lr = 0.0001
I1212 00:13:36.417737 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:13:36.734943 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154500.caffemodel
I1212 00:13:36.856478 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_154500.solverstate
I1212 00:13:36.862478 17660 solver.cpp:330] Iteration 154500, Testing net (#0)
I1212 00:13:36.863479 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:13:38.544751 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:13:38.611762 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1212 00:13:38.611762 17660 solver.cpp:397]     Test net output #1: loss = 0.251822 (* 1 = 0.251822 loss)
I1212 00:13:38.686185 17660 solver.cpp:218] Iteration 154500 (10.0961 iter/s, 9.90481s/100 iters), loss = 0.011651
I1212 00:13:38.686185 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:38.686185 17660 solver.cpp:237]     Train net output #1: loss = 0.0116509 (* 1 = 0.0116509 loss)
I1212 00:13:38.686185 17660 sgd_solver.cpp:105] Iteration 154500, lr = 0.0001
I1212 00:13:46.741297 17660 solver.cpp:218] Iteration 154600 (12.4146 iter/s, 8.05506s/100 iters), loss = 0.0199148
I1212 00:13:46.741297 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:46.741297 17660 solver.cpp:237]     Train net output #1: loss = 0.0199147 (* 1 = 0.0199147 loss)
I1212 00:13:46.741297 17660 sgd_solver.cpp:105] Iteration 154600, lr = 0.0001
I1212 00:13:54.787006 17660 solver.cpp:218] Iteration 154700 (12.4294 iter/s, 8.04546s/100 iters), loss = 0.0157993
I1212 00:13:54.788005 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:13:54.788005 17660 solver.cpp:237]     Train net output #1: loss = 0.0157992 (* 1 = 0.0157992 loss)
I1212 00:13:54.788005 17660 sgd_solver.cpp:105] Iteration 154700, lr = 0.0001
I1212 00:14:02.833964 17660 solver.cpp:218] Iteration 154800 (12.4291 iter/s, 8.04566s/100 iters), loss = 0.00846281
I1212 00:14:02.833964 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:02.833964 17660 solver.cpp:237]     Train net output #1: loss = 0.00846269 (* 1 = 0.00846269 loss)
I1212 00:14:02.833964 17660 sgd_solver.cpp:105] Iteration 154800, lr = 0.0001
I1212 00:14:10.882519 17660 solver.cpp:218] Iteration 154900 (12.4252 iter/s, 8.04819s/100 iters), loss = 0.00967382
I1212 00:14:10.882519 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:10.882519 17660 solver.cpp:237]     Train net output #1: loss = 0.0096737 (* 1 = 0.0096737 loss)
I1212 00:14:10.882519 17660 sgd_solver.cpp:105] Iteration 154900, lr = 0.0001
I1212 00:14:18.542789 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:14:18.861116 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155000.caffemodel
I1212 00:14:18.889116 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155000.solverstate
I1212 00:14:18.895135 17660 solver.cpp:330] Iteration 155000, Testing net (#0)
I1212 00:14:18.896118 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:14:20.611980 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:14:20.678519 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:14:20.678519 17660 solver.cpp:397]     Test net output #1: loss = 0.251426 (* 1 = 0.251426 loss)
I1212 00:14:20.753698 17660 solver.cpp:218] Iteration 155000 (10.1312 iter/s, 9.87049s/100 iters), loss = 0.0129153
I1212 00:14:20.753698 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:20.753698 17660 solver.cpp:237]     Train net output #1: loss = 0.0129152 (* 1 = 0.0129152 loss)
I1212 00:14:20.753698 17660 sgd_solver.cpp:105] Iteration 155000, lr = 0.0001
I1212 00:14:28.808897 17660 solver.cpp:218] Iteration 155100 (12.414 iter/s, 8.05542s/100 iters), loss = 0.0101102
I1212 00:14:28.808897 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:28.809897 17660 solver.cpp:237]     Train net output #1: loss = 0.0101101 (* 1 = 0.0101101 loss)
I1212 00:14:28.809897 17660 sgd_solver.cpp:105] Iteration 155100, lr = 0.0001
I1212 00:14:36.862432 17660 solver.cpp:218] Iteration 155200 (12.4191 iter/s, 8.05211s/100 iters), loss = 0.00984527
I1212 00:14:36.862432 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:36.862432 17660 solver.cpp:237]     Train net output #1: loss = 0.00984515 (* 1 = 0.00984515 loss)
I1212 00:14:36.862432 17660 sgd_solver.cpp:105] Iteration 155200, lr = 0.0001
I1212 00:14:44.919337 17660 solver.cpp:218] Iteration 155300 (12.4117 iter/s, 8.05692s/100 iters), loss = 0.0101953
I1212 00:14:44.919337 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:44.919337 17660 solver.cpp:237]     Train net output #1: loss = 0.0101952 (* 1 = 0.0101952 loss)
I1212 00:14:44.919337 17660 sgd_solver.cpp:105] Iteration 155300, lr = 0.0001
I1212 00:14:52.970970 17660 solver.cpp:218] Iteration 155400 (12.4207 iter/s, 8.0511s/100 iters), loss = 0.0110863
I1212 00:14:52.970970 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:14:52.970970 17660 solver.cpp:237]     Train net output #1: loss = 0.0110862 (* 1 = 0.0110862 loss)
I1212 00:14:52.970970 17660 sgd_solver.cpp:105] Iteration 155400, lr = 0.0001
I1212 00:15:00.635452 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:15:00.952952 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155500.caffemodel
I1212 00:15:01.028525 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_155500.solverstate
I1212 00:15:01.034235 17660 solver.cpp:330] Iteration 155500, Testing net (#0)
I1212 00:15:01.035234 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:15:02.714015 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:15:02.780045 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1212 00:15:02.781045 17660 solver.cpp:397]     Test net output #1: loss = 0.25153 (* 1 = 0.25153 loss)
I1212 00:15:02.855053 17660 solver.cpp:218] Iteration 155500 (10.1175 iter/s, 9.88387s/100 iters), loss = 0.011171
I1212 00:15:02.856052 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:02.856052 17660 solver.cpp:237]     Train net output #1: loss = 0.0111709 (* 1 = 0.0111709 loss)
I1212 00:15:02.856052 17660 sgd_solver.cpp:105] Iteration 155500, lr = 0.0001
I1212 00:15:10.899848 17660 solver.cpp:218] Iteration 155600 (12.4318 iter/s, 8.04387s/100 iters), loss = 0.0103395
I1212 00:15:10.899848 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:10.899848 17660 solver.cpp:237]     Train net output #1: loss = 0.0103394 (* 1 = 0.0103394 loss)
I1212 00:15:10.899848 17660 sgd_solver.cpp:105] Iteration 155600, lr = 0.0001
I1212 00:15:18.946451 17660 solver.cpp:218] Iteration 155700 (12.4288 iter/s, 8.04586s/100 iters), loss = 0.0132652
I1212 00:15:18.946451 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:18.946451 17660 solver.cpp:237]     Train net output #1: loss = 0.0132651 (* 1 = 0.0132651 loss)
I1212 00:15:18.946451 17660 sgd_solver.cpp:105] Iteration 155700, lr = 0.0001
I1212 00:15:26.999961 17660 solver.cpp:218] Iteration 155800 (12.4181 iter/s, 8.05274s/100 iters), loss = 0.00963921
I1212 00:15:26.999961 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:26.999961 17660 solver.cpp:237]     Train net output #1: loss = 0.00963909 (* 1 = 0.00963909 loss)
I1212 00:15:26.999961 17660 sgd_solver.cpp:105] Iteration 155800, lr = 0.0001
I1212 00:15:35.041204 17660 solver.cpp:218] Iteration 155900 (12.4367 iter/s, 8.04075s/100 iters), loss = 0.0111946
I1212 00:15:35.041204 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:35.041204 17660 solver.cpp:237]     Train net output #1: loss = 0.0111944 (* 1 = 0.0111944 loss)
I1212 00:15:35.041204 17660 sgd_solver.cpp:105] Iteration 155900, lr = 0.0001
I1212 00:15:42.701269 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:15:43.019320 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156000.caffemodel
I1212 00:15:43.077968 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156000.solverstate
I1212 00:15:43.083967 17660 solver.cpp:330] Iteration 156000, Testing net (#0)
I1212 00:15:43.083967 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:15:44.763383 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:15:44.830390 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:15:44.830390 17660 solver.cpp:397]     Test net output #1: loss = 0.251271 (* 1 = 0.251271 loss)
I1212 00:15:44.905025 17660 solver.cpp:218] Iteration 156000 (10.1378 iter/s, 9.86406s/100 iters), loss = 0.0267048
I1212 00:15:44.905025 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:44.905025 17660 solver.cpp:237]     Train net output #1: loss = 0.0267047 (* 1 = 0.0267047 loss)
I1212 00:15:44.905025 17660 sgd_solver.cpp:105] Iteration 156000, lr = 0.0001
I1212 00:15:52.953493 17660 solver.cpp:218] Iteration 156100 (12.4261 iter/s, 8.04757s/100 iters), loss = 0.0120208
I1212 00:15:52.953493 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:15:52.953493 17660 solver.cpp:237]     Train net output #1: loss = 0.0120207 (* 1 = 0.0120207 loss)
I1212 00:15:52.953493 17660 sgd_solver.cpp:105] Iteration 156100, lr = 0.0001
I1212 00:16:01.010429 17660 solver.cpp:218] Iteration 156200 (12.4123 iter/s, 8.0565s/100 iters), loss = 0.012806
I1212 00:16:01.010429 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:01.010429 17660 solver.cpp:237]     Train net output #1: loss = 0.0128059 (* 1 = 0.0128059 loss)
I1212 00:16:01.010429 17660 sgd_solver.cpp:105] Iteration 156200, lr = 0.0001
I1212 00:16:09.063872 17660 solver.cpp:218] Iteration 156300 (12.4185 iter/s, 8.05249s/100 iters), loss = 0.0101853
I1212 00:16:09.063872 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:09.063872 17660 solver.cpp:237]     Train net output #1: loss = 0.0101852 (* 1 = 0.0101852 loss)
I1212 00:16:09.063872 17660 sgd_solver.cpp:105] Iteration 156300, lr = 0.0001
I1212 00:16:17.160953 17660 solver.cpp:218] Iteration 156400 (12.3497 iter/s, 8.09738s/100 iters), loss = 0.0111503
I1212 00:16:17.161952 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:17.161952 17660 solver.cpp:237]     Train net output #1: loss = 0.0111502 (* 1 = 0.0111502 loss)
I1212 00:16:17.161952 17660 sgd_solver.cpp:105] Iteration 156400, lr = 0.0001
I1212 00:16:24.926367 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:16:25.247391 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156500.caffemodel
I1212 00:16:25.279392 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_156500.solverstate
I1212 00:16:25.286393 17660 solver.cpp:330] Iteration 156500, Testing net (#0)
I1212 00:16:25.286393 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:16:26.969542 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:16:27.038563 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:16:27.038563 17660 solver.cpp:397]     Test net output #1: loss = 0.250957 (* 1 = 0.250957 loss)
I1212 00:16:27.112570 17660 solver.cpp:218] Iteration 156500 (10.0497 iter/s, 9.95056s/100 iters), loss = 0.0240636
I1212 00:16:27.112570 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:27.112570 17660 solver.cpp:237]     Train net output #1: loss = 0.0240635 (* 1 = 0.0240635 loss)
I1212 00:16:27.112570 17660 sgd_solver.cpp:105] Iteration 156500, lr = 0.0001
I1212 00:16:35.221844 17660 solver.cpp:218] Iteration 156600 (12.3331 iter/s, 8.10826s/100 iters), loss = 0.00968143
I1212 00:16:35.221844 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:35.221844 17660 solver.cpp:237]     Train net output #1: loss = 0.00968131 (* 1 = 0.00968131 loss)
I1212 00:16:35.221844 17660 sgd_solver.cpp:105] Iteration 156600, lr = 0.0001
I1212 00:16:43.319612 17660 solver.cpp:218] Iteration 156700 (12.3487 iter/s, 8.09801s/100 iters), loss = 0.0130233
I1212 00:16:43.319612 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:43.320613 17660 solver.cpp:237]     Train net output #1: loss = 0.0130232 (* 1 = 0.0130232 loss)
I1212 00:16:43.320613 17660 sgd_solver.cpp:105] Iteration 156700, lr = 0.0001
I1212 00:16:51.376250 17660 solver.cpp:218] Iteration 156800 (12.4139 iter/s, 8.05552s/100 iters), loss = 0.0189927
I1212 00:16:51.376250 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:51.376250 17660 solver.cpp:237]     Train net output #1: loss = 0.0189926 (* 1 = 0.0189926 loss)
I1212 00:16:51.376250 17660 sgd_solver.cpp:105] Iteration 156800, lr = 0.0001
I1212 00:16:59.446386 17660 solver.cpp:218] Iteration 156900 (12.3914 iter/s, 8.07011s/100 iters), loss = 0.0101861
I1212 00:16:59.446386 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:16:59.446386 17660 solver.cpp:237]     Train net output #1: loss = 0.0101859 (* 1 = 0.0101859 loss)
I1212 00:16:59.446386 17660 sgd_solver.cpp:105] Iteration 156900, lr = 0.0001
I1212 00:17:07.161203 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:17:07.479339 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157000.caffemodel
I1212 00:17:07.541041 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157000.solverstate
I1212 00:17:07.547041 17660 solver.cpp:330] Iteration 157000, Testing net (#0)
I1212 00:17:07.547041 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:17:09.229992 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:17:09.298498 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1212 00:17:09.298498 17660 solver.cpp:397]     Test net output #1: loss = 0.251294 (* 1 = 0.251294 loss)
I1212 00:17:09.373004 17660 solver.cpp:218] Iteration 157000 (10.0744 iter/s, 9.92618s/100 iters), loss = 0.0147848
I1212 00:17:09.374006 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:09.374006 17660 solver.cpp:237]     Train net output #1: loss = 0.0147847 (* 1 = 0.0147847 loss)
I1212 00:17:09.374006 17660 sgd_solver.cpp:105] Iteration 157000, lr = 0.0001
I1212 00:17:17.444464 17660 solver.cpp:218] Iteration 157100 (12.3914 iter/s, 8.07014s/100 iters), loss = 0.0118296
I1212 00:17:17.444464 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:17.444464 17660 solver.cpp:237]     Train net output #1: loss = 0.0118295 (* 1 = 0.0118295 loss)
I1212 00:17:17.444464 17660 sgd_solver.cpp:105] Iteration 157100, lr = 0.0001
I1212 00:17:25.516353 17660 solver.cpp:218] Iteration 157200 (12.3882 iter/s, 8.07217s/100 iters), loss = 0.0193943
I1212 00:17:25.517354 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:25.517354 17660 solver.cpp:237]     Train net output #1: loss = 0.0193942 (* 1 = 0.0193942 loss)
I1212 00:17:25.517354 17660 sgd_solver.cpp:105] Iteration 157200, lr = 0.0001
I1212 00:17:33.609841 17660 solver.cpp:218] Iteration 157300 (12.3568 iter/s, 8.09272s/100 iters), loss = 0.0108796
I1212 00:17:33.609841 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:33.610832 17660 solver.cpp:237]     Train net output #1: loss = 0.0108794 (* 1 = 0.0108794 loss)
I1212 00:17:33.610832 17660 sgd_solver.cpp:105] Iteration 157300, lr = 0.0001
I1212 00:17:41.676822 17660 solver.cpp:218] Iteration 157400 (12.3979 iter/s, 8.06587s/100 iters), loss = 0.0115764
I1212 00:17:41.676822 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:41.676822 17660 solver.cpp:237]     Train net output #1: loss = 0.0115763 (* 1 = 0.0115763 loss)
I1212 00:17:41.676822 17660 sgd_solver.cpp:105] Iteration 157400, lr = 0.0001
I1212 00:17:49.350777 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:17:49.669318 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157500.caffemodel
I1212 00:17:49.701825 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_157500.solverstate
I1212 00:17:49.708336 17660 solver.cpp:330] Iteration 157500, Testing net (#0)
I1212 00:17:49.708336 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:17:51.392487 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:17:51.458490 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1212 00:17:51.458490 17660 solver.cpp:397]     Test net output #1: loss = 0.250715 (* 1 = 0.250715 loss)
I1212 00:17:51.535509 17660 solver.cpp:218] Iteration 157500 (10.1442 iter/s, 9.85783s/100 iters), loss = 0.0117893
I1212 00:17:51.535509 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:51.535509 17660 solver.cpp:237]     Train net output #1: loss = 0.0117892 (* 1 = 0.0117892 loss)
I1212 00:17:51.535509 17660 sgd_solver.cpp:105] Iteration 157500, lr = 0.0001
I1212 00:17:59.623505 17660 solver.cpp:218] Iteration 157600 (12.3648 iter/s, 8.08748s/100 iters), loss = 0.0085597
I1212 00:17:59.623505 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:17:59.623505 17660 solver.cpp:237]     Train net output #1: loss = 0.00855959 (* 1 = 0.00855959 loss)
I1212 00:17:59.623505 17660 sgd_solver.cpp:105] Iteration 157600, lr = 0.0001
I1212 00:18:07.719674 17660 solver.cpp:218] Iteration 157700 (12.3514 iter/s, 8.09625s/100 iters), loss = 0.0125129
I1212 00:18:07.719674 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:07.719674 17660 solver.cpp:237]     Train net output #1: loss = 0.0125128 (* 1 = 0.0125128 loss)
I1212 00:18:07.719674 17660 sgd_solver.cpp:105] Iteration 157700, lr = 0.0001
I1212 00:18:15.790452 17660 solver.cpp:218] Iteration 157800 (12.3912 iter/s, 8.07026s/100 iters), loss = 0.0103176
I1212 00:18:15.790452 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:15.790452 17660 solver.cpp:237]     Train net output #1: loss = 0.0103175 (* 1 = 0.0103175 loss)
I1212 00:18:15.791452 17660 sgd_solver.cpp:105] Iteration 157800, lr = 0.0001
I1212 00:18:23.861791 17660 solver.cpp:218] Iteration 157900 (12.3907 iter/s, 8.07057s/100 iters), loss = 0.0115949
I1212 00:18:23.861791 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:23.861791 17660 solver.cpp:237]     Train net output #1: loss = 0.0115947 (* 1 = 0.0115947 loss)
I1212 00:18:23.861791 17660 sgd_solver.cpp:105] Iteration 157900, lr = 0.0001
I1212 00:18:31.527690 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:18:31.850762 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158000.caffemodel
I1212 00:18:31.909762 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158000.solverstate
I1212 00:18:31.915762 17660 solver.cpp:330] Iteration 158000, Testing net (#0)
I1212 00:18:31.916762 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:18:33.616487 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:18:33.684514 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1212 00:18:33.684514 17660 solver.cpp:397]     Test net output #1: loss = 0.251904 (* 1 = 0.251904 loss)
I1212 00:18:33.761158 17660 solver.cpp:218] Iteration 158000 (10.1024 iter/s, 9.8986s/100 iters), loss = 0.0149297
I1212 00:18:33.761158 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:33.761158 17660 solver.cpp:237]     Train net output #1: loss = 0.0149296 (* 1 = 0.0149296 loss)
I1212 00:18:33.761158 17660 sgd_solver.cpp:105] Iteration 158000, lr = 0.0001
I1212 00:18:41.889681 17660 solver.cpp:218] Iteration 158100 (12.3033 iter/s, 8.12791s/100 iters), loss = 0.0113601
I1212 00:18:41.889681 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:41.889681 17660 solver.cpp:237]     Train net output #1: loss = 0.01136 (* 1 = 0.01136 loss)
I1212 00:18:41.889681 17660 sgd_solver.cpp:105] Iteration 158100, lr = 0.0001
I1212 00:18:49.982395 17660 solver.cpp:218] Iteration 158200 (12.3572 iter/s, 8.09243s/100 iters), loss = 0.0132363
I1212 00:18:49.982395 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:49.982395 17660 solver.cpp:237]     Train net output #1: loss = 0.0132362 (* 1 = 0.0132362 loss)
I1212 00:18:49.982395 17660 sgd_solver.cpp:105] Iteration 158200, lr = 0.0001
I1212 00:18:58.095053 17660 solver.cpp:218] Iteration 158300 (12.3274 iter/s, 8.11199s/100 iters), loss = 0.0109071
I1212 00:18:58.095053 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:18:58.095053 17660 solver.cpp:237]     Train net output #1: loss = 0.0109069 (* 1 = 0.0109069 loss)
I1212 00:18:58.095053 17660 sgd_solver.cpp:105] Iteration 158300, lr = 0.0001
I1212 00:19:06.226841 17660 solver.cpp:218] Iteration 158400 (12.2987 iter/s, 8.13094s/100 iters), loss = 0.0145225
I1212 00:19:06.226841 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:06.226841 17660 solver.cpp:237]     Train net output #1: loss = 0.0145224 (* 1 = 0.0145224 loss)
I1212 00:19:06.226841 17660 sgd_solver.cpp:105] Iteration 158400, lr = 0.0001
I1212 00:19:13.924088 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:19:14.250115 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158500.caffemodel
I1212 00:19:14.286118 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_158500.solverstate
I1212 00:19:14.293118 17660 solver.cpp:330] Iteration 158500, Testing net (#0)
I1212 00:19:14.293118 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:19:16.008335 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:19:16.078351 17660 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1212 00:19:16.078351 17660 solver.cpp:397]     Test net output #1: loss = 0.25128 (* 1 = 0.25128 loss)
I1212 00:19:16.155903 17660 solver.cpp:218] Iteration 158500 (10.0717 iter/s, 9.92881s/100 iters), loss = 0.0108512
I1212 00:19:16.155903 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:16.155903 17660 solver.cpp:237]     Train net output #1: loss = 0.0108511 (* 1 = 0.0108511 loss)
I1212 00:19:16.155903 17660 sgd_solver.cpp:105] Iteration 158500, lr = 0.0001
I1212 00:19:24.338681 17660 solver.cpp:218] Iteration 158600 (12.2222 iter/s, 8.18184s/100 iters), loss = 0.0200683
I1212 00:19:24.338681 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:24.338681 17660 solver.cpp:237]     Train net output #1: loss = 0.0200682 (* 1 = 0.0200682 loss)
I1212 00:19:24.338681 17660 sgd_solver.cpp:105] Iteration 158600, lr = 0.0001
I1212 00:19:32.462438 17660 solver.cpp:218] Iteration 158700 (12.3093 iter/s, 8.12392s/100 iters), loss = 0.0173392
I1212 00:19:32.462438 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:32.462438 17660 solver.cpp:237]     Train net output #1: loss = 0.0173391 (* 1 = 0.0173391 loss)
I1212 00:19:32.462438 17660 sgd_solver.cpp:105] Iteration 158700, lr = 0.0001
I1212 00:19:40.586599 17660 solver.cpp:218] Iteration 158800 (12.3094 iter/s, 8.12387s/100 iters), loss = 0.00992264
I1212 00:19:40.587600 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:40.587600 17660 solver.cpp:237]     Train net output #1: loss = 0.00992255 (* 1 = 0.00992255 loss)
I1212 00:19:40.587600 17660 sgd_solver.cpp:105] Iteration 158800, lr = 0.0001
I1212 00:19:48.714581 17660 solver.cpp:218] Iteration 158900 (12.3041 iter/s, 8.12738s/100 iters), loss = 0.00933261
I1212 00:19:48.714581 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:48.714581 17660 solver.cpp:237]     Train net output #1: loss = 0.00933251 (* 1 = 0.00933251 loss)
I1212 00:19:48.714581 17660 sgd_solver.cpp:105] Iteration 158900, lr = 0.0001
I1212 00:19:56.437433 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:19:56.764473 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159000.caffemodel
I1212 00:19:56.818473 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159000.solverstate
I1212 00:19:56.825475 17660 solver.cpp:330] Iteration 159000, Testing net (#0)
I1212 00:19:56.825475 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:19:58.520637 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:19:58.586645 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:19:58.586645 17660 solver.cpp:397]     Test net output #1: loss = 0.251409 (* 1 = 0.251409 loss)
I1212 00:19:58.662654 17660 solver.cpp:218] Iteration 159000 (10.0535 iter/s, 9.94676s/100 iters), loss = 0.011947
I1212 00:19:58.662654 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:19:58.662654 17660 solver.cpp:237]     Train net output #1: loss = 0.0119469 (* 1 = 0.0119469 loss)
I1212 00:19:58.662654 17660 sgd_solver.cpp:105] Iteration 159000, lr = 0.0001
I1212 00:20:06.799299 17660 solver.cpp:218] Iteration 159100 (12.2895 iter/s, 8.13702s/100 iters), loss = 0.0142038
I1212 00:20:06.800304 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:06.800304 17660 solver.cpp:237]     Train net output #1: loss = 0.0142037 (* 1 = 0.0142037 loss)
I1212 00:20:06.800304 17660 sgd_solver.cpp:105] Iteration 159100, lr = 0.0001
I1212 00:20:14.888219 17660 solver.cpp:218] Iteration 159200 (12.3646 iter/s, 8.08761s/100 iters), loss = 0.0139444
I1212 00:20:14.888219 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:14.888219 17660 solver.cpp:237]     Train net output #1: loss = 0.0139443 (* 1 = 0.0139443 loss)
I1212 00:20:14.888219 17660 sgd_solver.cpp:105] Iteration 159200, lr = 0.0001
I1212 00:20:22.989238 17660 solver.cpp:218] Iteration 159300 (12.3451 iter/s, 8.1004s/100 iters), loss = 0.00875856
I1212 00:20:22.989238 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:22.989238 17660 solver.cpp:237]     Train net output #1: loss = 0.00875847 (* 1 = 0.00875847 loss)
I1212 00:20:22.989238 17660 sgd_solver.cpp:105] Iteration 159300, lr = 0.0001
I1212 00:20:31.109679 17660 solver.cpp:218] Iteration 159400 (12.3143 iter/s, 8.12062s/100 iters), loss = 0.014592
I1212 00:20:31.109679 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:31.109679 17660 solver.cpp:237]     Train net output #1: loss = 0.0145919 (* 1 = 0.0145919 loss)
I1212 00:20:31.109679 17660 sgd_solver.cpp:105] Iteration 159400, lr = 0.0001
I1212 00:20:38.833591 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:20:39.151788 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159500.caffemodel
I1212 00:20:39.181860 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_159500.solverstate
I1212 00:20:39.187878 17660 solver.cpp:330] Iteration 159500, Testing net (#0)
I1212 00:20:39.188859 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:20:40.891369 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:20:40.958897 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1212 00:20:40.958897 17660 solver.cpp:397]     Test net output #1: loss = 0.252035 (* 1 = 0.252035 loss)
I1212 00:20:41.036051 17660 solver.cpp:218] Iteration 159500 (10.0754 iter/s, 9.92512s/100 iters), loss = 0.011112
I1212 00:20:41.036051 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:41.036051 17660 solver.cpp:237]     Train net output #1: loss = 0.0111119 (* 1 = 0.0111119 loss)
I1212 00:20:41.036051 17660 sgd_solver.cpp:105] Iteration 159500, lr = 0.0001
I1212 00:20:49.164139 17660 solver.cpp:218] Iteration 159600 (12.3036 iter/s, 8.12768s/100 iters), loss = 0.0111085
I1212 00:20:49.164139 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:49.164139 17660 solver.cpp:237]     Train net output #1: loss = 0.0111084 (* 1 = 0.0111084 loss)
I1212 00:20:49.164139 17660 sgd_solver.cpp:105] Iteration 159600, lr = 0.0001
I1212 00:20:57.254376 17660 solver.cpp:218] Iteration 159700 (12.3607 iter/s, 8.09013s/100 iters), loss = 0.00924848
I1212 00:20:57.254376 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:20:57.254376 17660 solver.cpp:237]     Train net output #1: loss = 0.0092484 (* 1 = 0.0092484 loss)
I1212 00:20:57.254376 17660 sgd_solver.cpp:105] Iteration 159700, lr = 0.0001
I1212 00:21:05.372493 17660 solver.cpp:218] Iteration 159800 (12.32 iter/s, 8.1169s/100 iters), loss = 0.00964987
I1212 00:21:05.372493 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:05.372493 17660 solver.cpp:237]     Train net output #1: loss = 0.00964978 (* 1 = 0.00964978 loss)
I1212 00:21:05.372493 17660 sgd_solver.cpp:105] Iteration 159800, lr = 0.0001
I1212 00:21:13.529165 17660 solver.cpp:218] Iteration 159900 (12.2606 iter/s, 8.15622s/100 iters), loss = 0.0122069
I1212 00:21:13.529165 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:13.529165 17660 solver.cpp:237]     Train net output #1: loss = 0.0122068 (* 1 = 0.0122068 loss)
I1212 00:21:13.529165 17660 sgd_solver.cpp:105] Iteration 159900, lr = 0.0001
I1212 00:21:21.249300 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:21:21.570327 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160000.caffemodel
I1212 00:21:21.626051 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160000.solverstate
I1212 00:21:21.633054 17660 solver.cpp:330] Iteration 160000, Testing net (#0)
I1212 00:21:21.633054 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:21:23.327816 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:21:23.394829 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:21:23.394829 17660 solver.cpp:397]     Test net output #1: loss = 0.251704 (* 1 = 0.251704 loss)
I1212 00:21:23.469820 17660 solver.cpp:218] Iteration 160000 (10.0604 iter/s, 9.93992s/100 iters), loss = 0.0141569
I1212 00:21:23.469820 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:23.469820 17660 solver.cpp:237]     Train net output #1: loss = 0.0141569 (* 1 = 0.0141569 loss)
I1212 00:21:23.469820 17660 sgd_solver.cpp:105] Iteration 160000, lr = 0.0001
I1212 00:21:31.571442 17660 solver.cpp:218] Iteration 160100 (12.344 iter/s, 8.10111s/100 iters), loss = 0.00877176
I1212 00:21:31.571442 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:31.571442 17660 solver.cpp:237]     Train net output #1: loss = 0.00877167 (* 1 = 0.00877167 loss)
I1212 00:21:31.571442 17660 sgd_solver.cpp:105] Iteration 160100, lr = 0.0001
I1212 00:21:39.678630 17660 solver.cpp:218] Iteration 160200 (12.3355 iter/s, 8.10666s/100 iters), loss = 0.00970848
I1212 00:21:39.678630 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:39.678630 17660 solver.cpp:237]     Train net output #1: loss = 0.0097084 (* 1 = 0.0097084 loss)
I1212 00:21:39.678630 17660 sgd_solver.cpp:105] Iteration 160200, lr = 0.0001
I1212 00:21:47.783217 17660 solver.cpp:218] Iteration 160300 (12.3394 iter/s, 8.10412s/100 iters), loss = 0.00925765
I1212 00:21:47.783217 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:47.783217 17660 solver.cpp:237]     Train net output #1: loss = 0.00925757 (* 1 = 0.00925757 loss)
I1212 00:21:47.783217 17660 sgd_solver.cpp:105] Iteration 160300, lr = 0.0001
I1212 00:21:56.038084 17660 solver.cpp:218] Iteration 160400 (12.1147 iter/s, 8.25444s/100 iters), loss = 0.010119
I1212 00:21:56.038084 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:21:56.038084 17660 solver.cpp:237]     Train net output #1: loss = 0.0101189 (* 1 = 0.0101189 loss)
I1212 00:21:56.038084 17660 sgd_solver.cpp:105] Iteration 160400, lr = 0.0001
I1212 00:22:03.802527 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:22:04.135601 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160500.caffemodel
I1212 00:22:04.174598 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_160500.solverstate
I1212 00:22:04.183598 17660 solver.cpp:330] Iteration 160500, Testing net (#0)
I1212 00:22:04.183598 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:22:05.893820 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:22:05.960834 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9355
I1212 00:22:05.960834 17660 solver.cpp:397]     Test net output #1: loss = 0.252253 (* 1 = 0.252253 loss)
I1212 00:22:06.037842 17660 solver.cpp:218] Iteration 160500 (10.0009 iter/s, 9.9991s/100 iters), loss = 0.01453
I1212 00:22:06.037842 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:06.037842 17660 solver.cpp:237]     Train net output #1: loss = 0.01453 (* 1 = 0.01453 loss)
I1212 00:22:06.037842 17660 sgd_solver.cpp:105] Iteration 160500, lr = 0.0001
I1212 00:22:14.229668 17660 solver.cpp:218] Iteration 160600 (12.2082 iter/s, 8.19121s/100 iters), loss = 0.012683
I1212 00:22:14.229668 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:14.229668 17660 solver.cpp:237]     Train net output #1: loss = 0.012683 (* 1 = 0.012683 loss)
I1212 00:22:14.229668 17660 sgd_solver.cpp:105] Iteration 160600, lr = 0.0001
I1212 00:22:22.411125 17660 solver.cpp:218] Iteration 160700 (12.2223 iter/s, 8.18175s/100 iters), loss = 0.00945877
I1212 00:22:22.412127 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:22.412127 17660 solver.cpp:237]     Train net output #1: loss = 0.00945869 (* 1 = 0.00945869 loss)
I1212 00:22:22.412127 17660 sgd_solver.cpp:105] Iteration 160700, lr = 0.0001
I1212 00:22:30.477589 17660 solver.cpp:218] Iteration 160800 (12.398 iter/s, 8.06581s/100 iters), loss = 0.00906612
I1212 00:22:30.477589 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:30.477589 17660 solver.cpp:237]     Train net output #1: loss = 0.00906604 (* 1 = 0.00906604 loss)
I1212 00:22:30.477589 17660 sgd_solver.cpp:105] Iteration 160800, lr = 0.0001
I1212 00:22:38.659613 17660 solver.cpp:218] Iteration 160900 (12.2239 iter/s, 8.1807s/100 iters), loss = 0.0123235
I1212 00:22:38.659613 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:38.659613 17660 solver.cpp:237]     Train net output #1: loss = 0.0123234 (* 1 = 0.0123234 loss)
I1212 00:22:38.659613 17660 sgd_solver.cpp:105] Iteration 160900, lr = 0.0001
I1212 00:22:46.419689 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:22:46.741763 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161000.caffemodel
I1212 00:22:46.801757 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161000.solverstate
I1212 00:22:46.807742 17660 solver.cpp:330] Iteration 161000, Testing net (#0)
I1212 00:22:46.807742 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:22:48.503207 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:22:48.569566 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:22:48.569566 17660 solver.cpp:397]     Test net output #1: loss = 0.252149 (* 1 = 0.252149 loss)
I1212 00:22:48.644343 17660 solver.cpp:218] Iteration 161000 (10.0151 iter/s, 9.98489s/100 iters), loss = 0.0109193
I1212 00:22:48.644343 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:48.644343 17660 solver.cpp:237]     Train net output #1: loss = 0.0109193 (* 1 = 0.0109193 loss)
I1212 00:22:48.644343 17660 sgd_solver.cpp:105] Iteration 161000, lr = 0.0001
I1212 00:22:56.827239 17660 solver.cpp:218] Iteration 161100 (12.2223 iter/s, 8.18176s/100 iters), loss = 0.0109123
I1212 00:22:56.827239 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:22:56.827239 17660 solver.cpp:237]     Train net output #1: loss = 0.0109122 (* 1 = 0.0109122 loss)
I1212 00:22:56.827239 17660 sgd_solver.cpp:105] Iteration 161100, lr = 0.0001
I1212 00:23:05.030556 17660 solver.cpp:218] Iteration 161200 (12.1913 iter/s, 8.20256s/100 iters), loss = 0.0167865
I1212 00:23:05.030556 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:05.030556 17660 solver.cpp:237]     Train net output #1: loss = 0.0167864 (* 1 = 0.0167864 loss)
I1212 00:23:05.030556 17660 sgd_solver.cpp:105] Iteration 161200, lr = 0.0001
I1212 00:23:13.265486 17660 solver.cpp:218] Iteration 161300 (12.1439 iter/s, 8.23459s/100 iters), loss = 0.00847994
I1212 00:23:13.265486 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:13.265486 17660 solver.cpp:237]     Train net output #1: loss = 0.00847986 (* 1 = 0.00847986 loss)
I1212 00:23:13.265486 17660 sgd_solver.cpp:105] Iteration 161300, lr = 0.0001
I1212 00:23:21.393520 17660 solver.cpp:218] Iteration 161400 (12.3046 iter/s, 8.12707s/100 iters), loss = 0.0100419
I1212 00:23:21.393520 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:21.393520 17660 solver.cpp:237]     Train net output #1: loss = 0.0100419 (* 1 = 0.0100419 loss)
I1212 00:23:21.393520 17660 sgd_solver.cpp:105] Iteration 161400, lr = 0.0001
I1212 00:23:29.122517 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:23:29.441123 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161500.caffemodel
I1212 00:23:29.473124 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_161500.solverstate
I1212 00:23:29.492123 17660 solver.cpp:330] Iteration 161500, Testing net (#0)
I1212 00:23:29.492123 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:23:31.170528 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:23:31.239536 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1212 00:23:31.239536 17660 solver.cpp:397]     Test net output #1: loss = 0.252319 (* 1 = 0.252319 loss)
I1212 00:23:31.314344 17660 solver.cpp:218] Iteration 161500 (10.0796 iter/s, 9.92106s/100 iters), loss = 0.0152499
I1212 00:23:31.314344 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:31.314344 17660 solver.cpp:237]     Train net output #1: loss = 0.0152499 (* 1 = 0.0152499 loss)
I1212 00:23:31.314344 17660 sgd_solver.cpp:105] Iteration 161500, lr = 0.0001
I1212 00:23:39.389482 17660 solver.cpp:218] Iteration 161600 (12.3845 iter/s, 8.07461s/100 iters), loss = 0.0139486
I1212 00:23:39.389482 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:39.389482 17660 solver.cpp:237]     Train net output #1: loss = 0.0139485 (* 1 = 0.0139485 loss)
I1212 00:23:39.389482 17660 sgd_solver.cpp:105] Iteration 161600, lr = 0.0001
I1212 00:23:47.499104 17660 solver.cpp:218] Iteration 161700 (12.332 iter/s, 8.10896s/100 iters), loss = 0.0105632
I1212 00:23:47.499104 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:47.499104 17660 solver.cpp:237]     Train net output #1: loss = 0.0105631 (* 1 = 0.0105631 loss)
I1212 00:23:47.499104 17660 sgd_solver.cpp:105] Iteration 161700, lr = 0.0001
I1212 00:23:55.652354 17660 solver.cpp:218] Iteration 161800 (12.267 iter/s, 8.15198s/100 iters), loss = 0.00911221
I1212 00:23:55.652354 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:23:55.652354 17660 solver.cpp:237]     Train net output #1: loss = 0.00911212 (* 1 = 0.00911212 loss)
I1212 00:23:55.652354 17660 sgd_solver.cpp:105] Iteration 161800, lr = 0.0001
I1212 00:24:03.740089 17660 solver.cpp:218] Iteration 161900 (12.3644 iter/s, 8.08775s/100 iters), loss = 0.0103989
I1212 00:24:03.740089 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:03.740089 17660 solver.cpp:237]     Train net output #1: loss = 0.0103989 (* 1 = 0.0103989 loss)
I1212 00:24:03.740089 17660 sgd_solver.cpp:105] Iteration 161900, lr = 0.0001
I1212 00:24:11.460341 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:24:11.785902 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162000.caffemodel
I1212 00:24:11.820902 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162000.solverstate
I1212 00:24:11.850930 17660 solver.cpp:330] Iteration 162000, Testing net (#0)
I1212 00:24:11.851930 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:24:13.540395 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:24:13.606431 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:24:13.606431 17660 solver.cpp:397]     Test net output #1: loss = 0.251268 (* 1 = 0.251268 loss)
I1212 00:24:13.681587 17660 solver.cpp:218] Iteration 162000 (10.0596 iter/s, 9.94073s/100 iters), loss = 0.0178133
I1212 00:24:13.681587 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:13.681587 17660 solver.cpp:237]     Train net output #1: loss = 0.0178132 (* 1 = 0.0178132 loss)
I1212 00:24:13.681587 17660 sgd_solver.cpp:105] Iteration 162000, lr = 0.0001
I1212 00:24:21.747727 17660 solver.cpp:218] Iteration 162100 (12.3979 iter/s, 8.06588s/100 iters), loss = 0.00829075
I1212 00:24:21.747727 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:21.747727 17660 solver.cpp:237]     Train net output #1: loss = 0.00829067 (* 1 = 0.00829067 loss)
I1212 00:24:21.747727 17660 sgd_solver.cpp:105] Iteration 162100, lr = 0.0001
I1212 00:24:29.808974 17660 solver.cpp:218] Iteration 162200 (12.4054 iter/s, 8.06098s/100 iters), loss = 0.0108989
I1212 00:24:29.809975 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:29.809975 17660 solver.cpp:237]     Train net output #1: loss = 0.0108988 (* 1 = 0.0108988 loss)
I1212 00:24:29.809975 17660 sgd_solver.cpp:105] Iteration 162200, lr = 0.0001
I1212 00:24:37.904389 17660 solver.cpp:218] Iteration 162300 (12.3549 iter/s, 8.09398s/100 iters), loss = 0.00915874
I1212 00:24:37.904389 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:37.904389 17660 solver.cpp:237]     Train net output #1: loss = 0.00915867 (* 1 = 0.00915867 loss)
I1212 00:24:37.904389 17660 sgd_solver.cpp:105] Iteration 162300, lr = 0.0001
I1212 00:24:45.961664 17660 solver.cpp:218] Iteration 162400 (12.4122 iter/s, 8.05657s/100 iters), loss = 0.00937077
I1212 00:24:45.961664 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:45.961664 17660 solver.cpp:237]     Train net output #1: loss = 0.0093707 (* 1 = 0.0093707 loss)
I1212 00:24:45.961664 17660 sgd_solver.cpp:105] Iteration 162400, lr = 0.0001
I1212 00:24:53.657687 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:24:53.977404 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162500.caffemodel
I1212 00:24:54.005547 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_162500.solverstate
I1212 00:24:54.033561 17660 solver.cpp:330] Iteration 162500, Testing net (#0)
I1212 00:24:54.033561 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:24:55.716138 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:24:55.783653 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1212 00:24:55.783653 17660 solver.cpp:397]     Test net output #1: loss = 0.251944 (* 1 = 0.251944 loss)
I1212 00:24:55.858162 17660 solver.cpp:218] Iteration 162500 (10.1049 iter/s, 9.89619s/100 iters), loss = 0.0113803
I1212 00:24:55.858162 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:24:55.858162 17660 solver.cpp:237]     Train net output #1: loss = 0.0113802 (* 1 = 0.0113802 loss)
I1212 00:24:55.858162 17660 sgd_solver.cpp:105] Iteration 162500, lr = 0.0001
I1212 00:25:03.942466 17660 solver.cpp:218] Iteration 162600 (12.3706 iter/s, 8.08369s/100 iters), loss = 0.00922197
I1212 00:25:03.942466 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:03.942466 17660 solver.cpp:237]     Train net output #1: loss = 0.0092219 (* 1 = 0.0092219 loss)
I1212 00:25:03.942466 17660 sgd_solver.cpp:105] Iteration 162600, lr = 0.0001
I1212 00:25:12.050070 17660 solver.cpp:218] Iteration 162700 (12.3338 iter/s, 8.10777s/100 iters), loss = 0.00965773
I1212 00:25:12.051069 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:12.051069 17660 solver.cpp:237]     Train net output #1: loss = 0.00965765 (* 1 = 0.00965765 loss)
I1212 00:25:12.051069 17660 sgd_solver.cpp:105] Iteration 162700, lr = 0.0001
I1212 00:25:20.179561 17660 solver.cpp:218] Iteration 162800 (12.3024 iter/s, 8.12847s/100 iters), loss = 0.0150187
I1212 00:25:20.180069 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:20.180069 17660 solver.cpp:237]     Train net output #1: loss = 0.0150186 (* 1 = 0.0150186 loss)
I1212 00:25:20.180069 17660 sgd_solver.cpp:105] Iteration 162800, lr = 0.0001
I1212 00:25:28.295428 17660 solver.cpp:218] Iteration 162900 (12.3225 iter/s, 8.11526s/100 iters), loss = 0.0102783
I1212 00:25:28.295428 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:28.295428 17660 solver.cpp:237]     Train net output #1: loss = 0.0102782 (* 1 = 0.0102782 loss)
I1212 00:25:28.295428 17660 sgd_solver.cpp:105] Iteration 162900, lr = 0.0001
I1212 00:25:36.054291 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:25:36.374313 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163000.caffemodel
I1212 00:25:36.407321 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163000.solverstate
I1212 00:25:36.442323 17660 solver.cpp:330] Iteration 163000, Testing net (#0)
I1212 00:25:36.442323 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:25:38.144614 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:25:38.211621 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1212 00:25:38.211621 17660 solver.cpp:397]     Test net output #1: loss = 0.251515 (* 1 = 0.251515 loss)
I1212 00:25:38.287627 17660 solver.cpp:218] Iteration 163000 (10.0084 iter/s, 9.99157s/100 iters), loss = 0.0176333
I1212 00:25:38.288130 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:38.288130 17660 solver.cpp:237]     Train net output #1: loss = 0.0176333 (* 1 = 0.0176333 loss)
I1212 00:25:38.288130 17660 sgd_solver.cpp:105] Iteration 163000, lr = 0.0001
I1212 00:25:46.452059 17660 solver.cpp:218] Iteration 163100 (12.2497 iter/s, 8.16349s/100 iters), loss = 0.0123881
I1212 00:25:46.452059 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:46.452059 17660 solver.cpp:237]     Train net output #1: loss = 0.0123881 (* 1 = 0.0123881 loss)
I1212 00:25:46.452059 17660 sgd_solver.cpp:105] Iteration 163100, lr = 0.0001
I1212 00:25:54.683311 17660 solver.cpp:218] Iteration 163200 (12.1496 iter/s, 8.23071s/100 iters), loss = 0.00975915
I1212 00:25:54.683311 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:25:54.683311 17660 solver.cpp:237]     Train net output #1: loss = 0.00975907 (* 1 = 0.00975907 loss)
I1212 00:25:54.683311 17660 sgd_solver.cpp:105] Iteration 163200, lr = 0.0001
I1212 00:26:02.840976 17660 solver.cpp:218] Iteration 163300 (12.2587 iter/s, 8.15749s/100 iters), loss = 0.0115774
I1212 00:26:02.840976 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:02.840976 17660 solver.cpp:237]     Train net output #1: loss = 0.0115773 (* 1 = 0.0115773 loss)
I1212 00:26:02.840976 17660 sgd_solver.cpp:105] Iteration 163300, lr = 0.0001
I1212 00:26:11.013856 17660 solver.cpp:218] Iteration 163400 (12.2371 iter/s, 8.17188s/100 iters), loss = 0.00982824
I1212 00:26:11.013856 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:11.013856 17660 solver.cpp:237]     Train net output #1: loss = 0.00982817 (* 1 = 0.00982817 loss)
I1212 00:26:11.013856 17660 sgd_solver.cpp:105] Iteration 163400, lr = 0.0001
I1212 00:26:18.750069 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:26:19.068352 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163500.caffemodel
I1212 00:26:19.097350 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_163500.solverstate
I1212 00:26:19.103363 17660 solver.cpp:330] Iteration 163500, Testing net (#0)
I1212 00:26:19.103363 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:26:20.802665 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:26:20.868594 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1212 00:26:20.868594 17660 solver.cpp:397]     Test net output #1: loss = 0.252736 (* 1 = 0.252736 loss)
I1212 00:26:20.944605 17660 solver.cpp:218] Iteration 163500 (10.0698 iter/s, 9.93066s/100 iters), loss = 0.0118292
I1212 00:26:20.944605 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:20.944605 17660 solver.cpp:237]     Train net output #1: loss = 0.0118291 (* 1 = 0.0118291 loss)
I1212 00:26:20.944605 17660 sgd_solver.cpp:105] Iteration 163500, lr = 0.0001
I1212 00:26:29.104058 17660 solver.cpp:218] Iteration 163600 (12.2572 iter/s, 8.15847s/100 iters), loss = 0.0138062
I1212 00:26:29.104058 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:29.104058 17660 solver.cpp:237]     Train net output #1: loss = 0.0138061 (* 1 = 0.0138061 loss)
I1212 00:26:29.104058 17660 sgd_solver.cpp:105] Iteration 163600, lr = 0.0001
I1212 00:26:37.207142 17660 solver.cpp:218] Iteration 163700 (12.3414 iter/s, 8.10283s/100 iters), loss = 0.0134469
I1212 00:26:37.207142 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:37.207142 17660 solver.cpp:237]     Train net output #1: loss = 0.0134468 (* 1 = 0.0134468 loss)
I1212 00:26:37.207142 17660 sgd_solver.cpp:105] Iteration 163700, lr = 0.0001
I1212 00:26:45.326649 17660 solver.cpp:218] Iteration 163800 (12.3168 iter/s, 8.11897s/100 iters), loss = 0.0102881
I1212 00:26:45.327149 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:45.327149 17660 solver.cpp:237]     Train net output #1: loss = 0.010288 (* 1 = 0.010288 loss)
I1212 00:26:45.327149 17660 sgd_solver.cpp:105] Iteration 163800, lr = 0.0001
I1212 00:26:53.515293 17660 solver.cpp:218] Iteration 163900 (12.2125 iter/s, 8.18835s/100 iters), loss = 0.00942141
I1212 00:26:53.515293 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:26:53.515293 17660 solver.cpp:237]     Train net output #1: loss = 0.00942134 (* 1 = 0.00942134 loss)
I1212 00:26:53.515293 17660 sgd_solver.cpp:105] Iteration 163900, lr = 0.0001
I1212 00:27:01.262066 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:27:01.580090 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164000.caffemodel
I1212 00:27:01.634093 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164000.solverstate
I1212 00:27:01.640099 17660 solver.cpp:330] Iteration 164000, Testing net (#0)
I1212 00:27:01.640099 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:27:03.328754 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:27:03.397256 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1212 00:27:03.397256 17660 solver.cpp:397]     Test net output #1: loss = 0.252742 (* 1 = 0.252742 loss)
I1212 00:27:03.474267 17660 solver.cpp:218] Iteration 164000 (10.0419 iter/s, 9.95832s/100 iters), loss = 0.0104154
I1212 00:27:03.474267 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:03.474267 17660 solver.cpp:237]     Train net output #1: loss = 0.0104153 (* 1 = 0.0104153 loss)
I1212 00:27:03.474267 17660 sgd_solver.cpp:105] Iteration 164000, lr = 0.0001
I1212 00:27:11.731943 17660 solver.cpp:218] Iteration 164100 (12.1119 iter/s, 8.25636s/100 iters), loss = 0.0110907
I1212 00:27:11.731943 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:11.731943 17660 solver.cpp:237]     Train net output #1: loss = 0.0110906 (* 1 = 0.0110906 loss)
I1212 00:27:11.731943 17660 sgd_solver.cpp:105] Iteration 164100, lr = 0.0001
I1212 00:27:19.878222 17660 solver.cpp:218] Iteration 164200 (12.2759 iter/s, 8.14602s/100 iters), loss = 0.0125298
I1212 00:27:19.878222 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:19.878222 17660 solver.cpp:237]     Train net output #1: loss = 0.0125297 (* 1 = 0.0125297 loss)
I1212 00:27:19.878222 17660 sgd_solver.cpp:105] Iteration 164200, lr = 0.0001
I1212 00:27:28.026150 17660 solver.cpp:218] Iteration 164300 (12.2741 iter/s, 8.14723s/100 iters), loss = 0.00935575
I1212 00:27:28.026150 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:28.026150 17660 solver.cpp:237]     Train net output #1: loss = 0.00935568 (* 1 = 0.00935568 loss)
I1212 00:27:28.026150 17660 sgd_solver.cpp:105] Iteration 164300, lr = 0.0001
I1212 00:27:36.183696 17660 solver.cpp:218] Iteration 164400 (12.2588 iter/s, 8.15741s/100 iters), loss = 0.0148001
I1212 00:27:36.183696 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:36.183696 17660 solver.cpp:237]     Train net output #1: loss = 0.0148 (* 1 = 0.0148 loss)
I1212 00:27:36.183696 17660 sgd_solver.cpp:105] Iteration 164400, lr = 0.0001
I1212 00:27:43.897879 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:27:44.219013 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164500.caffemodel
I1212 00:27:44.251520 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_164500.solverstate
I1212 00:27:44.257565 17660 solver.cpp:330] Iteration 164500, Testing net (#0)
I1212 00:27:44.257565 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:27:45.941124 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:27:46.008625 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1212 00:27:46.008625 17660 solver.cpp:397]     Test net output #1: loss = 0.253045 (* 1 = 0.253045 loss)
I1212 00:27:46.083636 17660 solver.cpp:218] Iteration 164500 (10.1017 iter/s, 9.89937s/100 iters), loss = 0.0200051
I1212 00:27:46.083636 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:46.083636 17660 solver.cpp:237]     Train net output #1: loss = 0.0200051 (* 1 = 0.0200051 loss)
I1212 00:27:46.083636 17660 sgd_solver.cpp:105] Iteration 164500, lr = 0.0001
I1212 00:27:54.161063 17660 solver.cpp:218] Iteration 164600 (12.3818 iter/s, 8.07635s/100 iters), loss = 0.0111848
I1212 00:27:54.161063 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:27:54.161063 17660 solver.cpp:237]     Train net output #1: loss = 0.0111847 (* 1 = 0.0111847 loss)
I1212 00:27:54.161063 17660 sgd_solver.cpp:105] Iteration 164600, lr = 0.0001
I1212 00:28:02.294220 17660 solver.cpp:218] Iteration 164700 (12.2961 iter/s, 8.13266s/100 iters), loss = 0.0104626
I1212 00:28:02.294220 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:02.294220 17660 solver.cpp:237]     Train net output #1: loss = 0.0104625 (* 1 = 0.0104625 loss)
I1212 00:28:02.294220 17660 sgd_solver.cpp:105] Iteration 164700, lr = 0.0001
I1212 00:28:10.394178 17660 solver.cpp:218] Iteration 164800 (12.3455 iter/s, 8.10012s/100 iters), loss = 0.00870118
I1212 00:28:10.394178 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:10.394178 17660 solver.cpp:237]     Train net output #1: loss = 0.00870111 (* 1 = 0.00870111 loss)
I1212 00:28:10.394178 17660 sgd_solver.cpp:105] Iteration 164800, lr = 0.0001
I1212 00:28:18.514407 17660 solver.cpp:218] Iteration 164900 (12.3167 iter/s, 8.11905s/100 iters), loss = 0.0108331
I1212 00:28:18.514407 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:18.514407 17660 solver.cpp:237]     Train net output #1: loss = 0.010833 (* 1 = 0.010833 loss)
I1212 00:28:18.514407 17660 sgd_solver.cpp:105] Iteration 164900, lr = 0.0001
I1212 00:28:26.255261 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:28:26.573498 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165000.caffemodel
I1212 00:28:26.617496 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165000.solverstate
I1212 00:28:26.623507 17660 solver.cpp:330] Iteration 165000, Testing net (#0)
I1212 00:28:26.624495 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:28:28.335316 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:28:28.404083 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:28:28.405083 17660 solver.cpp:397]     Test net output #1: loss = 0.252466 (* 1 = 0.252466 loss)
I1212 00:28:28.485605 17660 solver.cpp:218] Iteration 165000 (10.0291 iter/s, 9.97098s/100 iters), loss = 0.0124534
I1212 00:28:28.485605 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:28.485605 17660 solver.cpp:237]     Train net output #1: loss = 0.0124534 (* 1 = 0.0124534 loss)
I1212 00:28:28.485605 17660 sgd_solver.cpp:105] Iteration 165000, lr = 0.0001
I1212 00:28:36.672698 17660 solver.cpp:218] Iteration 165100 (12.2147 iter/s, 8.18684s/100 iters), loss = 0.00991622
I1212 00:28:36.672698 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:36.673705 17660 solver.cpp:237]     Train net output #1: loss = 0.00991615 (* 1 = 0.00991615 loss)
I1212 00:28:36.673705 17660 sgd_solver.cpp:105] Iteration 165100, lr = 0.0001
I1212 00:28:44.920294 17660 solver.cpp:218] Iteration 165200 (12.1258 iter/s, 8.24688s/100 iters), loss = 0.0122088
I1212 00:28:44.920294 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:44.920294 17660 solver.cpp:237]     Train net output #1: loss = 0.0122087 (* 1 = 0.0122087 loss)
I1212 00:28:44.920294 17660 sgd_solver.cpp:105] Iteration 165200, lr = 0.0001
I1212 00:28:53.022626 17660 solver.cpp:218] Iteration 165300 (12.343 iter/s, 8.10175s/100 iters), loss = 0.013659
I1212 00:28:53.022626 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:28:53.022626 17660 solver.cpp:237]     Train net output #1: loss = 0.0136589 (* 1 = 0.0136589 loss)
I1212 00:28:53.022626 17660 sgd_solver.cpp:105] Iteration 165300, lr = 0.0001
I1212 00:29:01.125758 17660 solver.cpp:218] Iteration 165400 (12.3418 iter/s, 8.10256s/100 iters), loss = 0.00997128
I1212 00:29:01.125758 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:01.125758 17660 solver.cpp:237]     Train net output #1: loss = 0.00997121 (* 1 = 0.00997121 loss)
I1212 00:29:01.125758 17660 sgd_solver.cpp:105] Iteration 165400, lr = 0.0001
I1212 00:29:08.820117 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:29:09.148761 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165500.caffemodel
I1212 00:29:09.183792 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_165500.solverstate
I1212 00:29:09.189793 17660 solver.cpp:330] Iteration 165500, Testing net (#0)
I1212 00:29:09.190790 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:29:10.899191 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:29:10.967226 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1212 00:29:10.967226 17660 solver.cpp:397]     Test net output #1: loss = 0.25225 (* 1 = 0.25225 loss)
I1212 00:29:11.042784 17660 solver.cpp:218] Iteration 165500 (10.0843 iter/s, 9.91642s/100 iters), loss = 0.0136833
I1212 00:29:11.042784 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:11.042784 17660 solver.cpp:237]     Train net output #1: loss = 0.0136832 (* 1 = 0.0136832 loss)
I1212 00:29:11.042784 17660 sgd_solver.cpp:105] Iteration 165500, lr = 0.0001
I1212 00:29:19.256685 17660 solver.cpp:218] Iteration 165600 (12.1758 iter/s, 8.213s/100 iters), loss = 0.00926443
I1212 00:29:19.256685 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:19.256685 17660 solver.cpp:237]     Train net output #1: loss = 0.00926436 (* 1 = 0.00926436 loss)
I1212 00:29:19.256685 17660 sgd_solver.cpp:105] Iteration 165600, lr = 0.0001
I1212 00:29:27.465118 17660 solver.cpp:218] Iteration 165700 (12.1839 iter/s, 8.20757s/100 iters), loss = 0.0121292
I1212 00:29:27.465118 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:27.465118 17660 solver.cpp:237]     Train net output #1: loss = 0.0121291 (* 1 = 0.0121291 loss)
I1212 00:29:27.465118 17660 sgd_solver.cpp:105] Iteration 165700, lr = 0.0001
I1212 00:29:35.626927 17660 solver.cpp:218] Iteration 165800 (12.2524 iter/s, 8.16169s/100 iters), loss = 0.0096416
I1212 00:29:35.626927 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:35.626927 17660 solver.cpp:237]     Train net output #1: loss = 0.00964153 (* 1 = 0.00964153 loss)
I1212 00:29:35.626927 17660 sgd_solver.cpp:105] Iteration 165800, lr = 0.0001
I1212 00:29:43.857357 17660 solver.cpp:218] Iteration 165900 (12.1513 iter/s, 8.22954s/100 iters), loss = 0.0112437
I1212 00:29:43.857357 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:43.857357 17660 solver.cpp:237]     Train net output #1: loss = 0.0112437 (* 1 = 0.0112437 loss)
I1212 00:29:43.857357 17660 sgd_solver.cpp:105] Iteration 165900, lr = 0.0001
I1212 00:29:51.623519 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:29:51.941553 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166000.caffemodel
I1212 00:29:51.999563 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166000.solverstate
I1212 00:29:52.006577 17660 solver.cpp:330] Iteration 166000, Testing net (#0)
I1212 00:29:52.006577 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:29:53.711731 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:29:53.779734 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1212 00:29:53.779734 17660 solver.cpp:397]     Test net output #1: loss = 0.251328 (* 1 = 0.251328 loss)
I1212 00:29:53.856739 17660 solver.cpp:218] Iteration 166000 (10.0009 iter/s, 9.99908s/100 iters), loss = 0.013949
I1212 00:29:53.857740 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:29:53.857740 17660 solver.cpp:237]     Train net output #1: loss = 0.0139489 (* 1 = 0.0139489 loss)
I1212 00:29:53.857740 17660 sgd_solver.cpp:105] Iteration 166000, lr = 0.0001
I1212 00:30:01.991672 17660 solver.cpp:218] Iteration 166100 (12.2946 iter/s, 8.13366s/100 iters), loss = 0.0105558
I1212 00:30:01.991672 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:01.992164 17660 solver.cpp:237]     Train net output #1: loss = 0.0105557 (* 1 = 0.0105557 loss)
I1212 00:30:01.992164 17660 sgd_solver.cpp:105] Iteration 166100, lr = 0.0001
I1212 00:30:10.064147 17660 solver.cpp:218] Iteration 166200 (12.3882 iter/s, 8.0722s/100 iters), loss = 0.0179218
I1212 00:30:10.064147 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:10.064147 17660 solver.cpp:237]     Train net output #1: loss = 0.0179218 (* 1 = 0.0179218 loss)
I1212 00:30:10.064147 17660 sgd_solver.cpp:105] Iteration 166200, lr = 0.0001
I1212 00:30:18.154171 17660 solver.cpp:218] Iteration 166300 (12.3613 iter/s, 8.08975s/100 iters), loss = 0.0127383
I1212 00:30:18.154171 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:18.154171 17660 solver.cpp:237]     Train net output #1: loss = 0.0127382 (* 1 = 0.0127382 loss)
I1212 00:30:18.154171 17660 sgd_solver.cpp:105] Iteration 166300, lr = 0.0001
I1212 00:30:26.256186 17660 solver.cpp:218] Iteration 166400 (12.3439 iter/s, 8.10119s/100 iters), loss = 0.0106733
I1212 00:30:26.256186 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:26.256186 17660 solver.cpp:237]     Train net output #1: loss = 0.0106732 (* 1 = 0.0106732 loss)
I1212 00:30:26.256186 17660 sgd_solver.cpp:105] Iteration 166400, lr = 0.0001
I1212 00:30:33.960062 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:30:34.278851 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166500.caffemodel
I1212 00:30:34.314416 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_166500.solverstate
I1212 00:30:34.322417 17660 solver.cpp:330] Iteration 166500, Testing net (#0)
I1212 00:30:34.322417 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:30:36.007967 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:30:36.073873 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:30:36.073873 17660 solver.cpp:397]     Test net output #1: loss = 0.252274 (* 1 = 0.252274 loss)
I1212 00:30:36.150884 17660 solver.cpp:218] Iteration 166500 (10.1067 iter/s, 9.89442s/100 iters), loss = 0.0143183
I1212 00:30:36.151870 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:36.151870 17660 solver.cpp:237]     Train net output #1: loss = 0.0143182 (* 1 = 0.0143182 loss)
I1212 00:30:36.151870 17660 sgd_solver.cpp:105] Iteration 166500, lr = 0.0001
I1212 00:30:44.237903 17660 solver.cpp:218] Iteration 166600 (12.3674 iter/s, 8.08581s/100 iters), loss = 0.00922183
I1212 00:30:44.237903 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:44.237903 17660 solver.cpp:237]     Train net output #1: loss = 0.00922177 (* 1 = 0.00922177 loss)
I1212 00:30:44.237903 17660 sgd_solver.cpp:105] Iteration 166600, lr = 0.0001
I1212 00:30:52.507625 17660 solver.cpp:218] Iteration 166700 (12.093 iter/s, 8.26923s/100 iters), loss = 0.0115292
I1212 00:30:52.507625 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:30:52.507625 17660 solver.cpp:237]     Train net output #1: loss = 0.0115291 (* 1 = 0.0115291 loss)
I1212 00:30:52.507625 17660 sgd_solver.cpp:105] Iteration 166700, lr = 0.0001
I1212 00:31:00.758848 17660 solver.cpp:218] Iteration 166800 (12.1202 iter/s, 8.25066s/100 iters), loss = 0.00953985
I1212 00:31:00.758848 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:00.758848 17660 solver.cpp:237]     Train net output #1: loss = 0.00953979 (* 1 = 0.00953979 loss)
I1212 00:31:00.758848 17660 sgd_solver.cpp:105] Iteration 166800, lr = 0.0001
I1212 00:31:08.904572 17660 solver.cpp:218] Iteration 166900 (12.2765 iter/s, 8.14566s/100 iters), loss = 0.0158079
I1212 00:31:08.904572 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:08.905571 17660 solver.cpp:237]     Train net output #1: loss = 0.0158078 (* 1 = 0.0158078 loss)
I1212 00:31:08.905571 17660 sgd_solver.cpp:105] Iteration 166900, lr = 0.0001
I1212 00:31:16.587514 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:31:16.910540 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167000.caffemodel
I1212 00:31:16.968107 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167000.solverstate
I1212 00:31:16.974107 17660 solver.cpp:330] Iteration 167000, Testing net (#0)
I1212 00:31:16.974107 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:31:18.660276 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:31:18.727284 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1212 00:31:18.727782 17660 solver.cpp:397]     Test net output #1: loss = 0.252249 (* 1 = 0.252249 loss)
I1212 00:31:18.803290 17660 solver.cpp:218] Iteration 167000 (10.1035 iter/s, 9.89758s/100 iters), loss = 0.0125574
I1212 00:31:18.803290 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:18.803290 17660 solver.cpp:237]     Train net output #1: loss = 0.0125573 (* 1 = 0.0125573 loss)
I1212 00:31:18.803290 17660 sgd_solver.cpp:105] Iteration 167000, lr = 0.0001
I1212 00:31:26.992836 17660 solver.cpp:218] Iteration 167100 (12.2121 iter/s, 8.18858s/100 iters), loss = 0.0134087
I1212 00:31:26.992836 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:26.992836 17660 solver.cpp:237]     Train net output #1: loss = 0.0134086 (* 1 = 0.0134086 loss)
I1212 00:31:26.992836 17660 sgd_solver.cpp:105] Iteration 167100, lr = 0.0001
I1212 00:31:35.166260 17660 solver.cpp:218] Iteration 167200 (12.2349 iter/s, 8.17336s/100 iters), loss = 0.0122244
I1212 00:31:35.166260 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:35.166260 17660 solver.cpp:237]     Train net output #1: loss = 0.0122243 (* 1 = 0.0122243 loss)
I1212 00:31:35.166260 17660 sgd_solver.cpp:105] Iteration 167200, lr = 0.0001
I1212 00:31:43.342921 17660 solver.cpp:218] Iteration 167300 (12.2301 iter/s, 8.17653s/100 iters), loss = 0.0100866
I1212 00:31:43.343922 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:43.343922 17660 solver.cpp:237]     Train net output #1: loss = 0.0100865 (* 1 = 0.0100865 loss)
I1212 00:31:43.343922 17660 sgd_solver.cpp:105] Iteration 167300, lr = 0.0001
I1212 00:31:51.472061 17660 solver.cpp:218] Iteration 167400 (12.3027 iter/s, 8.12828s/100 iters), loss = 0.00963129
I1212 00:31:51.472061 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:31:51.472061 17660 solver.cpp:237]     Train net output #1: loss = 0.00963122 (* 1 = 0.00963122 loss)
I1212 00:31:51.472061 17660 sgd_solver.cpp:105] Iteration 167400, lr = 0.0001
I1212 00:31:59.146306 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:31:59.462544 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167500.caffemodel
I1212 00:31:59.491547 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_167500.solverstate
I1212 00:31:59.497545 17660 solver.cpp:330] Iteration 167500, Testing net (#0)
I1212 00:31:59.498543 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:32:01.179986 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:32:01.247156 17660 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1212 00:32:01.247156 17660 solver.cpp:397]     Test net output #1: loss = 0.251842 (* 1 = 0.251842 loss)
I1212 00:32:01.321179 17660 solver.cpp:218] Iteration 167500 (10.1536 iter/s, 9.84875s/100 iters), loss = 0.0117362
I1212 00:32:01.322178 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:01.322178 17660 solver.cpp:237]     Train net output #1: loss = 0.0117361 (* 1 = 0.0117361 loss)
I1212 00:32:01.322178 17660 sgd_solver.cpp:105] Iteration 167500, lr = 0.0001
I1212 00:32:09.475414 17660 solver.cpp:218] Iteration 167600 (12.2655 iter/s, 8.15292s/100 iters), loss = 0.0151886
I1212 00:32:09.475414 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:09.475414 17660 solver.cpp:237]     Train net output #1: loss = 0.0151885 (* 1 = 0.0151885 loss)
I1212 00:32:09.475414 17660 sgd_solver.cpp:105] Iteration 167600, lr = 0.0001
I1212 00:32:17.657058 17660 solver.cpp:218] Iteration 167700 (12.2231 iter/s, 8.18124s/100 iters), loss = 0.0116309
I1212 00:32:17.657058 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:17.657058 17660 solver.cpp:237]     Train net output #1: loss = 0.0116308 (* 1 = 0.0116308 loss)
I1212 00:32:17.657058 17660 sgd_solver.cpp:105] Iteration 167700, lr = 0.0001
I1212 00:32:25.754698 17660 solver.cpp:218] Iteration 167800 (12.3499 iter/s, 8.09724s/100 iters), loss = 0.0155329
I1212 00:32:25.754698 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:25.754698 17660 solver.cpp:237]     Train net output #1: loss = 0.0155328 (* 1 = 0.0155328 loss)
I1212 00:32:25.754698 17660 sgd_solver.cpp:105] Iteration 167800, lr = 0.0001
I1212 00:32:33.819447 17660 solver.cpp:218] Iteration 167900 (12.4009 iter/s, 8.06393s/100 iters), loss = 0.00944868
I1212 00:32:33.819447 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:33.819447 17660 solver.cpp:237]     Train net output #1: loss = 0.00944861 (* 1 = 0.00944861 loss)
I1212 00:32:33.819447 17660 sgd_solver.cpp:105] Iteration 167900, lr = 0.0001
I1212 00:32:41.568167 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:32:41.887259 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168000.caffemodel
I1212 00:32:41.934260 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168000.solverstate
I1212 00:32:41.941258 17660 solver.cpp:330] Iteration 168000, Testing net (#0)
I1212 00:32:41.941258 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:32:43.625730 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:32:43.692239 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1212 00:32:43.692239 17660 solver.cpp:397]     Test net output #1: loss = 0.251893 (* 1 = 0.251893 loss)
I1212 00:32:43.766993 17660 solver.cpp:218] Iteration 168000 (10.0532 iter/s, 9.94705s/100 iters), loss = 0.013006
I1212 00:32:43.766993 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:43.766993 17660 solver.cpp:237]     Train net output #1: loss = 0.0130059 (* 1 = 0.0130059 loss)
I1212 00:32:43.766993 17660 sgd_solver.cpp:105] Iteration 168000, lr = 0.0001
I1212 00:32:51.943856 17660 solver.cpp:218] Iteration 168100 (12.2295 iter/s, 8.17693s/100 iters), loss = 0.0144076
I1212 00:32:51.943856 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:32:51.943856 17660 solver.cpp:237]     Train net output #1: loss = 0.0144075 (* 1 = 0.0144075 loss)
I1212 00:32:51.943856 17660 sgd_solver.cpp:105] Iteration 168100, lr = 0.0001
I1212 00:33:00.062742 17660 solver.cpp:218] Iteration 168200 (12.3188 iter/s, 8.11769s/100 iters), loss = 0.0100803
I1212 00:33:00.062742 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:00.062742 17660 solver.cpp:237]     Train net output #1: loss = 0.0100802 (* 1 = 0.0100802 loss)
I1212 00:33:00.062742 17660 sgd_solver.cpp:105] Iteration 168200, lr = 0.0001
I1212 00:33:08.165529 17660 solver.cpp:218] Iteration 168300 (12.3424 iter/s, 8.10216s/100 iters), loss = 0.00955223
I1212 00:33:08.165529 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:08.165529 17660 solver.cpp:237]     Train net output #1: loss = 0.00955216 (* 1 = 0.00955216 loss)
I1212 00:33:08.165529 17660 sgd_solver.cpp:105] Iteration 168300, lr = 0.0001
I1212 00:33:16.282460 17660 solver.cpp:218] Iteration 168400 (12.3206 iter/s, 8.11647s/100 iters), loss = 0.0109103
I1212 00:33:16.282460 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:16.282460 17660 solver.cpp:237]     Train net output #1: loss = 0.0109102 (* 1 = 0.0109102 loss)
I1212 00:33:16.282460 17660 sgd_solver.cpp:105] Iteration 168400, lr = 0.0001
I1212 00:33:24.002112 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:33:24.322060 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168500.caffemodel
I1212 00:33:24.354061 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_168500.solverstate
I1212 00:33:24.360069 17660 solver.cpp:330] Iteration 168500, Testing net (#0)
I1212 00:33:24.360568 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:33:26.043835 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:33:26.111846 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1212 00:33:26.111846 17660 solver.cpp:397]     Test net output #1: loss = 0.251739 (* 1 = 0.251739 loss)
I1212 00:33:26.186573 17660 solver.cpp:218] Iteration 168500 (10.0971 iter/s, 9.90386s/100 iters), loss = 0.0126766
I1212 00:33:26.186573 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:26.186573 17660 solver.cpp:237]     Train net output #1: loss = 0.0126765 (* 1 = 0.0126765 loss)
I1212 00:33:26.186573 17660 sgd_solver.cpp:105] Iteration 168500, lr = 0.0001
I1212 00:33:34.324853 17660 solver.cpp:218] Iteration 168600 (12.2885 iter/s, 8.13769s/100 iters), loss = 0.0125525
I1212 00:33:34.324853 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:34.324853 17660 solver.cpp:237]     Train net output #1: loss = 0.0125525 (* 1 = 0.0125525 loss)
I1212 00:33:34.324853 17660 sgd_solver.cpp:105] Iteration 168600, lr = 0.0001
I1212 00:33:42.436977 17660 solver.cpp:218] Iteration 168700 (12.3277 iter/s, 8.11178s/100 iters), loss = 0.0144711
I1212 00:33:42.436977 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:42.436977 17660 solver.cpp:237]     Train net output #1: loss = 0.0144711 (* 1 = 0.0144711 loss)
I1212 00:33:42.437978 17660 sgd_solver.cpp:105] Iteration 168700, lr = 0.0001
I1212 00:33:50.554637 17660 solver.cpp:218] Iteration 168800 (12.321 iter/s, 8.11622s/100 iters), loss = 0.0102173
I1212 00:33:50.554637 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:50.554637 17660 solver.cpp:237]     Train net output #1: loss = 0.0102172 (* 1 = 0.0102172 loss)
I1212 00:33:50.554637 17660 sgd_solver.cpp:105] Iteration 168800, lr = 0.0001
I1212 00:33:58.688125 17660 solver.cpp:218] Iteration 168900 (12.2954 iter/s, 8.13314s/100 iters), loss = 0.0111115
I1212 00:33:58.688125 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:33:58.688125 17660 solver.cpp:237]     Train net output #1: loss = 0.0111114 (* 1 = 0.0111114 loss)
I1212 00:33:58.688125 17660 sgd_solver.cpp:105] Iteration 168900, lr = 0.0001
I1212 00:34:06.423826 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:34:06.742369 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169000.caffemodel
I1212 00:34:06.803380 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169000.solverstate
I1212 00:34:06.810381 17660 solver.cpp:330] Iteration 169000, Testing net (#0)
I1212 00:34:06.810381 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:34:08.517571 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:34:08.587074 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1212 00:34:08.587574 17660 solver.cpp:397]     Test net output #1: loss = 0.251706 (* 1 = 0.251706 loss)
I1212 00:34:08.663578 17660 solver.cpp:218] Iteration 169000 (10.0254 iter/s, 9.9747s/100 iters), loss = 0.0149069
I1212 00:34:08.663578 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:08.663578 17660 solver.cpp:237]     Train net output #1: loss = 0.0149068 (* 1 = 0.0149068 loss)
I1212 00:34:08.663578 17660 sgd_solver.cpp:105] Iteration 169000, lr = 0.0001
I1212 00:34:16.783241 17660 solver.cpp:218] Iteration 169100 (12.3168 iter/s, 8.11899s/100 iters), loss = 0.0112985
I1212 00:34:16.783241 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:16.783241 17660 solver.cpp:237]     Train net output #1: loss = 0.0112984 (* 1 = 0.0112984 loss)
I1212 00:34:16.783241 17660 sgd_solver.cpp:105] Iteration 169100, lr = 0.0001
I1212 00:34:24.905198 17660 solver.cpp:218] Iteration 169200 (12.3128 iter/s, 8.12162s/100 iters), loss = 0.0140488
I1212 00:34:24.905198 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:24.905198 17660 solver.cpp:237]     Train net output #1: loss = 0.0140487 (* 1 = 0.0140487 loss)
I1212 00:34:24.905198 17660 sgd_solver.cpp:105] Iteration 169200, lr = 0.0001
I1212 00:34:33.040807 17660 solver.cpp:218] Iteration 169300 (12.2918 iter/s, 8.13547s/100 iters), loss = 0.0130115
I1212 00:34:33.040807 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:33.040807 17660 solver.cpp:237]     Train net output #1: loss = 0.0130114 (* 1 = 0.0130114 loss)
I1212 00:34:33.040807 17660 sgd_solver.cpp:105] Iteration 169300, lr = 0.0001
I1212 00:34:41.172078 17660 solver.cpp:218] Iteration 169400 (12.2999 iter/s, 8.13018s/100 iters), loss = 0.0170289
I1212 00:34:41.172078 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:41.172078 17660 solver.cpp:237]     Train net output #1: loss = 0.0170289 (* 1 = 0.0170289 loss)
I1212 00:34:41.172078 17660 sgd_solver.cpp:105] Iteration 169400, lr = 0.0001
I1212 00:34:48.949385 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:34:49.270577 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169500.caffemodel
I1212 00:34:49.302580 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_169500.solverstate
I1212 00:34:49.309082 17660 solver.cpp:330] Iteration 169500, Testing net (#0)
I1212 00:34:49.309581 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:34:51.052589 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:34:51.120649 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9351
I1212 00:34:51.120649 17660 solver.cpp:397]     Test net output #1: loss = 0.252114 (* 1 = 0.252114 loss)
I1212 00:34:51.195626 17660 solver.cpp:218] Iteration 169500 (9.97724 iter/s, 10.0228s/100 iters), loss = 0.0109533
I1212 00:34:51.195626 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:51.195626 17660 solver.cpp:237]     Train net output #1: loss = 0.0109532 (* 1 = 0.0109532 loss)
I1212 00:34:51.195626 17660 sgd_solver.cpp:105] Iteration 169500, lr = 0.0001
I1212 00:34:59.352526 17660 solver.cpp:218] Iteration 169600 (12.2594 iter/s, 8.15704s/100 iters), loss = 0.0120815
I1212 00:34:59.352526 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:34:59.352526 17660 solver.cpp:237]     Train net output #1: loss = 0.0120814 (* 1 = 0.0120814 loss)
I1212 00:34:59.352526 17660 sgd_solver.cpp:105] Iteration 169600, lr = 0.0001
I1212 00:35:07.581962 17660 solver.cpp:218] Iteration 169700 (12.1533 iter/s, 8.22823s/100 iters), loss = 0.0130378
I1212 00:35:07.581962 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:07.581962 17660 solver.cpp:237]     Train net output #1: loss = 0.0130377 (* 1 = 0.0130377 loss)
I1212 00:35:07.581962 17660 sgd_solver.cpp:105] Iteration 169700, lr = 0.0001
I1212 00:35:15.821099 17660 solver.cpp:218] Iteration 169800 (12.1379 iter/s, 8.23867s/100 iters), loss = 0.0100034
I1212 00:35:15.821099 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:15.821099 17660 solver.cpp:237]     Train net output #1: loss = 0.0100034 (* 1 = 0.0100034 loss)
I1212 00:35:15.821099 17660 sgd_solver.cpp:105] Iteration 169800, lr = 0.0001
I1212 00:35:23.948658 17660 solver.cpp:218] Iteration 169900 (12.3041 iter/s, 8.12736s/100 iters), loss = 0.0104324
I1212 00:35:23.948658 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:23.948658 17660 solver.cpp:237]     Train net output #1: loss = 0.0104323 (* 1 = 0.0104323 loss)
I1212 00:35:23.948658 17660 sgd_solver.cpp:105] Iteration 169900, lr = 0.0001
I1212 00:35:31.630486 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:35:31.946542 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170000.caffemodel
I1212 00:35:32.003545 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170000.solverstate
I1212 00:35:32.011545 17660 solver.cpp:330] Iteration 170000, Testing net (#0)
I1212 00:35:32.011545 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:35:33.697712 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:35:33.764518 17660 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1212 00:35:33.764518 17660 solver.cpp:397]     Test net output #1: loss = 0.253224 (* 1 = 0.253224 loss)
I1212 00:35:33.840030 17660 solver.cpp:218] Iteration 170000 (10.1101 iter/s, 9.89113s/100 iters), loss = 0.0116699
I1212 00:35:33.841034 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:33.841034 17660 solver.cpp:237]     Train net output #1: loss = 0.0116699 (* 1 = 0.0116699 loss)
I1212 00:35:33.841034 17660 sgd_solver.cpp:105] Iteration 170000, lr = 0.0001
I1212 00:35:41.919492 17660 solver.cpp:218] Iteration 170100 (12.3797 iter/s, 8.07772s/100 iters), loss = 0.0122071
I1212 00:35:41.919492 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:41.919492 17660 solver.cpp:237]     Train net output #1: loss = 0.012207 (* 1 = 0.012207 loss)
I1212 00:35:41.919492 17660 sgd_solver.cpp:105] Iteration 170100, lr = 0.0001
I1212 00:35:49.985435 17660 solver.cpp:218] Iteration 170200 (12.3985 iter/s, 8.0655s/100 iters), loss = 0.0111506
I1212 00:35:49.985435 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:49.985435 17660 solver.cpp:237]     Train net output #1: loss = 0.0111506 (* 1 = 0.0111506 loss)
I1212 00:35:49.985435 17660 sgd_solver.cpp:105] Iteration 170200, lr = 0.0001
I1212 00:35:58.044968 17660 solver.cpp:218] Iteration 170300 (12.4074 iter/s, 8.05971s/100 iters), loss = 0.00958432
I1212 00:35:58.045969 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:35:58.045969 17660 solver.cpp:237]     Train net output #1: loss = 0.00958426 (* 1 = 0.00958426 loss)
I1212 00:35:58.045969 17660 sgd_solver.cpp:105] Iteration 170300, lr = 0.0001
I1212 00:36:06.108928 17660 solver.cpp:218] Iteration 170400 (12.4016 iter/s, 8.06346s/100 iters), loss = 0.00907338
I1212 00:36:06.109930 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:06.109930 17660 solver.cpp:237]     Train net output #1: loss = 0.00907333 (* 1 = 0.00907333 loss)
I1212 00:36:06.109930 17660 sgd_solver.cpp:105] Iteration 170400, lr = 0.0001
I1212 00:36:13.774163 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:36:14.094902 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170500.caffemodel
I1212 00:36:14.124902 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_170500.solverstate
I1212 00:36:14.131911 17660 solver.cpp:330] Iteration 170500, Testing net (#0)
I1212 00:36:14.131911 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:36:15.823462 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:36:15.890511 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:36:15.890511 17660 solver.cpp:397]     Test net output #1: loss = 0.252802 (* 1 = 0.252802 loss)
I1212 00:36:15.965317 17660 solver.cpp:218] Iteration 170500 (10.1471 iter/s, 9.85507s/100 iters), loss = 0.0158992
I1212 00:36:15.965317 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:15.965317 17660 solver.cpp:237]     Train net output #1: loss = 0.0158991 (* 1 = 0.0158991 loss)
I1212 00:36:15.965317 17660 sgd_solver.cpp:105] Iteration 170500, lr = 0.0001
I1212 00:36:24.044286 17660 solver.cpp:218] Iteration 170600 (12.3785 iter/s, 8.0785s/100 iters), loss = 0.0176265
I1212 00:36:24.044286 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:24.044286 17660 solver.cpp:237]     Train net output #1: loss = 0.0176264 (* 1 = 0.0176264 loss)
I1212 00:36:24.044286 17660 sgd_solver.cpp:105] Iteration 170600, lr = 0.0001
I1212 00:36:32.103371 17660 solver.cpp:218] Iteration 170700 (12.4091 iter/s, 8.05861s/100 iters), loss = 0.0116205
I1212 00:36:32.103371 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:32.103371 17660 solver.cpp:237]     Train net output #1: loss = 0.0116204 (* 1 = 0.0116204 loss)
I1212 00:36:32.103371 17660 sgd_solver.cpp:105] Iteration 170700, lr = 0.0001
I1212 00:36:40.162791 17660 solver.cpp:218] Iteration 170800 (12.4082 iter/s, 8.05917s/100 iters), loss = 0.00977267
I1212 00:36:40.162791 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:40.162791 17660 solver.cpp:237]     Train net output #1: loss = 0.00977262 (* 1 = 0.00977262 loss)
I1212 00:36:40.162791 17660 sgd_solver.cpp:105] Iteration 170800, lr = 0.0001
I1212 00:36:48.208585 17660 solver.cpp:218] Iteration 170900 (12.4295 iter/s, 8.04537s/100 iters), loss = 0.00988899
I1212 00:36:48.208585 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:48.208585 17660 solver.cpp:237]     Train net output #1: loss = 0.00988893 (* 1 = 0.00988893 loss)
I1212 00:36:48.208585 17660 sgd_solver.cpp:105] Iteration 170900, lr = 0.0001
I1212 00:36:55.871824 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:36:56.190987 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171000.caffemodel
I1212 00:36:56.265498 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171000.solverstate
I1212 00:36:56.272500 17660 solver.cpp:330] Iteration 171000, Testing net (#0)
I1212 00:36:56.272500 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:36:57.958133 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:36:58.023646 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1212 00:36:58.023646 17660 solver.cpp:397]     Test net output #1: loss = 0.253019 (* 1 = 0.253019 loss)
I1212 00:36:58.099669 17660 solver.cpp:218] Iteration 171000 (10.1107 iter/s, 9.89052s/100 iters), loss = 0.0122038
I1212 00:36:58.099669 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:36:58.099669 17660 solver.cpp:237]     Train net output #1: loss = 0.0122037 (* 1 = 0.0122037 loss)
I1212 00:36:58.099669 17660 sgd_solver.cpp:105] Iteration 171000, lr = 0.0001
I1212 00:37:06.172955 17660 solver.cpp:218] Iteration 171100 (12.3873 iter/s, 8.0728s/100 iters), loss = 0.0120477
I1212 00:37:06.172955 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:06.172955 17660 solver.cpp:237]     Train net output #1: loss = 0.0120476 (* 1 = 0.0120476 loss)
I1212 00:37:06.172955 17660 sgd_solver.cpp:105] Iteration 171100, lr = 0.0001
I1212 00:37:14.248314 17660 solver.cpp:218] Iteration 171200 (12.3844 iter/s, 8.07469s/100 iters), loss = 0.0128581
I1212 00:37:14.248314 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:14.248314 17660 solver.cpp:237]     Train net output #1: loss = 0.012858 (* 1 = 0.012858 loss)
I1212 00:37:14.248314 17660 sgd_solver.cpp:105] Iteration 171200, lr = 0.0001
I1212 00:37:22.319386 17660 solver.cpp:218] Iteration 171300 (12.3914 iter/s, 8.07009s/100 iters), loss = 0.0120162
I1212 00:37:22.319386 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:22.319386 17660 solver.cpp:237]     Train net output #1: loss = 0.0120162 (* 1 = 0.0120162 loss)
I1212 00:37:22.319386 17660 sgd_solver.cpp:105] Iteration 171300, lr = 0.0001
I1212 00:37:30.394242 17660 solver.cpp:218] Iteration 171400 (12.384 iter/s, 8.07496s/100 iters), loss = 0.0099717
I1212 00:37:30.394242 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:30.394242 17660 solver.cpp:237]     Train net output #1: loss = 0.00997165 (* 1 = 0.00997165 loss)
I1212 00:37:30.394242 17660 sgd_solver.cpp:105] Iteration 171400, lr = 0.0001
I1212 00:37:38.186096 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:37:38.513917 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171500.caffemodel
I1212 00:37:38.550899 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_171500.solverstate
I1212 00:37:38.556901 17660 solver.cpp:330] Iteration 171500, Testing net (#0)
I1212 00:37:38.557902 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:37:40.251998 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:37:40.319948 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:37:40.319948 17660 solver.cpp:397]     Test net output #1: loss = 0.253279 (* 1 = 0.253279 loss)
I1212 00:37:40.394726 17660 solver.cpp:218] Iteration 171500 (10.0003 iter/s, 9.99974s/100 iters), loss = 0.0126371
I1212 00:37:40.394726 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:40.394726 17660 solver.cpp:237]     Train net output #1: loss = 0.012637 (* 1 = 0.012637 loss)
I1212 00:37:40.394726 17660 sgd_solver.cpp:105] Iteration 171500, lr = 0.0001
I1212 00:37:48.500052 17660 solver.cpp:218] Iteration 171600 (12.3386 iter/s, 8.10467s/100 iters), loss = 0.0156835
I1212 00:37:48.500052 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:48.500052 17660 solver.cpp:237]     Train net output #1: loss = 0.0156835 (* 1 = 0.0156835 loss)
I1212 00:37:48.500052 17660 sgd_solver.cpp:105] Iteration 171600, lr = 0.0001
I1212 00:37:56.573401 17660 solver.cpp:218] Iteration 171700 (12.3879 iter/s, 8.07242s/100 iters), loss = 0.0120284
I1212 00:37:56.573401 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:37:56.573401 17660 solver.cpp:237]     Train net output #1: loss = 0.0120284 (* 1 = 0.0120284 loss)
I1212 00:37:56.573401 17660 sgd_solver.cpp:105] Iteration 171700, lr = 0.0001
I1212 00:38:04.633373 17660 solver.cpp:218] Iteration 171800 (12.4076 iter/s, 8.05956s/100 iters), loss = 0.00926136
I1212 00:38:04.633373 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:04.633373 17660 solver.cpp:237]     Train net output #1: loss = 0.00926131 (* 1 = 0.00926131 loss)
I1212 00:38:04.633373 17660 sgd_solver.cpp:105] Iteration 171800, lr = 0.0001
I1212 00:38:12.705936 17660 solver.cpp:218] Iteration 171900 (12.3874 iter/s, 8.07271s/100 iters), loss = 0.0129782
I1212 00:38:12.705936 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:12.705936 17660 solver.cpp:237]     Train net output #1: loss = 0.0129781 (* 1 = 0.0129781 loss)
I1212 00:38:12.705936 17660 sgd_solver.cpp:105] Iteration 171900, lr = 0.0001
I1212 00:38:20.375807 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:38:20.692831 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_172000.caffemodel
I1212 00:38:20.754837 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_172000.solverstate
I1212 00:38:20.760836 17660 solver.cpp:330] Iteration 172000, Testing net (#0)
I1212 00:38:20.760836 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:38:22.445003 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:38:22.512012 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:38:22.512012 17660 solver.cpp:397]     Test net output #1: loss = 0.252852 (* 1 = 0.252852 loss)
I1212 00:38:22.587512 17660 solver.cpp:218] Iteration 172000 (10.121 iter/s, 9.88041s/100 iters), loss = 0.0117316
I1212 00:38:22.587512 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:22.587512 17660 solver.cpp:237]     Train net output #1: loss = 0.0117315 (* 1 = 0.0117315 loss)
I1212 00:38:22.587512 17660 sgd_solver.cpp:105] Iteration 172000, lr = 0.0001
I1212 00:38:30.646611 17660 solver.cpp:218] Iteration 172100 (12.4088 iter/s, 8.05879s/100 iters), loss = 0.0113343
I1212 00:38:30.646611 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:30.646611 17660 solver.cpp:237]     Train net output #1: loss = 0.0113343 (* 1 = 0.0113343 loss)
I1212 00:38:30.646611 17660 sgd_solver.cpp:105] Iteration 172100, lr = 0.0001
I1212 00:38:38.692711 17660 solver.cpp:218] Iteration 172200 (12.4291 iter/s, 8.0456s/100 iters), loss = 0.0223989
I1212 00:38:38.693210 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:38.693210 17660 solver.cpp:237]     Train net output #1: loss = 0.0223989 (* 1 = 0.0223989 loss)
I1212 00:38:38.693210 17660 sgd_solver.cpp:105] Iteration 172200, lr = 0.0001
I1212 00:38:46.748564 17660 solver.cpp:218] Iteration 172300 (12.4147 iter/s, 8.055s/100 iters), loss = 0.0122246
I1212 00:38:46.748564 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:46.748564 17660 solver.cpp:237]     Train net output #1: loss = 0.0122246 (* 1 = 0.0122246 loss)
I1212 00:38:46.748564 17660 sgd_solver.cpp:105] Iteration 172300, lr = 0.0001
I1212 00:38:54.810493 17660 solver.cpp:218] Iteration 172400 (12.4041 iter/s, 8.06186s/100 iters), loss = 0.00996152
I1212 00:38:54.810493 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:38:54.810493 17660 solver.cpp:237]     Train net output #1: loss = 0.00996147 (* 1 = 0.00996147 loss)
I1212 00:38:54.810493 17660 sgd_solver.cpp:105] Iteration 172400, lr = 0.0001
I1212 00:39:02.474613 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:39:02.795872 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_172500.caffemodel
I1212 00:39:02.825883 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_172500.solverstate
I1212 00:39:02.831871 17660 solver.cpp:330] Iteration 172500, Testing net (#0)
I1212 00:39:02.831871 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:39:04.514480 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:39:04.581480 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1212 00:39:04.581480 17660 solver.cpp:397]     Test net output #1: loss = 0.25266 (* 1 = 0.25266 loss)
I1212 00:39:04.655019 17660 solver.cpp:218] Iteration 172500 (10.1581 iter/s, 9.84437s/100 iters), loss = 0.0131381
I1212 00:39:04.656018 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:39:04.656018 17660 solver.cpp:237]     Train net output #1: loss = 0.013138 (* 1 = 0.013138 loss)
I1212 00:39:04.656018 17660 sgd_solver.cpp:105] Iteration 172500, lr = 0.0001
I1212 00:39:12.708648 17660 solver.cpp:218] Iteration 172600 (12.4185 iter/s, 8.05249s/100 iters), loss = 0.0115669
I1212 00:39:12.708648 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:39:12.708648 17660 solver.cpp:237]     Train net output #1: loss = 0.0115669 (* 1 = 0.0115669 loss)
I1212 00:39:12.708648 17660 sgd_solver.cpp:105] Iteration 172600, lr = 0.0001
I1212 00:39:20.762019 17660 solver.cpp:218] Iteration 172700 (12.4181 iter/s, 8.05273s/100 iters), loss = 0.0099222
I1212 00:39:20.762019 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:39:20.762019 17660 solver.cpp:237]     Train net output #1: loss = 0.00992216 (* 1 = 0.00992216 loss)
I1212 00:39:20.762019 17660 sgd_solver.cpp:105] Iteration 172700, lr = 0.0001
I1212 00:39:28.823801 17660 solver.cpp:218] Iteration 172800 (12.4048 iter/s, 8.06141s/100 iters), loss = 0.0102396
I1212 00:39:28.823801 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:39:28.823801 17660 solver.cpp:237]     Train net output #1: loss = 0.0102395 (* 1 = 0.0102395 loss)
I1212 00:39:28.823801 17660 sgd_solver.cpp:105] Iteration 172800, lr = 0.0001
I1212 00:39:36.897071 17660 solver.cpp:218] Iteration 172900 (12.3871 iter/s, 8.07294s/100 iters), loss = 0.0246578
I1212 00:39:36.897071 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:39:36.897071 17660 solver.cpp:237]     Train net output #1: loss = 0.0246577 (* 1 = 0.0246577 loss)
I1212 00:39:36.897071 17660 sgd_solver.cpp:105] Iteration 172900, lr = 0.0001
I1212 00:39:44.637917 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:39:44.959940 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_173000.caffemodel
I1212 00:39:45.020951 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_173000.solverstate
I1212 00:39:45.026955 17660 solver.cpp:330] Iteration 173000, Testing net (#0)
I1212 00:39:45.026955 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:39:46.734350 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:39:46.802350 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1212 00:39:46.802350 17660 solver.cpp:397]     Test net output #1: loss = 0.252786 (* 1 = 0.252786 loss)
I1212 00:39:46.876358 17660 solver.cpp:218] Iteration 173000 (10.0208 iter/s, 9.97928s/100 iters), loss = 0.0125913
I1212 00:39:46.877357 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:39:46.877357 17660 solver.cpp:237]     Train net output #1: loss = 0.0125912 (* 1 = 0.0125912 loss)
I1212 00:39:46.877357 17660 sgd_solver.cpp:105] Iteration 173000, lr = 0.0001
I1212 00:39:55.018563 17660 solver.cpp:218] Iteration 173100 (12.2836 iter/s, 8.14094s/100 iters), loss = 0.0110478
I1212 00:39:55.018563 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:39:55.019062 17660 solver.cpp:237]     Train net output #1: loss = 0.0110478 (* 1 = 0.0110478 loss)
I1212 00:39:55.019062 17660 sgd_solver.cpp:105] Iteration 173100, lr = 0.0001
I1212 00:40:03.182113 17660 solver.cpp:218] Iteration 173200 (12.2503 iter/s, 8.16309s/100 iters), loss = 0.0109457
I1212 00:40:03.182113 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:03.182113 17660 solver.cpp:237]     Train net output #1: loss = 0.0109456 (* 1 = 0.0109456 loss)
I1212 00:40:03.182113 17660 sgd_solver.cpp:105] Iteration 173200, lr = 0.0001
I1212 00:40:11.265990 17660 solver.cpp:218] Iteration 173300 (12.3716 iter/s, 8.08304s/100 iters), loss = 0.0118204
I1212 00:40:11.265990 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:11.265990 17660 solver.cpp:237]     Train net output #1: loss = 0.0118203 (* 1 = 0.0118203 loss)
I1212 00:40:11.265990 17660 sgd_solver.cpp:105] Iteration 173300, lr = 0.0001
I1212 00:40:19.355607 17660 solver.cpp:218] Iteration 173400 (12.3611 iter/s, 8.08987s/100 iters), loss = 0.0113438
I1212 00:40:19.356608 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:19.356608 17660 solver.cpp:237]     Train net output #1: loss = 0.0113437 (* 1 = 0.0113437 loss)
I1212 00:40:19.356608 17660 sgd_solver.cpp:105] Iteration 173400, lr = 0.0001
I1212 00:40:27.099056 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:40:27.417611 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_173500.caffemodel
I1212 00:40:27.448622 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_173500.solverstate
I1212 00:40:27.454623 17660 solver.cpp:330] Iteration 173500, Testing net (#0)
I1212 00:40:27.454623 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:40:29.158179 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:40:29.225178 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:40:29.225178 17660 solver.cpp:397]     Test net output #1: loss = 0.252517 (* 1 = 0.252517 loss)
I1212 00:40:29.301187 17660 solver.cpp:218] Iteration 173500 (10.0555 iter/s, 9.94482s/100 iters), loss = 0.0116556
I1212 00:40:29.301187 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:29.301187 17660 solver.cpp:237]     Train net output #1: loss = 0.0116556 (* 1 = 0.0116556 loss)
I1212 00:40:29.301187 17660 sgd_solver.cpp:105] Iteration 173500, lr = 0.0001
I1212 00:40:37.541326 17660 solver.cpp:218] Iteration 173600 (12.137 iter/s, 8.23926s/100 iters), loss = 0.011737
I1212 00:40:37.541826 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:37.541826 17660 solver.cpp:237]     Train net output #1: loss = 0.011737 (* 1 = 0.011737 loss)
I1212 00:40:37.541826 17660 sgd_solver.cpp:105] Iteration 173600, lr = 0.0001
I1212 00:40:45.869566 17660 solver.cpp:218] Iteration 173700 (12.0087 iter/s, 8.32728s/100 iters), loss = 0.0189784
I1212 00:40:45.869566 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:45.869566 17660 solver.cpp:237]     Train net output #1: loss = 0.0189783 (* 1 = 0.0189783 loss)
I1212 00:40:45.869566 17660 sgd_solver.cpp:105] Iteration 173700, lr = 0.0001
I1212 00:40:54.128090 17660 solver.cpp:218] Iteration 173800 (12.1093 iter/s, 8.25812s/100 iters), loss = 0.0126434
I1212 00:40:54.128090 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:40:54.128090 17660 solver.cpp:237]     Train net output #1: loss = 0.0126433 (* 1 = 0.0126433 loss)
I1212 00:40:54.128090 17660 sgd_solver.cpp:105] Iteration 173800, lr = 0.0001
I1212 00:41:02.429503 17660 solver.cpp:218] Iteration 173900 (12.0463 iter/s, 8.30133s/100 iters), loss = 0.00949235
I1212 00:41:02.429503 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:02.429503 17660 solver.cpp:237]     Train net output #1: loss = 0.0094923 (* 1 = 0.0094923 loss)
I1212 00:41:02.429503 17660 sgd_solver.cpp:105] Iteration 173900, lr = 0.0001
I1212 00:41:10.224779 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:41:10.551616 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_174000.caffemodel
I1212 00:41:10.593849 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_174000.solverstate
I1212 00:41:10.600859 17660 solver.cpp:330] Iteration 174000, Testing net (#0)
I1212 00:41:10.600859 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:41:12.316129 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:41:12.383438 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1212 00:41:12.383438 17660 solver.cpp:397]     Test net output #1: loss = 0.251911 (* 1 = 0.251911 loss)
I1212 00:41:12.461443 17660 solver.cpp:218] Iteration 174000 (9.96845 iter/s, 10.0316s/100 iters), loss = 0.0104817
I1212 00:41:12.462572 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:12.462572 17660 solver.cpp:237]     Train net output #1: loss = 0.0104816 (* 1 = 0.0104816 loss)
I1212 00:41:12.462572 17660 sgd_solver.cpp:105] Iteration 174000, lr = 0.0001
I1212 00:41:20.703239 17660 solver.cpp:218] Iteration 174100 (12.1352 iter/s, 8.24049s/100 iters), loss = 0.0157764
I1212 00:41:20.703239 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:20.703239 17660 solver.cpp:237]     Train net output #1: loss = 0.0157763 (* 1 = 0.0157763 loss)
I1212 00:41:20.703239 17660 sgd_solver.cpp:105] Iteration 174100, lr = 0.0001
I1212 00:41:28.848738 17660 solver.cpp:218] Iteration 174200 (12.2778 iter/s, 8.1448s/100 iters), loss = 0.011933
I1212 00:41:28.848738 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:28.848738 17660 solver.cpp:237]     Train net output #1: loss = 0.011933 (* 1 = 0.011933 loss)
I1212 00:41:28.848738 17660 sgd_solver.cpp:105] Iteration 174200, lr = 0.0001
I1212 00:41:37.002616 17660 solver.cpp:218] Iteration 174300 (12.265 iter/s, 8.15329s/100 iters), loss = 0.0110317
I1212 00:41:37.002616 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:37.002616 17660 solver.cpp:237]     Train net output #1: loss = 0.0110317 (* 1 = 0.0110317 loss)
I1212 00:41:37.002616 17660 sgd_solver.cpp:105] Iteration 174300, lr = 0.0001
I1212 00:41:45.107630 17660 solver.cpp:218] Iteration 174400 (12.3388 iter/s, 8.10452s/100 iters), loss = 0.0145483
I1212 00:41:45.107630 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:45.107630 17660 solver.cpp:237]     Train net output #1: loss = 0.0145483 (* 1 = 0.0145483 loss)
I1212 00:41:45.107630 17660 sgd_solver.cpp:105] Iteration 174400, lr = 0.0001
I1212 00:41:52.819880 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:41:53.138901 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_174500.caffemodel
I1212 00:41:53.170408 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_174500.solverstate
I1212 00:41:53.176911 17660 solver.cpp:330] Iteration 174500, Testing net (#0)
I1212 00:41:53.176911 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:41:54.870544 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:41:54.936046 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9352
I1212 00:41:54.936046 17660 solver.cpp:397]     Test net output #1: loss = 0.252646 (* 1 = 0.252646 loss)
I1212 00:41:55.013056 17660 solver.cpp:218] Iteration 174500 (10.096 iter/s, 9.90491s/100 iters), loss = 0.0138272
I1212 00:41:55.013056 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:41:55.013056 17660 solver.cpp:237]     Train net output #1: loss = 0.0138271 (* 1 = 0.0138271 loss)
I1212 00:41:55.013056 17660 sgd_solver.cpp:105] Iteration 174500, lr = 0.0001
I1212 00:42:03.097465 17660 solver.cpp:218] Iteration 174600 (12.3704 iter/s, 8.08383s/100 iters), loss = 0.0223134
I1212 00:42:03.097465 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:42:03.097465 17660 solver.cpp:237]     Train net output #1: loss = 0.0223134 (* 1 = 0.0223134 loss)
I1212 00:42:03.097465 17660 sgd_solver.cpp:105] Iteration 174600, lr = 0.0001
I1212 00:42:11.162389 17660 solver.cpp:218] Iteration 174700 (12.4002 iter/s, 8.06439s/100 iters), loss = 0.014604
I1212 00:42:11.162389 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:42:11.162389 17660 solver.cpp:237]     Train net output #1: loss = 0.0146039 (* 1 = 0.0146039 loss)
I1212 00:42:11.162389 17660 sgd_solver.cpp:105] Iteration 174700, lr = 0.0001
I1212 00:42:19.247210 17660 solver.cpp:218] Iteration 174800 (12.3694 iter/s, 8.08447s/100 iters), loss = 0.00987182
I1212 00:42:19.247210 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:42:19.247210 17660 solver.cpp:237]     Train net output #1: loss = 0.00987178 (* 1 = 0.00987178 loss)
I1212 00:42:19.247210 17660 sgd_solver.cpp:105] Iteration 174800, lr = 0.0001
I1212 00:42:27.339514 17660 solver.cpp:218] Iteration 174900 (12.3574 iter/s, 8.09229s/100 iters), loss = 0.0138291
I1212 00:42:27.339514 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:42:27.340514 17660 solver.cpp:237]     Train net output #1: loss = 0.0138291 (* 1 = 0.0138291 loss)
I1212 00:42:27.340514 17660 sgd_solver.cpp:105] Iteration 174900, lr = 0.0001
I1212 00:42:35.038540 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:42:35.357592 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_175000.caffemodel
I1212 00:42:35.443749 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_175000.solverstate
I1212 00:42:35.450743 17660 solver.cpp:330] Iteration 175000, Testing net (#0)
I1212 00:42:35.450743 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:42:37.137754 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:42:37.204768 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:42:37.204768 17660 solver.cpp:397]     Test net output #1: loss = 0.252879 (* 1 = 0.252879 loss)
I1212 00:42:37.280771 17660 solver.cpp:218] Iteration 175000 (10.0604 iter/s, 9.93993s/100 iters), loss = 0.0171416
I1212 00:42:37.280771 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:42:37.280771 17660 solver.cpp:237]     Train net output #1: loss = 0.0171415 (* 1 = 0.0171415 loss)
I1212 00:42:37.280771 17660 sgd_solver.cpp:105] Iteration 175000, lr = 0.0001
I1212 00:42:45.359203 17660 solver.cpp:218] Iteration 175100 (12.3787 iter/s, 8.07839s/100 iters), loss = 0.0216362
I1212 00:42:45.359203 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:42:45.359203 17660 solver.cpp:237]     Train net output #1: loss = 0.0216362 (* 1 = 0.0216362 loss)
I1212 00:42:45.359203 17660 sgd_solver.cpp:105] Iteration 175100, lr = 0.0001
I1212 00:42:53.458686 17660 solver.cpp:218] Iteration 175200 (12.347 iter/s, 8.09916s/100 iters), loss = 0.010835
I1212 00:42:53.458686 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:42:53.458686 17660 solver.cpp:237]     Train net output #1: loss = 0.0108349 (* 1 = 0.0108349 loss)
I1212 00:42:53.458686 17660 sgd_solver.cpp:105] Iteration 175200, lr = 0.0001
I1212 00:43:01.583570 17660 solver.cpp:218] Iteration 175300 (12.3095 iter/s, 8.12381s/100 iters), loss = 0.00935484
I1212 00:43:01.583570 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:01.583570 17660 solver.cpp:237]     Train net output #1: loss = 0.0093548 (* 1 = 0.0093548 loss)
I1212 00:43:01.583570 17660 sgd_solver.cpp:105] Iteration 175300, lr = 0.0001
I1212 00:43:09.732206 17660 solver.cpp:218] Iteration 175400 (12.272 iter/s, 8.14862s/100 iters), loss = 0.0120301
I1212 00:43:09.732206 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:09.732206 17660 solver.cpp:237]     Train net output #1: loss = 0.0120301 (* 1 = 0.0120301 loss)
I1212 00:43:09.732206 17660 sgd_solver.cpp:105] Iteration 175400, lr = 0.0001
I1212 00:43:17.508411 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:43:17.843020 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_175500.caffemodel
I1212 00:43:17.877022 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_175500.solverstate
I1212 00:43:17.883020 17660 solver.cpp:330] Iteration 175500, Testing net (#0)
I1212 00:43:17.884032 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:43:19.614204 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:43:19.685196 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:43:19.685196 17660 solver.cpp:397]     Test net output #1: loss = 0.252574 (* 1 = 0.252574 loss)
I1212 00:43:19.763216 17660 solver.cpp:218] Iteration 175500 (9.96994 iter/s, 10.0302s/100 iters), loss = 0.0118713
I1212 00:43:19.763216 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:19.763216 17660 solver.cpp:237]     Train net output #1: loss = 0.0118712 (* 1 = 0.0118712 loss)
I1212 00:43:19.763216 17660 sgd_solver.cpp:105] Iteration 175500, lr = 0.0001
I1212 00:43:28.114464 17660 solver.cpp:218] Iteration 175600 (11.9744 iter/s, 8.35115s/100 iters), loss = 0.0112318
I1212 00:43:28.115463 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:28.115463 17660 solver.cpp:237]     Train net output #1: loss = 0.0112318 (* 1 = 0.0112318 loss)
I1212 00:43:28.115463 17660 sgd_solver.cpp:105] Iteration 175600, lr = 0.0001
I1212 00:43:36.211364 17660 solver.cpp:218] Iteration 175700 (12.3524 iter/s, 8.09558s/100 iters), loss = 0.0111053
I1212 00:43:36.211364 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:36.211364 17660 solver.cpp:237]     Train net output #1: loss = 0.0111053 (* 1 = 0.0111053 loss)
I1212 00:43:36.211364 17660 sgd_solver.cpp:105] Iteration 175700, lr = 0.0001
I1212 00:43:44.363484 17660 solver.cpp:218] Iteration 175800 (12.2671 iter/s, 8.15186s/100 iters), loss = 0.00977808
I1212 00:43:44.363484 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:44.363484 17660 solver.cpp:237]     Train net output #1: loss = 0.00977804 (* 1 = 0.00977804 loss)
I1212 00:43:44.363484 17660 sgd_solver.cpp:105] Iteration 175800, lr = 0.0001
I1212 00:43:52.756832 17660 solver.cpp:218] Iteration 175900 (11.9156 iter/s, 8.39234s/100 iters), loss = 0.0142106
I1212 00:43:52.756832 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:43:52.756832 17660 solver.cpp:237]     Train net output #1: loss = 0.0142106 (* 1 = 0.0142106 loss)
I1212 00:43:52.756832 17660 sgd_solver.cpp:105] Iteration 175900, lr = 0.0001
I1212 00:44:00.417927 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:44:00.737135 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_176000.caffemodel
I1212 00:44:00.790149 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_176000.solverstate
I1212 00:44:00.797147 17660 solver.cpp:330] Iteration 176000, Testing net (#0)
I1212 00:44:00.797650 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:44:02.478071 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:44:02.545099 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1212 00:44:02.545099 17660 solver.cpp:397]     Test net output #1: loss = 0.253021 (* 1 = 0.253021 loss)
I1212 00:44:02.620036 17660 solver.cpp:218] Iteration 176000 (10.1391 iter/s, 9.86276s/100 iters), loss = 0.0137284
I1212 00:44:02.620036 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:02.620036 17660 solver.cpp:237]     Train net output #1: loss = 0.0137283 (* 1 = 0.0137283 loss)
I1212 00:44:02.620036 17660 sgd_solver.cpp:105] Iteration 176000, lr = 0.0001
I1212 00:44:10.921710 17660 solver.cpp:218] Iteration 176100 (12.0461 iter/s, 8.30141s/100 iters), loss = 0.0143588
I1212 00:44:10.921710 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:10.921710 17660 solver.cpp:237]     Train net output #1: loss = 0.0143588 (* 1 = 0.0143588 loss)
I1212 00:44:10.921710 17660 sgd_solver.cpp:105] Iteration 176100, lr = 0.0001
I1212 00:44:19.050657 17660 solver.cpp:218] Iteration 176200 (12.3029 iter/s, 8.12815s/100 iters), loss = 0.0106408
I1212 00:44:19.050657 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:19.050657 17660 solver.cpp:237]     Train net output #1: loss = 0.0106408 (* 1 = 0.0106408 loss)
I1212 00:44:19.050657 17660 sgd_solver.cpp:105] Iteration 176200, lr = 0.0001
I1212 00:44:27.190358 17660 solver.cpp:218] Iteration 176300 (12.2859 iter/s, 8.13944s/100 iters), loss = 0.0101547
I1212 00:44:27.190358 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:27.190358 17660 solver.cpp:237]     Train net output #1: loss = 0.0101547 (* 1 = 0.0101547 loss)
I1212 00:44:27.190358 17660 sgd_solver.cpp:105] Iteration 176300, lr = 0.0001
I1212 00:44:35.475028 17660 solver.cpp:218] Iteration 176400 (12.0708 iter/s, 8.28445s/100 iters), loss = 0.011703
I1212 00:44:35.475028 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:35.475028 17660 solver.cpp:237]     Train net output #1: loss = 0.0117029 (* 1 = 0.0117029 loss)
I1212 00:44:35.475028 17660 sgd_solver.cpp:105] Iteration 176400, lr = 0.0001
I1212 00:44:43.171900 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:44:43.494210 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_176500.caffemodel
I1212 00:44:43.524211 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_176500.solverstate
I1212 00:44:43.529712 17660 solver.cpp:330] Iteration 176500, Testing net (#0)
I1212 00:44:43.529712 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:44:45.243664 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:44:45.314167 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1212 00:44:45.314167 17660 solver.cpp:397]     Test net output #1: loss = 0.253346 (* 1 = 0.253346 loss)
I1212 00:44:45.394675 17660 solver.cpp:218] Iteration 176500 (10.0823 iter/s, 9.91833s/100 iters), loss = 0.0144348
I1212 00:44:45.394675 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:45.394675 17660 solver.cpp:237]     Train net output #1: loss = 0.0144348 (* 1 = 0.0144348 loss)
I1212 00:44:45.394675 17660 sgd_solver.cpp:105] Iteration 176500, lr = 0.0001
I1212 00:44:53.680392 17660 solver.cpp:218] Iteration 176600 (12.0695 iter/s, 8.28535s/100 iters), loss = 0.0110315
I1212 00:44:53.680392 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:44:53.680392 17660 solver.cpp:237]     Train net output #1: loss = 0.0110315 (* 1 = 0.0110315 loss)
I1212 00:44:53.680392 17660 sgd_solver.cpp:105] Iteration 176600, lr = 0.0001
I1212 00:45:02.056912 17660 solver.cpp:218] Iteration 176700 (11.9391 iter/s, 8.37586s/100 iters), loss = 0.0137142
I1212 00:45:02.056912 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:02.056912 17660 solver.cpp:237]     Train net output #1: loss = 0.0137142 (* 1 = 0.0137142 loss)
I1212 00:45:02.056912 17660 sgd_solver.cpp:105] Iteration 176700, lr = 0.0001
I1212 00:45:10.344844 17660 solver.cpp:218] Iteration 176800 (12.0662 iter/s, 8.2876s/100 iters), loss = 0.00969985
I1212 00:45:10.344844 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:10.344844 17660 solver.cpp:237]     Train net output #1: loss = 0.00969983 (* 1 = 0.00969983 loss)
I1212 00:45:10.344844 17660 sgd_solver.cpp:105] Iteration 176800, lr = 0.0001
I1212 00:45:18.507735 17660 solver.cpp:218] Iteration 176900 (12.2511 iter/s, 8.16253s/100 iters), loss = 0.0118061
I1212 00:45:18.507735 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:18.507735 17660 solver.cpp:237]     Train net output #1: loss = 0.011806 (* 1 = 0.011806 loss)
I1212 00:45:18.507735 17660 sgd_solver.cpp:105] Iteration 176900, lr = 0.0001
I1212 00:45:26.240484 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:45:26.560048 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_177000.caffemodel
I1212 00:45:26.619048 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_177000.solverstate
I1212 00:45:26.625048 17660 solver.cpp:330] Iteration 177000, Testing net (#0)
I1212 00:45:26.626049 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:45:28.328255 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:45:28.394274 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9349
I1212 00:45:28.394274 17660 solver.cpp:397]     Test net output #1: loss = 0.253062 (* 1 = 0.253062 loss)
I1212 00:45:28.470306 17660 solver.cpp:218] Iteration 177000 (10.0378 iter/s, 9.9623s/100 iters), loss = 0.0103738
I1212 00:45:28.470306 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:28.470306 17660 solver.cpp:237]     Train net output #1: loss = 0.0103737 (* 1 = 0.0103737 loss)
I1212 00:45:28.470306 17660 sgd_solver.cpp:105] Iteration 177000, lr = 0.0001
I1212 00:45:36.645251 17660 solver.cpp:218] Iteration 177100 (12.2342 iter/s, 8.17382s/100 iters), loss = 0.0106824
I1212 00:45:36.645752 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:36.645752 17660 solver.cpp:237]     Train net output #1: loss = 0.0106824 (* 1 = 0.0106824 loss)
I1212 00:45:36.645752 17660 sgd_solver.cpp:105] Iteration 177100, lr = 0.0001
I1212 00:45:44.974865 17660 solver.cpp:218] Iteration 177200 (12.0061 iter/s, 8.32912s/100 iters), loss = 0.0168188
I1212 00:45:44.974865 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:44.974865 17660 solver.cpp:237]     Train net output #1: loss = 0.0168188 (* 1 = 0.0168188 loss)
I1212 00:45:44.974865 17660 sgd_solver.cpp:105] Iteration 177200, lr = 0.0001
I1212 00:45:53.340389 17660 solver.cpp:218] Iteration 177300 (11.9552 iter/s, 8.36456s/100 iters), loss = 0.00883248
I1212 00:45:53.340389 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:45:53.340389 17660 solver.cpp:237]     Train net output #1: loss = 0.00883246 (* 1 = 0.00883246 loss)
I1212 00:45:53.340389 17660 sgd_solver.cpp:105] Iteration 177300, lr = 0.0001
I1212 00:46:01.887936 17660 solver.cpp:218] Iteration 177400 (11.6991 iter/s, 8.5477s/100 iters), loss = 0.0107889
I1212 00:46:01.887936 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:01.887936 17660 solver.cpp:237]     Train net output #1: loss = 0.0107889 (* 1 = 0.0107889 loss)
I1212 00:46:01.887936 17660 sgd_solver.cpp:105] Iteration 177400, lr = 0.0001
I1212 00:46:09.770643 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:46:10.105937 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_177500.caffemodel
I1212 00:46:10.134922 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_177500.solverstate
I1212 00:46:10.140944 17660 solver.cpp:330] Iteration 177500, Testing net (#0)
I1212 00:46:10.140944 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:46:11.864922 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:46:11.931937 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1212 00:46:11.931937 17660 solver.cpp:397]     Test net output #1: loss = 0.252678 (* 1 = 0.252678 loss)
I1212 00:46:12.009853 17660 solver.cpp:218] Iteration 177500 (9.8804 iter/s, 10.121s/100 iters), loss = 0.0113466
I1212 00:46:12.009853 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:12.009853 17660 solver.cpp:237]     Train net output #1: loss = 0.0113466 (* 1 = 0.0113466 loss)
I1212 00:46:12.009853 17660 sgd_solver.cpp:105] Iteration 177500, lr = 0.0001
I1212 00:46:20.169467 17660 solver.cpp:218] Iteration 177600 (12.2557 iter/s, 8.15944s/100 iters), loss = 0.00955618
I1212 00:46:20.169467 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:20.170470 17660 solver.cpp:237]     Train net output #1: loss = 0.00955616 (* 1 = 0.00955616 loss)
I1212 00:46:20.170470 17660 sgd_solver.cpp:105] Iteration 177600, lr = 0.0001
I1212 00:46:28.325135 17660 solver.cpp:218] Iteration 177700 (12.2628 iter/s, 8.15473s/100 iters), loss = 0.00917264
I1212 00:46:28.325135 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:28.325135 17660 solver.cpp:237]     Train net output #1: loss = 0.00917262 (* 1 = 0.00917262 loss)
I1212 00:46:28.325135 17660 sgd_solver.cpp:105] Iteration 177700, lr = 0.0001
I1212 00:46:36.472663 17660 solver.cpp:218] Iteration 177800 (12.2749 iter/s, 8.14669s/100 iters), loss = 0.00803463
I1212 00:46:36.472663 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:36.472663 17660 solver.cpp:237]     Train net output #1: loss = 0.00803462 (* 1 = 0.00803462 loss)
I1212 00:46:36.472663 17660 sgd_solver.cpp:105] Iteration 177800, lr = 0.0001
I1212 00:46:44.616601 17660 solver.cpp:218] Iteration 177900 (12.28 iter/s, 8.14333s/100 iters), loss = 0.0112564
I1212 00:46:44.616601 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:44.616601 17660 solver.cpp:237]     Train net output #1: loss = 0.0112564 (* 1 = 0.0112564 loss)
I1212 00:46:44.616601 17660 sgd_solver.cpp:105] Iteration 177900, lr = 0.0001
I1212 00:46:52.372540 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:46:52.694599 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_178000.caffemodel
I1212 00:46:52.760599 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_178000.solverstate
I1212 00:46:52.767601 17660 solver.cpp:330] Iteration 178000, Testing net (#0)
I1212 00:46:52.767601 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:46:54.469849 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:46:54.537855 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9353
I1212 00:46:54.537855 17660 solver.cpp:397]     Test net output #1: loss = 0.253298 (* 1 = 0.253298 loss)
I1212 00:46:54.613863 17660 solver.cpp:218] Iteration 178000 (10.0035 iter/s, 9.99646s/100 iters), loss = 0.0106391
I1212 00:46:54.613863 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:46:54.613863 17660 solver.cpp:237]     Train net output #1: loss = 0.0106391 (* 1 = 0.0106391 loss)
I1212 00:46:54.613863 17660 sgd_solver.cpp:105] Iteration 178000, lr = 0.0001
I1212 00:47:02.785471 17660 solver.cpp:218] Iteration 178100 (12.2384 iter/s, 8.171s/100 iters), loss = 0.0117692
I1212 00:47:02.785471 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:02.785471 17660 solver.cpp:237]     Train net output #1: loss = 0.0117692 (* 1 = 0.0117692 loss)
I1212 00:47:02.785471 17660 sgd_solver.cpp:105] Iteration 178100, lr = 0.0001
I1212 00:47:11.127249 17660 solver.cpp:218] Iteration 178200 (11.9881 iter/s, 8.3416s/100 iters), loss = 0.0103819
I1212 00:47:11.127249 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:11.127249 17660 solver.cpp:237]     Train net output #1: loss = 0.0103819 (* 1 = 0.0103819 loss)
I1212 00:47:11.127249 17660 sgd_solver.cpp:105] Iteration 178200, lr = 0.0001
I1212 00:47:19.431828 17660 solver.cpp:218] Iteration 178300 (12.0415 iter/s, 8.3046s/100 iters), loss = 0.0148282
I1212 00:47:19.432829 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:19.432829 17660 solver.cpp:237]     Train net output #1: loss = 0.0148282 (* 1 = 0.0148282 loss)
I1212 00:47:19.432829 17660 sgd_solver.cpp:105] Iteration 178300, lr = 0.0001
I1212 00:47:27.710278 17660 solver.cpp:218] Iteration 178400 (12.0814 iter/s, 8.2772s/100 iters), loss = 0.00925005
I1212 00:47:27.710278 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:27.710278 17660 solver.cpp:237]     Train net output #1: loss = 0.00925003 (* 1 = 0.00925003 loss)
I1212 00:47:27.710278 17660 sgd_solver.cpp:105] Iteration 178400, lr = 0.0001
I1212 00:47:35.697755 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:47:36.025089 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_178500.caffemodel
I1212 00:47:36.053088 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_178500.solverstate
I1212 00:47:36.059101 17660 solver.cpp:330] Iteration 178500, Testing net (#0)
I1212 00:47:36.059101 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:47:37.773452 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:47:37.840986 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9345
I1212 00:47:37.840986 17660 solver.cpp:397]     Test net output #1: loss = 0.252997 (* 1 = 0.252997 loss)
I1212 00:47:37.917234 17660 solver.cpp:218] Iteration 178500 (9.79795 iter/s, 10.2062s/100 iters), loss = 0.0121707
I1212 00:47:37.917234 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:37.917234 17660 solver.cpp:237]     Train net output #1: loss = 0.0121707 (* 1 = 0.0121707 loss)
I1212 00:47:37.917234 17660 sgd_solver.cpp:105] Iteration 178500, lr = 0.0001
I1212 00:47:46.102627 17660 solver.cpp:218] Iteration 178600 (12.217 iter/s, 8.18528s/100 iters), loss = 0.013362
I1212 00:47:46.102627 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:46.102627 17660 solver.cpp:237]     Train net output #1: loss = 0.013362 (* 1 = 0.013362 loss)
I1212 00:47:46.102627 17660 sgd_solver.cpp:105] Iteration 178600, lr = 0.0001
I1212 00:47:54.335841 17660 solver.cpp:218] Iteration 178700 (12.1475 iter/s, 8.23217s/100 iters), loss = 0.0119233
I1212 00:47:54.335841 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:47:54.335841 17660 solver.cpp:237]     Train net output #1: loss = 0.0119233 (* 1 = 0.0119233 loss)
I1212 00:47:54.335841 17660 sgd_solver.cpp:105] Iteration 178700, lr = 0.0001
I1212 00:48:02.589951 17660 solver.cpp:218] Iteration 178800 (12.1162 iter/s, 8.25345s/100 iters), loss = 0.0181845
I1212 00:48:02.589951 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:48:02.589951 17660 solver.cpp:237]     Train net output #1: loss = 0.0181845 (* 1 = 0.0181845 loss)
I1212 00:48:02.589951 17660 sgd_solver.cpp:105] Iteration 178800, lr = 0.0001
I1212 00:48:10.819427 17660 solver.cpp:218] Iteration 178900 (12.1519 iter/s, 8.22917s/100 iters), loss = 0.0092752
I1212 00:48:10.819427 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:48:10.819427 17660 solver.cpp:237]     Train net output #1: loss = 0.00927518 (* 1 = 0.00927518 loss)
I1212 00:48:10.819427 17660 sgd_solver.cpp:105] Iteration 178900, lr = 0.0001
I1212 00:48:18.730653 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:48:19.057274 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_179000.caffemodel
I1212 00:48:19.129374 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_179000.solverstate
I1212 00:48:19.135387 17660 solver.cpp:330] Iteration 179000, Testing net (#0)
I1212 00:48:19.135387 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:48:20.882591 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:48:20.951689 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1212 00:48:20.951689 17660 solver.cpp:397]     Test net output #1: loss = 0.253817 (* 1 = 0.253817 loss)
I1212 00:48:21.032781 17660 solver.cpp:218] Iteration 179000 (9.79169 iter/s, 10.2127s/100 iters), loss = 0.0214252
I1212 00:48:21.032781 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:48:21.032781 17660 solver.cpp:237]     Train net output #1: loss = 0.0214252 (* 1 = 0.0214252 loss)
I1212 00:48:21.032781 17660 sgd_solver.cpp:105] Iteration 179000, lr = 0.0001
I1212 00:48:29.472460 17660 solver.cpp:218] Iteration 179100 (11.8503 iter/s, 8.43859s/100 iters), loss = 0.0142621
I1212 00:48:29.472460 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:48:29.472460 17660 solver.cpp:237]     Train net output #1: loss = 0.014262 (* 1 = 0.014262 loss)
I1212 00:48:29.472460 17660 sgd_solver.cpp:105] Iteration 179100, lr = 0.0001
I1212 00:48:37.665611 17660 solver.cpp:218] Iteration 179200 (12.2052 iter/s, 8.19323s/100 iters), loss = 0.0111921
I1212 00:48:37.665611 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:48:37.665611 17660 solver.cpp:237]     Train net output #1: loss = 0.0111921 (* 1 = 0.0111921 loss)
I1212 00:48:37.665611 17660 sgd_solver.cpp:105] Iteration 179200, lr = 0.0001
I1212 00:48:45.874781 17660 solver.cpp:218] Iteration 179300 (12.1821 iter/s, 8.20876s/100 iters), loss = 0.00999528
I1212 00:48:45.875782 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:48:45.875782 17660 solver.cpp:237]     Train net output #1: loss = 0.00999526 (* 1 = 0.00999526 loss)
I1212 00:48:45.875782 17660 sgd_solver.cpp:105] Iteration 179300, lr = 0.0001
I1212 00:48:54.065942 17660 solver.cpp:218] Iteration 179400 (12.2101 iter/s, 8.18994s/100 iters), loss = 0.0114122
I1212 00:48:54.065942 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:48:54.065942 17660 solver.cpp:237]     Train net output #1: loss = 0.0114122 (* 1 = 0.0114122 loss)
I1212 00:48:54.065942 17660 sgd_solver.cpp:105] Iteration 179400, lr = 0.0001
I1212 00:49:01.944444 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:49:02.274734 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_179500.caffemodel
I1212 00:49:02.307729 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_179500.solverstate
I1212 00:49:02.313731 17660 solver.cpp:330] Iteration 179500, Testing net (#0)
I1212 00:49:02.313731 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:49:04.047709 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:49:04.115703 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1212 00:49:04.115703 17660 solver.cpp:397]     Test net output #1: loss = 0.253908 (* 1 = 0.253908 loss)
I1212 00:49:04.192725 17660 solver.cpp:218] Iteration 179500 (9.87504 iter/s, 10.1265s/100 iters), loss = 0.0125963
I1212 00:49:04.192725 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:04.192725 17660 solver.cpp:237]     Train net output #1: loss = 0.0125963 (* 1 = 0.0125963 loss)
I1212 00:49:04.192725 17660 sgd_solver.cpp:105] Iteration 179500, lr = 0.0001
I1212 00:49:12.378239 17660 solver.cpp:218] Iteration 179600 (12.2173 iter/s, 8.18513s/100 iters), loss = 0.0104193
I1212 00:49:12.378239 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:12.378239 17660 solver.cpp:237]     Train net output #1: loss = 0.0104192 (* 1 = 0.0104192 loss)
I1212 00:49:12.379223 17660 sgd_solver.cpp:105] Iteration 179600, lr = 0.0001
I1212 00:49:20.573318 17660 solver.cpp:218] Iteration 179700 (12.2045 iter/s, 8.19368s/100 iters), loss = 0.0130291
I1212 00:49:20.573318 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:20.573318 17660 solver.cpp:237]     Train net output #1: loss = 0.0130291 (* 1 = 0.0130291 loss)
I1212 00:49:20.573318 17660 sgd_solver.cpp:105] Iteration 179700, lr = 0.0001
I1212 00:49:28.855315 17660 solver.cpp:218] Iteration 179800 (12.0744 iter/s, 8.28199s/100 iters), loss = 0.0109946
I1212 00:49:28.855315 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:28.855315 17660 solver.cpp:237]     Train net output #1: loss = 0.0109946 (* 1 = 0.0109946 loss)
I1212 00:49:28.855315 17660 sgd_solver.cpp:105] Iteration 179800, lr = 0.0001
I1212 00:49:37.067652 17660 solver.cpp:218] Iteration 179900 (12.1782 iter/s, 8.21141s/100 iters), loss = 0.0115636
I1212 00:49:37.067652 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:37.067652 17660 solver.cpp:237]     Train net output #1: loss = 0.0115635 (* 1 = 0.0115635 loss)
I1212 00:49:37.067652 17660 sgd_solver.cpp:105] Iteration 179900, lr = 0.0001
I1212 00:49:44.809571 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:49:45.127424 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_180000.caffemodel
I1212 00:49:45.183579 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_180000.solverstate
I1212 00:49:45.190567 17660 solver.cpp:330] Iteration 180000, Testing net (#0)
I1212 00:49:45.190567 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:49:46.870964 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:49:46.938503 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9346
I1212 00:49:46.938503 17660 solver.cpp:397]     Test net output #1: loss = 0.254216 (* 1 = 0.254216 loss)
I1212 00:49:47.013511 17660 solver.cpp:218] Iteration 180000 (10.0546 iter/s, 9.94574s/100 iters), loss = 0.0183096
I1212 00:49:47.014513 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:47.014513 17660 solver.cpp:237]     Train net output #1: loss = 0.0183096 (* 1 = 0.0183096 loss)
I1212 00:49:47.014513 17660 sgd_solver.cpp:105] Iteration 180000, lr = 0.0001
I1212 00:49:55.158443 17660 solver.cpp:218] Iteration 180100 (12.2789 iter/s, 8.14407s/100 iters), loss = 0.00871962
I1212 00:49:55.158443 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:49:55.158443 17660 solver.cpp:237]     Train net output #1: loss = 0.0087196 (* 1 = 0.0087196 loss)
I1212 00:49:55.158443 17660 sgd_solver.cpp:105] Iteration 180100, lr = 0.0001
I1212 00:50:03.285235 17660 solver.cpp:218] Iteration 180200 (12.3057 iter/s, 8.12631s/100 iters), loss = 0.0142108
I1212 00:50:03.285235 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:03.285235 17660 solver.cpp:237]     Train net output #1: loss = 0.0142108 (* 1 = 0.0142108 loss)
I1212 00:50:03.285235 17660 sgd_solver.cpp:105] Iteration 180200, lr = 0.0001
I1212 00:50:11.428791 17660 solver.cpp:218] Iteration 180300 (12.2808 iter/s, 8.14278s/100 iters), loss = 0.0111953
I1212 00:50:11.428791 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:11.428791 17660 solver.cpp:237]     Train net output #1: loss = 0.0111953 (* 1 = 0.0111953 loss)
I1212 00:50:11.428791 17660 sgd_solver.cpp:105] Iteration 180300, lr = 0.0001
I1212 00:50:19.623935 17660 solver.cpp:218] Iteration 180400 (12.2037 iter/s, 8.19423s/100 iters), loss = 0.015045
I1212 00:50:19.623935 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:19.623935 17660 solver.cpp:237]     Train net output #1: loss = 0.015045 (* 1 = 0.015045 loss)
I1212 00:50:19.623935 17660 sgd_solver.cpp:105] Iteration 180400, lr = 0.0001
I1212 00:50:27.350194 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:50:27.666746 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_180500.caffemodel
I1212 00:50:27.698746 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_180500.solverstate
I1212 00:50:27.705747 17660 solver.cpp:330] Iteration 180500, Testing net (#0)
I1212 00:50:27.705747 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:50:29.393944 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:50:29.460945 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9348
I1212 00:50:29.461447 17660 solver.cpp:397]     Test net output #1: loss = 0.25343 (* 1 = 0.25343 loss)
I1212 00:50:29.537950 17660 solver.cpp:218] Iteration 180500 (10.0872 iter/s, 9.91355s/100 iters), loss = 0.0112673
I1212 00:50:29.537950 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:29.537950 17660 solver.cpp:237]     Train net output #1: loss = 0.0112673 (* 1 = 0.0112673 loss)
I1212 00:50:29.537950 17660 sgd_solver.cpp:105] Iteration 180500, lr = 0.0001
I1212 00:50:37.608922 17660 solver.cpp:218] Iteration 180600 (12.3907 iter/s, 8.07055s/100 iters), loss = 0.0104262
I1212 00:50:37.608922 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:37.608922 17660 solver.cpp:237]     Train net output #1: loss = 0.0104262 (* 1 = 0.0104262 loss)
I1212 00:50:37.608922 17660 sgd_solver.cpp:105] Iteration 180600, lr = 0.0001
I1212 00:50:45.728615 17660 solver.cpp:218] Iteration 180700 (12.3169 iter/s, 8.11892s/100 iters), loss = 0.011131
I1212 00:50:45.729116 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:45.729116 17660 solver.cpp:237]     Train net output #1: loss = 0.011131 (* 1 = 0.011131 loss)
I1212 00:50:45.729116 17660 sgd_solver.cpp:105] Iteration 180700, lr = 0.0001
I1212 00:50:53.875777 17660 solver.cpp:218] Iteration 180800 (12.2753 iter/s, 8.14643s/100 iters), loss = 0.00952933
I1212 00:50:53.875777 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:50:53.875777 17660 solver.cpp:237]     Train net output #1: loss = 0.00952931 (* 1 = 0.00952931 loss)
I1212 00:50:53.875777 17660 sgd_solver.cpp:105] Iteration 180800, lr = 0.0001
I1212 00:51:01.998018 17660 solver.cpp:218] Iteration 180900 (12.312 iter/s, 8.12215s/100 iters), loss = 0.0122331
I1212 00:51:01.998018 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:01.998018 17660 solver.cpp:237]     Train net output #1: loss = 0.0122331 (* 1 = 0.0122331 loss)
I1212 00:51:01.998018 17660 sgd_solver.cpp:105] Iteration 180900, lr = 0.0001
I1212 00:51:09.851723 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:51:10.170733 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_181000.caffemodel
I1212 00:51:10.251741 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_181000.solverstate
I1212 00:51:10.257742 17660 solver.cpp:330] Iteration 181000, Testing net (#0)
I1212 00:51:10.257742 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:51:11.976028 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:51:12.047031 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1212 00:51:12.047031 17660 solver.cpp:397]     Test net output #1: loss = 0.254051 (* 1 = 0.254051 loss)
I1212 00:51:12.123029 17660 solver.cpp:218] Iteration 181000 (9.8778 iter/s, 10.1237s/100 iters), loss = 0.0128314
I1212 00:51:12.123029 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:12.123029 17660 solver.cpp:237]     Train net output #1: loss = 0.0128314 (* 1 = 0.0128314 loss)
I1212 00:51:12.123029 17660 sgd_solver.cpp:105] Iteration 181000, lr = 0.0001
I1212 00:51:20.248551 17660 solver.cpp:218] Iteration 181100 (12.3073 iter/s, 8.12529s/100 iters), loss = 0.0148336
I1212 00:51:20.248551 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:20.248551 17660 solver.cpp:237]     Train net output #1: loss = 0.0148336 (* 1 = 0.0148336 loss)
I1212 00:51:20.248551 17660 sgd_solver.cpp:105] Iteration 181100, lr = 0.0001
I1212 00:51:28.349512 17660 solver.cpp:218] Iteration 181200 (12.3446 iter/s, 8.10073s/100 iters), loss = 0.0204419
I1212 00:51:28.349512 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:28.349512 17660 solver.cpp:237]     Train net output #1: loss = 0.0204419 (* 1 = 0.0204419 loss)
I1212 00:51:28.349512 17660 sgd_solver.cpp:105] Iteration 181200, lr = 0.0001
I1212 00:51:36.510496 17660 solver.cpp:218] Iteration 181300 (12.2552 iter/s, 8.15977s/100 iters), loss = 0.0100672
I1212 00:51:36.510496 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:36.510496 17660 solver.cpp:237]     Train net output #1: loss = 0.0100672 (* 1 = 0.0100672 loss)
I1212 00:51:36.510496 17660 sgd_solver.cpp:105] Iteration 181300, lr = 0.0001
I1212 00:51:44.823318 17660 solver.cpp:218] Iteration 181400 (12.0299 iter/s, 8.31259s/100 iters), loss = 0.0104694
I1212 00:51:44.823318 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:44.823318 17660 solver.cpp:237]     Train net output #1: loss = 0.0104694 (* 1 = 0.0104694 loss)
I1212 00:51:44.823318 17660 sgd_solver.cpp:105] Iteration 181400, lr = 0.0001
I1212 00:51:52.566382 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:51:52.887392 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_181500.caffemodel
I1212 00:51:52.918390 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_181500.solverstate
I1212 00:51:52.924391 17660 solver.cpp:330] Iteration 181500, Testing net (#0)
I1212 00:51:52.924391 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:51:54.618412 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:51:54.685508 17660 solver.cpp:397]     Test net output #0: accuracy = 0.935
I1212 00:51:54.685508 17660 solver.cpp:397]     Test net output #1: loss = 0.253072 (* 1 = 0.253072 loss)
I1212 00:51:54.763049 17660 solver.cpp:218] Iteration 181500 (10.0613 iter/s, 9.93903s/100 iters), loss = 0.0122839
I1212 00:51:54.763049 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:51:54.763049 17660 solver.cpp:237]     Train net output #1: loss = 0.0122839 (* 1 = 0.0122839 loss)
I1212 00:51:54.763049 17660 sgd_solver.cpp:105] Iteration 181500, lr = 0.0001
I1212 00:52:02.940114 17660 solver.cpp:218] Iteration 181600 (12.2301 iter/s, 8.17657s/100 iters), loss = 0.0141521
I1212 00:52:02.940114 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:52:02.940114 17660 solver.cpp:237]     Train net output #1: loss = 0.0141521 (* 1 = 0.0141521 loss)
I1212 00:52:02.940114 17660 sgd_solver.cpp:105] Iteration 181600, lr = 0.0001
I1212 00:52:11.062080 17660 solver.cpp:218] Iteration 181700 (12.3125 iter/s, 8.12185s/100 iters), loss = 0.0201827
I1212 00:52:11.062080 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:52:11.062080 17660 solver.cpp:237]     Train net output #1: loss = 0.0201827 (* 1 = 0.0201827 loss)
I1212 00:52:11.062080 17660 sgd_solver.cpp:105] Iteration 181700, lr = 0.0001
I1212 00:52:19.224915 17660 solver.cpp:218] Iteration 181800 (12.2524 iter/s, 8.16167s/100 iters), loss = 0.0123626
I1212 00:52:19.224915 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:52:19.224915 17660 solver.cpp:237]     Train net output #1: loss = 0.0123625 (* 1 = 0.0123625 loss)
I1212 00:52:19.224915 17660 sgd_solver.cpp:105] Iteration 181800, lr = 0.0001
I1212 00:52:27.369674 17660 solver.cpp:218] Iteration 181900 (12.2786 iter/s, 8.14428s/100 iters), loss = 0.0286787
I1212 00:52:27.369674 17660 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1212 00:52:27.369674 17660 solver.cpp:237]     Train net output #1: loss = 0.0286786 (* 1 = 0.0286786 loss)
I1212 00:52:27.369674 17660 sgd_solver.cpp:105] Iteration 181900, lr = 0.0001
I1212 00:52:35.154851 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:52:35.474884 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_182000.caffemodel
I1212 00:52:35.502892 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_182000.solverstate
I1212 00:52:35.509893 17660 solver.cpp:330] Iteration 182000, Testing net (#0)
I1212 00:52:35.509893 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:52:37.193059 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:52:37.261059 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9347
I1212 00:52:37.261059 17660 solver.cpp:397]     Test net output #1: loss = 0.25241 (* 1 = 0.25241 loss)
I1212 00:52:37.335068 17660 solver.cpp:218] Iteration 182000 (10.0347 iter/s, 9.96542s/100 iters), loss = 0.0121601
I1212 00:52:37.335068 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:52:37.335068 17660 solver.cpp:237]     Train net output #1: loss = 0.0121601 (* 1 = 0.0121601 loss)
I1212 00:52:37.335068 17660 sgd_solver.cpp:105] Iteration 182000, lr = 0.0001
I1212 00:52:45.405663 17660 solver.cpp:218] Iteration 182100 (12.3916 iter/s, 8.06998s/100 iters), loss = 0.0126986
I1212 00:52:45.405663 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:52:45.405663 17660 solver.cpp:237]     Train net output #1: loss = 0.0126986 (* 1 = 0.0126986 loss)
I1212 00:52:45.405663 17660 sgd_solver.cpp:105] Iteration 182100, lr = 0.0001
I1212 00:52:53.694054 17660 solver.cpp:218] Iteration 182200 (12.0665 iter/s, 8.28741s/100 iters), loss = 0.01612
I1212 00:52:53.694054 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:52:53.694054 17660 solver.cpp:237]     Train net output #1: loss = 0.01612 (* 1 = 0.01612 loss)
I1212 00:52:53.694054 17660 sgd_solver.cpp:105] Iteration 182200, lr = 0.0001
I1212 00:53:01.985208 17660 solver.cpp:218] Iteration 182300 (12.0622 iter/s, 8.29037s/100 iters), loss = 0.0105037
I1212 00:53:01.985208 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:01.985208 17660 solver.cpp:237]     Train net output #1: loss = 0.0105037 (* 1 = 0.0105037 loss)
I1212 00:53:01.985208 17660 sgd_solver.cpp:105] Iteration 182300, lr = 0.0001
I1212 00:53:10.154506 17660 solver.cpp:218] Iteration 182400 (12.2418 iter/s, 8.16873s/100 iters), loss = 0.0110045
I1212 00:53:10.154506 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:10.154506 17660 solver.cpp:237]     Train net output #1: loss = 0.0110045 (* 1 = 0.0110045 loss)
I1212 00:53:10.154506 17660 sgd_solver.cpp:105] Iteration 182400, lr = 0.0001
I1212 00:53:17.890172 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:53:18.209265 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_182500.caffemodel
I1212 00:53:18.237267 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_182500.solverstate
I1212 00:53:18.243281 17660 solver.cpp:330] Iteration 182500, Testing net (#0)
I1212 00:53:18.243281 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:53:19.925468 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:53:19.993474 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9354
I1212 00:53:19.993474 17660 solver.cpp:397]     Test net output #1: loss = 0.253212 (* 1 = 0.253212 loss)
I1212 00:53:20.067473 17660 solver.cpp:218] Iteration 182500 (10.0878 iter/s, 9.91295s/100 iters), loss = 0.0111093
I1212 00:53:20.067473 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:20.067473 17660 solver.cpp:237]     Train net output #1: loss = 0.0111093 (* 1 = 0.0111093 loss)
I1212 00:53:20.067473 17660 sgd_solver.cpp:105] Iteration 182500, lr = 0.0001
I1212 00:53:28.115317 17660 solver.cpp:218] Iteration 182600 (12.4265 iter/s, 8.0473s/100 iters), loss = 0.011804
I1212 00:53:28.115317 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:28.115317 17660 solver.cpp:237]     Train net output #1: loss = 0.011804 (* 1 = 0.011804 loss)
I1212 00:53:28.115317 17660 sgd_solver.cpp:105] Iteration 182600, lr = 0.0001
I1212 00:53:36.230836 17660 solver.cpp:218] Iteration 182700 (12.3236 iter/s, 8.11449s/100 iters), loss = 0.011134
I1212 00:53:36.230836 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:36.230836 17660 solver.cpp:237]     Train net output #1: loss = 0.011134 (* 1 = 0.011134 loss)
I1212 00:53:36.230836 17660 sgd_solver.cpp:105] Iteration 182700, lr = 0.0001
I1212 00:53:44.490062 17660 solver.cpp:218] Iteration 182800 (12.1083 iter/s, 8.25877s/100 iters), loss = 0.00832723
I1212 00:53:44.490062 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:44.490062 17660 solver.cpp:237]     Train net output #1: loss = 0.00832721 (* 1 = 0.00832721 loss)
I1212 00:53:44.490062 17660 sgd_solver.cpp:105] Iteration 182800, lr = 0.0001
I1212 00:53:52.691412 17660 solver.cpp:218] Iteration 182900 (12.1934 iter/s, 8.20115s/100 iters), loss = 0.019057
I1212 00:53:52.691412 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:53:52.691412 17660 solver.cpp:237]     Train net output #1: loss = 0.019057 (* 1 = 0.019057 loss)
I1212 00:53:52.691412 17660 sgd_solver.cpp:105] Iteration 182900, lr = 0.0001
I1212 00:54:00.394567 12884 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:54:00.713564 17660 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_183000.caffemodel
I1212 00:54:00.745065 17660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_183000.solverstate
I1212 00:54:00.751566 17660 solver.cpp:330] Iteration 183000, Testing net (#0)
I1212 00:54:00.752066 17660 net.cpp:676] Ignoring source layer accuracy_training
I1212 00:54:02.430948 22400 data_layer.cpp:73] Restarting data prefetching from start.
I1212 00:54:02.497951 17660 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1212 00:54:02.497951 17660 solver.cpp:397]     Test net output #1: loss = 0.253389 (* 1 = 0.253389 loss)
I1212 00:54:02.572968 17660 solver.cpp:218] Iteration 183000 (10.1205 iter/s, 9.88097s/100 iters), loss = 0.0124986
I1212 00:54:02.572968 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:54:02.572968 17660 solver.cpp:237]     Train net output #1: loss = 0.0124986 (* 1 = 0.0124986 loss)
I1212 00:54:02.572968 17660 sgd_solver.cpp:105] Iteration 183000, lr = 0.0001
I1212 00:54:10.857980 17660 solver.cpp:218] Iteration 183100 (12.0707 iter/s, 8.28456s/100 iters), loss = 0.0121411
I1212 00:54:10.857980 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:54:10.857980 17660 solver.cpp:237]     Train net output #1: loss = 0.0121411 (* 1 = 0.0121411 loss)
I1212 00:54:10.857980 17660 sgd_solver.cpp:105] Iteration 183100, lr = 0.0001
I1212 00:54:19.302299 17660 solver.cpp:218] Iteration 183200 (11.8434 iter/s, 8.44356s/100 iters), loss = 0.0149729
I1212 00:54:19.302299 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:54:19.302299 17660 solver.cpp:237]     Train net output #1: loss = 0.0149728 (* 1 = 0.0149728 loss)
I1212 00:54:19.302299 17660 sgd_solver.cpp:105] Iteration 183200, lr = 0.0001
I1212 00:54:27.439558 17660 solver.cpp:218] Iteration 183300 (12.2905 iter/s, 8.13638s/100 iters), loss = 0.0102995
I1212 00:54:27.439558 17660 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1212 00:54:27.439558 17660 solver.cpp:237]     Train net output #1: loss = 0.0102994 (* 1 = 0.0102994 loss)
I1212 00:54:27.439558 17660 sgd_solver.cpp:105] Iteration 183300, lr = 0.0001