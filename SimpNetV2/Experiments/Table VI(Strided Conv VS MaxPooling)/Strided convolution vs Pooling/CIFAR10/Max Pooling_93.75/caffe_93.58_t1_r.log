
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt --snapshot=examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate 
I1203 16:39:44.105628 12164 caffe.cpp:219] Using GPUs 0
I1203 16:39:44.300302 12164 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1203 16:39:44.600564 12164 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1203 16:39:44.616575 12164 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/resnet32_with3pooling"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 195000
stepvalue: 220000
stepvalue: 270000
type: "AdaDelta"
I1203 16:39:44.617561 12164 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 16:39:44.619573 12164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 16:39:44.619573 12164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1203 16:39:44.619573 12164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1203 16:39:44.619573 12164 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1203 16:39:44.620560 12164 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy_training"
  include
I1203 16:39:44.623579 12164 layer_factory.cpp:58] Creating layer cifar
I1203 16:39:44.628571 12164 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I1203 16:39:44.628571 12164 net.cpp:84] Creating Layer cifar
I1203 16:39:44.628571 12164 net.cpp:380] cifar -> data
I1203 16:39:44.628571 12164 net.cpp:380] cifar -> label
I1203 16:39:44.629570 12164 data_layer.cpp:45] output data size: 100,3,32,32
I1203 16:39:44.637563 12164 net.cpp:122] Setting up cifar
I1203 16:39:44.637563 12164 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1203 16:39:44.637563 12164 net.cpp:129] Top shape: 100 (100)
I1203 16:39:44.637563 12164 net.cpp:137] Memory required for data: 1229200
I1203 16:39:44.637563 12164 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1203 16:39:44.637563 12164 net.cpp:84] Creating Layer label_cifar_1_split
I1203 16:39:44.637563 12164 net.cpp:406] label_cifar_1_split <- label
I1203 16:39:44.637563 12164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1203 16:39:44.637563 12164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1203 16:39:44.637563 12164 net.cpp:122] Setting up label_cifar_1_split
I1203 16:39:44.637563 12164 net.cpp:129] Top shape: 100 (100)
I1203 16:39:44.637563 12164 net.cpp:129] Top shape: 100 (100)
I1203 16:39:44.637563 12164 net.cpp:137] Memory required for data: 1230000
I1203 16:39:44.637563 12164 layer_factory.cpp:58] Creating layer first_conv
I1203 16:39:44.637563 12164 net.cpp:84] Creating Layer first_conv
I1203 16:39:44.637563 12164 net.cpp:406] first_conv <- data
I1203 16:39:44.637563 12164 net.cpp:380] first_conv -> first_conv
I1203 16:39:44.638573  6116 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1203 16:39:44.882073 12164 net.cpp:122] Setting up first_conv
I1203 16:39:44.882073 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.883090 12164 net.cpp:137] Memory required for data: 7783600
I1203 16:39:44.883090 12164 layer_factory.cpp:58] Creating layer first_conv_bn
I1203 16:39:44.883090 12164 net.cpp:84] Creating Layer first_conv_bn
I1203 16:39:44.883090 12164 net.cpp:406] first_conv_bn <- first_conv
I1203 16:39:44.883090 12164 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1203 16:39:44.883090 12164 net.cpp:122] Setting up first_conv_bn
I1203 16:39:44.883090 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.883090 12164 net.cpp:137] Memory required for data: 14337200
I1203 16:39:44.883090 12164 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 16:39:44.883090 12164 net.cpp:84] Creating Layer first_conv_scale
I1203 16:39:44.883090 12164 net.cpp:406] first_conv_scale <- first_conv
I1203 16:39:44.883090 12164 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1203 16:39:44.883090 12164 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 16:39:44.883090 12164 net.cpp:122] Setting up first_conv_scale
I1203 16:39:44.883090 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.883090 12164 net.cpp:137] Memory required for data: 20890800
I1203 16:39:44.883090 12164 layer_factory.cpp:58] Creating layer first_conv_relu
I1203 16:39:44.883090 12164 net.cpp:84] Creating Layer first_conv_relu
I1203 16:39:44.883090 12164 net.cpp:406] first_conv_relu <- first_conv
I1203 16:39:44.883090 12164 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1203 16:39:44.883090 12164 net.cpp:122] Setting up first_conv_relu
I1203 16:39:44.883090 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.883090 12164 net.cpp:137] Memory required for data: 27444400
I1203 16:39:44.883090 12164 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1203 16:39:44.883090 12164 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1203 16:39:44.883090 12164 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1203 16:39:44.883090 12164 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1203 16:39:44.883090 12164 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1203 16:39:44.883090 12164 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1203 16:39:44.883090 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.883090 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.883090 12164 net.cpp:137] Memory required for data: 40551600
I1203 16:39:44.883090 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1203 16:39:44.883090 12164 net.cpp:84] Creating Layer group0_block0_conv0
I1203 16:39:44.883090 12164 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1203 16:39:44.883090 12164 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1203 16:39:44.885614 12164 net.cpp:122] Setting up group0_block0_conv0
I1203 16:39:44.885614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.885614 12164 net.cpp:137] Memory required for data: 47105200
I1203 16:39:44.885614 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1203 16:39:44.885614 12164 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1203 16:39:44.885614 12164 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1203 16:39:44.885614 12164 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1203 16:39:44.885614 12164 net.cpp:122] Setting up group0_block0_conv0_bn
I1203 16:39:44.885614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.885614 12164 net.cpp:137] Memory required for data: 53658800
I1203 16:39:44.886107 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 16:39:44.886107 12164 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1203 16:39:44.886107 12164 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1203 16:39:44.886107 12164 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1203 16:39:44.886107 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 16:39:44.886107 12164 net.cpp:122] Setting up group0_block0_conv0_scale
I1203 16:39:44.886107 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.886107 12164 net.cpp:137] Memory required for data: 60212400
I1203 16:39:44.886107 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1203 16:39:44.886107 12164 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1203 16:39:44.886107 12164 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1203 16:39:44.886107 12164 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1203 16:39:44.886107 12164 net.cpp:122] Setting up group0_block0_conv0_relu
I1203 16:39:44.886615 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.886615 12164 net.cpp:137] Memory required for data: 66766000
I1203 16:39:44.886615 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1203 16:39:44.886615 12164 net.cpp:84] Creating Layer group0_block0_conv1
I1203 16:39:44.886615 12164 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1203 16:39:44.886615 12164 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1203 16:39:44.887614 12164 net.cpp:122] Setting up group0_block0_conv1
I1203 16:39:44.887614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.887614 12164 net.cpp:137] Memory required for data: 73319600
I1203 16:39:44.887614 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1203 16:39:44.887614 12164 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1203 16:39:44.887614 12164 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1203 16:39:44.887614 12164 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1203 16:39:44.887614 12164 net.cpp:122] Setting up group0_block0_conv1_bn
I1203 16:39:44.887614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.887614 12164 net.cpp:137] Memory required for data: 79873200
I1203 16:39:44.887614 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 16:39:44.887614 12164 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1203 16:39:44.887614 12164 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1203 16:39:44.887614 12164 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1203 16:39:44.887614 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 16:39:44.887614 12164 net.cpp:122] Setting up group0_block0_conv1_scale
I1203 16:39:44.887614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.887614 12164 net.cpp:137] Memory required for data: 86426800
I1203 16:39:44.887614 12164 layer_factory.cpp:58] Creating layer group0_block0_sum
I1203 16:39:44.887614 12164 net.cpp:84] Creating Layer group0_block0_sum
I1203 16:39:44.887614 12164 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1203 16:39:44.888113 12164 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1203 16:39:44.888113 12164 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1203 16:39:44.888113 12164 net.cpp:122] Setting up group0_block0_sum
I1203 16:39:44.888113 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.888113 12164 net.cpp:137] Memory required for data: 92980400
I1203 16:39:44.888113 12164 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1203 16:39:44.888113 12164 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1203 16:39:44.888113 12164 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1203 16:39:44.888113 12164 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1203 16:39:44.888113 12164 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1203 16:39:44.888113 12164 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1203 16:39:44.888113 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.888113 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.888113 12164 net.cpp:137] Memory required for data: 106087600
I1203 16:39:44.888113 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1203 16:39:44.888113 12164 net.cpp:84] Creating Layer group0_block1_conv0
I1203 16:39:44.888113 12164 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1203 16:39:44.888113 12164 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1203 16:39:44.889114 12164 net.cpp:122] Setting up group0_block1_conv0
I1203 16:39:44.889114 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.889114 12164 net.cpp:137] Memory required for data: 112641200
I1203 16:39:44.889114 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1203 16:39:44.889114 12164 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1203 16:39:44.889114 12164 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1203 16:39:44.889114 12164 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1203 16:39:44.889614 12164 net.cpp:122] Setting up group0_block1_conv0_bn
I1203 16:39:44.889614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.889614 12164 net.cpp:137] Memory required for data: 119194800
I1203 16:39:44.889614 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 16:39:44.889614 12164 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1203 16:39:44.889614 12164 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1203 16:39:44.889614 12164 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1203 16:39:44.889614 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 16:39:44.889614 12164 net.cpp:122] Setting up group0_block1_conv0_scale
I1203 16:39:44.889614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.889614 12164 net.cpp:137] Memory required for data: 125748400
I1203 16:39:44.889614 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1203 16:39:44.889614 12164 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1203 16:39:44.889614 12164 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1203 16:39:44.889614 12164 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1203 16:39:44.889614 12164 net.cpp:122] Setting up group0_block1_conv0_relu
I1203 16:39:44.889614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.889614 12164 net.cpp:137] Memory required for data: 132302000
I1203 16:39:44.889614 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1203 16:39:44.890115 12164 net.cpp:84] Creating Layer group0_block1_conv1
I1203 16:39:44.890115 12164 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1203 16:39:44.890115 12164 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1203 16:39:44.891113 12164 net.cpp:122] Setting up group0_block1_conv1
I1203 16:39:44.891113 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.891113 12164 net.cpp:137] Memory required for data: 138855600
I1203 16:39:44.891113 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1203 16:39:44.891113 12164 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1203 16:39:44.891113 12164 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1203 16:39:44.891113 12164 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1203 16:39:44.891113 12164 net.cpp:122] Setting up group0_block1_conv1_bn
I1203 16:39:44.891113 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.891113 12164 net.cpp:137] Memory required for data: 145409200
I1203 16:39:44.891113 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 16:39:44.891113 12164 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1203 16:39:44.891113 12164 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1203 16:39:44.891113 12164 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1203 16:39:44.891113 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 16:39:44.891113 12164 net.cpp:122] Setting up group0_block1_conv1_scale
I1203 16:39:44.891113 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.891113 12164 net.cpp:137] Memory required for data: 151962800
I1203 16:39:44.891113 12164 layer_factory.cpp:58] Creating layer group0_block1_sum
I1203 16:39:44.891613 12164 net.cpp:84] Creating Layer group0_block1_sum
I1203 16:39:44.891613 12164 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1203 16:39:44.891613 12164 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1203 16:39:44.891613 12164 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1203 16:39:44.891613 12164 net.cpp:122] Setting up group0_block1_sum
I1203 16:39:44.891613 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.891613 12164 net.cpp:137] Memory required for data: 158516400
I1203 16:39:44.891613 12164 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1203 16:39:44.891613 12164 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1203 16:39:44.891613 12164 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1203 16:39:44.891613 12164 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1203 16:39:44.891613 12164 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1203 16:39:44.891613 12164 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1203 16:39:44.891613 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.891613 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.891613 12164 net.cpp:137] Memory required for data: 171623600
I1203 16:39:44.891613 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1203 16:39:44.891613 12164 net.cpp:84] Creating Layer group0_block2_conv0
I1203 16:39:44.891613 12164 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1203 16:39:44.891613 12164 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1203 16:39:44.892614 12164 net.cpp:122] Setting up group0_block2_conv0
I1203 16:39:44.892614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.892614 12164 net.cpp:137] Memory required for data: 178177200
I1203 16:39:44.892614 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1203 16:39:44.892614 12164 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1203 16:39:44.892614 12164 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1203 16:39:44.892614 12164 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1203 16:39:44.892614 12164 net.cpp:122] Setting up group0_block2_conv0_bn
I1203 16:39:44.892614 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.892614 12164 net.cpp:137] Memory required for data: 184730800
I1203 16:39:44.892614 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 16:39:44.893115 12164 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1203 16:39:44.893115 12164 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1203 16:39:44.893115 12164 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1203 16:39:44.893115 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 16:39:44.893115 12164 net.cpp:122] Setting up group0_block2_conv0_scale
I1203 16:39:44.893115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.893115 12164 net.cpp:137] Memory required for data: 191284400
I1203 16:39:44.893115 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1203 16:39:44.893115 12164 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1203 16:39:44.893115 12164 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1203 16:39:44.893115 12164 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1203 16:39:44.893615 12164 net.cpp:122] Setting up group0_block2_conv0_relu
I1203 16:39:44.893615 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.893615 12164 net.cpp:137] Memory required for data: 197838000
I1203 16:39:44.893615 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1203 16:39:44.893615 12164 net.cpp:84] Creating Layer group0_block2_conv1
I1203 16:39:44.893615 12164 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1203 16:39:44.893615 12164 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1203 16:39:44.894608 12164 net.cpp:122] Setting up group0_block2_conv1
I1203 16:39:44.894608 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.894608 12164 net.cpp:137] Memory required for data: 204391600
I1203 16:39:44.894608 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1203 16:39:44.894608 12164 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1203 16:39:44.894608 12164 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1203 16:39:44.894608 12164 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1203 16:39:44.895112 12164 net.cpp:122] Setting up group0_block2_conv1_bn
I1203 16:39:44.895112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.895112 12164 net.cpp:137] Memory required for data: 210945200
I1203 16:39:44.895112 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 16:39:44.895112 12164 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1203 16:39:44.895112 12164 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1203 16:39:44.895112 12164 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1203 16:39:44.895112 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 16:39:44.895112 12164 net.cpp:122] Setting up group0_block2_conv1_scale
I1203 16:39:44.895112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.895112 12164 net.cpp:137] Memory required for data: 217498800
I1203 16:39:44.895112 12164 layer_factory.cpp:58] Creating layer group0_block2_sum
I1203 16:39:44.895112 12164 net.cpp:84] Creating Layer group0_block2_sum
I1203 16:39:44.895112 12164 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1203 16:39:44.895112 12164 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1203 16:39:44.895112 12164 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1203 16:39:44.895112 12164 net.cpp:122] Setting up group0_block2_sum
I1203 16:39:44.895112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.895112 12164 net.cpp:137] Memory required for data: 224052400
I1203 16:39:44.895112 12164 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1203 16:39:44.895112 12164 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1203 16:39:44.895112 12164 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1203 16:39:44.895112 12164 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1203 16:39:44.895112 12164 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1203 16:39:44.895112 12164 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1203 16:39:44.895112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.895112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.895112 12164 net.cpp:137] Memory required for data: 237159600
I1203 16:39:44.895112 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1203 16:39:44.895611 12164 net.cpp:84] Creating Layer group0_block3_conv0
I1203 16:39:44.895611 12164 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1203 16:39:44.895611 12164 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1203 16:39:44.896610 12164 net.cpp:122] Setting up group0_block3_conv0
I1203 16:39:44.896610 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.896610 12164 net.cpp:137] Memory required for data: 243713200
I1203 16:39:44.896610 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1203 16:39:44.896610 12164 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1203 16:39:44.896610 12164 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1203 16:39:44.896610 12164 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1203 16:39:44.896610 12164 net.cpp:122] Setting up group0_block3_conv0_bn
I1203 16:39:44.896610 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.896610 12164 net.cpp:137] Memory required for data: 250266800
I1203 16:39:44.896610 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 16:39:44.896610 12164 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1203 16:39:44.896610 12164 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1203 16:39:44.896610 12164 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1203 16:39:44.896610 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 16:39:44.896610 12164 net.cpp:122] Setting up group0_block3_conv0_scale
I1203 16:39:44.896610 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.896610 12164 net.cpp:137] Memory required for data: 256820400
I1203 16:39:44.896610 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1203 16:39:44.896610 12164 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1203 16:39:44.896610 12164 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1203 16:39:44.896610 12164 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1203 16:39:44.897110 12164 net.cpp:122] Setting up group0_block3_conv0_relu
I1203 16:39:44.897110 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.897110 12164 net.cpp:137] Memory required for data: 263374000
I1203 16:39:44.897110 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1203 16:39:44.897110 12164 net.cpp:84] Creating Layer group0_block3_conv1
I1203 16:39:44.897110 12164 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1203 16:39:44.897110 12164 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1203 16:39:44.898110 12164 net.cpp:122] Setting up group0_block3_conv1
I1203 16:39:44.898110 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.898110 12164 net.cpp:137] Memory required for data: 269927600
I1203 16:39:44.898110 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1203 16:39:44.898110 12164 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1203 16:39:44.898110 12164 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1203 16:39:44.898110 12164 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1203 16:39:44.898612 12164 net.cpp:122] Setting up group0_block3_conv1_bn
I1203 16:39:44.898612 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.898612 12164 net.cpp:137] Memory required for data: 276481200
I1203 16:39:44.898612 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 16:39:44.898612 12164 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1203 16:39:44.898612 12164 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1203 16:39:44.898612 12164 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1203 16:39:44.898612 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 16:39:44.898612 12164 net.cpp:122] Setting up group0_block3_conv1_scale
I1203 16:39:44.898612 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.898612 12164 net.cpp:137] Memory required for data: 283034800
I1203 16:39:44.898612 12164 layer_factory.cpp:58] Creating layer group0_block3_sum
I1203 16:39:44.898612 12164 net.cpp:84] Creating Layer group0_block3_sum
I1203 16:39:44.898612 12164 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1203 16:39:44.898612 12164 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1203 16:39:44.898612 12164 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1203 16:39:44.898612 12164 net.cpp:122] Setting up group0_block3_sum
I1203 16:39:44.898612 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.898612 12164 net.cpp:137] Memory required for data: 289588400
I1203 16:39:44.898612 12164 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1203 16:39:44.898612 12164 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1203 16:39:44.898612 12164 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1203 16:39:44.898612 12164 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1203 16:39:44.898612 12164 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1203 16:39:44.898612 12164 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1203 16:39:44.898612 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.898612 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.898612 12164 net.cpp:137] Memory required for data: 302695600
I1203 16:39:44.898612 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1203 16:39:44.899111 12164 net.cpp:84] Creating Layer group0_block4_conv0
I1203 16:39:44.899111 12164 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1203 16:39:44.899111 12164 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1203 16:39:44.900112 12164 net.cpp:122] Setting up group0_block4_conv0
I1203 16:39:44.900112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.900112 12164 net.cpp:137] Memory required for data: 309249200
I1203 16:39:44.900112 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1203 16:39:44.900112 12164 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1203 16:39:44.900112 12164 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1203 16:39:44.900112 12164 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1203 16:39:44.900112 12164 net.cpp:122] Setting up group0_block4_conv0_bn
I1203 16:39:44.900112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.900112 12164 net.cpp:137] Memory required for data: 315802800
I1203 16:39:44.900112 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 16:39:44.900112 12164 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1203 16:39:44.900112 12164 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1203 16:39:44.900112 12164 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1203 16:39:44.900112 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 16:39:44.900112 12164 net.cpp:122] Setting up group0_block4_conv0_scale
I1203 16:39:44.900112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.900112 12164 net.cpp:137] Memory required for data: 322356400
I1203 16:39:44.900112 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1203 16:39:44.900112 12164 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1203 16:39:44.900112 12164 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1203 16:39:44.900112 12164 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1203 16:39:44.900112 12164 net.cpp:122] Setting up group0_block4_conv0_relu
I1203 16:39:44.900112 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.900112 12164 net.cpp:137] Memory required for data: 328910000
I1203 16:39:44.900112 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1203 16:39:44.900112 12164 net.cpp:84] Creating Layer group0_block4_conv1
I1203 16:39:44.900112 12164 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1203 16:39:44.900112 12164 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1203 16:39:44.901127 12164 net.cpp:122] Setting up group0_block4_conv1
I1203 16:39:44.902115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.902115 12164 net.cpp:137] Memory required for data: 335463600
I1203 16:39:44.902115 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1203 16:39:44.902115 12164 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1203 16:39:44.902115 12164 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1203 16:39:44.902115 12164 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1203 16:39:44.902115 12164 net.cpp:122] Setting up group0_block4_conv1_bn
I1203 16:39:44.902115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.902115 12164 net.cpp:137] Memory required for data: 342017200
I1203 16:39:44.902115 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 16:39:44.902115 12164 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1203 16:39:44.902115 12164 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1203 16:39:44.902115 12164 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1203 16:39:44.902115 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 16:39:44.902115 12164 net.cpp:122] Setting up group0_block4_conv1_scale
I1203 16:39:44.902115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.902115 12164 net.cpp:137] Memory required for data: 348570800
I1203 16:39:44.902115 12164 layer_factory.cpp:58] Creating layer group0_block4_sum
I1203 16:39:44.902115 12164 net.cpp:84] Creating Layer group0_block4_sum
I1203 16:39:44.902115 12164 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1203 16:39:44.902115 12164 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1203 16:39:44.902115 12164 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1203 16:39:44.902115 12164 net.cpp:122] Setting up group0_block4_sum
I1203 16:39:44.902115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.902115 12164 net.cpp:137] Memory required for data: 355124400
I1203 16:39:44.902115 12164 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1203 16:39:44.902115 12164 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1203 16:39:44.902115 12164 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1203 16:39:44.902115 12164 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1203 16:39:44.902115 12164 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1203 16:39:44.902115 12164 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1203 16:39:44.902115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.902115 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.902115 12164 net.cpp:137] Memory required for data: 368231600
I1203 16:39:44.902115 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1203 16:39:44.902115 12164 net.cpp:84] Creating Layer group1_block0_conv0
I1203 16:39:44.902115 12164 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1203 16:39:44.902115 12164 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1203 16:39:44.904131 12164 net.cpp:122] Setting up group1_block0_conv0
I1203 16:39:44.904131 12164 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1203 16:39:44.904131 12164 net.cpp:137] Memory required for data: 381338800
I1203 16:39:44.904131 12164 layer_factory.cpp:58] Creating layer pool1
I1203 16:39:44.904131 12164 net.cpp:84] Creating Layer pool1
I1203 16:39:44.904131 12164 net.cpp:406] pool1 <- group1_block0_conv0
I1203 16:39:44.904131 12164 net.cpp:380] pool1 -> pool1
I1203 16:39:44.904131 12164 net.cpp:122] Setting up pool1
I1203 16:39:44.904131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.904131 12164 net.cpp:137] Memory required for data: 384615600
I1203 16:39:44.904131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1203 16:39:44.904131 12164 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1203 16:39:44.904131 12164 net.cpp:406] group1_block0_conv0_bn <- pool1
I1203 16:39:44.904131 12164 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1203 16:39:44.904131 12164 net.cpp:122] Setting up group1_block0_conv0_bn
I1203 16:39:44.904131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.904131 12164 net.cpp:137] Memory required for data: 387892400
I1203 16:39:44.904131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 16:39:44.904131 12164 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1203 16:39:44.904131 12164 net.cpp:406] group1_block0_conv0_scale <- pool1
I1203 16:39:44.904131 12164 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1203 16:39:44.904131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 16:39:44.904131 12164 net.cpp:122] Setting up group1_block0_conv0_scale
I1203 16:39:44.904131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.904131 12164 net.cpp:137] Memory required for data: 391169200
I1203 16:39:44.904131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1203 16:39:44.904131 12164 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1203 16:39:44.904131 12164 net.cpp:406] group1_block0_conv0_relu <- pool1
I1203 16:39:44.904131 12164 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1203 16:39:44.905128 12164 net.cpp:122] Setting up group1_block0_conv0_relu
I1203 16:39:44.905128 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.905128 12164 net.cpp:137] Memory required for data: 394446000
I1203 16:39:44.905128 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1203 16:39:44.905128 12164 net.cpp:84] Creating Layer group1_block0_conv1
I1203 16:39:44.905128 12164 net.cpp:406] group1_block0_conv1 <- pool1
I1203 16:39:44.905128 12164 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1203 16:39:44.906131 12164 net.cpp:122] Setting up group1_block0_conv1
I1203 16:39:44.906131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.906131 12164 net.cpp:137] Memory required for data: 397722800
I1203 16:39:44.906131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1203 16:39:44.906131 12164 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1203 16:39:44.906131 12164 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1203 16:39:44.906131 12164 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1203 16:39:44.906131 12164 net.cpp:122] Setting up group1_block0_conv1_bn
I1203 16:39:44.906131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.906131 12164 net.cpp:137] Memory required for data: 400999600
I1203 16:39:44.906131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 16:39:44.906131 12164 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1203 16:39:44.906131 12164 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1203 16:39:44.906131 12164 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1203 16:39:44.906131 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 16:39:44.906131 12164 net.cpp:122] Setting up group1_block0_conv1_scale
I1203 16:39:44.906131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.906131 12164 net.cpp:137] Memory required for data: 404276400
I1203 16:39:44.906131 12164 layer_factory.cpp:58] Creating layer group1_block0_proj
I1203 16:39:44.906131 12164 net.cpp:84] Creating Layer group1_block0_proj
I1203 16:39:44.906131 12164 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1203 16:39:44.906131 12164 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1203 16:39:44.907131 12164 net.cpp:122] Setting up group1_block0_proj
I1203 16:39:44.907131 12164 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1203 16:39:44.907131 12164 net.cpp:137] Memory required for data: 416577200
I1203 16:39:44.907131 12164 layer_factory.cpp:58] Creating layer pool2
I1203 16:39:44.907131 12164 net.cpp:84] Creating Layer pool2
I1203 16:39:44.907131 12164 net.cpp:406] pool2 <- group1_block0_proj
I1203 16:39:44.907131 12164 net.cpp:380] pool2 -> pool2
I1203 16:39:44.907131 12164 net.cpp:122] Setting up pool2
I1203 16:39:44.907131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.907131 12164 net.cpp:137] Memory required for data: 419854000
I1203 16:39:44.908131 12164 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1203 16:39:44.908131 12164 net.cpp:84] Creating Layer group1_block0_proj_bn
I1203 16:39:44.908131 12164 net.cpp:406] group1_block0_proj_bn <- pool2
I1203 16:39:44.908131 12164 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1203 16:39:44.908131 12164 net.cpp:122] Setting up group1_block0_proj_bn
I1203 16:39:44.908131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.908131 12164 net.cpp:137] Memory required for data: 423130800
I1203 16:39:44.908131 12164 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 16:39:44.908131 12164 net.cpp:84] Creating Layer group1_block0_proj_scale
I1203 16:39:44.908131 12164 net.cpp:406] group1_block0_proj_scale <- pool2
I1203 16:39:44.908131 12164 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1203 16:39:44.908131 12164 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 16:39:44.908131 12164 net.cpp:122] Setting up group1_block0_proj_scale
I1203 16:39:44.908131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.908131 12164 net.cpp:137] Memory required for data: 426407600
I1203 16:39:44.908131 12164 layer_factory.cpp:58] Creating layer group1_block0_sum
I1203 16:39:44.908131 12164 net.cpp:84] Creating Layer group1_block0_sum
I1203 16:39:44.908131 12164 net.cpp:406] group1_block0_sum <- pool2
I1203 16:39:44.908131 12164 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1203 16:39:44.908131 12164 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1203 16:39:44.908131 12164 net.cpp:122] Setting up group1_block0_sum
I1203 16:39:44.908131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.908131 12164 net.cpp:137] Memory required for data: 429684400
I1203 16:39:44.908131 12164 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1203 16:39:44.908131 12164 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1203 16:39:44.908131 12164 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1203 16:39:44.908131 12164 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1203 16:39:44.908131 12164 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1203 16:39:44.908131 12164 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1203 16:39:44.908131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.908131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.908131 12164 net.cpp:137] Memory required for data: 436238000
I1203 16:39:44.908131 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1203 16:39:44.908131 12164 net.cpp:84] Creating Layer group1_block1_conv0
I1203 16:39:44.908131 12164 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1203 16:39:44.908131 12164 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1203 16:39:44.909132 12164 net.cpp:122] Setting up group1_block1_conv0
I1203 16:39:44.909132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.909132 12164 net.cpp:137] Memory required for data: 439514800
I1203 16:39:44.909132 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1203 16:39:44.909132 12164 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1203 16:39:44.909132 12164 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1203 16:39:44.909132 12164 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1203 16:39:44.910117 12164 net.cpp:122] Setting up group1_block1_conv0_bn
I1203 16:39:44.910117 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.910117 12164 net.cpp:137] Memory required for data: 442791600
I1203 16:39:44.910117 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 16:39:44.910117 12164 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1203 16:39:44.910117 12164 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1203 16:39:44.910117 12164 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1203 16:39:44.910117 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 16:39:44.910117 12164 net.cpp:122] Setting up group1_block1_conv0_scale
I1203 16:39:44.910117 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.910117 12164 net.cpp:137] Memory required for data: 446068400
I1203 16:39:44.910117 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1203 16:39:44.910117 12164 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1203 16:39:44.910117 12164 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1203 16:39:44.910117 12164 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1203 16:39:44.910117 12164 net.cpp:122] Setting up group1_block1_conv0_relu
I1203 16:39:44.910117 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.910117 12164 net.cpp:137] Memory required for data: 449345200
I1203 16:39:44.910117 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1203 16:39:44.910117 12164 net.cpp:84] Creating Layer group1_block1_conv1
I1203 16:39:44.910117 12164 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1203 16:39:44.910117 12164 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1203 16:39:44.911115 12164 net.cpp:122] Setting up group1_block1_conv1
I1203 16:39:44.911115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.911115 12164 net.cpp:137] Memory required for data: 452622000
I1203 16:39:44.911115 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1203 16:39:44.911115 12164 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1203 16:39:44.911115 12164 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1203 16:39:44.911115 12164 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1203 16:39:44.911115 12164 net.cpp:122] Setting up group1_block1_conv1_bn
I1203 16:39:44.911115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.911115 12164 net.cpp:137] Memory required for data: 455898800
I1203 16:39:44.911115 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 16:39:44.911115 12164 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1203 16:39:44.911115 12164 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1203 16:39:44.911115 12164 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1203 16:39:44.911115 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 16:39:44.912132 12164 net.cpp:122] Setting up group1_block1_conv1_scale
I1203 16:39:44.912132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.912132 12164 net.cpp:137] Memory required for data: 459175600
I1203 16:39:44.912132 12164 layer_factory.cpp:58] Creating layer group1_block1_sum
I1203 16:39:44.912132 12164 net.cpp:84] Creating Layer group1_block1_sum
I1203 16:39:44.912132 12164 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1203 16:39:44.912132 12164 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1203 16:39:44.912132 12164 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1203 16:39:44.912132 12164 net.cpp:122] Setting up group1_block1_sum
I1203 16:39:44.912132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.912132 12164 net.cpp:137] Memory required for data: 462452400
I1203 16:39:44.912132 12164 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1203 16:39:44.912132 12164 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1203 16:39:44.912132 12164 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1203 16:39:44.912132 12164 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1203 16:39:44.912132 12164 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1203 16:39:44.912132 12164 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1203 16:39:44.912132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.912132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.912132 12164 net.cpp:137] Memory required for data: 469006000
I1203 16:39:44.912132 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1203 16:39:44.912132 12164 net.cpp:84] Creating Layer group1_block2_conv0
I1203 16:39:44.912132 12164 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1203 16:39:44.912132 12164 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1203 16:39:44.913132 12164 net.cpp:122] Setting up group1_block2_conv0
I1203 16:39:44.913132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.913132 12164 net.cpp:137] Memory required for data: 472282800
I1203 16:39:44.913132 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1203 16:39:44.913132 12164 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1203 16:39:44.913132 12164 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1203 16:39:44.913132 12164 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1203 16:39:44.913132 12164 net.cpp:122] Setting up group1_block2_conv0_bn
I1203 16:39:44.913132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.913132 12164 net.cpp:137] Memory required for data: 475559600
I1203 16:39:44.913132 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 16:39:44.913132 12164 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1203 16:39:44.913132 12164 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1203 16:39:44.913132 12164 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1203 16:39:44.913132 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 16:39:44.913132 12164 net.cpp:122] Setting up group1_block2_conv0_scale
I1203 16:39:44.913132 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.913132 12164 net.cpp:137] Memory required for data: 478836400
I1203 16:39:44.913132 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1203 16:39:44.913132 12164 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1203 16:39:44.913132 12164 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1203 16:39:44.913132 12164 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1203 16:39:44.914131 12164 net.cpp:122] Setting up group1_block2_conv0_relu
I1203 16:39:44.914131 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.914131 12164 net.cpp:137] Memory required for data: 482113200
I1203 16:39:44.914131 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1203 16:39:44.914131 12164 net.cpp:84] Creating Layer group1_block2_conv1
I1203 16:39:44.914131 12164 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1203 16:39:44.914131 12164 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1203 16:39:44.916115 12164 net.cpp:122] Setting up group1_block2_conv1
I1203 16:39:44.916115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.916115 12164 net.cpp:137] Memory required for data: 485390000
I1203 16:39:44.916115 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1203 16:39:44.916115 12164 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1203 16:39:44.916115 12164 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1203 16:39:44.916115 12164 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1203 16:39:44.916115 12164 net.cpp:122] Setting up group1_block2_conv1_bn
I1203 16:39:44.916115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.916115 12164 net.cpp:137] Memory required for data: 488666800
I1203 16:39:44.916115 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 16:39:44.916115 12164 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1203 16:39:44.916115 12164 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1203 16:39:44.916115 12164 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1203 16:39:44.916115 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 16:39:44.916115 12164 net.cpp:122] Setting up group1_block2_conv1_scale
I1203 16:39:44.916115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.916115 12164 net.cpp:137] Memory required for data: 491943600
I1203 16:39:44.916115 12164 layer_factory.cpp:58] Creating layer group1_block2_sum
I1203 16:39:44.916115 12164 net.cpp:84] Creating Layer group1_block2_sum
I1203 16:39:44.916115 12164 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1203 16:39:44.916115 12164 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1203 16:39:44.916115 12164 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1203 16:39:44.916115 12164 net.cpp:122] Setting up group1_block2_sum
I1203 16:39:44.917114 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.917114 12164 net.cpp:137] Memory required for data: 495220400
I1203 16:39:44.917114 12164 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1203 16:39:44.917114 12164 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1203 16:39:44.917114 12164 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1203 16:39:44.917114 12164 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1203 16:39:44.917114 12164 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1203 16:39:44.917114 12164 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1203 16:39:44.917114 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.917114 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.917114 12164 net.cpp:137] Memory required for data: 501774000
I1203 16:39:44.917114 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1203 16:39:44.917114 12164 net.cpp:84] Creating Layer group1_block3_conv0
I1203 16:39:44.917114 12164 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1203 16:39:44.917114 12164 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1203 16:39:44.918128 12164 net.cpp:122] Setting up group1_block3_conv0
I1203 16:39:44.918128 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.918128 12164 net.cpp:137] Memory required for data: 505050800
I1203 16:39:44.918128 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1203 16:39:44.918128 12164 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1203 16:39:44.918128 12164 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1203 16:39:44.918128 12164 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1203 16:39:44.918128 12164 net.cpp:122] Setting up group1_block3_conv0_bn
I1203 16:39:44.918128 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.918128 12164 net.cpp:137] Memory required for data: 508327600
I1203 16:39:44.918128 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 16:39:44.918128 12164 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1203 16:39:44.918128 12164 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1203 16:39:44.918128 12164 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1203 16:39:44.918128 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 16:39:44.918128 12164 net.cpp:122] Setting up group1_block3_conv0_scale
I1203 16:39:44.918128 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.919127 12164 net.cpp:137] Memory required for data: 511604400
I1203 16:39:44.919127 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1203 16:39:44.919127 12164 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1203 16:39:44.919127 12164 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1203 16:39:44.919127 12164 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1203 16:39:44.919127 12164 net.cpp:122] Setting up group1_block3_conv0_relu
I1203 16:39:44.919127 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.919127 12164 net.cpp:137] Memory required for data: 514881200
I1203 16:39:44.919127 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1203 16:39:44.919127 12164 net.cpp:84] Creating Layer group1_block3_conv1
I1203 16:39:44.919127 12164 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1203 16:39:44.919127 12164 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1203 16:39:44.920115 12164 net.cpp:122] Setting up group1_block3_conv1
I1203 16:39:44.920115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.920115 12164 net.cpp:137] Memory required for data: 518158000
I1203 16:39:44.920115 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1203 16:39:44.920115 12164 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1203 16:39:44.920115 12164 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1203 16:39:44.920115 12164 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1203 16:39:44.920115 12164 net.cpp:122] Setting up group1_block3_conv1_bn
I1203 16:39:44.920115 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.920115 12164 net.cpp:137] Memory required for data: 521434800
I1203 16:39:44.920115 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 16:39:44.920115 12164 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1203 16:39:44.920115 12164 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1203 16:39:44.920115 12164 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1203 16:39:44.920115 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 16:39:44.921113 12164 net.cpp:122] Setting up group1_block3_conv1_scale
I1203 16:39:44.921113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.921113 12164 net.cpp:137] Memory required for data: 524711600
I1203 16:39:44.921113 12164 layer_factory.cpp:58] Creating layer group1_block3_sum
I1203 16:39:44.921113 12164 net.cpp:84] Creating Layer group1_block3_sum
I1203 16:39:44.921113 12164 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1203 16:39:44.921113 12164 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1203 16:39:44.921113 12164 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1203 16:39:44.921113 12164 net.cpp:122] Setting up group1_block3_sum
I1203 16:39:44.921113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.921113 12164 net.cpp:137] Memory required for data: 527988400
I1203 16:39:44.921113 12164 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1203 16:39:44.921113 12164 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1203 16:39:44.921113 12164 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1203 16:39:44.921113 12164 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1203 16:39:44.921113 12164 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1203 16:39:44.921113 12164 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1203 16:39:44.921113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.921113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.921113 12164 net.cpp:137] Memory required for data: 534542000
I1203 16:39:44.921113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1203 16:39:44.921113 12164 net.cpp:84] Creating Layer group1_block4_conv0
I1203 16:39:44.921113 12164 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1203 16:39:44.921113 12164 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1203 16:39:44.922113 12164 net.cpp:122] Setting up group1_block4_conv0
I1203 16:39:44.922113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.922113 12164 net.cpp:137] Memory required for data: 537818800
I1203 16:39:44.922113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1203 16:39:44.922113 12164 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1203 16:39:44.922113 12164 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1203 16:39:44.922113 12164 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1203 16:39:44.922113 12164 net.cpp:122] Setting up group1_block4_conv0_bn
I1203 16:39:44.922113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.922113 12164 net.cpp:137] Memory required for data: 541095600
I1203 16:39:44.922113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 16:39:44.922113 12164 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1203 16:39:44.922113 12164 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1203 16:39:44.922113 12164 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1203 16:39:44.922113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 16:39:44.922113 12164 net.cpp:122] Setting up group1_block4_conv0_scale
I1203 16:39:44.923113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.923113 12164 net.cpp:137] Memory required for data: 544372400
I1203 16:39:44.923113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1203 16:39:44.923113 12164 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1203 16:39:44.923113 12164 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1203 16:39:44.923113 12164 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1203 16:39:44.923113 12164 net.cpp:122] Setting up group1_block4_conv0_relu
I1203 16:39:44.923113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.923113 12164 net.cpp:137] Memory required for data: 547649200
I1203 16:39:44.923113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1203 16:39:44.923113 12164 net.cpp:84] Creating Layer group1_block4_conv1
I1203 16:39:44.923113 12164 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1203 16:39:44.923113 12164 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1203 16:39:44.924113 12164 net.cpp:122] Setting up group1_block4_conv1
I1203 16:39:44.924113 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.924113 12164 net.cpp:137] Memory required for data: 550926000
I1203 16:39:44.924113 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1203 16:39:44.924113 12164 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1203 16:39:44.924113 12164 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1203 16:39:44.924113 12164 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1203 16:39:44.925117 12164 net.cpp:122] Setting up group1_block4_conv1_bn
I1203 16:39:44.925117 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.925117 12164 net.cpp:137] Memory required for data: 554202800
I1203 16:39:44.925117 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 16:39:44.925117 12164 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1203 16:39:44.925117 12164 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1203 16:39:44.925117 12164 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1203 16:39:44.925117 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 16:39:44.925117 12164 net.cpp:122] Setting up group1_block4_conv1_scale
I1203 16:39:44.925117 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.925117 12164 net.cpp:137] Memory required for data: 557479600
I1203 16:39:44.925117 12164 layer_factory.cpp:58] Creating layer group1_block4_sum
I1203 16:39:44.925117 12164 net.cpp:84] Creating Layer group1_block4_sum
I1203 16:39:44.925117 12164 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1203 16:39:44.925117 12164 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1203 16:39:44.925117 12164 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1203 16:39:44.925117 12164 net.cpp:122] Setting up group1_block4_sum
I1203 16:39:44.925117 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.925117 12164 net.cpp:137] Memory required for data: 560756400
I1203 16:39:44.925117 12164 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1203 16:39:44.925117 12164 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1203 16:39:44.925117 12164 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1203 16:39:44.925117 12164 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1203 16:39:44.925117 12164 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1203 16:39:44.925117 12164 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1203 16:39:44.926116 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.926116 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:44.926116 12164 net.cpp:137] Memory required for data: 567310000
I1203 16:39:44.926116 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1203 16:39:44.926116 12164 net.cpp:84] Creating Layer group2_block0_conv0
I1203 16:39:44.926116 12164 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1203 16:39:44.926116 12164 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1203 16:39:44.929113 12164 net.cpp:122] Setting up group2_block0_conv0
I1203 16:39:44.929113 12164 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1203 16:39:44.929113 12164 net.cpp:137] Memory required for data: 573863600
I1203 16:39:44.929113 12164 layer_factory.cpp:58] Creating layer pool3
I1203 16:39:44.929113 12164 net.cpp:84] Creating Layer pool3
I1203 16:39:44.929113 12164 net.cpp:406] pool3 <- group2_block0_conv0
I1203 16:39:44.929113 12164 net.cpp:380] pool3 -> pool3
I1203 16:39:44.929113 12164 net.cpp:122] Setting up pool3
I1203 16:39:44.929113 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.929113 12164 net.cpp:137] Memory required for data: 575502000
I1203 16:39:44.929113 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1203 16:39:44.929113 12164 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1203 16:39:44.929113 12164 net.cpp:406] group2_block0_conv0_bn <- pool3
I1203 16:39:44.929113 12164 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1203 16:39:44.929113 12164 net.cpp:122] Setting up group2_block0_conv0_bn
I1203 16:39:44.929113 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.929113 12164 net.cpp:137] Memory required for data: 577140400
I1203 16:39:44.929113 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 16:39:44.929113 12164 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1203 16:39:44.929113 12164 net.cpp:406] group2_block0_conv0_scale <- pool3
I1203 16:39:44.929113 12164 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1203 16:39:44.929113 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 16:39:44.929113 12164 net.cpp:122] Setting up group2_block0_conv0_scale
I1203 16:39:44.929113 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.929113 12164 net.cpp:137] Memory required for data: 578778800
I1203 16:39:44.929113 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1203 16:39:44.929113 12164 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1203 16:39:44.929113 12164 net.cpp:406] group2_block0_conv0_relu <- pool3
I1203 16:39:44.929113 12164 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1203 16:39:44.930117 12164 net.cpp:122] Setting up group2_block0_conv0_relu
I1203 16:39:44.930117 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.930117 12164 net.cpp:137] Memory required for data: 580417200
I1203 16:39:44.930117 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1203 16:39:44.930117 12164 net.cpp:84] Creating Layer group2_block0_conv1
I1203 16:39:44.930117 12164 net.cpp:406] group2_block0_conv1 <- pool3
I1203 16:39:44.930117 12164 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1203 16:39:44.932114 12164 net.cpp:122] Setting up group2_block0_conv1
I1203 16:39:44.932114 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.932114 12164 net.cpp:137] Memory required for data: 582055600
I1203 16:39:44.932114 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1203 16:39:44.932114 12164 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1203 16:39:44.932114 12164 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1203 16:39:44.932114 12164 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1203 16:39:44.932114 12164 net.cpp:122] Setting up group2_block0_conv1_bn
I1203 16:39:44.932114 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.933116 12164 net.cpp:137] Memory required for data: 583694000
I1203 16:39:44.933116 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 16:39:44.933116 12164 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1203 16:39:44.933116 12164 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1203 16:39:44.933116 12164 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1203 16:39:44.933116 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 16:39:44.933116 12164 net.cpp:122] Setting up group2_block0_conv1_scale
I1203 16:39:44.933116 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.933116 12164 net.cpp:137] Memory required for data: 585332400
I1203 16:39:44.933116 12164 layer_factory.cpp:58] Creating layer group2_block0_proj
I1203 16:39:44.933116 12164 net.cpp:84] Creating Layer group2_block0_proj
I1203 16:39:44.933116 12164 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1203 16:39:44.933116 12164 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1203 16:39:44.935117 12164 net.cpp:122] Setting up group2_block0_proj
I1203 16:39:44.935117 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.935117 12164 net.cpp:137] Memory required for data: 586970800
I1203 16:39:44.935117 12164 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1203 16:39:44.935117 12164 net.cpp:84] Creating Layer group2_block0_proj_bn
I1203 16:39:44.935117 12164 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1203 16:39:44.935117 12164 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1203 16:39:44.935117 12164 net.cpp:122] Setting up group2_block0_proj_bn
I1203 16:39:44.935117 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.935117 12164 net.cpp:137] Memory required for data: 588609200
I1203 16:39:44.935117 12164 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 16:39:44.935117 12164 net.cpp:84] Creating Layer group2_block0_proj_scale
I1203 16:39:44.935117 12164 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1203 16:39:44.935117 12164 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1203 16:39:44.935117 12164 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 16:39:44.935117 12164 net.cpp:122] Setting up group2_block0_proj_scale
I1203 16:39:44.935117 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.935117 12164 net.cpp:137] Memory required for data: 590247600
I1203 16:39:44.935117 12164 layer_factory.cpp:58] Creating layer group2_block0_sum
I1203 16:39:44.935117 12164 net.cpp:84] Creating Layer group2_block0_sum
I1203 16:39:44.935117 12164 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1203 16:39:44.935117 12164 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1203 16:39:44.935117 12164 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1203 16:39:44.935117 12164 net.cpp:122] Setting up group2_block0_sum
I1203 16:39:44.935117 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.935117 12164 net.cpp:137] Memory required for data: 591886000
I1203 16:39:44.935117 12164 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1203 16:39:44.935117 12164 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1203 16:39:44.935117 12164 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1203 16:39:44.936113 12164 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1203 16:39:44.936113 12164 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1203 16:39:44.936113 12164 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1203 16:39:44.936113 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.936113 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.936113 12164 net.cpp:137] Memory required for data: 595162800
I1203 16:39:44.936113 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1203 16:39:44.936113 12164 net.cpp:84] Creating Layer group2_block1_conv0
I1203 16:39:44.936113 12164 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1203 16:39:44.936113 12164 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1203 16:39:44.941118 12164 net.cpp:122] Setting up group2_block1_conv0
I1203 16:39:44.941118 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.941118 12164 net.cpp:137] Memory required for data: 596801200
I1203 16:39:44.941118 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1203 16:39:44.941118 12164 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1203 16:39:44.941118 12164 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1203 16:39:44.941118 12164 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1203 16:39:44.941118 12164 net.cpp:122] Setting up group2_block1_conv0_bn
I1203 16:39:44.941118 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.941118 12164 net.cpp:137] Memory required for data: 598439600
I1203 16:39:44.941118 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 16:39:44.941118 12164 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1203 16:39:44.941118 12164 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1203 16:39:44.941118 12164 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1203 16:39:44.941118 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 16:39:44.942121 12164 net.cpp:122] Setting up group2_block1_conv0_scale
I1203 16:39:44.942121 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.942121 12164 net.cpp:137] Memory required for data: 600078000
I1203 16:39:44.942121 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1203 16:39:44.942121 12164 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1203 16:39:44.942121 12164 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1203 16:39:44.942121 12164 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1203 16:39:44.943116 12164 net.cpp:122] Setting up group2_block1_conv0_relu
I1203 16:39:44.943116 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.943116 12164 net.cpp:137] Memory required for data: 601716400
I1203 16:39:44.943116 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1203 16:39:44.943116 12164 net.cpp:84] Creating Layer group2_block1_conv1
I1203 16:39:44.943116 12164 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1203 16:39:44.943116 12164 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1203 16:39:44.946120 12164 net.cpp:122] Setting up group2_block1_conv1
I1203 16:39:44.946120 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.946120 12164 net.cpp:137] Memory required for data: 603354800
I1203 16:39:44.946120 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1203 16:39:44.946120 12164 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1203 16:39:44.946120 12164 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1203 16:39:44.946120 12164 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1203 16:39:44.946120 12164 net.cpp:122] Setting up group2_block1_conv1_bn
I1203 16:39:44.946120 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.946120 12164 net.cpp:137] Memory required for data: 604993200
I1203 16:39:44.946120 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 16:39:44.946120 12164 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1203 16:39:44.946120 12164 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1203 16:39:44.946120 12164 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1203 16:39:44.946120 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 16:39:44.946120 12164 net.cpp:122] Setting up group2_block1_conv1_scale
I1203 16:39:44.946120 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.946120 12164 net.cpp:137] Memory required for data: 606631600
I1203 16:39:44.947114 12164 layer_factory.cpp:58] Creating layer group2_block1_sum
I1203 16:39:44.947114 12164 net.cpp:84] Creating Layer group2_block1_sum
I1203 16:39:44.947114 12164 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1203 16:39:44.947114 12164 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1203 16:39:44.947114 12164 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1203 16:39:44.947114 12164 net.cpp:122] Setting up group2_block1_sum
I1203 16:39:44.947114 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.947114 12164 net.cpp:137] Memory required for data: 608270000
I1203 16:39:44.947114 12164 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1203 16:39:44.947114 12164 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1203 16:39:44.947114 12164 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1203 16:39:44.947114 12164 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1203 16:39:44.947114 12164 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1203 16:39:44.947114 12164 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1203 16:39:44.947114 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.947114 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.947114 12164 net.cpp:137] Memory required for data: 611546800
I1203 16:39:44.947114 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1203 16:39:44.947114 12164 net.cpp:84] Creating Layer group2_block2_conv0
I1203 16:39:44.947114 12164 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1203 16:39:44.947114 12164 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1203 16:39:44.949112 12164 net.cpp:122] Setting up group2_block2_conv0
I1203 16:39:44.949112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.949112 12164 net.cpp:137] Memory required for data: 613185200
I1203 16:39:44.949112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1203 16:39:44.949112 12164 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1203 16:39:44.949112 12164 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1203 16:39:44.949112 12164 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1203 16:39:44.949112 12164 net.cpp:122] Setting up group2_block2_conv0_bn
I1203 16:39:44.949112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.949112 12164 net.cpp:137] Memory required for data: 614823600
I1203 16:39:44.949112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 16:39:44.949112 12164 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1203 16:39:44.949112 12164 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1203 16:39:44.949112 12164 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1203 16:39:44.949112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 16:39:44.949112 12164 net.cpp:122] Setting up group2_block2_conv0_scale
I1203 16:39:44.949112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.949112 12164 net.cpp:137] Memory required for data: 616462000
I1203 16:39:44.949112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1203 16:39:44.949112 12164 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1203 16:39:44.949112 12164 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1203 16:39:44.949112 12164 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1203 16:39:44.950131 12164 net.cpp:122] Setting up group2_block2_conv0_relu
I1203 16:39:44.950131 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.950131 12164 net.cpp:137] Memory required for data: 618100400
I1203 16:39:44.950131 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1203 16:39:44.950131 12164 net.cpp:84] Creating Layer group2_block2_conv1
I1203 16:39:44.950131 12164 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1203 16:39:44.950131 12164 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1203 16:39:44.952112 12164 net.cpp:122] Setting up group2_block2_conv1
I1203 16:39:44.952112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.952112 12164 net.cpp:137] Memory required for data: 619738800
I1203 16:39:44.952112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1203 16:39:44.952112 12164 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1203 16:39:44.952112 12164 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1203 16:39:44.952112 12164 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1203 16:39:44.952112 12164 net.cpp:122] Setting up group2_block2_conv1_bn
I1203 16:39:44.952112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.952112 12164 net.cpp:137] Memory required for data: 621377200
I1203 16:39:44.952112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 16:39:44.952112 12164 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1203 16:39:44.952112 12164 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1203 16:39:44.952112 12164 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1203 16:39:44.952112 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 16:39:44.952112 12164 net.cpp:122] Setting up group2_block2_conv1_scale
I1203 16:39:44.952112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.952112 12164 net.cpp:137] Memory required for data: 623015600
I1203 16:39:44.952112 12164 layer_factory.cpp:58] Creating layer group2_block2_sum
I1203 16:39:44.952112 12164 net.cpp:84] Creating Layer group2_block2_sum
I1203 16:39:44.952112 12164 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1203 16:39:44.952112 12164 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1203 16:39:44.953128 12164 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1203 16:39:44.953128 12164 net.cpp:122] Setting up group2_block2_sum
I1203 16:39:44.953128 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.953128 12164 net.cpp:137] Memory required for data: 624654000
I1203 16:39:44.953128 12164 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1203 16:39:44.953128 12164 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1203 16:39:44.953128 12164 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1203 16:39:44.953128 12164 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1203 16:39:44.953128 12164 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1203 16:39:44.953128 12164 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1203 16:39:44.953128 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.953128 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.953128 12164 net.cpp:137] Memory required for data: 627930800
I1203 16:39:44.953128 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1203 16:39:44.953128 12164 net.cpp:84] Creating Layer group2_block3_conv0
I1203 16:39:44.953128 12164 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1203 16:39:44.953128 12164 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1203 16:39:44.954114 12164 net.cpp:122] Setting up group2_block3_conv0
I1203 16:39:44.954114 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.954114 12164 net.cpp:137] Memory required for data: 629569200
I1203 16:39:44.955128 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1203 16:39:44.955128 12164 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1203 16:39:44.955128 12164 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1203 16:39:44.955128 12164 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1203 16:39:44.955128 12164 net.cpp:122] Setting up group2_block3_conv0_bn
I1203 16:39:44.955128 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.955128 12164 net.cpp:137] Memory required for data: 631207600
I1203 16:39:44.955128 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 16:39:44.955128 12164 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1203 16:39:44.955128 12164 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1203 16:39:44.955128 12164 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1203 16:39:44.955128 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 16:39:44.955128 12164 net.cpp:122] Setting up group2_block3_conv0_scale
I1203 16:39:44.955128 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.955128 12164 net.cpp:137] Memory required for data: 632846000
I1203 16:39:44.955128 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1203 16:39:44.955128 12164 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1203 16:39:44.955128 12164 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1203 16:39:44.955128 12164 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1203 16:39:44.956115 12164 net.cpp:122] Setting up group2_block3_conv0_relu
I1203 16:39:44.956115 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.956115 12164 net.cpp:137] Memory required for data: 634484400
I1203 16:39:44.956115 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1203 16:39:44.956115 12164 net.cpp:84] Creating Layer group2_block3_conv1
I1203 16:39:44.956115 12164 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1203 16:39:44.956115 12164 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1203 16:39:44.957113 12164 net.cpp:122] Setting up group2_block3_conv1
I1203 16:39:44.957113 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.957113 12164 net.cpp:137] Memory required for data: 636122800
I1203 16:39:44.957113 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1203 16:39:44.957113 12164 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1203 16:39:44.957113 12164 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1203 16:39:44.957113 12164 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1203 16:39:44.958127 12164 net.cpp:122] Setting up group2_block3_conv1_bn
I1203 16:39:44.958127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.958127 12164 net.cpp:137] Memory required for data: 637761200
I1203 16:39:44.958127 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 16:39:44.958127 12164 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1203 16:39:44.958127 12164 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1203 16:39:44.958127 12164 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1203 16:39:44.958127 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 16:39:44.958127 12164 net.cpp:122] Setting up group2_block3_conv1_scale
I1203 16:39:44.958127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.958127 12164 net.cpp:137] Memory required for data: 639399600
I1203 16:39:44.958127 12164 layer_factory.cpp:58] Creating layer group2_block3_sum
I1203 16:39:44.958127 12164 net.cpp:84] Creating Layer group2_block3_sum
I1203 16:39:44.958127 12164 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1203 16:39:44.958127 12164 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1203 16:39:44.958127 12164 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1203 16:39:44.958127 12164 net.cpp:122] Setting up group2_block3_sum
I1203 16:39:44.958127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.958127 12164 net.cpp:137] Memory required for data: 641038000
I1203 16:39:44.958127 12164 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1203 16:39:44.958127 12164 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1203 16:39:44.958127 12164 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1203 16:39:44.958127 12164 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1203 16:39:44.958127 12164 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1203 16:39:44.958127 12164 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1203 16:39:44.958127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.958127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.958127 12164 net.cpp:137] Memory required for data: 644314800
I1203 16:39:44.958127 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1203 16:39:44.958127 12164 net.cpp:84] Creating Layer group2_block4_conv0
I1203 16:39:44.958127 12164 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1203 16:39:44.958127 12164 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1203 16:39:44.960111 12164 net.cpp:122] Setting up group2_block4_conv0
I1203 16:39:44.960111 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.960111 12164 net.cpp:137] Memory required for data: 645953200
I1203 16:39:44.960111 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1203 16:39:44.960111 12164 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1203 16:39:44.960111 12164 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1203 16:39:44.960111 12164 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1203 16:39:44.960111 12164 net.cpp:122] Setting up group2_block4_conv0_bn
I1203 16:39:44.960111 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.960111 12164 net.cpp:137] Memory required for data: 647591600
I1203 16:39:44.960111 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 16:39:44.960111 12164 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1203 16:39:44.960111 12164 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1203 16:39:44.960111 12164 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1203 16:39:44.960111 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 16:39:44.961127 12164 net.cpp:122] Setting up group2_block4_conv0_scale
I1203 16:39:44.961127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.961127 12164 net.cpp:137] Memory required for data: 649230000
I1203 16:39:44.961127 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1203 16:39:44.961127 12164 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1203 16:39:44.961127 12164 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1203 16:39:44.961127 12164 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1203 16:39:44.961127 12164 net.cpp:122] Setting up group2_block4_conv0_relu
I1203 16:39:44.961127 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.961127 12164 net.cpp:137] Memory required for data: 650868400
I1203 16:39:44.961127 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1203 16:39:44.961127 12164 net.cpp:84] Creating Layer group2_block4_conv1
I1203 16:39:44.961127 12164 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1203 16:39:44.961127 12164 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1203 16:39:44.963116 12164 net.cpp:122] Setting up group2_block4_conv1
I1203 16:39:44.963116 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.963116 12164 net.cpp:137] Memory required for data: 652506800
I1203 16:39:44.963116 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1203 16:39:44.963116 12164 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1203 16:39:44.963116 12164 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1203 16:39:44.963116 12164 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1203 16:39:44.963116 12164 net.cpp:122] Setting up group2_block4_conv1_bn
I1203 16:39:44.963116 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.963116 12164 net.cpp:137] Memory required for data: 654145200
I1203 16:39:44.963116 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 16:39:44.963116 12164 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1203 16:39:44.963116 12164 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1203 16:39:44.963116 12164 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1203 16:39:44.963116 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 16:39:44.964112 12164 net.cpp:122] Setting up group2_block4_conv1_scale
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.964112 12164 net.cpp:137] Memory required for data: 655783600
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer group2_block4_sum
I1203 16:39:44.964112 12164 net.cpp:84] Creating Layer group2_block4_sum
I1203 16:39:44.964112 12164 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1203 16:39:44.964112 12164 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1203 16:39:44.964112 12164 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1203 16:39:44.964112 12164 net.cpp:122] Setting up group2_block4_sum
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:44.964112 12164 net.cpp:137] Memory required for data: 657422000
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer global_avg_pool
I1203 16:39:44.964112 12164 net.cpp:84] Creating Layer global_avg_pool
I1203 16:39:44.964112 12164 net.cpp:406] global_avg_pool <- group2_block4_sum
I1203 16:39:44.964112 12164 net.cpp:380] global_avg_pool -> global_avg_pool
I1203 16:39:44.964112 12164 net.cpp:122] Setting up global_avg_pool
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1203 16:39:44.964112 12164 net.cpp:137] Memory required for data: 657447600
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer fc
I1203 16:39:44.964112 12164 net.cpp:84] Creating Layer fc
I1203 16:39:44.964112 12164 net.cpp:406] fc <- global_avg_pool
I1203 16:39:44.964112 12164 net.cpp:380] fc -> fc
I1203 16:39:44.964112 12164 net.cpp:122] Setting up fc
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: 100 10 (1000)
I1203 16:39:44.964112 12164 net.cpp:137] Memory required for data: 657451600
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1203 16:39:44.964112 12164 net.cpp:84] Creating Layer fc_fc_0_split
I1203 16:39:44.964112 12164 net.cpp:406] fc_fc_0_split <- fc
I1203 16:39:44.964112 12164 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1203 16:39:44.964112 12164 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1203 16:39:44.964112 12164 net.cpp:122] Setting up fc_fc_0_split
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: 100 10 (1000)
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: 100 10 (1000)
I1203 16:39:44.964112 12164 net.cpp:137] Memory required for data: 657459600
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer accuracy_training
I1203 16:39:44.964112 12164 net.cpp:84] Creating Layer accuracy_training
I1203 16:39:44.964112 12164 net.cpp:406] accuracy_training <- fc_fc_0_split_0
I1203 16:39:44.964112 12164 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1203 16:39:44.964112 12164 net.cpp:380] accuracy_training -> accuracy_training
I1203 16:39:44.964112 12164 net.cpp:122] Setting up accuracy_training
I1203 16:39:44.964112 12164 net.cpp:129] Top shape: (1)
I1203 16:39:44.964112 12164 net.cpp:137] Memory required for data: 657459604
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer loss
I1203 16:39:44.964112 12164 net.cpp:84] Creating Layer loss
I1203 16:39:44.964112 12164 net.cpp:406] loss <- fc_fc_0_split_1
I1203 16:39:44.964112 12164 net.cpp:406] loss <- label_cifar_1_split_1
I1203 16:39:44.964112 12164 net.cpp:380] loss -> loss
I1203 16:39:44.964112 12164 layer_factory.cpp:58] Creating layer loss
I1203 16:39:44.965112 12164 net.cpp:122] Setting up loss
I1203 16:39:44.965112 12164 net.cpp:129] Top shape: (1)
I1203 16:39:44.965112 12164 net.cpp:132]     with loss weight 1
I1203 16:39:44.965112 12164 net.cpp:137] Memory required for data: 657459608
I1203 16:39:44.965112 12164 net.cpp:198] loss needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:200] accuracy_training does not need backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] fc_fc_0_split needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] fc needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] global_avg_pool needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_sum needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv1 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block4_conv0 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_sum needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv1 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block3_conv0 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_sum needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv1 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block2_conv0 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_sum needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv1 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block1_conv0 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_sum needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_proj needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv1 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] pool3 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group2_block0_conv0 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_sum needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv1 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block4_conv0 needs backward computation.
I1203 16:39:44.965112 12164 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block3_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block2_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block1_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] pool2 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_proj needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] pool1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group1_block0_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block4_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block3_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block2_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block1_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_sum needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv1 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] group0_block0_conv0 needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] first_conv_relu needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] first_conv_scale needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] first_conv_bn needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:198] first_conv needs backward computation.
I1203 16:39:44.966112 12164 net.cpp:200] label_cifar_1_split does not need backward computation.
I1203 16:39:44.966112 12164 net.cpp:200] cifar does not need backward computation.
I1203 16:39:44.966112 12164 net.cpp:242] This network produces output accuracy_training
I1203 16:39:44.966112 12164 net.cpp:242] This network produces output loss
I1203 16:39:44.966112 12164 net.cpp:255] Network initialization done.
I1203 16:39:44.968112 12164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 16:39:44.968112 12164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1203 16:39:44.968112 12164 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1203 16:39:44.968112 12164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1203 16:39:44.968112 12164 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1203 16:39:44.968112 12164 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_resnet_32_with 3pooling"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "first_conv"
  type: "Convolution"
  bottom: "data"
  top: "first_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "first_conv_bn"
  type: "BatchNorm"
  bottom: "first_conv"
  top: "first_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "first_conv_scale"
  type: "Scale"
  bottom: "first_conv"
  top: "first_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "first_conv_relu"
  type: "ReLU"
  bottom: "first_conv"
  top: "first_conv"
}
layer {
  name: "group0_block0_conv0"
  type: "Convolution"
  bottom: "first_conv"
  top: "group0_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv0_scale"
  type: "Scale"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_conv0_relu"
  type: "ReLU"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv0"
}
layer {
  name: "group0_block0_conv1"
  type: "Convolution"
  bottom: "group0_block0_conv0"
  top: "group0_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block0_conv1_scale"
  type: "Scale"
  bottom: "group0_block0_conv1"
  top: "group0_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block0_sum"
  type: "Eltwise"
  bottom: "group0_block0_conv1"
  bottom: "first_conv"
  top: "group0_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block1_conv0"
  type: "Convolution"
  bottom: "group0_block0_sum"
  top: "group0_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv0_scale"
  type: "Scale"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_conv0_relu"
  type: "ReLU"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv0"
}
layer {
  name: "group0_block1_conv1"
  type: "Convolution"
  bottom: "group0_block1_conv0"
  top: "group0_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block1_conv1_scale"
  type: "Scale"
  bottom: "group0_block1_conv1"
  top: "group0_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block1_sum"
  type: "Eltwise"
  bottom: "group0_block1_conv1"
  bottom: "group0_block0_sum"
  top: "group0_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block2_conv0"
  type: "Convolution"
  bottom: "group0_block1_sum"
  top: "group0_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv0_scale"
  type: "Scale"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_conv0_relu"
  type: "ReLU"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv0"
}
layer {
  name: "group0_block2_conv1"
  type: "Convolution"
  bottom: "group0_block2_conv0"
  top: "group0_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block2_conv1_scale"
  type: "Scale"
  bottom: "group0_block2_conv1"
  top: "group0_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block2_sum"
  type: "Eltwise"
  bottom: "group0_block2_conv1"
  bottom: "group0_block1_sum"
  top: "group0_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block3_conv0"
  type: "Convolution"
  bottom: "group0_block2_sum"
  top: "group0_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv0_scale"
  type: "Scale"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_conv0_relu"
  type: "ReLU"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv0"
}
layer {
  name: "group0_block3_conv1"
  type: "Convolution"
  bottom: "group0_block3_conv0"
  top: "group0_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block3_conv1_scale"
  type: "Scale"
  bottom: "group0_block3_conv1"
  top: "group0_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block3_sum"
  type: "Eltwise"
  bottom: "group0_block3_conv1"
  bottom: "group0_block2_sum"
  top: "group0_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group0_block4_conv0"
  type: "Convolution"
  bottom: "group0_block3_sum"
  top: "group0_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv0_scale"
  type: "Scale"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_conv0_relu"
  type: "ReLU"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv0"
}
layer {
  name: "group0_block4_conv1"
  type: "Convolution"
  bottom: "group0_block4_conv0"
  top: "group0_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group0_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group0_block4_conv1_scale"
  type: "Scale"
  bottom: "group0_block4_conv1"
  top: "group0_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group0_block4_sum"
  type: "Eltwise"
  bottom: "group0_block4_conv1"
  bottom: "group0_block3_sum"
  top: "group0_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block0_conv0"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "group1_block0_conv0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv0_scale"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "group1_block0_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_conv1_scale"
  type: "Scale"
  bottom: "group1_block0_conv1"
  top: "group1_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_proj"
  type: "Convolution"
  bottom: "group0_block4_sum"
  top: "group1_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "group1_block0_proj"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group1_block0_proj_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block0_proj_scale"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block0_sum"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "group1_block0_conv1"
  top: "group1_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block1_conv0"
  type: "Convolution"
  bottom: "group1_block0_sum"
  top: "group1_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv0_scale"
  type: "Scale"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_conv0_relu"
  type: "ReLU"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv0"
}
layer {
  name: "group1_block1_conv1"
  type: "Convolution"
  bottom: "group1_block1_conv0"
  top: "group1_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block1_conv1_scale"
  type: "Scale"
  bottom: "group1_block1_conv1"
  top: "group1_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block1_sum"
  type: "Eltwise"
  bottom: "group1_block1_conv1"
  bottom: "group1_block0_sum"
  top: "group1_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block2_conv0"
  type: "Convolution"
  bottom: "group1_block1_sum"
  top: "group1_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv0_scale"
  type: "Scale"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_conv0_relu"
  type: "ReLU"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv0"
}
layer {
  name: "group1_block2_conv1"
  type: "Convolution"
  bottom: "group1_block2_conv0"
  top: "group1_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block2_conv1_scale"
  type: "Scale"
  bottom: "group1_block2_conv1"
  top: "group1_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block2_sum"
  type: "Eltwise"
  bottom: "group1_block2_conv1"
  bottom: "group1_block1_sum"
  top: "group1_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block3_conv0"
  type: "Convolution"
  bottom: "group1_block2_sum"
  top: "group1_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv0_scale"
  type: "Scale"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_conv0_relu"
  type: "ReLU"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv0"
}
layer {
  name: "group1_block3_conv1"
  type: "Convolution"
  bottom: "group1_block3_conv0"
  top: "group1_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block3_conv1_scale"
  type: "Scale"
  bottom: "group1_block3_conv1"
  top: "group1_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block3_sum"
  type: "Eltwise"
  bottom: "group1_block3_conv1"
  bottom: "group1_block2_sum"
  top: "group1_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group1_block4_conv0"
  type: "Convolution"
  bottom: "group1_block3_sum"
  top: "group1_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv0_scale"
  type: "Scale"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_conv0_relu"
  type: "ReLU"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv0"
}
layer {
  name: "group1_block4_conv1"
  type: "Convolution"
  bottom: "group1_block4_conv0"
  top: "group1_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group1_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group1_block4_conv1_scale"
  type: "Scale"
  bottom: "group1_block4_conv1"
  top: "group1_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group1_block4_sum"
  type: "Eltwise"
  bottom: "group1_block4_conv1"
  bottom: "group1_block3_sum"
  top: "group1_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block0_conv0"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "group2_block0_conv0"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "group2_block0_conv0_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "pool3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv0_scale"
  type: "Scale"
  bottom: "pool3"
  top: "pool3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_conv0_relu"
  type: "ReLU"
  bottom: "pool3"
  top: "pool3"
}
layer {
  name: "group2_block0_conv1"
  type: "Convolution"
  bottom: "pool3"
  top: "group2_block0_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_conv1_scale"
  type: "Scale"
  bottom: "group2_block0_conv1"
  top: "group2_block0_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_proj"
  type: "Convolution"
  bottom: "group1_block4_sum"
  top: "group2_block0_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block0_proj_bn"
  type: "BatchNorm"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block0_proj_scale"
  type: "Scale"
  bottom: "group2_block0_proj"
  top: "group2_block0_proj"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block0_sum"
  type: "Eltwise"
  bottom: "group2_block0_proj"
  bottom: "group2_block0_conv1"
  top: "group2_block0_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block1_conv0"
  type: "Convolution"
  bottom: "group2_block0_sum"
  top: "group2_block1_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv0_scale"
  type: "Scale"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_conv0_relu"
  type: "ReLU"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv0"
}
layer {
  name: "group2_block1_conv1"
  type: "Convolution"
  bottom: "group2_block1_conv0"
  top: "group2_block1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block1_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block1_conv1_scale"
  type: "Scale"
  bottom: "group2_block1_conv1"
  top: "group2_block1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block1_sum"
  type: "Eltwise"
  bottom: "group2_block1_conv1"
  bottom: "group2_block0_sum"
  top: "group2_block1_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block2_conv0"
  type: "Convolution"
  bottom: "group2_block1_sum"
  top: "group2_block2_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv0_scale"
  type: "Scale"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_conv0_relu"
  type: "ReLU"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv0"
}
layer {
  name: "group2_block2_conv1"
  type: "Convolution"
  bottom: "group2_block2_conv0"
  top: "group2_block2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block2_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block2_conv1_scale"
  type: "Scale"
  bottom: "group2_block2_conv1"
  top: "group2_block2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block2_sum"
  type: "Eltwise"
  bottom: "group2_block2_conv1"
  bottom: "group2_block1_sum"
  top: "group2_block2_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block3_conv0"
  type: "Convolution"
  bottom: "group2_block2_sum"
  top: "group2_block3_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv0_scale"
  type: "Scale"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_conv0_relu"
  type: "ReLU"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv0"
}
layer {
  name: "group2_block3_conv1"
  type: "Convolution"
  bottom: "group2_block3_conv0"
  top: "group2_block3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block3_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block3_conv1_scale"
  type: "Scale"
  bottom: "group2_block3_conv1"
  top: "group2_block3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block3_sum"
  type: "Eltwise"
  bottom: "group2_block3_conv1"
  bottom: "group2_block2_sum"
  top: "group2_block3_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "group2_block4_conv0"
  type: "Convolution"
  bottom: "group2_block3_sum"
  top: "group2_block4_conv0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv0_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv0_scale"
  type: "Scale"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_conv0_relu"
  type: "ReLU"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv0"
}
layer {
  name: "group2_block4_conv1"
  type: "Convolution"
  bottom: "group2_block4_conv0"
  top: "group2_block4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "group2_block4_conv1_bn"
  type: "BatchNorm"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "group2_block4_conv1_scale"
  type: "Scale"
  bottom: "group2_block4_conv1"
  top: "group2_block4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "group2_block4_sum"
  type: "Eltwise"
  bottom: "group2_block4_conv1"
  bottom: "group2_block3_sum"
  top: "group2_block4_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "global_avg_pool"
  type: "Pooling"
  bottom: "group2_block4_sum"
  top: "global_avg_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "global_avg_pool"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "Soft
I1203 16:39:44.969112 12164 layer_factory.cpp:58] Creating layer cifar
I1203 16:39:44.974112 12164 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I1203 16:39:44.975112 12164 net.cpp:84] Creating Layer cifar
I1203 16:39:44.975112 12164 net.cpp:380] cifar -> data
I1203 16:39:44.975112 12164 net.cpp:380] cifar -> label
I1203 16:39:44.975112 12164 data_layer.cpp:45] output data size: 100,3,32,32
I1203 16:39:44.982112 12164 net.cpp:122] Setting up cifar
I1203 16:39:44.982112 12164 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1203 16:39:44.982112 12164 net.cpp:129] Top shape: 100 (100)
I1203 16:39:44.982112 12164 net.cpp:137] Memory required for data: 1229200
I1203 16:39:44.982112 12164 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1203 16:39:44.982112 12164 net.cpp:84] Creating Layer label_cifar_1_split
I1203 16:39:44.982112 12164 net.cpp:406] label_cifar_1_split <- label
I1203 16:39:44.982112 12164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1203 16:39:44.982112 12164 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1203 16:39:44.982112 12164 net.cpp:122] Setting up label_cifar_1_split
I1203 16:39:44.982112 12164 net.cpp:129] Top shape: 100 (100)
I1203 16:39:44.982112 12164 net.cpp:129] Top shape: 100 (100)
I1203 16:39:44.982112 12164 net.cpp:137] Memory required for data: 1230000
I1203 16:39:44.982112 12164 layer_factory.cpp:58] Creating layer first_conv
I1203 16:39:44.982112 12164 net.cpp:84] Creating Layer first_conv
I1203 16:39:44.982112 12164 net.cpp:406] first_conv <- data
I1203 16:39:44.982112 12164 net.cpp:380] first_conv -> first_conv
I1203 16:39:44.984113 15980 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1203 16:39:44.984635 12164 net.cpp:122] Setting up first_conv
I1203 16:39:44.984635 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.984635 12164 net.cpp:137] Memory required for data: 7783600
I1203 16:39:44.984635 12164 layer_factory.cpp:58] Creating layer first_conv_bn
I1203 16:39:44.984635 12164 net.cpp:84] Creating Layer first_conv_bn
I1203 16:39:44.984635 12164 net.cpp:406] first_conv_bn <- first_conv
I1203 16:39:44.984635 12164 net.cpp:367] first_conv_bn -> first_conv (in-place)
I1203 16:39:44.984635 12164 net.cpp:122] Setting up first_conv_bn
I1203 16:39:44.985134 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.985134 12164 net.cpp:137] Memory required for data: 14337200
I1203 16:39:44.985134 12164 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 16:39:44.985134 12164 net.cpp:84] Creating Layer first_conv_scale
I1203 16:39:44.985134 12164 net.cpp:406] first_conv_scale <- first_conv
I1203 16:39:44.985134 12164 net.cpp:367] first_conv_scale -> first_conv (in-place)
I1203 16:39:44.985134 12164 layer_factory.cpp:58] Creating layer first_conv_scale
I1203 16:39:44.985134 12164 net.cpp:122] Setting up first_conv_scale
I1203 16:39:44.985134 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.985134 12164 net.cpp:137] Memory required for data: 20890800
I1203 16:39:44.985134 12164 layer_factory.cpp:58] Creating layer first_conv_relu
I1203 16:39:44.985134 12164 net.cpp:84] Creating Layer first_conv_relu
I1203 16:39:44.985134 12164 net.cpp:406] first_conv_relu <- first_conv
I1203 16:39:44.985134 12164 net.cpp:367] first_conv_relu -> first_conv (in-place)
I1203 16:39:44.985635 12164 net.cpp:122] Setting up first_conv_relu
I1203 16:39:44.985635 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.985635 12164 net.cpp:137] Memory required for data: 27444400
I1203 16:39:44.985635 12164 layer_factory.cpp:58] Creating layer first_conv_first_conv_relu_0_split
I1203 16:39:44.985635 12164 net.cpp:84] Creating Layer first_conv_first_conv_relu_0_split
I1203 16:39:44.985635 12164 net.cpp:406] first_conv_first_conv_relu_0_split <- first_conv
I1203 16:39:44.985635 12164 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_0
I1203 16:39:44.985635 12164 net.cpp:380] first_conv_first_conv_relu_0_split -> first_conv_first_conv_relu_0_split_1
I1203 16:39:44.985635 12164 net.cpp:122] Setting up first_conv_first_conv_relu_0_split
I1203 16:39:44.985635 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.985635 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.985635 12164 net.cpp:137] Memory required for data: 40551600
I1203 16:39:44.985635 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0
I1203 16:39:44.985635 12164 net.cpp:84] Creating Layer group0_block0_conv0
I1203 16:39:44.985635 12164 net.cpp:406] group0_block0_conv0 <- first_conv_first_conv_relu_0_split_0
I1203 16:39:44.985635 12164 net.cpp:380] group0_block0_conv0 -> group0_block0_conv0
I1203 16:39:44.987134 12164 net.cpp:122] Setting up group0_block0_conv0
I1203 16:39:44.987134 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.987134 12164 net.cpp:137] Memory required for data: 47105200
I1203 16:39:44.987134 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_bn
I1203 16:39:44.987134 12164 net.cpp:84] Creating Layer group0_block0_conv0_bn
I1203 16:39:44.987134 12164 net.cpp:406] group0_block0_conv0_bn <- group0_block0_conv0
I1203 16:39:44.987134 12164 net.cpp:367] group0_block0_conv0_bn -> group0_block0_conv0 (in-place)
I1203 16:39:44.987635 12164 net.cpp:122] Setting up group0_block0_conv0_bn
I1203 16:39:44.987635 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.987635 12164 net.cpp:137] Memory required for data: 53658800
I1203 16:39:44.987635 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 16:39:44.987635 12164 net.cpp:84] Creating Layer group0_block0_conv0_scale
I1203 16:39:44.987635 12164 net.cpp:406] group0_block0_conv0_scale <- group0_block0_conv0
I1203 16:39:44.987635 12164 net.cpp:367] group0_block0_conv0_scale -> group0_block0_conv0 (in-place)
I1203 16:39:44.987635 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_scale
I1203 16:39:44.987635 12164 net.cpp:122] Setting up group0_block0_conv0_scale
I1203 16:39:44.987635 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.987635 12164 net.cpp:137] Memory required for data: 60212400
I1203 16:39:44.987635 12164 layer_factory.cpp:58] Creating layer group0_block0_conv0_relu
I1203 16:39:44.987635 12164 net.cpp:84] Creating Layer group0_block0_conv0_relu
I1203 16:39:44.987635 12164 net.cpp:406] group0_block0_conv0_relu <- group0_block0_conv0
I1203 16:39:44.987635 12164 net.cpp:367] group0_block0_conv0_relu -> group0_block0_conv0 (in-place)
I1203 16:39:44.989120 12164 net.cpp:122] Setting up group0_block0_conv0_relu
I1203 16:39:44.989120 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.989120 12164 net.cpp:137] Memory required for data: 66766000
I1203 16:39:44.989120 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1
I1203 16:39:44.989120 12164 net.cpp:84] Creating Layer group0_block0_conv1
I1203 16:39:44.989120 12164 net.cpp:406] group0_block0_conv1 <- group0_block0_conv0
I1203 16:39:44.989120 12164 net.cpp:380] group0_block0_conv1 -> group0_block0_conv1
I1203 16:39:44.990619 12164 net.cpp:122] Setting up group0_block0_conv1
I1203 16:39:44.990619 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.990619 12164 net.cpp:137] Memory required for data: 73319600
I1203 16:39:44.990619 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1_bn
I1203 16:39:44.990619 12164 net.cpp:84] Creating Layer group0_block0_conv1_bn
I1203 16:39:44.990619 12164 net.cpp:406] group0_block0_conv1_bn <- group0_block0_conv1
I1203 16:39:44.990619 12164 net.cpp:367] group0_block0_conv1_bn -> group0_block0_conv1 (in-place)
I1203 16:39:44.991120 12164 net.cpp:122] Setting up group0_block0_conv1_bn
I1203 16:39:44.991120 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.991120 12164 net.cpp:137] Memory required for data: 79873200
I1203 16:39:44.991120 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 16:39:44.991120 12164 net.cpp:84] Creating Layer group0_block0_conv1_scale
I1203 16:39:44.991120 12164 net.cpp:406] group0_block0_conv1_scale <- group0_block0_conv1
I1203 16:39:44.991120 12164 net.cpp:367] group0_block0_conv1_scale -> group0_block0_conv1 (in-place)
I1203 16:39:44.991120 12164 layer_factory.cpp:58] Creating layer group0_block0_conv1_scale
I1203 16:39:44.991120 12164 net.cpp:122] Setting up group0_block0_conv1_scale
I1203 16:39:44.991120 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.991120 12164 net.cpp:137] Memory required for data: 86426800
I1203 16:39:44.991120 12164 layer_factory.cpp:58] Creating layer group0_block0_sum
I1203 16:39:44.991120 12164 net.cpp:84] Creating Layer group0_block0_sum
I1203 16:39:44.991120 12164 net.cpp:406] group0_block0_sum <- group0_block0_conv1
I1203 16:39:44.991120 12164 net.cpp:406] group0_block0_sum <- first_conv_first_conv_relu_0_split_1
I1203 16:39:44.991120 12164 net.cpp:380] group0_block0_sum -> group0_block0_sum
I1203 16:39:44.991619 12164 net.cpp:122] Setting up group0_block0_sum
I1203 16:39:44.991619 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.991619 12164 net.cpp:137] Memory required for data: 92980400
I1203 16:39:44.991619 12164 layer_factory.cpp:58] Creating layer group0_block0_sum_group0_block0_sum_0_split
I1203 16:39:44.991619 12164 net.cpp:84] Creating Layer group0_block0_sum_group0_block0_sum_0_split
I1203 16:39:44.991619 12164 net.cpp:406] group0_block0_sum_group0_block0_sum_0_split <- group0_block0_sum
I1203 16:39:44.991619 12164 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_0
I1203 16:39:44.991619 12164 net.cpp:380] group0_block0_sum_group0_block0_sum_0_split -> group0_block0_sum_group0_block0_sum_0_split_1
I1203 16:39:44.991619 12164 net.cpp:122] Setting up group0_block0_sum_group0_block0_sum_0_split
I1203 16:39:44.991619 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.991619 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.991619 12164 net.cpp:137] Memory required for data: 106087600
I1203 16:39:44.991619 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0
I1203 16:39:44.991619 12164 net.cpp:84] Creating Layer group0_block1_conv0
I1203 16:39:44.991619 12164 net.cpp:406] group0_block1_conv0 <- group0_block0_sum_group0_block0_sum_0_split_0
I1203 16:39:44.991619 12164 net.cpp:380] group0_block1_conv0 -> group0_block1_conv0
I1203 16:39:44.993122 12164 net.cpp:122] Setting up group0_block1_conv0
I1203 16:39:44.993122 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.993122 12164 net.cpp:137] Memory required for data: 112641200
I1203 16:39:44.993122 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_bn
I1203 16:39:44.993620 12164 net.cpp:84] Creating Layer group0_block1_conv0_bn
I1203 16:39:44.993620 12164 net.cpp:406] group0_block1_conv0_bn <- group0_block1_conv0
I1203 16:39:44.993620 12164 net.cpp:367] group0_block1_conv0_bn -> group0_block1_conv0 (in-place)
I1203 16:39:44.993620 12164 net.cpp:122] Setting up group0_block1_conv0_bn
I1203 16:39:44.993620 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.993620 12164 net.cpp:137] Memory required for data: 119194800
I1203 16:39:44.993620 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 16:39:44.993620 12164 net.cpp:84] Creating Layer group0_block1_conv0_scale
I1203 16:39:44.993620 12164 net.cpp:406] group0_block1_conv0_scale <- group0_block1_conv0
I1203 16:39:44.994119 12164 net.cpp:367] group0_block1_conv0_scale -> group0_block1_conv0 (in-place)
I1203 16:39:44.994119 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_scale
I1203 16:39:44.994119 12164 net.cpp:122] Setting up group0_block1_conv0_scale
I1203 16:39:44.994119 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.994619 12164 net.cpp:137] Memory required for data: 125748400
I1203 16:39:44.994619 12164 layer_factory.cpp:58] Creating layer group0_block1_conv0_relu
I1203 16:39:44.994619 12164 net.cpp:84] Creating Layer group0_block1_conv0_relu
I1203 16:39:44.994619 12164 net.cpp:406] group0_block1_conv0_relu <- group0_block1_conv0
I1203 16:39:44.994619 12164 net.cpp:367] group0_block1_conv0_relu -> group0_block1_conv0 (in-place)
I1203 16:39:44.995121 12164 net.cpp:122] Setting up group0_block1_conv0_relu
I1203 16:39:44.995121 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.995121 12164 net.cpp:137] Memory required for data: 132302000
I1203 16:39:44.995121 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1
I1203 16:39:44.995620 12164 net.cpp:84] Creating Layer group0_block1_conv1
I1203 16:39:44.995620 12164 net.cpp:406] group0_block1_conv1 <- group0_block1_conv0
I1203 16:39:44.995620 12164 net.cpp:380] group0_block1_conv1 -> group0_block1_conv1
I1203 16:39:44.997622 12164 net.cpp:122] Setting up group0_block1_conv1
I1203 16:39:44.997622 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.997622 12164 net.cpp:137] Memory required for data: 138855600
I1203 16:39:44.997622 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1_bn
I1203 16:39:44.997622 12164 net.cpp:84] Creating Layer group0_block1_conv1_bn
I1203 16:39:44.997622 12164 net.cpp:406] group0_block1_conv1_bn <- group0_block1_conv1
I1203 16:39:44.997622 12164 net.cpp:367] group0_block1_conv1_bn -> group0_block1_conv1 (in-place)
I1203 16:39:44.998121 12164 net.cpp:122] Setting up group0_block1_conv1_bn
I1203 16:39:44.998121 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.998121 12164 net.cpp:137] Memory required for data: 145409200
I1203 16:39:44.998121 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 16:39:44.998121 12164 net.cpp:84] Creating Layer group0_block1_conv1_scale
I1203 16:39:44.998121 12164 net.cpp:406] group0_block1_conv1_scale <- group0_block1_conv1
I1203 16:39:44.998121 12164 net.cpp:367] group0_block1_conv1_scale -> group0_block1_conv1 (in-place)
I1203 16:39:44.998620 12164 layer_factory.cpp:58] Creating layer group0_block1_conv1_scale
I1203 16:39:44.998620 12164 net.cpp:122] Setting up group0_block1_conv1_scale
I1203 16:39:44.998620 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.998620 12164 net.cpp:137] Memory required for data: 151962800
I1203 16:39:44.998620 12164 layer_factory.cpp:58] Creating layer group0_block1_sum
I1203 16:39:44.999121 12164 net.cpp:84] Creating Layer group0_block1_sum
I1203 16:39:44.999121 12164 net.cpp:406] group0_block1_sum <- group0_block1_conv1
I1203 16:39:44.999121 12164 net.cpp:406] group0_block1_sum <- group0_block0_sum_group0_block0_sum_0_split_1
I1203 16:39:44.999121 12164 net.cpp:380] group0_block1_sum -> group0_block1_sum
I1203 16:39:44.999121 12164 net.cpp:122] Setting up group0_block1_sum
I1203 16:39:44.999121 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.999121 12164 net.cpp:137] Memory required for data: 158516400
I1203 16:39:44.999121 12164 layer_factory.cpp:58] Creating layer group0_block1_sum_group0_block1_sum_0_split
I1203 16:39:44.999121 12164 net.cpp:84] Creating Layer group0_block1_sum_group0_block1_sum_0_split
I1203 16:39:44.999121 12164 net.cpp:406] group0_block1_sum_group0_block1_sum_0_split <- group0_block1_sum
I1203 16:39:44.999121 12164 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_0
I1203 16:39:44.999121 12164 net.cpp:380] group0_block1_sum_group0_block1_sum_0_split -> group0_block1_sum_group0_block1_sum_0_split_1
I1203 16:39:44.999121 12164 net.cpp:122] Setting up group0_block1_sum_group0_block1_sum_0_split
I1203 16:39:44.999121 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.999121 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:44.999121 12164 net.cpp:137] Memory required for data: 171623600
I1203 16:39:44.999121 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0
I1203 16:39:44.999121 12164 net.cpp:84] Creating Layer group0_block2_conv0
I1203 16:39:44.999121 12164 net.cpp:406] group0_block2_conv0 <- group0_block1_sum_group0_block1_sum_0_split_0
I1203 16:39:44.999121 12164 net.cpp:380] group0_block2_conv0 -> group0_block2_conv0
I1203 16:39:45.000684 12164 net.cpp:122] Setting up group0_block2_conv0
I1203 16:39:45.000684 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.000684 12164 net.cpp:137] Memory required for data: 178177200
I1203 16:39:45.000684 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_bn
I1203 16:39:45.000684 12164 net.cpp:84] Creating Layer group0_block2_conv0_bn
I1203 16:39:45.000684 12164 net.cpp:406] group0_block2_conv0_bn <- group0_block2_conv0
I1203 16:39:45.000684 12164 net.cpp:367] group0_block2_conv0_bn -> group0_block2_conv0 (in-place)
I1203 16:39:45.001687 12164 net.cpp:122] Setting up group0_block2_conv0_bn
I1203 16:39:45.001687 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.001687 12164 net.cpp:137] Memory required for data: 184730800
I1203 16:39:45.001687 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 16:39:45.001687 12164 net.cpp:84] Creating Layer group0_block2_conv0_scale
I1203 16:39:45.001687 12164 net.cpp:406] group0_block2_conv0_scale <- group0_block2_conv0
I1203 16:39:45.001687 12164 net.cpp:367] group0_block2_conv0_scale -> group0_block2_conv0 (in-place)
I1203 16:39:45.001687 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_scale
I1203 16:39:45.001687 12164 net.cpp:122] Setting up group0_block2_conv0_scale
I1203 16:39:45.001687 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.001687 12164 net.cpp:137] Memory required for data: 191284400
I1203 16:39:45.001687 12164 layer_factory.cpp:58] Creating layer group0_block2_conv0_relu
I1203 16:39:45.001687 12164 net.cpp:84] Creating Layer group0_block2_conv0_relu
I1203 16:39:45.001687 12164 net.cpp:406] group0_block2_conv0_relu <- group0_block2_conv0
I1203 16:39:45.001687 12164 net.cpp:367] group0_block2_conv0_relu -> group0_block2_conv0 (in-place)
I1203 16:39:45.002686 12164 net.cpp:122] Setting up group0_block2_conv0_relu
I1203 16:39:45.002686 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.003685 12164 net.cpp:137] Memory required for data: 197838000
I1203 16:39:45.003685 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1
I1203 16:39:45.003685 12164 net.cpp:84] Creating Layer group0_block2_conv1
I1203 16:39:45.003685 12164 net.cpp:406] group0_block2_conv1 <- group0_block2_conv0
I1203 16:39:45.003685 12164 net.cpp:380] group0_block2_conv1 -> group0_block2_conv1
I1203 16:39:45.004701 12164 net.cpp:122] Setting up group0_block2_conv1
I1203 16:39:45.004701 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.004701 12164 net.cpp:137] Memory required for data: 204391600
I1203 16:39:45.005700 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1_bn
I1203 16:39:45.005700 12164 net.cpp:84] Creating Layer group0_block2_conv1_bn
I1203 16:39:45.005700 12164 net.cpp:406] group0_block2_conv1_bn <- group0_block2_conv1
I1203 16:39:45.005700 12164 net.cpp:367] group0_block2_conv1_bn -> group0_block2_conv1 (in-place)
I1203 16:39:45.005700 12164 net.cpp:122] Setting up group0_block2_conv1_bn
I1203 16:39:45.005700 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.005700 12164 net.cpp:137] Memory required for data: 210945200
I1203 16:39:45.005700 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 16:39:45.005700 12164 net.cpp:84] Creating Layer group0_block2_conv1_scale
I1203 16:39:45.005700 12164 net.cpp:406] group0_block2_conv1_scale <- group0_block2_conv1
I1203 16:39:45.005700 12164 net.cpp:367] group0_block2_conv1_scale -> group0_block2_conv1 (in-place)
I1203 16:39:45.005700 12164 layer_factory.cpp:58] Creating layer group0_block2_conv1_scale
I1203 16:39:45.005700 12164 net.cpp:122] Setting up group0_block2_conv1_scale
I1203 16:39:45.005700 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.005700 12164 net.cpp:137] Memory required for data: 217498800
I1203 16:39:45.005700 12164 layer_factory.cpp:58] Creating layer group0_block2_sum
I1203 16:39:45.005700 12164 net.cpp:84] Creating Layer group0_block2_sum
I1203 16:39:45.005700 12164 net.cpp:406] group0_block2_sum <- group0_block2_conv1
I1203 16:39:45.005700 12164 net.cpp:406] group0_block2_sum <- group0_block1_sum_group0_block1_sum_0_split_1
I1203 16:39:45.005700 12164 net.cpp:380] group0_block2_sum -> group0_block2_sum
I1203 16:39:45.005700 12164 net.cpp:122] Setting up group0_block2_sum
I1203 16:39:45.005700 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.005700 12164 net.cpp:137] Memory required for data: 224052400
I1203 16:39:45.005700 12164 layer_factory.cpp:58] Creating layer group0_block2_sum_group0_block2_sum_0_split
I1203 16:39:45.005700 12164 net.cpp:84] Creating Layer group0_block2_sum_group0_block2_sum_0_split
I1203 16:39:45.005700 12164 net.cpp:406] group0_block2_sum_group0_block2_sum_0_split <- group0_block2_sum
I1203 16:39:45.005700 12164 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_0
I1203 16:39:45.005700 12164 net.cpp:380] group0_block2_sum_group0_block2_sum_0_split -> group0_block2_sum_group0_block2_sum_0_split_1
I1203 16:39:45.005700 12164 net.cpp:122] Setting up group0_block2_sum_group0_block2_sum_0_split
I1203 16:39:45.005700 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.005700 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.005700 12164 net.cpp:137] Memory required for data: 237159600
I1203 16:39:45.005700 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0
I1203 16:39:45.005700 12164 net.cpp:84] Creating Layer group0_block3_conv0
I1203 16:39:45.005700 12164 net.cpp:406] group0_block3_conv0 <- group0_block2_sum_group0_block2_sum_0_split_0
I1203 16:39:45.005700 12164 net.cpp:380] group0_block3_conv0 -> group0_block3_conv0
I1203 16:39:45.007701 12164 net.cpp:122] Setting up group0_block3_conv0
I1203 16:39:45.007701 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.007701 12164 net.cpp:137] Memory required for data: 243713200
I1203 16:39:45.007701 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_bn
I1203 16:39:45.007701 12164 net.cpp:84] Creating Layer group0_block3_conv0_bn
I1203 16:39:45.007701 12164 net.cpp:406] group0_block3_conv0_bn <- group0_block3_conv0
I1203 16:39:45.007701 12164 net.cpp:367] group0_block3_conv0_bn -> group0_block3_conv0 (in-place)
I1203 16:39:45.007701 12164 net.cpp:122] Setting up group0_block3_conv0_bn
I1203 16:39:45.007701 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.007701 12164 net.cpp:137] Memory required for data: 250266800
I1203 16:39:45.007701 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 16:39:45.007701 12164 net.cpp:84] Creating Layer group0_block3_conv0_scale
I1203 16:39:45.007701 12164 net.cpp:406] group0_block3_conv0_scale <- group0_block3_conv0
I1203 16:39:45.007701 12164 net.cpp:367] group0_block3_conv0_scale -> group0_block3_conv0 (in-place)
I1203 16:39:45.007701 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_scale
I1203 16:39:45.007701 12164 net.cpp:122] Setting up group0_block3_conv0_scale
I1203 16:39:45.007701 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.007701 12164 net.cpp:137] Memory required for data: 256820400
I1203 16:39:45.007701 12164 layer_factory.cpp:58] Creating layer group0_block3_conv0_relu
I1203 16:39:45.007701 12164 net.cpp:84] Creating Layer group0_block3_conv0_relu
I1203 16:39:45.007701 12164 net.cpp:406] group0_block3_conv0_relu <- group0_block3_conv0
I1203 16:39:45.007701 12164 net.cpp:367] group0_block3_conv0_relu -> group0_block3_conv0 (in-place)
I1203 16:39:45.008700 12164 net.cpp:122] Setting up group0_block3_conv0_relu
I1203 16:39:45.008700 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.008700 12164 net.cpp:137] Memory required for data: 263374000
I1203 16:39:45.008700 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1
I1203 16:39:45.008700 12164 net.cpp:84] Creating Layer group0_block3_conv1
I1203 16:39:45.008700 12164 net.cpp:406] group0_block3_conv1 <- group0_block3_conv0
I1203 16:39:45.008700 12164 net.cpp:380] group0_block3_conv1 -> group0_block3_conv1
I1203 16:39:45.009683 12164 net.cpp:122] Setting up group0_block3_conv1
I1203 16:39:45.010694 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.010694 12164 net.cpp:137] Memory required for data: 269927600
I1203 16:39:45.010694 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1_bn
I1203 16:39:45.010694 12164 net.cpp:84] Creating Layer group0_block3_conv1_bn
I1203 16:39:45.010694 12164 net.cpp:406] group0_block3_conv1_bn <- group0_block3_conv1
I1203 16:39:45.010694 12164 net.cpp:367] group0_block3_conv1_bn -> group0_block3_conv1 (in-place)
I1203 16:39:45.010694 12164 net.cpp:122] Setting up group0_block3_conv1_bn
I1203 16:39:45.010694 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.010694 12164 net.cpp:137] Memory required for data: 276481200
I1203 16:39:45.010694 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 16:39:45.010694 12164 net.cpp:84] Creating Layer group0_block3_conv1_scale
I1203 16:39:45.010694 12164 net.cpp:406] group0_block3_conv1_scale <- group0_block3_conv1
I1203 16:39:45.010694 12164 net.cpp:367] group0_block3_conv1_scale -> group0_block3_conv1 (in-place)
I1203 16:39:45.010694 12164 layer_factory.cpp:58] Creating layer group0_block3_conv1_scale
I1203 16:39:45.010694 12164 net.cpp:122] Setting up group0_block3_conv1_scale
I1203 16:39:45.010694 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.010694 12164 net.cpp:137] Memory required for data: 283034800
I1203 16:39:45.010694 12164 layer_factory.cpp:58] Creating layer group0_block3_sum
I1203 16:39:45.010694 12164 net.cpp:84] Creating Layer group0_block3_sum
I1203 16:39:45.010694 12164 net.cpp:406] group0_block3_sum <- group0_block3_conv1
I1203 16:39:45.010694 12164 net.cpp:406] group0_block3_sum <- group0_block2_sum_group0_block2_sum_0_split_1
I1203 16:39:45.010694 12164 net.cpp:380] group0_block3_sum -> group0_block3_sum
I1203 16:39:45.010694 12164 net.cpp:122] Setting up group0_block3_sum
I1203 16:39:45.010694 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.010694 12164 net.cpp:137] Memory required for data: 289588400
I1203 16:39:45.010694 12164 layer_factory.cpp:58] Creating layer group0_block3_sum_group0_block3_sum_0_split
I1203 16:39:45.010694 12164 net.cpp:84] Creating Layer group0_block3_sum_group0_block3_sum_0_split
I1203 16:39:45.010694 12164 net.cpp:406] group0_block3_sum_group0_block3_sum_0_split <- group0_block3_sum
I1203 16:39:45.010694 12164 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_0
I1203 16:39:45.010694 12164 net.cpp:380] group0_block3_sum_group0_block3_sum_0_split -> group0_block3_sum_group0_block3_sum_0_split_1
I1203 16:39:45.010694 12164 net.cpp:122] Setting up group0_block3_sum_group0_block3_sum_0_split
I1203 16:39:45.010694 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.010694 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.010694 12164 net.cpp:137] Memory required for data: 302695600
I1203 16:39:45.010694 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0
I1203 16:39:45.010694 12164 net.cpp:84] Creating Layer group0_block4_conv0
I1203 16:39:45.010694 12164 net.cpp:406] group0_block4_conv0 <- group0_block3_sum_group0_block3_sum_0_split_0
I1203 16:39:45.010694 12164 net.cpp:380] group0_block4_conv0 -> group0_block4_conv0
I1203 16:39:45.012684 12164 net.cpp:122] Setting up group0_block4_conv0
I1203 16:39:45.012684 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.012684 12164 net.cpp:137] Memory required for data: 309249200
I1203 16:39:45.012684 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_bn
I1203 16:39:45.012684 12164 net.cpp:84] Creating Layer group0_block4_conv0_bn
I1203 16:39:45.012684 12164 net.cpp:406] group0_block4_conv0_bn <- group0_block4_conv0
I1203 16:39:45.012684 12164 net.cpp:367] group0_block4_conv0_bn -> group0_block4_conv0 (in-place)
I1203 16:39:45.012684 12164 net.cpp:122] Setting up group0_block4_conv0_bn
I1203 16:39:45.012684 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.012684 12164 net.cpp:137] Memory required for data: 315802800
I1203 16:39:45.012684 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 16:39:45.012684 12164 net.cpp:84] Creating Layer group0_block4_conv0_scale
I1203 16:39:45.012684 12164 net.cpp:406] group0_block4_conv0_scale <- group0_block4_conv0
I1203 16:39:45.012684 12164 net.cpp:367] group0_block4_conv0_scale -> group0_block4_conv0 (in-place)
I1203 16:39:45.012684 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_scale
I1203 16:39:45.013681 12164 net.cpp:122] Setting up group0_block4_conv0_scale
I1203 16:39:45.013681 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.013681 12164 net.cpp:137] Memory required for data: 322356400
I1203 16:39:45.013681 12164 layer_factory.cpp:58] Creating layer group0_block4_conv0_relu
I1203 16:39:45.013681 12164 net.cpp:84] Creating Layer group0_block4_conv0_relu
I1203 16:39:45.013681 12164 net.cpp:406] group0_block4_conv0_relu <- group0_block4_conv0
I1203 16:39:45.013681 12164 net.cpp:367] group0_block4_conv0_relu -> group0_block4_conv0 (in-place)
I1203 16:39:45.013681 12164 net.cpp:122] Setting up group0_block4_conv0_relu
I1203 16:39:45.013681 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.013681 12164 net.cpp:137] Memory required for data: 328910000
I1203 16:39:45.013681 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1
I1203 16:39:45.013681 12164 net.cpp:84] Creating Layer group0_block4_conv1
I1203 16:39:45.013681 12164 net.cpp:406] group0_block4_conv1 <- group0_block4_conv0
I1203 16:39:45.013681 12164 net.cpp:380] group0_block4_conv1 -> group0_block4_conv1
I1203 16:39:45.014690 12164 net.cpp:122] Setting up group0_block4_conv1
I1203 16:39:45.014690 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.014690 12164 net.cpp:137] Memory required for data: 335463600
I1203 16:39:45.014690 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1_bn
I1203 16:39:45.014690 12164 net.cpp:84] Creating Layer group0_block4_conv1_bn
I1203 16:39:45.014690 12164 net.cpp:406] group0_block4_conv1_bn <- group0_block4_conv1
I1203 16:39:45.014690 12164 net.cpp:367] group0_block4_conv1_bn -> group0_block4_conv1 (in-place)
I1203 16:39:45.015683 12164 net.cpp:122] Setting up group0_block4_conv1_bn
I1203 16:39:45.015683 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.015683 12164 net.cpp:137] Memory required for data: 342017200
I1203 16:39:45.015683 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 16:39:45.015683 12164 net.cpp:84] Creating Layer group0_block4_conv1_scale
I1203 16:39:45.015683 12164 net.cpp:406] group0_block4_conv1_scale <- group0_block4_conv1
I1203 16:39:45.015683 12164 net.cpp:367] group0_block4_conv1_scale -> group0_block4_conv1 (in-place)
I1203 16:39:45.015683 12164 layer_factory.cpp:58] Creating layer group0_block4_conv1_scale
I1203 16:39:45.015683 12164 net.cpp:122] Setting up group0_block4_conv1_scale
I1203 16:39:45.015683 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.015683 12164 net.cpp:137] Memory required for data: 348570800
I1203 16:39:45.015683 12164 layer_factory.cpp:58] Creating layer group0_block4_sum
I1203 16:39:45.015683 12164 net.cpp:84] Creating Layer group0_block4_sum
I1203 16:39:45.015683 12164 net.cpp:406] group0_block4_sum <- group0_block4_conv1
I1203 16:39:45.015683 12164 net.cpp:406] group0_block4_sum <- group0_block3_sum_group0_block3_sum_0_split_1
I1203 16:39:45.015683 12164 net.cpp:380] group0_block4_sum -> group0_block4_sum
I1203 16:39:45.015683 12164 net.cpp:122] Setting up group0_block4_sum
I1203 16:39:45.015683 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.015683 12164 net.cpp:137] Memory required for data: 355124400
I1203 16:39:45.015683 12164 layer_factory.cpp:58] Creating layer group0_block4_sum_group0_block4_sum_0_split
I1203 16:39:45.015683 12164 net.cpp:84] Creating Layer group0_block4_sum_group0_block4_sum_0_split
I1203 16:39:45.015683 12164 net.cpp:406] group0_block4_sum_group0_block4_sum_0_split <- group0_block4_sum
I1203 16:39:45.015683 12164 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_0
I1203 16:39:45.015683 12164 net.cpp:380] group0_block4_sum_group0_block4_sum_0_split -> group0_block4_sum_group0_block4_sum_0_split_1
I1203 16:39:45.015683 12164 net.cpp:122] Setting up group0_block4_sum_group0_block4_sum_0_split
I1203 16:39:45.015683 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.015683 12164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1203 16:39:45.015683 12164 net.cpp:137] Memory required for data: 368231600
I1203 16:39:45.015683 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0
I1203 16:39:45.015683 12164 net.cpp:84] Creating Layer group1_block0_conv0
I1203 16:39:45.015683 12164 net.cpp:406] group1_block0_conv0 <- group0_block4_sum_group0_block4_sum_0_split_0
I1203 16:39:45.015683 12164 net.cpp:380] group1_block0_conv0 -> group1_block0_conv0
I1203 16:39:45.017693 12164 net.cpp:122] Setting up group1_block0_conv0
I1203 16:39:45.017693 12164 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1203 16:39:45.017693 12164 net.cpp:137] Memory required for data: 381338800
I1203 16:39:45.017693 12164 layer_factory.cpp:58] Creating layer pool1
I1203 16:39:45.017693 12164 net.cpp:84] Creating Layer pool1
I1203 16:39:45.017693 12164 net.cpp:406] pool1 <- group1_block0_conv0
I1203 16:39:45.017693 12164 net.cpp:380] pool1 -> pool1
I1203 16:39:45.017693 12164 net.cpp:122] Setting up pool1
I1203 16:39:45.017693 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.017693 12164 net.cpp:137] Memory required for data: 384615600
I1203 16:39:45.017693 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_bn
I1203 16:39:45.017693 12164 net.cpp:84] Creating Layer group1_block0_conv0_bn
I1203 16:39:45.017693 12164 net.cpp:406] group1_block0_conv0_bn <- pool1
I1203 16:39:45.017693 12164 net.cpp:367] group1_block0_conv0_bn -> pool1 (in-place)
I1203 16:39:45.017693 12164 net.cpp:122] Setting up group1_block0_conv0_bn
I1203 16:39:45.017693 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.017693 12164 net.cpp:137] Memory required for data: 387892400
I1203 16:39:45.017693 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 16:39:45.017693 12164 net.cpp:84] Creating Layer group1_block0_conv0_scale
I1203 16:39:45.017693 12164 net.cpp:406] group1_block0_conv0_scale <- pool1
I1203 16:39:45.017693 12164 net.cpp:367] group1_block0_conv0_scale -> pool1 (in-place)
I1203 16:39:45.017693 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_scale
I1203 16:39:45.017693 12164 net.cpp:122] Setting up group1_block0_conv0_scale
I1203 16:39:45.017693 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.017693 12164 net.cpp:137] Memory required for data: 391169200
I1203 16:39:45.017693 12164 layer_factory.cpp:58] Creating layer group1_block0_conv0_relu
I1203 16:39:45.017693 12164 net.cpp:84] Creating Layer group1_block0_conv0_relu
I1203 16:39:45.017693 12164 net.cpp:406] group1_block0_conv0_relu <- pool1
I1203 16:39:45.017693 12164 net.cpp:367] group1_block0_conv0_relu -> pool1 (in-place)
I1203 16:39:45.018692 12164 net.cpp:122] Setting up group1_block0_conv0_relu
I1203 16:39:45.018692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.018692 12164 net.cpp:137] Memory required for data: 394446000
I1203 16:39:45.018692 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1
I1203 16:39:45.018692 12164 net.cpp:84] Creating Layer group1_block0_conv1
I1203 16:39:45.018692 12164 net.cpp:406] group1_block0_conv1 <- pool1
I1203 16:39:45.018692 12164 net.cpp:380] group1_block0_conv1 -> group1_block0_conv1
I1203 16:39:45.019691 12164 net.cpp:122] Setting up group1_block0_conv1
I1203 16:39:45.019691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.019691 12164 net.cpp:137] Memory required for data: 397722800
I1203 16:39:45.019691 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1_bn
I1203 16:39:45.019691 12164 net.cpp:84] Creating Layer group1_block0_conv1_bn
I1203 16:39:45.019691 12164 net.cpp:406] group1_block0_conv1_bn <- group1_block0_conv1
I1203 16:39:45.019691 12164 net.cpp:367] group1_block0_conv1_bn -> group1_block0_conv1 (in-place)
I1203 16:39:45.019691 12164 net.cpp:122] Setting up group1_block0_conv1_bn
I1203 16:39:45.019691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.019691 12164 net.cpp:137] Memory required for data: 400999600
I1203 16:39:45.019691 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 16:39:45.019691 12164 net.cpp:84] Creating Layer group1_block0_conv1_scale
I1203 16:39:45.019691 12164 net.cpp:406] group1_block0_conv1_scale <- group1_block0_conv1
I1203 16:39:45.019691 12164 net.cpp:367] group1_block0_conv1_scale -> group1_block0_conv1 (in-place)
I1203 16:39:45.019691 12164 layer_factory.cpp:58] Creating layer group1_block0_conv1_scale
I1203 16:39:45.019691 12164 net.cpp:122] Setting up group1_block0_conv1_scale
I1203 16:39:45.019691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.019691 12164 net.cpp:137] Memory required for data: 404276400
I1203 16:39:45.019691 12164 layer_factory.cpp:58] Creating layer group1_block0_proj
I1203 16:39:45.019691 12164 net.cpp:84] Creating Layer group1_block0_proj
I1203 16:39:45.020692 12164 net.cpp:406] group1_block0_proj <- group0_block4_sum_group0_block4_sum_0_split_1
I1203 16:39:45.020692 12164 net.cpp:380] group1_block0_proj -> group1_block0_proj
I1203 16:39:45.021692 12164 net.cpp:122] Setting up group1_block0_proj
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 31 31 (3075200)
I1203 16:39:45.021692 12164 net.cpp:137] Memory required for data: 416577200
I1203 16:39:45.021692 12164 layer_factory.cpp:58] Creating layer pool2
I1203 16:39:45.021692 12164 net.cpp:84] Creating Layer pool2
I1203 16:39:45.021692 12164 net.cpp:406] pool2 <- group1_block0_proj
I1203 16:39:45.021692 12164 net.cpp:380] pool2 -> pool2
I1203 16:39:45.021692 12164 net.cpp:122] Setting up pool2
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.021692 12164 net.cpp:137] Memory required for data: 419854000
I1203 16:39:45.021692 12164 layer_factory.cpp:58] Creating layer group1_block0_proj_bn
I1203 16:39:45.021692 12164 net.cpp:84] Creating Layer group1_block0_proj_bn
I1203 16:39:45.021692 12164 net.cpp:406] group1_block0_proj_bn <- pool2
I1203 16:39:45.021692 12164 net.cpp:367] group1_block0_proj_bn -> pool2 (in-place)
I1203 16:39:45.021692 12164 net.cpp:122] Setting up group1_block0_proj_bn
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.021692 12164 net.cpp:137] Memory required for data: 423130800
I1203 16:39:45.021692 12164 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 16:39:45.021692 12164 net.cpp:84] Creating Layer group1_block0_proj_scale
I1203 16:39:45.021692 12164 net.cpp:406] group1_block0_proj_scale <- pool2
I1203 16:39:45.021692 12164 net.cpp:367] group1_block0_proj_scale -> pool2 (in-place)
I1203 16:39:45.021692 12164 layer_factory.cpp:58] Creating layer group1_block0_proj_scale
I1203 16:39:45.021692 12164 net.cpp:122] Setting up group1_block0_proj_scale
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.021692 12164 net.cpp:137] Memory required for data: 426407600
I1203 16:39:45.021692 12164 layer_factory.cpp:58] Creating layer group1_block0_sum
I1203 16:39:45.021692 12164 net.cpp:84] Creating Layer group1_block0_sum
I1203 16:39:45.021692 12164 net.cpp:406] group1_block0_sum <- pool2
I1203 16:39:45.021692 12164 net.cpp:406] group1_block0_sum <- group1_block0_conv1
I1203 16:39:45.021692 12164 net.cpp:380] group1_block0_sum -> group1_block0_sum
I1203 16:39:45.021692 12164 net.cpp:122] Setting up group1_block0_sum
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.021692 12164 net.cpp:137] Memory required for data: 429684400
I1203 16:39:45.021692 12164 layer_factory.cpp:58] Creating layer group1_block0_sum_group1_block0_sum_0_split
I1203 16:39:45.021692 12164 net.cpp:84] Creating Layer group1_block0_sum_group1_block0_sum_0_split
I1203 16:39:45.021692 12164 net.cpp:406] group1_block0_sum_group1_block0_sum_0_split <- group1_block0_sum
I1203 16:39:45.021692 12164 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_0
I1203 16:39:45.021692 12164 net.cpp:380] group1_block0_sum_group1_block0_sum_0_split -> group1_block0_sum_group1_block0_sum_0_split_1
I1203 16:39:45.021692 12164 net.cpp:122] Setting up group1_block0_sum_group1_block0_sum_0_split
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.021692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.022692 12164 net.cpp:137] Memory required for data: 436238000
I1203 16:39:45.022692 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0
I1203 16:39:45.022692 12164 net.cpp:84] Creating Layer group1_block1_conv0
I1203 16:39:45.022692 12164 net.cpp:406] group1_block1_conv0 <- group1_block0_sum_group1_block0_sum_0_split_0
I1203 16:39:45.022692 12164 net.cpp:380] group1_block1_conv0 -> group1_block1_conv0
I1203 16:39:45.023685 12164 net.cpp:122] Setting up group1_block1_conv0
I1203 16:39:45.023685 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.023685 12164 net.cpp:137] Memory required for data: 439514800
I1203 16:39:45.023685 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_bn
I1203 16:39:45.023685 12164 net.cpp:84] Creating Layer group1_block1_conv0_bn
I1203 16:39:45.023685 12164 net.cpp:406] group1_block1_conv0_bn <- group1_block1_conv0
I1203 16:39:45.023685 12164 net.cpp:367] group1_block1_conv0_bn -> group1_block1_conv0 (in-place)
I1203 16:39:45.023685 12164 net.cpp:122] Setting up group1_block1_conv0_bn
I1203 16:39:45.023685 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.023685 12164 net.cpp:137] Memory required for data: 442791600
I1203 16:39:45.023685 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 16:39:45.023685 12164 net.cpp:84] Creating Layer group1_block1_conv0_scale
I1203 16:39:45.023685 12164 net.cpp:406] group1_block1_conv0_scale <- group1_block1_conv0
I1203 16:39:45.023685 12164 net.cpp:367] group1_block1_conv0_scale -> group1_block1_conv0 (in-place)
I1203 16:39:45.023685 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_scale
I1203 16:39:45.024685 12164 net.cpp:122] Setting up group1_block1_conv0_scale
I1203 16:39:45.024685 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.024685 12164 net.cpp:137] Memory required for data: 446068400
I1203 16:39:45.024685 12164 layer_factory.cpp:58] Creating layer group1_block1_conv0_relu
I1203 16:39:45.024685 12164 net.cpp:84] Creating Layer group1_block1_conv0_relu
I1203 16:39:45.024685 12164 net.cpp:406] group1_block1_conv0_relu <- group1_block1_conv0
I1203 16:39:45.024685 12164 net.cpp:367] group1_block1_conv0_relu -> group1_block1_conv0 (in-place)
I1203 16:39:45.024685 12164 net.cpp:122] Setting up group1_block1_conv0_relu
I1203 16:39:45.024685 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.024685 12164 net.cpp:137] Memory required for data: 449345200
I1203 16:39:45.024685 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1
I1203 16:39:45.024685 12164 net.cpp:84] Creating Layer group1_block1_conv1
I1203 16:39:45.024685 12164 net.cpp:406] group1_block1_conv1 <- group1_block1_conv0
I1203 16:39:45.024685 12164 net.cpp:380] group1_block1_conv1 -> group1_block1_conv1
I1203 16:39:45.025707 12164 net.cpp:122] Setting up group1_block1_conv1
I1203 16:39:45.025707 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.025707 12164 net.cpp:137] Memory required for data: 452622000
I1203 16:39:45.025707 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1_bn
I1203 16:39:45.025707 12164 net.cpp:84] Creating Layer group1_block1_conv1_bn
I1203 16:39:45.025707 12164 net.cpp:406] group1_block1_conv1_bn <- group1_block1_conv1
I1203 16:39:45.025707 12164 net.cpp:367] group1_block1_conv1_bn -> group1_block1_conv1 (in-place)
I1203 16:39:45.026692 12164 net.cpp:122] Setting up group1_block1_conv1_bn
I1203 16:39:45.026692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.026692 12164 net.cpp:137] Memory required for data: 455898800
I1203 16:39:45.026692 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 16:39:45.026692 12164 net.cpp:84] Creating Layer group1_block1_conv1_scale
I1203 16:39:45.026692 12164 net.cpp:406] group1_block1_conv1_scale <- group1_block1_conv1
I1203 16:39:45.026692 12164 net.cpp:367] group1_block1_conv1_scale -> group1_block1_conv1 (in-place)
I1203 16:39:45.026692 12164 layer_factory.cpp:58] Creating layer group1_block1_conv1_scale
I1203 16:39:45.026692 12164 net.cpp:122] Setting up group1_block1_conv1_scale
I1203 16:39:45.026692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.026692 12164 net.cpp:137] Memory required for data: 459175600
I1203 16:39:45.026692 12164 layer_factory.cpp:58] Creating layer group1_block1_sum
I1203 16:39:45.026692 12164 net.cpp:84] Creating Layer group1_block1_sum
I1203 16:39:45.026692 12164 net.cpp:406] group1_block1_sum <- group1_block1_conv1
I1203 16:39:45.026692 12164 net.cpp:406] group1_block1_sum <- group1_block0_sum_group1_block0_sum_0_split_1
I1203 16:39:45.026692 12164 net.cpp:380] group1_block1_sum -> group1_block1_sum
I1203 16:39:45.026692 12164 net.cpp:122] Setting up group1_block1_sum
I1203 16:39:45.026692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.026692 12164 net.cpp:137] Memory required for data: 462452400
I1203 16:39:45.026692 12164 layer_factory.cpp:58] Creating layer group1_block1_sum_group1_block1_sum_0_split
I1203 16:39:45.026692 12164 net.cpp:84] Creating Layer group1_block1_sum_group1_block1_sum_0_split
I1203 16:39:45.026692 12164 net.cpp:406] group1_block1_sum_group1_block1_sum_0_split <- group1_block1_sum
I1203 16:39:45.026692 12164 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_0
I1203 16:39:45.026692 12164 net.cpp:380] group1_block1_sum_group1_block1_sum_0_split -> group1_block1_sum_group1_block1_sum_0_split_1
I1203 16:39:45.026692 12164 net.cpp:122] Setting up group1_block1_sum_group1_block1_sum_0_split
I1203 16:39:45.026692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.026692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.026692 12164 net.cpp:137] Memory required for data: 469006000
I1203 16:39:45.026692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0
I1203 16:39:45.026692 12164 net.cpp:84] Creating Layer group1_block2_conv0
I1203 16:39:45.026692 12164 net.cpp:406] group1_block2_conv0 <- group1_block1_sum_group1_block1_sum_0_split_0
I1203 16:39:45.026692 12164 net.cpp:380] group1_block2_conv0 -> group1_block2_conv0
I1203 16:39:45.027691 12164 net.cpp:122] Setting up group1_block2_conv0
I1203 16:39:45.027691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.027691 12164 net.cpp:137] Memory required for data: 472282800
I1203 16:39:45.027691 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_bn
I1203 16:39:45.027691 12164 net.cpp:84] Creating Layer group1_block2_conv0_bn
I1203 16:39:45.027691 12164 net.cpp:406] group1_block2_conv0_bn <- group1_block2_conv0
I1203 16:39:45.027691 12164 net.cpp:367] group1_block2_conv0_bn -> group1_block2_conv0 (in-place)
I1203 16:39:45.028692 12164 net.cpp:122] Setting up group1_block2_conv0_bn
I1203 16:39:45.028692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.028692 12164 net.cpp:137] Memory required for data: 475559600
I1203 16:39:45.028692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 16:39:45.028692 12164 net.cpp:84] Creating Layer group1_block2_conv0_scale
I1203 16:39:45.028692 12164 net.cpp:406] group1_block2_conv0_scale <- group1_block2_conv0
I1203 16:39:45.028692 12164 net.cpp:367] group1_block2_conv0_scale -> group1_block2_conv0 (in-place)
I1203 16:39:45.028692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_scale
I1203 16:39:45.028692 12164 net.cpp:122] Setting up group1_block2_conv0_scale
I1203 16:39:45.028692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.028692 12164 net.cpp:137] Memory required for data: 478836400
I1203 16:39:45.028692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv0_relu
I1203 16:39:45.028692 12164 net.cpp:84] Creating Layer group1_block2_conv0_relu
I1203 16:39:45.028692 12164 net.cpp:406] group1_block2_conv0_relu <- group1_block2_conv0
I1203 16:39:45.028692 12164 net.cpp:367] group1_block2_conv0_relu -> group1_block2_conv0 (in-place)
I1203 16:39:45.028692 12164 net.cpp:122] Setting up group1_block2_conv0_relu
I1203 16:39:45.028692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.028692 12164 net.cpp:137] Memory required for data: 482113200
I1203 16:39:45.028692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1
I1203 16:39:45.028692 12164 net.cpp:84] Creating Layer group1_block2_conv1
I1203 16:39:45.028692 12164 net.cpp:406] group1_block2_conv1 <- group1_block2_conv0
I1203 16:39:45.028692 12164 net.cpp:380] group1_block2_conv1 -> group1_block2_conv1
I1203 16:39:45.029691 12164 net.cpp:122] Setting up group1_block2_conv1
I1203 16:39:45.029691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.029691 12164 net.cpp:137] Memory required for data: 485390000
I1203 16:39:45.029691 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1_bn
I1203 16:39:45.029691 12164 net.cpp:84] Creating Layer group1_block2_conv1_bn
I1203 16:39:45.029691 12164 net.cpp:406] group1_block2_conv1_bn <- group1_block2_conv1
I1203 16:39:45.029691 12164 net.cpp:367] group1_block2_conv1_bn -> group1_block2_conv1 (in-place)
I1203 16:39:45.030692 12164 net.cpp:122] Setting up group1_block2_conv1_bn
I1203 16:39:45.030692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.030692 12164 net.cpp:137] Memory required for data: 488666800
I1203 16:39:45.030692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 16:39:45.030692 12164 net.cpp:84] Creating Layer group1_block2_conv1_scale
I1203 16:39:45.030692 12164 net.cpp:406] group1_block2_conv1_scale <- group1_block2_conv1
I1203 16:39:45.030692 12164 net.cpp:367] group1_block2_conv1_scale -> group1_block2_conv1 (in-place)
I1203 16:39:45.030692 12164 layer_factory.cpp:58] Creating layer group1_block2_conv1_scale
I1203 16:39:45.030692 12164 net.cpp:122] Setting up group1_block2_conv1_scale
I1203 16:39:45.030692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.030692 12164 net.cpp:137] Memory required for data: 491943600
I1203 16:39:45.030692 12164 layer_factory.cpp:58] Creating layer group1_block2_sum
I1203 16:39:45.030692 12164 net.cpp:84] Creating Layer group1_block2_sum
I1203 16:39:45.030692 12164 net.cpp:406] group1_block2_sum <- group1_block2_conv1
I1203 16:39:45.030692 12164 net.cpp:406] group1_block2_sum <- group1_block1_sum_group1_block1_sum_0_split_1
I1203 16:39:45.030692 12164 net.cpp:380] group1_block2_sum -> group1_block2_sum
I1203 16:39:45.030692 12164 net.cpp:122] Setting up group1_block2_sum
I1203 16:39:45.030692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.030692 12164 net.cpp:137] Memory required for data: 495220400
I1203 16:39:45.030692 12164 layer_factory.cpp:58] Creating layer group1_block2_sum_group1_block2_sum_0_split
I1203 16:39:45.030692 12164 net.cpp:84] Creating Layer group1_block2_sum_group1_block2_sum_0_split
I1203 16:39:45.030692 12164 net.cpp:406] group1_block2_sum_group1_block2_sum_0_split <- group1_block2_sum
I1203 16:39:45.030692 12164 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_0
I1203 16:39:45.030692 12164 net.cpp:380] group1_block2_sum_group1_block2_sum_0_split -> group1_block2_sum_group1_block2_sum_0_split_1
I1203 16:39:45.030692 12164 net.cpp:122] Setting up group1_block2_sum_group1_block2_sum_0_split
I1203 16:39:45.030692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.030692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.030692 12164 net.cpp:137] Memory required for data: 501774000
I1203 16:39:45.030692 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0
I1203 16:39:45.030692 12164 net.cpp:84] Creating Layer group1_block3_conv0
I1203 16:39:45.030692 12164 net.cpp:406] group1_block3_conv0 <- group1_block2_sum_group1_block2_sum_0_split_0
I1203 16:39:45.030692 12164 net.cpp:380] group1_block3_conv0 -> group1_block3_conv0
I1203 16:39:45.031692 12164 net.cpp:122] Setting up group1_block3_conv0
I1203 16:39:45.031692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.031692 12164 net.cpp:137] Memory required for data: 505050800
I1203 16:39:45.031692 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_bn
I1203 16:39:45.031692 12164 net.cpp:84] Creating Layer group1_block3_conv0_bn
I1203 16:39:45.031692 12164 net.cpp:406] group1_block3_conv0_bn <- group1_block3_conv0
I1203 16:39:45.031692 12164 net.cpp:367] group1_block3_conv0_bn -> group1_block3_conv0 (in-place)
I1203 16:39:45.032696 12164 net.cpp:122] Setting up group1_block3_conv0_bn
I1203 16:39:45.032696 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.032696 12164 net.cpp:137] Memory required for data: 508327600
I1203 16:39:45.032696 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 16:39:45.032696 12164 net.cpp:84] Creating Layer group1_block3_conv0_scale
I1203 16:39:45.032696 12164 net.cpp:406] group1_block3_conv0_scale <- group1_block3_conv0
I1203 16:39:45.032696 12164 net.cpp:367] group1_block3_conv0_scale -> group1_block3_conv0 (in-place)
I1203 16:39:45.032696 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_scale
I1203 16:39:45.032696 12164 net.cpp:122] Setting up group1_block3_conv0_scale
I1203 16:39:45.032696 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.032696 12164 net.cpp:137] Memory required for data: 511604400
I1203 16:39:45.032696 12164 layer_factory.cpp:58] Creating layer group1_block3_conv0_relu
I1203 16:39:45.032696 12164 net.cpp:84] Creating Layer group1_block3_conv0_relu
I1203 16:39:45.032696 12164 net.cpp:406] group1_block3_conv0_relu <- group1_block3_conv0
I1203 16:39:45.032696 12164 net.cpp:367] group1_block3_conv0_relu -> group1_block3_conv0 (in-place)
I1203 16:39:45.032696 12164 net.cpp:122] Setting up group1_block3_conv0_relu
I1203 16:39:45.032696 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.032696 12164 net.cpp:137] Memory required for data: 514881200
I1203 16:39:45.032696 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1
I1203 16:39:45.032696 12164 net.cpp:84] Creating Layer group1_block3_conv1
I1203 16:39:45.032696 12164 net.cpp:406] group1_block3_conv1 <- group1_block3_conv0
I1203 16:39:45.032696 12164 net.cpp:380] group1_block3_conv1 -> group1_block3_conv1
I1203 16:39:45.034692 12164 net.cpp:122] Setting up group1_block3_conv1
I1203 16:39:45.034692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.034692 12164 net.cpp:137] Memory required for data: 518158000
I1203 16:39:45.034692 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1_bn
I1203 16:39:45.034692 12164 net.cpp:84] Creating Layer group1_block3_conv1_bn
I1203 16:39:45.034692 12164 net.cpp:406] group1_block3_conv1_bn <- group1_block3_conv1
I1203 16:39:45.034692 12164 net.cpp:367] group1_block3_conv1_bn -> group1_block3_conv1 (in-place)
I1203 16:39:45.034692 12164 net.cpp:122] Setting up group1_block3_conv1_bn
I1203 16:39:45.034692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.034692 12164 net.cpp:137] Memory required for data: 521434800
I1203 16:39:45.034692 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 16:39:45.034692 12164 net.cpp:84] Creating Layer group1_block3_conv1_scale
I1203 16:39:45.034692 12164 net.cpp:406] group1_block3_conv1_scale <- group1_block3_conv1
I1203 16:39:45.034692 12164 net.cpp:367] group1_block3_conv1_scale -> group1_block3_conv1 (in-place)
I1203 16:39:45.034692 12164 layer_factory.cpp:58] Creating layer group1_block3_conv1_scale
I1203 16:39:45.034692 12164 net.cpp:122] Setting up group1_block3_conv1_scale
I1203 16:39:45.034692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.034692 12164 net.cpp:137] Memory required for data: 524711600
I1203 16:39:45.034692 12164 layer_factory.cpp:58] Creating layer group1_block3_sum
I1203 16:39:45.034692 12164 net.cpp:84] Creating Layer group1_block3_sum
I1203 16:39:45.034692 12164 net.cpp:406] group1_block3_sum <- group1_block3_conv1
I1203 16:39:45.034692 12164 net.cpp:406] group1_block3_sum <- group1_block2_sum_group1_block2_sum_0_split_1
I1203 16:39:45.034692 12164 net.cpp:380] group1_block3_sum -> group1_block3_sum
I1203 16:39:45.034692 12164 net.cpp:122] Setting up group1_block3_sum
I1203 16:39:45.034692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.034692 12164 net.cpp:137] Memory required for data: 527988400
I1203 16:39:45.034692 12164 layer_factory.cpp:58] Creating layer group1_block3_sum_group1_block3_sum_0_split
I1203 16:39:45.034692 12164 net.cpp:84] Creating Layer group1_block3_sum_group1_block3_sum_0_split
I1203 16:39:45.034692 12164 net.cpp:406] group1_block3_sum_group1_block3_sum_0_split <- group1_block3_sum
I1203 16:39:45.034692 12164 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_0
I1203 16:39:45.034692 12164 net.cpp:380] group1_block3_sum_group1_block3_sum_0_split -> group1_block3_sum_group1_block3_sum_0_split_1
I1203 16:39:45.034692 12164 net.cpp:122] Setting up group1_block3_sum_group1_block3_sum_0_split
I1203 16:39:45.034692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.034692 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.034692 12164 net.cpp:137] Memory required for data: 534542000
I1203 16:39:45.034692 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0
I1203 16:39:45.034692 12164 net.cpp:84] Creating Layer group1_block4_conv0
I1203 16:39:45.034692 12164 net.cpp:406] group1_block4_conv0 <- group1_block3_sum_group1_block3_sum_0_split_0
I1203 16:39:45.034692 12164 net.cpp:380] group1_block4_conv0 -> group1_block4_conv0
I1203 16:39:45.036691 12164 net.cpp:122] Setting up group1_block4_conv0
I1203 16:39:45.036691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.036691 12164 net.cpp:137] Memory required for data: 537818800
I1203 16:39:45.036691 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_bn
I1203 16:39:45.036691 12164 net.cpp:84] Creating Layer group1_block4_conv0_bn
I1203 16:39:45.036691 12164 net.cpp:406] group1_block4_conv0_bn <- group1_block4_conv0
I1203 16:39:45.036691 12164 net.cpp:367] group1_block4_conv0_bn -> group1_block4_conv0 (in-place)
I1203 16:39:45.036691 12164 net.cpp:122] Setting up group1_block4_conv0_bn
I1203 16:39:45.036691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.036691 12164 net.cpp:137] Memory required for data: 541095600
I1203 16:39:45.036691 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 16:39:45.036691 12164 net.cpp:84] Creating Layer group1_block4_conv0_scale
I1203 16:39:45.036691 12164 net.cpp:406] group1_block4_conv0_scale <- group1_block4_conv0
I1203 16:39:45.036691 12164 net.cpp:367] group1_block4_conv0_scale -> group1_block4_conv0 (in-place)
I1203 16:39:45.036691 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_scale
I1203 16:39:45.036691 12164 net.cpp:122] Setting up group1_block4_conv0_scale
I1203 16:39:45.036691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.036691 12164 net.cpp:137] Memory required for data: 544372400
I1203 16:39:45.036691 12164 layer_factory.cpp:58] Creating layer group1_block4_conv0_relu
I1203 16:39:45.036691 12164 net.cpp:84] Creating Layer group1_block4_conv0_relu
I1203 16:39:45.036691 12164 net.cpp:406] group1_block4_conv0_relu <- group1_block4_conv0
I1203 16:39:45.036691 12164 net.cpp:367] group1_block4_conv0_relu -> group1_block4_conv0 (in-place)
I1203 16:39:45.036691 12164 net.cpp:122] Setting up group1_block4_conv0_relu
I1203 16:39:45.036691 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.036691 12164 net.cpp:137] Memory required for data: 547649200
I1203 16:39:45.036691 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1
I1203 16:39:45.036691 12164 net.cpp:84] Creating Layer group1_block4_conv1
I1203 16:39:45.036691 12164 net.cpp:406] group1_block4_conv1 <- group1_block4_conv0
I1203 16:39:45.036691 12164 net.cpp:380] group1_block4_conv1 -> group1_block4_conv1
I1203 16:39:45.038708 12164 net.cpp:122] Setting up group1_block4_conv1
I1203 16:39:45.038708 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.038708 12164 net.cpp:137] Memory required for data: 550926000
I1203 16:39:45.038708 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1_bn
I1203 16:39:45.038708 12164 net.cpp:84] Creating Layer group1_block4_conv1_bn
I1203 16:39:45.038708 12164 net.cpp:406] group1_block4_conv1_bn <- group1_block4_conv1
I1203 16:39:45.038708 12164 net.cpp:367] group1_block4_conv1_bn -> group1_block4_conv1 (in-place)
I1203 16:39:45.038708 12164 net.cpp:122] Setting up group1_block4_conv1_bn
I1203 16:39:45.038708 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.038708 12164 net.cpp:137] Memory required for data: 554202800
I1203 16:39:45.038708 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 16:39:45.038708 12164 net.cpp:84] Creating Layer group1_block4_conv1_scale
I1203 16:39:45.038708 12164 net.cpp:406] group1_block4_conv1_scale <- group1_block4_conv1
I1203 16:39:45.038708 12164 net.cpp:367] group1_block4_conv1_scale -> group1_block4_conv1 (in-place)
I1203 16:39:45.038708 12164 layer_factory.cpp:58] Creating layer group1_block4_conv1_scale
I1203 16:39:45.038708 12164 net.cpp:122] Setting up group1_block4_conv1_scale
I1203 16:39:45.038708 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.038708 12164 net.cpp:137] Memory required for data: 557479600
I1203 16:39:45.038708 12164 layer_factory.cpp:58] Creating layer group1_block4_sum
I1203 16:39:45.038708 12164 net.cpp:84] Creating Layer group1_block4_sum
I1203 16:39:45.038708 12164 net.cpp:406] group1_block4_sum <- group1_block4_conv1
I1203 16:39:45.038708 12164 net.cpp:406] group1_block4_sum <- group1_block3_sum_group1_block3_sum_0_split_1
I1203 16:39:45.038708 12164 net.cpp:380] group1_block4_sum -> group1_block4_sum
I1203 16:39:45.038708 12164 net.cpp:122] Setting up group1_block4_sum
I1203 16:39:45.038708 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.038708 12164 net.cpp:137] Memory required for data: 560756400
I1203 16:39:45.038708 12164 layer_factory.cpp:58] Creating layer group1_block4_sum_group1_block4_sum_0_split
I1203 16:39:45.038708 12164 net.cpp:84] Creating Layer group1_block4_sum_group1_block4_sum_0_split
I1203 16:39:45.038708 12164 net.cpp:406] group1_block4_sum_group1_block4_sum_0_split <- group1_block4_sum
I1203 16:39:45.038708 12164 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_0
I1203 16:39:45.038708 12164 net.cpp:380] group1_block4_sum_group1_block4_sum_0_split -> group1_block4_sum_group1_block4_sum_0_split_1
I1203 16:39:45.038708 12164 net.cpp:122] Setting up group1_block4_sum_group1_block4_sum_0_split
I1203 16:39:45.038708 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.038708 12164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1203 16:39:45.038708 12164 net.cpp:137] Memory required for data: 567310000
I1203 16:39:45.038708 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0
I1203 16:39:45.038708 12164 net.cpp:84] Creating Layer group2_block0_conv0
I1203 16:39:45.038708 12164 net.cpp:406] group2_block0_conv0 <- group1_block4_sum_group1_block4_sum_0_split_0
I1203 16:39:45.038708 12164 net.cpp:380] group2_block0_conv0 -> group2_block0_conv0
I1203 16:39:45.040700 12164 net.cpp:122] Setting up group2_block0_conv0
I1203 16:39:45.040700 12164 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1203 16:39:45.040700 12164 net.cpp:137] Memory required for data: 573863600
I1203 16:39:45.040700 12164 layer_factory.cpp:58] Creating layer pool3
I1203 16:39:45.040700 12164 net.cpp:84] Creating Layer pool3
I1203 16:39:45.040700 12164 net.cpp:406] pool3 <- group2_block0_conv0
I1203 16:39:45.040700 12164 net.cpp:380] pool3 -> pool3
I1203 16:39:45.040700 12164 net.cpp:122] Setting up pool3
I1203 16:39:45.040700 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.040700 12164 net.cpp:137] Memory required for data: 575502000
I1203 16:39:45.040700 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_bn
I1203 16:39:45.040700 12164 net.cpp:84] Creating Layer group2_block0_conv0_bn
I1203 16:39:45.040700 12164 net.cpp:406] group2_block0_conv0_bn <- pool3
I1203 16:39:45.040700 12164 net.cpp:367] group2_block0_conv0_bn -> pool3 (in-place)
I1203 16:39:45.040700 12164 net.cpp:122] Setting up group2_block0_conv0_bn
I1203 16:39:45.040700 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.040700 12164 net.cpp:137] Memory required for data: 577140400
I1203 16:39:45.040700 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 16:39:45.040700 12164 net.cpp:84] Creating Layer group2_block0_conv0_scale
I1203 16:39:45.040700 12164 net.cpp:406] group2_block0_conv0_scale <- pool3
I1203 16:39:45.040700 12164 net.cpp:367] group2_block0_conv0_scale -> pool3 (in-place)
I1203 16:39:45.040700 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_scale
I1203 16:39:45.040700 12164 net.cpp:122] Setting up group2_block0_conv0_scale
I1203 16:39:45.040700 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.040700 12164 net.cpp:137] Memory required for data: 578778800
I1203 16:39:45.040700 12164 layer_factory.cpp:58] Creating layer group2_block0_conv0_relu
I1203 16:39:45.040700 12164 net.cpp:84] Creating Layer group2_block0_conv0_relu
I1203 16:39:45.040700 12164 net.cpp:406] group2_block0_conv0_relu <- pool3
I1203 16:39:45.040700 12164 net.cpp:367] group2_block0_conv0_relu -> pool3 (in-place)
I1203 16:39:45.041695 12164 net.cpp:122] Setting up group2_block0_conv0_relu
I1203 16:39:45.041695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.041695 12164 net.cpp:137] Memory required for data: 580417200
I1203 16:39:45.041695 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1
I1203 16:39:45.041695 12164 net.cpp:84] Creating Layer group2_block0_conv1
I1203 16:39:45.041695 12164 net.cpp:406] group2_block0_conv1 <- pool3
I1203 16:39:45.041695 12164 net.cpp:380] group2_block0_conv1 -> group2_block0_conv1
I1203 16:39:45.042699 12164 net.cpp:122] Setting up group2_block0_conv1
I1203 16:39:45.042699 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.042699 12164 net.cpp:137] Memory required for data: 582055600
I1203 16:39:45.042699 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1_bn
I1203 16:39:45.042699 12164 net.cpp:84] Creating Layer group2_block0_conv1_bn
I1203 16:39:45.042699 12164 net.cpp:406] group2_block0_conv1_bn <- group2_block0_conv1
I1203 16:39:45.042699 12164 net.cpp:367] group2_block0_conv1_bn -> group2_block0_conv1 (in-place)
I1203 16:39:45.042699 12164 net.cpp:122] Setting up group2_block0_conv1_bn
I1203 16:39:45.042699 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.042699 12164 net.cpp:137] Memory required for data: 583694000
I1203 16:39:45.042699 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 16:39:45.042699 12164 net.cpp:84] Creating Layer group2_block0_conv1_scale
I1203 16:39:45.042699 12164 net.cpp:406] group2_block0_conv1_scale <- group2_block0_conv1
I1203 16:39:45.042699 12164 net.cpp:367] group2_block0_conv1_scale -> group2_block0_conv1 (in-place)
I1203 16:39:45.043696 12164 layer_factory.cpp:58] Creating layer group2_block0_conv1_scale
I1203 16:39:45.043696 12164 net.cpp:122] Setting up group2_block0_conv1_scale
I1203 16:39:45.043696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.043696 12164 net.cpp:137] Memory required for data: 585332400
I1203 16:39:45.043696 12164 layer_factory.cpp:58] Creating layer group2_block0_proj
I1203 16:39:45.043696 12164 net.cpp:84] Creating Layer group2_block0_proj
I1203 16:39:45.043696 12164 net.cpp:406] group2_block0_proj <- group1_block4_sum_group1_block4_sum_0_split_1
I1203 16:39:45.043696 12164 net.cpp:380] group2_block0_proj -> group2_block0_proj
I1203 16:39:45.044695 12164 net.cpp:122] Setting up group2_block0_proj
I1203 16:39:45.044695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.044695 12164 net.cpp:137] Memory required for data: 586970800
I1203 16:39:45.044695 12164 layer_factory.cpp:58] Creating layer group2_block0_proj_bn
I1203 16:39:45.044695 12164 net.cpp:84] Creating Layer group2_block0_proj_bn
I1203 16:39:45.044695 12164 net.cpp:406] group2_block0_proj_bn <- group2_block0_proj
I1203 16:39:45.044695 12164 net.cpp:367] group2_block0_proj_bn -> group2_block0_proj (in-place)
I1203 16:39:45.044695 12164 net.cpp:122] Setting up group2_block0_proj_bn
I1203 16:39:45.044695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.044695 12164 net.cpp:137] Memory required for data: 588609200
I1203 16:39:45.044695 12164 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 16:39:45.044695 12164 net.cpp:84] Creating Layer group2_block0_proj_scale
I1203 16:39:45.044695 12164 net.cpp:406] group2_block0_proj_scale <- group2_block0_proj
I1203 16:39:45.044695 12164 net.cpp:367] group2_block0_proj_scale -> group2_block0_proj (in-place)
I1203 16:39:45.044695 12164 layer_factory.cpp:58] Creating layer group2_block0_proj_scale
I1203 16:39:45.044695 12164 net.cpp:122] Setting up group2_block0_proj_scale
I1203 16:39:45.044695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.044695 12164 net.cpp:137] Memory required for data: 590247600
I1203 16:39:45.044695 12164 layer_factory.cpp:58] Creating layer group2_block0_sum
I1203 16:39:45.044695 12164 net.cpp:84] Creating Layer group2_block0_sum
I1203 16:39:45.044695 12164 net.cpp:406] group2_block0_sum <- group2_block0_proj
I1203 16:39:45.044695 12164 net.cpp:406] group2_block0_sum <- group2_block0_conv1
I1203 16:39:45.044695 12164 net.cpp:380] group2_block0_sum -> group2_block0_sum
I1203 16:39:45.045696 12164 net.cpp:122] Setting up group2_block0_sum
I1203 16:39:45.045696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.045696 12164 net.cpp:137] Memory required for data: 591886000
I1203 16:39:45.045696 12164 layer_factory.cpp:58] Creating layer group2_block0_sum_group2_block0_sum_0_split
I1203 16:39:45.045696 12164 net.cpp:84] Creating Layer group2_block0_sum_group2_block0_sum_0_split
I1203 16:39:45.045696 12164 net.cpp:406] group2_block0_sum_group2_block0_sum_0_split <- group2_block0_sum
I1203 16:39:45.045696 12164 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_0
I1203 16:39:45.045696 12164 net.cpp:380] group2_block0_sum_group2_block0_sum_0_split -> group2_block0_sum_group2_block0_sum_0_split_1
I1203 16:39:45.045696 12164 net.cpp:122] Setting up group2_block0_sum_group2_block0_sum_0_split
I1203 16:39:45.045696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.045696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.045696 12164 net.cpp:137] Memory required for data: 595162800
I1203 16:39:45.045696 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0
I1203 16:39:45.045696 12164 net.cpp:84] Creating Layer group2_block1_conv0
I1203 16:39:45.045696 12164 net.cpp:406] group2_block1_conv0 <- group2_block0_sum_group2_block0_sum_0_split_0
I1203 16:39:45.045696 12164 net.cpp:380] group2_block1_conv0 -> group2_block1_conv0
I1203 16:39:45.046695 12164 net.cpp:122] Setting up group2_block1_conv0
I1203 16:39:45.046695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.046695 12164 net.cpp:137] Memory required for data: 596801200
I1203 16:39:45.046695 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_bn
I1203 16:39:45.046695 12164 net.cpp:84] Creating Layer group2_block1_conv0_bn
I1203 16:39:45.046695 12164 net.cpp:406] group2_block1_conv0_bn <- group2_block1_conv0
I1203 16:39:45.046695 12164 net.cpp:367] group2_block1_conv0_bn -> group2_block1_conv0 (in-place)
I1203 16:39:45.046695 12164 net.cpp:122] Setting up group2_block1_conv0_bn
I1203 16:39:45.046695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.046695 12164 net.cpp:137] Memory required for data: 598439600
I1203 16:39:45.046695 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 16:39:45.046695 12164 net.cpp:84] Creating Layer group2_block1_conv0_scale
I1203 16:39:45.046695 12164 net.cpp:406] group2_block1_conv0_scale <- group2_block1_conv0
I1203 16:39:45.046695 12164 net.cpp:367] group2_block1_conv0_scale -> group2_block1_conv0 (in-place)
I1203 16:39:45.046695 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_scale
I1203 16:39:45.047696 12164 net.cpp:122] Setting up group2_block1_conv0_scale
I1203 16:39:45.047696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.047696 12164 net.cpp:137] Memory required for data: 600078000
I1203 16:39:45.047696 12164 layer_factory.cpp:58] Creating layer group2_block1_conv0_relu
I1203 16:39:45.047696 12164 net.cpp:84] Creating Layer group2_block1_conv0_relu
I1203 16:39:45.047696 12164 net.cpp:406] group2_block1_conv0_relu <- group2_block1_conv0
I1203 16:39:45.047696 12164 net.cpp:367] group2_block1_conv0_relu -> group2_block1_conv0 (in-place)
I1203 16:39:45.047696 12164 net.cpp:122] Setting up group2_block1_conv0_relu
I1203 16:39:45.047696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.047696 12164 net.cpp:137] Memory required for data: 601716400
I1203 16:39:45.047696 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1
I1203 16:39:45.047696 12164 net.cpp:84] Creating Layer group2_block1_conv1
I1203 16:39:45.047696 12164 net.cpp:406] group2_block1_conv1 <- group2_block1_conv0
I1203 16:39:45.047696 12164 net.cpp:380] group2_block1_conv1 -> group2_block1_conv1
I1203 16:39:45.049695 12164 net.cpp:122] Setting up group2_block1_conv1
I1203 16:39:45.049695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.049695 12164 net.cpp:137] Memory required for data: 603354800
I1203 16:39:45.049695 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1_bn
I1203 16:39:45.049695 12164 net.cpp:84] Creating Layer group2_block1_conv1_bn
I1203 16:39:45.049695 12164 net.cpp:406] group2_block1_conv1_bn <- group2_block1_conv1
I1203 16:39:45.049695 12164 net.cpp:367] group2_block1_conv1_bn -> group2_block1_conv1 (in-place)
I1203 16:39:45.049695 12164 net.cpp:122] Setting up group2_block1_conv1_bn
I1203 16:39:45.049695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.049695 12164 net.cpp:137] Memory required for data: 604993200
I1203 16:39:45.049695 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 16:39:45.049695 12164 net.cpp:84] Creating Layer group2_block1_conv1_scale
I1203 16:39:45.049695 12164 net.cpp:406] group2_block1_conv1_scale <- group2_block1_conv1
I1203 16:39:45.049695 12164 net.cpp:367] group2_block1_conv1_scale -> group2_block1_conv1 (in-place)
I1203 16:39:45.049695 12164 layer_factory.cpp:58] Creating layer group2_block1_conv1_scale
I1203 16:39:45.050705 12164 net.cpp:122] Setting up group2_block1_conv1_scale
I1203 16:39:45.050705 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.050705 12164 net.cpp:137] Memory required for data: 606631600
I1203 16:39:45.050705 12164 layer_factory.cpp:58] Creating layer group2_block1_sum
I1203 16:39:45.050705 12164 net.cpp:84] Creating Layer group2_block1_sum
I1203 16:39:45.050705 12164 net.cpp:406] group2_block1_sum <- group2_block1_conv1
I1203 16:39:45.050705 12164 net.cpp:406] group2_block1_sum <- group2_block0_sum_group2_block0_sum_0_split_1
I1203 16:39:45.050705 12164 net.cpp:380] group2_block1_sum -> group2_block1_sum
I1203 16:39:45.050705 12164 net.cpp:122] Setting up group2_block1_sum
I1203 16:39:45.050705 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.050705 12164 net.cpp:137] Memory required for data: 608270000
I1203 16:39:45.050705 12164 layer_factory.cpp:58] Creating layer group2_block1_sum_group2_block1_sum_0_split
I1203 16:39:45.050705 12164 net.cpp:84] Creating Layer group2_block1_sum_group2_block1_sum_0_split
I1203 16:39:45.050705 12164 net.cpp:406] group2_block1_sum_group2_block1_sum_0_split <- group2_block1_sum
I1203 16:39:45.050705 12164 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_0
I1203 16:39:45.050705 12164 net.cpp:380] group2_block1_sum_group2_block1_sum_0_split -> group2_block1_sum_group2_block1_sum_0_split_1
I1203 16:39:45.050705 12164 net.cpp:122] Setting up group2_block1_sum_group2_block1_sum_0_split
I1203 16:39:45.050705 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.050705 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.050705 12164 net.cpp:137] Memory required for data: 611546800
I1203 16:39:45.050705 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0
I1203 16:39:45.050705 12164 net.cpp:84] Creating Layer group2_block2_conv0
I1203 16:39:45.050705 12164 net.cpp:406] group2_block2_conv0 <- group2_block1_sum_group2_block1_sum_0_split_0
I1203 16:39:45.050705 12164 net.cpp:380] group2_block2_conv0 -> group2_block2_conv0
I1203 16:39:45.052696 12164 net.cpp:122] Setting up group2_block2_conv0
I1203 16:39:45.052696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.052696 12164 net.cpp:137] Memory required for data: 613185200
I1203 16:39:45.052696 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_bn
I1203 16:39:45.052696 12164 net.cpp:84] Creating Layer group2_block2_conv0_bn
I1203 16:39:45.052696 12164 net.cpp:406] group2_block2_conv0_bn <- group2_block2_conv0
I1203 16:39:45.052696 12164 net.cpp:367] group2_block2_conv0_bn -> group2_block2_conv0 (in-place)
I1203 16:39:45.052696 12164 net.cpp:122] Setting up group2_block2_conv0_bn
I1203 16:39:45.052696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.052696 12164 net.cpp:137] Memory required for data: 614823600
I1203 16:39:45.052696 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 16:39:45.052696 12164 net.cpp:84] Creating Layer group2_block2_conv0_scale
I1203 16:39:45.052696 12164 net.cpp:406] group2_block2_conv0_scale <- group2_block2_conv0
I1203 16:39:45.052696 12164 net.cpp:367] group2_block2_conv0_scale -> group2_block2_conv0 (in-place)
I1203 16:39:45.052696 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_scale
I1203 16:39:45.052696 12164 net.cpp:122] Setting up group2_block2_conv0_scale
I1203 16:39:45.052696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.052696 12164 net.cpp:137] Memory required for data: 616462000
I1203 16:39:45.052696 12164 layer_factory.cpp:58] Creating layer group2_block2_conv0_relu
I1203 16:39:45.052696 12164 net.cpp:84] Creating Layer group2_block2_conv0_relu
I1203 16:39:45.052696 12164 net.cpp:406] group2_block2_conv0_relu <- group2_block2_conv0
I1203 16:39:45.052696 12164 net.cpp:367] group2_block2_conv0_relu -> group2_block2_conv0 (in-place)
I1203 16:39:45.052696 12164 net.cpp:122] Setting up group2_block2_conv0_relu
I1203 16:39:45.052696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.052696 12164 net.cpp:137] Memory required for data: 618100400
I1203 16:39:45.052696 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1
I1203 16:39:45.052696 12164 net.cpp:84] Creating Layer group2_block2_conv1
I1203 16:39:45.052696 12164 net.cpp:406] group2_block2_conv1 <- group2_block2_conv0
I1203 16:39:45.053692 12164 net.cpp:380] group2_block2_conv1 -> group2_block2_conv1
I1203 16:39:45.055691 12164 net.cpp:122] Setting up group2_block2_conv1
I1203 16:39:45.055691 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.055691 12164 net.cpp:137] Memory required for data: 619738800
I1203 16:39:45.055691 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1_bn
I1203 16:39:45.055691 12164 net.cpp:84] Creating Layer group2_block2_conv1_bn
I1203 16:39:45.055691 12164 net.cpp:406] group2_block2_conv1_bn <- group2_block2_conv1
I1203 16:39:45.055691 12164 net.cpp:367] group2_block2_conv1_bn -> group2_block2_conv1 (in-place)
I1203 16:39:45.055691 12164 net.cpp:122] Setting up group2_block2_conv1_bn
I1203 16:39:45.055691 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.055691 12164 net.cpp:137] Memory required for data: 621377200
I1203 16:39:45.055691 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 16:39:45.055691 12164 net.cpp:84] Creating Layer group2_block2_conv1_scale
I1203 16:39:45.055691 12164 net.cpp:406] group2_block2_conv1_scale <- group2_block2_conv1
I1203 16:39:45.055691 12164 net.cpp:367] group2_block2_conv1_scale -> group2_block2_conv1 (in-place)
I1203 16:39:45.055691 12164 layer_factory.cpp:58] Creating layer group2_block2_conv1_scale
I1203 16:39:45.055691 12164 net.cpp:122] Setting up group2_block2_conv1_scale
I1203 16:39:45.055691 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.055691 12164 net.cpp:137] Memory required for data: 623015600
I1203 16:39:45.055691 12164 layer_factory.cpp:58] Creating layer group2_block2_sum
I1203 16:39:45.055691 12164 net.cpp:84] Creating Layer group2_block2_sum
I1203 16:39:45.055691 12164 net.cpp:406] group2_block2_sum <- group2_block2_conv1
I1203 16:39:45.055691 12164 net.cpp:406] group2_block2_sum <- group2_block1_sum_group2_block1_sum_0_split_1
I1203 16:39:45.055691 12164 net.cpp:380] group2_block2_sum -> group2_block2_sum
I1203 16:39:45.055691 12164 net.cpp:122] Setting up group2_block2_sum
I1203 16:39:45.055691 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.055691 12164 net.cpp:137] Memory required for data: 624654000
I1203 16:39:45.055691 12164 layer_factory.cpp:58] Creating layer group2_block2_sum_group2_block2_sum_0_split
I1203 16:39:45.055691 12164 net.cpp:84] Creating Layer group2_block2_sum_group2_block2_sum_0_split
I1203 16:39:45.055691 12164 net.cpp:406] group2_block2_sum_group2_block2_sum_0_split <- group2_block2_sum
I1203 16:39:45.055691 12164 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_0
I1203 16:39:45.055691 12164 net.cpp:380] group2_block2_sum_group2_block2_sum_0_split -> group2_block2_sum_group2_block2_sum_0_split_1
I1203 16:39:45.055691 12164 net.cpp:122] Setting up group2_block2_sum_group2_block2_sum_0_split
I1203 16:39:45.055691 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.055691 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.055691 12164 net.cpp:137] Memory required for data: 627930800
I1203 16:39:45.055691 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0
I1203 16:39:45.055691 12164 net.cpp:84] Creating Layer group2_block3_conv0
I1203 16:39:45.055691 12164 net.cpp:406] group2_block3_conv0 <- group2_block2_sum_group2_block2_sum_0_split_0
I1203 16:39:45.055691 12164 net.cpp:380] group2_block3_conv0 -> group2_block3_conv0
I1203 16:39:45.057700 12164 net.cpp:122] Setting up group2_block3_conv0
I1203 16:39:45.057700 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.057700 12164 net.cpp:137] Memory required for data: 629569200
I1203 16:39:45.057700 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_bn
I1203 16:39:45.057700 12164 net.cpp:84] Creating Layer group2_block3_conv0_bn
I1203 16:39:45.057700 12164 net.cpp:406] group2_block3_conv0_bn <- group2_block3_conv0
I1203 16:39:45.057700 12164 net.cpp:367] group2_block3_conv0_bn -> group2_block3_conv0 (in-place)
I1203 16:39:45.057700 12164 net.cpp:122] Setting up group2_block3_conv0_bn
I1203 16:39:45.057700 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.057700 12164 net.cpp:137] Memory required for data: 631207600
I1203 16:39:45.057700 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 16:39:45.057700 12164 net.cpp:84] Creating Layer group2_block3_conv0_scale
I1203 16:39:45.057700 12164 net.cpp:406] group2_block3_conv0_scale <- group2_block3_conv0
I1203 16:39:45.057700 12164 net.cpp:367] group2_block3_conv0_scale -> group2_block3_conv0 (in-place)
I1203 16:39:45.057700 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_scale
I1203 16:39:45.058696 12164 net.cpp:122] Setting up group2_block3_conv0_scale
I1203 16:39:45.058696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.058696 12164 net.cpp:137] Memory required for data: 632846000
I1203 16:39:45.058696 12164 layer_factory.cpp:58] Creating layer group2_block3_conv0_relu
I1203 16:39:45.058696 12164 net.cpp:84] Creating Layer group2_block3_conv0_relu
I1203 16:39:45.058696 12164 net.cpp:406] group2_block3_conv0_relu <- group2_block3_conv0
I1203 16:39:45.058696 12164 net.cpp:367] group2_block3_conv0_relu -> group2_block3_conv0 (in-place)
I1203 16:39:45.058696 12164 net.cpp:122] Setting up group2_block3_conv0_relu
I1203 16:39:45.058696 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.058696 12164 net.cpp:137] Memory required for data: 634484400
I1203 16:39:45.058696 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1
I1203 16:39:45.058696 12164 net.cpp:84] Creating Layer group2_block3_conv1
I1203 16:39:45.058696 12164 net.cpp:406] group2_block3_conv1 <- group2_block3_conv0
I1203 16:39:45.058696 12164 net.cpp:380] group2_block3_conv1 -> group2_block3_conv1
I1203 16:39:45.059695 12164 net.cpp:122] Setting up group2_block3_conv1
I1203 16:39:45.059695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.059695 12164 net.cpp:137] Memory required for data: 636122800
I1203 16:39:45.059695 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1_bn
I1203 16:39:45.059695 12164 net.cpp:84] Creating Layer group2_block3_conv1_bn
I1203 16:39:45.059695 12164 net.cpp:406] group2_block3_conv1_bn <- group2_block3_conv1
I1203 16:39:45.059695 12164 net.cpp:367] group2_block3_conv1_bn -> group2_block3_conv1 (in-place)
I1203 16:39:45.060695 12164 net.cpp:122] Setting up group2_block3_conv1_bn
I1203 16:39:45.060695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.060695 12164 net.cpp:137] Memory required for data: 637761200
I1203 16:39:45.060695 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 16:39:45.060695 12164 net.cpp:84] Creating Layer group2_block3_conv1_scale
I1203 16:39:45.060695 12164 net.cpp:406] group2_block3_conv1_scale <- group2_block3_conv1
I1203 16:39:45.060695 12164 net.cpp:367] group2_block3_conv1_scale -> group2_block3_conv1 (in-place)
I1203 16:39:45.060695 12164 layer_factory.cpp:58] Creating layer group2_block3_conv1_scale
I1203 16:39:45.060695 12164 net.cpp:122] Setting up group2_block3_conv1_scale
I1203 16:39:45.060695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.060695 12164 net.cpp:137] Memory required for data: 639399600
I1203 16:39:45.060695 12164 layer_factory.cpp:58] Creating layer group2_block3_sum
I1203 16:39:45.060695 12164 net.cpp:84] Creating Layer group2_block3_sum
I1203 16:39:45.060695 12164 net.cpp:406] group2_block3_sum <- group2_block3_conv1
I1203 16:39:45.060695 12164 net.cpp:406] group2_block3_sum <- group2_block2_sum_group2_block2_sum_0_split_1
I1203 16:39:45.060695 12164 net.cpp:380] group2_block3_sum -> group2_block3_sum
I1203 16:39:45.060695 12164 net.cpp:122] Setting up group2_block3_sum
I1203 16:39:45.060695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.060695 12164 net.cpp:137] Memory required for data: 641038000
I1203 16:39:45.060695 12164 layer_factory.cpp:58] Creating layer group2_block3_sum_group2_block3_sum_0_split
I1203 16:39:45.060695 12164 net.cpp:84] Creating Layer group2_block3_sum_group2_block3_sum_0_split
I1203 16:39:45.060695 12164 net.cpp:406] group2_block3_sum_group2_block3_sum_0_split <- group2_block3_sum
I1203 16:39:45.060695 12164 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_0
I1203 16:39:45.060695 12164 net.cpp:380] group2_block3_sum_group2_block3_sum_0_split -> group2_block3_sum_group2_block3_sum_0_split_1
I1203 16:39:45.060695 12164 net.cpp:122] Setting up group2_block3_sum_group2_block3_sum_0_split
I1203 16:39:45.060695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.060695 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.060695 12164 net.cpp:137] Memory required for data: 644314800
I1203 16:39:45.060695 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0
I1203 16:39:45.060695 12164 net.cpp:84] Creating Layer group2_block4_conv0
I1203 16:39:45.060695 12164 net.cpp:406] group2_block4_conv0 <- group2_block3_sum_group2_block3_sum_0_split_0
I1203 16:39:45.060695 12164 net.cpp:380] group2_block4_conv0 -> group2_block4_conv0
I1203 16:39:45.062711 12164 net.cpp:122] Setting up group2_block4_conv0
I1203 16:39:45.062711 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.062711 12164 net.cpp:137] Memory required for data: 645953200
I1203 16:39:45.062711 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_bn
I1203 16:39:45.062711 12164 net.cpp:84] Creating Layer group2_block4_conv0_bn
I1203 16:39:45.062711 12164 net.cpp:406] group2_block4_conv0_bn <- group2_block4_conv0
I1203 16:39:45.062711 12164 net.cpp:367] group2_block4_conv0_bn -> group2_block4_conv0 (in-place)
I1203 16:39:45.063684 12164 net.cpp:122] Setting up group2_block4_conv0_bn
I1203 16:39:45.063684 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.063684 12164 net.cpp:137] Memory required for data: 647591600
I1203 16:39:45.063684 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 16:39:45.063684 12164 net.cpp:84] Creating Layer group2_block4_conv0_scale
I1203 16:39:45.063684 12164 net.cpp:406] group2_block4_conv0_scale <- group2_block4_conv0
I1203 16:39:45.063684 12164 net.cpp:367] group2_block4_conv0_scale -> group2_block4_conv0 (in-place)
I1203 16:39:45.063684 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_scale
I1203 16:39:45.063684 12164 net.cpp:122] Setting up group2_block4_conv0_scale
I1203 16:39:45.063684 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.063684 12164 net.cpp:137] Memory required for data: 649230000
I1203 16:39:45.063684 12164 layer_factory.cpp:58] Creating layer group2_block4_conv0_relu
I1203 16:39:45.063684 12164 net.cpp:84] Creating Layer group2_block4_conv0_relu
I1203 16:39:45.063684 12164 net.cpp:406] group2_block4_conv0_relu <- group2_block4_conv0
I1203 16:39:45.063684 12164 net.cpp:367] group2_block4_conv0_relu -> group2_block4_conv0 (in-place)
I1203 16:39:45.064710 12164 net.cpp:122] Setting up group2_block4_conv0_relu
I1203 16:39:45.064710 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.064710 12164 net.cpp:137] Memory required for data: 650868400
I1203 16:39:45.064710 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1
I1203 16:39:45.064710 12164 net.cpp:84] Creating Layer group2_block4_conv1
I1203 16:39:45.064710 12164 net.cpp:406] group2_block4_conv1 <- group2_block4_conv0
I1203 16:39:45.064710 12164 net.cpp:380] group2_block4_conv1 -> group2_block4_conv1
I1203 16:39:45.066681 12164 net.cpp:122] Setting up group2_block4_conv1
I1203 16:39:45.066681 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.066681 12164 net.cpp:137] Memory required for data: 652506800
I1203 16:39:45.066681 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1_bn
I1203 16:39:45.066681 12164 net.cpp:84] Creating Layer group2_block4_conv1_bn
I1203 16:39:45.066681 12164 net.cpp:406] group2_block4_conv1_bn <- group2_block4_conv1
I1203 16:39:45.066681 12164 net.cpp:367] group2_block4_conv1_bn -> group2_block4_conv1 (in-place)
I1203 16:39:45.066681 12164 net.cpp:122] Setting up group2_block4_conv1_bn
I1203 16:39:45.066681 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.066681 12164 net.cpp:137] Memory required for data: 654145200
I1203 16:39:45.066681 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 16:39:45.066681 12164 net.cpp:84] Creating Layer group2_block4_conv1_scale
I1203 16:39:45.066681 12164 net.cpp:406] group2_block4_conv1_scale <- group2_block4_conv1
I1203 16:39:45.066681 12164 net.cpp:367] group2_block4_conv1_scale -> group2_block4_conv1 (in-place)
I1203 16:39:45.066681 12164 layer_factory.cpp:58] Creating layer group2_block4_conv1_scale
I1203 16:39:45.066681 12164 net.cpp:122] Setting up group2_block4_conv1_scale
I1203 16:39:45.066681 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.066681 12164 net.cpp:137] Memory required for data: 655783600
I1203 16:39:45.066681 12164 layer_factory.cpp:58] Creating layer group2_block4_sum
I1203 16:39:45.066681 12164 net.cpp:84] Creating Layer group2_block4_sum
I1203 16:39:45.066681 12164 net.cpp:406] group2_block4_sum <- group2_block4_conv1
I1203 16:39:45.066681 12164 net.cpp:406] group2_block4_sum <- group2_block3_sum_group2_block3_sum_0_split_1
I1203 16:39:45.067682 12164 net.cpp:380] group2_block4_sum -> group2_block4_sum
I1203 16:39:45.067682 12164 net.cpp:122] Setting up group2_block4_sum
I1203 16:39:45.067682 12164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1203 16:39:45.067682 12164 net.cpp:137] Memory required for data: 657422000
I1203 16:39:45.067682 12164 layer_factory.cpp:58] Creating layer global_avg_pool
I1203 16:39:45.067682 12164 net.cpp:84] Creating Layer global_avg_pool
I1203 16:39:45.067682 12164 net.cpp:406] global_avg_pool <- group2_block4_sum
I1203 16:39:45.067682 12164 net.cpp:380] global_avg_pool -> global_avg_pool
I1203 16:39:45.067682 12164 net.cpp:122] Setting up global_avg_pool
I1203 16:39:45.067682 12164 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1203 16:39:45.067682 12164 net.cpp:137] Memory required for data: 657447600
I1203 16:39:45.067682 12164 layer_factory.cpp:58] Creating layer fc
I1203 16:39:45.067682 12164 net.cpp:84] Creating Layer fc
I1203 16:39:45.068681 12164 net.cpp:406] fc <- global_avg_pool
I1203 16:39:45.068681 12164 net.cpp:380] fc -> fc
I1203 16:39:45.068681 12164 net.cpp:122] Setting up fc
I1203 16:39:45.068681 12164 net.cpp:129] Top shape: 100 10 (1000)
I1203 16:39:45.068681 12164 net.cpp:137] Memory required for data: 657451600
I1203 16:39:45.068681 12164 layer_factory.cpp:58] Creating layer fc_fc_0_split
I1203 16:39:45.068681 12164 net.cpp:84] Creating Layer fc_fc_0_split
I1203 16:39:45.068681 12164 net.cpp:406] fc_fc_0_split <- fc
I1203 16:39:45.068681 12164 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_0
I1203 16:39:45.068681 12164 net.cpp:380] fc_fc_0_split -> fc_fc_0_split_1
I1203 16:39:45.068681 12164 net.cpp:122] Setting up fc_fc_0_split
I1203 16:39:45.068681 12164 net.cpp:129] Top shape: 100 10 (1000)
I1203 16:39:45.068681 12164 net.cpp:129] Top shape: 100 10 (1000)
I1203 16:39:45.068681 12164 net.cpp:137] Memory required for data: 657459600
I1203 16:39:45.068681 12164 layer_factory.cpp:58] Creating layer accuracy
I1203 16:39:45.068681 12164 net.cpp:84] Creating Layer accuracy
I1203 16:39:45.068681 12164 net.cpp:406] accuracy <- fc_fc_0_split_0
I1203 16:39:45.068681 12164 net.cpp:406] accuracy <- label_cifar_1_split_0
I1203 16:39:45.068681 12164 net.cpp:380] accuracy -> accuracy
I1203 16:39:45.068681 12164 net.cpp:122] Setting up accuracy
I1203 16:39:45.068681 12164 net.cpp:129] Top shape: (1)
I1203 16:39:45.068681 12164 net.cpp:137] Memory required for data: 657459604
I1203 16:39:45.068681 12164 layer_factory.cpp:58] Creating layer loss
I1203 16:39:45.068681 12164 net.cpp:84] Creating Layer loss
I1203 16:39:45.068681 12164 net.cpp:406] loss <- fc_fc_0_split_1
I1203 16:39:45.068681 12164 net.cpp:406] loss <- label_cifar_1_split_1
I1203 16:39:45.068681 12164 net.cpp:380] loss -> loss
I1203 16:39:45.068681 12164 layer_factory.cpp:58] Creating layer loss
I1203 16:39:45.068681 12164 net.cpp:122] Setting up loss
I1203 16:39:45.068681 12164 net.cpp:129] Top shape: (1)
I1203 16:39:45.068681 12164 net.cpp:132]     with loss weight 1
I1203 16:39:45.068681 12164 net.cpp:137] Memory required for data: 657459608
I1203 16:39:45.068681 12164 net.cpp:198] loss needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:200] accuracy does not need backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] fc_fc_0_split needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] fc needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] global_avg_pool needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_sum needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv1_scale needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv1_bn needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv1 needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv0_relu needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv0_scale needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv0_bn needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block4_conv0 needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_sum_group2_block3_sum_0_split needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_sum needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv1_scale needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv1_bn needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv1 needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv0_relu needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv0_scale needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv0_bn needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block3_conv0 needs backward computation.
I1203 16:39:45.068681 12164 net.cpp:198] group2_block2_sum_group2_block2_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block2_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_sum_group2_block1_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block1_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_sum_group2_block0_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_proj_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_proj_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_proj needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] pool3 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group2_block0_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_sum_group1_block4_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block4_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_sum_group1_block3_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block3_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_sum_group1_block2_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block2_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_sum_group1_block1_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block1_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_sum_group1_block0_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_proj_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_proj_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] pool2 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_proj needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] pool1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group1_block0_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_sum_group0_block4_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block4_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_sum_group0_block3_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block3_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_sum_group0_block2_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block2_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_sum_group0_block1_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block1_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_sum_group0_block0_sum_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_sum needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv1_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv1_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv1 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv0_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv0_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv0_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] group0_block0_conv0 needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] first_conv_first_conv_relu_0_split needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] first_conv_relu needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] first_conv_scale needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] first_conv_bn needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:198] first_conv needs backward computation.
I1203 16:39:45.069681 12164 net.cpp:200] label_cifar_1_split does not need backward computation.
I1203 16:39:45.069681 12164 net.cpp:200] cifar does not need backward computation.
I1203 16:39:45.069681 12164 net.cpp:242] This network produces output accuracy
I1203 16:39:45.070682 12164 net.cpp:242] This network produces output loss
I1203 16:39:45.070682 12164 net.cpp:255] Network initialization done.
I1203 16:39:45.070682 12164 solver.cpp:56] Solver scaffolding done.
I1203 16:39:45.081681 12164 caffe.cpp:243] Resuming from examples/cifar10/snaps/resnet32_with3pooling_iter_90000.solverstate
I1203 16:39:45.090688 12164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/snaps/resnet32_with3pooling_iter_90000.caffemodel
I1203 16:39:45.090688 12164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1203 16:39:45.091189 12164 sgd_solver.cpp:318] SGDSolver: restoring history
I1203 16:39:45.099189 12164 caffe.cpp:249] Starting Optimization
I1203 16:39:45.099189 12164 solver.cpp:272] Solving CIFAR10_resnet_32_with 3pooling
I1203 16:39:45.099189 12164 solver.cpp:273] Learning Rate Policy: multistep
I1203 16:39:45.103087 12164 solver.cpp:330] Iteration 90000, Testing net (#0)
I1203 16:39:45.108072 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:39:46.887197 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:39:46.954730 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8685
I1203 16:39:46.954730 12164 solver.cpp:397]     Test net output #1: loss = 0.443522 (* 1 = 0.443522 loss)
I1203 16:39:47.130504 12164 solver.cpp:218] Iteration 90000 (44357.8 iter/s, 2.02895s/100 iters), loss = 0.118051
I1203 16:39:47.130504 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:39:47.130504 12164 solver.cpp:237]     Train net output #1: loss = 0.118051 (* 1 = 0.118051 loss)
I1203 16:39:47.130504 12164 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1203 16:39:55.167026 12164 solver.cpp:218] Iteration 90100 (12.4436 iter/s, 8.03624s/100 iters), loss = 0.146579
I1203 16:39:55.167026 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 16:39:55.167026 12164 solver.cpp:237]     Train net output #1: loss = 0.146579 (* 1 = 0.146579 loss)
I1203 16:39:55.167026 12164 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1203 16:40:03.193971 12164 solver.cpp:218] Iteration 90200 (12.4588 iter/s, 8.02649s/100 iters), loss = 0.0773743
I1203 16:40:03.193971 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:40:03.193971 12164 solver.cpp:237]     Train net output #1: loss = 0.0773743 (* 1 = 0.0773743 loss)
I1203 16:40:03.193971 12164 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1203 16:40:11.182662 12164 solver.cpp:218] Iteration 90300 (12.5175 iter/s, 7.98879s/100 iters), loss = 0.119259
I1203 16:40:11.182662 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:40:11.182662 12164 solver.cpp:237]     Train net output #1: loss = 0.119259 (* 1 = 0.119259 loss)
I1203 16:40:11.182662 12164 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1203 16:40:19.152523 12164 solver.cpp:218] Iteration 90400 (12.5492 iter/s, 7.96865s/100 iters), loss = 0.0443338
I1203 16:40:19.152523 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:40:19.152523 12164 solver.cpp:237]     Train net output #1: loss = 0.0443339 (* 1 = 0.0443339 loss)
I1203 16:40:19.152523 12164 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1203 16:40:26.736176  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:40:27.053211 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.caffemodel
I1203 16:40:27.083217 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_90500.solverstate
I1203 16:40:27.089218 12164 solver.cpp:330] Iteration 90500, Testing net (#0)
I1203 16:40:27.089218 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:40:28.763826 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:40:28.830330 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8293
I1203 16:40:28.831331 12164 solver.cpp:397]     Test net output #1: loss = 0.619094 (* 1 = 0.619094 loss)
I1203 16:40:28.905335 12164 solver.cpp:218] Iteration 90500 (10.254 iter/s, 9.75234s/100 iters), loss = 0.225361
I1203 16:40:28.905335 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1203 16:40:28.905335 12164 solver.cpp:237]     Train net output #1: loss = 0.225361 (* 1 = 0.225361 loss)
I1203 16:40:28.905335 12164 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1203 16:40:36.881075 12164 solver.cpp:218] Iteration 90600 (12.538 iter/s, 7.97577s/100 iters), loss = 0.120888
I1203 16:40:36.881075 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:40:36.881075 12164 solver.cpp:237]     Train net output #1: loss = 0.120888 (* 1 = 0.120888 loss)
I1203 16:40:36.881075 12164 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1203 16:40:44.849854 12164 solver.cpp:218] Iteration 90700 (12.5499 iter/s, 7.96822s/100 iters), loss = 0.146476
I1203 16:40:44.849854 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 16:40:44.849854 12164 solver.cpp:237]     Train net output #1: loss = 0.146476 (* 1 = 0.146476 loss)
I1203 16:40:44.849854 12164 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1203 16:40:52.825711 12164 solver.cpp:218] Iteration 90800 (12.5388 iter/s, 7.97526s/100 iters), loss = 0.0846707
I1203 16:40:52.825711 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:40:52.825711 12164 solver.cpp:237]     Train net output #1: loss = 0.0846708 (* 1 = 0.0846708 loss)
I1203 16:40:52.825711 12164 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1203 16:41:00.792310 12164 solver.cpp:218] Iteration 90900 (12.5527 iter/s, 7.96638s/100 iters), loss = 0.104227
I1203 16:41:00.792310 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 16:41:00.792310 12164 solver.cpp:237]     Train net output #1: loss = 0.104227 (* 1 = 0.104227 loss)
I1203 16:41:00.792310 12164 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1203 16:41:08.393977  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:41:08.708993 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.caffemodel
I1203 16:41:08.736996 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91000.solverstate
I1203 16:41:08.744501 12164 solver.cpp:330] Iteration 91000, Testing net (#0)
I1203 16:41:08.745002 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:41:10.423633 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:41:10.489137 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8486
I1203 16:41:10.489137 12164 solver.cpp:397]     Test net output #1: loss = 0.517243 (* 1 = 0.517243 loss)
I1203 16:41:10.564146 12164 solver.cpp:218] Iteration 91000 (10.234 iter/s, 9.77132s/100 iters), loss = 0.116587
I1203 16:41:10.564146 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:41:10.564146 12164 solver.cpp:237]     Train net output #1: loss = 0.116587 (* 1 = 0.116587 loss)
I1203 16:41:10.564146 12164 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1203 16:41:18.538233 12164 solver.cpp:218] Iteration 91100 (12.5423 iter/s, 7.97301s/100 iters), loss = 0.0929923
I1203 16:41:18.538233 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:41:18.538233 12164 solver.cpp:237]     Train net output #1: loss = 0.0929924 (* 1 = 0.0929924 loss)
I1203 16:41:18.538233 12164 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1203 16:41:26.513553 12164 solver.cpp:218] Iteration 91200 (12.5395 iter/s, 7.97483s/100 iters), loss = 0.128016
I1203 16:41:26.513553 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:41:26.513553 12164 solver.cpp:237]     Train net output #1: loss = 0.128016 (* 1 = 0.128016 loss)
I1203 16:41:26.513553 12164 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1203 16:41:34.488898 12164 solver.cpp:218] Iteration 91300 (12.5389 iter/s, 7.97517s/100 iters), loss = 0.0865965
I1203 16:41:34.488898 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:41:34.488898 12164 solver.cpp:237]     Train net output #1: loss = 0.0865966 (* 1 = 0.0865966 loss)
I1203 16:41:34.488898 12164 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1203 16:41:42.476760 12164 solver.cpp:218] Iteration 91400 (12.5205 iter/s, 7.9869s/100 iters), loss = 0.1058
I1203 16:41:42.476760 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:41:42.476760 12164 solver.cpp:237]     Train net output #1: loss = 0.1058 (* 1 = 0.1058 loss)
I1203 16:41:42.476760 12164 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1203 16:41:50.086695  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:41:50.401731 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.caffemodel
I1203 16:41:50.430233 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_91500.solverstate
I1203 16:41:50.436733 12164 solver.cpp:330] Iteration 91500, Testing net (#0)
I1203 16:41:50.436733 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:41:52.117877 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:41:52.183890 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8638
I1203 16:41:52.183890 12164 solver.cpp:397]     Test net output #1: loss = 0.467716 (* 1 = 0.467716 loss)
I1203 16:41:52.260912 12164 solver.cpp:218] Iteration 91500 (10.2207 iter/s, 9.78403s/100 iters), loss = 0.112959
I1203 16:41:52.260912 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:41:52.260912 12164 solver.cpp:237]     Train net output #1: loss = 0.112959 (* 1 = 0.112959 loss)
I1203 16:41:52.260912 12164 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1203 16:42:00.259683 12164 solver.cpp:218] Iteration 91600 (12.5024 iter/s, 7.99849s/100 iters), loss = 0.139348
I1203 16:42:00.259683 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:42:00.259683 12164 solver.cpp:237]     Train net output #1: loss = 0.139348 (* 1 = 0.139348 loss)
I1203 16:42:00.259683 12164 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1203 16:42:08.264209 12164 solver.cpp:218] Iteration 91700 (12.4934 iter/s, 8.00423s/100 iters), loss = 0.0914527
I1203 16:42:08.265223 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:42:08.265223 12164 solver.cpp:237]     Train net output #1: loss = 0.0914528 (* 1 = 0.0914528 loss)
I1203 16:42:08.265223 12164 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1203 16:42:16.261521 12164 solver.cpp:218] Iteration 91800 (12.5063 iter/s, 7.99595s/100 iters), loss = 0.103311
I1203 16:42:16.261521 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:42:16.261521 12164 solver.cpp:237]     Train net output #1: loss = 0.103311 (* 1 = 0.103311 loss)
I1203 16:42:16.261521 12164 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1203 16:42:24.261646 12164 solver.cpp:218] Iteration 91900 (12.5002 iter/s, 7.99986s/100 iters), loss = 0.0633971
I1203 16:42:24.261646 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:42:24.261646 12164 solver.cpp:237]     Train net output #1: loss = 0.0633972 (* 1 = 0.0633972 loss)
I1203 16:42:24.261646 12164 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1203 16:42:31.869412  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:42:32.188040 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.caffemodel
I1203 16:42:32.217038 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92000.solverstate
I1203 16:42:32.224038 12164 solver.cpp:330] Iteration 92000, Testing net (#0)
I1203 16:42:32.224038 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:42:33.903944 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:42:33.971987 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8823
I1203 16:42:33.971987 12164 solver.cpp:397]     Test net output #1: loss = 0.400292 (* 1 = 0.400292 loss)
I1203 16:42:34.046993 12164 solver.cpp:218] Iteration 92000 (10.2203 iter/s, 9.78444s/100 iters), loss = 0.0819374
I1203 16:42:34.046993 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:42:34.046993 12164 solver.cpp:237]     Train net output #1: loss = 0.0819375 (* 1 = 0.0819375 loss)
I1203 16:42:34.046993 12164 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1203 16:42:42.036063 12164 solver.cpp:218] Iteration 92100 (12.5176 iter/s, 7.98873s/100 iters), loss = 0.0658978
I1203 16:42:42.036063 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:42:42.036063 12164 solver.cpp:237]     Train net output #1: loss = 0.0658979 (* 1 = 0.0658979 loss)
I1203 16:42:42.036063 12164 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1203 16:42:50.038183 12164 solver.cpp:218] Iteration 92200 (12.4965 iter/s, 8.00224s/100 iters), loss = 0.17999
I1203 16:42:50.038183 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I1203 16:42:50.038183 12164 solver.cpp:237]     Train net output #1: loss = 0.17999 (* 1 = 0.17999 loss)
I1203 16:42:50.038183 12164 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1203 16:42:58.040979 12164 solver.cpp:218] Iteration 92300 (12.4961 iter/s, 8.00248s/100 iters), loss = 0.0986138
I1203 16:42:58.040979 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:42:58.041980 12164 solver.cpp:237]     Train net output #1: loss = 0.0986139 (* 1 = 0.0986139 loss)
I1203 16:42:58.041980 12164 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1203 16:43:06.045332 12164 solver.cpp:218] Iteration 92400 (12.4939 iter/s, 8.00392s/100 iters), loss = 0.109965
I1203 16:43:06.046331 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:43:06.046331 12164 solver.cpp:237]     Train net output #1: loss = 0.109965 (* 1 = 0.109965 loss)
I1203 16:43:06.046331 12164 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1203 16:43:13.649893  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:43:13.968921 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.caffemodel
I1203 16:43:13.997920 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_92500.solverstate
I1203 16:43:14.003921 12164 solver.cpp:330] Iteration 92500, Testing net (#0)
I1203 16:43:14.003921 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:43:15.684073 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:43:15.750077 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8801
I1203 16:43:15.750077 12164 solver.cpp:397]     Test net output #1: loss = 0.388021 (* 1 = 0.388021 loss)
I1203 16:43:15.825078 12164 solver.cpp:218] Iteration 92500 (10.2266 iter/s, 9.77845s/100 iters), loss = 0.124745
I1203 16:43:15.825078 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:43:15.825078 12164 solver.cpp:237]     Train net output #1: loss = 0.124745 (* 1 = 0.124745 loss)
I1203 16:43:15.825078 12164 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1203 16:43:23.828616 12164 solver.cpp:218] Iteration 92600 (12.4955 iter/s, 8.00291s/100 iters), loss = 0.179751
I1203 16:43:23.828616 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 16:43:23.828616 12164 solver.cpp:237]     Train net output #1: loss = 0.179751 (* 1 = 0.179751 loss)
I1203 16:43:23.828616 12164 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1203 16:43:31.830963 12164 solver.cpp:218] Iteration 92700 (12.4971 iter/s, 8.00188s/100 iters), loss = 0.113797
I1203 16:43:31.830963 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:43:31.830963 12164 solver.cpp:237]     Train net output #1: loss = 0.113798 (* 1 = 0.113798 loss)
I1203 16:43:31.830963 12164 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1203 16:43:39.835916 12164 solver.cpp:218] Iteration 92800 (12.4924 iter/s, 8.00489s/100 iters), loss = 0.0795711
I1203 16:43:39.835916 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:43:39.835916 12164 solver.cpp:237]     Train net output #1: loss = 0.0795711 (* 1 = 0.0795711 loss)
I1203 16:43:39.835916 12164 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1203 16:43:47.831385 12164 solver.cpp:218] Iteration 92900 (12.5083 iter/s, 7.99467s/100 iters), loss = 0.0758272
I1203 16:43:47.831385 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:43:47.831385 12164 solver.cpp:237]     Train net output #1: loss = 0.0758273 (* 1 = 0.0758273 loss)
I1203 16:43:47.831385 12164 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1203 16:43:55.444722  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:43:55.759757 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.caffemodel
I1203 16:43:55.787757 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93000.solverstate
I1203 16:43:55.794757 12164 solver.cpp:330] Iteration 93000, Testing net (#0)
I1203 16:43:55.794757 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:43:57.471909 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:43:57.538920 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8696
I1203 16:43:57.538920 12164 solver.cpp:397]     Test net output #1: loss = 0.427486 (* 1 = 0.427486 loss)
I1203 16:43:57.612920 12164 solver.cpp:218] Iteration 93000 (10.2238 iter/s, 9.7811s/100 iters), loss = 0.0986536
I1203 16:43:57.612920 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:43:57.612920 12164 solver.cpp:237]     Train net output #1: loss = 0.0986537 (* 1 = 0.0986537 loss)
I1203 16:43:57.612920 12164 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1203 16:44:05.613703 12164 solver.cpp:218] Iteration 93100 (12.4996 iter/s, 8.00026s/100 iters), loss = 0.131042
I1203 16:44:05.613703 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:44:05.613703 12164 solver.cpp:237]     Train net output #1: loss = 0.131042 (* 1 = 0.131042 loss)
I1203 16:44:05.613703 12164 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1203 16:44:13.620543 12164 solver.cpp:218] Iteration 93200 (12.49 iter/s, 8.00643s/100 iters), loss = 0.0701001
I1203 16:44:13.620543 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:44:13.620543 12164 solver.cpp:237]     Train net output #1: loss = 0.0701002 (* 1 = 0.0701002 loss)
I1203 16:44:13.620543 12164 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1203 16:44:21.614370 12164 solver.cpp:218] Iteration 93300 (12.5105 iter/s, 7.99326s/100 iters), loss = 0.143994
I1203 16:44:21.614370 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 16:44:21.614370 12164 solver.cpp:237]     Train net output #1: loss = 0.143994 (* 1 = 0.143994 loss)
I1203 16:44:21.614370 12164 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1203 16:44:29.602084 12164 solver.cpp:218] Iteration 93400 (12.5198 iter/s, 7.98737s/100 iters), loss = 0.0784097
I1203 16:44:29.602084 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:44:29.602084 12164 solver.cpp:237]     Train net output #1: loss = 0.0784098 (* 1 = 0.0784098 loss)
I1203 16:44:29.602084 12164 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1203 16:44:37.209174  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:44:37.525205 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.caffemodel
I1203 16:44:37.553208 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_93500.solverstate
I1203 16:44:37.559209 12164 solver.cpp:330] Iteration 93500, Testing net (#0)
I1203 16:44:37.559209 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:44:39.241335 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:44:39.308336 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I1203 16:44:39.308336 12164 solver.cpp:397]     Test net output #1: loss = 0.353174 (* 1 = 0.353174 loss)
I1203 16:44:39.382340 12164 solver.cpp:218] Iteration 93500 (10.2255 iter/s, 9.77947s/100 iters), loss = 0.107997
I1203 16:44:39.382340 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:44:39.382340 12164 solver.cpp:237]     Train net output #1: loss = 0.107997 (* 1 = 0.107997 loss)
I1203 16:44:39.382340 12164 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1203 16:44:47.374228 12164 solver.cpp:218] Iteration 93600 (12.5124 iter/s, 7.99207s/100 iters), loss = 0.158591
I1203 16:44:47.374228 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:44:47.374228 12164 solver.cpp:237]     Train net output #1: loss = 0.158591 (* 1 = 0.158591 loss)
I1203 16:44:47.374228 12164 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1203 16:44:55.376164 12164 solver.cpp:218] Iteration 93700 (12.4975 iter/s, 8.00161s/100 iters), loss = 0.0813127
I1203 16:44:55.377164 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:44:55.377164 12164 solver.cpp:237]     Train net output #1: loss = 0.0813128 (* 1 = 0.0813128 loss)
I1203 16:44:55.377164 12164 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1203 16:45:03.373972 12164 solver.cpp:218] Iteration 93800 (12.5046 iter/s, 7.99706s/100 iters), loss = 0.13435
I1203 16:45:03.373972 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 16:45:03.373972 12164 solver.cpp:237]     Train net output #1: loss = 0.13435 (* 1 = 0.13435 loss)
I1203 16:45:03.373972 12164 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1203 16:45:11.377779 12164 solver.cpp:218] Iteration 93900 (12.4946 iter/s, 8.00347s/100 iters), loss = 0.124564
I1203 16:45:11.377779 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1203 16:45:11.377779 12164 solver.cpp:237]     Train net output #1: loss = 0.124564 (* 1 = 0.124564 loss)
I1203 16:45:11.377779 12164 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1203 16:45:18.987433  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:45:19.303463 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.caffemodel
I1203 16:45:19.336968 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94000.solverstate
I1203 16:45:19.342969 12164 solver.cpp:330] Iteration 94000, Testing net (#0)
I1203 16:45:19.342969 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:45:21.021594 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:45:21.087594 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8673
I1203 16:45:21.087594 12164 solver.cpp:397]     Test net output #1: loss = 0.4441 (* 1 = 0.4441 loss)
I1203 16:45:21.163604 12164 solver.cpp:218] Iteration 94000 (10.2202 iter/s, 9.78458s/100 iters), loss = 0.14476
I1203 16:45:21.163604 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I1203 16:45:21.163604 12164 solver.cpp:237]     Train net output #1: loss = 0.14476 (* 1 = 0.14476 loss)
I1203 16:45:21.163604 12164 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1203 16:45:29.154675 12164 solver.cpp:218] Iteration 94100 (12.5135 iter/s, 7.99135s/100 iters), loss = 0.0910697
I1203 16:45:29.155675 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:45:29.155675 12164 solver.cpp:237]     Train net output #1: loss = 0.0910697 (* 1 = 0.0910697 loss)
I1203 16:45:29.155675 12164 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1203 16:45:37.158028 12164 solver.cpp:218] Iteration 94200 (12.4967 iter/s, 8.00212s/100 iters), loss = 0.0922619
I1203 16:45:37.158028 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:45:37.158028 12164 solver.cpp:237]     Train net output #1: loss = 0.092262 (* 1 = 0.092262 loss)
I1203 16:45:37.158028 12164 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1203 16:45:45.159937 12164 solver.cpp:218] Iteration 94300 (12.4976 iter/s, 8.00155s/100 iters), loss = 0.0919033
I1203 16:45:45.159937 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:45:45.159937 12164 solver.cpp:237]     Train net output #1: loss = 0.0919034 (* 1 = 0.0919034 loss)
I1203 16:45:45.159937 12164 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1203 16:45:53.159582 12164 solver.cpp:218] Iteration 94400 (12.5014 iter/s, 7.99907s/100 iters), loss = 0.0669695
I1203 16:45:53.159582 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:45:53.159582 12164 solver.cpp:237]     Train net output #1: loss = 0.0669695 (* 1 = 0.0669695 loss)
I1203 16:45:53.159582 12164 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1203 16:46:00.765413  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:46:01.082437 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.caffemodel
I1203 16:46:01.110436 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_94500.solverstate
I1203 16:46:01.117439 12164 solver.cpp:330] Iteration 94500, Testing net (#0)
I1203 16:46:01.117439 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:46:02.799600 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:46:02.865613 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8725
I1203 16:46:02.866614 12164 solver.cpp:397]     Test net output #1: loss = 0.417743 (* 1 = 0.417743 loss)
I1203 16:46:02.941620 12164 solver.cpp:218] Iteration 94500 (10.2227 iter/s, 9.78211s/100 iters), loss = 0.101103
I1203 16:46:02.941620 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:46:02.941620 12164 solver.cpp:237]     Train net output #1: loss = 0.101103 (* 1 = 0.101103 loss)
I1203 16:46:02.941620 12164 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1203 16:46:10.940410 12164 solver.cpp:218] Iteration 94600 (12.5042 iter/s, 7.99729s/100 iters), loss = 0.119156
I1203 16:46:10.940410 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:46:10.940410 12164 solver.cpp:237]     Train net output #1: loss = 0.119156 (* 1 = 0.119156 loss)
I1203 16:46:10.940410 12164 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1203 16:46:18.941473 12164 solver.cpp:218] Iteration 94700 (12.498 iter/s, 8.00126s/100 iters), loss = 0.0834675
I1203 16:46:18.942472 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:46:18.942472 12164 solver.cpp:237]     Train net output #1: loss = 0.0834675 (* 1 = 0.0834675 loss)
I1203 16:46:18.942472 12164 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1203 16:46:26.934082 12164 solver.cpp:218] Iteration 94800 (12.5128 iter/s, 7.99179s/100 iters), loss = 0.0649466
I1203 16:46:26.934082 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:46:26.934082 12164 solver.cpp:237]     Train net output #1: loss = 0.0649466 (* 1 = 0.0649466 loss)
I1203 16:46:26.934082 12164 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1203 16:46:34.938206 12164 solver.cpp:218] Iteration 94900 (12.4947 iter/s, 8.00339s/100 iters), loss = 0.0702705
I1203 16:46:34.938206 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:46:34.938206 12164 solver.cpp:237]     Train net output #1: loss = 0.0702705 (* 1 = 0.0702705 loss)
I1203 16:46:34.938206 12164 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1203 16:46:42.549080  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:46:42.866123 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.caffemodel
I1203 16:46:42.895126 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95000.solverstate
I1203 16:46:42.901127 12164 solver.cpp:330] Iteration 95000, Testing net (#0)
I1203 16:46:42.901127 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:46:44.580520 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:46:44.648519 12164 solver.cpp:397]     Test net output #0: accuracy = 0.8985
I1203 16:46:44.648519 12164 solver.cpp:397]     Test net output #1: loss = 0.330285 (* 1 = 0.330285 loss)
I1203 16:46:44.723526 12164 solver.cpp:218] Iteration 95000 (10.2204 iter/s, 9.78434s/100 iters), loss = 0.0968127
I1203 16:46:44.723526 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:46:44.723526 12164 solver.cpp:237]     Train net output #1: loss = 0.0968128 (* 1 = 0.0968128 loss)
I1203 16:46:44.723526 12164 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1203 16:46:44.723526 12164 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1203 16:46:52.730556 12164 solver.cpp:218] Iteration 95100 (12.4902 iter/s, 8.00627s/100 iters), loss = 0.175284
I1203 16:46:52.730556 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1203 16:46:52.730556 12164 solver.cpp:237]     Train net output #1: loss = 0.175284 (* 1 = 0.175284 loss)
I1203 16:46:52.730556 12164 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1203 16:47:00.733587 12164 solver.cpp:218] Iteration 95200 (12.4948 iter/s, 8.00336s/100 iters), loss = 0.0913931
I1203 16:47:00.734587 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:47:00.734587 12164 solver.cpp:237]     Train net output #1: loss = 0.0913931 (* 1 = 0.0913931 loss)
I1203 16:47:00.734587 12164 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1203 16:47:08.727350 12164 solver.cpp:218] Iteration 95300 (12.5119 iter/s, 7.99238s/100 iters), loss = 0.108268
I1203 16:47:08.727350 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1203 16:47:08.727350 12164 solver.cpp:237]     Train net output #1: loss = 0.108268 (* 1 = 0.108268 loss)
I1203 16:47:08.727350 12164 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1203 16:47:16.723152 12164 solver.cpp:218] Iteration 95400 (12.5067 iter/s, 7.99573s/100 iters), loss = 0.0483353
I1203 16:47:16.723152 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:47:16.723152 12164 solver.cpp:237]     Train net output #1: loss = 0.0483353 (* 1 = 0.0483353 loss)
I1203 16:47:16.723152 12164 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1203 16:47:24.328907  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:47:24.644984 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.caffemodel
I1203 16:47:24.671990 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_95500.solverstate
I1203 16:47:24.677991 12164 solver.cpp:330] Iteration 95500, Testing net (#0)
I1203 16:47:24.678491 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:47:26.360107 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:47:26.426113 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9236
I1203 16:47:26.426113 12164 solver.cpp:397]     Test net output #1: loss = 0.240032 (* 1 = 0.240032 loss)
I1203 16:47:26.500135 12164 solver.cpp:218] Iteration 95500 (10.2289 iter/s, 9.77622s/100 iters), loss = 0.052259
I1203 16:47:26.500135 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:47:26.500135 12164 solver.cpp:237]     Train net output #1: loss = 0.052259 (* 1 = 0.052259 loss)
I1203 16:47:26.500135 12164 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1203 16:47:34.502923 12164 solver.cpp:218] Iteration 95600 (12.4955 iter/s, 8.0029s/100 iters), loss = 0.0705072
I1203 16:47:34.502923 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:47:34.502923 12164 solver.cpp:237]     Train net output #1: loss = 0.0705072 (* 1 = 0.0705072 loss)
I1203 16:47:34.502923 12164 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1203 16:47:42.504851 12164 solver.cpp:218] Iteration 95700 (12.4988 iter/s, 8.00078s/100 iters), loss = 0.0811431
I1203 16:47:42.504851 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:47:42.504851 12164 solver.cpp:237]     Train net output #1: loss = 0.0811431 (* 1 = 0.0811431 loss)
I1203 16:47:42.504851 12164 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1203 16:47:50.522567 12164 solver.cpp:218] Iteration 95800 (12.4725 iter/s, 8.01763s/100 iters), loss = 0.0453482
I1203 16:47:50.522567 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:47:50.522567 12164 solver.cpp:237]     Train net output #1: loss = 0.0453483 (* 1 = 0.0453483 loss)
I1203 16:47:50.522567 12164 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1203 16:47:58.520370 12164 solver.cpp:218] Iteration 95900 (12.5046 iter/s, 7.99706s/100 iters), loss = 0.055605
I1203 16:47:58.520370 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:47:58.520370 12164 solver.cpp:237]     Train net output #1: loss = 0.055605 (* 1 = 0.055605 loss)
I1203 16:47:58.520370 12164 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1203 16:48:06.128123  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:48:06.444643 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.caffemodel
I1203 16:48:06.472151 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96000.solverstate
I1203 16:48:06.479152 12164 solver.cpp:330] Iteration 96000, Testing net (#0)
I1203 16:48:06.479152 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:48:08.159291 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:48:08.226290 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9272
I1203 16:48:08.226290 12164 solver.cpp:397]     Test net output #1: loss = 0.232991 (* 1 = 0.232991 loss)
I1203 16:48:08.301295 12164 solver.cpp:218] Iteration 96000 (10.224 iter/s, 9.78086s/100 iters), loss = 0.057256
I1203 16:48:08.301295 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:48:08.301295 12164 solver.cpp:237]     Train net output #1: loss = 0.0572561 (* 1 = 0.0572561 loss)
I1203 16:48:08.301295 12164 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1203 16:48:16.304106 12164 solver.cpp:218] Iteration 96100 (12.4961 iter/s, 8.00249s/100 iters), loss = 0.091482
I1203 16:48:16.304106 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:48:16.304106 12164 solver.cpp:237]     Train net output #1: loss = 0.091482 (* 1 = 0.091482 loss)
I1203 16:48:16.304106 12164 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1203 16:48:24.307845 12164 solver.cpp:218] Iteration 96200 (12.496 iter/s, 8.00257s/100 iters), loss = 0.0638476
I1203 16:48:24.307845 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:48:24.307845 12164 solver.cpp:237]     Train net output #1: loss = 0.0638476 (* 1 = 0.0638476 loss)
I1203 16:48:24.307845 12164 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1203 16:48:32.306689 12164 solver.cpp:218] Iteration 96300 (12.5019 iter/s, 7.99878s/100 iters), loss = 0.0381704
I1203 16:48:32.306689 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:48:32.306689 12164 solver.cpp:237]     Train net output #1: loss = 0.0381704 (* 1 = 0.0381704 loss)
I1203 16:48:32.306689 12164 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1203 16:48:40.309597 12164 solver.cpp:218] Iteration 96400 (12.4965 iter/s, 8.00225s/100 iters), loss = 0.0295597
I1203 16:48:40.309597 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:48:40.309597 12164 solver.cpp:237]     Train net output #1: loss = 0.0295597 (* 1 = 0.0295597 loss)
I1203 16:48:40.309597 12164 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1203 16:48:47.915273  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:48:48.232290 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.caffemodel
I1203 16:48:48.268295 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_96500.solverstate
I1203 16:48:48.274796 12164 solver.cpp:330] Iteration 96500, Testing net (#0)
I1203 16:48:48.274796 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:48:49.954409 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:48:50.020413 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9294
I1203 16:48:50.020413 12164 solver.cpp:397]     Test net output #1: loss = 0.225965 (* 1 = 0.225965 loss)
I1203 16:48:50.096421 12164 solver.cpp:218] Iteration 96500 (10.2177 iter/s, 9.78696s/100 iters), loss = 0.0658378
I1203 16:48:50.097420 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:48:50.097420 12164 solver.cpp:237]     Train net output #1: loss = 0.0658378 (* 1 = 0.0658378 loss)
I1203 16:48:50.097420 12164 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1203 16:48:58.099134 12164 solver.cpp:218] Iteration 96600 (12.4973 iter/s, 8.00173s/100 iters), loss = 0.0620321
I1203 16:48:58.099134 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:48:58.099134 12164 solver.cpp:237]     Train net output #1: loss = 0.0620321 (* 1 = 0.0620321 loss)
I1203 16:48:58.099134 12164 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1203 16:49:06.096480 12164 solver.cpp:218] Iteration 96700 (12.5049 iter/s, 7.99689s/100 iters), loss = 0.0448707
I1203 16:49:06.096982 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:49:06.096982 12164 solver.cpp:237]     Train net output #1: loss = 0.0448707 (* 1 = 0.0448707 loss)
I1203 16:49:06.096982 12164 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1203 16:49:14.089383 12164 solver.cpp:218] Iteration 96800 (12.5122 iter/s, 7.9922s/100 iters), loss = 0.0309391
I1203 16:49:14.089383 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:49:14.089383 12164 solver.cpp:237]     Train net output #1: loss = 0.0309391 (* 1 = 0.0309391 loss)
I1203 16:49:14.089383 12164 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1203 16:49:22.087662 12164 solver.cpp:218] Iteration 96900 (12.5035 iter/s, 7.99775s/100 iters), loss = 0.0489229
I1203 16:49:22.087662 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:49:22.087662 12164 solver.cpp:237]     Train net output #1: loss = 0.0489229 (* 1 = 0.0489229 loss)
I1203 16:49:22.087662 12164 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1203 16:49:29.686448  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:49:30.001480 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.caffemodel
I1203 16:49:30.029484 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97000.solverstate
I1203 16:49:30.035485 12164 solver.cpp:330] Iteration 97000, Testing net (#0)
I1203 16:49:30.035485 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:49:31.713613 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:49:31.779611 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9297
I1203 16:49:31.779611 12164 solver.cpp:397]     Test net output #1: loss = 0.226741 (* 1 = 0.226741 loss)
I1203 16:49:31.855623 12164 solver.cpp:218] Iteration 97000 (10.2378 iter/s, 9.76769s/100 iters), loss = 0.0390012
I1203 16:49:31.855623 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:49:31.855623 12164 solver.cpp:237]     Train net output #1: loss = 0.0390011 (* 1 = 0.0390011 loss)
I1203 16:49:31.855623 12164 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1203 16:49:39.853523 12164 solver.cpp:218] Iteration 97100 (12.5043 iter/s, 7.99725s/100 iters), loss = 0.0516856
I1203 16:49:39.853523 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:49:39.853523 12164 solver.cpp:237]     Train net output #1: loss = 0.0516856 (* 1 = 0.0516856 loss)
I1203 16:49:39.853523 12164 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1203 16:49:47.849267 12164 solver.cpp:218] Iteration 97200 (12.5067 iter/s, 7.99571s/100 iters), loss = 0.0434267
I1203 16:49:47.849267 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:49:47.849267 12164 solver.cpp:237]     Train net output #1: loss = 0.0434267 (* 1 = 0.0434267 loss)
I1203 16:49:47.849267 12164 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1203 16:49:55.843300 12164 solver.cpp:218] Iteration 97300 (12.5112 iter/s, 7.99286s/100 iters), loss = 0.0350808
I1203 16:49:55.843300 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:49:55.843300 12164 solver.cpp:237]     Train net output #1: loss = 0.0350808 (* 1 = 0.0350808 loss)
I1203 16:49:55.843300 12164 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1203 16:50:03.880406 12164 solver.cpp:218] Iteration 97400 (12.4432 iter/s, 8.03649s/100 iters), loss = 0.0138736
I1203 16:50:03.880406 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:50:03.880406 12164 solver.cpp:237]     Train net output #1: loss = 0.0138736 (* 1 = 0.0138736 loss)
I1203 16:50:03.880406 12164 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1203 16:50:11.527624  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:50:11.841743 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.caffemodel
I1203 16:50:11.871785 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_97500.solverstate
I1203 16:50:11.877781 12164 solver.cpp:330] Iteration 97500, Testing net (#0)
I1203 16:50:11.878304 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:50:13.573540 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:50:13.639552 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9308
I1203 16:50:13.639552 12164 solver.cpp:397]     Test net output #1: loss = 0.224139 (* 1 = 0.224139 loss)
I1203 16:50:13.713615 12164 solver.cpp:218] Iteration 97500 (10.1693 iter/s, 9.83351s/100 iters), loss = 0.025082
I1203 16:50:13.714618 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:50:13.714618 12164 solver.cpp:237]     Train net output #1: loss = 0.025082 (* 1 = 0.025082 loss)
I1203 16:50:13.714618 12164 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1203 16:50:21.733156 12164 solver.cpp:218] Iteration 97600 (12.4715 iter/s, 8.01826s/100 iters), loss = 0.071149
I1203 16:50:21.733156 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:50:21.733156 12164 solver.cpp:237]     Train net output #1: loss = 0.071149 (* 1 = 0.071149 loss)
I1203 16:50:21.733156 12164 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1203 16:50:29.751765 12164 solver.cpp:218] Iteration 97700 (12.4713 iter/s, 8.01844s/100 iters), loss = 0.0257761
I1203 16:50:29.751765 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:50:29.751765 12164 solver.cpp:237]     Train net output #1: loss = 0.0257761 (* 1 = 0.0257761 loss)
I1203 16:50:29.751765 12164 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1203 16:50:37.755519 12164 solver.cpp:218] Iteration 97800 (12.4955 iter/s, 8.00289s/100 iters), loss = 0.0253328
I1203 16:50:37.755519 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:50:37.755519 12164 solver.cpp:237]     Train net output #1: loss = 0.0253328 (* 1 = 0.0253328 loss)
I1203 16:50:37.755519 12164 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1203 16:50:45.753298 12164 solver.cpp:218] Iteration 97900 (12.5042 iter/s, 7.99732s/100 iters), loss = 0.0454673
I1203 16:50:45.753298 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:50:45.753298 12164 solver.cpp:237]     Train net output #1: loss = 0.0454672 (* 1 = 0.0454672 loss)
I1203 16:50:45.753298 12164 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1203 16:50:53.364012  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:50:53.679041 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.caffemodel
I1203 16:50:53.707041 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98000.solverstate
I1203 16:50:53.713042 12164 solver.cpp:330] Iteration 98000, Testing net (#0)
I1203 16:50:53.713042 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:50:55.394172 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:50:55.461175 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9284
I1203 16:50:55.461175 12164 solver.cpp:397]     Test net output #1: loss = 0.230153 (* 1 = 0.230153 loss)
I1203 16:50:55.537178 12164 solver.cpp:218] Iteration 98000 (10.2216 iter/s, 9.78319s/100 iters), loss = 0.0365731
I1203 16:50:55.537178 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:50:55.537178 12164 solver.cpp:237]     Train net output #1: loss = 0.036573 (* 1 = 0.036573 loss)
I1203 16:50:55.537178 12164 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1203 16:51:03.528898 12164 solver.cpp:218] Iteration 98100 (12.5128 iter/s, 7.99184s/100 iters), loss = 0.0827992
I1203 16:51:03.528898 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:51:03.528898 12164 solver.cpp:237]     Train net output #1: loss = 0.0827992 (* 1 = 0.0827992 loss)
I1203 16:51:03.528898 12164 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1203 16:51:11.536885 12164 solver.cpp:218] Iteration 98200 (12.4885 iter/s, 8.00739s/100 iters), loss = 0.0511356
I1203 16:51:11.536885 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:51:11.536885 12164 solver.cpp:237]     Train net output #1: loss = 0.0511355 (* 1 = 0.0511355 loss)
I1203 16:51:11.536885 12164 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1203 16:51:19.533885 12164 solver.cpp:218] Iteration 98300 (12.5047 iter/s, 7.997s/100 iters), loss = 0.0388204
I1203 16:51:19.534874 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:51:19.534874 12164 solver.cpp:237]     Train net output #1: loss = 0.0388203 (* 1 = 0.0388203 loss)
I1203 16:51:19.534874 12164 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1203 16:51:27.534919 12164 solver.cpp:218] Iteration 98400 (12.4998 iter/s, 8.00013s/100 iters), loss = 0.0183214
I1203 16:51:27.534919 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:51:27.534919 12164 solver.cpp:237]     Train net output #1: loss = 0.0183213 (* 1 = 0.0183213 loss)
I1203 16:51:27.534919 12164 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1203 16:51:35.159396  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:51:35.475566 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.caffemodel
I1203 16:51:35.504611 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_98500.solverstate
I1203 16:51:35.510607 12164 solver.cpp:330] Iteration 98500, Testing net (#0)
I1203 16:51:35.510607 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:51:37.193362 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:51:37.260970 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9307
I1203 16:51:37.260970 12164 solver.cpp:397]     Test net output #1: loss = 0.232643 (* 1 = 0.232643 loss)
I1203 16:51:37.335333 12164 solver.cpp:218] Iteration 98500 (10.2041 iter/s, 9.8s/100 iters), loss = 0.0310608
I1203 16:51:37.335333 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:51:37.335333 12164 solver.cpp:237]     Train net output #1: loss = 0.0310608 (* 1 = 0.0310608 loss)
I1203 16:51:37.335333 12164 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1203 16:51:45.353230 12164 solver.cpp:218] Iteration 98600 (12.473 iter/s, 8.01731s/100 iters), loss = 0.0569323
I1203 16:51:45.353230 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:51:45.353230 12164 solver.cpp:237]     Train net output #1: loss = 0.0569323 (* 1 = 0.0569323 loss)
I1203 16:51:45.353230 12164 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1203 16:51:53.372100 12164 solver.cpp:218] Iteration 98700 (12.4719 iter/s, 8.01802s/100 iters), loss = 0.0439746
I1203 16:51:53.372100 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:51:53.372100 12164 solver.cpp:237]     Train net output #1: loss = 0.0439746 (* 1 = 0.0439746 loss)
I1203 16:51:53.372100 12164 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1203 16:52:01.383235 12164 solver.cpp:218] Iteration 98800 (12.483 iter/s, 8.01089s/100 iters), loss = 0.0199885
I1203 16:52:01.383235 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:52:01.383235 12164 solver.cpp:237]     Train net output #1: loss = 0.0199885 (* 1 = 0.0199885 loss)
I1203 16:52:01.383235 12164 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1203 16:52:09.385537 12164 solver.cpp:218] Iteration 98900 (12.4972 iter/s, 8.0018s/100 iters), loss = 0.0161256
I1203 16:52:09.385537 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:52:09.385537 12164 solver.cpp:237]     Train net output #1: loss = 0.0161255 (* 1 = 0.0161255 loss)
I1203 16:52:09.385537 12164 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1203 16:52:16.999418  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:52:17.314452 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.caffemodel
I1203 16:52:17.341454 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99000.solverstate
I1203 16:52:17.347453 12164 solver.cpp:330] Iteration 99000, Testing net (#0)
I1203 16:52:17.348454 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:52:19.028414 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:52:19.094964 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9308
I1203 16:52:19.094964 12164 solver.cpp:397]     Test net output #1: loss = 0.227899 (* 1 = 0.227899 loss)
I1203 16:52:19.170948 12164 solver.cpp:218] Iteration 99000 (10.2192 iter/s, 9.78551s/100 iters), loss = 0.0328485
I1203 16:52:19.171947 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:52:19.171947 12164 solver.cpp:237]     Train net output #1: loss = 0.0328484 (* 1 = 0.0328484 loss)
I1203 16:52:19.171947 12164 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1203 16:52:27.163287 12164 solver.cpp:218] Iteration 99100 (12.5133 iter/s, 7.99148s/100 iters), loss = 0.0434978
I1203 16:52:27.163287 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:52:27.163287 12164 solver.cpp:237]     Train net output #1: loss = 0.0434977 (* 1 = 0.0434977 loss)
I1203 16:52:27.163287 12164 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1203 16:52:35.146505 12164 solver.cpp:218] Iteration 99200 (12.5275 iter/s, 7.98242s/100 iters), loss = 0.0223051
I1203 16:52:35.146505 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:52:35.146505 12164 solver.cpp:237]     Train net output #1: loss = 0.022305 (* 1 = 0.022305 loss)
I1203 16:52:35.146505 12164 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1203 16:52:43.136055 12164 solver.cpp:218] Iteration 99300 (12.5174 iter/s, 7.98886s/100 iters), loss = 0.0183433
I1203 16:52:43.136055 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:52:43.136055 12164 solver.cpp:237]     Train net output #1: loss = 0.0183433 (* 1 = 0.0183433 loss)
I1203 16:52:43.136055 12164 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1203 16:52:51.139508 12164 solver.cpp:218] Iteration 99400 (12.4949 iter/s, 8.00326s/100 iters), loss = 0.0240903
I1203 16:52:51.139508 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:52:51.139508 12164 solver.cpp:237]     Train net output #1: loss = 0.0240902 (* 1 = 0.0240902 loss)
I1203 16:52:51.139508 12164 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1203 16:52:58.749207  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:52:59.065241 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.caffemodel
I1203 16:52:59.092242 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_99500.solverstate
I1203 16:52:59.098242 12164 solver.cpp:330] Iteration 99500, Testing net (#0)
I1203 16:52:59.098242 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:53:00.778375 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:53:00.844378 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1203 16:53:00.844378 12164 solver.cpp:397]     Test net output #1: loss = 0.228821 (* 1 = 0.228821 loss)
I1203 16:53:00.921381 12164 solver.cpp:218] Iteration 99500 (10.2235 iter/s, 9.78134s/100 iters), loss = 0.0502926
I1203 16:53:00.921381 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:53:00.921381 12164 solver.cpp:237]     Train net output #1: loss = 0.0502925 (* 1 = 0.0502925 loss)
I1203 16:53:00.921381 12164 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1203 16:53:08.924054 12164 solver.cpp:218] Iteration 99600 (12.4963 iter/s, 8.00234s/100 iters), loss = 0.0536473
I1203 16:53:08.924554 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:53:08.924554 12164 solver.cpp:237]     Train net output #1: loss = 0.0536473 (* 1 = 0.0536473 loss)
I1203 16:53:08.924554 12164 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1203 16:53:16.938462 12164 solver.cpp:218] Iteration 99700 (12.4785 iter/s, 8.01381s/100 iters), loss = 0.0327664
I1203 16:53:16.938462 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:53:16.938962 12164 solver.cpp:237]     Train net output #1: loss = 0.0327663 (* 1 = 0.0327663 loss)
I1203 16:53:16.938962 12164 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1203 16:53:24.944746 12164 solver.cpp:218] Iteration 99800 (12.4904 iter/s, 8.00612s/100 iters), loss = 0.0291728
I1203 16:53:24.944746 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:53:24.945742 12164 solver.cpp:237]     Train net output #1: loss = 0.0291728 (* 1 = 0.0291728 loss)
I1203 16:53:24.945742 12164 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1203 16:53:32.948554 12164 solver.cpp:218] Iteration 99900 (12.4966 iter/s, 8.00217s/100 iters), loss = 0.0240568
I1203 16:53:32.948554 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:53:32.948554 12164 solver.cpp:237]     Train net output #1: loss = 0.0240567 (* 1 = 0.0240567 loss)
I1203 16:53:32.948554 12164 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1203 16:53:40.555301  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:53:40.872319 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.caffemodel
I1203 16:53:40.907320 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100000.solverstate
I1203 16:53:40.913319 12164 solver.cpp:330] Iteration 100000, Testing net (#0)
I1203 16:53:40.913319 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:53:42.592473 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:53:42.660480 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9315
I1203 16:53:42.660480 12164 solver.cpp:397]     Test net output #1: loss = 0.231187 (* 1 = 0.231187 loss)
I1203 16:53:42.734483 12164 solver.cpp:218] Iteration 100000 (10.219 iter/s, 9.78568s/100 iters), loss = 0.0342384
I1203 16:53:42.734483 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:53:42.734982 12164 solver.cpp:237]     Train net output #1: loss = 0.0342383 (* 1 = 0.0342383 loss)
I1203 16:53:42.734982 12164 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1203 16:53:50.733203 12164 solver.cpp:218] Iteration 100100 (12.5034 iter/s, 7.99786s/100 iters), loss = 0.0473968
I1203 16:53:50.733203 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:53:50.733203 12164 solver.cpp:237]     Train net output #1: loss = 0.0473967 (* 1 = 0.0473967 loss)
I1203 16:53:50.733203 12164 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1203 16:53:58.739176 12164 solver.cpp:218] Iteration 100200 (12.491 iter/s, 8.00576s/100 iters), loss = 0.0531637
I1203 16:53:58.739176 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:53:58.739176 12164 solver.cpp:237]     Train net output #1: loss = 0.0531636 (* 1 = 0.0531636 loss)
I1203 16:53:58.739176 12164 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1203 16:54:06.738020 12164 solver.cpp:218] Iteration 100300 (12.5027 iter/s, 7.99827s/100 iters), loss = 0.0334199
I1203 16:54:06.738020 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:54:06.738020 12164 solver.cpp:237]     Train net output #1: loss = 0.0334198 (* 1 = 0.0334198 loss)
I1203 16:54:06.738020 12164 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1203 16:54:14.740432 12164 solver.cpp:218] Iteration 100400 (12.4969 iter/s, 8.00198s/100 iters), loss = 0.0139569
I1203 16:54:14.740432 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:54:14.740432 12164 solver.cpp:237]     Train net output #1: loss = 0.0139568 (* 1 = 0.0139568 loss)
I1203 16:54:14.740432 12164 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1203 16:54:22.347717  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:54:22.662765 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.caffemodel
I1203 16:54:22.690764 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_100500.solverstate
I1203 16:54:22.696765 12164 solver.cpp:330] Iteration 100500, Testing net (#0)
I1203 16:54:22.696765 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:54:24.377952 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:54:24.444949 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9317
I1203 16:54:24.444949 12164 solver.cpp:397]     Test net output #1: loss = 0.229826 (* 1 = 0.229826 loss)
I1203 16:54:24.518954 12164 solver.cpp:218] Iteration 100500 (10.2269 iter/s, 9.77817s/100 iters), loss = 0.0402434
I1203 16:54:24.518954 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:54:24.518954 12164 solver.cpp:237]     Train net output #1: loss = 0.0402433 (* 1 = 0.0402433 loss)
I1203 16:54:24.518954 12164 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1203 16:54:32.512333 12164 solver.cpp:218] Iteration 100600 (12.5116 iter/s, 7.9926s/100 iters), loss = 0.0398003
I1203 16:54:32.512333 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:54:32.512333 12164 solver.cpp:237]     Train net output #1: loss = 0.0398002 (* 1 = 0.0398002 loss)
I1203 16:54:32.512333 12164 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1203 16:54:40.513471 12164 solver.cpp:218] Iteration 100700 (12.499 iter/s, 8.00064s/100 iters), loss = 0.0132976
I1203 16:54:40.513471 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:54:40.513471 12164 solver.cpp:237]     Train net output #1: loss = 0.0132975 (* 1 = 0.0132975 loss)
I1203 16:54:40.513471 12164 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1203 16:54:48.514152 12164 solver.cpp:218] Iteration 100800 (12.4992 iter/s, 8.0005s/100 iters), loss = 0.0235883
I1203 16:54:48.514152 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:54:48.514152 12164 solver.cpp:237]     Train net output #1: loss = 0.0235883 (* 1 = 0.0235883 loss)
I1203 16:54:48.514152 12164 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1203 16:54:56.516366 12164 solver.cpp:218] Iteration 100900 (12.4979 iter/s, 8.00137s/100 iters), loss = 0.0155211
I1203 16:54:56.516366 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:54:56.516366 12164 solver.cpp:237]     Train net output #1: loss = 0.015521 (* 1 = 0.015521 loss)
I1203 16:54:56.516366 12164 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1203 16:55:04.126489  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:55:04.440642 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.caffemodel
I1203 16:55:04.473642 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101000.solverstate
I1203 16:55:04.479641 12164 solver.cpp:330] Iteration 101000, Testing net (#0)
I1203 16:55:04.479641 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:55:06.159478 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:55:06.226997 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9314
I1203 16:55:06.226997 12164 solver.cpp:397]     Test net output #1: loss = 0.23258 (* 1 = 0.23258 loss)
I1203 16:55:06.301196 12164 solver.cpp:218] Iteration 101000 (10.2203 iter/s, 9.78441s/100 iters), loss = 0.0196448
I1203 16:55:06.301196 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:55:06.301196 12164 solver.cpp:237]     Train net output #1: loss = 0.0196447 (* 1 = 0.0196447 loss)
I1203 16:55:06.301196 12164 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1203 16:55:14.308017 12164 solver.cpp:218] Iteration 101100 (12.4889 iter/s, 8.00711s/100 iters), loss = 0.04036
I1203 16:55:14.308017 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:55:14.308017 12164 solver.cpp:237]     Train net output #1: loss = 0.0403599 (* 1 = 0.0403599 loss)
I1203 16:55:14.308017 12164 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1203 16:55:22.313469 12164 solver.cpp:218] Iteration 101200 (12.4935 iter/s, 8.00413s/100 iters), loss = 0.0288447
I1203 16:55:22.313469 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:55:22.313469 12164 solver.cpp:237]     Train net output #1: loss = 0.0288447 (* 1 = 0.0288447 loss)
I1203 16:55:22.313469 12164 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1203 16:55:30.320183 12164 solver.cpp:218] Iteration 101300 (12.4894 iter/s, 8.0068s/100 iters), loss = 0.0176771
I1203 16:55:30.320183 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:55:30.320183 12164 solver.cpp:237]     Train net output #1: loss = 0.0176771 (* 1 = 0.0176771 loss)
I1203 16:55:30.320183 12164 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1203 16:55:38.318900 12164 solver.cpp:218] Iteration 101400 (12.5023 iter/s, 7.99854s/100 iters), loss = 0.0147032
I1203 16:55:38.318900 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:55:38.319900 12164 solver.cpp:237]     Train net output #1: loss = 0.0147031 (* 1 = 0.0147031 loss)
I1203 16:55:38.319900 12164 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1203 16:55:45.916671  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:55:46.231712 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.caffemodel
I1203 16:55:46.263720 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_101500.solverstate
I1203 16:55:46.269721 12164 solver.cpp:330] Iteration 101500, Testing net (#0)
I1203 16:55:46.269721 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:55:47.948870 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:55:48.014871 12164 solver.cpp:397]     Test net output #0: accuracy = 0.932
I1203 16:55:48.014871 12164 solver.cpp:397]     Test net output #1: loss = 0.228668 (* 1 = 0.228668 loss)
I1203 16:55:48.089879 12164 solver.cpp:218] Iteration 101500 (10.235 iter/s, 9.77043s/100 iters), loss = 0.0254062
I1203 16:55:48.089879 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:55:48.089879 12164 solver.cpp:237]     Train net output #1: loss = 0.0254062 (* 1 = 0.0254062 loss)
I1203 16:55:48.089879 12164 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1203 16:55:56.089845 12164 solver.cpp:218] Iteration 101600 (12.5014 iter/s, 7.99911s/100 iters), loss = 0.0762688
I1203 16:55:56.089845 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:55:56.089845 12164 solver.cpp:237]     Train net output #1: loss = 0.0762688 (* 1 = 0.0762688 loss)
I1203 16:55:56.089845 12164 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1203 16:56:04.095878 12164 solver.cpp:218] Iteration 101700 (12.4912 iter/s, 8.00565s/100 iters), loss = 0.0528301
I1203 16:56:04.095878 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:56:04.095878 12164 solver.cpp:237]     Train net output #1: loss = 0.05283 (* 1 = 0.05283 loss)
I1203 16:56:04.095878 12164 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1203 16:56:12.101013 12164 solver.cpp:218] Iteration 101800 (12.493 iter/s, 8.00451s/100 iters), loss = 0.0254376
I1203 16:56:12.101013 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:56:12.101013 12164 solver.cpp:237]     Train net output #1: loss = 0.0254375 (* 1 = 0.0254375 loss)
I1203 16:56:12.101013 12164 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1203 16:56:20.100740 12164 solver.cpp:218] Iteration 101900 (12.5006 iter/s, 7.99961s/100 iters), loss = 0.0212551
I1203 16:56:20.100740 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:56:20.100740 12164 solver.cpp:237]     Train net output #1: loss = 0.0212551 (* 1 = 0.0212551 loss)
I1203 16:56:20.100740 12164 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1203 16:56:27.715463  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:56:28.033493 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.caffemodel
I1203 16:56:28.062491 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102000.solverstate
I1203 16:56:28.068998 12164 solver.cpp:330] Iteration 102000, Testing net (#0)
I1203 16:56:28.069499 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:56:29.747617 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:56:29.815625 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1203 16:56:29.815625 12164 solver.cpp:397]     Test net output #1: loss = 0.231467 (* 1 = 0.231467 loss)
I1203 16:56:29.889631 12164 solver.cpp:218] Iteration 102000 (10.2166 iter/s, 9.78802s/100 iters), loss = 0.0332971
I1203 16:56:29.889631 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:56:29.889631 12164 solver.cpp:237]     Train net output #1: loss = 0.033297 (* 1 = 0.033297 loss)
I1203 16:56:29.889631 12164 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1203 16:56:37.889398 12164 solver.cpp:218] Iteration 102100 (12.5009 iter/s, 7.9994s/100 iters), loss = 0.0324531
I1203 16:56:37.889398 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:56:37.889398 12164 solver.cpp:237]     Train net output #1: loss = 0.0324531 (* 1 = 0.0324531 loss)
I1203 16:56:37.889398 12164 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1203 16:56:45.878350 12164 solver.cpp:218] Iteration 102200 (12.5184 iter/s, 7.98825s/100 iters), loss = 0.0424235
I1203 16:56:45.878350 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:56:45.878350 12164 solver.cpp:237]     Train net output #1: loss = 0.0424235 (* 1 = 0.0424235 loss)
I1203 16:56:45.878350 12164 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1203 16:56:53.885090 12164 solver.cpp:218] Iteration 102300 (12.4892 iter/s, 8.00693s/100 iters), loss = 0.0129318
I1203 16:56:53.886090 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:56:53.886090 12164 solver.cpp:237]     Train net output #1: loss = 0.0129318 (* 1 = 0.0129318 loss)
I1203 16:56:53.886090 12164 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1203 16:57:01.886955 12164 solver.cpp:218] Iteration 102400 (12.4979 iter/s, 8.00136s/100 iters), loss = 0.0204697
I1203 16:57:01.887955 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:57:01.887955 12164 solver.cpp:237]     Train net output #1: loss = 0.0204696 (* 1 = 0.0204696 loss)
I1203 16:57:01.887955 12164 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1203 16:57:09.539767  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:57:09.856827 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.caffemodel
I1203 16:57:09.884831 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_102500.solverstate
I1203 16:57:09.890836 12164 solver.cpp:330] Iteration 102500, Testing net (#0)
I1203 16:57:09.890836 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:57:11.571954 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:57:11.637954 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1203 16:57:11.637954 12164 solver.cpp:397]     Test net output #1: loss = 0.228888 (* 1 = 0.228888 loss)
I1203 16:57:11.712962 12164 solver.cpp:218] Iteration 102500 (10.178 iter/s, 9.82513s/100 iters), loss = 0.0226037
I1203 16:57:11.712962 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:57:11.712962 12164 solver.cpp:237]     Train net output #1: loss = 0.0226036 (* 1 = 0.0226036 loss)
I1203 16:57:11.712962 12164 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1203 16:57:19.731899 12164 solver.cpp:218] Iteration 102600 (12.4716 iter/s, 8.0182s/100 iters), loss = 0.0430836
I1203 16:57:19.731899 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:57:19.731899 12164 solver.cpp:237]     Train net output #1: loss = 0.0430836 (* 1 = 0.0430836 loss)
I1203 16:57:19.731899 12164 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1203 16:57:27.727643 12164 solver.cpp:218] Iteration 102700 (12.5067 iter/s, 7.99571s/100 iters), loss = 0.0369934
I1203 16:57:27.727643 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:57:27.727643 12164 solver.cpp:237]     Train net output #1: loss = 0.0369933 (* 1 = 0.0369933 loss)
I1203 16:57:27.727643 12164 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1203 16:57:35.843682 12164 solver.cpp:218] Iteration 102800 (12.3226 iter/s, 8.11515s/100 iters), loss = 0.0248356
I1203 16:57:35.843682 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:57:35.843682 12164 solver.cpp:237]     Train net output #1: loss = 0.0248356 (* 1 = 0.0248356 loss)
I1203 16:57:35.843682 12164 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1203 16:57:43.956511 12164 solver.cpp:218] Iteration 102900 (12.3274 iter/s, 8.11199s/100 iters), loss = 0.013808
I1203 16:57:43.956511 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:57:43.956511 12164 solver.cpp:237]     Train net output #1: loss = 0.013808 (* 1 = 0.013808 loss)
I1203 16:57:43.956511 12164 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1203 16:57:51.610695  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:57:51.925722 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.caffemodel
I1203 16:57:51.960722 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103000.solverstate
I1203 16:57:51.966732 12164 solver.cpp:330] Iteration 103000, Testing net (#0)
I1203 16:57:51.966732 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:57:53.659878 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:57:53.726887 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1203 16:57:53.726887 12164 solver.cpp:397]     Test net output #1: loss = 0.230012 (* 1 = 0.230012 loss)
I1203 16:57:53.800887 12164 solver.cpp:218] Iteration 103000 (10.1585 iter/s, 9.84402s/100 iters), loss = 0.0395981
I1203 16:57:53.800887 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:57:53.800887 12164 solver.cpp:237]     Train net output #1: loss = 0.0395981 (* 1 = 0.0395981 loss)
I1203 16:57:53.800887 12164 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1203 16:58:01.906235 12164 solver.cpp:218] Iteration 103100 (12.3382 iter/s, 8.10494s/100 iters), loss = 0.0336736
I1203 16:58:01.906235 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:58:01.906735 12164 solver.cpp:237]     Train net output #1: loss = 0.0336735 (* 1 = 0.0336735 loss)
I1203 16:58:01.906735 12164 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1203 16:58:09.916741 12164 solver.cpp:218] Iteration 103200 (12.4845 iter/s, 8.00991s/100 iters), loss = 0.0173667
I1203 16:58:09.916741 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:58:09.916741 12164 solver.cpp:237]     Train net output #1: loss = 0.0173667 (* 1 = 0.0173667 loss)
I1203 16:58:09.916741 12164 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1203 16:58:17.927449 12164 solver.cpp:218] Iteration 103300 (12.4834 iter/s, 8.01062s/100 iters), loss = 0.0155158
I1203 16:58:17.927449 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:58:17.927449 12164 solver.cpp:237]     Train net output #1: loss = 0.0155157 (* 1 = 0.0155157 loss)
I1203 16:58:17.927449 12164 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1203 16:58:26.060330 12164 solver.cpp:218] Iteration 103400 (12.2964 iter/s, 8.13244s/100 iters), loss = 0.0137611
I1203 16:58:26.060330 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:58:26.060330 12164 solver.cpp:237]     Train net output #1: loss = 0.013761 (* 1 = 0.013761 loss)
I1203 16:58:26.060330 12164 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1203 16:58:33.689152  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:58:34.004196 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.caffemodel
I1203 16:58:34.036700 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_103500.solverstate
I1203 16:58:34.042701 12164 solver.cpp:330] Iteration 103500, Testing net (#0)
I1203 16:58:34.043201 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:58:35.727394 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:58:35.793396 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1203 16:58:35.793396 12164 solver.cpp:397]     Test net output #1: loss = 0.228674 (* 1 = 0.228674 loss)
I1203 16:58:35.870404 12164 solver.cpp:218] Iteration 103500 (10.1947 iter/s, 9.80899s/100 iters), loss = 0.0182072
I1203 16:58:35.870404 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:58:35.870404 12164 solver.cpp:237]     Train net output #1: loss = 0.0182072 (* 1 = 0.0182072 loss)
I1203 16:58:35.870404 12164 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1203 16:58:43.960443 12164 solver.cpp:218] Iteration 103600 (12.361 iter/s, 8.08998s/100 iters), loss = 0.0326096
I1203 16:58:43.960443 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:58:43.960443 12164 solver.cpp:237]     Train net output #1: loss = 0.0326096 (* 1 = 0.0326096 loss)
I1203 16:58:43.960443 12164 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1203 16:58:52.050235 12164 solver.cpp:218] Iteration 103700 (12.3616 iter/s, 8.0896s/100 iters), loss = 0.0379667
I1203 16:58:52.051234 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:58:52.051234 12164 solver.cpp:237]     Train net output #1: loss = 0.0379667 (* 1 = 0.0379667 loss)
I1203 16:58:52.051234 12164 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1203 16:59:00.083604 12164 solver.cpp:218] Iteration 103800 (12.4499 iter/s, 8.03219s/100 iters), loss = 0.0222517
I1203 16:59:00.083604 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:59:00.083604 12164 solver.cpp:237]     Train net output #1: loss = 0.0222517 (* 1 = 0.0222517 loss)
I1203 16:59:00.083604 12164 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1203 16:59:08.236315 12164 solver.cpp:218] Iteration 103900 (12.2659 iter/s, 8.15271s/100 iters), loss = 0.0294626
I1203 16:59:08.236315 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:59:08.236315 12164 solver.cpp:237]     Train net output #1: loss = 0.0294626 (* 1 = 0.0294626 loss)
I1203 16:59:08.236315 12164 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1203 16:59:15.879081  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:59:16.194115 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.caffemodel
I1203 16:59:16.221135 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104000.solverstate
I1203 16:59:16.227131 12164 solver.cpp:330] Iteration 104000, Testing net (#0)
I1203 16:59:16.227131 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:59:17.905280 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:59:17.973282 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1203 16:59:17.973282 12164 solver.cpp:397]     Test net output #1: loss = 0.23023 (* 1 = 0.23023 loss)
I1203 16:59:18.047286 12164 solver.cpp:218] Iteration 104000 (10.1936 iter/s, 9.81006s/100 iters), loss = 0.0227769
I1203 16:59:18.047286 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:59:18.047286 12164 solver.cpp:237]     Train net output #1: loss = 0.0227768 (* 1 = 0.0227768 loss)
I1203 16:59:18.047286 12164 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1203 16:59:26.034068 12164 solver.cpp:218] Iteration 104100 (12.5219 iter/s, 7.98602s/100 iters), loss = 0.0731124
I1203 16:59:26.034068 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1203 16:59:26.034068 12164 solver.cpp:237]     Train net output #1: loss = 0.0731123 (* 1 = 0.0731123 loss)
I1203 16:59:26.034068 12164 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1203 16:59:34.021821 12164 solver.cpp:218] Iteration 104200 (12.5196 iter/s, 7.9875s/100 iters), loss = 0.0508688
I1203 16:59:34.021821 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 16:59:34.021821 12164 solver.cpp:237]     Train net output #1: loss = 0.0508687 (* 1 = 0.0508687 loss)
I1203 16:59:34.021821 12164 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1203 16:59:42.019634 12164 solver.cpp:218] Iteration 104300 (12.5035 iter/s, 7.99777s/100 iters), loss = 0.0164488
I1203 16:59:42.020635 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:59:42.020635 12164 solver.cpp:237]     Train net output #1: loss = 0.0164487 (* 1 = 0.0164487 loss)
I1203 16:59:42.020635 12164 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1203 16:59:50.016669 12164 solver.cpp:218] Iteration 104400 (12.5066 iter/s, 7.9958s/100 iters), loss = 0.0180765
I1203 16:59:50.016669 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 16:59:50.016669 12164 solver.cpp:237]     Train net output #1: loss = 0.0180764 (* 1 = 0.0180764 loss)
I1203 16:59:50.016669 12164 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1203 16:59:57.667456  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:59:57.990000 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.caffemodel
I1203 16:59:58.018503 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_104500.solverstate
I1203 16:59:58.024504 12164 solver.cpp:330] Iteration 104500, Testing net (#0)
I1203 16:59:58.024504 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 16:59:59.716703 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 16:59:59.784207 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 16:59:59.784207 12164 solver.cpp:397]     Test net output #1: loss = 0.230272 (* 1 = 0.230272 loss)
I1203 16:59:59.860710 12164 solver.cpp:218] Iteration 104500 (10.1585 iter/s, 9.84393s/100 iters), loss = 0.0318532
I1203 16:59:59.860710 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 16:59:59.860710 12164 solver.cpp:237]     Train net output #1: loss = 0.0318532 (* 1 = 0.0318532 loss)
I1203 16:59:59.860710 12164 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1203 17:00:07.966555 12164 solver.cpp:218] Iteration 104600 (12.337 iter/s, 8.10571s/100 iters), loss = 0.0337119
I1203 17:00:07.967556 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:07.967556 12164 solver.cpp:237]     Train net output #1: loss = 0.0337119 (* 1 = 0.0337119 loss)
I1203 17:00:07.967556 12164 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1203 17:00:16.326102 12164 solver.cpp:218] Iteration 104700 (11.9634 iter/s, 8.3588s/100 iters), loss = 0.0189477
I1203 17:00:16.326102 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:16.326102 12164 solver.cpp:237]     Train net output #1: loss = 0.0189476 (* 1 = 0.0189476 loss)
I1203 17:00:16.326102 12164 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1203 17:00:24.881273 12164 solver.cpp:218] Iteration 104800 (11.69 iter/s, 8.55434s/100 iters), loss = 0.0192461
I1203 17:00:24.881772 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:24.881772 12164 solver.cpp:237]     Train net output #1: loss = 0.019246 (* 1 = 0.019246 loss)
I1203 17:00:24.881772 12164 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1203 17:00:33.220896 12164 solver.cpp:218] Iteration 104900 (11.9925 iter/s, 8.33851s/100 iters), loss = 0.0185221
I1203 17:00:33.220896 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:33.220896 12164 solver.cpp:237]     Train net output #1: loss = 0.0185221 (* 1 = 0.0185221 loss)
I1203 17:00:33.220896 12164 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1203 17:00:41.081620  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:00:41.398905 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.caffemodel
I1203 17:00:41.432904 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105000.solverstate
I1203 17:00:41.438922 12164 solver.cpp:330] Iteration 105000, Testing net (#0)
I1203 17:00:41.438922 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:00:43.155489 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:00:43.224032 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 17:00:43.224032 12164 solver.cpp:397]     Test net output #1: loss = 0.232686 (* 1 = 0.232686 loss)
I1203 17:00:43.303071 12164 solver.cpp:218] Iteration 105000 (9.91915 iter/s, 10.0815s/100 iters), loss = 0.0340192
I1203 17:00:43.303071 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:43.303071 12164 solver.cpp:237]     Train net output #1: loss = 0.0340191 (* 1 = 0.0340191 loss)
I1203 17:00:43.303071 12164 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1203 17:00:51.520541 12164 solver.cpp:218] Iteration 105100 (12.1688 iter/s, 8.21776s/100 iters), loss = 0.0228467
I1203 17:00:51.521543 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:51.521543 12164 solver.cpp:237]     Train net output #1: loss = 0.0228467 (* 1 = 0.0228467 loss)
I1203 17:00:51.521543 12164 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1203 17:00:59.744680 12164 solver.cpp:218] Iteration 105200 (12.1608 iter/s, 8.22318s/100 iters), loss = 0.0301096
I1203 17:00:59.744680 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:00:59.744680 12164 solver.cpp:237]     Train net output #1: loss = 0.0301096 (* 1 = 0.0301096 loss)
I1203 17:00:59.744680 12164 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1203 17:01:07.973748 12164 solver.cpp:218] Iteration 105300 (12.1521 iter/s, 8.22901s/100 iters), loss = 0.0148087
I1203 17:01:07.974748 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:01:07.974748 12164 solver.cpp:237]     Train net output #1: loss = 0.0148086 (* 1 = 0.0148086 loss)
I1203 17:01:07.974748 12164 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1203 17:01:16.176467 12164 solver.cpp:218] Iteration 105400 (12.1929 iter/s, 8.20147s/100 iters), loss = 0.0332657
I1203 17:01:16.176467 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:01:16.176467 12164 solver.cpp:237]     Train net output #1: loss = 0.0332656 (* 1 = 0.0332656 loss)
I1203 17:01:16.176467 12164 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1203 17:01:23.966539  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:01:24.292575 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.caffemodel
I1203 17:01:24.322577 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_105500.solverstate
I1203 17:01:24.328583 12164 solver.cpp:330] Iteration 105500, Testing net (#0)
I1203 17:01:24.328583 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:01:26.056757 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:01:26.124760 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1203 17:01:26.124760 12164 solver.cpp:397]     Test net output #1: loss = 0.235387 (* 1 = 0.235387 loss)
I1203 17:01:26.201766 12164 solver.cpp:218] Iteration 105500 (9.97551 iter/s, 10.0245s/100 iters), loss = 0.0252141
I1203 17:01:26.201766 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:01:26.201766 12164 solver.cpp:237]     Train net output #1: loss = 0.025214 (* 1 = 0.025214 loss)
I1203 17:01:26.201766 12164 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1203 17:01:34.390830 12164 solver.cpp:218] Iteration 105600 (12.2123 iter/s, 8.18848s/100 iters), loss = 0.0607895
I1203 17:01:34.390830 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:01:34.390830 12164 solver.cpp:237]     Train net output #1: loss = 0.0607895 (* 1 = 0.0607895 loss)
I1203 17:01:34.390830 12164 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1203 17:01:42.566726 12164 solver.cpp:218] Iteration 105700 (12.2307 iter/s, 8.17616s/100 iters), loss = 0.049802
I1203 17:01:42.566726 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:01:42.566726 12164 solver.cpp:237]     Train net output #1: loss = 0.049802 (* 1 = 0.049802 loss)
I1203 17:01:42.566726 12164 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1203 17:01:50.744585 12164 solver.cpp:218] Iteration 105800 (12.2293 iter/s, 8.1771s/100 iters), loss = 0.0140902
I1203 17:01:50.744585 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:01:50.744585 12164 solver.cpp:237]     Train net output #1: loss = 0.0140902 (* 1 = 0.0140902 loss)
I1203 17:01:50.744585 12164 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1203 17:01:58.925273 12164 solver.cpp:218] Iteration 105900 (12.2249 iter/s, 8.18002s/100 iters), loss = 0.0226337
I1203 17:01:58.925779 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:01:58.925779 12164 solver.cpp:237]     Train net output #1: loss = 0.0226336 (* 1 = 0.0226336 loss)
I1203 17:01:58.925779 12164 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1203 17:02:06.672085  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:02:06.998131 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.caffemodel
I1203 17:02:07.030138 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106000.solverstate
I1203 17:02:07.036150 12164 solver.cpp:330] Iteration 106000, Testing net (#0)
I1203 17:02:07.036150 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:02:08.742300 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:02:08.809298 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1203 17:02:08.809298 12164 solver.cpp:397]     Test net output #1: loss = 0.233667 (* 1 = 0.233667 loss)
I1203 17:02:08.885305 12164 solver.cpp:218] Iteration 106000 (10.0408 iter/s, 9.95932s/100 iters), loss = 0.0204508
I1203 17:02:08.885305 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:02:08.885305 12164 solver.cpp:237]     Train net output #1: loss = 0.0204508 (* 1 = 0.0204508 loss)
I1203 17:02:08.885305 12164 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1203 17:02:17.065224 12164 solver.cpp:218] Iteration 106100 (12.2264 iter/s, 8.17899s/100 iters), loss = 0.0596374
I1203 17:02:17.065224 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:02:17.065224 12164 solver.cpp:237]     Train net output #1: loss = 0.0596374 (* 1 = 0.0596374 loss)
I1203 17:02:17.065224 12164 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1203 17:02:25.236074 12164 solver.cpp:218] Iteration 106200 (12.2391 iter/s, 8.17054s/100 iters), loss = 0.029123
I1203 17:02:25.236074 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:02:25.236074 12164 solver.cpp:237]     Train net output #1: loss = 0.029123 (* 1 = 0.029123 loss)
I1203 17:02:25.236074 12164 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1203 17:02:33.416880 12164 solver.cpp:218] Iteration 106300 (12.2243 iter/s, 8.1804s/100 iters), loss = 0.0247835
I1203 17:02:33.416880 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:02:33.416880 12164 solver.cpp:237]     Train net output #1: loss = 0.0247835 (* 1 = 0.0247835 loss)
I1203 17:02:33.416880 12164 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1203 17:02:41.627110 12164 solver.cpp:218] Iteration 106400 (12.1806 iter/s, 8.20976s/100 iters), loss = 0.0115917
I1203 17:02:41.627110 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:02:41.627110 12164 solver.cpp:237]     Train net output #1: loss = 0.0115916 (* 1 = 0.0115916 loss)
I1203 17:02:41.627110 12164 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1203 17:02:49.448438  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:02:49.776458 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.caffemodel
I1203 17:02:49.809459 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_106500.solverstate
I1203 17:02:49.816459 12164 solver.cpp:330] Iteration 106500, Testing net (#0)
I1203 17:02:49.816459 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:02:51.518525 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:02:51.587529 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:02:51.587529 12164 solver.cpp:397]     Test net output #1: loss = 0.234294 (* 1 = 0.234294 loss)
I1203 17:02:51.664549 12164 solver.cpp:218] Iteration 106500 (9.96278 iter/s, 10.0374s/100 iters), loss = 0.0242583
I1203 17:02:51.664549 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:02:51.664549 12164 solver.cpp:237]     Train net output #1: loss = 0.0242583 (* 1 = 0.0242583 loss)
I1203 17:02:51.665550 12164 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1203 17:02:59.878554 12164 solver.cpp:218] Iteration 106600 (12.1756 iter/s, 8.21318s/100 iters), loss = 0.0603062
I1203 17:02:59.878554 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:02:59.878554 12164 solver.cpp:237]     Train net output #1: loss = 0.0603061 (* 1 = 0.0603061 loss)
I1203 17:02:59.878554 12164 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1203 17:03:08.108348 12164 solver.cpp:218] Iteration 106700 (12.152 iter/s, 8.22913s/100 iters), loss = 0.0210004
I1203 17:03:08.108348 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:03:08.108348 12164 solver.cpp:237]     Train net output #1: loss = 0.0210004 (* 1 = 0.0210004 loss)
I1203 17:03:08.108348 12164 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1203 17:03:16.300416 12164 solver.cpp:218] Iteration 106800 (12.207 iter/s, 8.19204s/100 iters), loss = 0.0106618
I1203 17:03:16.301417 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:03:16.301417 12164 solver.cpp:237]     Train net output #1: loss = 0.0106617 (* 1 = 0.0106617 loss)
I1203 17:03:16.301417 12164 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1203 17:03:24.519702 12164 solver.cpp:218] Iteration 106900 (12.1687 iter/s, 8.21781s/100 iters), loss = 0.0111363
I1203 17:03:24.519702 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:03:24.519702 12164 solver.cpp:237]     Train net output #1: loss = 0.0111363 (* 1 = 0.0111363 loss)
I1203 17:03:24.519702 12164 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1203 17:03:32.342592  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:03:32.658614 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.caffemodel
I1203 17:03:32.687614 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107000.solverstate
I1203 17:03:32.693615 12164 solver.cpp:330] Iteration 107000, Testing net (#0)
I1203 17:03:32.693615 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:03:34.413789 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:03:34.482798 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1203 17:03:34.482798 12164 solver.cpp:397]     Test net output #1: loss = 0.237346 (* 1 = 0.237346 loss)
I1203 17:03:34.562832 12164 solver.cpp:218] Iteration 107000 (9.95774 iter/s, 10.0424s/100 iters), loss = 0.0165854
I1203 17:03:34.562832 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:03:34.562832 12164 solver.cpp:237]     Train net output #1: loss = 0.0165853 (* 1 = 0.0165853 loss)
I1203 17:03:34.562832 12164 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1203 17:03:42.761700 12164 solver.cpp:218] Iteration 107100 (12.1968 iter/s, 8.19885s/100 iters), loss = 0.0234985
I1203 17:03:42.761700 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:03:42.761700 12164 solver.cpp:237]     Train net output #1: loss = 0.0234985 (* 1 = 0.0234985 loss)
I1203 17:03:42.761700 12164 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1203 17:03:50.965621 12164 solver.cpp:218] Iteration 107200 (12.1905 iter/s, 8.20311s/100 iters), loss = 0.0238997
I1203 17:03:50.965621 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:03:50.965621 12164 solver.cpp:237]     Train net output #1: loss = 0.0238997 (* 1 = 0.0238997 loss)
I1203 17:03:50.965621 12164 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1203 17:03:59.201130 12164 solver.cpp:218] Iteration 107300 (12.1429 iter/s, 8.23525s/100 iters), loss = 0.0532458
I1203 17:03:59.201130 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:03:59.201130 12164 solver.cpp:237]     Train net output #1: loss = 0.0532458 (* 1 = 0.0532458 loss)
I1203 17:03:59.201130 12164 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1203 17:04:07.407269 12164 solver.cpp:218] Iteration 107400 (12.1865 iter/s, 8.20579s/100 iters), loss = 0.0428686
I1203 17:04:07.407269 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:04:07.407269 12164 solver.cpp:237]     Train net output #1: loss = 0.0428686 (* 1 = 0.0428686 loss)
I1203 17:04:07.407269 12164 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1203 17:04:15.205185  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:04:15.534250 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.caffemodel
I1203 17:04:15.564254 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_107500.solverstate
I1203 17:04:15.570255 12164 solver.cpp:330] Iteration 107500, Testing net (#0)
I1203 17:04:15.570255 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:04:17.293591 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:04:17.360599 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1203 17:04:17.360599 12164 solver.cpp:397]     Test net output #1: loss = 0.234256 (* 1 = 0.234256 loss)
I1203 17:04:17.434598 12164 solver.cpp:218] Iteration 107500 (9.97347 iter/s, 10.0266s/100 iters), loss = 0.0191693
I1203 17:04:17.435099 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:04:17.435099 12164 solver.cpp:237]     Train net output #1: loss = 0.0191693 (* 1 = 0.0191693 loss)
I1203 17:04:17.435099 12164 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1203 17:04:25.651603 12164 solver.cpp:218] Iteration 107600 (12.1702 iter/s, 8.21679s/100 iters), loss = 0.0295805
I1203 17:04:25.651603 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:04:25.651603 12164 solver.cpp:237]     Train net output #1: loss = 0.0295804 (* 1 = 0.0295804 loss)
I1203 17:04:25.651603 12164 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1203 17:04:33.854568 12164 solver.cpp:218] Iteration 107700 (12.1924 iter/s, 8.20185s/100 iters), loss = 0.0221622
I1203 17:04:33.854568 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:04:33.854568 12164 solver.cpp:237]     Train net output #1: loss = 0.0221622 (* 1 = 0.0221622 loss)
I1203 17:04:33.854568 12164 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1203 17:04:42.071570 12164 solver.cpp:218] Iteration 107800 (12.1707 iter/s, 8.21649s/100 iters), loss = 0.0111472
I1203 17:04:42.071570 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:04:42.071570 12164 solver.cpp:237]     Train net output #1: loss = 0.0111472 (* 1 = 0.0111472 loss)
I1203 17:04:42.071570 12164 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1203 17:04:50.304497 12164 solver.cpp:218] Iteration 107900 (12.1472 iter/s, 8.23233s/100 iters), loss = 0.0134689
I1203 17:04:50.304497 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:04:50.304497 12164 solver.cpp:237]     Train net output #1: loss = 0.0134688 (* 1 = 0.0134688 loss)
I1203 17:04:50.304497 12164 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1203 17:04:58.110316  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:04:58.438849 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.caffemodel
I1203 17:04:58.469365 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108000.solverstate
I1203 17:04:58.475365 12164 solver.cpp:330] Iteration 108000, Testing net (#0)
I1203 17:04:58.476351 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:05:00.180488 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:05:00.247491 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1203 17:05:00.247491 12164 solver.cpp:397]     Test net output #1: loss = 0.234641 (* 1 = 0.234641 loss)
I1203 17:05:00.324494 12164 solver.cpp:218] Iteration 108000 (9.9801 iter/s, 10.0199s/100 iters), loss = 0.0335692
I1203 17:05:00.324494 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:05:00.324494 12164 solver.cpp:237]     Train net output #1: loss = 0.0335692 (* 1 = 0.0335692 loss)
I1203 17:05:00.324494 12164 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1203 17:05:08.536698 12164 solver.cpp:218] Iteration 108100 (12.1786 iter/s, 8.2111s/100 iters), loss = 0.0304576
I1203 17:05:08.536698 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:05:08.536698 12164 solver.cpp:237]     Train net output #1: loss = 0.0304576 (* 1 = 0.0304576 loss)
I1203 17:05:08.536698 12164 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1203 17:05:16.754783 12164 solver.cpp:218] Iteration 108200 (12.1691 iter/s, 8.21754s/100 iters), loss = 0.0285211
I1203 17:05:16.754783 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:05:16.754783 12164 solver.cpp:237]     Train net output #1: loss = 0.0285211 (* 1 = 0.0285211 loss)
I1203 17:05:16.754783 12164 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1203 17:05:24.958469 12164 solver.cpp:218] Iteration 108300 (12.191 iter/s, 8.20279s/100 iters), loss = 0.0110807
I1203 17:05:24.958469 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:05:24.958469 12164 solver.cpp:237]     Train net output #1: loss = 0.0110807 (* 1 = 0.0110807 loss)
I1203 17:05:24.958469 12164 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1203 17:05:33.155572 12164 solver.cpp:218] Iteration 108400 (12.1997 iter/s, 8.19691s/100 iters), loss = 0.0122871
I1203 17:05:33.155572 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:05:33.155572 12164 solver.cpp:237]     Train net output #1: loss = 0.012287 (* 1 = 0.012287 loss)
I1203 17:05:33.155572 12164 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1203 17:05:40.986882  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:05:41.308907 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.caffemodel
I1203 17:05:41.336908 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_108500.solverstate
I1203 17:05:41.342913 12164 solver.cpp:330] Iteration 108500, Testing net (#0)
I1203 17:05:41.342913 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:05:43.053052 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:05:43.121055 12164 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1203 17:05:43.121055 12164 solver.cpp:397]     Test net output #1: loss = 0.231851 (* 1 = 0.231851 loss)
I1203 17:05:43.199064 12164 solver.cpp:218] Iteration 108500 (9.95728 iter/s, 10.0429s/100 iters), loss = 0.0259272
I1203 17:05:43.199064 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:05:43.199064 12164 solver.cpp:237]     Train net output #1: loss = 0.0259272 (* 1 = 0.0259272 loss)
I1203 17:05:43.199064 12164 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1203 17:05:51.404000 12164 solver.cpp:218] Iteration 108600 (12.1881 iter/s, 8.20475s/100 iters), loss = 0.0164974
I1203 17:05:51.404000 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:05:51.404000 12164 solver.cpp:237]     Train net output #1: loss = 0.0164974 (* 1 = 0.0164974 loss)
I1203 17:05:51.404000 12164 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1203 17:05:59.621786 12164 solver.cpp:218] Iteration 108700 (12.1706 iter/s, 8.21654s/100 iters), loss = 0.0149132
I1203 17:05:59.621786 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:05:59.621786 12164 solver.cpp:237]     Train net output #1: loss = 0.0149131 (* 1 = 0.0149131 loss)
I1203 17:05:59.621786 12164 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1203 17:06:07.855900 12164 solver.cpp:218] Iteration 108800 (12.1453 iter/s, 8.23364s/100 iters), loss = 0.0211929
I1203 17:06:07.855900 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:06:07.855900 12164 solver.cpp:237]     Train net output #1: loss = 0.0211928 (* 1 = 0.0211928 loss)
I1203 17:06:07.855900 12164 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1203 17:06:16.061959 12164 solver.cpp:218] Iteration 108900 (12.1868 iter/s, 8.20561s/100 iters), loss = 0.017655
I1203 17:06:16.061959 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:06:16.061959 12164 solver.cpp:237]     Train net output #1: loss = 0.0176549 (* 1 = 0.0176549 loss)
I1203 17:06:16.061959 12164 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1203 17:06:23.862836  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:06:24.188860 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.caffemodel
I1203 17:06:24.222365 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109000.solverstate
I1203 17:06:24.228871 12164 solver.cpp:330] Iteration 109000, Testing net (#0)
I1203 17:06:24.228871 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:06:25.958045 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:06:26.027060 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1203 17:06:26.027060 12164 solver.cpp:397]     Test net output #1: loss = 0.232005 (* 1 = 0.232005 loss)
I1203 17:06:26.104059 12164 solver.cpp:218] Iteration 109000 (9.95819 iter/s, 10.042s/100 iters), loss = 0.0133947
I1203 17:06:26.104059 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:06:26.104059 12164 solver.cpp:237]     Train net output #1: loss = 0.0133946 (* 1 = 0.0133946 loss)
I1203 17:06:26.104059 12164 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1203 17:06:34.309151 12164 solver.cpp:218] Iteration 109100 (12.1888 iter/s, 8.20423s/100 iters), loss = 0.046197
I1203 17:06:34.309151 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:06:34.309151 12164 solver.cpp:237]     Train net output #1: loss = 0.046197 (* 1 = 0.046197 loss)
I1203 17:06:34.309151 12164 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1203 17:06:42.513690 12164 solver.cpp:218] Iteration 109200 (12.1892 iter/s, 8.204s/100 iters), loss = 0.0204377
I1203 17:06:42.513690 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:06:42.513690 12164 solver.cpp:237]     Train net output #1: loss = 0.0204377 (* 1 = 0.0204377 loss)
I1203 17:06:42.513690 12164 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1203 17:06:50.735430 12164 solver.cpp:218] Iteration 109300 (12.1637 iter/s, 8.22117s/100 iters), loss = 0.0189311
I1203 17:06:50.735430 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:06:50.735430 12164 solver.cpp:237]     Train net output #1: loss = 0.0189311 (* 1 = 0.0189311 loss)
I1203 17:06:50.735430 12164 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1203 17:06:58.955807 12164 solver.cpp:218] Iteration 109400 (12.1651 iter/s, 8.22025s/100 iters), loss = 0.021424
I1203 17:06:58.955807 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:06:58.955807 12164 solver.cpp:237]     Train net output #1: loss = 0.021424 (* 1 = 0.021424 loss)
I1203 17:06:58.955807 12164 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1203 17:07:06.746680  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:07:07.076706 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.caffemodel
I1203 17:07:07.112705 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_109500.solverstate
I1203 17:07:07.118706 12164 solver.cpp:330] Iteration 109500, Testing net (#0)
I1203 17:07:07.118706 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:07:08.827960 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:07:08.893960 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1203 17:07:08.893960 12164 solver.cpp:397]     Test net output #1: loss = 0.236888 (* 1 = 0.236888 loss)
I1203 17:07:08.968973 12164 solver.cpp:218] Iteration 109500 (9.98738 iter/s, 10.0126s/100 iters), loss = 0.0135865
I1203 17:07:08.968973 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:07:08.968973 12164 solver.cpp:237]     Train net output #1: loss = 0.0135864 (* 1 = 0.0135864 loss)
I1203 17:07:08.968973 12164 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1203 17:07:17.211830 12164 solver.cpp:218] Iteration 109600 (12.1328 iter/s, 8.24212s/100 iters), loss = 0.028254
I1203 17:07:17.211830 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:07:17.211830 12164 solver.cpp:237]     Train net output #1: loss = 0.0282539 (* 1 = 0.0282539 loss)
I1203 17:07:17.211830 12164 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1203 17:07:25.426203 12164 solver.cpp:218] Iteration 109700 (12.1752 iter/s, 8.21341s/100 iters), loss = 0.0462089
I1203 17:07:25.426203 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:07:25.426203 12164 solver.cpp:237]     Train net output #1: loss = 0.0462089 (* 1 = 0.0462089 loss)
I1203 17:07:25.426203 12164 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1203 17:07:33.625052 12164 solver.cpp:218] Iteration 109800 (12.1966 iter/s, 8.19901s/100 iters), loss = 0.0129999
I1203 17:07:33.625052 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:07:33.625052 12164 solver.cpp:237]     Train net output #1: loss = 0.0129998 (* 1 = 0.0129998 loss)
I1203 17:07:33.625052 12164 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1203 17:07:41.830595 12164 solver.cpp:218] Iteration 109900 (12.1877 iter/s, 8.20499s/100 iters), loss = 0.0110453
I1203 17:07:41.830595 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:07:41.830595 12164 solver.cpp:237]     Train net output #1: loss = 0.0110453 (* 1 = 0.0110453 loss)
I1203 17:07:41.830595 12164 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1203 17:07:49.652418  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:07:49.981528 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.caffemodel
I1203 17:07:50.014528 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110000.solverstate
I1203 17:07:50.020542 12164 solver.cpp:330] Iteration 110000, Testing net (#0)
I1203 17:07:50.020542 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:07:51.725442 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:07:51.794950 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1203 17:07:51.794950 12164 solver.cpp:397]     Test net output #1: loss = 0.235553 (* 1 = 0.235553 loss)
I1203 17:07:51.872454 12164 solver.cpp:218] Iteration 110000 (9.95957 iter/s, 10.0406s/100 iters), loss = 0.0247995
I1203 17:07:51.872454 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:07:51.872454 12164 solver.cpp:237]     Train net output #1: loss = 0.0247994 (* 1 = 0.0247994 loss)
I1203 17:07:51.872454 12164 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1203 17:08:00.065539 12164 solver.cpp:218] Iteration 110100 (12.2054 iter/s, 8.19308s/100 iters), loss = 0.0136452
I1203 17:08:00.065539 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:08:00.065539 12164 solver.cpp:237]     Train net output #1: loss = 0.0136451 (* 1 = 0.0136451 loss)
I1203 17:08:00.065539 12164 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1203 17:08:08.289621 12164 solver.cpp:218] Iteration 110200 (12.1606 iter/s, 8.22326s/100 iters), loss = 0.0140733
I1203 17:08:08.289621 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:08:08.289621 12164 solver.cpp:237]     Train net output #1: loss = 0.0140732 (* 1 = 0.0140732 loss)
I1203 17:08:08.289621 12164 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1203 17:08:16.499620 12164 solver.cpp:218] Iteration 110300 (12.1809 iter/s, 8.20958s/100 iters), loss = 0.0144957
I1203 17:08:16.499620 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:08:16.499620 12164 solver.cpp:237]     Train net output #1: loss = 0.0144957 (* 1 = 0.0144957 loss)
I1203 17:08:16.499620 12164 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1203 17:08:24.699798 12164 solver.cpp:218] Iteration 110400 (12.1948 iter/s, 8.20021s/100 iters), loss = 0.0225564
I1203 17:08:24.700799 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:08:24.700799 12164 solver.cpp:237]     Train net output #1: loss = 0.0225564 (* 1 = 0.0225564 loss)
I1203 17:08:24.700799 12164 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1203 17:08:32.520653  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:08:32.836671 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.caffemodel
I1203 17:08:32.866672 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_110500.solverstate
I1203 17:08:32.871673 12164 solver.cpp:330] Iteration 110500, Testing net (#0)
I1203 17:08:32.871673 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:08:34.598016 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:08:34.667021 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9358
I1203 17:08:34.667021 12164 solver.cpp:397]     Test net output #1: loss = 0.234321 (* 1 = 0.234321 loss)
I1203 17:08:34.747022 12164 solver.cpp:218] Iteration 110500 (9.95455 iter/s, 10.0457s/100 iters), loss = 0.0229415
I1203 17:08:34.747022 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:08:34.747022 12164 solver.cpp:237]     Train net output #1: loss = 0.0229414 (* 1 = 0.0229414 loss)
I1203 17:08:34.747022 12164 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1203 17:08:42.958804 12164 solver.cpp:218] Iteration 110600 (12.1785 iter/s, 8.21119s/100 iters), loss = 0.0195605
I1203 17:08:42.958804 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:08:42.958804 12164 solver.cpp:237]     Train net output #1: loss = 0.0195604 (* 1 = 0.0195604 loss)
I1203 17:08:42.958804 12164 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1203 17:08:51.162540 12164 solver.cpp:218] Iteration 110700 (12.1903 iter/s, 8.20321s/100 iters), loss = 0.0185327
I1203 17:08:51.162540 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:08:51.162540 12164 solver.cpp:237]     Train net output #1: loss = 0.0185327 (* 1 = 0.0185327 loss)
I1203 17:08:51.162540 12164 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1203 17:08:59.399610 12164 solver.cpp:218] Iteration 110800 (12.1411 iter/s, 8.23649s/100 iters), loss = 0.0160044
I1203 17:08:59.399610 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:08:59.399610 12164 solver.cpp:237]     Train net output #1: loss = 0.0160043 (* 1 = 0.0160043 loss)
I1203 17:08:59.399610 12164 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1203 17:09:07.617440 12164 solver.cpp:218] Iteration 110900 (12.1689 iter/s, 8.21765s/100 iters), loss = 0.0128826
I1203 17:09:07.617440 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:09:07.617440 12164 solver.cpp:237]     Train net output #1: loss = 0.0128825 (* 1 = 0.0128825 loss)
I1203 17:09:07.617440 12164 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1203 17:09:15.424661  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:09:15.751718 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.caffemodel
I1203 17:09:15.783718 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111000.solverstate
I1203 17:09:15.790223 12164 solver.cpp:330] Iteration 111000, Testing net (#0)
I1203 17:09:15.790722 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:09:17.508896 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:09:17.574895 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 17:09:17.575896 12164 solver.cpp:397]     Test net output #1: loss = 0.235147 (* 1 = 0.235147 loss)
I1203 17:09:17.649901 12164 solver.cpp:218] Iteration 111000 (9.96835 iter/s, 10.0317s/100 iters), loss = 0.0224591
I1203 17:09:17.649901 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:09:17.649901 12164 solver.cpp:237]     Train net output #1: loss = 0.0224591 (* 1 = 0.0224591 loss)
I1203 17:09:17.649901 12164 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1203 17:09:25.874877 12164 solver.cpp:218] Iteration 111100 (12.1582 iter/s, 8.22487s/100 iters), loss = 0.0180612
I1203 17:09:25.874877 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:09:25.874877 12164 solver.cpp:237]     Train net output #1: loss = 0.0180612 (* 1 = 0.0180612 loss)
I1203 17:09:25.874877 12164 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1203 17:09:34.078248 12164 solver.cpp:218] Iteration 111200 (12.1907 iter/s, 8.20296s/100 iters), loss = 0.0160625
I1203 17:09:34.078248 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:09:34.078248 12164 solver.cpp:237]     Train net output #1: loss = 0.0160625 (* 1 = 0.0160625 loss)
I1203 17:09:34.078248 12164 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1203 17:09:42.285742 12164 solver.cpp:218] Iteration 111300 (12.1852 iter/s, 8.20668s/100 iters), loss = 0.0301882
I1203 17:09:42.285742 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:09:42.285742 12164 solver.cpp:237]     Train net output #1: loss = 0.0301882 (* 1 = 0.0301882 loss)
I1203 17:09:42.285742 12164 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1203 17:09:50.505759 12164 solver.cpp:218] Iteration 111400 (12.1661 iter/s, 8.21956s/100 iters), loss = 0.0267169
I1203 17:09:50.505759 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:09:50.505759 12164 solver.cpp:237]     Train net output #1: loss = 0.0267168 (* 1 = 0.0267168 loss)
I1203 17:09:50.505759 12164 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1203 17:09:58.319768  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:09:58.648787 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.caffemodel
I1203 17:09:58.677788 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_111500.solverstate
I1203 17:09:58.684788 12164 solver.cpp:330] Iteration 111500, Testing net (#0)
I1203 17:09:58.684788 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:10:00.391680 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:10:00.461184 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1203 17:10:00.461184 12164 solver.cpp:397]     Test net output #1: loss = 0.236732 (* 1 = 0.236732 loss)
I1203 17:10:00.539685 12164 solver.cpp:218] Iteration 111500 (9.96714 iter/s, 10.033s/100 iters), loss = 0.0137684
I1203 17:10:00.539685 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:00.539685 12164 solver.cpp:237]     Train net output #1: loss = 0.0137684 (* 1 = 0.0137684 loss)
I1203 17:10:00.539685 12164 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1203 17:10:08.791255 12164 solver.cpp:218] Iteration 111600 (12.1188 iter/s, 8.25161s/100 iters), loss = 0.0185432
I1203 17:10:08.791255 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:08.791255 12164 solver.cpp:237]     Train net output #1: loss = 0.0185432 (* 1 = 0.0185432 loss)
I1203 17:10:08.791255 12164 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1203 17:10:17.014379 12164 solver.cpp:218] Iteration 111700 (12.1625 iter/s, 8.22196s/100 iters), loss = 0.0212218
I1203 17:10:17.014379 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:17.014379 12164 solver.cpp:237]     Train net output #1: loss = 0.0212218 (* 1 = 0.0212218 loss)
I1203 17:10:17.014379 12164 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1203 17:10:25.222508 12164 solver.cpp:218] Iteration 111800 (12.1833 iter/s, 8.20794s/100 iters), loss = 0.0154013
I1203 17:10:25.222508 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:25.222508 12164 solver.cpp:237]     Train net output #1: loss = 0.0154013 (* 1 = 0.0154013 loss)
I1203 17:10:25.222508 12164 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1203 17:10:33.421291 12164 solver.cpp:218] Iteration 111900 (12.1978 iter/s, 8.19818s/100 iters), loss = 0.0167904
I1203 17:10:33.421291 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:33.421291 12164 solver.cpp:237]     Train net output #1: loss = 0.0167904 (* 1 = 0.0167904 loss)
I1203 17:10:33.421291 12164 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1203 17:10:41.240438  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:10:41.556951 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.caffemodel
I1203 17:10:41.595453 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112000.solverstate
I1203 17:10:41.601953 12164 solver.cpp:330] Iteration 112000, Testing net (#0)
I1203 17:10:41.601953 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:10:43.320612 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:10:43.389636 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1203 17:10:43.389636 12164 solver.cpp:397]     Test net output #1: loss = 0.238739 (* 1 = 0.238739 loss)
I1203 17:10:43.466646 12164 solver.cpp:218] Iteration 112000 (9.95559 iter/s, 10.0446s/100 iters), loss = 0.0152067
I1203 17:10:43.466646 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:43.466646 12164 solver.cpp:237]     Train net output #1: loss = 0.0152067 (* 1 = 0.0152067 loss)
I1203 17:10:43.466646 12164 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1203 17:10:51.672516 12164 solver.cpp:218] Iteration 112100 (12.1867 iter/s, 8.20567s/100 iters), loss = 0.0234888
I1203 17:10:51.672516 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:51.672516 12164 solver.cpp:237]     Train net output #1: loss = 0.0234887 (* 1 = 0.0234887 loss)
I1203 17:10:51.672516 12164 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1203 17:10:59.881841 12164 solver.cpp:218] Iteration 112200 (12.1813 iter/s, 8.20929s/100 iters), loss = 0.0178065
I1203 17:10:59.882841 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:10:59.882841 12164 solver.cpp:237]     Train net output #1: loss = 0.0178065 (* 1 = 0.0178065 loss)
I1203 17:10:59.882841 12164 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1203 17:11:08.132731 12164 solver.cpp:218] Iteration 112300 (12.1218 iter/s, 8.24959s/100 iters), loss = 0.0136437
I1203 17:11:08.132731 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:11:08.132731 12164 solver.cpp:237]     Train net output #1: loss = 0.0136437 (* 1 = 0.0136437 loss)
I1203 17:11:08.132731 12164 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1203 17:11:16.353287 12164 solver.cpp:218] Iteration 112400 (12.1654 iter/s, 8.22006s/100 iters), loss = 0.0150516
I1203 17:11:16.353287 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:11:16.353287 12164 solver.cpp:237]     Train net output #1: loss = 0.0150516 (* 1 = 0.0150516 loss)
I1203 17:11:16.353287 12164 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1203 17:11:24.145241  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:11:24.471274 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.caffemodel
I1203 17:11:24.500274 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_112500.solverstate
I1203 17:11:24.507275 12164 solver.cpp:330] Iteration 112500, Testing net (#0)
I1203 17:11:24.507275 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:11:26.233399 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:11:26.302404 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1203 17:11:26.302404 12164 solver.cpp:397]     Test net output #1: loss = 0.241253 (* 1 = 0.241253 loss)
I1203 17:11:26.375424 12164 solver.cpp:218] Iteration 112500 (9.97778 iter/s, 10.0223s/100 iters), loss = 0.0137203
I1203 17:11:26.375424 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:11:26.375424 12164 solver.cpp:237]     Train net output #1: loss = 0.0137203 (* 1 = 0.0137203 loss)
I1203 17:11:26.375424 12164 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1203 17:11:34.592700 12164 solver.cpp:218] Iteration 112600 (12.1708 iter/s, 8.21636s/100 iters), loss = 0.0234349
I1203 17:11:34.592700 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:11:34.592700 12164 solver.cpp:237]     Train net output #1: loss = 0.0234348 (* 1 = 0.0234348 loss)
I1203 17:11:34.592700 12164 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1203 17:11:42.784821 12164 solver.cpp:218] Iteration 112700 (12.2083 iter/s, 8.19117s/100 iters), loss = 0.0205096
I1203 17:11:42.784821 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:11:42.784821 12164 solver.cpp:237]     Train net output #1: loss = 0.0205096 (* 1 = 0.0205096 loss)
I1203 17:11:42.784821 12164 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1203 17:11:50.983659 12164 solver.cpp:218] Iteration 112800 (12.1976 iter/s, 8.1983s/100 iters), loss = 0.0150657
I1203 17:11:50.983659 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:11:50.983659 12164 solver.cpp:237]     Train net output #1: loss = 0.0150656 (* 1 = 0.0150656 loss)
I1203 17:11:50.983659 12164 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1203 17:11:59.211045 12164 solver.cpp:218] Iteration 112900 (12.1541 iter/s, 8.22766s/100 iters), loss = 0.0239054
I1203 17:11:59.211045 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:11:59.211045 12164 solver.cpp:237]     Train net output #1: loss = 0.0239053 (* 1 = 0.0239053 loss)
I1203 17:11:59.211045 12164 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1203 17:12:07.006870  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:12:07.333897 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.caffemodel
I1203 17:12:07.365913 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113000.solverstate
I1203 17:12:07.372584 12164 solver.cpp:330] Iteration 113000, Testing net (#0)
I1203 17:12:07.372584 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:12:09.075074 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:12:09.144073 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9341
I1203 17:12:09.144073 12164 solver.cpp:397]     Test net output #1: loss = 0.239475 (* 1 = 0.239475 loss)
I1203 17:12:09.221582 12164 solver.cpp:218] Iteration 113000 (9.9907 iter/s, 10.0093s/100 iters), loss = 0.0158078
I1203 17:12:09.221582 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:12:09.221582 12164 solver.cpp:237]     Train net output #1: loss = 0.0158078 (* 1 = 0.0158078 loss)
I1203 17:12:09.221582 12164 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1203 17:12:17.426455 12164 solver.cpp:218] Iteration 113100 (12.188 iter/s, 8.20479s/100 iters), loss = 0.027479
I1203 17:12:17.426455 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:12:17.426455 12164 solver.cpp:237]     Train net output #1: loss = 0.027479 (* 1 = 0.027479 loss)
I1203 17:12:17.426455 12164 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1203 17:12:25.607689 12164 solver.cpp:218] Iteration 113200 (12.2244 iter/s, 8.18038s/100 iters), loss = 0.0172537
I1203 17:12:25.607689 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:12:25.607689 12164 solver.cpp:237]     Train net output #1: loss = 0.0172536 (* 1 = 0.0172536 loss)
I1203 17:12:25.607689 12164 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1203 17:12:33.790570 12164 solver.cpp:218] Iteration 113300 (12.2213 iter/s, 8.18246s/100 iters), loss = 0.0418645
I1203 17:12:33.790570 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:12:33.790570 12164 solver.cpp:237]     Train net output #1: loss = 0.0418644 (* 1 = 0.0418644 loss)
I1203 17:12:33.790570 12164 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1203 17:12:41.961443 12164 solver.cpp:218] Iteration 113400 (12.2391 iter/s, 8.17055s/100 iters), loss = 0.0186756
I1203 17:12:41.961944 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:12:41.961944 12164 solver.cpp:237]     Train net output #1: loss = 0.0186755 (* 1 = 0.0186755 loss)
I1203 17:12:41.961944 12164 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1203 17:12:49.735153  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:12:50.060184 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.caffemodel
I1203 17:12:50.089193 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_113500.solverstate
I1203 17:12:50.095193 12164 solver.cpp:330] Iteration 113500, Testing net (#0)
I1203 17:12:50.095193 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:12:51.794313 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:12:51.862315 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1203 17:12:51.862315 12164 solver.cpp:397]     Test net output #1: loss = 0.237669 (* 1 = 0.237669 loss)
I1203 17:12:51.940320 12164 solver.cpp:218] Iteration 113500 (10.0214 iter/s, 9.97865s/100 iters), loss = 0.0156378
I1203 17:12:51.940320 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:12:51.941323 12164 solver.cpp:237]     Train net output #1: loss = 0.0156378 (* 1 = 0.0156378 loss)
I1203 17:12:51.941323 12164 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1203 17:13:00.101330 12164 solver.cpp:218] Iteration 113600 (12.2554 iter/s, 8.15964s/100 iters), loss = 0.0278725
I1203 17:13:00.101330 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:00.101330 12164 solver.cpp:237]     Train net output #1: loss = 0.0278724 (* 1 = 0.0278724 loss)
I1203 17:13:00.101330 12164 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1203 17:13:08.291831 12164 solver.cpp:218] Iteration 113700 (12.2103 iter/s, 8.18978s/100 iters), loss = 0.0113218
I1203 17:13:08.291831 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:08.291831 12164 solver.cpp:237]     Train net output #1: loss = 0.0113218 (* 1 = 0.0113218 loss)
I1203 17:13:08.291831 12164 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1203 17:13:16.499543 12164 solver.cpp:218] Iteration 113800 (12.1834 iter/s, 8.20786s/100 iters), loss = 0.0157779
I1203 17:13:16.499543 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:16.499543 12164 solver.cpp:237]     Train net output #1: loss = 0.0157778 (* 1 = 0.0157778 loss)
I1203 17:13:16.499543 12164 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1203 17:13:24.698375 12164 solver.cpp:218] Iteration 113900 (12.198 iter/s, 8.19804s/100 iters), loss = 0.0170906
I1203 17:13:24.698375 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:24.698375 12164 solver.cpp:237]     Train net output #1: loss = 0.0170906 (* 1 = 0.0170906 loss)
I1203 17:13:24.698375 12164 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1203 17:13:32.515224  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:13:32.831244 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.caffemodel
I1203 17:13:32.865245 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114000.solverstate
I1203 17:13:32.873251 12164 solver.cpp:330] Iteration 114000, Testing net (#0)
I1203 17:13:32.873751 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:13:34.601416 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:13:34.670920 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:13:34.671419 12164 solver.cpp:397]     Test net output #1: loss = 0.240302 (* 1 = 0.240302 loss)
I1203 17:13:34.747421 12164 solver.cpp:218] Iteration 114000 (9.9517 iter/s, 10.0485s/100 iters), loss = 0.0204986
I1203 17:13:34.747421 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:34.747421 12164 solver.cpp:237]     Train net output #1: loss = 0.0204986 (* 1 = 0.0204986 loss)
I1203 17:13:34.747421 12164 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1203 17:13:42.966446 12164 solver.cpp:218] Iteration 114100 (12.1673 iter/s, 8.21872s/100 iters), loss = 0.028189
I1203 17:13:42.966446 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:42.966446 12164 solver.cpp:237]     Train net output #1: loss = 0.0281889 (* 1 = 0.0281889 loss)
I1203 17:13:42.966446 12164 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1203 17:13:51.184360 12164 solver.cpp:218] Iteration 114200 (12.1699 iter/s, 8.21696s/100 iters), loss = 0.0198289
I1203 17:13:51.184360 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:51.184360 12164 solver.cpp:237]     Train net output #1: loss = 0.0198288 (* 1 = 0.0198288 loss)
I1203 17:13:51.184360 12164 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1203 17:13:59.422408 12164 solver.cpp:218] Iteration 114300 (12.1387 iter/s, 8.23814s/100 iters), loss = 0.0181781
I1203 17:13:59.422408 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:13:59.422408 12164 solver.cpp:237]     Train net output #1: loss = 0.0181781 (* 1 = 0.0181781 loss)
I1203 17:13:59.422408 12164 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1203 17:14:07.646142 12164 solver.cpp:218] Iteration 114400 (12.1613 iter/s, 8.2228s/100 iters), loss = 0.0125041
I1203 17:14:07.646142 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:14:07.646142 12164 solver.cpp:237]     Train net output #1: loss = 0.0125041 (* 1 = 0.0125041 loss)
I1203 17:14:07.646142 12164 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1203 17:14:15.451231  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:14:15.776271 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.caffemodel
I1203 17:14:15.809285 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_114500.solverstate
I1203 17:14:15.815286 12164 solver.cpp:330] Iteration 114500, Testing net (#0)
I1203 17:14:15.815286 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:14:17.529461 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:14:17.597467 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1203 17:14:17.597467 12164 solver.cpp:397]     Test net output #1: loss = 0.238146 (* 1 = 0.238146 loss)
I1203 17:14:17.671466 12164 solver.cpp:218] Iteration 114500 (9.97485 iter/s, 10.0252s/100 iters), loss = 0.0207539
I1203 17:14:17.671466 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:14:17.671466 12164 solver.cpp:237]     Train net output #1: loss = 0.0207538 (* 1 = 0.0207538 loss)
I1203 17:14:17.671466 12164 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1203 17:14:25.910722 12164 solver.cpp:218] Iteration 114600 (12.139 iter/s, 8.2379s/100 iters), loss = 0.0216933
I1203 17:14:25.910722 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:14:25.910722 12164 solver.cpp:237]     Train net output #1: loss = 0.0216932 (* 1 = 0.0216932 loss)
I1203 17:14:25.910722 12164 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1203 17:14:34.108558 12164 solver.cpp:218] Iteration 114700 (12.1983 iter/s, 8.19785s/100 iters), loss = 0.0253241
I1203 17:14:34.108558 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:14:34.108558 12164 solver.cpp:237]     Train net output #1: loss = 0.025324 (* 1 = 0.025324 loss)
I1203 17:14:34.108558 12164 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1203 17:14:42.321486 12164 solver.cpp:218] Iteration 114800 (12.1763 iter/s, 8.2127s/100 iters), loss = 0.00951883
I1203 17:14:42.321486 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:14:42.322487 12164 solver.cpp:237]     Train net output #1: loss = 0.00951878 (* 1 = 0.00951878 loss)
I1203 17:14:42.322487 12164 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1203 17:14:50.544572 12164 solver.cpp:218] Iteration 114900 (12.1624 iter/s, 8.22204s/100 iters), loss = 0.01927
I1203 17:14:50.544572 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:14:50.544572 12164 solver.cpp:237]     Train net output #1: loss = 0.01927 (* 1 = 0.01927 loss)
I1203 17:14:50.544572 12164 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1203 17:14:58.358343  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:14:58.683420 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.caffemodel
I1203 17:14:58.713425 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115000.solverstate
I1203 17:14:58.720425 12164 solver.cpp:330] Iteration 115000, Testing net (#0)
I1203 17:14:58.720425 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:15:00.425446 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:15:00.493949 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 17:15:00.493949 12164 solver.cpp:397]     Test net output #1: loss = 0.240159 (* 1 = 0.240159 loss)
I1203 17:15:00.571455 12164 solver.cpp:218] Iteration 115000 (9.97362 iter/s, 10.0264s/100 iters), loss = 0.0373891
I1203 17:15:00.571455 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:15:00.571455 12164 solver.cpp:237]     Train net output #1: loss = 0.0373891 (* 1 = 0.0373891 loss)
I1203 17:15:00.571455 12164 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1203 17:15:08.780450 12164 solver.cpp:218] Iteration 115100 (12.183 iter/s, 8.20819s/100 iters), loss = 0.0240298
I1203 17:15:08.780450 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:08.780450 12164 solver.cpp:237]     Train net output #1: loss = 0.0240298 (* 1 = 0.0240298 loss)
I1203 17:15:08.780450 12164 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1203 17:15:17.002384 12164 solver.cpp:218] Iteration 115200 (12.1637 iter/s, 8.22121s/100 iters), loss = 0.0253911
I1203 17:15:17.002384 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:17.002384 12164 solver.cpp:237]     Train net output #1: loss = 0.0253911 (* 1 = 0.0253911 loss)
I1203 17:15:17.002384 12164 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1203 17:15:25.210183 12164 solver.cpp:218] Iteration 115300 (12.1834 iter/s, 8.2079s/100 iters), loss = 0.0109361
I1203 17:15:25.210183 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:25.210183 12164 solver.cpp:237]     Train net output #1: loss = 0.0109361 (* 1 = 0.0109361 loss)
I1203 17:15:25.210183 12164 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1203 17:15:33.410019 12164 solver.cpp:218] Iteration 115400 (12.1965 iter/s, 8.19908s/100 iters), loss = 0.0136447
I1203 17:15:33.410019 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:33.410019 12164 solver.cpp:237]     Train net output #1: loss = 0.0136446 (* 1 = 0.0136446 loss)
I1203 17:15:33.410019 12164 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1203 17:15:41.239887  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:15:41.555943 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.caffemodel
I1203 17:15:41.582943 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_115500.solverstate
I1203 17:15:41.589448 12164 solver.cpp:330] Iteration 115500, Testing net (#0)
I1203 17:15:41.589448 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:15:43.309113 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:15:43.377112 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9344
I1203 17:15:43.377112 12164 solver.cpp:397]     Test net output #1: loss = 0.238361 (* 1 = 0.238361 loss)
I1203 17:15:43.455118 12164 solver.cpp:218] Iteration 115500 (9.95593 iter/s, 10.0443s/100 iters), loss = 0.0168353
I1203 17:15:43.455118 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:43.455118 12164 solver.cpp:237]     Train net output #1: loss = 0.0168352 (* 1 = 0.0168352 loss)
I1203 17:15:43.455118 12164 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1203 17:15:51.670435 12164 solver.cpp:218] Iteration 115600 (12.1731 iter/s, 8.21483s/100 iters), loss = 0.0251987
I1203 17:15:51.670435 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:51.670435 12164 solver.cpp:237]     Train net output #1: loss = 0.0251987 (* 1 = 0.0251987 loss)
I1203 17:15:51.670435 12164 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1203 17:15:59.876458 12164 solver.cpp:218] Iteration 115700 (12.1876 iter/s, 8.20509s/100 iters), loss = 0.0153249
I1203 17:15:59.876458 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:15:59.876458 12164 solver.cpp:237]     Train net output #1: loss = 0.0153249 (* 1 = 0.0153249 loss)
I1203 17:15:59.876458 12164 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1203 17:16:08.102180 12164 solver.cpp:218] Iteration 115800 (12.1572 iter/s, 8.22555s/100 iters), loss = 0.032518
I1203 17:16:08.102180 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1203 17:16:08.102180 12164 solver.cpp:237]     Train net output #1: loss = 0.0325179 (* 1 = 0.0325179 loss)
I1203 17:16:08.102180 12164 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1203 17:16:16.321581 12164 solver.cpp:218] Iteration 115900 (12.167 iter/s, 8.21892s/100 iters), loss = 0.0190952
I1203 17:16:16.321581 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:16:16.321581 12164 solver.cpp:237]     Train net output #1: loss = 0.0190952 (* 1 = 0.0190952 loss)
I1203 17:16:16.321581 12164 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1203 17:16:24.116942  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:16:24.445662 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.caffemodel
I1203 17:16:24.477664 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116000.solverstate
I1203 17:16:24.483676 12164 solver.cpp:330] Iteration 116000, Testing net (#0)
I1203 17:16:24.483676 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:16:26.210531 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:16:26.277531 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1203 17:16:26.277531 12164 solver.cpp:397]     Test net output #1: loss = 0.24271 (* 1 = 0.24271 loss)
I1203 17:16:26.350481 12164 solver.cpp:218] Iteration 116000 (9.97168 iter/s, 10.0284s/100 iters), loss = 0.0227673
I1203 17:16:26.350481 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:16:26.350481 12164 solver.cpp:237]     Train net output #1: loss = 0.0227673 (* 1 = 0.0227673 loss)
I1203 17:16:26.350481 12164 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1203 17:16:34.570022 12164 solver.cpp:218] Iteration 116100 (12.1667 iter/s, 8.21917s/100 iters), loss = 0.0438344
I1203 17:16:34.570022 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:16:34.570022 12164 solver.cpp:237]     Train net output #1: loss = 0.0438343 (* 1 = 0.0438343 loss)
I1203 17:16:34.570022 12164 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1203 17:16:42.777811 12164 solver.cpp:218] Iteration 116200 (12.1843 iter/s, 8.20728s/100 iters), loss = 0.0170644
I1203 17:16:42.777811 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:16:42.777811 12164 solver.cpp:237]     Train net output #1: loss = 0.0170644 (* 1 = 0.0170644 loss)
I1203 17:16:42.777811 12164 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1203 17:16:50.984707 12164 solver.cpp:218] Iteration 116300 (12.186 iter/s, 8.20613s/100 iters), loss = 0.0128553
I1203 17:16:50.984707 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:16:50.984707 12164 solver.cpp:237]     Train net output #1: loss = 0.0128553 (* 1 = 0.0128553 loss)
I1203 17:16:50.984707 12164 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1203 17:16:59.219549 12164 solver.cpp:218] Iteration 116400 (12.144 iter/s, 8.23453s/100 iters), loss = 0.0119025
I1203 17:16:59.219549 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:16:59.219549 12164 solver.cpp:237]     Train net output #1: loss = 0.0119024 (* 1 = 0.0119024 loss)
I1203 17:16:59.219549 12164 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1203 17:17:07.023484  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:17:07.351514 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.caffemodel
I1203 17:17:07.380515 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_116500.solverstate
I1203 17:17:07.387532 12164 solver.cpp:330] Iteration 116500, Testing net (#0)
I1203 17:17:07.388021 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:17:09.094100 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:17:09.163604 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9343
I1203 17:17:09.163604 12164 solver.cpp:397]     Test net output #1: loss = 0.239331 (* 1 = 0.239331 loss)
I1203 17:17:09.240614 12164 solver.cpp:218] Iteration 116500 (9.97916 iter/s, 10.0209s/100 iters), loss = 0.0145169
I1203 17:17:09.240614 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:17:09.240614 12164 solver.cpp:237]     Train net output #1: loss = 0.0145169 (* 1 = 0.0145169 loss)
I1203 17:17:09.240614 12164 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1203 17:17:17.468189 12164 solver.cpp:218] Iteration 116600 (12.1562 iter/s, 8.22627s/100 iters), loss = 0.0273406
I1203 17:17:17.468189 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:17:17.468189 12164 solver.cpp:237]     Train net output #1: loss = 0.0273406 (* 1 = 0.0273406 loss)
I1203 17:17:17.468189 12164 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1203 17:17:25.708330 12164 solver.cpp:218] Iteration 116700 (12.1366 iter/s, 8.23956s/100 iters), loss = 0.0125299
I1203 17:17:25.708330 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:17:25.708330 12164 solver.cpp:237]     Train net output #1: loss = 0.0125298 (* 1 = 0.0125298 loss)
I1203 17:17:25.708330 12164 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1203 17:17:33.911968 12164 solver.cpp:218] Iteration 116800 (12.1907 iter/s, 8.20299s/100 iters), loss = 0.0150546
I1203 17:17:33.911968 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:17:33.911968 12164 solver.cpp:237]     Train net output #1: loss = 0.0150545 (* 1 = 0.0150545 loss)
I1203 17:17:33.911968 12164 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1203 17:17:42.116801 12164 solver.cpp:218] Iteration 116900 (12.1879 iter/s, 8.20483s/100 iters), loss = 0.0155158
I1203 17:17:42.116801 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:17:42.116801 12164 solver.cpp:237]     Train net output #1: loss = 0.0155158 (* 1 = 0.0155158 loss)
I1203 17:17:42.116801 12164 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1203 17:17:49.955364  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:17:50.281399 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.caffemodel
I1203 17:17:50.317440 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117000.solverstate
I1203 17:17:50.323427 12164 solver.cpp:330] Iteration 117000, Testing net (#0)
I1203 17:17:50.324427 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:17:52.034574 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:17:52.103591 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 17:17:52.103591 12164 solver.cpp:397]     Test net output #1: loss = 0.240196 (* 1 = 0.240196 loss)
I1203 17:17:52.182593 12164 solver.cpp:218] Iteration 117000 (9.93593 iter/s, 10.0645s/100 iters), loss = 0.0245898
I1203 17:17:52.182593 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:17:52.182593 12164 solver.cpp:237]     Train net output #1: loss = 0.0245897 (* 1 = 0.0245897 loss)
I1203 17:17:52.182593 12164 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1203 17:18:00.395509 12164 solver.cpp:218] Iteration 117100 (12.1769 iter/s, 8.21228s/100 iters), loss = 0.0242676
I1203 17:18:00.395509 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:00.395509 12164 solver.cpp:237]     Train net output #1: loss = 0.0242676 (* 1 = 0.0242676 loss)
I1203 17:18:00.395509 12164 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1203 17:18:08.615288 12164 solver.cpp:218] Iteration 117200 (12.1668 iter/s, 8.21909s/100 iters), loss = 0.0233733
I1203 17:18:08.615288 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:08.615288 12164 solver.cpp:237]     Train net output #1: loss = 0.0233733 (* 1 = 0.0233733 loss)
I1203 17:18:08.615288 12164 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1203 17:18:16.834653 12164 solver.cpp:218] Iteration 117300 (12.1665 iter/s, 8.21927s/100 iters), loss = 0.0140374
I1203 17:18:16.834653 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:16.834653 12164 solver.cpp:237]     Train net output #1: loss = 0.0140373 (* 1 = 0.0140373 loss)
I1203 17:18:16.834653 12164 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1203 17:18:25.027868 12164 solver.cpp:218] Iteration 117400 (12.2065 iter/s, 8.19238s/100 iters), loss = 0.0125911
I1203 17:18:25.027868 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:25.027868 12164 solver.cpp:237]     Train net output #1: loss = 0.0125911 (* 1 = 0.0125911 loss)
I1203 17:18:25.027868 12164 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1203 17:18:32.827005  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:18:33.148515 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.caffemodel
I1203 17:18:33.179515 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_117500.solverstate
I1203 17:18:33.186527 12164 solver.cpp:330] Iteration 117500, Testing net (#0)
I1203 17:18:33.187026 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:18:34.915913 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:18:34.984903 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:18:34.984903 12164 solver.cpp:397]     Test net output #1: loss = 0.24096 (* 1 = 0.24096 loss)
I1203 17:18:35.063619 12164 solver.cpp:218] Iteration 117500 (9.9644 iter/s, 10.0357s/100 iters), loss = 0.0269555
I1203 17:18:35.063619 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:35.063619 12164 solver.cpp:237]     Train net output #1: loss = 0.0269554 (* 1 = 0.0269554 loss)
I1203 17:18:35.063619 12164 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1203 17:18:43.265429 12164 solver.cpp:218] Iteration 117600 (12.193 iter/s, 8.20146s/100 iters), loss = 0.0358852
I1203 17:18:43.265429 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:43.265429 12164 solver.cpp:237]     Train net output #1: loss = 0.0358851 (* 1 = 0.0358851 loss)
I1203 17:18:43.265429 12164 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1203 17:18:51.471129 12164 solver.cpp:218] Iteration 117700 (12.1873 iter/s, 8.20524s/100 iters), loss = 0.014577
I1203 17:18:51.471129 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:51.472131 12164 solver.cpp:237]     Train net output #1: loss = 0.0145769 (* 1 = 0.0145769 loss)
I1203 17:18:51.472131 12164 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1203 17:18:59.692231 12164 solver.cpp:218] Iteration 117800 (12.1647 iter/s, 8.22054s/100 iters), loss = 0.0154681
I1203 17:18:59.692231 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:18:59.692231 12164 solver.cpp:237]     Train net output #1: loss = 0.0154681 (* 1 = 0.0154681 loss)
I1203 17:18:59.692231 12164 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1203 17:19:07.923132 12164 solver.cpp:218] Iteration 117900 (12.1511 iter/s, 8.22969s/100 iters), loss = 0.00915066
I1203 17:19:07.923132 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:19:07.923132 12164 solver.cpp:237]     Train net output #1: loss = 0.0091506 (* 1 = 0.0091506 loss)
I1203 17:19:07.923132 12164 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1203 17:19:15.723179  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:19:16.050205 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.caffemodel
I1203 17:19:16.082207 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118000.solverstate
I1203 17:19:16.088207 12164 solver.cpp:330] Iteration 118000, Testing net (#0)
I1203 17:19:16.089210 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:19:17.797967 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:19:17.864470 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 17:19:17.864470 12164 solver.cpp:397]     Test net output #1: loss = 0.243794 (* 1 = 0.243794 loss)
I1203 17:19:17.939479 12164 solver.cpp:218] Iteration 118000 (9.98398 iter/s, 10.016s/100 iters), loss = 0.0223478
I1203 17:19:17.939479 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:19:17.939479 12164 solver.cpp:237]     Train net output #1: loss = 0.0223477 (* 1 = 0.0223477 loss)
I1203 17:19:17.939479 12164 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1203 17:19:26.182760 12164 solver.cpp:218] Iteration 118100 (12.1314 iter/s, 8.24308s/100 iters), loss = 0.0151815
I1203 17:19:26.182760 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:19:26.182760 12164 solver.cpp:237]     Train net output #1: loss = 0.0151815 (* 1 = 0.0151815 loss)
I1203 17:19:26.182760 12164 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1203 17:19:34.393715 12164 solver.cpp:218] Iteration 118200 (12.1804 iter/s, 8.20992s/100 iters), loss = 0.0277457
I1203 17:19:34.393715 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:19:34.393715 12164 solver.cpp:237]     Train net output #1: loss = 0.0277457 (* 1 = 0.0277457 loss)
I1203 17:19:34.393715 12164 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1203 17:19:42.598419 12164 solver.cpp:218] Iteration 118300 (12.1888 iter/s, 8.20428s/100 iters), loss = 0.0130755
I1203 17:19:42.598419 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:19:42.598419 12164 solver.cpp:237]     Train net output #1: loss = 0.0130754 (* 1 = 0.0130754 loss)
I1203 17:19:42.598419 12164 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1203 17:19:50.801791 12164 solver.cpp:218] Iteration 118400 (12.1911 iter/s, 8.20268s/100 iters), loss = 0.0114942
I1203 17:19:50.801791 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:19:50.801791 12164 solver.cpp:237]     Train net output #1: loss = 0.0114941 (* 1 = 0.0114941 loss)
I1203 17:19:50.801791 12164 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1203 17:19:58.625502  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:19:58.954924 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.caffemodel
I1203 17:19:58.989924 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_118500.solverstate
I1203 17:19:58.995935 12164 solver.cpp:330] Iteration 118500, Testing net (#0)
I1203 17:19:58.995935 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:20:00.704130 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:20:00.773687 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9324
I1203 17:20:00.773687 12164 solver.cpp:397]     Test net output #1: loss = 0.239443 (* 1 = 0.239443 loss)
I1203 17:20:00.853206 12164 solver.cpp:218] Iteration 118500 (9.94973 iter/s, 10.0505s/100 iters), loss = 0.0131384
I1203 17:20:00.853206 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:00.853206 12164 solver.cpp:237]     Train net output #1: loss = 0.0131384 (* 1 = 0.0131384 loss)
I1203 17:20:00.853206 12164 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1203 17:20:09.057170 12164 solver.cpp:218] Iteration 118600 (12.1895 iter/s, 8.20381s/100 iters), loss = 0.0200834
I1203 17:20:09.057170 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:09.057170 12164 solver.cpp:237]     Train net output #1: loss = 0.0200833 (* 1 = 0.0200833 loss)
I1203 17:20:09.057170 12164 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1203 17:20:17.289044 12164 solver.cpp:218] Iteration 118700 (12.149 iter/s, 8.23111s/100 iters), loss = 0.0204574
I1203 17:20:17.289044 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:17.289044 12164 solver.cpp:237]     Train net output #1: loss = 0.0204574 (* 1 = 0.0204574 loss)
I1203 17:20:17.289044 12164 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1203 17:20:25.494429 12164 solver.cpp:218] Iteration 118800 (12.187 iter/s, 8.20544s/100 iters), loss = 0.0159955
I1203 17:20:25.494429 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:25.494429 12164 solver.cpp:237]     Train net output #1: loss = 0.0159955 (* 1 = 0.0159955 loss)
I1203 17:20:25.494429 12164 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1203 17:20:33.706277 12164 solver.cpp:218] Iteration 118900 (12.1793 iter/s, 8.21068s/100 iters), loss = 0.0132346
I1203 17:20:33.706277 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:33.706277 12164 solver.cpp:237]     Train net output #1: loss = 0.0132346 (* 1 = 0.0132346 loss)
I1203 17:20:33.706277 12164 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1203 17:20:41.518373  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:20:41.834409 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.caffemodel
I1203 17:20:41.861409 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119000.solverstate
I1203 17:20:41.867409 12164 solver.cpp:330] Iteration 119000, Testing net (#0)
I1203 17:20:41.868412 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:20:43.594609 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:20:43.663619 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1203 17:20:43.663619 12164 solver.cpp:397]     Test net output #1: loss = 0.242413 (* 1 = 0.242413 loss)
I1203 17:20:43.741631 12164 solver.cpp:218] Iteration 119000 (9.96503 iter/s, 10.0351s/100 iters), loss = 0.0134551
I1203 17:20:43.741631 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:43.741631 12164 solver.cpp:237]     Train net output #1: loss = 0.013455 (* 1 = 0.013455 loss)
I1203 17:20:43.741631 12164 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1203 17:20:51.956913 12164 solver.cpp:218] Iteration 119100 (12.1726 iter/s, 8.21514s/100 iters), loss = 0.0254979
I1203 17:20:51.956913 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:20:51.957914 12164 solver.cpp:237]     Train net output #1: loss = 0.0254978 (* 1 = 0.0254978 loss)
I1203 17:20:51.957914 12164 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1203 17:21:00.167228 12164 solver.cpp:218] Iteration 119200 (12.1818 iter/s, 8.20896s/100 iters), loss = 0.0195163
I1203 17:21:00.167228 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:00.167228 12164 solver.cpp:237]     Train net output #1: loss = 0.0195162 (* 1 = 0.0195162 loss)
I1203 17:21:00.167228 12164 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1203 17:21:08.400192 12164 solver.cpp:218] Iteration 119300 (12.1467 iter/s, 8.23266s/100 iters), loss = 0.0127836
I1203 17:21:08.400192 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:08.400192 12164 solver.cpp:237]     Train net output #1: loss = 0.0127836 (* 1 = 0.0127836 loss)
I1203 17:21:08.400192 12164 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1203 17:21:16.603526 12164 solver.cpp:218] Iteration 119400 (12.1916 iter/s, 8.20237s/100 iters), loss = 0.0117131
I1203 17:21:16.603526 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:16.603526 12164 solver.cpp:237]     Train net output #1: loss = 0.0117131 (* 1 = 0.0117131 loss)
I1203 17:21:16.603526 12164 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1203 17:21:24.404448  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:21:24.735491 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.caffemodel
I1203 17:21:24.765475 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_119500.solverstate
I1203 17:21:24.772490 12164 solver.cpp:330] Iteration 119500, Testing net (#0)
I1203 17:21:24.772490 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:21:26.490895 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:21:26.556895 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1203 17:21:26.556895 12164 solver.cpp:397]     Test net output #1: loss = 0.243099 (* 1 = 0.243099 loss)
I1203 17:21:26.630900 12164 solver.cpp:218] Iteration 119500 (9.97242 iter/s, 10.0277s/100 iters), loss = 0.0183497
I1203 17:21:26.630900 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:26.630900 12164 solver.cpp:237]     Train net output #1: loss = 0.0183496 (* 1 = 0.0183496 loss)
I1203 17:21:26.630900 12164 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1203 17:21:34.844846 12164 solver.cpp:218] Iteration 119600 (12.1752 iter/s, 8.21344s/100 iters), loss = 0.0241612
I1203 17:21:34.844846 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:34.844846 12164 solver.cpp:237]     Train net output #1: loss = 0.0241611 (* 1 = 0.0241611 loss)
I1203 17:21:34.844846 12164 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1203 17:21:43.048172 12164 solver.cpp:218] Iteration 119700 (12.1923 iter/s, 8.20191s/100 iters), loss = 0.0324286
I1203 17:21:43.048172 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:21:43.048172 12164 solver.cpp:237]     Train net output #1: loss = 0.0324285 (* 1 = 0.0324285 loss)
I1203 17:21:43.048172 12164 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1203 17:21:51.262382 12164 solver.cpp:218] Iteration 119800 (12.1739 iter/s, 8.21432s/100 iters), loss = 0.0102159
I1203 17:21:51.262382 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:51.262382 12164 solver.cpp:237]     Train net output #1: loss = 0.0102159 (* 1 = 0.0102159 loss)
I1203 17:21:51.262382 12164 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1203 17:21:59.477098 12164 solver.cpp:218] Iteration 119900 (12.1738 iter/s, 8.21436s/100 iters), loss = 0.0139977
I1203 17:21:59.477098 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:21:59.477098 12164 solver.cpp:237]     Train net output #1: loss = 0.0139976 (* 1 = 0.0139976 loss)
I1203 17:21:59.477098 12164 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1203 17:22:07.289443  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:22:07.616485 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.caffemodel
I1203 17:22:07.649485 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120000.solverstate
I1203 17:22:07.656483 12164 solver.cpp:330] Iteration 120000, Testing net (#0)
I1203 17:22:07.656483 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:22:09.358781 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:22:09.428791 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1203 17:22:09.428791 12164 solver.cpp:397]     Test net output #1: loss = 0.244601 (* 1 = 0.244601 loss)
I1203 17:22:09.506816 12164 solver.cpp:218] Iteration 120000 (9.97128 iter/s, 10.0288s/100 iters), loss = 0.0169925
I1203 17:22:09.507316 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:22:09.507316 12164 solver.cpp:237]     Train net output #1: loss = 0.0169925 (* 1 = 0.0169925 loss)
I1203 17:22:09.507316 12164 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1203 17:22:17.711843 12164 solver.cpp:218] Iteration 120100 (12.1889 iter/s, 8.20416s/100 iters), loss = 0.0237314
I1203 17:22:17.711843 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:22:17.711843 12164 solver.cpp:237]     Train net output #1: loss = 0.0237313 (* 1 = 0.0237313 loss)
I1203 17:22:17.711843 12164 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1203 17:22:25.928958 12164 solver.cpp:218] Iteration 120200 (12.1702 iter/s, 8.21678s/100 iters), loss = 0.0123913
I1203 17:22:25.928958 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:22:25.928958 12164 solver.cpp:237]     Train net output #1: loss = 0.0123913 (* 1 = 0.0123913 loss)
I1203 17:22:25.928958 12164 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1203 17:22:34.129292 12164 solver.cpp:218] Iteration 120300 (12.195 iter/s, 8.20007s/100 iters), loss = 0.0199606
I1203 17:22:34.129292 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:22:34.129292 12164 solver.cpp:237]     Train net output #1: loss = 0.0199606 (* 1 = 0.0199606 loss)
I1203 17:22:34.129292 12164 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1203 17:22:42.331773 12164 solver.cpp:218] Iteration 120400 (12.1923 iter/s, 8.20191s/100 iters), loss = 0.0179933
I1203 17:22:42.331773 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:22:42.331773 12164 solver.cpp:237]     Train net output #1: loss = 0.0179932 (* 1 = 0.0179932 loss)
I1203 17:22:42.331773 12164 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1203 17:22:50.191578  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:22:50.508631 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.caffemodel
I1203 17:22:50.541631 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_120500.solverstate
I1203 17:22:50.547632 12164 solver.cpp:330] Iteration 120500, Testing net (#0)
I1203 17:22:50.547632 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:22:52.262802 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:22:52.331806 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 17:22:52.331806 12164 solver.cpp:397]     Test net output #1: loss = 0.240459 (* 1 = 0.240459 loss)
I1203 17:22:52.409819 12164 solver.cpp:218] Iteration 120500 (9.92344 iter/s, 10.0772s/100 iters), loss = 0.0153541
I1203 17:22:52.409819 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:22:52.409819 12164 solver.cpp:237]     Train net output #1: loss = 0.015354 (* 1 = 0.015354 loss)
I1203 17:22:52.409819 12164 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1203 17:23:00.585300 12164 solver.cpp:218] Iteration 120600 (12.2328 iter/s, 8.17474s/100 iters), loss = 0.0145647
I1203 17:23:00.585300 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:00.585300 12164 solver.cpp:237]     Train net output #1: loss = 0.0145646 (* 1 = 0.0145646 loss)
I1203 17:23:00.585300 12164 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1203 17:23:08.755195 12164 solver.cpp:218] Iteration 120700 (12.2397 iter/s, 8.17015s/100 iters), loss = 0.0168576
I1203 17:23:08.755195 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:08.755195 12164 solver.cpp:237]     Train net output #1: loss = 0.0168576 (* 1 = 0.0168576 loss)
I1203 17:23:08.755195 12164 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1203 17:23:16.933779 12164 solver.cpp:218] Iteration 120800 (12.2292 iter/s, 8.17714s/100 iters), loss = 0.0164352
I1203 17:23:16.933779 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:16.933779 12164 solver.cpp:237]     Train net output #1: loss = 0.0164352 (* 1 = 0.0164352 loss)
I1203 17:23:16.933779 12164 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1203 17:23:25.096799 12164 solver.cpp:218] Iteration 120900 (12.2512 iter/s, 8.16247s/100 iters), loss = 0.0124004
I1203 17:23:25.096799 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:25.096799 12164 solver.cpp:237]     Train net output #1: loss = 0.0124003 (* 1 = 0.0124003 loss)
I1203 17:23:25.096799 12164 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1203 17:23:32.846027  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:23:33.166052 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.caffemodel
I1203 17:23:33.199062 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121000.solverstate
I1203 17:23:33.206064 12164 solver.cpp:330] Iteration 121000, Testing net (#0)
I1203 17:23:33.206064 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:23:34.926153 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:23:34.994154 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1203 17:23:34.994154 12164 solver.cpp:397]     Test net output #1: loss = 0.242286 (* 1 = 0.242286 loss)
I1203 17:23:35.072155 12164 solver.cpp:218] Iteration 121000 (10.0248 iter/s, 9.97522s/100 iters), loss = 0.0159267
I1203 17:23:35.072155 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:35.072155 12164 solver.cpp:237]     Train net output #1: loss = 0.0159266 (* 1 = 0.0159266 loss)
I1203 17:23:35.072155 12164 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1203 17:23:43.226284 12164 solver.cpp:218] Iteration 121100 (12.2646 iter/s, 8.15357s/100 iters), loss = 0.0242189
I1203 17:23:43.226284 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:43.226284 12164 solver.cpp:237]     Train net output #1: loss = 0.0242188 (* 1 = 0.0242188 loss)
I1203 17:23:43.226284 12164 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1203 17:23:51.396492 12164 solver.cpp:218] Iteration 121200 (12.2408 iter/s, 8.1694s/100 iters), loss = 0.0136834
I1203 17:23:51.396492 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:51.396492 12164 solver.cpp:237]     Train net output #1: loss = 0.0136834 (* 1 = 0.0136834 loss)
I1203 17:23:51.396492 12164 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1203 17:23:59.589422 12164 solver.cpp:218] Iteration 121300 (12.2071 iter/s, 8.19196s/100 iters), loss = 0.0134531
I1203 17:23:59.589422 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:23:59.589422 12164 solver.cpp:237]     Train net output #1: loss = 0.013453 (* 1 = 0.013453 loss)
I1203 17:23:59.589422 12164 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1203 17:24:07.807500 12164 solver.cpp:218] Iteration 121400 (12.1681 iter/s, 8.21818s/100 iters), loss = 0.0105447
I1203 17:24:07.807500 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:24:07.807500 12164 solver.cpp:237]     Train net output #1: loss = 0.0105446 (* 1 = 0.0105446 loss)
I1203 17:24:07.807500 12164 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1203 17:24:15.611701  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:24:15.940721 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.caffemodel
I1203 17:24:15.976722 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_121500.solverstate
I1203 17:24:15.983728 12164 solver.cpp:330] Iteration 121500, Testing net (#0)
I1203 17:24:15.983728 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:24:17.696931 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:24:17.764935 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9339
I1203 17:24:17.764935 12164 solver.cpp:397]     Test net output #1: loss = 0.243577 (* 1 = 0.243577 loss)
I1203 17:24:17.838953 12164 solver.cpp:218] Iteration 121500 (9.96968 iter/s, 10.0304s/100 iters), loss = 0.0301149
I1203 17:24:17.838953 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:24:17.838953 12164 solver.cpp:237]     Train net output #1: loss = 0.0301149 (* 1 = 0.0301149 loss)
I1203 17:24:17.838953 12164 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1203 17:24:26.063359 12164 solver.cpp:218] Iteration 121600 (12.1592 iter/s, 8.22422s/100 iters), loss = 0.0222477
I1203 17:24:26.063359 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:24:26.063359 12164 solver.cpp:237]     Train net output #1: loss = 0.0222476 (* 1 = 0.0222476 loss)
I1203 17:24:26.063359 12164 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1203 17:24:34.269583 12164 solver.cpp:218] Iteration 121700 (12.1868 iter/s, 8.20559s/100 iters), loss = 0.0148208
I1203 17:24:34.269583 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:24:34.269583 12164 solver.cpp:237]     Train net output #1: loss = 0.0148208 (* 1 = 0.0148208 loss)
I1203 17:24:34.269583 12164 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1203 17:24:42.469740 12164 solver.cpp:218] Iteration 121800 (12.1953 iter/s, 8.19987s/100 iters), loss = 0.0146595
I1203 17:24:42.469740 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:24:42.469740 12164 solver.cpp:237]     Train net output #1: loss = 0.0146594 (* 1 = 0.0146594 loss)
I1203 17:24:42.469740 12164 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1203 17:24:50.681716 12164 solver.cpp:218] Iteration 121900 (12.1781 iter/s, 8.21143s/100 iters), loss = 0.0143342
I1203 17:24:50.681716 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:24:50.681716 12164 solver.cpp:237]     Train net output #1: loss = 0.0143341 (* 1 = 0.0143341 loss)
I1203 17:24:50.681716 12164 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1203 17:24:58.488914  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:24:58.816653 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.caffemodel
I1203 17:24:58.849647 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122000.solverstate
I1203 17:24:58.856637 12164 solver.cpp:330] Iteration 122000, Testing net (#0)
I1203 17:24:58.856637 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:25:00.561799 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:25:00.629391 12164 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1203 17:25:00.630391 12164 solver.cpp:397]     Test net output #1: loss = 0.241082 (* 1 = 0.241082 loss)
I1203 17:25:00.708693 12164 solver.cpp:218] Iteration 122000 (9.97374 iter/s, 10.0263s/100 iters), loss = 0.0170288
I1203 17:25:00.708693 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:00.708693 12164 solver.cpp:237]     Train net output #1: loss = 0.0170287 (* 1 = 0.0170287 loss)
I1203 17:25:00.708693 12164 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1203 17:25:08.909162 12164 solver.cpp:218] Iteration 122100 (12.1949 iter/s, 8.20016s/100 iters), loss = 0.0210451
I1203 17:25:08.909162 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:08.909162 12164 solver.cpp:237]     Train net output #1: loss = 0.021045 (* 1 = 0.021045 loss)
I1203 17:25:08.909162 12164 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1203 17:25:17.136041 12164 solver.cpp:218] Iteration 122200 (12.1573 iter/s, 8.22549s/100 iters), loss = 0.0196687
I1203 17:25:17.136041 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:17.136041 12164 solver.cpp:237]     Train net output #1: loss = 0.0196686 (* 1 = 0.0196686 loss)
I1203 17:25:17.136041 12164 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1203 17:25:25.340737 12164 solver.cpp:218] Iteration 122300 (12.1879 iter/s, 8.20488s/100 iters), loss = 0.0156241
I1203 17:25:25.340737 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:25.340737 12164 solver.cpp:237]     Train net output #1: loss = 0.015624 (* 1 = 0.015624 loss)
I1203 17:25:25.340737 12164 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1203 17:25:33.546558 12164 solver.cpp:218] Iteration 122400 (12.1875 iter/s, 8.20512s/100 iters), loss = 0.0117779
I1203 17:25:33.546558 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:33.546558 12164 solver.cpp:237]     Train net output #1: loss = 0.0117778 (* 1 = 0.0117778 loss)
I1203 17:25:33.546558 12164 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1203 17:25:41.361032  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:25:41.677063 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.caffemodel
I1203 17:25:41.705065 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_122500.solverstate
I1203 17:25:41.711570 12164 solver.cpp:330] Iteration 122500, Testing net (#0)
I1203 17:25:41.711570 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:25:43.429277 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:25:43.498277 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:25:43.498277 12164 solver.cpp:397]     Test net output #1: loss = 0.242113 (* 1 = 0.242113 loss)
I1203 17:25:43.575291 12164 solver.cpp:218] Iteration 122500 (9.97204 iter/s, 10.028s/100 iters), loss = 0.0152996
I1203 17:25:43.575291 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:43.575291 12164 solver.cpp:237]     Train net output #1: loss = 0.0152995 (* 1 = 0.0152995 loss)
I1203 17:25:43.575291 12164 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1203 17:25:51.772634 12164 solver.cpp:218] Iteration 122600 (12.1999 iter/s, 8.19679s/100 iters), loss = 0.013015
I1203 17:25:51.772634 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:51.772634 12164 solver.cpp:237]     Train net output #1: loss = 0.0130149 (* 1 = 0.0130149 loss)
I1203 17:25:51.772634 12164 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1203 17:25:59.986438 12164 solver.cpp:218] Iteration 122700 (12.1752 iter/s, 8.2134s/100 iters), loss = 0.0152444
I1203 17:25:59.986438 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:25:59.986438 12164 solver.cpp:237]     Train net output #1: loss = 0.0152444 (* 1 = 0.0152444 loss)
I1203 17:25:59.986438 12164 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1203 17:26:08.213691 12164 solver.cpp:218] Iteration 122800 (12.1563 iter/s, 8.22618s/100 iters), loss = 0.0099937
I1203 17:26:08.213691 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:08.213691 12164 solver.cpp:237]     Train net output #1: loss = 0.00999363 (* 1 = 0.00999363 loss)
I1203 17:26:08.213691 12164 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1203 17:26:16.413547 12164 solver.cpp:218] Iteration 122900 (12.1961 iter/s, 8.19934s/100 iters), loss = 0.0108002
I1203 17:26:16.413547 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:16.413547 12164 solver.cpp:237]     Train net output #1: loss = 0.0108001 (* 1 = 0.0108001 loss)
I1203 17:26:16.413547 12164 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1203 17:26:24.211552  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:26:24.536499 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.caffemodel
I1203 17:26:24.572135 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123000.solverstate
I1203 17:26:24.578133 12164 solver.cpp:330] Iteration 123000, Testing net (#0)
I1203 17:26:24.578133 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:26:26.299376 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:26:26.366919 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9323
I1203 17:26:26.366919 12164 solver.cpp:397]     Test net output #1: loss = 0.244085 (* 1 = 0.244085 loss)
I1203 17:26:26.440932 12164 solver.cpp:218] Iteration 123000 (9.97307 iter/s, 10.027s/100 iters), loss = 0.0184868
I1203 17:26:26.440932 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:26.440932 12164 solver.cpp:237]     Train net output #1: loss = 0.0184868 (* 1 = 0.0184868 loss)
I1203 17:26:26.440932 12164 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1203 17:26:34.659981 12164 solver.cpp:218] Iteration 123100 (12.1667 iter/s, 8.21916s/100 iters), loss = 0.0163819
I1203 17:26:34.660974 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:34.660974 12164 solver.cpp:237]     Train net output #1: loss = 0.0163819 (* 1 = 0.0163819 loss)
I1203 17:26:34.660974 12164 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1203 17:26:42.867146 12164 solver.cpp:218] Iteration 123200 (12.1853 iter/s, 8.20659s/100 iters), loss = 0.0120262
I1203 17:26:42.868135 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:42.868135 12164 solver.cpp:237]     Train net output #1: loss = 0.0120261 (* 1 = 0.0120261 loss)
I1203 17:26:42.868135 12164 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1203 17:26:51.061095 12164 solver.cpp:218] Iteration 123300 (12.2055 iter/s, 8.19304s/100 iters), loss = 0.0112477
I1203 17:26:51.061095 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:51.061095 12164 solver.cpp:237]     Train net output #1: loss = 0.0112476 (* 1 = 0.0112476 loss)
I1203 17:26:51.061095 12164 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1203 17:26:59.285384 12164 solver.cpp:218] Iteration 123400 (12.1599 iter/s, 8.22374s/100 iters), loss = 0.0124713
I1203 17:26:59.285384 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:26:59.285384 12164 solver.cpp:237]     Train net output #1: loss = 0.0124712 (* 1 = 0.0124712 loss)
I1203 17:26:59.285384 12164 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1203 17:27:07.077632  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:27:07.401962 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.caffemodel
I1203 17:27:07.434978 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_123500.solverstate
I1203 17:27:07.441998 12164 solver.cpp:330] Iteration 123500, Testing net (#0)
I1203 17:27:07.441998 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:27:09.144913 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:27:09.213397 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 17:27:09.213397 12164 solver.cpp:397]     Test net output #1: loss = 0.244503 (* 1 = 0.244503 loss)
I1203 17:27:09.293053 12164 solver.cpp:218] Iteration 123500 (9.99309 iter/s, 10.0069s/100 iters), loss = 0.0168067
I1203 17:27:09.293053 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:27:09.293053 12164 solver.cpp:237]     Train net output #1: loss = 0.0168066 (* 1 = 0.0168066 loss)
I1203 17:27:09.293053 12164 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1203 17:27:17.513329 12164 solver.cpp:218] Iteration 123600 (12.1657 iter/s, 8.21986s/100 iters), loss = 0.0168818
I1203 17:27:17.513329 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:27:17.513329 12164 solver.cpp:237]     Train net output #1: loss = 0.0168818 (* 1 = 0.0168818 loss)
I1203 17:27:17.513329 12164 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1203 17:27:25.729071 12164 solver.cpp:218] Iteration 123700 (12.1728 iter/s, 8.21504s/100 iters), loss = 0.0129324
I1203 17:27:25.729071 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:27:25.729071 12164 solver.cpp:237]     Train net output #1: loss = 0.0129324 (* 1 = 0.0129324 loss)
I1203 17:27:25.729071 12164 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1203 17:27:33.931025 12164 solver.cpp:218] Iteration 123800 (12.1924 iter/s, 8.20182s/100 iters), loss = 0.00959635
I1203 17:27:33.931025 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:27:33.931025 12164 solver.cpp:237]     Train net output #1: loss = 0.00959627 (* 1 = 0.00959627 loss)
I1203 17:27:33.931025 12164 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1203 17:27:42.133410 12164 solver.cpp:218] Iteration 123900 (12.1931 iter/s, 8.20137s/100 iters), loss = 0.0153614
I1203 17:27:42.133410 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:27:42.133410 12164 solver.cpp:237]     Train net output #1: loss = 0.0153613 (* 1 = 0.0153613 loss)
I1203 17:27:42.133410 12164 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1203 17:27:49.962841  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:27:50.285393 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.caffemodel
I1203 17:27:50.313395 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124000.solverstate
I1203 17:27:50.320395 12164 solver.cpp:330] Iteration 124000, Testing net (#0)
I1203 17:27:50.320395 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:27:52.032546 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:27:52.100553 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9332
I1203 17:27:52.100553 12164 solver.cpp:397]     Test net output #1: loss = 0.244729 (* 1 = 0.244729 loss)
I1203 17:27:52.178556 12164 solver.cpp:218] Iteration 124000 (9.95549 iter/s, 10.0447s/100 iters), loss = 0.0135003
I1203 17:27:52.178556 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:27:52.178556 12164 solver.cpp:237]     Train net output #1: loss = 0.0135002 (* 1 = 0.0135002 loss)
I1203 17:27:52.178556 12164 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1203 17:28:00.390966 12164 solver.cpp:218] Iteration 124100 (12.177 iter/s, 8.21221s/100 iters), loss = 0.0249847
I1203 17:28:00.390966 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:00.390966 12164 solver.cpp:237]     Train net output #1: loss = 0.0249847 (* 1 = 0.0249847 loss)
I1203 17:28:00.390966 12164 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1203 17:28:08.596920 12164 solver.cpp:218] Iteration 124200 (12.1876 iter/s, 8.20504s/100 iters), loss = 0.0277744
I1203 17:28:08.596920 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:28:08.596920 12164 solver.cpp:237]     Train net output #1: loss = 0.0277743 (* 1 = 0.0277743 loss)
I1203 17:28:08.596920 12164 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1203 17:28:16.797559 12164 solver.cpp:218] Iteration 124300 (12.1953 iter/s, 8.1999s/100 iters), loss = 0.0133815
I1203 17:28:16.797559 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:16.797559 12164 solver.cpp:237]     Train net output #1: loss = 0.0133814 (* 1 = 0.0133814 loss)
I1203 17:28:16.797559 12164 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1203 17:28:24.994945 12164 solver.cpp:218] Iteration 124400 (12.1986 iter/s, 8.19765s/100 iters), loss = 0.0154784
I1203 17:28:24.994945 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:24.994945 12164 solver.cpp:237]     Train net output #1: loss = 0.0154784 (* 1 = 0.0154784 loss)
I1203 17:28:24.995944 12164 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1203 17:28:32.793967  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:28:33.114501 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.caffemodel
I1203 17:28:33.144004 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_124500.solverstate
I1203 17:28:33.151012 12164 solver.cpp:330] Iteration 124500, Testing net (#0)
I1203 17:28:33.152005 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:28:34.880321 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:28:34.949327 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:28:34.949327 12164 solver.cpp:397]     Test net output #1: loss = 0.245016 (* 1 = 0.245016 loss)
I1203 17:28:35.026331 12164 solver.cpp:218] Iteration 124500 (9.96994 iter/s, 10.0302s/100 iters), loss = 0.0130758
I1203 17:28:35.026331 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:35.026331 12164 solver.cpp:237]     Train net output #1: loss = 0.0130757 (* 1 = 0.0130757 loss)
I1203 17:28:35.026331 12164 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1203 17:28:43.220679 12164 solver.cpp:218] Iteration 124600 (12.2043 iter/s, 8.19382s/100 iters), loss = 0.0162259
I1203 17:28:43.220679 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:43.221179 12164 solver.cpp:237]     Train net output #1: loss = 0.0162258 (* 1 = 0.0162258 loss)
I1203 17:28:43.221179 12164 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1203 17:28:51.420018 12164 solver.cpp:218] Iteration 124700 (12.197 iter/s, 8.19876s/100 iters), loss = 0.0155502
I1203 17:28:51.420018 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:51.420018 12164 solver.cpp:237]     Train net output #1: loss = 0.0155501 (* 1 = 0.0155501 loss)
I1203 17:28:51.420018 12164 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1203 17:28:59.636862 12164 solver.cpp:218] Iteration 124800 (12.1709 iter/s, 8.21629s/100 iters), loss = 0.0108603
I1203 17:28:59.636862 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:28:59.636862 12164 solver.cpp:237]     Train net output #1: loss = 0.0108603 (* 1 = 0.0108603 loss)
I1203 17:28:59.636862 12164 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1203 17:29:07.851676 12164 solver.cpp:218] Iteration 124900 (12.1733 iter/s, 8.21469s/100 iters), loss = 0.0178486
I1203 17:29:07.851676 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:29:07.851676 12164 solver.cpp:237]     Train net output #1: loss = 0.0178485 (* 1 = 0.0178485 loss)
I1203 17:29:07.851676 12164 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1203 17:29:15.654443  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:29:15.982470 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.caffemodel
I1203 17:29:16.010975 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125000.solverstate
I1203 17:29:16.017480 12164 solver.cpp:330] Iteration 125000, Testing net (#0)
I1203 17:29:16.017480 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:29:17.727638 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:29:17.794636 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1203 17:29:17.794636 12164 solver.cpp:397]     Test net output #1: loss = 0.24559 (* 1 = 0.24559 loss)
I1203 17:29:17.870642 12164 solver.cpp:218] Iteration 125000 (9.98223 iter/s, 10.0178s/100 iters), loss = 0.0118554
I1203 17:29:17.870642 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:29:17.870642 12164 solver.cpp:237]     Train net output #1: loss = 0.0118553 (* 1 = 0.0118553 loss)
I1203 17:29:17.870642 12164 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1203 17:29:26.104665 12164 solver.cpp:218] Iteration 125100 (12.1451 iter/s, 8.23378s/100 iters), loss = 0.0330565
I1203 17:29:26.104665 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:29:26.104665 12164 solver.cpp:237]     Train net output #1: loss = 0.0330564 (* 1 = 0.0330564 loss)
I1203 17:29:26.104665 12164 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1203 17:29:34.305455 12164 solver.cpp:218] Iteration 125200 (12.1945 iter/s, 8.2004s/100 iters), loss = 0.0167975
I1203 17:29:34.305455 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:29:34.305455 12164 solver.cpp:237]     Train net output #1: loss = 0.0167974 (* 1 = 0.0167974 loss)
I1203 17:29:34.305455 12164 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1203 17:29:42.513762 12164 solver.cpp:218] Iteration 125300 (12.184 iter/s, 8.20751s/100 iters), loss = 0.00811643
I1203 17:29:42.513762 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:29:42.513762 12164 solver.cpp:237]     Train net output #1: loss = 0.00811631 (* 1 = 0.00811631 loss)
I1203 17:29:42.513762 12164 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1203 17:29:50.732409 12164 solver.cpp:218] Iteration 125400 (12.1679 iter/s, 8.21832s/100 iters), loss = 0.0138586
I1203 17:29:50.732909 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:29:50.732909 12164 solver.cpp:237]     Train net output #1: loss = 0.0138585 (* 1 = 0.0138585 loss)
I1203 17:29:50.732909 12164 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1203 17:29:58.547684  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:29:58.874312 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.caffemodel
I1203 17:29:58.905311 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_125500.solverstate
I1203 17:29:58.911311 12164 solver.cpp:330] Iteration 125500, Testing net (#0)
I1203 17:29:58.912310 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:30:00.620229 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:30:00.689234 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 17:30:00.689234 12164 solver.cpp:397]     Test net output #1: loss = 0.245571 (* 1 = 0.245571 loss)
I1203 17:30:00.767238 12164 solver.cpp:218] Iteration 125500 (9.96619 iter/s, 10.0339s/100 iters), loss = 0.0187189
I1203 17:30:00.767238 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:30:00.767238 12164 solver.cpp:237]     Train net output #1: loss = 0.0187188 (* 1 = 0.0187188 loss)
I1203 17:30:00.767238 12164 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1203 17:30:08.970219 12164 solver.cpp:218] Iteration 125600 (12.1914 iter/s, 8.20247s/100 iters), loss = 0.018541
I1203 17:30:08.970219 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:30:08.970219 12164 solver.cpp:237]     Train net output #1: loss = 0.0185409 (* 1 = 0.0185409 loss)
I1203 17:30:08.970219 12164 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1203 17:30:17.200086 12164 solver.cpp:218] Iteration 125700 (12.1515 iter/s, 8.22943s/100 iters), loss = 0.0147353
I1203 17:30:17.200086 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:30:17.200086 12164 solver.cpp:237]     Train net output #1: loss = 0.0147352 (* 1 = 0.0147352 loss)
I1203 17:30:17.200086 12164 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1203 17:30:25.400135 12164 solver.cpp:218] Iteration 125800 (12.1948 iter/s, 8.20023s/100 iters), loss = 0.0292768
I1203 17:30:25.400135 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:30:25.400135 12164 solver.cpp:237]     Train net output #1: loss = 0.0292767 (* 1 = 0.0292767 loss)
I1203 17:30:25.400135 12164 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1203 17:30:33.602537 12164 solver.cpp:218] Iteration 125900 (12.1934 iter/s, 8.20114s/100 iters), loss = 0.0118313
I1203 17:30:33.602537 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:30:33.602537 12164 solver.cpp:237]     Train net output #1: loss = 0.0118312 (* 1 = 0.0118312 loss)
I1203 17:30:33.602537 12164 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1203 17:30:41.414384  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:30:41.731398 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.caffemodel
I1203 17:30:41.761399 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126000.solverstate
I1203 17:30:41.767403 12164 solver.cpp:330] Iteration 126000, Testing net (#0)
I1203 17:30:41.767902 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:30:43.490581 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:30:43.559579 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1203 17:30:43.560580 12164 solver.cpp:397]     Test net output #1: loss = 0.247622 (* 1 = 0.247622 loss)
I1203 17:30:43.637598 12164 solver.cpp:218] Iteration 126000 (9.96538 iter/s, 10.0347s/100 iters), loss = 0.0143978
I1203 17:30:43.637598 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:30:43.637598 12164 solver.cpp:237]     Train net output #1: loss = 0.0143977 (* 1 = 0.0143977 loss)
I1203 17:30:43.637598 12164 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1203 17:30:51.832844 12164 solver.cpp:218] Iteration 126100 (12.2032 iter/s, 8.19457s/100 iters), loss = 0.0203218
I1203 17:30:51.832844 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:30:51.832844 12164 solver.cpp:237]     Train net output #1: loss = 0.0203217 (* 1 = 0.0203217 loss)
I1203 17:30:51.832844 12164 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1203 17:31:00.017652 12164 solver.cpp:218] Iteration 126200 (12.2187 iter/s, 8.18417s/100 iters), loss = 0.0118352
I1203 17:31:00.017652 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:00.017652 12164 solver.cpp:237]     Train net output #1: loss = 0.0118351 (* 1 = 0.0118351 loss)
I1203 17:31:00.017652 12164 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1203 17:31:08.264016 12164 solver.cpp:218] Iteration 126300 (12.1266 iter/s, 8.24632s/100 iters), loss = 0.016575
I1203 17:31:08.264016 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:08.264016 12164 solver.cpp:237]     Train net output #1: loss = 0.0165749 (* 1 = 0.0165749 loss)
I1203 17:31:08.264016 12164 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1203 17:31:16.464114 12164 solver.cpp:218] Iteration 126400 (12.1958 iter/s, 8.19951s/100 iters), loss = 0.0112861
I1203 17:31:16.464114 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:16.464114 12164 solver.cpp:237]     Train net output #1: loss = 0.011286 (* 1 = 0.011286 loss)
I1203 17:31:16.464114 12164 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1203 17:31:24.260475  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:31:24.587693 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.caffemodel
I1203 17:31:24.617197 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_126500.solverstate
I1203 17:31:24.623211 12164 solver.cpp:330] Iteration 126500, Testing net (#0)
I1203 17:31:24.624220 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:31:26.345260 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:31:26.411293 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1203 17:31:26.411293 12164 solver.cpp:397]     Test net output #1: loss = 0.245131 (* 1 = 0.245131 loss)
I1203 17:31:26.488281 12164 solver.cpp:218] Iteration 126500 (9.97688 iter/s, 10.0232s/100 iters), loss = 0.0140796
I1203 17:31:26.488281 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:26.488281 12164 solver.cpp:237]     Train net output #1: loss = 0.0140795 (* 1 = 0.0140795 loss)
I1203 17:31:26.488281 12164 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1203 17:31:34.703562 12164 solver.cpp:218] Iteration 126600 (12.1733 iter/s, 8.21472s/100 iters), loss = 0.0163031
I1203 17:31:34.703562 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:34.703562 12164 solver.cpp:237]     Train net output #1: loss = 0.016303 (* 1 = 0.016303 loss)
I1203 17:31:34.703562 12164 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1203 17:31:42.895157 12164 solver.cpp:218] Iteration 126700 (12.2085 iter/s, 8.19099s/100 iters), loss = 0.0116383
I1203 17:31:42.895157 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:42.895157 12164 solver.cpp:237]     Train net output #1: loss = 0.0116382 (* 1 = 0.0116382 loss)
I1203 17:31:42.895157 12164 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1203 17:31:51.126765 12164 solver.cpp:218] Iteration 126800 (12.1487 iter/s, 8.23134s/100 iters), loss = 0.00855289
I1203 17:31:51.126765 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:51.126765 12164 solver.cpp:237]     Train net output #1: loss = 0.00855281 (* 1 = 0.00855281 loss)
I1203 17:31:51.126765 12164 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1203 17:31:59.379653 12164 solver.cpp:218] Iteration 126900 (12.117 iter/s, 8.25289s/100 iters), loss = 0.0131513
I1203 17:31:59.380653 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:31:59.380653 12164 solver.cpp:237]     Train net output #1: loss = 0.0131513 (* 1 = 0.0131513 loss)
I1203 17:31:59.380653 12164 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1203 17:32:07.194548  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:32:07.521585 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.caffemodel
I1203 17:32:07.550587 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127000.solverstate
I1203 17:32:07.556586 12164 solver.cpp:330] Iteration 127000, Testing net (#0)
I1203 17:32:07.556586 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:32:09.262925 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:32:09.331931 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 17:32:09.331931 12164 solver.cpp:397]     Test net output #1: loss = 0.243588 (* 1 = 0.243588 loss)
I1203 17:32:09.409946 12164 solver.cpp:218] Iteration 127000 (9.97123 iter/s, 10.0289s/100 iters), loss = 0.0134989
I1203 17:32:09.409946 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:32:09.409946 12164 solver.cpp:237]     Train net output #1: loss = 0.0134988 (* 1 = 0.0134988 loss)
I1203 17:32:09.409946 12164 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1203 17:32:17.635135 12164 solver.cpp:218] Iteration 127100 (12.1588 iter/s, 8.22451s/100 iters), loss = 0.0187978
I1203 17:32:17.635135 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:32:17.635135 12164 solver.cpp:237]     Train net output #1: loss = 0.0187977 (* 1 = 0.0187977 loss)
I1203 17:32:17.635135 12164 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1203 17:32:25.862175 12164 solver.cpp:218] Iteration 127200 (12.1552 iter/s, 8.22693s/100 iters), loss = 0.0255702
I1203 17:32:25.862175 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:32:25.862175 12164 solver.cpp:237]     Train net output #1: loss = 0.0255701 (* 1 = 0.0255701 loss)
I1203 17:32:25.862175 12164 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1203 17:32:34.072980 12164 solver.cpp:218] Iteration 127300 (12.1796 iter/s, 8.21042s/100 iters), loss = 0.0111027
I1203 17:32:34.072980 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:32:34.072980 12164 solver.cpp:237]     Train net output #1: loss = 0.0111026 (* 1 = 0.0111026 loss)
I1203 17:32:34.072980 12164 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1203 17:32:42.267927 12164 solver.cpp:218] Iteration 127400 (12.2037 iter/s, 8.19426s/100 iters), loss = 0.0153734
I1203 17:32:42.267927 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:32:42.267927 12164 solver.cpp:237]     Train net output #1: loss = 0.0153733 (* 1 = 0.0153733 loss)
I1203 17:32:42.267927 12164 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1203 17:32:50.109552  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:32:50.427722 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.caffemodel
I1203 17:32:50.456722 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_127500.solverstate
I1203 17:32:50.462723 12164 solver.cpp:330] Iteration 127500, Testing net (#0)
I1203 17:32:50.462723 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:32:52.177687 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:32:52.245199 12164 solver.cpp:397]     Test net output #0: accuracy = 0.932
I1203 17:32:52.245199 12164 solver.cpp:397]     Test net output #1: loss = 0.246439 (* 1 = 0.246439 loss)
I1203 17:32:52.322250 12164 solver.cpp:218] Iteration 127500 (9.94614 iter/s, 10.0541s/100 iters), loss = 0.0142976
I1203 17:32:52.323249 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:32:52.323249 12164 solver.cpp:237]     Train net output #1: loss = 0.0142975 (* 1 = 0.0142975 loss)
I1203 17:32:52.323249 12164 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1203 17:33:00.526059 12164 solver.cpp:218] Iteration 127600 (12.191 iter/s, 8.20274s/100 iters), loss = 0.0228206
I1203 17:33:00.526059 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:00.526059 12164 solver.cpp:237]     Train net output #1: loss = 0.0228205 (* 1 = 0.0228205 loss)
I1203 17:33:00.526059 12164 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1203 17:33:08.738582 12164 solver.cpp:218] Iteration 127700 (12.177 iter/s, 8.21218s/100 iters), loss = 0.0198042
I1203 17:33:08.738582 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:08.738582 12164 solver.cpp:237]     Train net output #1: loss = 0.0198041 (* 1 = 0.0198041 loss)
I1203 17:33:08.738582 12164 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1203 17:33:16.958796 12164 solver.cpp:218] Iteration 127800 (12.1657 iter/s, 8.21986s/100 iters), loss = 0.0110728
I1203 17:33:16.958796 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:16.958796 12164 solver.cpp:237]     Train net output #1: loss = 0.0110727 (* 1 = 0.0110727 loss)
I1203 17:33:16.958796 12164 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1203 17:33:25.155910 12164 solver.cpp:218] Iteration 127900 (12.2001 iter/s, 8.19664s/100 iters), loss = 0.0129513
I1203 17:33:25.156911 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:25.156911 12164 solver.cpp:237]     Train net output #1: loss = 0.0129512 (* 1 = 0.0129512 loss)
I1203 17:33:25.156911 12164 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1203 17:33:32.946692  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:33:33.270736 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.caffemodel
I1203 17:33:33.309741 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128000.solverstate
I1203 17:33:33.315742 12164 solver.cpp:330] Iteration 128000, Testing net (#0)
I1203 17:33:33.316241 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:33:35.042906 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:33:35.112409 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:33:35.112409 12164 solver.cpp:397]     Test net output #1: loss = 0.246913 (* 1 = 0.246913 loss)
I1203 17:33:35.186913 12164 solver.cpp:218] Iteration 128000 (9.96987 iter/s, 10.0302s/100 iters), loss = 0.0213027
I1203 17:33:35.186913 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:35.186913 12164 solver.cpp:237]     Train net output #1: loss = 0.0213026 (* 1 = 0.0213026 loss)
I1203 17:33:35.186913 12164 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1203 17:33:43.357105 12164 solver.cpp:218] Iteration 128100 (12.2411 iter/s, 8.16917s/100 iters), loss = 0.027036
I1203 17:33:43.357105 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:33:43.357105 12164 solver.cpp:237]     Train net output #1: loss = 0.0270359 (* 1 = 0.0270359 loss)
I1203 17:33:43.357105 12164 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1203 17:33:51.529055 12164 solver.cpp:218] Iteration 128200 (12.2379 iter/s, 8.17131s/100 iters), loss = 0.0178161
I1203 17:33:51.529055 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:51.529055 12164 solver.cpp:237]     Train net output #1: loss = 0.017816 (* 1 = 0.017816 loss)
I1203 17:33:51.529055 12164 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1203 17:33:59.696996 12164 solver.cpp:218] Iteration 128300 (12.243 iter/s, 8.16796s/100 iters), loss = 0.0159515
I1203 17:33:59.696996 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:33:59.696996 12164 solver.cpp:237]     Train net output #1: loss = 0.0159514 (* 1 = 0.0159514 loss)
I1203 17:33:59.696996 12164 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1203 17:34:07.865016 12164 solver.cpp:218] Iteration 128400 (12.2431 iter/s, 8.16788s/100 iters), loss = 0.0202008
I1203 17:34:07.866017 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:34:07.866017 12164 solver.cpp:237]     Train net output #1: loss = 0.0202007 (* 1 = 0.0202007 loss)
I1203 17:34:07.866017 12164 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1203 17:34:15.615303  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:34:15.940857 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.caffemodel
I1203 17:34:15.974854 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_128500.solverstate
I1203 17:34:15.981853 12164 solver.cpp:330] Iteration 128500, Testing net (#0)
I1203 17:34:15.981853 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:34:17.682988 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:34:17.750993 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1203 17:34:17.750993 12164 solver.cpp:397]     Test net output #1: loss = 0.250043 (* 1 = 0.250043 loss)
I1203 17:34:17.825994 12164 solver.cpp:218] Iteration 128500 (10.0402 iter/s, 9.95999s/100 iters), loss = 0.0117898
I1203 17:34:17.825994 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:34:17.825994 12164 solver.cpp:237]     Train net output #1: loss = 0.0117897 (* 1 = 0.0117897 loss)
I1203 17:34:17.825994 12164 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1203 17:34:26.010606 12164 solver.cpp:218] Iteration 128600 (12.2186 iter/s, 8.18423s/100 iters), loss = 0.0150011
I1203 17:34:26.010606 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:34:26.010606 12164 solver.cpp:237]     Train net output #1: loss = 0.015001 (* 1 = 0.015001 loss)
I1203 17:34:26.010606 12164 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1203 17:34:34.188380 12164 solver.cpp:218] Iteration 128700 (12.2287 iter/s, 8.17747s/100 iters), loss = 0.0121431
I1203 17:34:34.188380 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:34:34.189380 12164 solver.cpp:237]     Train net output #1: loss = 0.012143 (* 1 = 0.012143 loss)
I1203 17:34:34.189380 12164 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1203 17:34:42.390544 12164 solver.cpp:218] Iteration 128800 (12.1929 iter/s, 8.20149s/100 iters), loss = 0.00967619
I1203 17:34:42.390544 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:34:42.390544 12164 solver.cpp:237]     Train net output #1: loss = 0.00967609 (* 1 = 0.00967609 loss)
I1203 17:34:42.391543 12164 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1203 17:34:50.599345 12164 solver.cpp:218] Iteration 128900 (12.1828 iter/s, 8.2083s/100 iters), loss = 0.012483
I1203 17:34:50.599345 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:34:50.599345 12164 solver.cpp:237]     Train net output #1: loss = 0.0124829 (* 1 = 0.0124829 loss)
I1203 17:34:50.600347 12164 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1203 17:34:58.409325  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:34:58.740412 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.caffemodel
I1203 17:34:58.773413 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129000.solverstate
I1203 17:34:58.779428 12164 solver.cpp:330] Iteration 129000, Testing net (#0)
I1203 17:34:58.779428 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:35:00.485580 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:35:00.553591 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9336
I1203 17:35:00.553591 12164 solver.cpp:397]     Test net output #1: loss = 0.24765 (* 1 = 0.24765 loss)
I1203 17:35:00.630594 12164 solver.cpp:218] Iteration 129000 (9.96988 iter/s, 10.0302s/100 iters), loss = 0.0122742
I1203 17:35:00.631094 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:00.631094 12164 solver.cpp:237]     Train net output #1: loss = 0.0122741 (* 1 = 0.0122741 loss)
I1203 17:35:00.631094 12164 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1203 17:35:08.834229 12164 solver.cpp:218] Iteration 129100 (12.1911 iter/s, 8.20272s/100 iters), loss = 0.0275086
I1203 17:35:08.834229 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:08.834229 12164 solver.cpp:237]     Train net output #1: loss = 0.0275085 (* 1 = 0.0275085 loss)
I1203 17:35:08.834229 12164 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1203 17:35:17.060935 12164 solver.cpp:218] Iteration 129200 (12.1554 iter/s, 8.22682s/100 iters), loss = 0.0117138
I1203 17:35:17.060935 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:17.060935 12164 solver.cpp:237]     Train net output #1: loss = 0.0117137 (* 1 = 0.0117137 loss)
I1203 17:35:17.060935 12164 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1203 17:35:25.266834 12164 solver.cpp:218] Iteration 129300 (12.1867 iter/s, 8.20569s/100 iters), loss = 0.0109225
I1203 17:35:25.267834 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:25.267834 12164 solver.cpp:237]     Train net output #1: loss = 0.0109224 (* 1 = 0.0109224 loss)
I1203 17:35:25.267834 12164 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1203 17:35:33.481554 12164 solver.cpp:218] Iteration 129400 (12.1741 iter/s, 8.21414s/100 iters), loss = 0.0138672
I1203 17:35:33.482555 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:33.482555 12164 solver.cpp:237]     Train net output #1: loss = 0.0138671 (* 1 = 0.0138671 loss)
I1203 17:35:33.482555 12164 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1203 17:35:41.346967  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:35:41.670614 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.caffemodel
I1203 17:35:41.698613 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_129500.solverstate
I1203 17:35:41.704612 12164 solver.cpp:330] Iteration 129500, Testing net (#0)
I1203 17:35:41.704612 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:35:43.439476 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:35:43.507519 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1203 17:35:43.507519 12164 solver.cpp:397]     Test net output #1: loss = 0.243532 (* 1 = 0.243532 loss)
I1203 17:35:43.584550 12164 solver.cpp:218] Iteration 129500 (9.8995 iter/s, 10.1015s/100 iters), loss = 0.0152499
I1203 17:35:43.584550 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:43.584550 12164 solver.cpp:237]     Train net output #1: loss = 0.0152498 (* 1 = 0.0152498 loss)
I1203 17:35:43.584550 12164 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1203 17:35:51.818531 12164 solver.cpp:218] Iteration 129600 (12.1448 iter/s, 8.23396s/100 iters), loss = 0.0140782
I1203 17:35:51.818531 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:35:51.818531 12164 solver.cpp:237]     Train net output #1: loss = 0.0140781 (* 1 = 0.0140781 loss)
I1203 17:35:51.818531 12164 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1203 17:36:00.040402 12164 solver.cpp:218] Iteration 129700 (12.1637 iter/s, 8.2212s/100 iters), loss = 0.0121678
I1203 17:36:00.040402 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:36:00.040402 12164 solver.cpp:237]     Train net output #1: loss = 0.0121676 (* 1 = 0.0121676 loss)
I1203 17:36:00.040402 12164 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1203 17:36:08.275508 12164 solver.cpp:218] Iteration 129800 (12.1435 iter/s, 8.23484s/100 iters), loss = 0.0129534
I1203 17:36:08.275508 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:36:08.275508 12164 solver.cpp:237]     Train net output #1: loss = 0.0129532 (* 1 = 0.0129532 loss)
I1203 17:36:08.275508 12164 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1203 17:36:16.529584 12164 solver.cpp:218] Iteration 129900 (12.1159 iter/s, 8.25359s/100 iters), loss = 0.0157178
I1203 17:36:16.529584 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:36:16.529584 12164 solver.cpp:237]     Train net output #1: loss = 0.0157177 (* 1 = 0.0157177 loss)
I1203 17:36:16.529584 12164 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1203 17:36:24.326086  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:36:24.653647 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.caffemodel
I1203 17:36:24.687151 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130000.solverstate
I1203 17:36:24.694154 12164 solver.cpp:330] Iteration 130000, Testing net (#0)
I1203 17:36:24.694154 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:36:26.415458 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:36:26.481467 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 17:36:26.481467 12164 solver.cpp:397]     Test net output #1: loss = 0.248842 (* 1 = 0.248842 loss)
I1203 17:36:26.556476 12164 solver.cpp:218] Iteration 130000 (9.97421 iter/s, 10.0259s/100 iters), loss = 0.0147974
I1203 17:36:26.556476 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:36:26.556476 12164 solver.cpp:237]     Train net output #1: loss = 0.0147973 (* 1 = 0.0147973 loss)
I1203 17:36:26.556476 12164 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1203 17:36:34.767251 12164 solver.cpp:218] Iteration 130100 (12.1799 iter/s, 8.21026s/100 iters), loss = 0.0341559
I1203 17:36:34.767251 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:36:34.767251 12164 solver.cpp:237]     Train net output #1: loss = 0.0341558 (* 1 = 0.0341558 loss)
I1203 17:36:34.767251 12164 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1203 17:36:42.962302 12164 solver.cpp:218] Iteration 130200 (12.2031 iter/s, 8.19463s/100 iters), loss = 0.0161903
I1203 17:36:42.962302 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:36:42.962302 12164 solver.cpp:237]     Train net output #1: loss = 0.0161902 (* 1 = 0.0161902 loss)
I1203 17:36:42.962302 12164 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1203 17:36:51.157130 12164 solver.cpp:218] Iteration 130300 (12.2038 iter/s, 8.19416s/100 iters), loss = 0.0373097
I1203 17:36:51.157130 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:36:51.157130 12164 solver.cpp:237]     Train net output #1: loss = 0.0373096 (* 1 = 0.0373096 loss)
I1203 17:36:51.157130 12164 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1203 17:36:59.379061 12164 solver.cpp:218] Iteration 130400 (12.1623 iter/s, 8.22211s/100 iters), loss = 0.01851
I1203 17:36:59.379061 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:36:59.379061 12164 solver.cpp:237]     Train net output #1: loss = 0.0185099 (* 1 = 0.0185099 loss)
I1203 17:36:59.379061 12164 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1203 17:37:07.214289  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:37:07.542330 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.caffemodel
I1203 17:37:07.571331 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_130500.solverstate
I1203 17:37:07.577334 12164 solver.cpp:330] Iteration 130500, Testing net (#0)
I1203 17:37:07.577334 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:37:09.311602 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:37:09.380609 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 17:37:09.381610 12164 solver.cpp:397]     Test net output #1: loss = 0.249957 (* 1 = 0.249957 loss)
I1203 17:37:09.458608 12164 solver.cpp:218] Iteration 130500 (9.9221 iter/s, 10.0785s/100 iters), loss = 0.016384
I1203 17:37:09.458608 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:37:09.458608 12164 solver.cpp:237]     Train net output #1: loss = 0.0163839 (* 1 = 0.0163839 loss)
I1203 17:37:09.458608 12164 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1203 17:37:17.692028 12164 solver.cpp:218] Iteration 130600 (12.1459 iter/s, 8.23321s/100 iters), loss = 0.0147625
I1203 17:37:17.692028 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:37:17.692028 12164 solver.cpp:237]     Train net output #1: loss = 0.0147623 (* 1 = 0.0147623 loss)
I1203 17:37:17.692028 12164 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1203 17:37:25.976514 12164 solver.cpp:218] Iteration 130700 (12.0721 iter/s, 8.28356s/100 iters), loss = 0.0197788
I1203 17:37:25.976514 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:37:25.976514 12164 solver.cpp:237]     Train net output #1: loss = 0.0197786 (* 1 = 0.0197786 loss)
I1203 17:37:25.976514 12164 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1203 17:37:34.240566 12164 solver.cpp:218] Iteration 130800 (12.1008 iter/s, 8.26388s/100 iters), loss = 0.010426
I1203 17:37:34.240566 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:37:34.241566 12164 solver.cpp:237]     Train net output #1: loss = 0.0104259 (* 1 = 0.0104259 loss)
I1203 17:37:34.241566 12164 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1203 17:37:42.455075 12164 solver.cpp:218] Iteration 130900 (12.1748 iter/s, 8.21367s/100 iters), loss = 0.00927049
I1203 17:37:42.455075 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:37:42.455075 12164 solver.cpp:237]     Train net output #1: loss = 0.00927035 (* 1 = 0.00927035 loss)
I1203 17:37:42.455075 12164 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1203 17:37:50.311280  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:37:50.626314 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.caffemodel
I1203 17:37:50.655320 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131000.solverstate
I1203 17:37:50.661321 12164 solver.cpp:330] Iteration 131000, Testing net (#0)
I1203 17:37:50.661321 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:37:52.384510 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:37:52.452519 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9331
I1203 17:37:52.452519 12164 solver.cpp:397]     Test net output #1: loss = 0.247127 (* 1 = 0.247127 loss)
I1203 17:37:52.529520 12164 solver.cpp:218] Iteration 131000 (9.92702 iter/s, 10.0735s/100 iters), loss = 0.0149594
I1203 17:37:52.529520 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:37:52.529520 12164 solver.cpp:237]     Train net output #1: loss = 0.0149592 (* 1 = 0.0149592 loss)
I1203 17:37:52.529520 12164 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1203 17:38:00.741394 12164 solver.cpp:218] Iteration 131100 (12.1787 iter/s, 8.21108s/100 iters), loss = 0.0233676
I1203 17:38:00.741394 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:38:00.741394 12164 solver.cpp:237]     Train net output #1: loss = 0.0233675 (* 1 = 0.0233675 loss)
I1203 17:38:00.741394 12164 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1203 17:38:08.930258 12164 solver.cpp:218] Iteration 131200 (12.2118 iter/s, 8.18879s/100 iters), loss = 0.0109242
I1203 17:38:08.930258 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:38:08.930258 12164 solver.cpp:237]     Train net output #1: loss = 0.010924 (* 1 = 0.010924 loss)
I1203 17:38:08.930258 12164 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1203 17:38:17.148336 12164 solver.cpp:218] Iteration 131300 (12.1699 iter/s, 8.21698s/100 iters), loss = 0.011995
I1203 17:38:17.148336 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:38:17.148336 12164 solver.cpp:237]     Train net output #1: loss = 0.0119948 (* 1 = 0.0119948 loss)
I1203 17:38:17.148336 12164 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1203 17:38:25.356845 12164 solver.cpp:218] Iteration 131400 (12.1827 iter/s, 8.20835s/100 iters), loss = 0.0225858
I1203 17:38:25.356845 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:38:25.356845 12164 solver.cpp:237]     Train net output #1: loss = 0.0225856 (* 1 = 0.0225856 loss)
I1203 17:38:25.356845 12164 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1203 17:38:33.200078  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:38:33.531131 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.caffemodel
I1203 17:38:33.565130 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_131500.solverstate
I1203 17:38:33.570130 12164 solver.cpp:330] Iteration 131500, Testing net (#0)
I1203 17:38:33.571131 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:38:35.304373 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:38:35.371378 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9333
I1203 17:38:35.371378 12164 solver.cpp:397]     Test net output #1: loss = 0.247957 (* 1 = 0.247957 loss)
I1203 17:38:35.446384 12164 solver.cpp:218] Iteration 131500 (9.912 iter/s, 10.0888s/100 iters), loss = 0.0170212
I1203 17:38:35.446384 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:38:35.446384 12164 solver.cpp:237]     Train net output #1: loss = 0.0170211 (* 1 = 0.0170211 loss)
I1203 17:38:35.446384 12164 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1203 17:38:43.693048 12164 solver.cpp:218] Iteration 131600 (12.1272 iter/s, 8.24591s/100 iters), loss = 0.0232733
I1203 17:38:43.693048 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:38:43.693048 12164 solver.cpp:237]     Train net output #1: loss = 0.0232731 (* 1 = 0.0232731 loss)
I1203 17:38:43.693048 12164 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1203 17:38:51.941104 12164 solver.cpp:218] Iteration 131700 (12.1251 iter/s, 8.24739s/100 iters), loss = 0.012327
I1203 17:38:51.941104 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:38:51.941104 12164 solver.cpp:237]     Train net output #1: loss = 0.0123268 (* 1 = 0.0123268 loss)
I1203 17:38:51.941104 12164 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1203 17:39:00.269103 12164 solver.cpp:218] Iteration 131800 (12.0078 iter/s, 8.32795s/100 iters), loss = 0.0127936
I1203 17:39:00.269103 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:00.269103 12164 solver.cpp:237]     Train net output #1: loss = 0.0127935 (* 1 = 0.0127935 loss)
I1203 17:39:00.269103 12164 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1203 17:39:08.499917 12164 solver.cpp:218] Iteration 131900 (12.1501 iter/s, 8.23037s/100 iters), loss = 0.013132
I1203 17:39:08.499917 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:08.499917 12164 solver.cpp:237]     Train net output #1: loss = 0.0131318 (* 1 = 0.0131318 loss)
I1203 17:39:08.499917 12164 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1203 17:39:16.316795  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:39:16.647838 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.caffemodel
I1203 17:39:16.682843 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132000.solverstate
I1203 17:39:16.688840 12164 solver.cpp:330] Iteration 132000, Testing net (#0)
I1203 17:39:16.688840 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:39:18.403972 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:39:18.473996 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 17:39:18.473996 12164 solver.cpp:397]     Test net output #1: loss = 0.246949 (* 1 = 0.246949 loss)
I1203 17:39:18.551026 12164 solver.cpp:218] Iteration 132000 (9.95015 iter/s, 10.0501s/100 iters), loss = 0.0119665
I1203 17:39:18.551026 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:18.551026 12164 solver.cpp:237]     Train net output #1: loss = 0.0119664 (* 1 = 0.0119664 loss)
I1203 17:39:18.551026 12164 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1203 17:39:26.771944 12164 solver.cpp:218] Iteration 132100 (12.1652 iter/s, 8.22015s/100 iters), loss = 0.0146603
I1203 17:39:26.771944 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:26.771944 12164 solver.cpp:237]     Train net output #1: loss = 0.0146601 (* 1 = 0.0146601 loss)
I1203 17:39:26.771944 12164 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1203 17:39:35.013789 12164 solver.cpp:218] Iteration 132200 (12.1332 iter/s, 8.24184s/100 iters), loss = 0.0130615
I1203 17:39:35.013789 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:35.013789 12164 solver.cpp:237]     Train net output #1: loss = 0.0130613 (* 1 = 0.0130613 loss)
I1203 17:39:35.013789 12164 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1203 17:39:43.248934 12164 solver.cpp:218] Iteration 132300 (12.1448 iter/s, 8.23399s/100 iters), loss = 0.0103665
I1203 17:39:43.248934 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:43.248934 12164 solver.cpp:237]     Train net output #1: loss = 0.0103663 (* 1 = 0.0103663 loss)
I1203 17:39:43.248934 12164 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1203 17:39:51.491740 12164 solver.cpp:218] Iteration 132400 (12.1314 iter/s, 8.24308s/100 iters), loss = 0.0094673
I1203 17:39:51.492746 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:39:51.492746 12164 solver.cpp:237]     Train net output #1: loss = 0.00946715 (* 1 = 0.00946715 loss)
I1203 17:39:51.492746 12164 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1203 17:39:59.362725  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:39:59.677744 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.caffemodel
I1203 17:39:59.706744 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_132500.solverstate
I1203 17:39:59.712744 12164 solver.cpp:330] Iteration 132500, Testing net (#0)
I1203 17:39:59.712744 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:40:01.442353 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:40:01.510857 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1203 17:40:01.510857 12164 solver.cpp:397]     Test net output #1: loss = 0.247584 (* 1 = 0.247584 loss)
I1203 17:40:01.585871 12164 solver.cpp:218] Iteration 132500 (9.9078 iter/s, 10.0931s/100 iters), loss = 0.014893
I1203 17:40:01.585871 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:40:01.585871 12164 solver.cpp:237]     Train net output #1: loss = 0.0148929 (* 1 = 0.0148929 loss)
I1203 17:40:01.585871 12164 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1203 17:40:09.801918 12164 solver.cpp:218] Iteration 132600 (12.1716 iter/s, 8.21582s/100 iters), loss = 0.0275253
I1203 17:40:09.802918 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:40:09.802918 12164 solver.cpp:237]     Train net output #1: loss = 0.0275252 (* 1 = 0.0275252 loss)
I1203 17:40:09.802918 12164 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1203 17:40:18.018887 12164 solver.cpp:218] Iteration 132700 (12.1714 iter/s, 8.216s/100 iters), loss = 0.0199038
I1203 17:40:18.018887 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:40:18.018887 12164 solver.cpp:237]     Train net output #1: loss = 0.0199036 (* 1 = 0.0199036 loss)
I1203 17:40:18.018887 12164 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1203 17:40:26.263082 12164 solver.cpp:218] Iteration 132800 (12.1302 iter/s, 8.24387s/100 iters), loss = 0.0110351
I1203 17:40:26.263082 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:40:26.263082 12164 solver.cpp:237]     Train net output #1: loss = 0.0110349 (* 1 = 0.0110349 loss)
I1203 17:40:26.263082 12164 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1203 17:40:34.500749 12164 solver.cpp:218] Iteration 132900 (12.141 iter/s, 8.23655s/100 iters), loss = 0.0104171
I1203 17:40:34.500749 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:40:34.500749 12164 solver.cpp:237]     Train net output #1: loss = 0.0104169 (* 1 = 0.0104169 loss)
I1203 17:40:34.500749 12164 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1203 17:40:42.319697  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:40:42.645750 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.caffemodel
I1203 17:40:42.674748 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133000.solverstate
I1203 17:40:42.680749 12164 solver.cpp:330] Iteration 133000, Testing net (#0)
I1203 17:40:42.681751 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:40:44.397958 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:40:44.464962 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9322
I1203 17:40:44.464962 12164 solver.cpp:397]     Test net output #1: loss = 0.249033 (* 1 = 0.249033 loss)
I1203 17:40:44.538475 12164 solver.cpp:218] Iteration 133000 (9.9628 iter/s, 10.0373s/100 iters), loss = 0.0143309
I1203 17:40:44.538475 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:40:44.538475 12164 solver.cpp:237]     Train net output #1: loss = 0.0143307 (* 1 = 0.0143307 loss)
I1203 17:40:44.538475 12164 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1203 17:40:52.761467 12164 solver.cpp:218] Iteration 133100 (12.161 iter/s, 8.22303s/100 iters), loss = 0.0129741
I1203 17:40:52.761467 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:40:52.761467 12164 solver.cpp:237]     Train net output #1: loss = 0.012974 (* 1 = 0.012974 loss)
I1203 17:40:52.762464 12164 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1203 17:41:01.001314 12164 solver.cpp:218] Iteration 133200 (12.1374 iter/s, 8.23897s/100 iters), loss = 0.0259294
I1203 17:41:01.001314 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:41:01.001314 12164 solver.cpp:237]     Train net output #1: loss = 0.0259292 (* 1 = 0.0259292 loss)
I1203 17:41:01.001314 12164 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1203 17:41:09.220317 12164 solver.cpp:218] Iteration 133300 (12.1685 iter/s, 8.21797s/100 iters), loss = 0.0192861
I1203 17:41:09.220317 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:41:09.220317 12164 solver.cpp:237]     Train net output #1: loss = 0.0192859 (* 1 = 0.0192859 loss)
I1203 17:41:09.220317 12164 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1203 17:41:17.421849 12164 solver.cpp:218] Iteration 133400 (12.193 iter/s, 8.20143s/100 iters), loss = 0.010746
I1203 17:41:17.421849 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:41:17.421849 12164 solver.cpp:237]     Train net output #1: loss = 0.0107458 (* 1 = 0.0107458 loss)
I1203 17:41:17.421849 12164 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1203 17:41:25.251286  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:41:25.578825 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.caffemodel
I1203 17:41:25.610824 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_133500.solverstate
I1203 17:41:25.617825 12164 solver.cpp:330] Iteration 133500, Testing net (#0)
I1203 17:41:25.617825 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:41:27.320955 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:41:27.388967 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1203 17:41:27.388967 12164 solver.cpp:397]     Test net output #1: loss = 0.24861 (* 1 = 0.24861 loss)
I1203 17:41:27.465975 12164 solver.cpp:218] Iteration 133500 (9.95706 iter/s, 10.0431s/100 iters), loss = 0.0133471
I1203 17:41:27.465975 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:41:27.465975 12164 solver.cpp:237]     Train net output #1: loss = 0.013347 (* 1 = 0.013347 loss)
I1203 17:41:27.465975 12164 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1203 17:41:35.816731 12164 solver.cpp:218] Iteration 133600 (11.9754 iter/s, 8.35046s/100 iters), loss = 0.0141072
I1203 17:41:35.816731 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:41:35.816731 12164 solver.cpp:237]     Train net output #1: loss = 0.014107 (* 1 = 0.014107 loss)
I1203 17:41:35.816731 12164 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1203 17:41:44.065753 12164 solver.cpp:218] Iteration 133700 (12.1226 iter/s, 8.24908s/100 iters), loss = 0.0151955
I1203 17:41:44.066752 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:41:44.066752 12164 solver.cpp:237]     Train net output #1: loss = 0.0151954 (* 1 = 0.0151954 loss)
I1203 17:41:44.066752 12164 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1203 17:41:52.281410 12164 solver.cpp:218] Iteration 133800 (12.174 iter/s, 8.21425s/100 iters), loss = 0.0188657
I1203 17:41:52.281410 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:41:52.281410 12164 solver.cpp:237]     Train net output #1: loss = 0.0188656 (* 1 = 0.0188656 loss)
I1203 17:41:52.281410 12164 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1203 17:42:00.520539 12164 solver.cpp:218] Iteration 133900 (12.1378 iter/s, 8.23869s/100 iters), loss = 0.0138288
I1203 17:42:00.520539 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:42:00.520539 12164 solver.cpp:237]     Train net output #1: loss = 0.0138287 (* 1 = 0.0138287 loss)
I1203 17:42:00.520539 12164 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1203 17:42:08.352210  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:42:08.671231 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.caffemodel
I1203 17:42:08.701231 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134000.solverstate
I1203 17:42:08.708230 12164 solver.cpp:330] Iteration 134000, Testing net (#0)
I1203 17:42:08.708230 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:42:10.433078 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:42:10.502588 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9337
I1203 17:42:10.502588 12164 solver.cpp:397]     Test net output #1: loss = 0.247402 (* 1 = 0.247402 loss)
I1203 17:42:10.578595 12164 solver.cpp:218] Iteration 134000 (9.94215 iter/s, 10.0582s/100 iters), loss = 0.0160305
I1203 17:42:10.579596 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:42:10.579596 12164 solver.cpp:237]     Train net output #1: loss = 0.0160304 (* 1 = 0.0160304 loss)
I1203 17:42:10.579596 12164 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1203 17:42:18.833820 12164 solver.cpp:218] Iteration 134100 (12.1159 iter/s, 8.25363s/100 iters), loss = 0.0285147
I1203 17:42:18.833820 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:42:18.833820 12164 solver.cpp:237]     Train net output #1: loss = 0.0285145 (* 1 = 0.0285145 loss)
I1203 17:42:18.833820 12164 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1203 17:42:27.230931 12164 solver.cpp:218] Iteration 134200 (11.9089 iter/s, 8.39709s/100 iters), loss = 0.0131131
I1203 17:42:27.230931 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:42:27.230931 12164 solver.cpp:237]     Train net output #1: loss = 0.013113 (* 1 = 0.013113 loss)
I1203 17:42:27.230931 12164 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1203 17:42:35.473181 12164 solver.cpp:218] Iteration 134300 (12.1331 iter/s, 8.24194s/100 iters), loss = 0.0100426
I1203 17:42:35.473181 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:42:35.473181 12164 solver.cpp:237]     Train net output #1: loss = 0.0100424 (* 1 = 0.0100424 loss)
I1203 17:42:35.473181 12164 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1203 17:42:43.703763 12164 solver.cpp:218] Iteration 134400 (12.1511 iter/s, 8.22971s/100 iters), loss = 0.0116321
I1203 17:42:43.703763 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:42:43.703763 12164 solver.cpp:237]     Train net output #1: loss = 0.0116319 (* 1 = 0.0116319 loss)
I1203 17:42:43.703763 12164 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1203 17:42:51.543228  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:42:51.870280 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.caffemodel
I1203 17:42:51.900285 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_134500.solverstate
I1203 17:42:51.906289 12164 solver.cpp:330] Iteration 134500, Testing net (#0)
I1203 17:42:51.906289 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:42:53.631446 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:42:53.700945 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 17:42:53.700945 12164 solver.cpp:397]     Test net output #1: loss = 0.243441 (* 1 = 0.243441 loss)
I1203 17:42:53.776944 12164 solver.cpp:218] Iteration 134500 (9.92831 iter/s, 10.0722s/100 iters), loss = 0.0114747
I1203 17:42:53.776944 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:42:53.776944 12164 solver.cpp:237]     Train net output #1: loss = 0.0114746 (* 1 = 0.0114746 loss)
I1203 17:42:53.776944 12164 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1203 17:43:02.111146 12164 solver.cpp:218] Iteration 134600 (11.9995 iter/s, 8.33371s/100 iters), loss = 0.0203384
I1203 17:43:02.111146 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:43:02.111146 12164 solver.cpp:237]     Train net output #1: loss = 0.0203383 (* 1 = 0.0203383 loss)
I1203 17:43:02.111146 12164 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1203 17:43:10.373358 12164 solver.cpp:218] Iteration 134700 (12.1033 iter/s, 8.2622s/100 iters), loss = 0.0128712
I1203 17:43:10.373358 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:43:10.373358 12164 solver.cpp:237]     Train net output #1: loss = 0.012871 (* 1 = 0.012871 loss)
I1203 17:43:10.373358 12164 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1203 17:43:18.548923 12164 solver.cpp:218] Iteration 134800 (12.2326 iter/s, 8.17487s/100 iters), loss = 0.0140322
I1203 17:43:18.548923 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:43:18.548923 12164 solver.cpp:237]     Train net output #1: loss = 0.0140321 (* 1 = 0.0140321 loss)
I1203 17:43:18.548923 12164 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1203 17:43:26.763667 12164 solver.cpp:218] Iteration 134900 (12.174 iter/s, 8.21423s/100 iters), loss = 0.0103076
I1203 17:43:26.763667 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:43:26.763667 12164 solver.cpp:237]     Train net output #1: loss = 0.0103075 (* 1 = 0.0103075 loss)
I1203 17:43:26.763667 12164 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1203 17:43:34.574072  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:43:34.899979 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.caffemodel
I1203 17:43:34.931820 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135000.solverstate
I1203 17:43:34.940822 12164 solver.cpp:330] Iteration 135000, Testing net (#0)
I1203 17:43:34.940822 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:43:36.652261 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:43:36.719441 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 17:43:36.719441 12164 solver.cpp:397]     Test net output #1: loss = 0.245142 (* 1 = 0.245142 loss)
I1203 17:43:36.795449 12164 solver.cpp:218] Iteration 135000 (9.96922 iter/s, 10.0309s/100 iters), loss = 0.0132514
I1203 17:43:36.795449 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:43:36.795449 12164 solver.cpp:237]     Train net output #1: loss = 0.0132513 (* 1 = 0.0132513 loss)
I1203 17:43:36.795449 12164 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1203 17:43:44.899113 12164 solver.cpp:218] Iteration 135100 (12.3407 iter/s, 8.10324s/100 iters), loss = 0.0191389
I1203 17:43:44.899113 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:43:44.899113 12164 solver.cpp:237]     Train net output #1: loss = 0.0191387 (* 1 = 0.0191387 loss)
I1203 17:43:44.899113 12164 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1203 17:43:53.059849 12164 solver.cpp:218] Iteration 135200 (12.2547 iter/s, 8.16015s/100 iters), loss = 0.0174385
I1203 17:43:53.059849 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:43:53.059849 12164 solver.cpp:237]     Train net output #1: loss = 0.0174383 (* 1 = 0.0174383 loss)
I1203 17:43:53.059849 12164 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1203 17:44:01.272756 12164 solver.cpp:218] Iteration 135300 (12.1766 iter/s, 8.21249s/100 iters), loss = 0.0114166
I1203 17:44:01.272756 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:44:01.272756 12164 solver.cpp:237]     Train net output #1: loss = 0.0114165 (* 1 = 0.0114165 loss)
I1203 17:44:01.272756 12164 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1203 17:44:09.386907 12164 solver.cpp:218] Iteration 135400 (12.3253 iter/s, 8.11338s/100 iters), loss = 0.0188369
I1203 17:44:09.386907 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:44:09.386907 12164 solver.cpp:237]     Train net output #1: loss = 0.0188368 (* 1 = 0.0188368 loss)
I1203 17:44:09.386907 12164 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1203 17:44:17.055227  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:44:17.370798 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.caffemodel
I1203 17:44:17.400799 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_135500.solverstate
I1203 17:44:17.406800 12164 solver.cpp:330] Iteration 135500, Testing net (#0)
I1203 17:44:17.406800 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:44:19.127308 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:44:19.195312 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9335
I1203 17:44:19.195312 12164 solver.cpp:397]     Test net output #1: loss = 0.249099 (* 1 = 0.249099 loss)
I1203 17:44:19.273334 12164 solver.cpp:218] Iteration 135500 (10.1151 iter/s, 9.88624s/100 iters), loss = 0.0217966
I1203 17:44:19.273334 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:44:19.273334 12164 solver.cpp:237]     Train net output #1: loss = 0.0217965 (* 1 = 0.0217965 loss)
I1203 17:44:19.273334 12164 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1203 17:44:27.446427 12164 solver.cpp:218] Iteration 135600 (12.2368 iter/s, 8.17209s/100 iters), loss = 0.014443
I1203 17:44:27.446427 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:44:27.446427 12164 solver.cpp:237]     Train net output #1: loss = 0.0144429 (* 1 = 0.0144429 loss)
I1203 17:44:27.446427 12164 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1203 17:44:35.552498 12164 solver.cpp:218] Iteration 135700 (12.3372 iter/s, 8.10557s/100 iters), loss = 0.0117031
I1203 17:44:35.552498 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:44:35.552498 12164 solver.cpp:237]     Train net output #1: loss = 0.011703 (* 1 = 0.011703 loss)
I1203 17:44:35.552498 12164 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1203 17:44:43.797853 12164 solver.cpp:218] Iteration 135800 (12.1283 iter/s, 8.2452s/100 iters), loss = 0.0138571
I1203 17:44:43.797853 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:44:43.797853 12164 solver.cpp:237]     Train net output #1: loss = 0.013857 (* 1 = 0.013857 loss)
I1203 17:44:43.797853 12164 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1203 17:44:51.868752 12164 solver.cpp:218] Iteration 135900 (12.3902 iter/s, 8.07092s/100 iters), loss = 0.0117791
I1203 17:44:51.869770 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:44:51.869770 12164 solver.cpp:237]     Train net output #1: loss = 0.0117789 (* 1 = 0.0117789 loss)
I1203 17:44:51.869770 12164 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1203 17:44:59.531529  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:44:59.849562 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.caffemodel
I1203 17:44:59.894564 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136000.solverstate
I1203 17:44:59.901563 12164 solver.cpp:330] Iteration 136000, Testing net (#0)
I1203 17:44:59.901563 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:45:01.621495 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:45:01.686997 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 17:45:01.686997 12164 solver.cpp:397]     Test net output #1: loss = 0.250908 (* 1 = 0.250908 loss)
I1203 17:45:01.763005 12164 solver.cpp:218] Iteration 136000 (10.1084 iter/s, 9.89279s/100 iters), loss = 0.0156423
I1203 17:45:01.763005 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:45:01.763005 12164 solver.cpp:237]     Train net output #1: loss = 0.0156422 (* 1 = 0.0156422 loss)
I1203 17:45:01.763005 12164 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1203 17:45:09.859473 12164 solver.cpp:218] Iteration 136100 (12.3514 iter/s, 8.09623s/100 iters), loss = 0.0187277
I1203 17:45:09.859473 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:45:09.859473 12164 solver.cpp:237]     Train net output #1: loss = 0.0187275 (* 1 = 0.0187275 loss)
I1203 17:45:09.859473 12164 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1203 17:45:17.994662 12164 solver.cpp:218] Iteration 136200 (12.2932 iter/s, 8.13456s/100 iters), loss = 0.014413
I1203 17:45:17.994662 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:45:17.994662 12164 solver.cpp:237]     Train net output #1: loss = 0.0144128 (* 1 = 0.0144128 loss)
I1203 17:45:17.994662 12164 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1203 17:45:26.083557 12164 solver.cpp:218] Iteration 136300 (12.3637 iter/s, 8.08822s/100 iters), loss = 0.0152867
I1203 17:45:26.083557 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:45:26.083557 12164 solver.cpp:237]     Train net output #1: loss = 0.0152866 (* 1 = 0.0152866 loss)
I1203 17:45:26.083557 12164 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1203 17:45:34.195374 12164 solver.cpp:218] Iteration 136400 (12.3275 iter/s, 8.11192s/100 iters), loss = 0.0110274
I1203 17:45:34.195374 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:45:34.195374 12164 solver.cpp:237]     Train net output #1: loss = 0.0110273 (* 1 = 0.0110273 loss)
I1203 17:45:34.195374 12164 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1203 17:45:41.919369  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:45:42.252398 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.caffemodel
I1203 17:45:42.286397 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_136500.solverstate
I1203 17:45:42.293398 12164 solver.cpp:330] Iteration 136500, Testing net (#0)
I1203 17:45:42.293398 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:45:43.978575 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:45:44.046560 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 17:45:44.046560 12164 solver.cpp:397]     Test net output #1: loss = 0.244132 (* 1 = 0.244132 loss)
I1203 17:45:44.125061 12164 solver.cpp:218] Iteration 136500 (10.0717 iter/s, 9.92879s/100 iters), loss = 0.0278564
I1203 17:45:44.125061 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:45:44.125061 12164 solver.cpp:237]     Train net output #1: loss = 0.0278562 (* 1 = 0.0278562 loss)
I1203 17:45:44.125061 12164 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1203 17:45:52.239359 12164 solver.cpp:218] Iteration 136600 (12.3246 iter/s, 8.11383s/100 iters), loss = 0.0334083
I1203 17:45:52.239359 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:45:52.239359 12164 solver.cpp:237]     Train net output #1: loss = 0.0334081 (* 1 = 0.0334081 loss)
I1203 17:45:52.239359 12164 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1203 17:46:00.241768 12164 solver.cpp:218] Iteration 136700 (12.4972 iter/s, 8.00177s/100 iters), loss = 0.0119607
I1203 17:46:00.241768 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:00.241768 12164 solver.cpp:237]     Train net output #1: loss = 0.0119606 (* 1 = 0.0119606 loss)
I1203 17:46:00.241768 12164 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1203 17:46:08.353114 12164 solver.cpp:218] Iteration 136800 (12.3293 iter/s, 8.11073s/100 iters), loss = 0.0159389
I1203 17:46:08.353114 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:08.353114 12164 solver.cpp:237]     Train net output #1: loss = 0.0159387 (* 1 = 0.0159387 loss)
I1203 17:46:08.353114 12164 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1203 17:46:16.462466 12164 solver.cpp:218] Iteration 136900 (12.3324 iter/s, 8.10874s/100 iters), loss = 0.0115571
I1203 17:46:16.462466 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:16.462466 12164 solver.cpp:237]     Train net output #1: loss = 0.0115569 (* 1 = 0.0115569 loss)
I1203 17:46:16.462466 12164 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1203 17:46:24.141490  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:46:24.459067 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.caffemodel
I1203 17:46:24.487067 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137000.solverstate
I1203 17:46:24.493068 12164 solver.cpp:330] Iteration 137000, Testing net (#0)
I1203 17:46:24.493068 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:46:26.172209 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:46:26.241220 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9325
I1203 17:46:26.241220 12164 solver.cpp:397]     Test net output #1: loss = 0.245861 (* 1 = 0.245861 loss)
I1203 17:46:26.323215 12164 solver.cpp:218] Iteration 137000 (10.1416 iter/s, 9.86034s/100 iters), loss = 0.0142018
I1203 17:46:26.323215 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:26.323215 12164 solver.cpp:237]     Train net output #1: loss = 0.0142016 (* 1 = 0.0142016 loss)
I1203 17:46:26.323215 12164 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1203 17:46:34.506038 12164 solver.cpp:218] Iteration 137100 (12.2214 iter/s, 8.18239s/100 iters), loss = 0.0198363
I1203 17:46:34.506038 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:34.506038 12164 solver.cpp:237]     Train net output #1: loss = 0.0198362 (* 1 = 0.0198362 loss)
I1203 17:46:34.506038 12164 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1203 17:46:42.712103 12164 solver.cpp:218] Iteration 137200 (12.1862 iter/s, 8.20603s/100 iters), loss = 0.0154537
I1203 17:46:42.712103 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:42.712103 12164 solver.cpp:237]     Train net output #1: loss = 0.0154536 (* 1 = 0.0154536 loss)
I1203 17:46:42.712103 12164 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1203 17:46:50.863173 12164 solver.cpp:218] Iteration 137300 (12.269 iter/s, 8.15062s/100 iters), loss = 0.00851202
I1203 17:46:50.863173 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:50.863173 12164 solver.cpp:237]     Train net output #1: loss = 0.00851187 (* 1 = 0.00851187 loss)
I1203 17:46:50.863173 12164 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1203 17:46:58.932024 12164 solver.cpp:218] Iteration 137400 (12.394 iter/s, 8.06842s/100 iters), loss = 0.0154342
I1203 17:46:58.932024 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:46:58.932024 12164 solver.cpp:237]     Train net output #1: loss = 0.0154341 (* 1 = 0.0154341 loss)
I1203 17:46:58.932024 12164 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1203 17:47:06.641065  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:47:06.970091 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.caffemodel
I1203 17:47:07.000111 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_137500.solverstate
I1203 17:47:07.007103 12164 solver.cpp:330] Iteration 137500, Testing net (#0)
I1203 17:47:07.007103 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:47:08.741240 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:47:08.810258 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9313
I1203 17:47:08.810258 12164 solver.cpp:397]     Test net output #1: loss = 0.248776 (* 1 = 0.248776 loss)
I1203 17:47:08.889259 12164 solver.cpp:218] Iteration 137500 (10.0442 iter/s, 9.95603s/100 iters), loss = 0.01336
I1203 17:47:08.889259 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:47:08.889259 12164 solver.cpp:237]     Train net output #1: loss = 0.0133599 (* 1 = 0.0133599 loss)
I1203 17:47:08.889259 12164 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1203 17:47:17.042146 12164 solver.cpp:218] Iteration 137600 (12.2666 iter/s, 8.15224s/100 iters), loss = 0.0379819
I1203 17:47:17.042146 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:47:17.042146 12164 solver.cpp:237]     Train net output #1: loss = 0.0379818 (* 1 = 0.0379818 loss)
I1203 17:47:17.042146 12164 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1203 17:47:25.121035 12164 solver.cpp:218] Iteration 137700 (12.3787 iter/s, 8.07839s/100 iters), loss = 0.0244613
I1203 17:47:25.121035 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:47:25.121035 12164 solver.cpp:237]     Train net output #1: loss = 0.0244611 (* 1 = 0.0244611 loss)
I1203 17:47:25.121035 12164 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1203 17:47:33.115332 12164 solver.cpp:218] Iteration 137800 (12.5095 iter/s, 7.99392s/100 iters), loss = 0.0121272
I1203 17:47:33.115332 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:47:33.115833 12164 solver.cpp:237]     Train net output #1: loss = 0.012127 (* 1 = 0.012127 loss)
I1203 17:47:33.115833 12164 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1203 17:47:41.115602 12164 solver.cpp:218] Iteration 137900 (12.5003 iter/s, 7.99981s/100 iters), loss = 0.0115945
I1203 17:47:41.115602 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:47:41.115602 12164 solver.cpp:237]     Train net output #1: loss = 0.0115944 (* 1 = 0.0115944 loss)
I1203 17:47:41.115602 12164 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1203 17:47:48.720417  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:47:49.035437 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.caffemodel
I1203 17:47:49.064440 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138000.solverstate
I1203 17:47:49.070439 12164 solver.cpp:330] Iteration 138000, Testing net (#0)
I1203 17:47:49.070439 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:47:50.764940 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:47:50.830942 12164 solver.cpp:397]     Test net output #0: accuracy = 0.933
I1203 17:47:50.830942 12164 solver.cpp:397]     Test net output #1: loss = 0.248531 (* 1 = 0.248531 loss)
I1203 17:47:50.905947 12164 solver.cpp:218] Iteration 138000 (10.215 iter/s, 9.78952s/100 iters), loss = 0.012877
I1203 17:47:50.905947 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:47:50.905947 12164 solver.cpp:237]     Train net output #1: loss = 0.0128768 (* 1 = 0.0128768 loss)
I1203 17:47:50.905947 12164 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1203 17:47:58.913678 12164 solver.cpp:218] Iteration 138100 (12.4878 iter/s, 8.00782s/100 iters), loss = 0.0158948
I1203 17:47:58.913678 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:47:58.913678 12164 solver.cpp:237]     Train net output #1: loss = 0.0158947 (* 1 = 0.0158947 loss)
I1203 17:47:58.913678 12164 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1203 17:48:06.901937 12164 solver.cpp:218] Iteration 138200 (12.52 iter/s, 7.98721s/100 iters), loss = 0.0122128
I1203 17:48:06.901937 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:06.901937 12164 solver.cpp:237]     Train net output #1: loss = 0.0122126 (* 1 = 0.0122126 loss)
I1203 17:48:06.901937 12164 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1203 17:48:14.905395 12164 solver.cpp:218] Iteration 138300 (12.4949 iter/s, 8.00325s/100 iters), loss = 0.00836284
I1203 17:48:14.905395 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:14.905896 12164 solver.cpp:237]     Train net output #1: loss = 0.0083627 (* 1 = 0.0083627 loss)
I1203 17:48:14.905896 12164 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1203 17:48:22.932907 12164 solver.cpp:218] Iteration 138400 (12.4573 iter/s, 8.02744s/100 iters), loss = 0.0103878
I1203 17:48:22.932907 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:22.932907 12164 solver.cpp:237]     Train net output #1: loss = 0.0103877 (* 1 = 0.0103877 loss)
I1203 17:48:22.932907 12164 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1203 17:48:30.551697  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:48:30.866735 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.caffemodel
I1203 17:48:30.899739 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_138500.solverstate
I1203 17:48:30.905740 12164 solver.cpp:330] Iteration 138500, Testing net (#0)
I1203 17:48:30.905740 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:48:32.584863 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:48:32.651863 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9338
I1203 17:48:32.651863 12164 solver.cpp:397]     Test net output #1: loss = 0.247562 (* 1 = 0.247562 loss)
I1203 17:48:32.726868 12164 solver.cpp:218] Iteration 138500 (10.2112 iter/s, 9.79313s/100 iters), loss = 0.0135707
I1203 17:48:32.726868 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:32.726868 12164 solver.cpp:237]     Train net output #1: loss = 0.0135706 (* 1 = 0.0135706 loss)
I1203 17:48:32.726868 12164 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1203 17:48:40.784651 12164 solver.cpp:218] Iteration 138600 (12.4108 iter/s, 8.05752s/100 iters), loss = 0.0126326
I1203 17:48:40.784651 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:40.784651 12164 solver.cpp:237]     Train net output #1: loss = 0.0126325 (* 1 = 0.0126325 loss)
I1203 17:48:40.784651 12164 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1203 17:48:48.788476 12164 solver.cpp:218] Iteration 138700 (12.4946 iter/s, 8.00346s/100 iters), loss = 0.0125569
I1203 17:48:48.789476 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:48.789476 12164 solver.cpp:237]     Train net output #1: loss = 0.0125567 (* 1 = 0.0125567 loss)
I1203 17:48:48.789476 12164 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1203 17:48:56.788311 12164 solver.cpp:218] Iteration 138800 (12.5013 iter/s, 7.99918s/100 iters), loss = 0.0120209
I1203 17:48:56.788311 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:48:56.789311 12164 solver.cpp:237]     Train net output #1: loss = 0.0120207 (* 1 = 0.0120207 loss)
I1203 17:48:56.789311 12164 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1203 17:49:04.795117 12164 solver.cpp:218] Iteration 138900 (12.4908 iter/s, 8.00591s/100 iters), loss = 0.0194762
I1203 17:49:04.795117 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:49:04.795117 12164 solver.cpp:237]     Train net output #1: loss = 0.019476 (* 1 = 0.019476 loss)
I1203 17:49:04.795117 12164 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1203 17:49:12.510138  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:49:12.830176 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.caffemodel
I1203 17:49:12.859177 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139000.solverstate
I1203 17:49:12.865182 12164 solver.cpp:330] Iteration 139000, Testing net (#0)
I1203 17:49:12.865682 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:49:14.581357 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:49:14.650357 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9342
I1203 17:49:14.650357 12164 solver.cpp:397]     Test net output #1: loss = 0.24758 (* 1 = 0.24758 loss)
I1203 17:49:14.728375 12164 solver.cpp:218] Iteration 139000 (10.0675 iter/s, 9.933s/100 iters), loss = 0.0120715
I1203 17:49:14.729377 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:49:14.729377 12164 solver.cpp:237]     Train net output #1: loss = 0.0120714 (* 1 = 0.0120714 loss)
I1203 17:49:14.729377 12164 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1203 17:49:22.889391 12164 solver.cpp:218] Iteration 139100 (12.2544 iter/s, 8.16032s/100 iters), loss = 0.0154283
I1203 17:49:22.889391 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:49:22.889391 12164 solver.cpp:237]     Train net output #1: loss = 0.0154282 (* 1 = 0.0154282 loss)
I1203 17:49:22.889391 12164 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1203 17:49:30.949228 12164 solver.cpp:218] Iteration 139200 (12.4086 iter/s, 8.05894s/100 iters), loss = 0.0189881
I1203 17:49:30.949228 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:49:30.949228 12164 solver.cpp:237]     Train net output #1: loss = 0.0189879 (* 1 = 0.0189879 loss)
I1203 17:49:30.949228 12164 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1203 17:49:39.147251 12164 solver.cpp:218] Iteration 139300 (12.1991 iter/s, 8.19733s/100 iters), loss = 0.011575
I1203 17:49:39.147251 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:49:39.147251 12164 solver.cpp:237]     Train net output #1: loss = 0.0115748 (* 1 = 0.0115748 loss)
I1203 17:49:39.147251 12164 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1203 17:49:47.215054 12164 solver.cpp:218] Iteration 139400 (12.3955 iter/s, 8.06744s/100 iters), loss = 0.0199564
I1203 17:49:47.215054 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:49:47.215054 12164 solver.cpp:237]     Train net output #1: loss = 0.0199562 (* 1 = 0.0199562 loss)
I1203 17:49:47.215054 12164 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1203 17:49:54.853817  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:49:55.171346 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.caffemodel
I1203 17:49:55.202852 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_139500.solverstate
I1203 17:49:55.208851 12164 solver.cpp:330] Iteration 139500, Testing net (#0)
I1203 17:49:55.208851 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:49:56.884997 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:49:56.953997 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 17:49:56.953997 12164 solver.cpp:397]     Test net output #1: loss = 0.248197 (* 1 = 0.248197 loss)
I1203 17:49:57.030004 12164 solver.cpp:218] Iteration 139500 (10.1893 iter/s, 9.8142s/100 iters), loss = 0.0133167
I1203 17:49:57.030004 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:49:57.030004 12164 solver.cpp:237]     Train net output #1: loss = 0.0133165 (* 1 = 0.0133165 loss)
I1203 17:49:57.030004 12164 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1203 17:50:05.087412 12164 solver.cpp:218] Iteration 139600 (12.4119 iter/s, 8.05677s/100 iters), loss = 0.01201
I1203 17:50:05.087412 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:50:05.087412 12164 solver.cpp:237]     Train net output #1: loss = 0.0120099 (* 1 = 0.0120099 loss)
I1203 17:50:05.087412 12164 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1203 17:50:13.104792 12164 solver.cpp:218] Iteration 139700 (12.473 iter/s, 8.01733s/100 iters), loss = 0.0177667
I1203 17:50:13.104792 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:50:13.104792 12164 solver.cpp:237]     Train net output #1: loss = 0.0177665 (* 1 = 0.0177665 loss)
I1203 17:50:13.104792 12164 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1203 17:50:21.218672 12164 solver.cpp:218] Iteration 139800 (12.3247 iter/s, 8.11381s/100 iters), loss = 0.0117642
I1203 17:50:21.218672 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:50:21.218672 12164 solver.cpp:237]     Train net output #1: loss = 0.0117641 (* 1 = 0.0117641 loss)
I1203 17:50:21.218672 12164 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1203 17:50:29.337276 12164 solver.cpp:218] Iteration 139900 (12.3181 iter/s, 8.11811s/100 iters), loss = 0.0108993
I1203 17:50:29.337276 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:50:29.337276 12164 solver.cpp:237]     Train net output #1: loss = 0.0108991 (* 1 = 0.0108991 loss)
I1203 17:50:29.337276 12164 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1203 17:50:37.102543  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:50:37.418798 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.caffemodel
I1203 17:50:37.446113 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140000.solverstate
I1203 17:50:37.452128 12164 solver.cpp:330] Iteration 140000, Testing net (#0)
I1203 17:50:37.452128 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:50:39.124109 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:50:39.189777 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 17:50:39.189777 12164 solver.cpp:397]     Test net output #1: loss = 0.249936 (* 1 = 0.249936 loss)
I1203 17:50:39.264286 12164 solver.cpp:218] Iteration 140000 (10.0743 iter/s, 9.92627s/100 iters), loss = 0.0301212
I1203 17:50:39.264286 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:50:39.264286 12164 solver.cpp:237]     Train net output #1: loss = 0.030121 (* 1 = 0.030121 loss)
I1203 17:50:39.264286 12164 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1203 17:50:47.479387 12164 solver.cpp:218] Iteration 140100 (12.1737 iter/s, 8.21442s/100 iters), loss = 0.0127774
I1203 17:50:47.479387 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:50:47.479387 12164 solver.cpp:237]     Train net output #1: loss = 0.0127772 (* 1 = 0.0127772 loss)
I1203 17:50:47.479387 12164 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1203 17:50:55.521073 12164 solver.cpp:218] Iteration 140200 (12.4365 iter/s, 8.04088s/100 iters), loss = 0.0137753
I1203 17:50:55.521073 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:50:55.521073 12164 solver.cpp:237]     Train net output #1: loss = 0.0137752 (* 1 = 0.0137752 loss)
I1203 17:50:55.521073 12164 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1203 17:51:03.679904 12164 solver.cpp:218] Iteration 140300 (12.2569 iter/s, 8.15864s/100 iters), loss = 0.0146196
I1203 17:51:03.679904 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:03.679904 12164 solver.cpp:237]     Train net output #1: loss = 0.0146194 (* 1 = 0.0146194 loss)
I1203 17:51:03.679904 12164 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1203 17:51:11.848886 12164 solver.cpp:218] Iteration 140400 (12.2421 iter/s, 8.16854s/100 iters), loss = 0.0160616
I1203 17:51:11.848886 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:11.848886 12164 solver.cpp:237]     Train net output #1: loss = 0.0160615 (* 1 = 0.0160615 loss)
I1203 17:51:11.848886 12164 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1203 17:51:19.521242  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:51:19.848528 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.caffemodel
I1203 17:51:19.883527 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_140500.solverstate
I1203 17:51:19.889542 12164 solver.cpp:330] Iteration 140500, Testing net (#0)
I1203 17:51:19.889542 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:51:21.644142 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:51:21.713647 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9321
I1203 17:51:21.713647 12164 solver.cpp:397]     Test net output #1: loss = 0.246888 (* 1 = 0.246888 loss)
I1203 17:51:21.791684 12164 solver.cpp:218] Iteration 140500 (10.0583 iter/s, 9.94204s/100 iters), loss = 0.0140957
I1203 17:51:21.791684 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:21.791684 12164 solver.cpp:237]     Train net output #1: loss = 0.0140956 (* 1 = 0.0140956 loss)
I1203 17:51:21.791684 12164 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1203 17:51:29.858711 12164 solver.cpp:218] Iteration 140600 (12.3968 iter/s, 8.06658s/100 iters), loss = 0.0179264
I1203 17:51:29.858711 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:29.858711 12164 solver.cpp:237]     Train net output #1: loss = 0.0179263 (* 1 = 0.0179263 loss)
I1203 17:51:29.858711 12164 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1203 17:51:38.004726 12164 solver.cpp:218] Iteration 140700 (12.2777 iter/s, 8.14484s/100 iters), loss = 0.0148004
I1203 17:51:38.004726 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:38.004726 12164 solver.cpp:237]     Train net output #1: loss = 0.0148002 (* 1 = 0.0148002 loss)
I1203 17:51:38.004726 12164 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1203 17:51:46.234962 12164 solver.cpp:218] Iteration 140800 (12.1507 iter/s, 8.22995s/100 iters), loss = 0.0125578
I1203 17:51:46.234962 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:46.234962 12164 solver.cpp:237]     Train net output #1: loss = 0.0125576 (* 1 = 0.0125576 loss)
I1203 17:51:46.234962 12164 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1203 17:51:54.266537 12164 solver.cpp:218] Iteration 140900 (12.4517 iter/s, 8.03104s/100 iters), loss = 0.0116398
I1203 17:51:54.266537 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:51:54.266537 12164 solver.cpp:237]     Train net output #1: loss = 0.0116396 (* 1 = 0.0116396 loss)
I1203 17:51:54.266537 12164 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1203 17:52:01.894110  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:52:02.209130 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.caffemodel
I1203 17:52:02.236129 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141000.solverstate
I1203 17:52:02.242128 12164 solver.cpp:330] Iteration 141000, Testing net (#0)
I1203 17:52:02.243129 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:52:03.927309 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:52:03.994318 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9319
I1203 17:52:03.994318 12164 solver.cpp:397]     Test net output #1: loss = 0.249956 (* 1 = 0.249956 loss)
I1203 17:52:04.069818 12164 solver.cpp:218] Iteration 141000 (10.2015 iter/s, 9.80247s/100 iters), loss = 0.011233
I1203 17:52:04.069818 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:52:04.069818 12164 solver.cpp:237]     Train net output #1: loss = 0.0112329 (* 1 = 0.0112329 loss)
I1203 17:52:04.069818 12164 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1203 17:52:12.090226 12164 solver.cpp:218] Iteration 141100 (12.468 iter/s, 8.02051s/100 iters), loss = 0.0216062
I1203 17:52:12.090226 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:52:12.090226 12164 solver.cpp:237]     Train net output #1: loss = 0.0216061 (* 1 = 0.0216061 loss)
I1203 17:52:12.090226 12164 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1203 17:52:20.114410 12164 solver.cpp:218] Iteration 141200 (12.4628 iter/s, 8.02388s/100 iters), loss = 0.0161057
I1203 17:52:20.115411 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:52:20.115411 12164 solver.cpp:237]     Train net output #1: loss = 0.0161055 (* 1 = 0.0161055 loss)
I1203 17:52:20.115411 12164 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1203 17:52:28.145200 12164 solver.cpp:218] Iteration 141300 (12.4542 iter/s, 8.02945s/100 iters), loss = 0.022473
I1203 17:52:28.145200 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:52:28.145200 12164 solver.cpp:237]     Train net output #1: loss = 0.0224728 (* 1 = 0.0224728 loss)
I1203 17:52:28.145200 12164 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1203 17:52:36.267475 12164 solver.cpp:218] Iteration 141400 (12.3128 iter/s, 8.12163s/100 iters), loss = 0.0124842
I1203 17:52:36.267475 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:52:36.267475 12164 solver.cpp:237]     Train net output #1: loss = 0.012484 (* 1 = 0.012484 loss)
I1203 17:52:36.267475 12164 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1203 17:52:44.101428  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:52:44.430464 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.caffemodel
I1203 17:52:44.470464 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_141500.solverstate
I1203 17:52:44.476984 12164 solver.cpp:330] Iteration 141500, Testing net (#0)
I1203 17:52:44.476984 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:52:46.204792 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:52:46.274291 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9326
I1203 17:52:46.274291 12164 solver.cpp:397]     Test net output #1: loss = 0.250649 (* 1 = 0.250649 loss)
I1203 17:52:46.350795 12164 solver.cpp:218] Iteration 141500 (9.91743 iter/s, 10.0833s/100 iters), loss = 0.0115993
I1203 17:52:46.350795 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:52:46.350795 12164 solver.cpp:237]     Train net output #1: loss = 0.0115992 (* 1 = 0.0115992 loss)
I1203 17:52:46.350795 12164 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1203 17:52:54.436322 12164 solver.cpp:218] Iteration 141600 (12.3696 iter/s, 8.08433s/100 iters), loss = 0.0375817
I1203 17:52:54.436322 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:52:54.436322 12164 solver.cpp:237]     Train net output #1: loss = 0.0375815 (* 1 = 0.0375815 loss)
I1203 17:52:54.436322 12164 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1203 17:53:02.466682 12164 solver.cpp:218] Iteration 141700 (12.4523 iter/s, 8.03063s/100 iters), loss = 0.0188015
I1203 17:53:02.466682 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:53:02.466682 12164 solver.cpp:237]     Train net output #1: loss = 0.0188014 (* 1 = 0.0188014 loss)
I1203 17:53:02.466682 12164 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1203 17:53:10.483745 12164 solver.cpp:218] Iteration 141800 (12.4751 iter/s, 8.01595s/100 iters), loss = 0.0186276
I1203 17:53:10.483745 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:53:10.483745 12164 solver.cpp:237]     Train net output #1: loss = 0.0186274 (* 1 = 0.0186274 loss)
I1203 17:53:10.483745 12164 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1203 17:53:18.518513 12164 solver.cpp:218] Iteration 141900 (12.4464 iter/s, 8.03448s/100 iters), loss = 0.0107359
I1203 17:53:18.518513 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:53:18.518513 12164 solver.cpp:237]     Train net output #1: loss = 0.0107358 (* 1 = 0.0107358 loss)
I1203 17:53:18.518513 12164 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1203 17:53:26.138499  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:53:26.461851 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.caffemodel
I1203 17:53:26.491837 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142000.solverstate
I1203 17:53:26.497874 12164 solver.cpp:330] Iteration 142000, Testing net (#0)
I1203 17:53:26.497874 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:53:28.186331 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:53:28.252951 12164 solver.cpp:397]     Test net output #0: accuracy = 0.934
I1203 17:53:28.252951 12164 solver.cpp:397]     Test net output #1: loss = 0.249237 (* 1 = 0.249237 loss)
I1203 17:53:28.326951 12164 solver.cpp:218] Iteration 142000 (10.1959 iter/s, 9.80784s/100 iters), loss = 0.0249289
I1203 17:53:28.326951 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:53:28.326951 12164 solver.cpp:237]     Train net output #1: loss = 0.0249288 (* 1 = 0.0249288 loss)
I1203 17:53:28.326951 12164 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1203 17:53:36.368607 12164 solver.cpp:218] Iteration 142100 (12.4351 iter/s, 8.04176s/100 iters), loss = 0.0239907
I1203 17:53:36.368607 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:53:36.369608 12164 solver.cpp:237]     Train net output #1: loss = 0.0239905 (* 1 = 0.0239905 loss)
I1203 17:53:36.369608 12164 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1203 17:53:44.398721 12164 solver.cpp:218] Iteration 142200 (12.455 iter/s, 8.02892s/100 iters), loss = 0.0191712
I1203 17:53:44.398721 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:53:44.398721 12164 solver.cpp:237]     Train net output #1: loss = 0.019171 (* 1 = 0.019171 loss)
I1203 17:53:44.398721 12164 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1203 17:53:52.571962 12164 solver.cpp:218] Iteration 142300 (12.2346 iter/s, 8.17353s/100 iters), loss = 0.0114734
I1203 17:53:52.572970 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:53:52.572970 12164 solver.cpp:237]     Train net output #1: loss = 0.0114733 (* 1 = 0.0114733 loss)
I1203 17:53:52.572970 12164 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1203 17:54:00.775233 12164 solver.cpp:218] Iteration 142400 (12.1922 iter/s, 8.20195s/100 iters), loss = 0.00896674
I1203 17:54:00.775735 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:54:00.775735 12164 solver.cpp:237]     Train net output #1: loss = 0.00896659 (* 1 = 0.00896659 loss)
I1203 17:54:00.775735 12164 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1203 17:54:08.569706  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:54:08.892756 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.caffemodel
I1203 17:54:08.924757 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_142500.solverstate
I1203 17:54:08.930760 12164 solver.cpp:330] Iteration 142500, Testing net (#0)
I1203 17:54:08.931759 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:54:10.641968 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:54:10.707973 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 17:54:10.708974 12164 solver.cpp:397]     Test net output #1: loss = 0.248371 (* 1 = 0.248371 loss)
I1203 17:54:10.783977 12164 solver.cpp:218] Iteration 142500 (9.99137 iter/s, 10.0086s/100 iters), loss = 0.0311466
I1203 17:54:10.784978 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:54:10.784978 12164 solver.cpp:237]     Train net output #1: loss = 0.0311464 (* 1 = 0.0311464 loss)
I1203 17:54:10.784978 12164 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1203 17:54:18.937994 12164 solver.cpp:218] Iteration 142600 (12.2648 iter/s, 8.15339s/100 iters), loss = 0.014141
I1203 17:54:18.938993 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:54:18.938993 12164 solver.cpp:237]     Train net output #1: loss = 0.0141408 (* 1 = 0.0141408 loss)
I1203 17:54:18.938993 12164 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1203 17:54:27.301731 12164 solver.cpp:218] Iteration 142700 (11.9574 iter/s, 8.36303s/100 iters), loss = 0.0182164
I1203 17:54:27.301731 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:54:27.302727 12164 solver.cpp:237]     Train net output #1: loss = 0.0182162 (* 1 = 0.0182162 loss)
I1203 17:54:27.302727 12164 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1203 17:54:35.837023 12164 solver.cpp:218] Iteration 142800 (11.7169 iter/s, 8.53471s/100 iters), loss = 0.0289387
I1203 17:54:35.838024 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:54:35.838024 12164 solver.cpp:237]     Train net output #1: loss = 0.0289385 (* 1 = 0.0289385 loss)
I1203 17:54:35.838024 12164 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1203 17:54:44.278512 12164 solver.cpp:218] Iteration 142900 (11.8479 iter/s, 8.4403s/100 iters), loss = 0.0105012
I1203 17:54:44.278512 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:54:44.278512 12164 solver.cpp:237]     Train net output #1: loss = 0.0105011 (* 1 = 0.0105011 loss)
I1203 17:54:44.278512 12164 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1203 17:54:52.152912  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:54:52.478958 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.caffemodel
I1203 17:54:52.509963 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143000.solverstate
I1203 17:54:52.516970 12164 solver.cpp:330] Iteration 143000, Testing net (#0)
I1203 17:54:52.516970 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:54:54.230129 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:54:54.299135 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9329
I1203 17:54:54.299135 12164 solver.cpp:397]     Test net output #1: loss = 0.249731 (* 1 = 0.249731 loss)
I1203 17:54:54.378137 12164 solver.cpp:218] Iteration 143000 (9.90222 iter/s, 10.0987s/100 iters), loss = 0.014204
I1203 17:54:54.378137 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:54:54.378137 12164 solver.cpp:237]     Train net output #1: loss = 0.0142039 (* 1 = 0.0142039 loss)
I1203 17:54:54.378137 12164 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1203 17:55:02.622333 12164 solver.cpp:218] Iteration 143100 (12.1304 iter/s, 8.24377s/100 iters), loss = 0.0122015
I1203 17:55:02.622333 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:55:02.622333 12164 solver.cpp:237]     Train net output #1: loss = 0.0122014 (* 1 = 0.0122014 loss)
I1203 17:55:02.622333 12164 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1203 17:55:10.925778 12164 solver.cpp:218] Iteration 143200 (12.0435 iter/s, 8.30324s/100 iters), loss = 0.0125047
I1203 17:55:10.925778 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:55:10.925778 12164 solver.cpp:237]     Train net output #1: loss = 0.0125045 (* 1 = 0.0125045 loss)
I1203 17:55:10.925778 12164 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1203 17:55:19.157260 12164 solver.cpp:218] Iteration 143300 (12.1498 iter/s, 8.23059s/100 iters), loss = 0.0102036
I1203 17:55:19.157260 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:55:19.157260 12164 solver.cpp:237]     Train net output #1: loss = 0.0102034 (* 1 = 0.0102034 loss)
I1203 17:55:19.157260 12164 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1203 17:55:27.384308 12164 solver.cpp:218] Iteration 143400 (12.156 iter/s, 8.22639s/100 iters), loss = 0.012416
I1203 17:55:27.384308 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:55:27.384308 12164 solver.cpp:237]     Train net output #1: loss = 0.0124159 (* 1 = 0.0124159 loss)
I1203 17:55:27.384308 12164 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1203 17:55:35.173540  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:55:35.491060 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.caffemodel
I1203 17:55:35.519564 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_143500.solverstate
I1203 17:55:35.525564 12164 solver.cpp:330] Iteration 143500, Testing net (#0)
I1203 17:55:35.526564 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:55:37.227722 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:55:37.296231 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9316
I1203 17:55:37.296231 12164 solver.cpp:397]     Test net output #1: loss = 0.249654 (* 1 = 0.249654 loss)
I1203 17:55:37.371736 12164 solver.cpp:218] Iteration 143500 (10.0125 iter/s, 9.98748s/100 iters), loss = 0.0136969
I1203 17:55:37.371736 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:55:37.371736 12164 solver.cpp:237]     Train net output #1: loss = 0.0136967 (* 1 = 0.0136967 loss)
I1203 17:55:37.371736 12164 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1203 17:55:45.527958 12164 solver.cpp:218] Iteration 143600 (12.2614 iter/s, 8.15565s/100 iters), loss = 0.0332189
I1203 17:55:45.527958 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:55:45.527958 12164 solver.cpp:237]     Train net output #1: loss = 0.0332188 (* 1 = 0.0332188 loss)
I1203 17:55:45.527958 12164 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1203 17:55:53.730985 12164 solver.cpp:218] Iteration 143700 (12.1919 iter/s, 8.20214s/100 iters), loss = 0.0121472
I1203 17:55:53.730985 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:55:53.730985 12164 solver.cpp:237]     Train net output #1: loss = 0.0121471 (* 1 = 0.0121471 loss)
I1203 17:55:53.730985 12164 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1203 17:56:02.011056 12164 solver.cpp:218] Iteration 143800 (12.0772 iter/s, 8.28004s/100 iters), loss = 0.0113346
I1203 17:56:02.011056 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:56:02.011056 12164 solver.cpp:237]     Train net output #1: loss = 0.0113345 (* 1 = 0.0113345 loss)
I1203 17:56:02.011056 12164 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1203 17:56:10.277930 12164 solver.cpp:218] Iteration 143900 (12.0977 iter/s, 8.26604s/100 iters), loss = 0.0128214
I1203 17:56:10.277930 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:56:10.277930 12164 solver.cpp:237]     Train net output #1: loss = 0.0128213 (* 1 = 0.0128213 loss)
I1203 17:56:10.277930 12164 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1203 17:56:18.171247  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:56:18.503391 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.caffemodel
I1203 17:56:18.536391 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144000.solverstate
I1203 17:56:18.543392 12164 solver.cpp:330] Iteration 144000, Testing net (#0)
I1203 17:56:18.543392 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:56:20.276633 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:56:20.342604 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9328
I1203 17:56:20.342604 12164 solver.cpp:397]     Test net output #1: loss = 0.251037 (* 1 = 0.251037 loss)
I1203 17:56:20.416468 12164 solver.cpp:218] Iteration 144000 (9.86363 iter/s, 10.1383s/100 iters), loss = 0.0113186
I1203 17:56:20.416468 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:56:20.416468 12164 solver.cpp:237]     Train net output #1: loss = 0.0113184 (* 1 = 0.0113184 loss)
I1203 17:56:20.416468 12164 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1203 17:56:28.660635 12164 solver.cpp:218] Iteration 144100 (12.1315 iter/s, 8.24298s/100 iters), loss = 0.0264719
I1203 17:56:28.660635 12164 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1203 17:56:28.660635 12164 solver.cpp:237]     Train net output #1: loss = 0.0264718 (* 1 = 0.0264718 loss)
I1203 17:56:28.660635 12164 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1203 17:56:36.911413 12164 solver.cpp:218] Iteration 144200 (12.1209 iter/s, 8.25021s/100 iters), loss = 0.0197551
I1203 17:56:36.911413 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:56:36.911413 12164 solver.cpp:237]     Train net output #1: loss = 0.0197549 (* 1 = 0.0197549 loss)
I1203 17:56:36.911413 12164 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1203 17:56:45.160966 12164 solver.cpp:218] Iteration 144300 (12.1221 iter/s, 8.24938s/100 iters), loss = 0.00972564
I1203 17:56:45.160966 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:56:45.161468 12164 solver.cpp:237]     Train net output #1: loss = 0.00972548 (* 1 = 0.00972548 loss)
I1203 17:56:45.161468 12164 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1203 17:56:53.450775 12164 solver.cpp:218] Iteration 144400 (12.0636 iter/s, 8.28938s/100 iters), loss = 0.0111251
I1203 17:56:53.450775 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:56:53.450775 12164 solver.cpp:237]     Train net output #1: loss = 0.011125 (* 1 = 0.011125 loss)
I1203 17:56:53.450775 12164 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1203 17:57:01.248638  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:57:01.578696 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.caffemodel
I1203 17:57:01.610697 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_144500.solverstate
I1203 17:57:01.617708 12164 solver.cpp:330] Iteration 144500, Testing net (#0)
I1203 17:57:01.618700 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:57:03.323863 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:57:03.392873 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9312
I1203 17:57:03.392873 12164 solver.cpp:397]     Test net output #1: loss = 0.255586 (* 1 = 0.255586 loss)
I1203 17:57:03.473373 12164 solver.cpp:218] Iteration 144500 (9.97827 iter/s, 10.0218s/100 iters), loss = 0.0102373
I1203 17:57:03.473373 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:03.473373 12164 solver.cpp:237]     Train net output #1: loss = 0.0102371 (* 1 = 0.0102371 loss)
I1203 17:57:03.473373 12164 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1203 17:57:11.685845 12164 solver.cpp:218] Iteration 144600 (12.1767 iter/s, 8.21239s/100 iters), loss = 0.0113447
I1203 17:57:11.685845 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:11.685845 12164 solver.cpp:237]     Train net output #1: loss = 0.0113445 (* 1 = 0.0113445 loss)
I1203 17:57:11.685845 12164 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1203 17:57:19.871042 12164 solver.cpp:218] Iteration 144700 (12.2187 iter/s, 8.1842s/100 iters), loss = 0.00963999
I1203 17:57:19.871042 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:19.871042 12164 solver.cpp:237]     Train net output #1: loss = 0.00963982 (* 1 = 0.00963982 loss)
I1203 17:57:19.871042 12164 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1203 17:57:28.156107 12164 solver.cpp:218] Iteration 144800 (12.071 iter/s, 8.28429s/100 iters), loss = 0.00935571
I1203 17:57:28.156107 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:28.156107 12164 solver.cpp:237]     Train net output #1: loss = 0.00935555 (* 1 = 0.00935555 loss)
I1203 17:57:28.156107 12164 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1203 17:57:36.470860 12164 solver.cpp:218] Iteration 144900 (12.0274 iter/s, 8.31432s/100 iters), loss = 0.0136321
I1203 17:57:36.470860 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:36.471360 12164 solver.cpp:237]     Train net output #1: loss = 0.0136319 (* 1 = 0.0136319 loss)
I1203 17:57:36.471360 12164 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1203 17:57:44.308715  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:57:44.626792 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.caffemodel
I1203 17:57:44.656811 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145000.solverstate
I1203 17:57:44.662807 12164 solver.cpp:330] Iteration 145000, Testing net (#0)
I1203 17:57:44.662807 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:57:46.382676 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:57:46.451467 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1203 17:57:46.451467 12164 solver.cpp:397]     Test net output #1: loss = 0.250616 (* 1 = 0.250616 loss)
I1203 17:57:46.528728 12164 solver.cpp:218] Iteration 145000 (9.94345 iter/s, 10.0569s/100 iters), loss = 0.0105428
I1203 17:57:46.528728 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:46.528728 12164 solver.cpp:237]     Train net output #1: loss = 0.0105427 (* 1 = 0.0105427 loss)
I1203 17:57:46.528728 12164 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1203 17:57:54.726958 12164 solver.cpp:218] Iteration 145100 (12.1985 iter/s, 8.19772s/100 iters), loss = 0.0137619
I1203 17:57:54.726958 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:57:54.726958 12164 solver.cpp:237]     Train net output #1: loss = 0.0137617 (* 1 = 0.0137617 loss)
I1203 17:57:54.726958 12164 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1203 17:58:02.976907 12164 solver.cpp:218] Iteration 145200 (12.1221 iter/s, 8.24937s/100 iters), loss = 0.0106973
I1203 17:58:02.976907 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:02.976907 12164 solver.cpp:237]     Train net output #1: loss = 0.0106971 (* 1 = 0.0106971 loss)
I1203 17:58:02.976907 12164 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1203 17:58:11.238937 12164 solver.cpp:218] Iteration 145300 (12.1037 iter/s, 8.26194s/100 iters), loss = 0.00894219
I1203 17:58:11.238937 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:11.238937 12164 solver.cpp:237]     Train net output #1: loss = 0.00894202 (* 1 = 0.00894202 loss)
I1203 17:58:11.238937 12164 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1203 17:58:19.475121 12164 solver.cpp:218] Iteration 145400 (12.1427 iter/s, 8.2354s/100 iters), loss = 0.0101038
I1203 17:58:19.475121 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:19.475121 12164 solver.cpp:237]     Train net output #1: loss = 0.0101036 (* 1 = 0.0101036 loss)
I1203 17:58:19.475121 12164 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1203 17:58:27.423753  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:58:27.772251 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.caffemodel
I1203 17:58:27.807251 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_145500.solverstate
I1203 17:58:27.813751 12164 solver.cpp:330] Iteration 145500, Testing net (#0)
I1203 17:58:27.813751 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:58:29.534751 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:58:29.603251 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9327
I1203 17:58:29.603251 12164 solver.cpp:397]     Test net output #1: loss = 0.251722 (* 1 = 0.251722 loss)
I1203 17:58:29.680250 12164 solver.cpp:218] Iteration 145500 (9.79957 iter/s, 10.2045s/100 iters), loss = 0.0142734
I1203 17:58:29.680250 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:29.680250 12164 solver.cpp:237]     Train net output #1: loss = 0.0142732 (* 1 = 0.0142732 loss)
I1203 17:58:29.680250 12164 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1203 17:58:37.937328 12164 solver.cpp:218] Iteration 145600 (12.1116 iter/s, 8.25655s/100 iters), loss = 0.0161482
I1203 17:58:37.937328 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:37.937328 12164 solver.cpp:237]     Train net output #1: loss = 0.016148 (* 1 = 0.016148 loss)
I1203 17:58:37.937328 12164 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1203 17:58:46.225644 12164 solver.cpp:218] Iteration 145700 (12.0656 iter/s, 8.28805s/100 iters), loss = 0.0130662
I1203 17:58:46.225644 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:46.225644 12164 solver.cpp:237]     Train net output #1: loss = 0.0130661 (* 1 = 0.0130661 loss)
I1203 17:58:46.225644 12164 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1203 17:58:54.503895 12164 solver.cpp:218] Iteration 145800 (12.0812 iter/s, 8.27731s/100 iters), loss = 0.0124031
I1203 17:58:54.503895 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:58:54.503895 12164 solver.cpp:237]     Train net output #1: loss = 0.0124029 (* 1 = 0.0124029 loss)
I1203 17:58:54.503895 12164 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1203 17:59:02.804316 12164 solver.cpp:218] Iteration 145900 (12.0484 iter/s, 8.29984s/100 iters), loss = 0.0123438
I1203 17:59:02.804316 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:59:02.804316 12164 solver.cpp:237]     Train net output #1: loss = 0.0123436 (* 1 = 0.0123436 loss)
I1203 17:59:02.804316 12164 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1203 17:59:10.702503  6116 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:59:11.033368 12164 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.caffemodel
I1203 17:59:11.066370 12164 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/resnet32_with3pooling_iter_146000.solverstate
I1203 17:59:11.073370 12164 solver.cpp:330] Iteration 146000, Testing net (#0)
I1203 17:59:11.074369 12164 net.cpp:676] Ignoring source layer accuracy_training
I1203 17:59:12.794412 15980 data_layer.cpp:73] Restarting data prefetching from start.
I1203 17:59:12.862421 12164 solver.cpp:397]     Test net output #0: accuracy = 0.9334
I1203 17:59:12.862421 12164 solver.cpp:397]     Test net output #1: loss = 0.250318 (* 1 = 0.250318 loss)
I1203 17:59:12.939435 12164 solver.cpp:218] Iteration 146000 (9.8666 iter/s, 10.1352s/100 iters), loss = 0.0205442
I1203 17:59:12.940433 12164 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1203 17:59:12.940433 12164 solver.cpp:237]     Train net output #1: loss = 0.020544 (* 