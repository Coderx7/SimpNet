
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt --snapshot=examples/cifar10/snaps/slimnet_1M__iter_90000.solverstate 
I1016 21:14:26.250854   636 caffe.cpp:219] Using GPUs 0
I1016 21:14:26.484834   636 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1016 21:14:27.005777   636 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1016 21:14:27.052640   636 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 500
snapshot_prefix: "examples/cifar10/snaps/slimnet_1M_"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 153000
stepvalue: 195000
stepvalue: 220000
stepvalue: 270000
type: "AdaDelta"
I1016 21:14:27.052640   636 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1016 21:14:27.052640   636 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1016 21:14:27.052640   636 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1016 21:14:27.052640   636 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1016 21:14:27.052640   636 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_1M"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 60
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 110
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 110
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 127
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 150
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1016 21:14:27.052640   636 layer_factory.cpp:58] Creating layer cifar
I1016 21:14:27.068282   636 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I1016 21:14:27.068282   636 net.cpp:84] Creating Layer cifar
I1016 21:14:27.068282   636 net.cpp:380] cifar -> data
I1016 21:14:27.068282   636 net.cpp:380] cifar -> label
I1016 21:14:27.068282   636 data_layer.cpp:45] output data size: 100,3,32,32
I1016 21:14:27.068282   636 net.cpp:122] Setting up cifar
I1016 21:14:27.068282   636 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1016 21:14:27.068282   636 net.cpp:129] Top shape: 100 (100)
I1016 21:14:27.068282   636 net.cpp:137] Memory required for data: 1229200
I1016 21:14:27.068282   636 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1016 21:14:27.068282   636 net.cpp:84] Creating Layer label_cifar_1_split
I1016 21:14:27.068282   636 net.cpp:406] label_cifar_1_split <- label
I1016 21:14:27.068282   636 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1016 21:14:27.068282   636 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1016 21:14:27.068282   636 net.cpp:122] Setting up label_cifar_1_split
I1016 21:14:27.068282   636 net.cpp:129] Top shape: 100 (100)
I1016 21:14:27.068282   636 net.cpp:129] Top shape: 100 (100)
I1016 21:14:27.068282   636 net.cpp:137] Memory required for data: 1230000
I1016 21:14:27.068282   636 layer_factory.cpp:58] Creating layer conv1
I1016 21:14:27.068282   636 net.cpp:84] Creating Layer conv1
I1016 21:14:27.068282   636 net.cpp:406] conv1 <- data
I1016 21:14:27.068282   636 net.cpp:380] conv1 -> conv1
I1016 21:14:27.068282  4172 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1016 21:14:27.776211   636 net.cpp:122] Setting up conv1
I1016 21:14:27.776211   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.776211   636 net.cpp:137] Memory required for data: 25806000
I1016 21:14:27.776211   636 layer_factory.cpp:58] Creating layer bn1
I1016 21:14:27.776211   636 net.cpp:84] Creating Layer bn1
I1016 21:14:27.776211   636 net.cpp:406] bn1 <- conv1
I1016 21:14:27.776211   636 net.cpp:367] bn1 -> conv1 (in-place)
I1016 21:14:27.776211   636 net.cpp:122] Setting up bn1
I1016 21:14:27.776211   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.776211   636 net.cpp:137] Memory required for data: 50382000
I1016 21:14:27.776211   636 layer_factory.cpp:58] Creating layer scale1
I1016 21:14:27.776211   636 net.cpp:84] Creating Layer scale1
I1016 21:14:27.776211   636 net.cpp:406] scale1 <- conv1
I1016 21:14:27.776211   636 net.cpp:367] scale1 -> conv1 (in-place)
I1016 21:14:27.776211   636 layer_factory.cpp:58] Creating layer scale1
I1016 21:14:27.776729   636 net.cpp:122] Setting up scale1
I1016 21:14:27.776729   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.776729   636 net.cpp:137] Memory required for data: 74958000
I1016 21:14:27.776729   636 layer_factory.cpp:58] Creating layer relu1
I1016 21:14:27.776729   636 net.cpp:84] Creating Layer relu1
I1016 21:14:27.776729   636 net.cpp:406] relu1 <- conv1
I1016 21:14:27.776729   636 net.cpp:367] relu1 -> conv1 (in-place)
I1016 21:14:27.776729   636 net.cpp:122] Setting up relu1
I1016 21:14:27.776729   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.776729   636 net.cpp:137] Memory required for data: 99534000
I1016 21:14:27.776729   636 layer_factory.cpp:58] Creating layer conv1_0
I1016 21:14:27.776729   636 net.cpp:84] Creating Layer conv1_0
I1016 21:14:27.776729   636 net.cpp:406] conv1_0 <- conv1
I1016 21:14:27.776729   636 net.cpp:380] conv1_0 -> conv1_0
I1016 21:14:27.778964   636 net.cpp:122] Setting up conv1_0
I1016 21:14:27.778964   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.778964   636 net.cpp:137] Memory required for data: 132302000
I1016 21:14:27.778964   636 layer_factory.cpp:58] Creating layer bn1_0
I1016 21:14:27.778964   636 net.cpp:84] Creating Layer bn1_0
I1016 21:14:27.779477   636 net.cpp:406] bn1_0 <- conv1_0
I1016 21:14:27.779477   636 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1016 21:14:27.779477   636 net.cpp:122] Setting up bn1_0
I1016 21:14:27.779477   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.779477   636 net.cpp:137] Memory required for data: 165070000
I1016 21:14:27.779477   636 layer_factory.cpp:58] Creating layer scale1_0
I1016 21:14:27.779477   636 net.cpp:84] Creating Layer scale1_0
I1016 21:14:27.779477   636 net.cpp:406] scale1_0 <- conv1_0
I1016 21:14:27.779477   636 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1016 21:14:27.779477   636 layer_factory.cpp:58] Creating layer scale1_0
I1016 21:14:27.779477   636 net.cpp:122] Setting up scale1_0
I1016 21:14:27.779477   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.779477   636 net.cpp:137] Memory required for data: 197838000
I1016 21:14:27.779477   636 layer_factory.cpp:58] Creating layer relu1_0
I1016 21:14:27.779477   636 net.cpp:84] Creating Layer relu1_0
I1016 21:14:27.779477   636 net.cpp:406] relu1_0 <- conv1_0
I1016 21:14:27.779477   636 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1016 21:14:27.779961   636 net.cpp:122] Setting up relu1_0
I1016 21:14:27.780450   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.780450   636 net.cpp:137] Memory required for data: 230606000
I1016 21:14:27.780450   636 layer_factory.cpp:58] Creating layer conv2
I1016 21:14:27.780450   636 net.cpp:84] Creating Layer conv2
I1016 21:14:27.780450   636 net.cpp:406] conv2 <- conv1_0
I1016 21:14:27.780450   636 net.cpp:380] conv2 -> conv2
I1016 21:14:27.781713   636 net.cpp:122] Setting up conv2
I1016 21:14:27.781713   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.781713   636 net.cpp:137] Memory required for data: 263374000
I1016 21:14:27.781713   636 layer_factory.cpp:58] Creating layer bn2
I1016 21:14:27.781713   636 net.cpp:84] Creating Layer bn2
I1016 21:14:27.781713   636 net.cpp:406] bn2 <- conv2
I1016 21:14:27.781713   636 net.cpp:367] bn2 -> conv2 (in-place)
I1016 21:14:27.781713   636 net.cpp:122] Setting up bn2
I1016 21:14:27.781713   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.781713   636 net.cpp:137] Memory required for data: 296142000
I1016 21:14:27.781713   636 layer_factory.cpp:58] Creating layer scale2
I1016 21:14:27.781713   636 net.cpp:84] Creating Layer scale2
I1016 21:14:27.781713   636 net.cpp:406] scale2 <- conv2
I1016 21:14:27.781713   636 net.cpp:367] scale2 -> conv2 (in-place)
I1016 21:14:27.781713   636 layer_factory.cpp:58] Creating layer scale2
I1016 21:14:27.781713   636 net.cpp:122] Setting up scale2
I1016 21:14:27.781713   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.781713   636 net.cpp:137] Memory required for data: 328910000
I1016 21:14:27.781713   636 layer_factory.cpp:58] Creating layer relu2
I1016 21:14:27.781713   636 net.cpp:84] Creating Layer relu2
I1016 21:14:27.781713   636 net.cpp:406] relu2 <- conv2
I1016 21:14:27.781713   636 net.cpp:367] relu2 -> conv2 (in-place)
I1016 21:14:27.782234   636 net.cpp:122] Setting up relu2
I1016 21:14:27.782234   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.782234   636 net.cpp:137] Memory required for data: 361678000
I1016 21:14:27.782234   636 layer_factory.cpp:58] Creating layer conv2_1
I1016 21:14:27.782234   636 net.cpp:84] Creating Layer conv2_1
I1016 21:14:27.782234   636 net.cpp:406] conv2_1 <- conv2
I1016 21:14:27.782234   636 net.cpp:380] conv2_1 -> conv2_1
I1016 21:14:27.783721   636 net.cpp:122] Setting up conv2_1
I1016 21:14:27.783721   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.783721   636 net.cpp:137] Memory required for data: 394446000
I1016 21:14:27.783721   636 layer_factory.cpp:58] Creating layer bn2_1
I1016 21:14:27.783721   636 net.cpp:84] Creating Layer bn2_1
I1016 21:14:27.783721   636 net.cpp:406] bn2_1 <- conv2_1
I1016 21:14:27.783721   636 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1016 21:14:27.784234   636 net.cpp:122] Setting up bn2_1
I1016 21:14:27.784234   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.784234   636 net.cpp:137] Memory required for data: 427214000
I1016 21:14:27.784234   636 layer_factory.cpp:58] Creating layer scale2_1
I1016 21:14:27.784234   636 net.cpp:84] Creating Layer scale2_1
I1016 21:14:27.784234   636 net.cpp:406] scale2_1 <- conv2_1
I1016 21:14:27.784234   636 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1016 21:14:27.784234   636 layer_factory.cpp:58] Creating layer scale2_1
I1016 21:14:27.784234   636 net.cpp:122] Setting up scale2_1
I1016 21:14:27.784234   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.784234   636 net.cpp:137] Memory required for data: 459982000
I1016 21:14:27.784234   636 layer_factory.cpp:58] Creating layer relu2_1
I1016 21:14:27.784234   636 net.cpp:84] Creating Layer relu2_1
I1016 21:14:27.784234   636 net.cpp:406] relu2_1 <- conv2_1
I1016 21:14:27.784234   636 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1016 21:14:27.784734   636 net.cpp:122] Setting up relu2_1
I1016 21:14:27.784734   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.784734   636 net.cpp:137] Memory required for data: 492750000
I1016 21:14:27.784734   636 layer_factory.cpp:58] Creating layer conv2_2
I1016 21:14:27.784734   636 net.cpp:84] Creating Layer conv2_2
I1016 21:14:27.784734   636 net.cpp:406] conv2_2 <- conv2_1
I1016 21:14:27.784734   636 net.cpp:380] conv2_2 -> conv2_2
I1016 21:14:27.786236   636 net.cpp:122] Setting up conv2_2
I1016 21:14:27.786236   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.786236   636 net.cpp:137] Memory required for data: 527566000
I1016 21:14:27.786236   636 layer_factory.cpp:58] Creating layer bn2_2
I1016 21:14:27.786236   636 net.cpp:84] Creating Layer bn2_2
I1016 21:14:27.786236   636 net.cpp:406] bn2_2 <- conv2_2
I1016 21:14:27.786236   636 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1016 21:14:27.786236   636 net.cpp:122] Setting up bn2_2
I1016 21:14:27.786236   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.786236   636 net.cpp:137] Memory required for data: 562382000
I1016 21:14:27.786236   636 layer_factory.cpp:58] Creating layer scale2_2
I1016 21:14:27.786236   636 net.cpp:84] Creating Layer scale2_2
I1016 21:14:27.786236   636 net.cpp:406] scale2_2 <- conv2_2
I1016 21:14:27.786236   636 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1016 21:14:27.786736   636 layer_factory.cpp:58] Creating layer scale2_2
I1016 21:14:27.786736   636 net.cpp:122] Setting up scale2_2
I1016 21:14:27.786736   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.786736   636 net.cpp:137] Memory required for data: 597198000
I1016 21:14:27.786736   636 layer_factory.cpp:58] Creating layer relu2_2
I1016 21:14:27.786736   636 net.cpp:84] Creating Layer relu2_2
I1016 21:14:27.786736   636 net.cpp:406] relu2_2 <- conv2_2
I1016 21:14:27.786736   636 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1016 21:14:27.786736   636 net.cpp:122] Setting up relu2_2
I1016 21:14:27.787220   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.787220   636 net.cpp:137] Memory required for data: 632014000
I1016 21:14:27.787220   636 layer_factory.cpp:58] Creating layer pool2_1
I1016 21:14:27.787220   636 net.cpp:84] Creating Layer pool2_1
I1016 21:14:27.787220   636 net.cpp:406] pool2_1 <- conv2_2
I1016 21:14:27.787220   636 net.cpp:380] pool2_1 -> pool2_1
I1016 21:14:27.787220   636 net.cpp:122] Setting up pool2_1
I1016 21:14:27.787220   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.787220   636 net.cpp:137] Memory required for data: 640718000
I1016 21:14:27.787220   636 layer_factory.cpp:58] Creating layer conv3
I1016 21:14:27.787220   636 net.cpp:84] Creating Layer conv3
I1016 21:14:27.787220   636 net.cpp:406] conv3 <- pool2_1
I1016 21:14:27.787220   636 net.cpp:380] conv3 -> conv3
I1016 21:14:27.790222   636 net.cpp:122] Setting up conv3
I1016 21:14:27.790222   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.790222   636 net.cpp:137] Memory required for data: 649422000
I1016 21:14:27.790222   636 layer_factory.cpp:58] Creating layer bn3
I1016 21:14:27.790222   636 net.cpp:84] Creating Layer bn3
I1016 21:14:27.790222   636 net.cpp:406] bn3 <- conv3
I1016 21:14:27.790222   636 net.cpp:367] bn3 -> conv3 (in-place)
I1016 21:14:27.790222   636 net.cpp:122] Setting up bn3
I1016 21:14:27.790222   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.790222   636 net.cpp:137] Memory required for data: 658126000
I1016 21:14:27.790222   636 layer_factory.cpp:58] Creating layer scale3
I1016 21:14:27.790222   636 net.cpp:84] Creating Layer scale3
I1016 21:14:27.790222   636 net.cpp:406] scale3 <- conv3
I1016 21:14:27.790222   636 net.cpp:367] scale3 -> conv3 (in-place)
I1016 21:14:27.790222   636 layer_factory.cpp:58] Creating layer scale3
I1016 21:14:27.790222   636 net.cpp:122] Setting up scale3
I1016 21:14:27.790222   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.790222   636 net.cpp:137] Memory required for data: 666830000
I1016 21:14:27.790222   636 layer_factory.cpp:58] Creating layer relu3
I1016 21:14:27.790222   636 net.cpp:84] Creating Layer relu3
I1016 21:14:27.790735   636 net.cpp:406] relu3 <- conv3
I1016 21:14:27.790735   636 net.cpp:367] relu3 -> conv3 (in-place)
I1016 21:14:27.790735   636 net.cpp:122] Setting up relu3
I1016 21:14:27.790735   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.790735   636 net.cpp:137] Memory required for data: 675534000
I1016 21:14:27.790735   636 layer_factory.cpp:58] Creating layer conv3_1
I1016 21:14:27.790735   636 net.cpp:84] Creating Layer conv3_1
I1016 21:14:27.790735   636 net.cpp:406] conv3_1 <- conv3
I1016 21:14:27.790735   636 net.cpp:380] conv3_1 -> conv3_1
I1016 21:14:27.792745   636 net.cpp:122] Setting up conv3_1
I1016 21:14:27.792745   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.792745   636 net.cpp:137] Memory required for data: 684750000
I1016 21:14:27.792745   636 layer_factory.cpp:58] Creating layer bn3_1
I1016 21:14:27.792745   636 net.cpp:84] Creating Layer bn3_1
I1016 21:14:27.792745   636 net.cpp:406] bn3_1 <- conv3_1
I1016 21:14:27.792745   636 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1016 21:14:27.792745   636 net.cpp:122] Setting up bn3_1
I1016 21:14:27.792745   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.792745   636 net.cpp:137] Memory required for data: 693966000
I1016 21:14:27.792745   636 layer_factory.cpp:58] Creating layer scale3_1
I1016 21:14:27.792745   636 net.cpp:84] Creating Layer scale3_1
I1016 21:14:27.792745   636 net.cpp:406] scale3_1 <- conv3_1
I1016 21:14:27.792745   636 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1016 21:14:27.792745   636 layer_factory.cpp:58] Creating layer scale3_1
I1016 21:14:27.792745   636 net.cpp:122] Setting up scale3_1
I1016 21:14:27.792745   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.792745   636 net.cpp:137] Memory required for data: 703182000
I1016 21:14:27.792745   636 layer_factory.cpp:58] Creating layer relu3_1
I1016 21:14:27.792745   636 net.cpp:84] Creating Layer relu3_1
I1016 21:14:27.792745   636 net.cpp:406] relu3_1 <- conv3_1
I1016 21:14:27.792745   636 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1016 21:14:27.793748   636 net.cpp:122] Setting up relu3_1
I1016 21:14:27.793748   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.793748   636 net.cpp:137] Memory required for data: 712398000
I1016 21:14:27.793748   636 layer_factory.cpp:58] Creating layer conv4
I1016 21:14:27.793748   636 net.cpp:84] Creating Layer conv4
I1016 21:14:27.793748   636 net.cpp:406] conv4 <- conv3_1
I1016 21:14:27.793748   636 net.cpp:380] conv4 -> conv4
I1016 21:14:27.795733   636 net.cpp:122] Setting up conv4
I1016 21:14:27.795733   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.795733   636 net.cpp:137] Memory required for data: 721614000
I1016 21:14:27.795733   636 layer_factory.cpp:58] Creating layer bn4
I1016 21:14:27.795733   636 net.cpp:84] Creating Layer bn4
I1016 21:14:27.795733   636 net.cpp:406] bn4 <- conv4
I1016 21:14:27.795733   636 net.cpp:367] bn4 -> conv4 (in-place)
I1016 21:14:27.795733   636 net.cpp:122] Setting up bn4
I1016 21:14:27.795733   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.795733   636 net.cpp:137] Memory required for data: 730830000
I1016 21:14:27.795733   636 layer_factory.cpp:58] Creating layer scale4
I1016 21:14:27.795733   636 net.cpp:84] Creating Layer scale4
I1016 21:14:27.795733   636 net.cpp:406] scale4 <- conv4
I1016 21:14:27.795733   636 net.cpp:367] scale4 -> conv4 (in-place)
I1016 21:14:27.795733   636 layer_factory.cpp:58] Creating layer scale4
I1016 21:14:27.795733   636 net.cpp:122] Setting up scale4
I1016 21:14:27.795733   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.795733   636 net.cpp:137] Memory required for data: 740046000
I1016 21:14:27.795733   636 layer_factory.cpp:58] Creating layer relu4
I1016 21:14:27.795733   636 net.cpp:84] Creating Layer relu4
I1016 21:14:27.795733   636 net.cpp:406] relu4 <- conv4
I1016 21:14:27.795733   636 net.cpp:367] relu4 -> conv4 (in-place)
I1016 21:14:27.796735   636 net.cpp:122] Setting up relu4
I1016 21:14:27.796735   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.796735   636 net.cpp:137] Memory required for data: 749262000
I1016 21:14:27.796735   636 layer_factory.cpp:58] Creating layer conv4_1
I1016 21:14:27.796735   636 net.cpp:84] Creating Layer conv4_1
I1016 21:14:27.796735   636 net.cpp:406] conv4_1 <- conv4
I1016 21:14:27.796735   636 net.cpp:380] conv4_1 -> conv4_1
I1016 21:14:27.798421   636 net.cpp:122] Setting up conv4_1
I1016 21:14:27.798421   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.798421   636 net.cpp:137] Memory required for data: 758478000
I1016 21:14:27.798421   636 layer_factory.cpp:58] Creating layer bn4_1
I1016 21:14:27.798421   636 net.cpp:84] Creating Layer bn4_1
I1016 21:14:27.798421   636 net.cpp:406] bn4_1 <- conv4_1
I1016 21:14:27.798421   636 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1016 21:14:27.798421   636 net.cpp:122] Setting up bn4_1
I1016 21:14:27.798421   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.798421   636 net.cpp:137] Memory required for data: 767694000
I1016 21:14:27.798421   636 layer_factory.cpp:58] Creating layer scale4_1
I1016 21:14:27.798421   636 net.cpp:84] Creating Layer scale4_1
I1016 21:14:27.798421   636 net.cpp:406] scale4_1 <- conv4_1
I1016 21:14:27.798421   636 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1016 21:14:27.798421   636 layer_factory.cpp:58] Creating layer scale4_1
I1016 21:14:27.798421   636 net.cpp:122] Setting up scale4_1
I1016 21:14:27.798421   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.798421   636 net.cpp:137] Memory required for data: 776910000
I1016 21:14:27.798421   636 layer_factory.cpp:58] Creating layer relu4_1
I1016 21:14:27.798421   636 net.cpp:84] Creating Layer relu4_1
I1016 21:14:27.798421   636 net.cpp:406] relu4_1 <- conv4_1
I1016 21:14:27.798421   636 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1016 21:14:27.799177   636 net.cpp:122] Setting up relu4_1
I1016 21:14:27.799177   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.799177   636 net.cpp:137] Memory required for data: 786126000
I1016 21:14:27.799177   636 layer_factory.cpp:58] Creating layer conv4_2
I1016 21:14:27.799177   636 net.cpp:84] Creating Layer conv4_2
I1016 21:14:27.799177   636 net.cpp:406] conv4_2 <- conv4_1
I1016 21:14:27.799177   636 net.cpp:380] conv4_2 -> conv4_2
I1016 21:14:27.801184   636 net.cpp:122] Setting up conv4_2
I1016 21:14:27.801184   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.801184   636 net.cpp:137] Memory required for data: 797390000
I1016 21:14:27.801184   636 layer_factory.cpp:58] Creating layer bn4_2
I1016 21:14:27.801184   636 net.cpp:84] Creating Layer bn4_2
I1016 21:14:27.801184   636 net.cpp:406] bn4_2 <- conv4_2
I1016 21:14:27.801184   636 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1016 21:14:27.801184   636 net.cpp:122] Setting up bn4_2
I1016 21:14:27.801184   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.801184   636 net.cpp:137] Memory required for data: 808654000
I1016 21:14:27.801184   636 layer_factory.cpp:58] Creating layer scale4_2
I1016 21:14:27.801184   636 net.cpp:84] Creating Layer scale4_2
I1016 21:14:27.801184   636 net.cpp:406] scale4_2 <- conv4_2
I1016 21:14:27.801184   636 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1016 21:14:27.801184   636 layer_factory.cpp:58] Creating layer scale4_2
I1016 21:14:27.801184   636 net.cpp:122] Setting up scale4_2
I1016 21:14:27.801184   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.801184   636 net.cpp:137] Memory required for data: 819918000
I1016 21:14:27.801184   636 layer_factory.cpp:58] Creating layer relu4_2
I1016 21:14:27.801184   636 net.cpp:84] Creating Layer relu4_2
I1016 21:14:27.801184   636 net.cpp:406] relu4_2 <- conv4_2
I1016 21:14:27.801184   636 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1016 21:14:27.801184   636 net.cpp:122] Setting up relu4_2
I1016 21:14:27.801184   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.801184   636 net.cpp:137] Memory required for data: 831182000
I1016 21:14:27.801184   636 layer_factory.cpp:58] Creating layer pool4_2
I1016 21:14:27.801184   636 net.cpp:84] Creating Layer pool4_2
I1016 21:14:27.801184   636 net.cpp:406] pool4_2 <- conv4_2
I1016 21:14:27.801184   636 net.cpp:380] pool4_2 -> pool4_2
I1016 21:14:27.801184   636 net.cpp:122] Setting up pool4_2
I1016 21:14:27.801184   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.801184   636 net.cpp:137] Memory required for data: 833998000
I1016 21:14:27.801184   636 layer_factory.cpp:58] Creating layer conv4_0
I1016 21:14:27.801184   636 net.cpp:84] Creating Layer conv4_0
I1016 21:14:27.801184   636 net.cpp:406] conv4_0 <- pool4_2
I1016 21:14:27.801184   636 net.cpp:380] conv4_0 -> conv4_0
I1016 21:14:27.804184   636 net.cpp:122] Setting up conv4_0
I1016 21:14:27.804184   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.804184   636 net.cpp:137] Memory required for data: 836814000
I1016 21:14:27.804184   636 layer_factory.cpp:58] Creating layer bn4_0
I1016 21:14:27.804184   636 net.cpp:84] Creating Layer bn4_0
I1016 21:14:27.804184   636 net.cpp:406] bn4_0 <- conv4_0
I1016 21:14:27.804184   636 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1016 21:14:27.804184   636 net.cpp:122] Setting up bn4_0
I1016 21:14:27.804184   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.804184   636 net.cpp:137] Memory required for data: 839630000
I1016 21:14:27.804184   636 layer_factory.cpp:58] Creating layer scale4_0
I1016 21:14:27.804184   636 net.cpp:84] Creating Layer scale4_0
I1016 21:14:27.804184   636 net.cpp:406] scale4_0 <- conv4_0
I1016 21:14:27.804184   636 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1016 21:14:27.804184   636 layer_factory.cpp:58] Creating layer scale4_0
I1016 21:14:27.805184   636 net.cpp:122] Setting up scale4_0
I1016 21:14:27.805184   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.805184   636 net.cpp:137] Memory required for data: 842446000
I1016 21:14:27.805184   636 layer_factory.cpp:58] Creating layer relu4_0
I1016 21:14:27.805184   636 net.cpp:84] Creating Layer relu4_0
I1016 21:14:27.805184   636 net.cpp:406] relu4_0 <- conv4_0
I1016 21:14:27.805184   636 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1016 21:14:27.805184   636 net.cpp:122] Setting up relu4_0
I1016 21:14:27.805184   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.805184   636 net.cpp:137] Memory required for data: 845262000
I1016 21:14:27.805184   636 layer_factory.cpp:58] Creating layer conv11
I1016 21:14:27.805184   636 net.cpp:84] Creating Layer conv11
I1016 21:14:27.805184   636 net.cpp:406] conv11 <- conv4_0
I1016 21:14:27.805184   636 net.cpp:380] conv11 -> conv11
I1016 21:14:27.809185   636 net.cpp:122] Setting up conv11
I1016 21:14:27.809185   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.809185   636 net.cpp:137] Memory required for data: 848513200
I1016 21:14:27.809185   636 layer_factory.cpp:58] Creating layer bn_conv11
I1016 21:14:27.809185   636 net.cpp:84] Creating Layer bn_conv11
I1016 21:14:27.809185   636 net.cpp:406] bn_conv11 <- conv11
I1016 21:14:27.809185   636 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1016 21:14:27.810184   636 net.cpp:122] Setting up bn_conv11
I1016 21:14:27.810184   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.810184   636 net.cpp:137] Memory required for data: 851764400
I1016 21:14:27.810184   636 layer_factory.cpp:58] Creating layer scale_conv11
I1016 21:14:27.810184   636 net.cpp:84] Creating Layer scale_conv11
I1016 21:14:27.810184   636 net.cpp:406] scale_conv11 <- conv11
I1016 21:14:27.810184   636 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1016 21:14:27.810184   636 layer_factory.cpp:58] Creating layer scale_conv11
I1016 21:14:27.810184   636 net.cpp:122] Setting up scale_conv11
I1016 21:14:27.810184   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.810184   636 net.cpp:137] Memory required for data: 855015600
I1016 21:14:27.810184   636 layer_factory.cpp:58] Creating layer relu_conv11
I1016 21:14:27.810184   636 net.cpp:84] Creating Layer relu_conv11
I1016 21:14:27.810184   636 net.cpp:406] relu_conv11 <- conv11
I1016 21:14:27.810184   636 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1016 21:14:27.810184   636 net.cpp:122] Setting up relu_conv11
I1016 21:14:27.810184   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.810184   636 net.cpp:137] Memory required for data: 858266800
I1016 21:14:27.810184   636 layer_factory.cpp:58] Creating layer conv12
I1016 21:14:27.810184   636 net.cpp:84] Creating Layer conv12
I1016 21:14:27.810184   636 net.cpp:406] conv12 <- conv11
I1016 21:14:27.810184   636 net.cpp:380] conv12 -> conv12
I1016 21:14:27.814193   636 net.cpp:122] Setting up conv12
I1016 21:14:27.814193   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.814193   636 net.cpp:137] Memory required for data: 862106800
I1016 21:14:27.814193   636 layer_factory.cpp:58] Creating layer bn_conv12
I1016 21:14:27.814193   636 net.cpp:84] Creating Layer bn_conv12
I1016 21:14:27.814193   636 net.cpp:406] bn_conv12 <- conv12
I1016 21:14:27.814193   636 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1016 21:14:27.814193   636 net.cpp:122] Setting up bn_conv12
I1016 21:14:27.814193   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.814193   636 net.cpp:137] Memory required for data: 865946800
I1016 21:14:27.814193   636 layer_factory.cpp:58] Creating layer scale_conv12
I1016 21:14:27.814193   636 net.cpp:84] Creating Layer scale_conv12
I1016 21:14:27.814193   636 net.cpp:406] scale_conv12 <- conv12
I1016 21:14:27.814193   636 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1016 21:14:27.814193   636 layer_factory.cpp:58] Creating layer scale_conv12
I1016 21:14:27.814193   636 net.cpp:122] Setting up scale_conv12
I1016 21:14:27.814193   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.814193   636 net.cpp:137] Memory required for data: 869786800
I1016 21:14:27.814193   636 layer_factory.cpp:58] Creating layer relu_conv12
I1016 21:14:27.814193   636 net.cpp:84] Creating Layer relu_conv12
I1016 21:14:27.814193   636 net.cpp:406] relu_conv12 <- conv12
I1016 21:14:27.814193   636 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1016 21:14:27.814193   636 net.cpp:122] Setting up relu_conv12
I1016 21:14:27.814193   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.814193   636 net.cpp:137] Memory required for data: 873626800
I1016 21:14:27.814193   636 layer_factory.cpp:58] Creating layer poolcp6
I1016 21:14:27.814193   636 net.cpp:84] Creating Layer poolcp6
I1016 21:14:27.814193   636 net.cpp:406] poolcp6 <- conv12
I1016 21:14:27.814193   636 net.cpp:380] poolcp6 -> poolcp6
I1016 21:14:27.814193   636 net.cpp:122] Setting up poolcp6
I1016 21:14:27.814193   636 net.cpp:129] Top shape: 100 150 1 1 (15000)
I1016 21:14:27.815182   636 net.cpp:137] Memory required for data: 873686800
I1016 21:14:27.815182   636 layer_factory.cpp:58] Creating layer ip1
I1016 21:14:27.815182   636 net.cpp:84] Creating Layer ip1
I1016 21:14:27.815182   636 net.cpp:406] ip1 <- poolcp6
I1016 21:14:27.815182   636 net.cpp:380] ip1 -> ip1
I1016 21:14:27.815182   636 net.cpp:122] Setting up ip1
I1016 21:14:27.815182   636 net.cpp:129] Top shape: 100 10 (1000)
I1016 21:14:27.815182   636 net.cpp:137] Memory required for data: 873690800
I1016 21:14:27.815182   636 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1016 21:14:27.815182   636 net.cpp:84] Creating Layer ip1_ip1_0_split
I1016 21:14:27.815182   636 net.cpp:406] ip1_ip1_0_split <- ip1
I1016 21:14:27.815182   636 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1016 21:14:27.815182   636 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1016 21:14:27.815182   636 net.cpp:122] Setting up ip1_ip1_0_split
I1016 21:14:27.815182   636 net.cpp:129] Top shape: 100 10 (1000)
I1016 21:14:27.815182   636 net.cpp:129] Top shape: 100 10 (1000)
I1016 21:14:27.815182   636 net.cpp:137] Memory required for data: 873698800
I1016 21:14:27.815182   636 layer_factory.cpp:58] Creating layer accuracy_training
I1016 21:14:27.815182   636 net.cpp:84] Creating Layer accuracy_training
I1016 21:14:27.815182   636 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1016 21:14:27.815182   636 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I1016 21:14:27.815182   636 net.cpp:380] accuracy_training -> accuracy_training
I1016 21:14:27.815182   636 net.cpp:122] Setting up accuracy_training
I1016 21:14:27.815182   636 net.cpp:129] Top shape: (1)
I1016 21:14:27.815182   636 net.cpp:137] Memory required for data: 873698804
I1016 21:14:27.815182   636 layer_factory.cpp:58] Creating layer loss
I1016 21:14:27.815182   636 net.cpp:84] Creating Layer loss
I1016 21:14:27.815182   636 net.cpp:406] loss <- ip1_ip1_0_split_1
I1016 21:14:27.815182   636 net.cpp:406] loss <- label_cifar_1_split_1
I1016 21:14:27.815182   636 net.cpp:380] loss -> loss
I1016 21:14:27.815182   636 layer_factory.cpp:58] Creating layer loss
I1016 21:14:27.816184   636 net.cpp:122] Setting up loss
I1016 21:14:27.816184   636 net.cpp:129] Top shape: (1)
I1016 21:14:27.816184   636 net.cpp:132]     with loss weight 1
I1016 21:14:27.816184   636 net.cpp:137] Memory required for data: 873698808
I1016 21:14:27.816184   636 net.cpp:198] loss needs backward computation.
I1016 21:14:27.816184   636 net.cpp:200] accuracy_training does not need backward computation.
I1016 21:14:27.816184   636 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] ip1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] poolcp6 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu_conv12 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale_conv12 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn_conv12 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv12 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu_conv11 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale_conv11 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn_conv11 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv11 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu4_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale4_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn4_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv4_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] pool4_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu4_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale4_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn4_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv4_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu4_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale4_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn4_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv4_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu4 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale4 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn4 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv4 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu3_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale3_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn3_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv3_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu3 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale3 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn3 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv3 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] pool2_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu2_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale2_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn2_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv2_2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu2_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale2_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn2_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv2_1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv2 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu1_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale1_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn1_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv1_0 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] relu1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] scale1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] bn1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:198] conv1 needs backward computation.
I1016 21:14:27.816184   636 net.cpp:200] label_cifar_1_split does not need backward computation.
I1016 21:14:27.816184   636 net.cpp:200] cifar does not need backward computation.
I1016 21:14:27.816184   636 net.cpp:242] This network produces output accuracy_training
I1016 21:14:27.816184   636 net.cpp:242] This network produces output loss
I1016 21:14:27.816184   636 net.cpp:255] Network initialization done.
I1016 21:14:27.817183   636 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1016 21:14:27.817183   636 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1016 21:14:27.817183   636 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1016 21:14:27.817183   636 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1016 21:14:27.817183   636 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_1M"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 60
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 80
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 85
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 90
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 110
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 110
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 127
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 150
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1016 21:14:27.818183   636 layer_factory.cpp:58] Creating layer cifar
I1016 21:14:27.824188   636 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I1016 21:14:27.824188   636 net.cpp:84] Creating Layer cifar
I1016 21:14:27.824188   636 net.cpp:380] cifar -> data
I1016 21:14:27.824188   636 net.cpp:380] cifar -> label
I1016 21:14:27.824188   636 data_layer.cpp:45] output data size: 100,3,32,32
I1016 21:14:27.830199   636 net.cpp:122] Setting up cifar
I1016 21:14:27.830199   636 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1016 21:14:27.830199   636 net.cpp:129] Top shape: 100 (100)
I1016 21:14:27.830199   636 net.cpp:137] Memory required for data: 1229200
I1016 21:14:27.830199   636 layer_factory.cpp:58] Creating layer label_cifar_1_split
I1016 21:14:27.830199   636 net.cpp:84] Creating Layer label_cifar_1_split
I1016 21:14:27.830199   636 net.cpp:406] label_cifar_1_split <- label
I1016 21:14:27.830199   636 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1016 21:14:27.830199   636 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1016 21:14:27.830199   636 net.cpp:122] Setting up label_cifar_1_split
I1016 21:14:27.830199   636 net.cpp:129] Top shape: 100 (100)
I1016 21:14:27.830199   636 net.cpp:129] Top shape: 100 (100)
I1016 21:14:27.830199   636 net.cpp:137] Memory required for data: 1230000
I1016 21:14:27.830199   636 layer_factory.cpp:58] Creating layer conv1
I1016 21:14:27.830199   636 net.cpp:84] Creating Layer conv1
I1016 21:14:27.830199   636 net.cpp:406] conv1 <- data
I1016 21:14:27.830199   636 net.cpp:380] conv1 -> conv1
I1016 21:14:27.831197  8920 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1016 21:14:27.831533   636 net.cpp:122] Setting up conv1
I1016 21:14:27.831533   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.831533   636 net.cpp:137] Memory required for data: 25806000
I1016 21:14:27.831533   636 layer_factory.cpp:58] Creating layer bn1
I1016 21:14:27.831533   636 net.cpp:84] Creating Layer bn1
I1016 21:14:27.831533   636 net.cpp:406] bn1 <- conv1
I1016 21:14:27.831533   636 net.cpp:367] bn1 -> conv1 (in-place)
I1016 21:14:27.831533   636 net.cpp:122] Setting up bn1
I1016 21:14:27.831533   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.831533   636 net.cpp:137] Memory required for data: 50382000
I1016 21:14:27.831533   636 layer_factory.cpp:58] Creating layer scale1
I1016 21:14:27.831533   636 net.cpp:84] Creating Layer scale1
I1016 21:14:27.831533   636 net.cpp:406] scale1 <- conv1
I1016 21:14:27.831533   636 net.cpp:367] scale1 -> conv1 (in-place)
I1016 21:14:27.831533   636 layer_factory.cpp:58] Creating layer scale1
I1016 21:14:27.831533   636 net.cpp:122] Setting up scale1
I1016 21:14:27.832551   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.832551   636 net.cpp:137] Memory required for data: 74958000
I1016 21:14:27.832551   636 layer_factory.cpp:58] Creating layer relu1
I1016 21:14:27.832551   636 net.cpp:84] Creating Layer relu1
I1016 21:14:27.832551   636 net.cpp:406] relu1 <- conv1
I1016 21:14:27.832551   636 net.cpp:367] relu1 -> conv1 (in-place)
I1016 21:14:27.832551   636 net.cpp:122] Setting up relu1
I1016 21:14:27.832551   636 net.cpp:129] Top shape: 100 60 32 32 (6144000)
I1016 21:14:27.832551   636 net.cpp:137] Memory required for data: 99534000
I1016 21:14:27.832551   636 layer_factory.cpp:58] Creating layer conv1_0
I1016 21:14:27.832551   636 net.cpp:84] Creating Layer conv1_0
I1016 21:14:27.832551   636 net.cpp:406] conv1_0 <- conv1
I1016 21:14:27.832551   636 net.cpp:380] conv1_0 -> conv1_0
I1016 21:14:27.833541   636 net.cpp:122] Setting up conv1_0
I1016 21:14:27.833541   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.833541   636 net.cpp:137] Memory required for data: 132302000
I1016 21:14:27.833541   636 layer_factory.cpp:58] Creating layer bn1_0
I1016 21:14:27.833541   636 net.cpp:84] Creating Layer bn1_0
I1016 21:14:27.833541   636 net.cpp:406] bn1_0 <- conv1_0
I1016 21:14:27.833541   636 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1016 21:14:27.834550   636 net.cpp:122] Setting up bn1_0
I1016 21:14:27.834550   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.834550   636 net.cpp:137] Memory required for data: 165070000
I1016 21:14:27.834550   636 layer_factory.cpp:58] Creating layer scale1_0
I1016 21:14:27.834550   636 net.cpp:84] Creating Layer scale1_0
I1016 21:14:27.834550   636 net.cpp:406] scale1_0 <- conv1_0
I1016 21:14:27.834550   636 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1016 21:14:27.834550   636 layer_factory.cpp:58] Creating layer scale1_0
I1016 21:14:27.834550   636 net.cpp:122] Setting up scale1_0
I1016 21:14:27.834550   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.834550   636 net.cpp:137] Memory required for data: 197838000
I1016 21:14:27.834550   636 layer_factory.cpp:58] Creating layer relu1_0
I1016 21:14:27.834550   636 net.cpp:84] Creating Layer relu1_0
I1016 21:14:27.834550   636 net.cpp:406] relu1_0 <- conv1_0
I1016 21:14:27.834550   636 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1016 21:14:27.834550   636 net.cpp:122] Setting up relu1_0
I1016 21:14:27.834550   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.834550   636 net.cpp:137] Memory required for data: 230606000
I1016 21:14:27.834550   636 layer_factory.cpp:58] Creating layer conv2
I1016 21:14:27.834550   636 net.cpp:84] Creating Layer conv2
I1016 21:14:27.834550   636 net.cpp:406] conv2 <- conv1_0
I1016 21:14:27.834550   636 net.cpp:380] conv2 -> conv2
I1016 21:14:27.837543   636 net.cpp:122] Setting up conv2
I1016 21:14:27.837543   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.837543   636 net.cpp:137] Memory required for data: 263374000
I1016 21:14:27.837543   636 layer_factory.cpp:58] Creating layer bn2
I1016 21:14:27.837543   636 net.cpp:84] Creating Layer bn2
I1016 21:14:27.837543   636 net.cpp:406] bn2 <- conv2
I1016 21:14:27.837543   636 net.cpp:367] bn2 -> conv2 (in-place)
I1016 21:14:27.837543   636 net.cpp:122] Setting up bn2
I1016 21:14:27.837543   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.837543   636 net.cpp:137] Memory required for data: 296142000
I1016 21:14:27.837543   636 layer_factory.cpp:58] Creating layer scale2
I1016 21:14:27.837543   636 net.cpp:84] Creating Layer scale2
I1016 21:14:27.837543   636 net.cpp:406] scale2 <- conv2
I1016 21:14:27.837543   636 net.cpp:367] scale2 -> conv2 (in-place)
I1016 21:14:27.837543   636 layer_factory.cpp:58] Creating layer scale2
I1016 21:14:27.838542   636 net.cpp:122] Setting up scale2
I1016 21:14:27.838542   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.838542   636 net.cpp:137] Memory required for data: 328910000
I1016 21:14:27.838542   636 layer_factory.cpp:58] Creating layer relu2
I1016 21:14:27.838542   636 net.cpp:84] Creating Layer relu2
I1016 21:14:27.838542   636 net.cpp:406] relu2 <- conv2
I1016 21:14:27.838542   636 net.cpp:367] relu2 -> conv2 (in-place)
I1016 21:14:27.838542   636 net.cpp:122] Setting up relu2
I1016 21:14:27.838542   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.838542   636 net.cpp:137] Memory required for data: 361678000
I1016 21:14:27.838542   636 layer_factory.cpp:58] Creating layer conv2_1
I1016 21:14:27.838542   636 net.cpp:84] Creating Layer conv2_1
I1016 21:14:27.838542   636 net.cpp:406] conv2_1 <- conv2
I1016 21:14:27.838542   636 net.cpp:380] conv2_1 -> conv2_1
I1016 21:14:27.840543   636 net.cpp:122] Setting up conv2_1
I1016 21:14:27.840543   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.840543   636 net.cpp:137] Memory required for data: 394446000
I1016 21:14:27.840543   636 layer_factory.cpp:58] Creating layer bn2_1
I1016 21:14:27.840543   636 net.cpp:84] Creating Layer bn2_1
I1016 21:14:27.840543   636 net.cpp:406] bn2_1 <- conv2_1
I1016 21:14:27.840543   636 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1016 21:14:27.840543   636 net.cpp:122] Setting up bn2_1
I1016 21:14:27.840543   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.840543   636 net.cpp:137] Memory required for data: 427214000
I1016 21:14:27.840543   636 layer_factory.cpp:58] Creating layer scale2_1
I1016 21:14:27.840543   636 net.cpp:84] Creating Layer scale2_1
I1016 21:14:27.840543   636 net.cpp:406] scale2_1 <- conv2_1
I1016 21:14:27.840543   636 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1016 21:14:27.840543   636 layer_factory.cpp:58] Creating layer scale2_1
I1016 21:14:27.841542   636 net.cpp:122] Setting up scale2_1
I1016 21:14:27.841542   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.841542   636 net.cpp:137] Memory required for data: 459982000
I1016 21:14:27.841542   636 layer_factory.cpp:58] Creating layer relu2_1
I1016 21:14:27.841542   636 net.cpp:84] Creating Layer relu2_1
I1016 21:14:27.841542   636 net.cpp:406] relu2_1 <- conv2_1
I1016 21:14:27.841542   636 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1016 21:14:27.841542   636 net.cpp:122] Setting up relu2_1
I1016 21:14:27.841542   636 net.cpp:129] Top shape: 100 80 32 32 (8192000)
I1016 21:14:27.841542   636 net.cpp:137] Memory required for data: 492750000
I1016 21:14:27.841542   636 layer_factory.cpp:58] Creating layer conv2_2
I1016 21:14:27.841542   636 net.cpp:84] Creating Layer conv2_2
I1016 21:14:27.841542   636 net.cpp:406] conv2_2 <- conv2_1
I1016 21:14:27.841542   636 net.cpp:380] conv2_2 -> conv2_2
I1016 21:14:27.843539   636 net.cpp:122] Setting up conv2_2
I1016 21:14:27.843539   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.843539   636 net.cpp:137] Memory required for data: 527566000
I1016 21:14:27.843539   636 layer_factory.cpp:58] Creating layer bn2_2
I1016 21:14:27.843539   636 net.cpp:84] Creating Layer bn2_2
I1016 21:14:27.843539   636 net.cpp:406] bn2_2 <- conv2_2
I1016 21:14:27.843539   636 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1016 21:14:27.843539   636 net.cpp:122] Setting up bn2_2
I1016 21:14:27.843539   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.843539   636 net.cpp:137] Memory required for data: 562382000
I1016 21:14:27.843539   636 layer_factory.cpp:58] Creating layer scale2_2
I1016 21:14:27.843539   636 net.cpp:84] Creating Layer scale2_2
I1016 21:14:27.843539   636 net.cpp:406] scale2_2 <- conv2_2
I1016 21:14:27.843539   636 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1016 21:14:27.843539   636 layer_factory.cpp:58] Creating layer scale2_2
I1016 21:14:27.844540   636 net.cpp:122] Setting up scale2_2
I1016 21:14:27.844540   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.844540   636 net.cpp:137] Memory required for data: 597198000
I1016 21:14:27.844540   636 layer_factory.cpp:58] Creating layer relu2_2
I1016 21:14:27.844540   636 net.cpp:84] Creating Layer relu2_2
I1016 21:14:27.844540   636 net.cpp:406] relu2_2 <- conv2_2
I1016 21:14:27.844540   636 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1016 21:14:27.844540   636 net.cpp:122] Setting up relu2_2
I1016 21:14:27.844540   636 net.cpp:129] Top shape: 100 85 32 32 (8704000)
I1016 21:14:27.844540   636 net.cpp:137] Memory required for data: 632014000
I1016 21:14:27.844540   636 layer_factory.cpp:58] Creating layer pool2_1
I1016 21:14:27.844540   636 net.cpp:84] Creating Layer pool2_1
I1016 21:14:27.844540   636 net.cpp:406] pool2_1 <- conv2_2
I1016 21:14:27.844540   636 net.cpp:380] pool2_1 -> pool2_1
I1016 21:14:27.844540   636 net.cpp:122] Setting up pool2_1
I1016 21:14:27.844540   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.844540   636 net.cpp:137] Memory required for data: 640718000
I1016 21:14:27.844540   636 layer_factory.cpp:58] Creating layer conv3
I1016 21:14:27.844540   636 net.cpp:84] Creating Layer conv3
I1016 21:14:27.844540   636 net.cpp:406] conv3 <- pool2_1
I1016 21:14:27.844540   636 net.cpp:380] conv3 -> conv3
I1016 21:14:27.847064   636 net.cpp:122] Setting up conv3
I1016 21:14:27.847064   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.847064   636 net.cpp:137] Memory required for data: 649422000
I1016 21:14:27.847064   636 layer_factory.cpp:58] Creating layer bn3
I1016 21:14:27.847064   636 net.cpp:84] Creating Layer bn3
I1016 21:14:27.847064   636 net.cpp:406] bn3 <- conv3
I1016 21:14:27.847064   636 net.cpp:367] bn3 -> conv3 (in-place)
I1016 21:14:27.847064   636 net.cpp:122] Setting up bn3
I1016 21:14:27.847064   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.847064   636 net.cpp:137] Memory required for data: 658126000
I1016 21:14:27.847064   636 layer_factory.cpp:58] Creating layer scale3
I1016 21:14:27.847064   636 net.cpp:84] Creating Layer scale3
I1016 21:14:27.847064   636 net.cpp:406] scale3 <- conv3
I1016 21:14:27.847064   636 net.cpp:367] scale3 -> conv3 (in-place)
I1016 21:14:27.847064   636 layer_factory.cpp:58] Creating layer scale3
I1016 21:14:27.847064   636 net.cpp:122] Setting up scale3
I1016 21:14:27.847064   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.847064   636 net.cpp:137] Memory required for data: 666830000
I1016 21:14:27.847064   636 layer_factory.cpp:58] Creating layer relu3
I1016 21:14:27.847064   636 net.cpp:84] Creating Layer relu3
I1016 21:14:27.847064   636 net.cpp:406] relu3 <- conv3
I1016 21:14:27.847064   636 net.cpp:367] relu3 -> conv3 (in-place)
I1016 21:14:27.847064   636 net.cpp:122] Setting up relu3
I1016 21:14:27.847064   636 net.cpp:129] Top shape: 100 85 16 16 (2176000)
I1016 21:14:27.847064   636 net.cpp:137] Memory required for data: 675534000
I1016 21:14:27.847064   636 layer_factory.cpp:58] Creating layer conv3_1
I1016 21:14:27.847064   636 net.cpp:84] Creating Layer conv3_1
I1016 21:14:27.847064   636 net.cpp:406] conv3_1 <- conv3
I1016 21:14:27.848070   636 net.cpp:380] conv3_1 -> conv3_1
I1016 21:14:27.849071   636 net.cpp:122] Setting up conv3_1
I1016 21:14:27.849071   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.849071   636 net.cpp:137] Memory required for data: 684750000
I1016 21:14:27.849071   636 layer_factory.cpp:58] Creating layer bn3_1
I1016 21:14:27.849071   636 net.cpp:84] Creating Layer bn3_1
I1016 21:14:27.849071   636 net.cpp:406] bn3_1 <- conv3_1
I1016 21:14:27.849071   636 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1016 21:14:27.849071   636 net.cpp:122] Setting up bn3_1
I1016 21:14:27.849071   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.849071   636 net.cpp:137] Memory required for data: 693966000
I1016 21:14:27.849071   636 layer_factory.cpp:58] Creating layer scale3_1
I1016 21:14:27.849071   636 net.cpp:84] Creating Layer scale3_1
I1016 21:14:27.849071   636 net.cpp:406] scale3_1 <- conv3_1
I1016 21:14:27.849071   636 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1016 21:14:27.849071   636 layer_factory.cpp:58] Creating layer scale3_1
I1016 21:14:27.850070   636 net.cpp:122] Setting up scale3_1
I1016 21:14:27.850070   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.850070   636 net.cpp:137] Memory required for data: 703182000
I1016 21:14:27.850070   636 layer_factory.cpp:58] Creating layer relu3_1
I1016 21:14:27.850070   636 net.cpp:84] Creating Layer relu3_1
I1016 21:14:27.850070   636 net.cpp:406] relu3_1 <- conv3_1
I1016 21:14:27.850070   636 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1016 21:14:27.850070   636 net.cpp:122] Setting up relu3_1
I1016 21:14:27.850070   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.850070   636 net.cpp:137] Memory required for data: 712398000
I1016 21:14:27.850070   636 layer_factory.cpp:58] Creating layer conv4
I1016 21:14:27.850070   636 net.cpp:84] Creating Layer conv4
I1016 21:14:27.850070   636 net.cpp:406] conv4 <- conv3_1
I1016 21:14:27.850070   636 net.cpp:380] conv4 -> conv4
I1016 21:14:27.852072   636 net.cpp:122] Setting up conv4
I1016 21:14:27.852072   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.852072   636 net.cpp:137] Memory required for data: 721614000
I1016 21:14:27.852072   636 layer_factory.cpp:58] Creating layer bn4
I1016 21:14:27.852072   636 net.cpp:84] Creating Layer bn4
I1016 21:14:27.852072   636 net.cpp:406] bn4 <- conv4
I1016 21:14:27.852072   636 net.cpp:367] bn4 -> conv4 (in-place)
I1016 21:14:27.852072   636 net.cpp:122] Setting up bn4
I1016 21:14:27.852072   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.852072   636 net.cpp:137] Memory required for data: 730830000
I1016 21:14:27.852072   636 layer_factory.cpp:58] Creating layer scale4
I1016 21:14:27.852072   636 net.cpp:84] Creating Layer scale4
I1016 21:14:27.852072   636 net.cpp:406] scale4 <- conv4
I1016 21:14:27.852072   636 net.cpp:367] scale4 -> conv4 (in-place)
I1016 21:14:27.852072   636 layer_factory.cpp:58] Creating layer scale4
I1016 21:14:27.852072   636 net.cpp:122] Setting up scale4
I1016 21:14:27.852072   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.852072   636 net.cpp:137] Memory required for data: 740046000
I1016 21:14:27.852072   636 layer_factory.cpp:58] Creating layer relu4
I1016 21:14:27.852072   636 net.cpp:84] Creating Layer relu4
I1016 21:14:27.852072   636 net.cpp:406] relu4 <- conv4
I1016 21:14:27.852072   636 net.cpp:367] relu4 -> conv4 (in-place)
I1016 21:14:27.852072   636 net.cpp:122] Setting up relu4
I1016 21:14:27.853070   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.853070   636 net.cpp:137] Memory required for data: 749262000
I1016 21:14:27.853070   636 layer_factory.cpp:58] Creating layer conv4_1
I1016 21:14:27.853070   636 net.cpp:84] Creating Layer conv4_1
I1016 21:14:27.853070   636 net.cpp:406] conv4_1 <- conv4
I1016 21:14:27.853070   636 net.cpp:380] conv4_1 -> conv4_1
I1016 21:14:27.854073   636 net.cpp:122] Setting up conv4_1
I1016 21:14:27.854073   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.854073   636 net.cpp:137] Memory required for data: 758478000
I1016 21:14:27.854073   636 layer_factory.cpp:58] Creating layer bn4_1
I1016 21:14:27.854073   636 net.cpp:84] Creating Layer bn4_1
I1016 21:14:27.854073   636 net.cpp:406] bn4_1 <- conv4_1
I1016 21:14:27.854073   636 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1016 21:14:27.855072   636 net.cpp:122] Setting up bn4_1
I1016 21:14:27.855072   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.855072   636 net.cpp:137] Memory required for data: 767694000
I1016 21:14:27.855072   636 layer_factory.cpp:58] Creating layer scale4_1
I1016 21:14:27.855072   636 net.cpp:84] Creating Layer scale4_1
I1016 21:14:27.855072   636 net.cpp:406] scale4_1 <- conv4_1
I1016 21:14:27.855072   636 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1016 21:14:27.855072   636 layer_factory.cpp:58] Creating layer scale4_1
I1016 21:14:27.855072   636 net.cpp:122] Setting up scale4_1
I1016 21:14:27.855072   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.855072   636 net.cpp:137] Memory required for data: 776910000
I1016 21:14:27.855072   636 layer_factory.cpp:58] Creating layer relu4_1
I1016 21:14:27.855072   636 net.cpp:84] Creating Layer relu4_1
I1016 21:14:27.855072   636 net.cpp:406] relu4_1 <- conv4_1
I1016 21:14:27.855072   636 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1016 21:14:27.855072   636 net.cpp:122] Setting up relu4_1
I1016 21:14:27.855072   636 net.cpp:129] Top shape: 100 90 16 16 (2304000)
I1016 21:14:27.855072   636 net.cpp:137] Memory required for data: 786126000
I1016 21:14:27.855072   636 layer_factory.cpp:58] Creating layer conv4_2
I1016 21:14:27.855072   636 net.cpp:84] Creating Layer conv4_2
I1016 21:14:27.855072   636 net.cpp:406] conv4_2 <- conv4_1
I1016 21:14:27.855072   636 net.cpp:380] conv4_2 -> conv4_2
I1016 21:14:27.857071   636 net.cpp:122] Setting up conv4_2
I1016 21:14:27.857071   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.857071   636 net.cpp:137] Memory required for data: 797390000
I1016 21:14:27.857071   636 layer_factory.cpp:58] Creating layer bn4_2
I1016 21:14:27.857071   636 net.cpp:84] Creating Layer bn4_2
I1016 21:14:27.857071   636 net.cpp:406] bn4_2 <- conv4_2
I1016 21:14:27.857071   636 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1016 21:14:27.857071   636 net.cpp:122] Setting up bn4_2
I1016 21:14:27.857071   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.857071   636 net.cpp:137] Memory required for data: 808654000
I1016 21:14:27.857071   636 layer_factory.cpp:58] Creating layer scale4_2
I1016 21:14:27.858072   636 net.cpp:84] Creating Layer scale4_2
I1016 21:14:27.858072   636 net.cpp:406] scale4_2 <- conv4_2
I1016 21:14:27.858072   636 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1016 21:14:27.858072   636 layer_factory.cpp:58] Creating layer scale4_2
I1016 21:14:27.858072   636 net.cpp:122] Setting up scale4_2
I1016 21:14:27.858072   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.858072   636 net.cpp:137] Memory required for data: 819918000
I1016 21:14:27.858072   636 layer_factory.cpp:58] Creating layer relu4_2
I1016 21:14:27.858072   636 net.cpp:84] Creating Layer relu4_2
I1016 21:14:27.858072   636 net.cpp:406] relu4_2 <- conv4_2
I1016 21:14:27.858072   636 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1016 21:14:27.858072   636 net.cpp:122] Setting up relu4_2
I1016 21:14:27.858072   636 net.cpp:129] Top shape: 100 110 16 16 (2816000)
I1016 21:14:27.858072   636 net.cpp:137] Memory required for data: 831182000
I1016 21:14:27.858072   636 layer_factory.cpp:58] Creating layer pool4_2
I1016 21:14:27.858072   636 net.cpp:84] Creating Layer pool4_2
I1016 21:14:27.858072   636 net.cpp:406] pool4_2 <- conv4_2
I1016 21:14:27.858072   636 net.cpp:380] pool4_2 -> pool4_2
I1016 21:14:27.858072   636 net.cpp:122] Setting up pool4_2
I1016 21:14:27.858072   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.858072   636 net.cpp:137] Memory required for data: 833998000
I1016 21:14:27.858072   636 layer_factory.cpp:58] Creating layer conv4_0
I1016 21:14:27.858072   636 net.cpp:84] Creating Layer conv4_0
I1016 21:14:27.858072   636 net.cpp:406] conv4_0 <- pool4_2
I1016 21:14:27.858072   636 net.cpp:380] conv4_0 -> conv4_0
I1016 21:14:27.860676   636 net.cpp:122] Setting up conv4_0
I1016 21:14:27.860676   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.860676   636 net.cpp:137] Memory required for data: 836814000
I1016 21:14:27.860676   636 layer_factory.cpp:58] Creating layer bn4_0
I1016 21:14:27.860676   636 net.cpp:84] Creating Layer bn4_0
I1016 21:14:27.860676   636 net.cpp:406] bn4_0 <- conv4_0
I1016 21:14:27.860676   636 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1016 21:14:27.860676   636 net.cpp:122] Setting up bn4_0
I1016 21:14:27.860676   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.860676   636 net.cpp:137] Memory required for data: 839630000
I1016 21:14:27.860676   636 layer_factory.cpp:58] Creating layer scale4_0
I1016 21:14:27.860676   636 net.cpp:84] Creating Layer scale4_0
I1016 21:14:27.860676   636 net.cpp:406] scale4_0 <- conv4_0
I1016 21:14:27.860676   636 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1016 21:14:27.860676   636 layer_factory.cpp:58] Creating layer scale4_0
I1016 21:14:27.860676   636 net.cpp:122] Setting up scale4_0
I1016 21:14:27.860676   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.860676   636 net.cpp:137] Memory required for data: 842446000
I1016 21:14:27.860676   636 layer_factory.cpp:58] Creating layer relu4_0
I1016 21:14:27.860676   636 net.cpp:84] Creating Layer relu4_0
I1016 21:14:27.860676   636 net.cpp:406] relu4_0 <- conv4_0
I1016 21:14:27.860676   636 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1016 21:14:27.860676   636 net.cpp:122] Setting up relu4_0
I1016 21:14:27.860676   636 net.cpp:129] Top shape: 100 110 8 8 (704000)
I1016 21:14:27.860676   636 net.cpp:137] Memory required for data: 845262000
I1016 21:14:27.860676   636 layer_factory.cpp:58] Creating layer conv11
I1016 21:14:27.860676   636 net.cpp:84] Creating Layer conv11
I1016 21:14:27.860676   636 net.cpp:406] conv11 <- conv4_0
I1016 21:14:27.860676   636 net.cpp:380] conv11 -> conv11
I1016 21:14:27.862681   636 net.cpp:122] Setting up conv11
I1016 21:14:27.862681   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.862681   636 net.cpp:137] Memory required for data: 848513200
I1016 21:14:27.862681   636 layer_factory.cpp:58] Creating layer bn_conv11
I1016 21:14:27.862681   636 net.cpp:84] Creating Layer bn_conv11
I1016 21:14:27.862681   636 net.cpp:406] bn_conv11 <- conv11
I1016 21:14:27.862681   636 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1016 21:14:27.862681   636 net.cpp:122] Setting up bn_conv11
I1016 21:14:27.862681   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.862681   636 net.cpp:137] Memory required for data: 851764400
I1016 21:14:27.862681   636 layer_factory.cpp:58] Creating layer scale_conv11
I1016 21:14:27.862681   636 net.cpp:84] Creating Layer scale_conv11
I1016 21:14:27.862681   636 net.cpp:406] scale_conv11 <- conv11
I1016 21:14:27.862681   636 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1016 21:14:27.862681   636 layer_factory.cpp:58] Creating layer scale_conv11
I1016 21:14:27.863682   636 net.cpp:122] Setting up scale_conv11
I1016 21:14:27.863682   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.863682   636 net.cpp:137] Memory required for data: 855015600
I1016 21:14:27.863682   636 layer_factory.cpp:58] Creating layer relu_conv11
I1016 21:14:27.863682   636 net.cpp:84] Creating Layer relu_conv11
I1016 21:14:27.863682   636 net.cpp:406] relu_conv11 <- conv11
I1016 21:14:27.863682   636 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1016 21:14:27.863682   636 net.cpp:122] Setting up relu_conv11
I1016 21:14:27.863682   636 net.cpp:129] Top shape: 100 127 8 8 (812800)
I1016 21:14:27.863682   636 net.cpp:137] Memory required for data: 858266800
I1016 21:14:27.863682   636 layer_factory.cpp:58] Creating layer conv12
I1016 21:14:27.863682   636 net.cpp:84] Creating Layer conv12
I1016 21:14:27.863682   636 net.cpp:406] conv12 <- conv11
I1016 21:14:27.863682   636 net.cpp:380] conv12 -> conv12
I1016 21:14:27.865681   636 net.cpp:122] Setting up conv12
I1016 21:14:27.865681   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.865681   636 net.cpp:137] Memory required for data: 862106800
I1016 21:14:27.865681   636 layer_factory.cpp:58] Creating layer bn_conv12
I1016 21:14:27.865681   636 net.cpp:84] Creating Layer bn_conv12
I1016 21:14:27.865681   636 net.cpp:406] bn_conv12 <- conv12
I1016 21:14:27.865681   636 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1016 21:14:27.866681   636 net.cpp:122] Setting up bn_conv12
I1016 21:14:27.866681   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.866681   636 net.cpp:137] Memory required for data: 865946800
I1016 21:14:27.866681   636 layer_factory.cpp:58] Creating layer scale_conv12
I1016 21:14:27.866681   636 net.cpp:84] Creating Layer scale_conv12
I1016 21:14:27.866681   636 net.cpp:406] scale_conv12 <- conv12
I1016 21:14:27.866681   636 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1016 21:14:27.866681   636 layer_factory.cpp:58] Creating layer scale_conv12
I1016 21:14:27.866681   636 net.cpp:122] Setting up scale_conv12
I1016 21:14:27.866681   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.866681   636 net.cpp:137] Memory required for data: 869786800
I1016 21:14:27.866681   636 layer_factory.cpp:58] Creating layer relu_conv12
I1016 21:14:27.866681   636 net.cpp:84] Creating Layer relu_conv12
I1016 21:14:27.866681   636 net.cpp:406] relu_conv12 <- conv12
I1016 21:14:27.866681   636 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1016 21:14:27.866681   636 net.cpp:122] Setting up relu_conv12
I1016 21:14:27.866681   636 net.cpp:129] Top shape: 100 150 8 8 (960000)
I1016 21:14:27.866681   636 net.cpp:137] Memory required for data: 873626800
I1016 21:14:27.866681   636 layer_factory.cpp:58] Creating layer poolcp6
I1016 21:14:27.866681   636 net.cpp:84] Creating Layer poolcp6
I1016 21:14:27.866681   636 net.cpp:406] poolcp6 <- conv12
I1016 21:14:27.866681   636 net.cpp:380] poolcp6 -> poolcp6
I1016 21:14:27.866681   636 net.cpp:122] Setting up poolcp6
I1016 21:14:27.866681   636 net.cpp:129] Top shape: 100 150 1 1 (15000)
I1016 21:14:27.866681   636 net.cpp:137] Memory required for data: 873686800
I1016 21:14:27.866681   636 layer_factory.cpp:58] Creating layer ip1
I1016 21:14:27.866681   636 net.cpp:84] Creating Layer ip1
I1016 21:14:27.866681   636 net.cpp:406] ip1 <- poolcp6
I1016 21:14:27.866681   636 net.cpp:380] ip1 -> ip1
I1016 21:14:27.866681   636 net.cpp:122] Setting up ip1
I1016 21:14:27.866681   636 net.cpp:129] Top shape: 100 10 (1000)
I1016 21:14:27.866681   636 net.cpp:137] Memory required for data: 873690800
I1016 21:14:27.866681   636 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1016 21:14:27.866681   636 net.cpp:84] Creating Layer ip1_ip1_0_split
I1016 21:14:27.866681   636 net.cpp:406] ip1_ip1_0_split <- ip1
I1016 21:14:27.867682   636 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1016 21:14:27.867682   636 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1016 21:14:27.867682   636 net.cpp:122] Setting up ip1_ip1_0_split
I1016 21:14:27.867682   636 net.cpp:129] Top shape: 100 10 (1000)
I1016 21:14:27.867682   636 net.cpp:129] Top shape: 100 10 (1000)
I1016 21:14:27.867682   636 net.cpp:137] Memory required for data: 873698800
I1016 21:14:27.867682   636 layer_factory.cpp:58] Creating layer accuracy
I1016 21:14:27.867682   636 net.cpp:84] Creating Layer accuracy
I1016 21:14:27.867682   636 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1016 21:14:27.867682   636 net.cpp:406] accuracy <- label_cifar_1_split_0
I1016 21:14:27.867682   636 net.cpp:380] accuracy -> accuracy
I1016 21:14:27.867682   636 net.cpp:122] Setting up accuracy
I1016 21:14:27.867682   636 net.cpp:129] Top shape: (1)
I1016 21:14:27.867682   636 net.cpp:137] Memory required for data: 873698804
I1016 21:14:27.867682   636 layer_factory.cpp:58] Creating layer loss
I1016 21:14:27.867682   636 net.cpp:84] Creating Layer loss
I1016 21:14:27.867682   636 net.cpp:406] loss <- ip1_ip1_0_split_1
I1016 21:14:27.867682   636 net.cpp:406] loss <- label_cifar_1_split_1
I1016 21:14:27.867682   636 net.cpp:380] loss -> loss
I1016 21:14:27.867682   636 layer_factory.cpp:58] Creating layer loss
I1016 21:14:27.867682   636 net.cpp:122] Setting up loss
I1016 21:14:27.867682   636 net.cpp:129] Top shape: (1)
I1016 21:14:27.867682   636 net.cpp:132]     with loss weight 1
I1016 21:14:27.867682   636 net.cpp:137] Memory required for data: 873698808
I1016 21:14:27.867682   636 net.cpp:198] loss needs backward computation.
I1016 21:14:27.867682   636 net.cpp:200] accuracy does not need backward computation.
I1016 21:14:27.867682   636 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] ip1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] poolcp6 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu_conv12 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale_conv12 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn_conv12 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv12 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu_conv11 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale_conv11 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn_conv11 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv11 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu4_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale4_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn4_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv4_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] pool4_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu4_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale4_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn4_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv4_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu4_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale4_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn4_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv4_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu4 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale4 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn4 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv4 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu3_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale3_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn3_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv3_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu3 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale3 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn3 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv3 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] pool2_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu2_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale2_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn2_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv2_2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu2_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale2_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn2_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv2_1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv2 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu1_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale1_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn1_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv1_0 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] relu1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] scale1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] bn1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:198] conv1 needs backward computation.
I1016 21:14:27.867682   636 net.cpp:200] label_cifar_1_split does not need backward computation.
I1016 21:14:27.867682   636 net.cpp:200] cifar does not need backward computation.
I1016 21:14:27.867682   636 net.cpp:242] This network produces output accuracy
I1016 21:14:27.867682   636 net.cpp:242] This network produces output loss
I1016 21:14:27.867682   636 net.cpp:255] Network initialization done.
I1016 21:14:27.868682   636 solver.cpp:56] Solver scaffolding done.
I1016 21:14:27.872681   636 caffe.cpp:243] Resuming from examples/cifar10/snaps/slimnet_1M__iter_90000.solverstate
I1016 21:14:28.085469   636 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/snaps/slimnet_1M__iter_90000.caffemodel
I1016 21:14:28.085957   636 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1016 21:14:28.086957   636 sgd_solver.cpp:318] SGDSolver: restoring history
I1016 21:14:28.093699   636 caffe.cpp:249] Starting Optimization
I1016 21:14:28.093699   636 solver.cpp:272] Solving CIFAR10_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_1M
I1016 21:14:28.093699   636 solver.cpp:273] Learning Rate Policy: multistep
I1016 21:14:28.096166   636 solver.cpp:330] Iteration 90000, Testing net (#0)
I1016 21:14:28.097159   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:14:30.435479  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:14:30.526012   636 solver.cpp:397]     Test net output #0: accuracy = 0.8891
I1016 21:14:30.526012   636 solver.cpp:397]     Test net output #1: loss = 0.385523 (* 1 = 0.385523 loss)
I1016 21:14:30.679175   636 solver.cpp:218] Iteration 90000 (34826.1 iter/s, 2.58427s/100 iters), loss = 0.0324538
I1016 21:14:30.679666   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:14:30.679666   636 solver.cpp:237]     Train net output #1: loss = 0.0324538 (* 1 = 0.0324538 loss)
I1016 21:14:30.679666   636 sgd_solver.cpp:105] Iteration 90000, lr = 0.01
I1016 21:14:39.887557   636 solver.cpp:218] Iteration 90100 (10.8605 iter/s, 9.20764s/100 iters), loss = 0.0664719
I1016 21:14:39.887557   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1016 21:14:39.887557   636 solver.cpp:237]     Train net output #1: loss = 0.0664719 (* 1 = 0.0664719 loss)
I1016 21:14:39.887557   636 sgd_solver.cpp:105] Iteration 90100, lr = 0.01
I1016 21:14:49.099702   636 solver.cpp:218] Iteration 90200 (10.8478 iter/s, 9.21848s/100 iters), loss = 0.0350402
I1016 21:14:49.099702   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:14:49.099702   636 solver.cpp:237]     Train net output #1: loss = 0.0350402 (* 1 = 0.0350402 loss)
I1016 21:14:49.099702   636 sgd_solver.cpp:105] Iteration 90200, lr = 0.01
I1016 21:14:58.260782   636 solver.cpp:218] Iteration 90300 (10.9241 iter/s, 9.15404s/100 iters), loss = 0.0149547
I1016 21:14:58.261282   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:14:58.261282   636 solver.cpp:237]     Train net output #1: loss = 0.0149547 (* 1 = 0.0149547 loss)
I1016 21:14:58.261282   636 sgd_solver.cpp:105] Iteration 90300, lr = 0.01
I1016 21:15:07.413978   636 solver.cpp:218] Iteration 90400 (10.9261 iter/s, 9.15237s/100 iters), loss = 0.0370018
I1016 21:15:07.413978   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:15:07.413978   636 solver.cpp:237]     Train net output #1: loss = 0.0370018 (* 1 = 0.0370018 loss)
I1016 21:15:07.413978   636 sgd_solver.cpp:105] Iteration 90400, lr = 0.01
I1016 21:15:16.095001  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:15:16.452487   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_90500.caffemodel
I1016 21:15:16.468124   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_90500.solverstate
I1016 21:15:16.483748   636 solver.cpp:330] Iteration 90500, Testing net (#0)
I1016 21:15:16.483748   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:15:18.747838  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:15:18.844225   636 solver.cpp:397]     Test net output #0: accuracy = 0.8892
I1016 21:15:18.844225   636 solver.cpp:397]     Test net output #1: loss = 0.403965 (* 1 = 0.403965 loss)
I1016 21:15:18.932763   636 solver.cpp:218] Iteration 90500 (8.68158 iter/s, 11.5186s/100 iters), loss = 0.0812037
I1016 21:15:18.932763   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:15:18.932763   636 solver.cpp:237]     Train net output #1: loss = 0.0812037 (* 1 = 0.0812037 loss)
I1016 21:15:18.932763   636 sgd_solver.cpp:105] Iteration 90500, lr = 0.01
I1016 21:15:28.026715   636 solver.cpp:218] Iteration 90600 (10.9848 iter/s, 9.10348s/100 iters), loss = 0.019676
I1016 21:15:28.026715   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:15:28.026715   636 solver.cpp:237]     Train net output #1: loss = 0.019676 (* 1 = 0.019676 loss)
I1016 21:15:28.026715   636 sgd_solver.cpp:105] Iteration 90600, lr = 0.01
I1016 21:15:37.163200   636 solver.cpp:218] Iteration 90700 (10.9575 iter/s, 9.12621s/100 iters), loss = 0.0304261
I1016 21:15:37.163200   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:15:37.163200   636 solver.cpp:237]     Train net output #1: loss = 0.0304261 (* 1 = 0.0304261 loss)
I1016 21:15:37.163200   636 sgd_solver.cpp:105] Iteration 90700, lr = 0.01
I1016 21:15:46.272538   636 solver.cpp:218] Iteration 90800 (10.971 iter/s, 9.11491s/100 iters), loss = 0.0453295
I1016 21:15:46.272538   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:15:46.272538   636 solver.cpp:237]     Train net output #1: loss = 0.0453295 (* 1 = 0.0453295 loss)
I1016 21:15:46.272538   636 sgd_solver.cpp:105] Iteration 90800, lr = 0.01
I1016 21:15:55.415964   636 solver.cpp:218] Iteration 90900 (10.9302 iter/s, 9.14896s/100 iters), loss = 0.0295124
I1016 21:15:55.415964   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:15:55.415964   636 solver.cpp:237]     Train net output #1: loss = 0.0295124 (* 1 = 0.0295124 loss)
I1016 21:15:55.415964   636 sgd_solver.cpp:105] Iteration 90900, lr = 0.01
I1016 21:16:04.097559  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:16:04.466645   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_91000.caffemodel
I1016 21:16:04.482280   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_91000.solverstate
I1016 21:16:04.497906   636 solver.cpp:330] Iteration 91000, Testing net (#0)
I1016 21:16:04.497906   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:16:06.769943  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:16:06.862249   636 solver.cpp:397]     Test net output #0: accuracy = 0.8876
I1016 21:16:06.862249   636 solver.cpp:397]     Test net output #1: loss = 0.398739 (* 1 = 0.398739 loss)
I1016 21:16:06.948375   636 solver.cpp:218] Iteration 91000 (8.67934 iter/s, 11.5216s/100 iters), loss = 0.0484896
I1016 21:16:06.948375   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:16:06.948375   636 solver.cpp:237]     Train net output #1: loss = 0.0484896 (* 1 = 0.0484896 loss)
I1016 21:16:06.948375   636 sgd_solver.cpp:105] Iteration 91000, lr = 0.01
I1016 21:16:16.087093   636 solver.cpp:218] Iteration 91100 (10.9463 iter/s, 9.13553s/100 iters), loss = 0.113265
I1016 21:16:16.087093   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1016 21:16:16.087093   636 solver.cpp:237]     Train net output #1: loss = 0.113265 (* 1 = 0.113265 loss)
I1016 21:16:16.087093   636 sgd_solver.cpp:105] Iteration 91100, lr = 0.01
I1016 21:16:25.264145   636 solver.cpp:218] Iteration 91200 (10.8918 iter/s, 9.18118s/100 iters), loss = 0.0487509
I1016 21:16:25.264145   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:16:25.264145   636 solver.cpp:237]     Train net output #1: loss = 0.0487509 (* 1 = 0.0487509 loss)
I1016 21:16:25.264145   636 sgd_solver.cpp:105] Iteration 91200, lr = 0.01
I1016 21:16:34.455842   636 solver.cpp:218] Iteration 91300 (10.8854 iter/s, 9.18662s/100 iters), loss = 0.0502995
I1016 21:16:34.455842   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:16:34.455842   636 solver.cpp:237]     Train net output #1: loss = 0.0502995 (* 1 = 0.0502995 loss)
I1016 21:16:34.455842   636 sgd_solver.cpp:105] Iteration 91300, lr = 0.01
I1016 21:16:43.711532   636 solver.cpp:218] Iteration 91400 (10.8039 iter/s, 9.25589s/100 iters), loss = 0.0438894
I1016 21:16:43.712533   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:16:43.712533   636 solver.cpp:237]     Train net output #1: loss = 0.0438894 (* 1 = 0.0438894 loss)
I1016 21:16:43.712533   636 sgd_solver.cpp:105] Iteration 91400, lr = 0.01
I1016 21:16:52.440378  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:16:52.801414   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_91500.caffemodel
I1016 21:16:52.827414   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_91500.solverstate
I1016 21:16:52.839414   636 solver.cpp:330] Iteration 91500, Testing net (#0)
I1016 21:16:52.839414   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:16:55.110631  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:16:55.201637   636 solver.cpp:397]     Test net output #0: accuracy = 0.8779
I1016 21:16:55.201637   636 solver.cpp:397]     Test net output #1: loss = 0.434269 (* 1 = 0.434269 loss)
I1016 21:16:55.290639   636 solver.cpp:218] Iteration 91500 (8.63711 iter/s, 11.5779s/100 iters), loss = 0.0335282
I1016 21:16:55.290639   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:16:55.290639   636 solver.cpp:237]     Train net output #1: loss = 0.0335282 (* 1 = 0.0335282 loss)
I1016 21:16:55.290639   636 sgd_solver.cpp:105] Iteration 91500, lr = 0.01
I1016 21:17:04.450598   636 solver.cpp:218] Iteration 91600 (10.9172 iter/s, 9.15986s/100 iters), loss = 0.0397477
I1016 21:17:04.450598   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:17:04.450598   636 solver.cpp:237]     Train net output #1: loss = 0.0397477 (* 1 = 0.0397477 loss)
I1016 21:17:04.450598   636 sgd_solver.cpp:105] Iteration 91600, lr = 0.01
I1016 21:17:13.647763   636 solver.cpp:218] Iteration 91700 (10.8735 iter/s, 9.19666s/100 iters), loss = 0.0438328
I1016 21:17:13.648762   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:17:13.648762   636 solver.cpp:237]     Train net output #1: loss = 0.0438328 (* 1 = 0.0438328 loss)
I1016 21:17:13.648762   636 sgd_solver.cpp:105] Iteration 91700, lr = 0.01
I1016 21:17:22.797346   636 solver.cpp:218] Iteration 91800 (10.931 iter/s, 9.14826s/100 iters), loss = 0.0434715
I1016 21:17:22.797346   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:17:22.797346   636 solver.cpp:237]     Train net output #1: loss = 0.0434714 (* 1 = 0.0434714 loss)
I1016 21:17:22.797346   636 sgd_solver.cpp:105] Iteration 91800, lr = 0.01
I1016 21:17:31.937000   636 solver.cpp:218] Iteration 91900 (10.9411 iter/s, 9.13981s/100 iters), loss = 0.069789
I1016 21:17:31.937000   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:17:31.937000   636 solver.cpp:237]     Train net output #1: loss = 0.069789 (* 1 = 0.069789 loss)
I1016 21:17:31.937000   636 sgd_solver.cpp:105] Iteration 91900, lr = 0.01
I1016 21:17:40.630522  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:17:40.991536   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_92000.caffemodel
I1016 21:17:41.017542   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_92000.solverstate
I1016 21:17:41.029546   636 solver.cpp:330] Iteration 92000, Testing net (#0)
I1016 21:17:41.029546   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:17:43.295711  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:17:43.386714   636 solver.cpp:397]     Test net output #0: accuracy = 0.9144
I1016 21:17:43.386714   636 solver.cpp:397]     Test net output #1: loss = 0.297818 (* 1 = 0.297818 loss)
I1016 21:17:43.475718   636 solver.cpp:218] Iteration 92000 (8.667 iter/s, 11.538s/100 iters), loss = 0.020577
I1016 21:17:43.475718   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:17:43.475718   636 solver.cpp:237]     Train net output #1: loss = 0.020577 (* 1 = 0.020577 loss)
I1016 21:17:43.475718   636 sgd_solver.cpp:105] Iteration 92000, lr = 0.01
I1016 21:17:52.616540   636 solver.cpp:218] Iteration 92100 (10.9411 iter/s, 9.13982s/100 iters), loss = 0.0338731
I1016 21:17:52.616540   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:17:52.616540   636 solver.cpp:237]     Train net output #1: loss = 0.033873 (* 1 = 0.033873 loss)
I1016 21:17:52.616540   636 sgd_solver.cpp:105] Iteration 92100, lr = 0.01
I1016 21:18:01.739979   636 solver.cpp:218] Iteration 92200 (10.9614 iter/s, 9.12291s/100 iters), loss = 0.0383188
I1016 21:18:01.739979   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:18:01.739979   636 solver.cpp:237]     Train net output #1: loss = 0.0383187 (* 1 = 0.0383187 loss)
I1016 21:18:01.739979   636 sgd_solver.cpp:105] Iteration 92200, lr = 0.01
I1016 21:18:10.861449   636 solver.cpp:218] Iteration 92300 (10.9585 iter/s, 9.12536s/100 iters), loss = 0.0435494
I1016 21:18:10.861449   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:18:10.861449   636 solver.cpp:237]     Train net output #1: loss = 0.0435493 (* 1 = 0.0435493 loss)
I1016 21:18:10.861449   636 sgd_solver.cpp:105] Iteration 92300, lr = 0.01
I1016 21:18:19.978147   636 solver.cpp:218] Iteration 92400 (10.9639 iter/s, 9.12086s/100 iters), loss = 0.0618002
I1016 21:18:19.978147   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:18:19.978147   636 solver.cpp:237]     Train net output #1: loss = 0.0618001 (* 1 = 0.0618001 loss)
I1016 21:18:19.978147   636 sgd_solver.cpp:105] Iteration 92400, lr = 0.01
I1016 21:18:28.641477  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:18:28.995375   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_92500.caffemodel
I1016 21:18:29.026633   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_92500.solverstate
I1016 21:18:29.042258   636 solver.cpp:330] Iteration 92500, Testing net (#0)
I1016 21:18:29.042258   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:18:31.300796  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:18:31.401015   636 solver.cpp:397]     Test net output #0: accuracy = 0.8925
I1016 21:18:31.401015   636 solver.cpp:397]     Test net output #1: loss = 0.395869 (* 1 = 0.395869 loss)
I1016 21:18:31.479143   636 solver.cpp:218] Iteration 92500 (8.69364 iter/s, 11.5027s/100 iters), loss = 0.0900832
I1016 21:18:31.479143   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:18:31.479143   636 solver.cpp:237]     Train net output #1: loss = 0.0900831 (* 1 = 0.0900831 loss)
I1016 21:18:31.479143   636 sgd_solver.cpp:105] Iteration 92500, lr = 0.01
I1016 21:18:40.598192   636 solver.cpp:218] Iteration 92600 (10.9746 iter/s, 9.11193s/100 iters), loss = 0.0954477
I1016 21:18:40.598192   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I1016 21:18:40.598192   636 solver.cpp:237]     Train net output #1: loss = 0.0954476 (* 1 = 0.0954476 loss)
I1016 21:18:40.598192   636 sgd_solver.cpp:105] Iteration 92600, lr = 0.01
I1016 21:18:49.710943   636 solver.cpp:218] Iteration 92700 (10.9685 iter/s, 9.11704s/100 iters), loss = 0.0559654
I1016 21:18:49.710943   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:18:49.710943   636 solver.cpp:237]     Train net output #1: loss = 0.0559653 (* 1 = 0.0559653 loss)
I1016 21:18:49.710943   636 sgd_solver.cpp:105] Iteration 92700, lr = 0.01
I1016 21:18:58.825812   636 solver.cpp:218] Iteration 92800 (10.9742 iter/s, 9.11231s/100 iters), loss = 0.0635071
I1016 21:18:58.825812   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:18:58.825812   636 solver.cpp:237]     Train net output #1: loss = 0.063507 (* 1 = 0.063507 loss)
I1016 21:18:58.825812   636 sgd_solver.cpp:105] Iteration 92800, lr = 0.01
I1016 21:19:07.938638   636 solver.cpp:218] Iteration 92900 (10.9781 iter/s, 9.10902s/100 iters), loss = 0.0209337
I1016 21:19:07.938638   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:19:07.938638   636 solver.cpp:237]     Train net output #1: loss = 0.0209335 (* 1 = 0.0209335 loss)
I1016 21:19:07.938638   636 sgd_solver.cpp:105] Iteration 92900, lr = 0.01
I1016 21:19:16.607053  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:19:16.954674   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_93000.caffemodel
I1016 21:19:16.992027   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_93000.solverstate
I1016 21:19:16.992027   636 solver.cpp:330] Iteration 93000, Testing net (#0)
I1016 21:19:16.992027   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:19:19.255570  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:19:19.354023   636 solver.cpp:397]     Test net output #0: accuracy = 0.9023
I1016 21:19:19.354023   636 solver.cpp:397]     Test net output #1: loss = 0.340169 (* 1 = 0.340169 loss)
I1016 21:19:19.440188   636 solver.cpp:218] Iteration 93000 (8.69237 iter/s, 11.5043s/100 iters), loss = 0.0394822
I1016 21:19:19.440188   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:19:19.440188   636 solver.cpp:237]     Train net output #1: loss = 0.039482 (* 1 = 0.039482 loss)
I1016 21:19:19.440188   636 sgd_solver.cpp:105] Iteration 93000, lr = 0.01
I1016 21:19:28.556269   636 solver.cpp:218] Iteration 93100 (10.9755 iter/s, 9.11118s/100 iters), loss = 0.0678057
I1016 21:19:28.556269   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:19:28.556269   636 solver.cpp:237]     Train net output #1: loss = 0.0678055 (* 1 = 0.0678055 loss)
I1016 21:19:28.556269   636 sgd_solver.cpp:105] Iteration 93100, lr = 0.01
I1016 21:19:37.675268   636 solver.cpp:218] Iteration 93200 (10.962 iter/s, 9.12239s/100 iters), loss = 0.0578267
I1016 21:19:37.675268   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1016 21:19:37.675268   636 solver.cpp:237]     Train net output #1: loss = 0.0578266 (* 1 = 0.0578266 loss)
I1016 21:19:37.675268   636 sgd_solver.cpp:105] Iteration 93200, lr = 0.01
I1016 21:19:46.791710   636 solver.cpp:218] Iteration 93300 (10.9705 iter/s, 9.11533s/100 iters), loss = 0.107911
I1016 21:19:46.791710   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1016 21:19:46.791710   636 solver.cpp:237]     Train net output #1: loss = 0.10791 (* 1 = 0.10791 loss)
I1016 21:19:46.791710   636 sgd_solver.cpp:105] Iteration 93300, lr = 0.01
I1016 21:19:55.911624   636 solver.cpp:218] Iteration 93400 (10.9709 iter/s, 9.11506s/100 iters), loss = 0.0219798
I1016 21:19:55.911624   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:19:55.911624   636 solver.cpp:237]     Train net output #1: loss = 0.0219796 (* 1 = 0.0219796 loss)
I1016 21:19:55.911624   636 sgd_solver.cpp:105] Iteration 93400, lr = 0.01
I1016 21:20:04.633319  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:20:04.996670   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_93500.caffemodel
I1016 21:20:05.024169   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_93500.solverstate
I1016 21:20:05.037169   636 solver.cpp:330] Iteration 93500, Testing net (#0)
I1016 21:20:05.037169   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:20:07.318382  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:20:07.409888   636 solver.cpp:397]     Test net output #0: accuracy = 0.8964
I1016 21:20:07.409888   636 solver.cpp:397]     Test net output #1: loss = 0.362928 (* 1 = 0.362928 loss)
I1016 21:20:07.498905   636 solver.cpp:218] Iteration 93500 (8.63179 iter/s, 11.5851s/100 iters), loss = 0.0206035
I1016 21:20:07.498905   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:20:07.498905   636 solver.cpp:237]     Train net output #1: loss = 0.0206033 (* 1 = 0.0206033 loss)
I1016 21:20:07.498905   636 sgd_solver.cpp:105] Iteration 93500, lr = 0.01
I1016 21:20:16.662748   636 solver.cpp:218] Iteration 93600 (10.9131 iter/s, 9.16326s/100 iters), loss = 0.0409242
I1016 21:20:16.662748   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:20:16.662748   636 solver.cpp:237]     Train net output #1: loss = 0.040924 (* 1 = 0.040924 loss)
I1016 21:20:16.662748   636 sgd_solver.cpp:105] Iteration 93600, lr = 0.01
I1016 21:20:25.800431   636 solver.cpp:218] Iteration 93700 (10.9442 iter/s, 9.13725s/100 iters), loss = 0.0559291
I1016 21:20:25.800431   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:20:25.800431   636 solver.cpp:237]     Train net output #1: loss = 0.0559289 (* 1 = 0.0559289 loss)
I1016 21:20:25.800431   636 sgd_solver.cpp:105] Iteration 93700, lr = 0.01
I1016 21:20:34.937134   636 solver.cpp:218] Iteration 93800 (10.9457 iter/s, 9.13603s/100 iters), loss = 0.0277696
I1016 21:20:34.937134   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:20:34.937134   636 solver.cpp:237]     Train net output #1: loss = 0.0277693 (* 1 = 0.0277693 loss)
I1016 21:20:34.937134   636 sgd_solver.cpp:105] Iteration 93800, lr = 0.01
I1016 21:20:44.070282   636 solver.cpp:218] Iteration 93900 (10.9497 iter/s, 9.13265s/100 iters), loss = 0.0580665
I1016 21:20:44.070282   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1016 21:20:44.070282   636 solver.cpp:237]     Train net output #1: loss = 0.0580662 (* 1 = 0.0580662 loss)
I1016 21:20:44.070282   636 sgd_solver.cpp:105] Iteration 93900, lr = 0.01
I1016 21:20:52.750975  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:20:53.112005   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_94000.caffemodel
I1016 21:20:53.139014   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_94000.solverstate
I1016 21:20:53.151015   636 solver.cpp:330] Iteration 94000, Testing net (#0)
I1016 21:20:53.151015   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:20:55.413306  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:20:55.504317   636 solver.cpp:397]     Test net output #0: accuracy = 0.8965
I1016 21:20:55.504317   636 solver.cpp:397]     Test net output #1: loss = 0.367086 (* 1 = 0.367086 loss)
I1016 21:20:55.593330   636 solver.cpp:218] Iteration 94000 (8.6792 iter/s, 11.5218s/100 iters), loss = 0.0572384
I1016 21:20:55.593330   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:20:55.593330   636 solver.cpp:237]     Train net output #1: loss = 0.0572382 (* 1 = 0.0572382 loss)
I1016 21:20:55.593330   636 sgd_solver.cpp:105] Iteration 94000, lr = 0.01
I1016 21:21:04.728982   636 solver.cpp:218] Iteration 94100 (10.9466 iter/s, 9.13529s/100 iters), loss = 0.0798718
I1016 21:21:04.728982   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1016 21:21:04.728982   636 solver.cpp:237]     Train net output #1: loss = 0.0798715 (* 1 = 0.0798715 loss)
I1016 21:21:04.728982   636 sgd_solver.cpp:105] Iteration 94100, lr = 0.01
I1016 21:21:13.863687   636 solver.cpp:218] Iteration 94200 (10.9479 iter/s, 9.1342s/100 iters), loss = 0.0157995
I1016 21:21:13.863687   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:21:13.863687   636 solver.cpp:237]     Train net output #1: loss = 0.0157993 (* 1 = 0.0157993 loss)
I1016 21:21:13.863687   636 sgd_solver.cpp:105] Iteration 94200, lr = 0.01
I1016 21:21:22.999045   636 solver.cpp:218] Iteration 94300 (10.947 iter/s, 9.13496s/100 iters), loss = 0.0402883
I1016 21:21:22.999045   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:21:22.999045   636 solver.cpp:237]     Train net output #1: loss = 0.0402881 (* 1 = 0.0402881 loss)
I1016 21:21:22.999045   636 sgd_solver.cpp:105] Iteration 94300, lr = 0.01
I1016 21:21:32.110754   636 solver.cpp:218] Iteration 94400 (10.9758 iter/s, 9.11092s/100 iters), loss = 0.0638439
I1016 21:21:32.110754   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:21:32.110754   636 solver.cpp:237]     Train net output #1: loss = 0.0638436 (* 1 = 0.0638436 loss)
I1016 21:21:32.110754   636 sgd_solver.cpp:105] Iteration 94400, lr = 0.01
I1016 21:21:40.772342  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:21:41.133364   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_94500.caffemodel
I1016 21:21:41.160369   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_94500.solverstate
I1016 21:21:41.172371   636 solver.cpp:330] Iteration 94500, Testing net (#0)
I1016 21:21:41.172371   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:21:43.428510  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:21:43.519516   636 solver.cpp:397]     Test net output #0: accuracy = 0.8936
I1016 21:21:43.519516   636 solver.cpp:397]     Test net output #1: loss = 0.394625 (* 1 = 0.394625 loss)
I1016 21:21:43.608527   636 solver.cpp:218] Iteration 94500 (8.69744 iter/s, 11.4976s/100 iters), loss = 0.0671799
I1016 21:21:43.608527   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:21:43.608527   636 solver.cpp:237]     Train net output #1: loss = 0.0671796 (* 1 = 0.0671796 loss)
I1016 21:21:43.608527   636 sgd_solver.cpp:105] Iteration 94500, lr = 0.01
I1016 21:21:52.726200   636 solver.cpp:218] Iteration 94600 (10.9686 iter/s, 9.11695s/100 iters), loss = 0.0277599
I1016 21:21:52.726200   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:21:52.726200   636 solver.cpp:237]     Train net output #1: loss = 0.0277597 (* 1 = 0.0277597 loss)
I1016 21:21:52.726701   636 sgd_solver.cpp:105] Iteration 94600, lr = 0.01
I1016 21:22:01.839759   636 solver.cpp:218] Iteration 94700 (10.9732 iter/s, 9.11308s/100 iters), loss = 0.0292524
I1016 21:22:01.839759   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:22:01.839759   636 solver.cpp:237]     Train net output #1: loss = 0.0292521 (* 1 = 0.0292521 loss)
I1016 21:22:01.839759   636 sgd_solver.cpp:105] Iteration 94700, lr = 0.01
I1016 21:22:10.956321   636 solver.cpp:218] Iteration 94800 (10.9692 iter/s, 9.11641s/100 iters), loss = 0.0563628
I1016 21:22:11.015355   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1016 21:22:11.015355   636 solver.cpp:237]     Train net output #1: loss = 0.0563625 (* 1 = 0.0563625 loss)
I1016 21:22:11.015355   636 sgd_solver.cpp:105] Iteration 94800, lr = 0.01
I1016 21:22:20.125044   636 solver.cpp:218] Iteration 94900 (10.978 iter/s, 9.10916s/100 iters), loss = 0.0472249
I1016 21:22:20.125044   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:22:20.125044   636 solver.cpp:237]     Train net output #1: loss = 0.0472246 (* 1 = 0.0472246 loss)
I1016 21:22:20.125044   636 sgd_solver.cpp:105] Iteration 94900, lr = 0.01
I1016 21:22:28.790812  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:22:29.151845   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_95000.caffemodel
I1016 21:22:29.176849   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_95000.solverstate
I1016 21:22:29.188863   636 solver.cpp:330] Iteration 95000, Testing net (#0)
I1016 21:22:29.188863   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:22:31.443066  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:22:31.533076   636 solver.cpp:397]     Test net output #0: accuracy = 0.8957
I1016 21:22:31.534075   636 solver.cpp:397]     Test net output #1: loss = 0.372883 (* 1 = 0.372883 loss)
I1016 21:22:31.622081   636 solver.cpp:218] Iteration 95000 (8.69842 iter/s, 11.4963s/100 iters), loss = 0.0356414
I1016 21:22:31.622081   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:22:31.622081   636 solver.cpp:237]     Train net output #1: loss = 0.0356412 (* 1 = 0.0356412 loss)
I1016 21:22:31.622081   636 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I1016 21:22:31.622081   636 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1016 21:22:40.733916   636 solver.cpp:218] Iteration 95100 (10.9756 iter/s, 9.11114s/100 iters), loss = 0.049258
I1016 21:22:40.733916   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:22:40.733916   636 solver.cpp:237]     Train net output #1: loss = 0.0492577 (* 1 = 0.0492577 loss)
I1016 21:22:40.733916   636 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1016 21:22:49.846755   636 solver.cpp:218] Iteration 95200 (10.9741 iter/s, 9.11237s/100 iters), loss = 0.0262053
I1016 21:22:49.846755   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:22:49.846755   636 solver.cpp:237]     Train net output #1: loss = 0.026205 (* 1 = 0.026205 loss)
I1016 21:22:49.846755   636 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1016 21:22:58.954470   636 solver.cpp:218] Iteration 95300 (10.9798 iter/s, 9.10762s/100 iters), loss = 0.0294309
I1016 21:22:58.954470   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1016 21:22:58.954470   636 solver.cpp:237]     Train net output #1: loss = 0.0294306 (* 1 = 0.0294306 loss)
I1016 21:22:58.954470   636 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1016 21:23:08.074784   636 solver.cpp:218] Iteration 95400 (10.9657 iter/s, 9.11932s/100 iters), loss = 0.00348767
I1016 21:23:08.074784   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:23:08.074784   636 solver.cpp:237]     Train net output #1: loss = 0.0034874 (* 1 = 0.0034874 loss)
I1016 21:23:08.074784   636 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1016 21:23:16.741750  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:23:17.101526   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_95500.caffemodel
I1016 21:23:17.128511   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_95500.solverstate
I1016 21:23:17.139842   636 solver.cpp:330] Iteration 95500, Testing net (#0)
I1016 21:23:17.139842   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:23:19.401219  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:23:19.492247   636 solver.cpp:397]     Test net output #0: accuracy = 0.9411
I1016 21:23:19.492247   636 solver.cpp:397]     Test net output #1: loss = 0.203104 (* 1 = 0.203104 loss)
I1016 21:23:19.580775   636 solver.cpp:218] Iteration 95500 (8.69159 iter/s, 11.5054s/100 iters), loss = 0.0212506
I1016 21:23:19.580775   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:23:19.580775   636 solver.cpp:237]     Train net output #1: loss = 0.0212503 (* 1 = 0.0212503 loss)
I1016 21:23:19.580775   636 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1016 21:23:28.690989   636 solver.cpp:218] Iteration 95600 (10.9773 iter/s, 9.10972s/100 iters), loss = 0.0303954
I1016 21:23:28.691488   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:23:28.691488   636 solver.cpp:237]     Train net output #1: loss = 0.0303951 (* 1 = 0.0303951 loss)
I1016 21:23:28.691488   636 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1016 21:23:37.803683   636 solver.cpp:218] Iteration 95700 (10.9746 iter/s, 9.11192s/100 iters), loss = 0.028817
I1016 21:23:37.803683   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:23:37.803683   636 solver.cpp:237]     Train net output #1: loss = 0.0288167 (* 1 = 0.0288167 loss)
I1016 21:23:37.803683   636 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1016 21:23:46.917565   636 solver.cpp:218] Iteration 95800 (10.9732 iter/s, 9.11312s/100 iters), loss = 0.0279098
I1016 21:23:46.917565   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:23:46.917565   636 solver.cpp:237]     Train net output #1: loss = 0.0279095 (* 1 = 0.0279095 loss)
I1016 21:23:46.917565   636 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1016 21:23:56.038436   636 solver.cpp:218] Iteration 95900 (10.964 iter/s, 9.12076s/100 iters), loss = 0.00933081
I1016 21:23:56.038436   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:23:56.038436   636 solver.cpp:237]     Train net output #1: loss = 0.00933054 (* 1 = 0.00933054 loss)
I1016 21:23:56.038436   636 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1016 21:24:04.704147  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:24:05.066193   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_96000.caffemodel
I1016 21:24:05.091193   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_96000.solverstate
I1016 21:24:05.104195   636 solver.cpp:330] Iteration 96000, Testing net (#0)
I1016 21:24:05.104195   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:24:07.359508  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:24:07.450515   636 solver.cpp:397]     Test net output #0: accuracy = 0.9408
I1016 21:24:07.450515   636 solver.cpp:397]     Test net output #1: loss = 0.201652 (* 1 = 0.201652 loss)
I1016 21:24:07.539532   636 solver.cpp:218] Iteration 96000 (8.69545 iter/s, 11.5003s/100 iters), loss = 0.00911267
I1016 21:24:07.539532   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:24:07.539532   636 solver.cpp:237]     Train net output #1: loss = 0.00911239 (* 1 = 0.00911239 loss)
I1016 21:24:07.539532   636 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1016 21:24:16.662477   636 solver.cpp:218] Iteration 96100 (10.9618 iter/s, 9.12263s/100 iters), loss = 0.0324269
I1016 21:24:16.662477   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:24:16.662477   636 solver.cpp:237]     Train net output #1: loss = 0.0324266 (* 1 = 0.0324266 loss)
I1016 21:24:16.662477   636 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1016 21:24:25.794366   636 solver.cpp:218] Iteration 96200 (10.9508 iter/s, 9.13175s/100 iters), loss = 0.0375531
I1016 21:24:25.795367   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:24:25.795367   636 solver.cpp:237]     Train net output #1: loss = 0.0375528 (* 1 = 0.0375528 loss)
I1016 21:24:25.795367   636 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1016 21:24:34.908229   636 solver.cpp:218] Iteration 96300 (10.974 iter/s, 9.11243s/100 iters), loss = 0.0168526
I1016 21:24:34.908229   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:24:34.908229   636 solver.cpp:237]     Train net output #1: loss = 0.0168523 (* 1 = 0.0168523 loss)
I1016 21:24:34.908229   636 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1016 21:24:44.035228   636 solver.cpp:218] Iteration 96400 (10.9569 iter/s, 9.12666s/100 iters), loss = 0.00616504
I1016 21:24:44.035228   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:24:44.035228   636 solver.cpp:237]     Train net output #1: loss = 0.00616475 (* 1 = 0.00616475 loss)
I1016 21:24:44.035228   636 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1016 21:24:52.704342  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:24:53.065389   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_96500.caffemodel
I1016 21:24:53.091388   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_96500.solverstate
I1016 21:24:53.103389   636 solver.cpp:330] Iteration 96500, Testing net (#0)
I1016 21:24:53.103389   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:24:55.357611  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:24:55.448609   636 solver.cpp:397]     Test net output #0: accuracy = 0.9433
I1016 21:24:55.448609   636 solver.cpp:397]     Test net output #1: loss = 0.200247 (* 1 = 0.200247 loss)
I1016 21:24:55.537111   636 solver.cpp:218] Iteration 96500 (8.69481 iter/s, 11.5011s/100 iters), loss = 0.00614672
I1016 21:24:55.537111   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:24:55.537111   636 solver.cpp:237]     Train net output #1: loss = 0.00614643 (* 1 = 0.00614643 loss)
I1016 21:24:55.537111   636 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1016 21:25:04.654242   636 solver.cpp:218] Iteration 96600 (10.9685 iter/s, 9.11699s/100 iters), loss = 0.0102285
I1016 21:25:04.654242   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:25:04.654242   636 solver.cpp:237]     Train net output #1: loss = 0.0102282 (* 1 = 0.0102282 loss)
I1016 21:25:04.654242   636 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1016 21:25:13.776000   636 solver.cpp:218] Iteration 96700 (10.9641 iter/s, 9.12064s/100 iters), loss = 0.00814746
I1016 21:25:13.776000   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:25:13.776000   636 solver.cpp:237]     Train net output #1: loss = 0.00814718 (* 1 = 0.00814718 loss)
I1016 21:25:13.776000   636 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1016 21:25:22.896303   636 solver.cpp:218] Iteration 96800 (10.9649 iter/s, 9.12005s/100 iters), loss = 0.0079055
I1016 21:25:22.896303   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:25:22.896303   636 solver.cpp:237]     Train net output #1: loss = 0.00790521 (* 1 = 0.00790521 loss)
I1016 21:25:22.896803   636 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1016 21:25:32.039633   636 solver.cpp:218] Iteration 96900 (10.9381 iter/s, 9.14239s/100 iters), loss = 0.0072117
I1016 21:25:32.039633   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:25:32.039633   636 solver.cpp:237]     Train net output #1: loss = 0.00721142 (* 1 = 0.00721142 loss)
I1016 21:25:32.039633   636 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1016 21:25:40.723296  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:25:41.083330   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_97000.caffemodel
I1016 21:25:41.108330   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_97000.solverstate
I1016 21:25:41.120331   636 solver.cpp:330] Iteration 97000, Testing net (#0)
I1016 21:25:41.120331   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:25:43.380610  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:25:43.471619   636 solver.cpp:397]     Test net output #0: accuracy = 0.9437
I1016 21:25:43.471619   636 solver.cpp:397]     Test net output #1: loss = 0.199633 (* 1 = 0.199633 loss)
I1016 21:25:43.560621   636 solver.cpp:218] Iteration 97000 (8.6801 iter/s, 11.5206s/100 iters), loss = 0.0027384
I1016 21:25:43.560621   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:25:43.560621   636 solver.cpp:237]     Train net output #1: loss = 0.00273811 (* 1 = 0.00273811 loss)
I1016 21:25:43.560621   636 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1016 21:25:52.695305   636 solver.cpp:218] Iteration 97100 (10.9479 iter/s, 9.13421s/100 iters), loss = 0.00503399
I1016 21:25:52.695305   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:25:52.695305   636 solver.cpp:237]     Train net output #1: loss = 0.00503371 (* 1 = 0.00503371 loss)
I1016 21:25:52.695305   636 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1016 21:26:01.812502   636 solver.cpp:218] Iteration 97200 (10.9691 iter/s, 9.1165s/100 iters), loss = 0.0118271
I1016 21:26:01.812502   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:26:01.812502   636 solver.cpp:237]     Train net output #1: loss = 0.0118268 (* 1 = 0.0118268 loss)
I1016 21:26:01.812502   636 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1016 21:26:10.905067   636 solver.cpp:218] Iteration 97300 (10.9981 iter/s, 9.09246s/100 iters), loss = 0.00592012
I1016 21:26:10.905067   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:26:10.905067   636 solver.cpp:237]     Train net output #1: loss = 0.00591985 (* 1 = 0.00591985 loss)
I1016 21:26:10.905067   636 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1016 21:26:20.003691   636 solver.cpp:218] Iteration 97400 (10.9914 iter/s, 9.09798s/100 iters), loss = 0.0105218
I1016 21:26:20.003691   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:26:20.003691   636 solver.cpp:237]     Train net output #1: loss = 0.0105216 (* 1 = 0.0105216 loss)
I1016 21:26:20.003691   636 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1016 21:26:28.679554  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:26:29.040570   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_97500.caffemodel
I1016 21:26:29.067571   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_97500.solverstate
I1016 21:26:29.079574   636 solver.cpp:330] Iteration 97500, Testing net (#0)
I1016 21:26:29.079574   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:26:31.341795  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:26:31.432838   636 solver.cpp:397]     Test net output #0: accuracy = 0.9449
I1016 21:26:31.432838   636 solver.cpp:397]     Test net output #1: loss = 0.19971 (* 1 = 0.19971 loss)
I1016 21:26:31.521837   636 solver.cpp:218] Iteration 97500 (8.68242 iter/s, 11.5175s/100 iters), loss = 0.00721707
I1016 21:26:31.521837   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:26:31.521837   636 solver.cpp:237]     Train net output #1: loss = 0.00721681 (* 1 = 0.00721681 loss)
I1016 21:26:31.521837   636 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1016 21:26:40.640978   636 solver.cpp:218] Iteration 97600 (10.9661 iter/s, 9.119s/100 iters), loss = 0.0089927
I1016 21:26:40.640978   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:26:40.640978   636 solver.cpp:237]     Train net output #1: loss = 0.00899244 (* 1 = 0.00899244 loss)
I1016 21:26:40.640978   636 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1016 21:26:49.759754   636 solver.cpp:218] Iteration 97700 (10.9671 iter/s, 9.11822s/100 iters), loss = 0.0196246
I1016 21:26:49.759754   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:26:49.759754   636 solver.cpp:237]     Train net output #1: loss = 0.0196244 (* 1 = 0.0196244 loss)
I1016 21:26:49.759754   636 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1016 21:26:58.871420   636 solver.cpp:218] Iteration 97800 (10.9756 iter/s, 9.1111s/100 iters), loss = 0.0140357
I1016 21:26:58.871420   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:26:58.871420   636 solver.cpp:237]     Train net output #1: loss = 0.0140354 (* 1 = 0.0140354 loss)
I1016 21:26:58.871420   636 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1016 21:27:07.994163   636 solver.cpp:218] Iteration 97900 (10.9628 iter/s, 9.12175s/100 iters), loss = 0.00163256
I1016 21:27:07.994163   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:27:07.994163   636 solver.cpp:237]     Train net output #1: loss = 0.00163229 (* 1 = 0.00163229 loss)
I1016 21:27:07.994163   636 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1016 21:27:16.648874  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:27:17.007889   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_98000.caffemodel
I1016 21:27:17.035894   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_98000.solverstate
I1016 21:27:17.048897   636 solver.cpp:330] Iteration 98000, Testing net (#0)
I1016 21:27:17.048897   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:27:19.304128  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:27:19.395130   636 solver.cpp:397]     Test net output #0: accuracy = 0.9436
I1016 21:27:19.395130   636 solver.cpp:397]     Test net output #1: loss = 0.200448 (* 1 = 0.200448 loss)
I1016 21:27:19.484130   636 solver.cpp:218] Iteration 98000 (8.70394 iter/s, 11.4891s/100 iters), loss = 0.00672677
I1016 21:27:19.484130   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:27:19.484130   636 solver.cpp:237]     Train net output #1: loss = 0.00672649 (* 1 = 0.00672649 loss)
I1016 21:27:19.484130   636 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1016 21:27:28.601974   636 solver.cpp:218] Iteration 98100 (10.9677 iter/s, 9.1177s/100 iters), loss = 0.0133187
I1016 21:27:28.602473   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:27:28.602473   636 solver.cpp:237]     Train net output #1: loss = 0.0133185 (* 1 = 0.0133185 loss)
I1016 21:27:28.602473   636 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1016 21:27:37.720746   636 solver.cpp:218] Iteration 98200 (10.9676 iter/s, 9.11778s/100 iters), loss = 0.00462213
I1016 21:27:37.720746   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:27:37.720746   636 solver.cpp:237]     Train net output #1: loss = 0.00462187 (* 1 = 0.00462187 loss)
I1016 21:27:37.720746   636 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1016 21:27:46.831666   636 solver.cpp:218] Iteration 98300 (10.9758 iter/s, 9.11092s/100 iters), loss = 0.00703522
I1016 21:27:46.831666   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:27:46.831666   636 solver.cpp:237]     Train net output #1: loss = 0.00703495 (* 1 = 0.00703495 loss)
I1016 21:27:46.831666   636 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1016 21:27:55.953375   636 solver.cpp:218] Iteration 98400 (10.9639 iter/s, 9.12082s/100 iters), loss = 0.0056134
I1016 21:27:55.953375   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:27:55.953375   636 solver.cpp:237]     Train net output #1: loss = 0.00561314 (* 1 = 0.00561314 loss)
I1016 21:27:55.953375   636 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1016 21:28:04.625056  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:28:04.987076   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_98500.caffemodel
I1016 21:28:05.015082   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_98500.solverstate
I1016 21:28:05.027083   636 solver.cpp:330] Iteration 98500, Testing net (#0)
I1016 21:28:05.027083   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:28:07.282243  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:28:07.373247   636 solver.cpp:397]     Test net output #0: accuracy = 0.9441
I1016 21:28:07.373247   636 solver.cpp:397]     Test net output #1: loss = 0.202073 (* 1 = 0.202073 loss)
I1016 21:28:07.461256   636 solver.cpp:218] Iteration 98500 (8.68966 iter/s, 11.5079s/100 iters), loss = 0.0114792
I1016 21:28:07.461256   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:28:07.462256   636 solver.cpp:237]     Train net output #1: loss = 0.0114789 (* 1 = 0.0114789 loss)
I1016 21:28:07.462256   636 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1016 21:28:16.584964   636 solver.cpp:218] Iteration 98600 (10.9619 iter/s, 9.12252s/100 iters), loss = 0.0102509
I1016 21:28:16.584964   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:28:16.584964   636 solver.cpp:237]     Train net output #1: loss = 0.0102507 (* 1 = 0.0102507 loss)
I1016 21:28:16.584964   636 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1016 21:28:25.704210   636 solver.cpp:218] Iteration 98700 (10.9664 iter/s, 9.11875s/100 iters), loss = 0.00505822
I1016 21:28:25.704210   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:28:25.704210   636 solver.cpp:237]     Train net output #1: loss = 0.00505795 (* 1 = 0.00505795 loss)
I1016 21:28:25.704210   636 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1016 21:28:34.812537   636 solver.cpp:218] Iteration 98800 (10.9795 iter/s, 9.10791s/100 iters), loss = 0.00979975
I1016 21:28:34.812537   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:28:34.812537   636 solver.cpp:237]     Train net output #1: loss = 0.00979949 (* 1 = 0.00979949 loss)
I1016 21:28:34.812537   636 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1016 21:28:43.927211   636 solver.cpp:218] Iteration 98900 (10.9716 iter/s, 9.11445s/100 iters), loss = 0.00198009
I1016 21:28:43.927211   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:28:43.927211   636 solver.cpp:237]     Train net output #1: loss = 0.00197982 (* 1 = 0.00197982 loss)
I1016 21:28:43.927211   636 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1016 21:28:52.592221  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:28:52.953318   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_99000.caffemodel
I1016 21:28:52.978320   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_99000.solverstate
I1016 21:28:52.990319   636 solver.cpp:330] Iteration 99000, Testing net (#0)
I1016 21:28:52.990819   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:28:55.246047  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:28:55.337057   636 solver.cpp:397]     Test net output #0: accuracy = 0.9447
I1016 21:28:55.337057   636 solver.cpp:397]     Test net output #1: loss = 0.201253 (* 1 = 0.201253 loss)
I1016 21:28:55.426074   636 solver.cpp:218] Iteration 99000 (8.69753 iter/s, 11.4975s/100 iters), loss = 0.00617262
I1016 21:28:55.426074   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:28:55.426074   636 solver.cpp:237]     Train net output #1: loss = 0.00617236 (* 1 = 0.00617236 loss)
I1016 21:28:55.426074   636 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1016 21:29:04.549326   636 solver.cpp:218] Iteration 99100 (10.9608 iter/s, 9.12342s/100 iters), loss = 0.00684951
I1016 21:29:04.549326   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:29:04.549326   636 solver.cpp:237]     Train net output #1: loss = 0.00684925 (* 1 = 0.00684925 loss)
I1016 21:29:04.549326   636 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1016 21:29:13.670994   636 solver.cpp:218] Iteration 99200 (10.9637 iter/s, 9.12098s/100 iters), loss = 0.0187328
I1016 21:29:13.670994   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:29:13.670994   636 solver.cpp:237]     Train net output #1: loss = 0.0187325 (* 1 = 0.0187325 loss)
I1016 21:29:13.670994   636 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1016 21:29:22.790706   636 solver.cpp:218] Iteration 99300 (10.9662 iter/s, 9.11896s/100 iters), loss = 0.00714689
I1016 21:29:22.790706   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:29:22.790706   636 solver.cpp:237]     Train net output #1: loss = 0.00714664 (* 1 = 0.00714664 loss)
I1016 21:29:22.790706   636 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1016 21:29:31.908524   636 solver.cpp:218] Iteration 99400 (10.9682 iter/s, 9.11727s/100 iters), loss = 0.00873246
I1016 21:29:31.908524   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:29:31.908524   636 solver.cpp:237]     Train net output #1: loss = 0.0087322 (* 1 = 0.0087322 loss)
I1016 21:29:31.908524   636 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1016 21:29:40.575749  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:29:40.933272   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_99500.caffemodel
I1016 21:29:40.960273   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_99500.solverstate
I1016 21:29:40.972779   636 solver.cpp:330] Iteration 99500, Testing net (#0)
I1016 21:29:40.972779   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:29:43.227546  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:29:43.319571   636 solver.cpp:397]     Test net output #0: accuracy = 0.9444
I1016 21:29:43.319571   636 solver.cpp:397]     Test net output #1: loss = 0.201672 (* 1 = 0.201672 loss)
I1016 21:29:43.407577   636 solver.cpp:218] Iteration 99500 (8.69694 iter/s, 11.4983s/100 iters), loss = 0.00418668
I1016 21:29:43.407577   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:29:43.407577   636 solver.cpp:237]     Train net output #1: loss = 0.00418642 (* 1 = 0.00418642 loss)
I1016 21:29:43.407577   636 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1016 21:29:52.512940   636 solver.cpp:218] Iteration 99600 (10.983 iter/s, 9.10502s/100 iters), loss = 0.00556695
I1016 21:29:52.512940   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:29:52.512940   636 solver.cpp:237]     Train net output #1: loss = 0.0055667 (* 1 = 0.0055667 loss)
I1016 21:29:52.512940   636 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1016 21:30:01.658061   636 solver.cpp:218] Iteration 99700 (10.9357 iter/s, 9.14435s/100 iters), loss = 0.0208031
I1016 21:30:01.658061   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:30:01.658061   636 solver.cpp:237]     Train net output #1: loss = 0.0208029 (* 1 = 0.0208029 loss)
I1016 21:30:01.658061   636 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1016 21:30:10.781507   636 solver.cpp:218] Iteration 99800 (10.9613 iter/s, 9.12298s/100 iters), loss = 0.0035127
I1016 21:30:10.781507   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:30:10.781507   636 solver.cpp:237]     Train net output #1: loss = 0.00351243 (* 1 = 0.00351243 loss)
I1016 21:30:10.781507   636 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1016 21:30:19.905200   636 solver.cpp:218] Iteration 99900 (10.9607 iter/s, 9.12348s/100 iters), loss = 0.0059363
I1016 21:30:19.905200   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:30:19.905200   636 solver.cpp:237]     Train net output #1: loss = 0.00593603 (* 1 = 0.00593603 loss)
I1016 21:30:19.905200   636 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1016 21:30:28.573410  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:30:28.935427   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_100000.caffemodel
I1016 21:30:28.959435   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_100000.solverstate
I1016 21:30:28.971436   636 solver.cpp:330] Iteration 100000, Testing net (#0)
I1016 21:30:28.971436   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:30:31.226750  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:30:31.317755   636 solver.cpp:397]     Test net output #0: accuracy = 0.9438
I1016 21:30:31.317755   636 solver.cpp:397]     Test net output #1: loss = 0.202496 (* 1 = 0.202496 loss)
I1016 21:30:31.405761   636 solver.cpp:218] Iteration 100000 (8.69553 iter/s, 11.5002s/100 iters), loss = 0.00255383
I1016 21:30:31.406762   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:30:31.406762   636 solver.cpp:237]     Train net output #1: loss = 0.00255356 (* 1 = 0.00255356 loss)
I1016 21:30:31.406762   636 sgd_solver.cpp:105] Iteration 100000, lr = 0.001
I1016 21:30:40.526652   636 solver.cpp:218] Iteration 100100 (10.9655 iter/s, 9.11951s/100 iters), loss = 0.00307972
I1016 21:30:40.526652   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:30:40.526652   636 solver.cpp:237]     Train net output #1: loss = 0.00307945 (* 1 = 0.00307945 loss)
I1016 21:30:40.526652   636 sgd_solver.cpp:105] Iteration 100100, lr = 0.001
I1016 21:30:49.640341   636 solver.cpp:218] Iteration 100200 (10.9732 iter/s, 9.11314s/100 iters), loss = 0.0254295
I1016 21:30:49.640341   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:30:49.640341   636 solver.cpp:237]     Train net output #1: loss = 0.0254292 (* 1 = 0.0254292 loss)
I1016 21:30:49.640341   636 sgd_solver.cpp:105] Iteration 100200, lr = 0.001
I1016 21:30:58.761179   636 solver.cpp:218] Iteration 100300 (10.9647 iter/s, 9.12022s/100 iters), loss = 0.00318505
I1016 21:30:58.761179   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:30:58.761179   636 solver.cpp:237]     Train net output #1: loss = 0.00318478 (* 1 = 0.00318478 loss)
I1016 21:30:58.761179   636 sgd_solver.cpp:105] Iteration 100300, lr = 0.001
I1016 21:31:07.877050   636 solver.cpp:218] Iteration 100400 (10.97 iter/s, 9.11575s/100 iters), loss = 0.00245277
I1016 21:31:07.877050   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:31:07.877050   636 solver.cpp:237]     Train net output #1: loss = 0.0024525 (* 1 = 0.0024525 loss)
I1016 21:31:07.877050   636 sgd_solver.cpp:105] Iteration 100400, lr = 0.001
I1016 21:31:16.548751  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:31:16.908799   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_100500.caffemodel
I1016 21:31:16.934798   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_100500.solverstate
I1016 21:31:16.946817   636 solver.cpp:330] Iteration 100500, Testing net (#0)
I1016 21:31:16.946817   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:31:19.202123  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:31:19.293148   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 21:31:19.293148   636 solver.cpp:397]     Test net output #1: loss = 0.202372 (* 1 = 0.202372 loss)
I1016 21:31:19.382158   636 solver.cpp:218] Iteration 100500 (8.69286 iter/s, 11.5037s/100 iters), loss = 0.00408729
I1016 21:31:19.382158   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:31:19.382158   636 solver.cpp:237]     Train net output #1: loss = 0.00408702 (* 1 = 0.00408702 loss)
I1016 21:31:19.382158   636 sgd_solver.cpp:105] Iteration 100500, lr = 0.001
I1016 21:31:28.504057   636 solver.cpp:218] Iteration 100600 (10.9625 iter/s, 9.12203s/100 iters), loss = 0.00592935
I1016 21:31:28.504057   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:31:28.504057   636 solver.cpp:237]     Train net output #1: loss = 0.00592907 (* 1 = 0.00592907 loss)
I1016 21:31:28.504057   636 sgd_solver.cpp:105] Iteration 100600, lr = 0.001
I1016 21:31:37.628744   636 solver.cpp:218] Iteration 100700 (10.9601 iter/s, 9.124s/100 iters), loss = 0.00780849
I1016 21:31:37.628744   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:31:37.628744   636 solver.cpp:237]     Train net output #1: loss = 0.00780822 (* 1 = 0.00780822 loss)
I1016 21:31:37.628744   636 sgd_solver.cpp:105] Iteration 100700, lr = 0.001
I1016 21:31:46.744506   636 solver.cpp:218] Iteration 100800 (10.9705 iter/s, 9.11537s/100 iters), loss = 0.00330627
I1016 21:31:46.744506   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:31:46.744506   636 solver.cpp:237]     Train net output #1: loss = 0.003306 (* 1 = 0.003306 loss)
I1016 21:31:46.744506   636 sgd_solver.cpp:105] Iteration 100800, lr = 0.001
I1016 21:31:55.864404   636 solver.cpp:218] Iteration 100900 (10.9661 iter/s, 9.11903s/100 iters), loss = 0.00159844
I1016 21:31:55.864907   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:31:55.864907   636 solver.cpp:237]     Train net output #1: loss = 0.00159817 (* 1 = 0.00159817 loss)
I1016 21:31:55.864907   636 sgd_solver.cpp:105] Iteration 100900, lr = 0.001
I1016 21:32:04.534162  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:32:04.895195   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_101000.caffemodel
I1016 21:32:04.920195   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_101000.solverstate
I1016 21:32:04.932196   636 solver.cpp:330] Iteration 101000, Testing net (#0)
I1016 21:32:04.932196   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:32:07.184504  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:32:07.275005   636 solver.cpp:397]     Test net output #0: accuracy = 0.9448
I1016 21:32:07.275005   636 solver.cpp:397]     Test net output #1: loss = 0.203327 (* 1 = 0.203327 loss)
I1016 21:32:07.363510   636 solver.cpp:218] Iteration 101000 (8.69716 iter/s, 11.498s/100 iters), loss = 0.00270306
I1016 21:32:07.363510   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:32:07.363510   636 solver.cpp:237]     Train net output #1: loss = 0.00270279 (* 1 = 0.00270279 loss)
I1016 21:32:07.363510   636 sgd_solver.cpp:105] Iteration 101000, lr = 0.001
I1016 21:32:16.531229   636 solver.cpp:218] Iteration 101100 (10.9076 iter/s, 9.16792s/100 iters), loss = 0.0067479
I1016 21:32:16.531229   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:32:16.531229   636 solver.cpp:237]     Train net output #1: loss = 0.00674763 (* 1 = 0.00674763 loss)
I1016 21:32:16.531229   636 sgd_solver.cpp:105] Iteration 101100, lr = 0.001
I1016 21:32:25.633316   636 solver.cpp:218] Iteration 101200 (10.9881 iter/s, 9.10072s/100 iters), loss = 0.00612672
I1016 21:32:25.633316   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:32:25.633316   636 solver.cpp:237]     Train net output #1: loss = 0.00612645 (* 1 = 0.00612645 loss)
I1016 21:32:25.633316   636 sgd_solver.cpp:105] Iteration 101200, lr = 0.001
I1016 21:32:34.725836   636 solver.cpp:218] Iteration 101300 (10.998 iter/s, 9.09255s/100 iters), loss = 0.00248807
I1016 21:32:34.725836   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:32:34.725836   636 solver.cpp:237]     Train net output #1: loss = 0.0024878 (* 1 = 0.0024878 loss)
I1016 21:32:34.725836   636 sgd_solver.cpp:105] Iteration 101300, lr = 0.001
I1016 21:32:43.815243   636 solver.cpp:218] Iteration 101400 (11.0025 iter/s, 9.08886s/100 iters), loss = 0.00337076
I1016 21:32:43.815243   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:32:43.815243   636 solver.cpp:237]     Train net output #1: loss = 0.00337049 (* 1 = 0.00337049 loss)
I1016 21:32:43.815243   636 sgd_solver.cpp:105] Iteration 101400, lr = 0.001
I1016 21:32:52.461987  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:32:52.822034   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_101500.caffemodel
I1016 21:32:52.849035   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_101500.solverstate
I1016 21:32:52.861033   636 solver.cpp:330] Iteration 101500, Testing net (#0)
I1016 21:32:52.861033   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:32:55.110285  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:32:55.200294   636 solver.cpp:397]     Test net output #0: accuracy = 0.9438
I1016 21:32:55.200294   636 solver.cpp:397]     Test net output #1: loss = 0.203859 (* 1 = 0.203859 loss)
I1016 21:32:55.288795   636 solver.cpp:218] Iteration 101500 (8.71652 iter/s, 11.4725s/100 iters), loss = 0.00261187
I1016 21:32:55.288795   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:32:55.288795   636 solver.cpp:237]     Train net output #1: loss = 0.0026116 (* 1 = 0.0026116 loss)
I1016 21:32:55.288795   636 sgd_solver.cpp:105] Iteration 101500, lr = 0.001
I1016 21:33:04.373091   636 solver.cpp:218] Iteration 101600 (11.0085 iter/s, 9.08386s/100 iters), loss = 0.00648638
I1016 21:33:04.373091   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:33:04.373091   636 solver.cpp:237]     Train net output #1: loss = 0.00648611 (* 1 = 0.00648611 loss)
I1016 21:33:04.373091   636 sgd_solver.cpp:105] Iteration 101600, lr = 0.001
I1016 21:33:13.467752   636 solver.cpp:218] Iteration 101700 (10.9963 iter/s, 9.09399s/100 iters), loss = 0.0161488
I1016 21:33:13.467752   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:33:13.467752   636 solver.cpp:237]     Train net output #1: loss = 0.0161485 (* 1 = 0.0161485 loss)
I1016 21:33:13.467752   636 sgd_solver.cpp:105] Iteration 101700, lr = 0.001
I1016 21:33:22.543452   636 solver.cpp:218] Iteration 101800 (11.0185 iter/s, 9.0756s/100 iters), loss = 0.00924371
I1016 21:33:22.543452   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:33:22.543452   636 solver.cpp:237]     Train net output #1: loss = 0.00924343 (* 1 = 0.00924343 loss)
I1016 21:33:22.543452   636 sgd_solver.cpp:105] Iteration 101800, lr = 0.001
I1016 21:33:31.612606   636 solver.cpp:218] Iteration 101900 (11.0268 iter/s, 9.06881s/100 iters), loss = 0.00264413
I1016 21:33:31.612606   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:33:31.612606   636 solver.cpp:237]     Train net output #1: loss = 0.00264385 (* 1 = 0.00264385 loss)
I1016 21:33:31.612606   636 sgd_solver.cpp:105] Iteration 101900, lr = 0.001
I1016 21:33:40.267030  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:33:40.627318   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_102000.caffemodel
I1016 21:33:40.651316   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_102000.solverstate
I1016 21:33:40.663316   636 solver.cpp:330] Iteration 102000, Testing net (#0)
I1016 21:33:40.663316   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:33:42.910801  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:33:43.000808   636 solver.cpp:397]     Test net output #0: accuracy = 0.9443
I1016 21:33:43.000808   636 solver.cpp:397]     Test net output #1: loss = 0.204515 (* 1 = 0.204515 loss)
I1016 21:33:43.089815   636 solver.cpp:218] Iteration 102000 (8.71392 iter/s, 11.4759s/100 iters), loss = 0.00406181
I1016 21:33:43.089815   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:33:43.089815   636 solver.cpp:237]     Train net output #1: loss = 0.00406154 (* 1 = 0.00406154 loss)
I1016 21:33:43.089815   636 sgd_solver.cpp:105] Iteration 102000, lr = 0.001
I1016 21:33:52.189445   636 solver.cpp:218] Iteration 102100 (10.9894 iter/s, 9.09967s/100 iters), loss = 0.0042621
I1016 21:33:52.189445   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:33:52.189445   636 solver.cpp:237]     Train net output #1: loss = 0.00426183 (* 1 = 0.00426183 loss)
I1016 21:33:52.189445   636 sgd_solver.cpp:105] Iteration 102100, lr = 0.001
I1016 21:34:01.283181   636 solver.cpp:218] Iteration 102200 (10.9972 iter/s, 9.09325s/100 iters), loss = 0.00899262
I1016 21:34:01.283181   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:01.283181   636 solver.cpp:237]     Train net output #1: loss = 0.00899235 (* 1 = 0.00899235 loss)
I1016 21:34:01.283181   636 sgd_solver.cpp:105] Iteration 102200, lr = 0.001
I1016 21:34:10.378556   636 solver.cpp:218] Iteration 102300 (10.9952 iter/s, 9.09486s/100 iters), loss = 0.00221681
I1016 21:34:10.378556   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:10.378556   636 solver.cpp:237]     Train net output #1: loss = 0.00221654 (* 1 = 0.00221654 loss)
I1016 21:34:10.378556   636 sgd_solver.cpp:105] Iteration 102300, lr = 0.001
I1016 21:34:19.470002   636 solver.cpp:218] Iteration 102400 (11.0003 iter/s, 9.09067s/100 iters), loss = 0.00180421
I1016 21:34:19.470002   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:19.470002   636 solver.cpp:237]     Train net output #1: loss = 0.00180394 (* 1 = 0.00180394 loss)
I1016 21:34:19.470002   636 sgd_solver.cpp:105] Iteration 102400, lr = 0.001
I1016 21:34:28.121188  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:34:28.479708   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_102500.caffemodel
I1016 21:34:28.504709   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_102500.solverstate
I1016 21:34:28.517715   636 solver.cpp:330] Iteration 102500, Testing net (#0)
I1016 21:34:28.517715   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:34:30.766911  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:34:30.856933   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 21:34:30.856933   636 solver.cpp:397]     Test net output #1: loss = 0.203366 (* 1 = 0.203366 loss)
I1016 21:34:30.945925   636 solver.cpp:218] Iteration 102500 (8.71422 iter/s, 11.4755s/100 iters), loss = 0.0026834
I1016 21:34:30.945925   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:30.945925   636 solver.cpp:237]     Train net output #1: loss = 0.00268313 (* 1 = 0.00268313 loss)
I1016 21:34:30.945925   636 sgd_solver.cpp:105] Iteration 102500, lr = 0.001
I1016 21:34:40.042686   636 solver.cpp:218] Iteration 102600 (10.9939 iter/s, 9.09597s/100 iters), loss = 0.00213169
I1016 21:34:40.042686   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:40.042686   636 solver.cpp:237]     Train net output #1: loss = 0.00213142 (* 1 = 0.00213142 loss)
I1016 21:34:40.042686   636 sgd_solver.cpp:105] Iteration 102600, lr = 0.001
I1016 21:34:49.141000   636 solver.cpp:218] Iteration 102700 (10.9911 iter/s, 9.09825s/100 iters), loss = 0.00286091
I1016 21:34:49.142001   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:49.142001   636 solver.cpp:237]     Train net output #1: loss = 0.00286063 (* 1 = 0.00286063 loss)
I1016 21:34:49.142001   636 sgd_solver.cpp:105] Iteration 102700, lr = 0.001
I1016 21:34:58.245430   636 solver.cpp:218] Iteration 102800 (10.9849 iter/s, 9.10342s/100 iters), loss = 0.00503096
I1016 21:34:58.245430   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:34:58.245430   636 solver.cpp:237]     Train net output #1: loss = 0.00503069 (* 1 = 0.00503069 loss)
I1016 21:34:58.245430   636 sgd_solver.cpp:105] Iteration 102800, lr = 0.001
I1016 21:35:07.342247   636 solver.cpp:218] Iteration 102900 (10.9936 iter/s, 9.0962s/100 iters), loss = 0.00595214
I1016 21:35:07.342247   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:35:07.342247   636 solver.cpp:237]     Train net output #1: loss = 0.00595188 (* 1 = 0.00595188 loss)
I1016 21:35:07.342247   636 sgd_solver.cpp:105] Iteration 102900, lr = 0.001
I1016 21:35:15.988651  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:35:16.348820   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_103000.caffemodel
I1016 21:35:16.375820   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_103000.solverstate
I1016 21:35:16.387827   636 solver.cpp:330] Iteration 103000, Testing net (#0)
I1016 21:35:16.387827   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:35:18.634397  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:35:18.724501   636 solver.cpp:397]     Test net output #0: accuracy = 0.9446
I1016 21:35:18.724501   636 solver.cpp:397]     Test net output #1: loss = 0.202524 (* 1 = 0.202524 loss)
I1016 21:35:18.812711   636 solver.cpp:218] Iteration 103000 (8.71827 iter/s, 11.4702s/100 iters), loss = 0.0101257
I1016 21:35:18.812711   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:35:18.812711   636 solver.cpp:237]     Train net output #1: loss = 0.0101254 (* 1 = 0.0101254 loss)
I1016 21:35:18.812711   636 sgd_solver.cpp:105] Iteration 103000, lr = 0.001
I1016 21:35:27.903740   636 solver.cpp:218] Iteration 103100 (11.0013 iter/s, 9.08985s/100 iters), loss = 0.0129831
I1016 21:35:27.903740   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:35:27.903740   636 solver.cpp:237]     Train net output #1: loss = 0.0129829 (* 1 = 0.0129829 loss)
I1016 21:35:27.903740   636 sgd_solver.cpp:105] Iteration 103100, lr = 0.001
I1016 21:35:36.996695   636 solver.cpp:218] Iteration 103200 (10.9973 iter/s, 9.09316s/100 iters), loss = 0.0110538
I1016 21:35:36.996695   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:35:36.996695   636 solver.cpp:237]     Train net output #1: loss = 0.0110535 (* 1 = 0.0110535 loss)
I1016 21:35:36.996695   636 sgd_solver.cpp:105] Iteration 103200, lr = 0.001
I1016 21:35:46.084441   636 solver.cpp:218] Iteration 103300 (11.0044 iter/s, 9.08731s/100 iters), loss = 0.00344096
I1016 21:35:46.085441   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:35:46.085441   636 solver.cpp:237]     Train net output #1: loss = 0.00344069 (* 1 = 0.00344069 loss)
I1016 21:35:46.085441   636 sgd_solver.cpp:105] Iteration 103300, lr = 0.001
I1016 21:35:55.179201   636 solver.cpp:218] Iteration 103400 (10.9969 iter/s, 9.09345s/100 iters), loss = 0.00306216
I1016 21:35:55.179201   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:35:55.179201   636 solver.cpp:237]     Train net output #1: loss = 0.00306189 (* 1 = 0.00306189 loss)
I1016 21:35:55.179201   636 sgd_solver.cpp:105] Iteration 103400, lr = 0.001
I1016 21:36:03.824264  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:36:04.182302   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_103500.caffemodel
I1016 21:36:04.209296   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_103500.solverstate
I1016 21:36:04.221297   636 solver.cpp:330] Iteration 103500, Testing net (#0)
I1016 21:36:04.221297   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:36:06.469983  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:36:06.560506   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 21:36:06.560506   636 solver.cpp:397]     Test net output #1: loss = 0.204538 (* 1 = 0.204538 loss)
I1016 21:36:06.648505   636 solver.cpp:218] Iteration 103500 (8.71903 iter/s, 11.4692s/100 iters), loss = 0.00234351
I1016 21:36:06.648505   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:36:06.648505   636 solver.cpp:237]     Train net output #1: loss = 0.00234324 (* 1 = 0.00234324 loss)
I1016 21:36:06.648505   636 sgd_solver.cpp:105] Iteration 103500, lr = 0.001
I1016 21:36:15.749271   636 solver.cpp:218] Iteration 103600 (10.9895 iter/s, 9.09956s/100 iters), loss = 0.00487025
I1016 21:36:15.749271   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:36:15.749271   636 solver.cpp:237]     Train net output #1: loss = 0.00486998 (* 1 = 0.00486998 loss)
I1016 21:36:15.749271   636 sgd_solver.cpp:105] Iteration 103600, lr = 0.001
I1016 21:36:24.848063   636 solver.cpp:218] Iteration 103700 (10.99 iter/s, 9.09917s/100 iters), loss = 0.00718155
I1016 21:36:24.848063   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:36:24.849064   636 solver.cpp:237]     Train net output #1: loss = 0.00718128 (* 1 = 0.00718128 loss)
I1016 21:36:24.849064   636 sgd_solver.cpp:105] Iteration 103700, lr = 0.001
I1016 21:36:33.940716   636 solver.cpp:218] Iteration 103800 (10.9986 iter/s, 9.09204s/100 iters), loss = 0.00727325
I1016 21:36:33.940716   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:36:33.940716   636 solver.cpp:237]     Train net output #1: loss = 0.00727298 (* 1 = 0.00727298 loss)
I1016 21:36:33.940716   636 sgd_solver.cpp:105] Iteration 103800, lr = 0.001
I1016 21:36:43.043459   636 solver.cpp:218] Iteration 103900 (10.9864 iter/s, 9.10217s/100 iters), loss = 0.00141072
I1016 21:36:43.043459   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:36:43.043459   636 solver.cpp:237]     Train net output #1: loss = 0.00141045 (* 1 = 0.00141045 loss)
I1016 21:36:43.043459   636 sgd_solver.cpp:105] Iteration 103900, lr = 0.001
I1016 21:36:51.672775  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:36:52.032810   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_104000.caffemodel
I1016 21:36:52.057811   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_104000.solverstate
I1016 21:36:52.069809   636 solver.cpp:330] Iteration 104000, Testing net (#0)
I1016 21:36:52.069809   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:36:54.316989  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:36:54.406997   636 solver.cpp:397]     Test net output #0: accuracy = 0.9453
I1016 21:36:54.406997   636 solver.cpp:397]     Test net output #1: loss = 0.203548 (* 1 = 0.203548 loss)
I1016 21:36:54.495995   636 solver.cpp:218] Iteration 104000 (8.7326 iter/s, 11.4513s/100 iters), loss = 0.00286689
I1016 21:36:54.495995   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:36:54.495995   636 solver.cpp:237]     Train net output #1: loss = 0.00286662 (* 1 = 0.00286662 loss)
I1016 21:36:54.495995   636 sgd_solver.cpp:105] Iteration 104000, lr = 0.001
I1016 21:37:03.591754   636 solver.cpp:218] Iteration 104100 (10.9945 iter/s, 9.09544s/100 iters), loss = 0.00629249
I1016 21:37:03.591754   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:37:03.591754   636 solver.cpp:237]     Train net output #1: loss = 0.00629222 (* 1 = 0.00629222 loss)
I1016 21:37:03.591754   636 sgd_solver.cpp:105] Iteration 104100, lr = 0.001
I1016 21:37:12.701475   636 solver.cpp:218] Iteration 104200 (10.9781 iter/s, 9.10907s/100 iters), loss = 0.0058184
I1016 21:37:12.701475   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:37:12.701475   636 solver.cpp:237]     Train net output #1: loss = 0.00581813 (* 1 = 0.00581813 loss)
I1016 21:37:12.701475   636 sgd_solver.cpp:105] Iteration 104200, lr = 0.001
I1016 21:37:21.809062   636 solver.cpp:218] Iteration 104300 (10.98 iter/s, 9.10751s/100 iters), loss = 0.00243902
I1016 21:37:21.809062   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:37:21.809062   636 solver.cpp:237]     Train net output #1: loss = 0.00243875 (* 1 = 0.00243875 loss)
I1016 21:37:21.809062   636 sgd_solver.cpp:105] Iteration 104300, lr = 0.001
I1016 21:37:30.912753   636 solver.cpp:218] Iteration 104400 (10.9856 iter/s, 9.10282s/100 iters), loss = 0.000674353
I1016 21:37:30.912753   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:37:30.912753   636 solver.cpp:237]     Train net output #1: loss = 0.000674081 (* 1 = 0.000674081 loss)
I1016 21:37:30.912753   636 sgd_solver.cpp:105] Iteration 104400, lr = 0.001
I1016 21:37:39.569403  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:37:39.929927   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_104500.caffemodel
I1016 21:37:39.954435   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_104500.solverstate
I1016 21:37:39.965435   636 solver.cpp:330] Iteration 104500, Testing net (#0)
I1016 21:37:39.965435   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:37:42.220645  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:37:42.312649   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 21:37:42.312649   636 solver.cpp:397]     Test net output #1: loss = 0.203013 (* 1 = 0.203013 loss)
I1016 21:37:42.400655   636 solver.cpp:218] Iteration 104500 (8.70504 iter/s, 11.4876s/100 iters), loss = 0.00411491
I1016 21:37:42.400655   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:37:42.400655   636 solver.cpp:237]     Train net output #1: loss = 0.00411464 (* 1 = 0.00411464 loss)
I1016 21:37:42.400655   636 sgd_solver.cpp:105] Iteration 104500, lr = 0.001
I1016 21:37:51.507263   636 solver.cpp:218] Iteration 104600 (10.9816 iter/s, 9.10611s/100 iters), loss = 0.00322364
I1016 21:37:51.507263   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:37:51.507263   636 solver.cpp:237]     Train net output #1: loss = 0.00322337 (* 1 = 0.00322337 loss)
I1016 21:37:51.507263   636 sgd_solver.cpp:105] Iteration 104600, lr = 0.001
I1016 21:38:00.616914   636 solver.cpp:218] Iteration 104700 (10.9781 iter/s, 9.10903s/100 iters), loss = 0.0147714
I1016 21:38:00.616914   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:38:00.616914   636 solver.cpp:237]     Train net output #1: loss = 0.0147712 (* 1 = 0.0147712 loss)
I1016 21:38:00.616914   636 sgd_solver.cpp:105] Iteration 104700, lr = 0.001
I1016 21:38:09.729531   636 solver.cpp:218] Iteration 104800 (10.9742 iter/s, 9.11227s/100 iters), loss = 0.00506806
I1016 21:38:09.729531   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:38:09.729531   636 solver.cpp:237]     Train net output #1: loss = 0.00506779 (* 1 = 0.00506779 loss)
I1016 21:38:09.729531   636 sgd_solver.cpp:105] Iteration 104800, lr = 0.001
I1016 21:38:18.835026   636 solver.cpp:218] Iteration 104900 (10.9839 iter/s, 9.10421s/100 iters), loss = 0.00358799
I1016 21:38:18.835026   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:38:18.835026   636 solver.cpp:237]     Train net output #1: loss = 0.00358771 (* 1 = 0.00358771 loss)
I1016 21:38:18.835026   636 sgd_solver.cpp:105] Iteration 104900, lr = 0.001
I1016 21:38:27.497691  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:38:27.857812   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_105000.caffemodel
I1016 21:38:27.883813   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_105000.solverstate
I1016 21:38:27.895332   636 solver.cpp:330] Iteration 105000, Testing net (#0)
I1016 21:38:27.895332   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:38:30.150792  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:38:30.241809   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 21:38:30.241809   636 solver.cpp:397]     Test net output #1: loss = 0.205226 (* 1 = 0.205226 loss)
I1016 21:38:30.330854   636 solver.cpp:218] Iteration 105000 (8.69928 iter/s, 11.4952s/100 iters), loss = 0.00260736
I1016 21:38:30.330854   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:38:30.330854   636 solver.cpp:237]     Train net output #1: loss = 0.00260708 (* 1 = 0.00260708 loss)
I1016 21:38:30.330854   636 sgd_solver.cpp:105] Iteration 105000, lr = 0.001
I1016 21:38:39.438302   636 solver.cpp:218] Iteration 105100 (10.98 iter/s, 9.10746s/100 iters), loss = 0.00459948
I1016 21:38:39.438302   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:38:39.438302   636 solver.cpp:237]     Train net output #1: loss = 0.0045992 (* 1 = 0.0045992 loss)
I1016 21:38:39.438302   636 sgd_solver.cpp:105] Iteration 105100, lr = 0.001
I1016 21:38:48.549026   636 solver.cpp:218] Iteration 105200 (10.977 iter/s, 9.10998s/100 iters), loss = 0.00404209
I1016 21:38:48.549026   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:38:48.549026   636 solver.cpp:237]     Train net output #1: loss = 0.00404182 (* 1 = 0.00404182 loss)
I1016 21:38:48.549026   636 sgd_solver.cpp:105] Iteration 105200, lr = 0.001
I1016 21:38:57.652263   636 solver.cpp:218] Iteration 105300 (10.9858 iter/s, 9.10268s/100 iters), loss = 0.00366542
I1016 21:38:57.652263   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:38:57.652263   636 solver.cpp:237]     Train net output #1: loss = 0.00366514 (* 1 = 0.00366514 loss)
I1016 21:38:57.652263   636 sgd_solver.cpp:105] Iteration 105300, lr = 0.001
I1016 21:39:06.760951   636 solver.cpp:218] Iteration 105400 (10.979 iter/s, 9.1083s/100 iters), loss = 0.00251386
I1016 21:39:06.760951   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:39:06.760951   636 solver.cpp:237]     Train net output #1: loss = 0.00251358 (* 1 = 0.00251358 loss)
I1016 21:39:06.760951   636 sgd_solver.cpp:105] Iteration 105400, lr = 0.001
I1016 21:39:15.423490  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:39:15.784559   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_105500.caffemodel
I1016 21:39:15.810557   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_105500.solverstate
I1016 21:39:15.822558   636 solver.cpp:330] Iteration 105500, Testing net (#0)
I1016 21:39:15.823559   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:39:18.076814  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:39:18.167824   636 solver.cpp:397]     Test net output #0: accuracy = 0.9453
I1016 21:39:18.167824   636 solver.cpp:397]     Test net output #1: loss = 0.205872 (* 1 = 0.205872 loss)
I1016 21:39:18.255820   636 solver.cpp:218] Iteration 105500 (8.69957 iter/s, 11.4948s/100 iters), loss = 0.00260067
I1016 21:39:18.256820   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:39:18.256820   636 solver.cpp:237]     Train net output #1: loss = 0.00260039 (* 1 = 0.00260039 loss)
I1016 21:39:18.256820   636 sgd_solver.cpp:105] Iteration 105500, lr = 0.001
I1016 21:39:27.363373   636 solver.cpp:218] Iteration 105600 (10.9807 iter/s, 9.10688s/100 iters), loss = 0.016055
I1016 21:39:27.363373   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:39:27.363373   636 solver.cpp:237]     Train net output #1: loss = 0.0160548 (* 1 = 0.0160548 loss)
I1016 21:39:27.363373   636 sgd_solver.cpp:105] Iteration 105600, lr = 0.001
I1016 21:39:36.470077   636 solver.cpp:218] Iteration 105700 (10.9826 iter/s, 9.10534s/100 iters), loss = 0.00768534
I1016 21:39:36.470077   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:39:36.470077   636 solver.cpp:237]     Train net output #1: loss = 0.00768506 (* 1 = 0.00768506 loss)
I1016 21:39:36.470077   636 sgd_solver.cpp:105] Iteration 105700, lr = 0.001
I1016 21:39:45.576866   636 solver.cpp:218] Iteration 105800 (10.9814 iter/s, 9.1063s/100 iters), loss = 0.00221494
I1016 21:39:45.576866   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:39:45.576866   636 solver.cpp:237]     Train net output #1: loss = 0.00221466 (* 1 = 0.00221466 loss)
I1016 21:39:45.576866   636 sgd_solver.cpp:105] Iteration 105800, lr = 0.001
I1016 21:39:54.686544   636 solver.cpp:218] Iteration 105900 (10.9773 iter/s, 9.10972s/100 iters), loss = 0.00332394
I1016 21:39:54.686544   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:39:54.686544   636 solver.cpp:237]     Train net output #1: loss = 0.00332367 (* 1 = 0.00332367 loss)
I1016 21:39:54.686544   636 sgd_solver.cpp:105] Iteration 105900, lr = 0.001
I1016 21:40:03.344245  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:40:03.705282   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_106000.caffemodel
I1016 21:40:03.732285   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_106000.solverstate
I1016 21:40:03.743283   636 solver.cpp:330] Iteration 106000, Testing net (#0)
I1016 21:40:03.743283   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:40:06.001482  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:40:06.091497   636 solver.cpp:397]     Test net output #0: accuracy = 0.9452
I1016 21:40:06.091497   636 solver.cpp:397]     Test net output #1: loss = 0.205183 (* 1 = 0.205183 loss)
I1016 21:40:06.179488   636 solver.cpp:218] Iteration 106000 (8.70128 iter/s, 11.4926s/100 iters), loss = 0.00288459
I1016 21:40:06.179488   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:40:06.179488   636 solver.cpp:237]     Train net output #1: loss = 0.00288432 (* 1 = 0.00288432 loss)
I1016 21:40:06.179488   636 sgd_solver.cpp:105] Iteration 106000, lr = 0.001
I1016 21:40:15.288147   636 solver.cpp:218] Iteration 106100 (10.9799 iter/s, 9.10752s/100 iters), loss = 0.00365069
I1016 21:40:15.288147   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:40:15.288147   636 solver.cpp:237]     Train net output #1: loss = 0.00365041 (* 1 = 0.00365041 loss)
I1016 21:40:15.288147   636 sgd_solver.cpp:105] Iteration 106100, lr = 0.001
I1016 21:40:24.390784   636 solver.cpp:218] Iteration 106200 (10.9861 iter/s, 9.1024s/100 iters), loss = 0.00327705
I1016 21:40:24.390784   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:40:24.390784   636 solver.cpp:237]     Train net output #1: loss = 0.00327677 (* 1 = 0.00327677 loss)
I1016 21:40:24.390784   636 sgd_solver.cpp:105] Iteration 106200, lr = 0.001
I1016 21:40:33.494920   636 solver.cpp:218] Iteration 106300 (10.9841 iter/s, 9.1041s/100 iters), loss = 0.00345652
I1016 21:40:33.495908   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:40:33.495908   636 solver.cpp:237]     Train net output #1: loss = 0.00345624 (* 1 = 0.00345624 loss)
I1016 21:40:33.495908   636 sgd_solver.cpp:105] Iteration 106300, lr = 0.001
I1016 21:40:42.602510   636 solver.cpp:218] Iteration 106400 (10.9808 iter/s, 9.10681s/100 iters), loss = 0.00110788
I1016 21:40:42.602510   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:40:42.602510   636 solver.cpp:237]     Train net output #1: loss = 0.0011076 (* 1 = 0.0011076 loss)
I1016 21:40:42.602510   636 sgd_solver.cpp:105] Iteration 106400, lr = 0.001
I1016 21:40:51.258370  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:40:51.618396   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_106500.caffemodel
I1016 21:40:51.643400   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_106500.solverstate
I1016 21:40:51.654400   636 solver.cpp:330] Iteration 106500, Testing net (#0)
I1016 21:40:51.654400   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:40:53.909593  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:40:54.000600   636 solver.cpp:397]     Test net output #0: accuracy = 0.9447
I1016 21:40:54.000600   636 solver.cpp:397]     Test net output #1: loss = 0.206169 (* 1 = 0.206169 loss)
I1016 21:40:54.089617   636 solver.cpp:218] Iteration 106500 (8.70612 iter/s, 11.4862s/100 iters), loss = 0.00486647
I1016 21:40:54.089617   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:40:54.089617   636 solver.cpp:237]     Train net output #1: loss = 0.00486619 (* 1 = 0.00486619 loss)
I1016 21:40:54.089617   636 sgd_solver.cpp:105] Iteration 106500, lr = 0.001
I1016 21:41:03.193910   636 solver.cpp:218] Iteration 106600 (10.9841 iter/s, 9.10405s/100 iters), loss = 0.00201844
I1016 21:41:03.193910   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:41:03.193910   636 solver.cpp:237]     Train net output #1: loss = 0.00201816 (* 1 = 0.00201816 loss)
I1016 21:41:03.193910   636 sgd_solver.cpp:105] Iteration 106600, lr = 0.001
I1016 21:41:12.300657   636 solver.cpp:218] Iteration 106700 (10.9811 iter/s, 9.10657s/100 iters), loss = 0.00390735
I1016 21:41:12.300657   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:41:12.300657   636 solver.cpp:237]     Train net output #1: loss = 0.00390707 (* 1 = 0.00390707 loss)
I1016 21:41:12.300657   636 sgd_solver.cpp:105] Iteration 106700, lr = 0.001
I1016 21:41:21.407552   636 solver.cpp:218] Iteration 106800 (10.9813 iter/s, 9.10643s/100 iters), loss = 0.00122224
I1016 21:41:21.407552   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:41:21.407552   636 solver.cpp:237]     Train net output #1: loss = 0.00122196 (* 1 = 0.00122196 loss)
I1016 21:41:21.407552   636 sgd_solver.cpp:105] Iteration 106800, lr = 0.001
I1016 21:41:30.518270   636 solver.cpp:218] Iteration 106900 (10.9773 iter/s, 9.10974s/100 iters), loss = 0.00212764
I1016 21:41:30.518270   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:41:30.518270   636 solver.cpp:237]     Train net output #1: loss = 0.00212736 (* 1 = 0.00212736 loss)
I1016 21:41:30.518270   636 sgd_solver.cpp:105] Iteration 106900, lr = 0.001
I1016 21:41:39.171874  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:41:39.531924   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_107000.caffemodel
I1016 21:41:39.557924   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_107000.solverstate
I1016 21:41:39.569923   636 solver.cpp:330] Iteration 107000, Testing net (#0)
I1016 21:41:39.569923   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:41:41.826126  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:41:41.916136   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 21:41:41.916136   636 solver.cpp:397]     Test net output #1: loss = 0.204516 (* 1 = 0.204516 loss)
I1016 21:41:42.005136   636 solver.cpp:218] Iteration 107000 (8.70609 iter/s, 11.4862s/100 iters), loss = 0.00261147
I1016 21:41:42.005136   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:41:42.005136   636 solver.cpp:237]     Train net output #1: loss = 0.00261119 (* 1 = 0.00261119 loss)
I1016 21:41:42.005136   636 sgd_solver.cpp:105] Iteration 107000, lr = 0.001
I1016 21:41:51.118836   636 solver.cpp:218] Iteration 107100 (10.9728 iter/s, 9.11349s/100 iters), loss = 0.00650138
I1016 21:41:51.118836   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:41:51.118836   636 solver.cpp:237]     Train net output #1: loss = 0.00650111 (* 1 = 0.00650111 loss)
I1016 21:41:51.118836   636 sgd_solver.cpp:105] Iteration 107100, lr = 0.001
I1016 21:42:00.232542   636 solver.cpp:218] Iteration 107200 (10.973 iter/s, 9.11325s/100 iters), loss = 0.00955804
I1016 21:42:00.232542   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:00.232542   636 solver.cpp:237]     Train net output #1: loss = 0.00955776 (* 1 = 0.00955776 loss)
I1016 21:42:00.232542   636 sgd_solver.cpp:105] Iteration 107200, lr = 0.001
I1016 21:42:09.342286   636 solver.cpp:218] Iteration 107300 (10.9783 iter/s, 9.10886s/100 iters), loss = 0.0037509
I1016 21:42:09.342286   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:09.342286   636 solver.cpp:237]     Train net output #1: loss = 0.00375063 (* 1 = 0.00375063 loss)
I1016 21:42:09.342286   636 sgd_solver.cpp:105] Iteration 107300, lr = 0.001
I1016 21:42:18.449939   636 solver.cpp:218] Iteration 107400 (10.9803 iter/s, 9.10719s/100 iters), loss = 0.0013939
I1016 21:42:18.449939   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:18.449939   636 solver.cpp:237]     Train net output #1: loss = 0.00139362 (* 1 = 0.00139362 loss)
I1016 21:42:18.449939   636 sgd_solver.cpp:105] Iteration 107400, lr = 0.001
I1016 21:42:27.115561  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:42:27.474594   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_107500.caffemodel
I1016 21:42:27.502595   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_107500.solverstate
I1016 21:42:27.514596   636 solver.cpp:330] Iteration 107500, Testing net (#0)
I1016 21:42:27.514596   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:42:29.769857  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:42:29.860860   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 21:42:29.860860   636 solver.cpp:397]     Test net output #1: loss = 0.206454 (* 1 = 0.206454 loss)
I1016 21:42:29.949364   636 solver.cpp:218] Iteration 107500 (8.69679 iter/s, 11.4985s/100 iters), loss = 0.00209928
I1016 21:42:29.949364   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:29.949364   636 solver.cpp:237]     Train net output #1: loss = 0.00209901 (* 1 = 0.00209901 loss)
I1016 21:42:29.949364   636 sgd_solver.cpp:105] Iteration 107500, lr = 0.001
I1016 21:42:39.056124   636 solver.cpp:218] Iteration 107600 (10.9814 iter/s, 9.10632s/100 iters), loss = 0.00415449
I1016 21:42:39.056124   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:39.056124   636 solver.cpp:237]     Train net output #1: loss = 0.00415421 (* 1 = 0.00415421 loss)
I1016 21:42:39.056124   636 sgd_solver.cpp:105] Iteration 107600, lr = 0.001
I1016 21:42:48.159631   636 solver.cpp:218] Iteration 107700 (10.9851 iter/s, 9.10326s/100 iters), loss = 0.00658401
I1016 21:42:48.159631   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:48.160132   636 solver.cpp:237]     Train net output #1: loss = 0.00658373 (* 1 = 0.00658373 loss)
I1016 21:42:48.160132   636 sgd_solver.cpp:105] Iteration 107700, lr = 0.001
I1016 21:42:57.263653   636 solver.cpp:218] Iteration 107800 (10.9846 iter/s, 9.10362s/100 iters), loss = 0.00395229
I1016 21:42:57.263653   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:42:57.263653   636 solver.cpp:237]     Train net output #1: loss = 0.00395201 (* 1 = 0.00395201 loss)
I1016 21:42:57.263653   636 sgd_solver.cpp:105] Iteration 107800, lr = 0.001
I1016 21:43:06.364686   636 solver.cpp:218] Iteration 107900 (10.9883 iter/s, 9.10061s/100 iters), loss = 0.00172084
I1016 21:43:06.364686   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:43:06.364686   636 solver.cpp:237]     Train net output #1: loss = 0.00172056 (* 1 = 0.00172056 loss)
I1016 21:43:06.364686   636 sgd_solver.cpp:105] Iteration 107900, lr = 0.001
I1016 21:43:15.026294  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:43:15.387344   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_108000.caffemodel
I1016 21:43:15.413344   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_108000.solverstate
I1016 21:43:15.425345   636 solver.cpp:330] Iteration 108000, Testing net (#0)
I1016 21:43:15.425345   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:43:17.681493  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:43:17.771502   636 solver.cpp:397]     Test net output #0: accuracy = 0.9444
I1016 21:43:17.771502   636 solver.cpp:397]     Test net output #1: loss = 0.206079 (* 1 = 0.206079 loss)
I1016 21:43:17.860003   636 solver.cpp:218] Iteration 108000 (8.69995 iter/s, 11.4943s/100 iters), loss = 0.00229325
I1016 21:43:17.860003   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:43:17.860003   636 solver.cpp:237]     Train net output #1: loss = 0.00229298 (* 1 = 0.00229298 loss)
I1016 21:43:17.860003   636 sgd_solver.cpp:105] Iteration 108000, lr = 0.001
I1016 21:43:26.967205   636 solver.cpp:218] Iteration 108100 (10.9802 iter/s, 9.10727s/100 iters), loss = 0.00328609
I1016 21:43:26.967205   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:43:26.967205   636 solver.cpp:237]     Train net output #1: loss = 0.00328581 (* 1 = 0.00328581 loss)
I1016 21:43:26.967205   636 sgd_solver.cpp:105] Iteration 108100, lr = 0.001
I1016 21:43:36.074028   636 solver.cpp:218] Iteration 108200 (10.9817 iter/s, 9.10605s/100 iters), loss = 0.00252165
I1016 21:43:36.074028   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:43:36.074028   636 solver.cpp:237]     Train net output #1: loss = 0.00252137 (* 1 = 0.00252137 loss)
I1016 21:43:36.074028   636 sgd_solver.cpp:105] Iteration 108200, lr = 0.001
I1016 21:43:45.190783   636 solver.cpp:218] Iteration 108300 (10.9691 iter/s, 9.1165s/100 iters), loss = 0.00264101
I1016 21:43:45.190783   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:43:45.190783   636 solver.cpp:237]     Train net output #1: loss = 0.00264073 (* 1 = 0.00264073 loss)
I1016 21:43:45.190783   636 sgd_solver.cpp:105] Iteration 108300, lr = 0.001
I1016 21:43:54.305505   636 solver.cpp:218] Iteration 108400 (10.972 iter/s, 9.11414s/100 iters), loss = 0.0094989
I1016 21:43:54.305505   636 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1016 21:43:54.305505   636 solver.cpp:237]     Train net output #1: loss = 0.00949862 (* 1 = 0.00949862 loss)
I1016 21:43:54.305505   636 sgd_solver.cpp:105] Iteration 108400, lr = 0.001
I1016 21:44:02.968559  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:44:03.329604   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_108500.caffemodel
I1016 21:44:03.355598   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_108500.solverstate
I1016 21:44:03.367599   636 solver.cpp:330] Iteration 108500, Testing net (#0)
I1016 21:44:03.367599   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:44:05.614820  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:44:05.706323   636 solver.cpp:397]     Test net output #0: accuracy = 0.9449
I1016 21:44:05.706323   636 solver.cpp:397]     Test net output #1: loss = 0.205534 (* 1 = 0.205534 loss)
I1016 21:44:05.794322   636 solver.cpp:218] Iteration 108500 (8.70477 iter/s, 11.488s/100 iters), loss = 0.00167721
I1016 21:44:05.794322   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:44:05.794322   636 solver.cpp:237]     Train net output #1: loss = 0.00167693 (* 1 = 0.00167693 loss)
I1016 21:44:05.794322   636 sgd_solver.cpp:105] Iteration 108500, lr = 0.001
I1016 21:44:14.897251   636 solver.cpp:218] Iteration 108600 (10.9861 iter/s, 9.10238s/100 iters), loss = 0.00311728
I1016 21:44:14.897251   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:44:14.897251   636 solver.cpp:237]     Train net output #1: loss = 0.00311701 (* 1 = 0.00311701 loss)
I1016 21:44:14.897251   636 sgd_solver.cpp:105] Iteration 108600, lr = 0.001
I1016 21:44:24.012068   636 solver.cpp:218] Iteration 108700 (10.9716 iter/s, 9.11443s/100 iters), loss = 0.00713077
I1016 21:44:24.012068   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:44:24.012068   636 solver.cpp:237]     Train net output #1: loss = 0.00713049 (* 1 = 0.00713049 loss)
I1016 21:44:24.012068   636 sgd_solver.cpp:105] Iteration 108700, lr = 0.001
I1016 21:44:33.119746   636 solver.cpp:218] Iteration 108800 (10.9803 iter/s, 9.10726s/100 iters), loss = 0.00312284
I1016 21:44:33.119746   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:44:33.119746   636 solver.cpp:237]     Train net output #1: loss = 0.00312257 (* 1 = 0.00312257 loss)
I1016 21:44:33.119746   636 sgd_solver.cpp:105] Iteration 108800, lr = 0.001
I1016 21:44:42.233434   636 solver.cpp:218] Iteration 108900 (10.9727 iter/s, 9.11351s/100 iters), loss = 0.00117912
I1016 21:44:42.234434   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:44:42.234434   636 solver.cpp:237]     Train net output #1: loss = 0.00117885 (* 1 = 0.00117885 loss)
I1016 21:44:42.234434   636 sgd_solver.cpp:105] Iteration 108900, lr = 0.001
I1016 21:44:50.892092  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:44:51.253129   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_109000.caffemodel
I1016 21:44:51.279129   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_109000.solverstate
I1016 21:44:51.291133   636 solver.cpp:330] Iteration 109000, Testing net (#0)
I1016 21:44:51.291133   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:44:53.547415  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:44:53.637421   636 solver.cpp:397]     Test net output #0: accuracy = 0.9453
I1016 21:44:53.637421   636 solver.cpp:397]     Test net output #1: loss = 0.207286 (* 1 = 0.207286 loss)
I1016 21:44:53.726472   636 solver.cpp:218] Iteration 109000 (8.70181 iter/s, 11.4919s/100 iters), loss = 0.00434605
I1016 21:44:53.726472   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:44:53.726472   636 solver.cpp:237]     Train net output #1: loss = 0.00434577 (* 1 = 0.00434577 loss)
I1016 21:44:53.726472   636 sgd_solver.cpp:105] Iteration 109000, lr = 0.001
I1016 21:45:02.840051   636 solver.cpp:218] Iteration 109100 (10.9735 iter/s, 9.11284s/100 iters), loss = 0.00650096
I1016 21:45:02.840051   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:02.840051   636 solver.cpp:237]     Train net output #1: loss = 0.00650069 (* 1 = 0.00650069 loss)
I1016 21:45:02.840051   636 sgd_solver.cpp:105] Iteration 109100, lr = 0.001
I1016 21:45:11.945720   636 solver.cpp:218] Iteration 109200 (10.9831 iter/s, 9.10488s/100 iters), loss = 0.00264001
I1016 21:45:11.945720   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:11.945720   636 solver.cpp:237]     Train net output #1: loss = 0.00263974 (* 1 = 0.00263974 loss)
I1016 21:45:11.945720   636 sgd_solver.cpp:105] Iteration 109200, lr = 0.001
I1016 21:45:21.053303   636 solver.cpp:218] Iteration 109300 (10.9797 iter/s, 9.10769s/100 iters), loss = 0.00213655
I1016 21:45:21.053303   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:21.053303   636 solver.cpp:237]     Train net output #1: loss = 0.00213628 (* 1 = 0.00213628 loss)
I1016 21:45:21.053303   636 sgd_solver.cpp:105] Iteration 109300, lr = 0.001
I1016 21:45:30.160477   636 solver.cpp:218] Iteration 109400 (10.9819 iter/s, 9.10587s/100 iters), loss = 0.00223708
I1016 21:45:30.160477   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:30.160477   636 solver.cpp:237]     Train net output #1: loss = 0.00223681 (* 1 = 0.00223681 loss)
I1016 21:45:30.160477   636 sgd_solver.cpp:105] Iteration 109400, lr = 0.001
I1016 21:45:38.822728  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:45:39.183769   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_109500.caffemodel
I1016 21:45:39.208770   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_109500.solverstate
I1016 21:45:39.220769   636 solver.cpp:330] Iteration 109500, Testing net (#0)
I1016 21:45:39.220769   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:45:41.476927  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:45:41.566933   636 solver.cpp:397]     Test net output #0: accuracy = 0.9447
I1016 21:45:41.566933   636 solver.cpp:397]     Test net output #1: loss = 0.205993 (* 1 = 0.205993 loss)
I1016 21:45:41.655938   636 solver.cpp:218] Iteration 109500 (8.69929 iter/s, 11.4952s/100 iters), loss = 0.00277707
I1016 21:45:41.655938   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:41.655938   636 solver.cpp:237]     Train net output #1: loss = 0.0027768 (* 1 = 0.0027768 loss)
I1016 21:45:41.655938   636 sgd_solver.cpp:105] Iteration 109500, lr = 0.001
I1016 21:45:50.768710   636 solver.cpp:218] Iteration 109600 (10.9743 iter/s, 9.11224s/100 iters), loss = 0.00192439
I1016 21:45:50.768710   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:50.768710   636 solver.cpp:237]     Train net output #1: loss = 0.00192412 (* 1 = 0.00192412 loss)
I1016 21:45:50.768710   636 sgd_solver.cpp:105] Iteration 109600, lr = 0.001
I1016 21:45:59.885854   636 solver.cpp:218] Iteration 109700 (10.9686 iter/s, 9.1169s/100 iters), loss = 0.00469327
I1016 21:45:59.885854   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:45:59.885854   636 solver.cpp:237]     Train net output #1: loss = 0.004693 (* 1 = 0.004693 loss)
I1016 21:45:59.885854   636 sgd_solver.cpp:105] Iteration 109700, lr = 0.001
I1016 21:46:08.994024   636 solver.cpp:218] Iteration 109800 (10.9801 iter/s, 9.10739s/100 iters), loss = 0.00320402
I1016 21:46:08.994024   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:46:08.994024   636 solver.cpp:237]     Train net output #1: loss = 0.00320375 (* 1 = 0.00320375 loss)
I1016 21:46:08.994024   636 sgd_solver.cpp:105] Iteration 109800, lr = 0.001
I1016 21:46:18.108270   636 solver.cpp:218] Iteration 109900 (10.9728 iter/s, 9.11346s/100 iters), loss = 0.00147454
I1016 21:46:18.108270   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:46:18.108270   636 solver.cpp:237]     Train net output #1: loss = 0.00147427 (* 1 = 0.00147427 loss)
I1016 21:46:18.108270   636 sgd_solver.cpp:105] Iteration 109900, lr = 0.001
I1016 21:46:26.777596  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:46:27.136703   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_110000.caffemodel
I1016 21:46:27.163707   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_110000.solverstate
I1016 21:46:27.175704   636 solver.cpp:330] Iteration 110000, Testing net (#0)
I1016 21:46:27.175704   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:46:29.433135  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:46:29.524148   636 solver.cpp:397]     Test net output #0: accuracy = 0.9448
I1016 21:46:29.524148   636 solver.cpp:397]     Test net output #1: loss = 0.206482 (* 1 = 0.206482 loss)
I1016 21:46:29.612179   636 solver.cpp:218] Iteration 110000 (8.69287 iter/s, 11.5037s/100 iters), loss = 0.00293745
I1016 21:46:29.612179   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:46:29.612679   636 solver.cpp:237]     Train net output #1: loss = 0.00293718 (* 1 = 0.00293718 loss)
I1016 21:46:29.612679   636 sgd_solver.cpp:105] Iteration 110000, lr = 0.001
I1016 21:46:38.714241   636 solver.cpp:218] Iteration 110100 (10.9873 iter/s, 9.10142s/100 iters), loss = 0.0023036
I1016 21:46:38.714241   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:46:38.714241   636 solver.cpp:237]     Train net output #1: loss = 0.00230333 (* 1 = 0.00230333 loss)
I1016 21:46:38.714241   636 sgd_solver.cpp:105] Iteration 110100, lr = 0.001
I1016 21:46:47.816992   636 solver.cpp:218] Iteration 110200 (10.9864 iter/s, 9.10218s/100 iters), loss = 0.0123985
I1016 21:46:47.816992   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:46:47.816992   636 solver.cpp:237]     Train net output #1: loss = 0.0123982 (* 1 = 0.0123982 loss)
I1016 21:46:47.816992   636 sgd_solver.cpp:105] Iteration 110200, lr = 0.001
I1016 21:46:56.920174   636 solver.cpp:218] Iteration 110300 (10.9856 iter/s, 9.10283s/100 iters), loss = 0.0036858
I1016 21:46:56.920675   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:46:56.920675   636 solver.cpp:237]     Train net output #1: loss = 0.00368553 (* 1 = 0.00368553 loss)
I1016 21:46:56.920675   636 sgd_solver.cpp:105] Iteration 110300, lr = 0.001
I1016 21:47:06.023445   636 solver.cpp:218] Iteration 110400 (10.9858 iter/s, 9.10264s/100 iters), loss = 0.00151282
I1016 21:47:06.023445   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:47:06.023445   636 solver.cpp:237]     Train net output #1: loss = 0.00151255 (* 1 = 0.00151255 loss)
I1016 21:47:06.023445   636 sgd_solver.cpp:105] Iteration 110400, lr = 0.001
I1016 21:47:14.678647  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:47:15.039667   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_110500.caffemodel
I1016 21:47:15.063668   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_110500.solverstate
I1016 21:47:15.075669   636 solver.cpp:330] Iteration 110500, Testing net (#0)
I1016 21:47:15.075669   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:47:17.333117  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:47:17.423620   636 solver.cpp:397]     Test net output #0: accuracy = 0.9442
I1016 21:47:17.423620   636 solver.cpp:397]     Test net output #1: loss = 0.20787 (* 1 = 0.20787 loss)
I1016 21:47:17.512120   636 solver.cpp:218] Iteration 110500 (8.70482 iter/s, 11.4879s/100 iters), loss = 0.00246289
I1016 21:47:17.512120   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:47:17.512120   636 solver.cpp:237]     Train net output #1: loss = 0.00246262 (* 1 = 0.00246262 loss)
I1016 21:47:17.512120   636 sgd_solver.cpp:105] Iteration 110500, lr = 0.001
I1016 21:47:26.622751   636 solver.cpp:218] Iteration 110600 (10.9762 iter/s, 9.11061s/100 iters), loss = 0.0033828
I1016 21:47:26.622751   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:47:26.622751   636 solver.cpp:237]     Train net output #1: loss = 0.00338253 (* 1 = 0.00338253 loss)
I1016 21:47:26.622751   636 sgd_solver.cpp:105] Iteration 110600, lr = 0.001
I1016 21:47:35.728474   636 solver.cpp:218] Iteration 110700 (10.9828 iter/s, 9.10514s/100 iters), loss = 0.00659926
I1016 21:47:35.728474   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:47:35.728474   636 solver.cpp:237]     Train net output #1: loss = 0.00659899 (* 1 = 0.00659899 loss)
I1016 21:47:35.728474   636 sgd_solver.cpp:105] Iteration 110700, lr = 0.001
I1016 21:47:44.837154   636 solver.cpp:218] Iteration 110800 (10.979 iter/s, 9.10832s/100 iters), loss = 0.00281441
I1016 21:47:44.837154   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:47:44.837154   636 solver.cpp:237]     Train net output #1: loss = 0.00281414 (* 1 = 0.00281414 loss)
I1016 21:47:44.837154   636 sgd_solver.cpp:105] Iteration 110800, lr = 0.001
I1016 21:47:53.944794   636 solver.cpp:218] Iteration 110900 (10.9801 iter/s, 9.10735s/100 iters), loss = 0.00155312
I1016 21:47:53.945794   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:47:53.945794   636 solver.cpp:237]     Train net output #1: loss = 0.00155286 (* 1 = 0.00155286 loss)
I1016 21:47:53.945794   636 sgd_solver.cpp:105] Iteration 110900, lr = 0.001
I1016 21:48:02.608495  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:48:02.969522   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_111000.caffemodel
I1016 21:48:02.995523   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_111000.solverstate
I1016 21:48:03.008541   636 solver.cpp:330] Iteration 111000, Testing net (#0)
I1016 21:48:03.008541   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:48:05.265893  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:48:05.356899   636 solver.cpp:397]     Test net output #0: accuracy = 0.9442
I1016 21:48:05.356899   636 solver.cpp:397]     Test net output #1: loss = 0.207879 (* 1 = 0.207879 loss)
I1016 21:48:05.444907   636 solver.cpp:218] Iteration 111000 (8.69618 iter/s, 11.4993s/100 iters), loss = 0.00186707
I1016 21:48:05.444907   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:48:05.444907   636 solver.cpp:237]     Train net output #1: loss = 0.0018668 (* 1 = 0.0018668 loss)
I1016 21:48:05.444907   636 sgd_solver.cpp:105] Iteration 111000, lr = 0.001
I1016 21:48:14.547911   636 solver.cpp:218] Iteration 111100 (10.9863 iter/s, 9.10228s/100 iters), loss = 0.0035822
I1016 21:48:14.547911   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:48:14.547911   636 solver.cpp:237]     Train net output #1: loss = 0.00358193 (* 1 = 0.00358193 loss)
I1016 21:48:14.547911   636 sgd_solver.cpp:105] Iteration 111100, lr = 0.001
I1016 21:48:23.654978   636 solver.cpp:218] Iteration 111200 (10.9807 iter/s, 9.10686s/100 iters), loss = 0.0074728
I1016 21:48:23.654978   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:48:23.654978   636 solver.cpp:237]     Train net output #1: loss = 0.00747254 (* 1 = 0.00747254 loss)
I1016 21:48:23.654978   636 sgd_solver.cpp:105] Iteration 111200, lr = 0.001
I1016 21:48:32.765688   636 solver.cpp:218] Iteration 111300 (10.9768 iter/s, 9.11016s/100 iters), loss = 0.00806825
I1016 21:48:32.765688   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:48:32.765688   636 solver.cpp:237]     Train net output #1: loss = 0.00806798 (* 1 = 0.00806798 loss)
I1016 21:48:32.765688   636 sgd_solver.cpp:105] Iteration 111300, lr = 0.001
I1016 21:48:41.880416   636 solver.cpp:218] Iteration 111400 (10.9718 iter/s, 9.11431s/100 iters), loss = 0.000883633
I1016 21:48:41.880416   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:48:41.880416   636 solver.cpp:237]     Train net output #1: loss = 0.000883362 (* 1 = 0.000883362 loss)
I1016 21:48:41.880416   636 sgd_solver.cpp:105] Iteration 111400, lr = 0.001
I1016 21:48:50.541263  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:48:50.901304   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_111500.caffemodel
I1016 21:48:50.926296   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_111500.solverstate
I1016 21:48:50.937803   636 solver.cpp:330] Iteration 111500, Testing net (#0)
I1016 21:48:50.938302   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:48:53.192461  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:48:53.283465   636 solver.cpp:397]     Test net output #0: accuracy = 0.9447
I1016 21:48:53.283465   636 solver.cpp:397]     Test net output #1: loss = 0.207645 (* 1 = 0.207645 loss)
I1016 21:48:53.371474   636 solver.cpp:218] Iteration 111500 (8.70283 iter/s, 11.4905s/100 iters), loss = 0.00491096
I1016 21:48:53.371474   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:48:53.371474   636 solver.cpp:237]     Train net output #1: loss = 0.00491069 (* 1 = 0.00491069 loss)
I1016 21:48:53.371474   636 sgd_solver.cpp:105] Iteration 111500, lr = 0.001
I1016 21:49:02.481122   636 solver.cpp:218] Iteration 111600 (10.9779 iter/s, 9.10921s/100 iters), loss = 0.00432916
I1016 21:49:02.481122   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:02.481122   636 solver.cpp:237]     Train net output #1: loss = 0.00432889 (* 1 = 0.00432889 loss)
I1016 21:49:02.481122   636 sgd_solver.cpp:105] Iteration 111600, lr = 0.001
I1016 21:49:11.591351   636 solver.cpp:218] Iteration 111700 (10.9779 iter/s, 9.10922s/100 iters), loss = 0.00741079
I1016 21:49:11.591351   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:11.591351   636 solver.cpp:237]     Train net output #1: loss = 0.00741052 (* 1 = 0.00741052 loss)
I1016 21:49:11.591850   636 sgd_solver.cpp:105] Iteration 111700, lr = 0.001
I1016 21:49:20.704663   636 solver.cpp:218] Iteration 111800 (10.9729 iter/s, 9.11332s/100 iters), loss = 0.00273486
I1016 21:49:20.705664   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:20.705664   636 solver.cpp:237]     Train net output #1: loss = 0.00273458 (* 1 = 0.00273458 loss)
I1016 21:49:20.705664   636 sgd_solver.cpp:105] Iteration 111800, lr = 0.001
I1016 21:49:29.813334   636 solver.cpp:218] Iteration 111900 (10.9801 iter/s, 9.10742s/100 iters), loss = 0.00178362
I1016 21:49:29.813334   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:29.813334   636 solver.cpp:237]     Train net output #1: loss = 0.00178335 (* 1 = 0.00178335 loss)
I1016 21:49:29.813334   636 sgd_solver.cpp:105] Iteration 111900, lr = 0.001
I1016 21:49:38.468721  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:49:38.828449   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_112000.caffemodel
I1016 21:49:38.855480   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_112000.solverstate
I1016 21:49:38.867501   636 solver.cpp:330] Iteration 112000, Testing net (#0)
I1016 21:49:38.867501   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:49:41.123773  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:49:41.214802   636 solver.cpp:397]     Test net output #0: accuracy = 0.9444
I1016 21:49:41.214802   636 solver.cpp:397]     Test net output #1: loss = 0.206903 (* 1 = 0.206903 loss)
I1016 21:49:41.302672   636 solver.cpp:218] Iteration 112000 (8.70377 iter/s, 11.4893s/100 iters), loss = 0.00136601
I1016 21:49:41.302672   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:41.302672   636 solver.cpp:237]     Train net output #1: loss = 0.00136574 (* 1 = 0.00136574 loss)
I1016 21:49:41.302672   636 sgd_solver.cpp:105] Iteration 112000, lr = 0.001
I1016 21:49:50.419998   636 solver.cpp:218] Iteration 112100 (10.9686 iter/s, 9.11697s/100 iters), loss = 0.00229236
I1016 21:49:50.419998   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:50.419998   636 solver.cpp:237]     Train net output #1: loss = 0.00229209 (* 1 = 0.00229209 loss)
I1016 21:49:50.419998   636 sgd_solver.cpp:105] Iteration 112100, lr = 0.001
I1016 21:49:59.527698   636 solver.cpp:218] Iteration 112200 (10.9809 iter/s, 9.10672s/100 iters), loss = 0.00278436
I1016 21:49:59.527698   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:49:59.527698   636 solver.cpp:237]     Train net output #1: loss = 0.00278409 (* 1 = 0.00278409 loss)
I1016 21:49:59.527698   636 sgd_solver.cpp:105] Iteration 112200, lr = 0.001
I1016 21:50:08.634346   636 solver.cpp:218] Iteration 112300 (10.9814 iter/s, 9.10631s/100 iters), loss = 0.00190456
I1016 21:50:08.634346   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:50:08.634346   636 solver.cpp:237]     Train net output #1: loss = 0.0019043 (* 1 = 0.0019043 loss)
I1016 21:50:08.634346   636 sgd_solver.cpp:105] Iteration 112300, lr = 0.001
I1016 21:50:17.745977   636 solver.cpp:218] Iteration 112400 (10.9754 iter/s, 9.11129s/100 iters), loss = 0.000707889
I1016 21:50:17.745977   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:50:17.745977   636 solver.cpp:237]     Train net output #1: loss = 0.000707618 (* 1 = 0.000707618 loss)
I1016 21:50:17.745977   636 sgd_solver.cpp:105] Iteration 112400, lr = 0.001
I1016 21:50:26.404161  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:50:26.764679   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_112500.caffemodel
I1016 21:50:26.789680   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_112500.solverstate
I1016 21:50:26.801687   636 solver.cpp:330] Iteration 112500, Testing net (#0)
I1016 21:50:26.801687   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:50:29.057255  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:50:29.148262   636 solver.cpp:397]     Test net output #0: accuracy = 0.9449
I1016 21:50:29.148262   636 solver.cpp:397]     Test net output #1: loss = 0.207213 (* 1 = 0.207213 loss)
I1016 21:50:29.237265   636 solver.cpp:218] Iteration 112500 (8.70312 iter/s, 11.4901s/100 iters), loss = 0.00313164
I1016 21:50:29.237265   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:50:29.237265   636 solver.cpp:237]     Train net output #1: loss = 0.00313137 (* 1 = 0.00313137 loss)
I1016 21:50:29.237265   636 sgd_solver.cpp:105] Iteration 112500, lr = 0.001
I1016 21:50:38.341523   636 solver.cpp:218] Iteration 112600 (10.9835 iter/s, 9.10457s/100 iters), loss = 0.00212127
I1016 21:50:38.342525   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:50:38.342525   636 solver.cpp:237]     Train net output #1: loss = 0.002121 (* 1 = 0.002121 loss)
I1016 21:50:38.342525   636 sgd_solver.cpp:105] Iteration 112600, lr = 0.001
I1016 21:50:47.452265   636 solver.cpp:218] Iteration 112700 (10.9774 iter/s, 9.10964s/100 iters), loss = 0.00558048
I1016 21:50:47.452265   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:50:47.452265   636 solver.cpp:237]     Train net output #1: loss = 0.00558021 (* 1 = 0.00558021 loss)
I1016 21:50:47.452265   636 sgd_solver.cpp:105] Iteration 112700, lr = 0.001
I1016 21:50:56.560982   636 solver.cpp:218] Iteration 112800 (10.9795 iter/s, 9.10788s/100 iters), loss = 0.003283
I1016 21:50:56.560982   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:50:56.560982   636 solver.cpp:237]     Train net output #1: loss = 0.00328273 (* 1 = 0.00328273 loss)
I1016 21:50:56.560982   636 sgd_solver.cpp:105] Iteration 112800, lr = 0.001
I1016 21:51:05.670058   636 solver.cpp:218] Iteration 112900 (10.9786 iter/s, 9.10867s/100 iters), loss = 0.00146447
I1016 21:51:05.670058   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:51:05.670058   636 solver.cpp:237]     Train net output #1: loss = 0.0014642 (* 1 = 0.0014642 loss)
I1016 21:51:05.670058   636 sgd_solver.cpp:105] Iteration 112900, lr = 0.001
I1016 21:51:14.333757  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:51:14.693814   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_113000.caffemodel
I1016 21:51:14.721813   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_113000.solverstate
I1016 21:51:14.733824   636 solver.cpp:330] Iteration 113000, Testing net (#0)
I1016 21:51:14.733824   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:51:16.989215  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:51:17.080220   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 21:51:17.080220   636 solver.cpp:397]     Test net output #1: loss = 0.207241 (* 1 = 0.207241 loss)
I1016 21:51:17.168721   636 solver.cpp:218] Iteration 113000 (8.69699 iter/s, 11.4982s/100 iters), loss = 0.00152258
I1016 21:51:17.168721   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:51:17.168721   636 solver.cpp:237]     Train net output #1: loss = 0.00152231 (* 1 = 0.00152231 loss)
I1016 21:51:17.168721   636 sgd_solver.cpp:105] Iteration 113000, lr = 0.001
I1016 21:51:26.273334   636 solver.cpp:218] Iteration 113100 (10.984 iter/s, 9.10411s/100 iters), loss = 0.00102424
I1016 21:51:26.273334   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:51:26.273334   636 solver.cpp:237]     Train net output #1: loss = 0.00102397 (* 1 = 0.00102397 loss)
I1016 21:51:26.273334   636 sgd_solver.cpp:105] Iteration 113100, lr = 0.001
I1016 21:51:35.643098   636 solver.cpp:218] Iteration 113200 (10.6732 iter/s, 9.36926s/100 iters), loss = 0.00655596
I1016 21:51:35.643098   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:51:35.643098   636 solver.cpp:237]     Train net output #1: loss = 0.00655569 (* 1 = 0.00655569 loss)
I1016 21:51:35.643098   636 sgd_solver.cpp:105] Iteration 113200, lr = 0.001
I1016 21:51:44.821269   636 solver.cpp:218] Iteration 113300 (10.8964 iter/s, 9.17737s/100 iters), loss = 0.00178811
I1016 21:51:44.821269   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:51:44.821269   636 solver.cpp:237]     Train net output #1: loss = 0.00178784 (* 1 = 0.00178784 loss)
I1016 21:51:44.821269   636 sgd_solver.cpp:105] Iteration 113300, lr = 0.001
I1016 21:51:53.951218   636 solver.cpp:218] Iteration 113400 (10.9536 iter/s, 9.12939s/100 iters), loss = 0.00223077
I1016 21:51:53.951218   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:51:53.951218   636 solver.cpp:237]     Train net output #1: loss = 0.0022305 (* 1 = 0.0022305 loss)
I1016 21:51:53.951218   636 sgd_solver.cpp:105] Iteration 113400, lr = 0.001
I1016 21:52:02.634398  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:52:02.995424   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_113500.caffemodel
I1016 21:52:03.020428   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_113500.solverstate
I1016 21:52:03.032428   636 solver.cpp:330] Iteration 113500, Testing net (#0)
I1016 21:52:03.032428   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:52:05.294143  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:52:05.385648   636 solver.cpp:397]     Test net output #0: accuracy = 0.9448
I1016 21:52:05.385648   636 solver.cpp:397]     Test net output #1: loss = 0.207076 (* 1 = 0.207076 loss)
I1016 21:52:05.473665   636 solver.cpp:218] Iteration 113500 (8.67866 iter/s, 11.5225s/100 iters), loss = 0.00308191
I1016 21:52:05.473665   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:52:05.473665   636 solver.cpp:237]     Train net output #1: loss = 0.00308165 (* 1 = 0.00308165 loss)
I1016 21:52:05.473665   636 sgd_solver.cpp:105] Iteration 113500, lr = 0.001
I1016 21:52:14.610538   636 solver.cpp:218] Iteration 113600 (10.945 iter/s, 9.13663s/100 iters), loss = 0.00422278
I1016 21:52:14.611537   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:52:14.611537   636 solver.cpp:237]     Train net output #1: loss = 0.00422251 (* 1 = 0.00422251 loss)
I1016 21:52:14.611537   636 sgd_solver.cpp:105] Iteration 113600, lr = 0.001
I1016 21:52:23.739894   636 solver.cpp:218] Iteration 113700 (10.9552 iter/s, 9.1281s/100 iters), loss = 0.00321139
I1016 21:52:23.739894   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:52:23.739894   636 solver.cpp:237]     Train net output #1: loss = 0.00321112 (* 1 = 0.00321112 loss)
I1016 21:52:23.739894   636 sgd_solver.cpp:105] Iteration 113700, lr = 0.001
I1016 21:52:33.009789   636 solver.cpp:218] Iteration 113800 (10.7881 iter/s, 9.26944s/100 iters), loss = 0.00463328
I1016 21:52:33.009789   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:52:33.009789   636 solver.cpp:237]     Train net output #1: loss = 0.00463301 (* 1 = 0.00463301 loss)
I1016 21:52:33.009789   636 sgd_solver.cpp:105] Iteration 113800, lr = 0.001
I1016 21:52:42.237530   636 solver.cpp:218] Iteration 113900 (10.8352 iter/s, 9.22919s/100 iters), loss = 0.00219729
I1016 21:52:42.237530   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:52:42.237530   636 solver.cpp:237]     Train net output #1: loss = 0.00219703 (* 1 = 0.00219703 loss)
I1016 21:52:42.237530   636 sgd_solver.cpp:105] Iteration 113900, lr = 0.001
I1016 21:52:50.995041  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:52:51.354162   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_114000.caffemodel
I1016 21:52:51.384155   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_114000.solverstate
I1016 21:52:51.394165   636 solver.cpp:330] Iteration 114000, Testing net (#0)
I1016 21:52:51.394165   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:52:53.685283  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:52:53.775293   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 21:52:53.775293   636 solver.cpp:397]     Test net output #1: loss = 0.208041 (* 1 = 0.208041 loss)
I1016 21:52:53.865303   636 solver.cpp:218] Iteration 114000 (8.59863 iter/s, 11.6298s/100 iters), loss = 0.00310932
I1016 21:52:53.865303   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:52:53.865303   636 solver.cpp:237]     Train net output #1: loss = 0.00310906 (* 1 = 0.00310906 loss)
I1016 21:52:53.865303   636 sgd_solver.cpp:105] Iteration 114000, lr = 0.001
I1016 21:53:03.039336   636 solver.cpp:218] Iteration 114100 (10.8999 iter/s, 9.17441s/100 iters), loss = 0.0101024
I1016 21:53:03.039336   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:53:03.039336   636 solver.cpp:237]     Train net output #1: loss = 0.0101022 (* 1 = 0.0101022 loss)
I1016 21:53:03.039336   636 sgd_solver.cpp:105] Iteration 114100, lr = 0.001
I1016 21:53:12.173523   636 solver.cpp:218] Iteration 114200 (10.9464 iter/s, 9.1354s/100 iters), loss = 0.00263996
I1016 21:53:12.173523   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:53:12.173523   636 solver.cpp:237]     Train net output #1: loss = 0.0026397 (* 1 = 0.0026397 loss)
I1016 21:53:12.173523   636 sgd_solver.cpp:105] Iteration 114200, lr = 0.001
I1016 21:53:21.298184   636 solver.cpp:218] Iteration 114300 (10.962 iter/s, 9.12246s/100 iters), loss = 0.00244612
I1016 21:53:21.298184   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:53:21.298184   636 solver.cpp:237]     Train net output #1: loss = 0.00244586 (* 1 = 0.00244586 loss)
I1016 21:53:21.298184   636 sgd_solver.cpp:105] Iteration 114300, lr = 0.001
I1016 21:53:30.431586   636 solver.cpp:218] Iteration 114400 (10.9561 iter/s, 9.1273s/100 iters), loss = 0.000955842
I1016 21:53:30.431586   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:53:30.431586   636 solver.cpp:237]     Train net output #1: loss = 0.000955584 (* 1 = 0.000955584 loss)
I1016 21:53:30.431586   636 sgd_solver.cpp:105] Iteration 114400, lr = 0.001
I1016 21:53:39.104984  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:53:39.465164   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_114500.caffemodel
I1016 21:53:39.485174   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_114500.solverstate
I1016 21:53:39.495182   636 solver.cpp:330] Iteration 114500, Testing net (#0)
I1016 21:53:39.495182   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:53:41.766233  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:53:41.856236   636 solver.cpp:397]     Test net output #0: accuracy = 0.9452
I1016 21:53:41.856236   636 solver.cpp:397]     Test net output #1: loss = 0.208336 (* 1 = 0.208336 loss)
I1016 21:53:41.946243   636 solver.cpp:218] Iteration 114500 (8.68465 iter/s, 11.5146s/100 iters), loss = 0.00137348
I1016 21:53:41.946243   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:53:41.946243   636 solver.cpp:237]     Train net output #1: loss = 0.00137322 (* 1 = 0.00137322 loss)
I1016 21:53:41.946243   636 sgd_solver.cpp:105] Iteration 114500, lr = 0.001
I1016 21:53:51.069893   636 solver.cpp:218] Iteration 114600 (10.9575 iter/s, 9.12615s/100 iters), loss = 0.00262684
I1016 21:53:51.069893   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:53:51.069893   636 solver.cpp:237]     Train net output #1: loss = 0.00262658 (* 1 = 0.00262658 loss)
I1016 21:53:51.069893   636 sgd_solver.cpp:105] Iteration 114600, lr = 0.001
I1016 21:54:00.195041   636 solver.cpp:218] Iteration 114700 (10.9605 iter/s, 9.12365s/100 iters), loss = 0.0018596
I1016 21:54:00.195041   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:00.195041   636 solver.cpp:237]     Train net output #1: loss = 0.00185934 (* 1 = 0.00185934 loss)
I1016 21:54:00.195041   636 sgd_solver.cpp:105] Iteration 114700, lr = 0.001
I1016 21:54:09.324398   636 solver.cpp:218] Iteration 114800 (10.958 iter/s, 9.12575s/100 iters), loss = 0.00220434
I1016 21:54:09.324398   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:09.324398   636 solver.cpp:237]     Train net output #1: loss = 0.00220408 (* 1 = 0.00220408 loss)
I1016 21:54:09.324398   636 sgd_solver.cpp:105] Iteration 114800, lr = 0.001
I1016 21:54:18.444031   636 solver.cpp:218] Iteration 114900 (10.9575 iter/s, 9.1262s/100 iters), loss = 0.00290254
I1016 21:54:18.444031   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:18.444031   636 solver.cpp:237]     Train net output #1: loss = 0.00290228 (* 1 = 0.00290228 loss)
I1016 21:54:18.444031   636 sgd_solver.cpp:105] Iteration 114900, lr = 0.001
I1016 21:54:27.128444  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:54:27.488397   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_115000.caffemodel
I1016 21:54:27.518404   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_115000.solverstate
I1016 21:54:27.528412   636 solver.cpp:330] Iteration 115000, Testing net (#0)
I1016 21:54:27.528412   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:54:29.788720  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:54:29.878724   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 21:54:29.878724   636 solver.cpp:397]     Test net output #1: loss = 0.207019 (* 1 = 0.207019 loss)
I1016 21:54:29.968727   636 solver.cpp:218] Iteration 115000 (8.67751 iter/s, 11.524s/100 iters), loss = 0.00442664
I1016 21:54:29.968727   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:29.968727   636 solver.cpp:237]     Train net output #1: loss = 0.00442638 (* 1 = 0.00442638 loss)
I1016 21:54:29.968727   636 sgd_solver.cpp:105] Iteration 115000, lr = 0.001
I1016 21:54:39.093014   636 solver.cpp:218] Iteration 115100 (10.9586 iter/s, 9.12523s/100 iters), loss = 0.00383229
I1016 21:54:39.093014   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:39.093014   636 solver.cpp:237]     Train net output #1: loss = 0.00383203 (* 1 = 0.00383203 loss)
I1016 21:54:39.093014   636 sgd_solver.cpp:105] Iteration 115100, lr = 0.001
I1016 21:54:48.218452   636 solver.cpp:218] Iteration 115200 (10.9666 iter/s, 9.1186s/100 iters), loss = 0.00508355
I1016 21:54:48.218452   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:48.218452   636 solver.cpp:237]     Train net output #1: loss = 0.0050833 (* 1 = 0.0050833 loss)
I1016 21:54:48.218452   636 sgd_solver.cpp:105] Iteration 115200, lr = 0.001
I1016 21:54:57.336781   636 solver.cpp:218] Iteration 115300 (10.962 iter/s, 9.12241s/100 iters), loss = 0.00336684
I1016 21:54:57.336781   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:54:57.336781   636 solver.cpp:237]     Train net output #1: loss = 0.00336659 (* 1 = 0.00336659 loss)
I1016 21:54:57.336781   636 sgd_solver.cpp:105] Iteration 115300, lr = 0.001
I1016 21:55:06.466997   636 solver.cpp:218] Iteration 115400 (10.9614 iter/s, 9.1229s/100 iters), loss = 0.00138969
I1016 21:55:06.466997   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:55:06.466997   636 solver.cpp:237]     Train net output #1: loss = 0.00138944 (* 1 = 0.00138944 loss)
I1016 21:55:06.466997   636 sgd_solver.cpp:105] Iteration 115400, lr = 0.001
I1016 21:55:15.131592  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:55:15.491991   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_115500.caffemodel
I1016 21:55:15.521996   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_115500.solverstate
I1016 21:55:15.531994   636 solver.cpp:330] Iteration 115500, Testing net (#0)
I1016 21:55:15.531994   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:55:17.793329  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:55:17.883333   636 solver.cpp:397]     Test net output #0: accuracy = 0.9449
I1016 21:55:17.883333   636 solver.cpp:397]     Test net output #1: loss = 0.206924 (* 1 = 0.206924 loss)
I1016 21:55:17.973337   636 solver.cpp:218] Iteration 115500 (8.68494 iter/s, 11.5142s/100 iters), loss = 0.00122877
I1016 21:55:17.973337   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:55:17.973337   636 solver.cpp:237]     Train net output #1: loss = 0.00122851 (* 1 = 0.00122851 loss)
I1016 21:55:17.973337   636 sgd_solver.cpp:105] Iteration 115500, lr = 0.001
I1016 21:55:27.097693   636 solver.cpp:218] Iteration 115600 (10.9659 iter/s, 9.11915s/100 iters), loss = 0.00468288
I1016 21:55:27.097693   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:55:27.097693   636 solver.cpp:237]     Train net output #1: loss = 0.00468263 (* 1 = 0.00468263 loss)
I1016 21:55:27.097693   636 sgd_solver.cpp:105] Iteration 115600, lr = 0.001
I1016 21:55:36.223050   636 solver.cpp:218] Iteration 115700 (10.9561 iter/s, 9.12731s/100 iters), loss = 0.00260344
I1016 21:55:36.223050   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:55:36.223050   636 solver.cpp:237]     Train net output #1: loss = 0.00260319 (* 1 = 0.00260319 loss)
I1016 21:55:36.223050   636 sgd_solver.cpp:105] Iteration 115700, lr = 0.001
I1016 21:55:45.351164   636 solver.cpp:218] Iteration 115800 (10.9602 iter/s, 9.12395s/100 iters), loss = 0.00658207
I1016 21:55:45.351164   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:55:45.351164   636 solver.cpp:237]     Train net output #1: loss = 0.00658181 (* 1 = 0.00658181 loss)
I1016 21:55:45.351164   636 sgd_solver.cpp:105] Iteration 115800, lr = 0.001
I1016 21:55:54.474822   636 solver.cpp:218] Iteration 115900 (10.9605 iter/s, 9.12368s/100 iters), loss = 0.0092019
I1016 21:55:54.474822   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:55:54.474822   636 solver.cpp:237]     Train net output #1: loss = 0.00920165 (* 1 = 0.00920165 loss)
I1016 21:55:54.474822   636 sgd_solver.cpp:105] Iteration 115900, lr = 0.001
I1016 21:56:03.150454  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:56:03.510608   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_116000.caffemodel
I1016 21:56:03.540632   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_116000.solverstate
I1016 21:56:03.550639   636 solver.cpp:330] Iteration 116000, Testing net (#0)
I1016 21:56:03.550639   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:56:05.812925  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:56:05.902930   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 21:56:05.902930   636 solver.cpp:397]     Test net output #1: loss = 0.206641 (* 1 = 0.206641 loss)
I1016 21:56:05.992938   636 solver.cpp:218] Iteration 116000 (8.68045 iter/s, 11.5201s/100 iters), loss = 0.00250631
I1016 21:56:05.992938   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:56:05.992938   636 solver.cpp:237]     Train net output #1: loss = 0.00250606 (* 1 = 0.00250606 loss)
I1016 21:56:05.992938   636 sgd_solver.cpp:105] Iteration 116000, lr = 0.001
I1016 21:56:15.117422   636 solver.cpp:218] Iteration 116100 (10.9642 iter/s, 9.12058s/100 iters), loss = 0.0018255
I1016 21:56:15.117422   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:56:15.117422   636 solver.cpp:237]     Train net output #1: loss = 0.00182525 (* 1 = 0.00182525 loss)
I1016 21:56:15.117422   636 sgd_solver.cpp:105] Iteration 116100, lr = 0.001
I1016 21:56:24.243243   636 solver.cpp:218] Iteration 116200 (10.9569 iter/s, 9.12669s/100 iters), loss = 0.00230527
I1016 21:56:24.243243   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:56:24.243243   636 solver.cpp:237]     Train net output #1: loss = 0.00230502 (* 1 = 0.00230502 loss)
I1016 21:56:24.243243   636 sgd_solver.cpp:105] Iteration 116200, lr = 0.001
I1016 21:56:33.362327   636 solver.cpp:218] Iteration 116300 (10.9599 iter/s, 9.1242s/100 iters), loss = 0.00138786
I1016 21:56:33.362327   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:56:33.362327   636 solver.cpp:237]     Train net output #1: loss = 0.00138761 (* 1 = 0.00138761 loss)
I1016 21:56:33.362327   636 sgd_solver.cpp:105] Iteration 116300, lr = 0.001
I1016 21:56:42.495441   636 solver.cpp:218] Iteration 116400 (10.9554 iter/s, 9.12793s/100 iters), loss = 0.00190545
I1016 21:56:42.495441   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:56:42.495441   636 solver.cpp:237]     Train net output #1: loss = 0.0019052 (* 1 = 0.0019052 loss)
I1016 21:56:42.495441   636 sgd_solver.cpp:105] Iteration 116400, lr = 0.001
I1016 21:56:51.179276  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:56:51.540518   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_116500.caffemodel
I1016 21:56:51.569532   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_116500.solverstate
I1016 21:56:51.579526   636 solver.cpp:330] Iteration 116500, Testing net (#0)
I1016 21:56:51.579526   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:56:53.844553  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:56:53.931555   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 21:56:53.931555   636 solver.cpp:397]     Test net output #1: loss = 0.204924 (* 1 = 0.204924 loss)
I1016 21:56:54.021584   636 solver.cpp:218] Iteration 116500 (8.67765 iter/s, 11.5239s/100 iters), loss = 0.00286883
I1016 21:56:54.021584   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:56:54.021584   636 solver.cpp:237]     Train net output #1: loss = 0.00286857 (* 1 = 0.00286857 loss)
I1016 21:56:54.021584   636 sgd_solver.cpp:105] Iteration 116500, lr = 0.001
I1016 21:57:03.146841   636 solver.cpp:218] Iteration 116600 (10.9608 iter/s, 9.12342s/100 iters), loss = 0.00397985
I1016 21:57:03.146841   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:57:03.146841   636 solver.cpp:237]     Train net output #1: loss = 0.0039796 (* 1 = 0.0039796 loss)
I1016 21:57:03.146841   636 sgd_solver.cpp:105] Iteration 116600, lr = 0.001
I1016 21:57:12.271992   636 solver.cpp:218] Iteration 116700 (10.958 iter/s, 9.12578s/100 iters), loss = 0.00203208
I1016 21:57:12.271992   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:57:12.271992   636 solver.cpp:237]     Train net output #1: loss = 0.00203183 (* 1 = 0.00203183 loss)
I1016 21:57:12.271992   636 sgd_solver.cpp:105] Iteration 116700, lr = 0.001
I1016 21:57:21.397994   636 solver.cpp:218] Iteration 116800 (10.954 iter/s, 9.12906s/100 iters), loss = 0.00470596
I1016 21:57:21.397994   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:57:21.397994   636 solver.cpp:237]     Train net output #1: loss = 0.00470571 (* 1 = 0.00470571 loss)
I1016 21:57:21.397994   636 sgd_solver.cpp:105] Iteration 116800, lr = 0.001
I1016 21:57:30.521981   636 solver.cpp:218] Iteration 116900 (10.9578 iter/s, 9.12593s/100 iters), loss = 0.00156124
I1016 21:57:30.521981   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:57:30.521981   636 solver.cpp:237]     Train net output #1: loss = 0.00156099 (* 1 = 0.00156099 loss)
I1016 21:57:30.521981   636 sgd_solver.cpp:105] Iteration 116900, lr = 0.001
I1016 21:57:39.196943  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:57:39.559002   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_117000.caffemodel
I1016 21:57:39.579010   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_117000.solverstate
I1016 21:57:39.589010   636 solver.cpp:330] Iteration 117000, Testing net (#0)
I1016 21:57:39.589010   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:57:41.850932  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:57:41.950938   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 21:57:41.950938   636 solver.cpp:397]     Test net output #1: loss = 0.206048 (* 1 = 0.206048 loss)
I1016 21:57:42.030941   636 solver.cpp:218] Iteration 117000 (8.68887 iter/s, 11.509s/100 iters), loss = 0.0017232
I1016 21:57:42.030941   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:57:42.030941   636 solver.cpp:237]     Train net output #1: loss = 0.00172295 (* 1 = 0.00172295 loss)
I1016 21:57:42.030941   636 sgd_solver.cpp:105] Iteration 117000, lr = 0.001
I1016 21:57:51.166404   636 solver.cpp:218] Iteration 117100 (10.9531 iter/s, 9.12981s/100 iters), loss = 0.0034206
I1016 21:57:51.166404   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:57:51.166404   636 solver.cpp:237]     Train net output #1: loss = 0.00342034 (* 1 = 0.00342034 loss)
I1016 21:57:51.166404   636 sgd_solver.cpp:105] Iteration 117100, lr = 0.001
I1016 21:58:00.291985   636 solver.cpp:218] Iteration 117200 (10.954 iter/s, 9.12908s/100 iters), loss = 0.00210573
I1016 21:58:00.291985   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:00.291985   636 solver.cpp:237]     Train net output #1: loss = 0.00210548 (* 1 = 0.00210548 loss)
I1016 21:58:00.291985   636 sgd_solver.cpp:105] Iteration 117200, lr = 0.001
I1016 21:58:09.427690   636 solver.cpp:218] Iteration 117300 (10.9546 iter/s, 9.12862s/100 iters), loss = 0.0034939
I1016 21:58:09.427690   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:09.427690   636 solver.cpp:237]     Train net output #1: loss = 0.00349365 (* 1 = 0.00349365 loss)
I1016 21:58:09.427690   636 sgd_solver.cpp:105] Iteration 117300, lr = 0.001
I1016 21:58:18.544678   636 solver.cpp:218] Iteration 117400 (10.9616 iter/s, 9.1228s/100 iters), loss = 0.000837263
I1016 21:58:18.544678   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:18.544678   636 solver.cpp:237]     Train net output #1: loss = 0.000837011 (* 1 = 0.000837011 loss)
I1016 21:58:18.544678   636 sgd_solver.cpp:105] Iteration 117400, lr = 0.001
I1016 21:58:27.228737  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:58:27.593407   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_117500.caffemodel
I1016 21:58:27.618916   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_117500.solverstate
I1016 21:58:27.628918   636 solver.cpp:330] Iteration 117500, Testing net (#0)
I1016 21:58:27.628918   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:58:29.894852  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:58:29.980854   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 21:58:29.980854   636 solver.cpp:397]     Test net output #1: loss = 0.206188 (* 1 = 0.206188 loss)
I1016 21:58:30.070864   636 solver.cpp:218] Iteration 117500 (8.67963 iter/s, 11.5212s/100 iters), loss = 0.00128468
I1016 21:58:30.070864   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:30.070864   636 solver.cpp:237]     Train net output #1: loss = 0.00128442 (* 1 = 0.00128442 loss)
I1016 21:58:30.070864   636 sgd_solver.cpp:105] Iteration 117500, lr = 0.001
I1016 21:58:39.196905   636 solver.cpp:218] Iteration 117600 (10.9614 iter/s, 9.12295s/100 iters), loss = 0.00171888
I1016 21:58:39.196905   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:39.196905   636 solver.cpp:237]     Train net output #1: loss = 0.00171863 (* 1 = 0.00171863 loss)
I1016 21:58:39.196905   636 sgd_solver.cpp:105] Iteration 117600, lr = 0.001
I1016 21:58:48.324371   636 solver.cpp:218] Iteration 117700 (10.9578 iter/s, 9.12589s/100 iters), loss = 0.00231437
I1016 21:58:48.324371   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:48.324371   636 solver.cpp:237]     Train net output #1: loss = 0.00231412 (* 1 = 0.00231412 loss)
I1016 21:58:48.324371   636 sgd_solver.cpp:105] Iteration 117700, lr = 0.001
I1016 21:58:57.482193   636 solver.cpp:218] Iteration 117800 (10.9201 iter/s, 9.15738s/100 iters), loss = 0.00197705
I1016 21:58:57.482193   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:58:57.482193   636 solver.cpp:237]     Train net output #1: loss = 0.0019768 (* 1 = 0.0019768 loss)
I1016 21:58:57.482193   636 sgd_solver.cpp:105] Iteration 117800, lr = 0.001
I1016 21:59:06.621176   636 solver.cpp:218] Iteration 117900 (10.9324 iter/s, 9.1471s/100 iters), loss = 0.00061236
I1016 21:59:06.621176   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:59:06.621176   636 solver.cpp:237]     Train net output #1: loss = 0.00061211 (* 1 = 0.00061211 loss)
I1016 21:59:06.621176   636 sgd_solver.cpp:105] Iteration 117900, lr = 0.001
I1016 21:59:15.296563  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:59:15.665699   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_118000.caffemodel
I1016 21:59:15.690912   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_118000.solverstate
I1016 21:59:15.702917   636 solver.cpp:330] Iteration 118000, Testing net (#0)
I1016 21:59:15.702917   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 21:59:17.965704  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 21:59:18.048207   636 solver.cpp:397]     Test net output #0: accuracy = 0.9448
I1016 21:59:18.048207   636 solver.cpp:397]     Test net output #1: loss = 0.206737 (* 1 = 0.206737 loss)
I1016 21:59:18.144359   636 solver.cpp:218] Iteration 118000 (8.68427 iter/s, 11.5151s/100 iters), loss = 0.00221481
I1016 21:59:18.144359   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:59:18.144359   636 solver.cpp:237]     Train net output #1: loss = 0.00221455 (* 1 = 0.00221455 loss)
I1016 21:59:18.144359   636 sgd_solver.cpp:105] Iteration 118000, lr = 0.001
I1016 21:59:27.273766   636 solver.cpp:218] Iteration 118100 (10.9523 iter/s, 9.13046s/100 iters), loss = 0.00291051
I1016 21:59:27.273766   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:59:27.273766   636 solver.cpp:237]     Train net output #1: loss = 0.00291026 (* 1 = 0.00291026 loss)
I1016 21:59:27.273766   636 sgd_solver.cpp:105] Iteration 118100, lr = 0.001
I1016 21:59:36.440598   636 solver.cpp:218] Iteration 118200 (10.9048 iter/s, 9.17023s/100 iters), loss = 0.00301053
I1016 21:59:36.440598   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:59:36.440598   636 solver.cpp:237]     Train net output #1: loss = 0.00301027 (* 1 = 0.00301027 loss)
I1016 21:59:36.440598   636 sgd_solver.cpp:105] Iteration 118200, lr = 0.001
I1016 21:59:45.624239   636 solver.cpp:218] Iteration 118300 (10.8923 iter/s, 9.18079s/100 iters), loss = 0.00179415
I1016 21:59:45.624239   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:59:45.624239   636 solver.cpp:237]     Train net output #1: loss = 0.0017939 (* 1 = 0.0017939 loss)
I1016 21:59:45.624239   636 sgd_solver.cpp:105] Iteration 118300, lr = 0.001
I1016 21:59:54.799903   636 solver.cpp:218] Iteration 118400 (10.8993 iter/s, 9.17491s/100 iters), loss = 0.00329523
I1016 21:59:54.799903   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 21:59:54.799903   636 solver.cpp:237]     Train net output #1: loss = 0.00329498 (* 1 = 0.00329498 loss)
I1016 21:59:54.799903   636 sgd_solver.cpp:105] Iteration 118400, lr = 0.001
I1016 22:00:03.594508  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:00:03.954396   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_118500.caffemodel
I1016 22:00:03.984532   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_118500.solverstate
I1016 22:00:03.994560   636 solver.cpp:330] Iteration 118500, Testing net (#0)
I1016 22:00:03.994560   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:00:06.266798  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:00:06.357827   636 solver.cpp:397]     Test net output #0: accuracy = 0.9452
I1016 22:00:06.357827   636 solver.cpp:397]     Test net output #1: loss = 0.206721 (* 1 = 0.206721 loss)
I1016 22:00:06.455345   636 solver.cpp:218] Iteration 118500 (8.58282 iter/s, 11.6512s/100 iters), loss = 0.00104775
I1016 22:00:06.455345   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:00:06.455345   636 solver.cpp:237]     Train net output #1: loss = 0.0010475 (* 1 = 0.0010475 loss)
I1016 22:00:06.455345   636 sgd_solver.cpp:105] Iteration 118500, lr = 0.001
I1016 22:00:15.630183   636 solver.cpp:218] Iteration 118600 (10.8948 iter/s, 9.17866s/100 iters), loss = 0.00594543
I1016 22:00:15.630183   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:00:15.630183   636 solver.cpp:237]     Train net output #1: loss = 0.00594518 (* 1 = 0.00594518 loss)
I1016 22:00:15.630183   636 sgd_solver.cpp:105] Iteration 118600, lr = 0.001
I1016 22:00:24.806145   636 solver.cpp:218] Iteration 118700 (10.8946 iter/s, 9.1789s/100 iters), loss = 0.00372007
I1016 22:00:24.806145   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:00:24.806145   636 solver.cpp:237]     Train net output #1: loss = 0.00371982 (* 1 = 0.00371982 loss)
I1016 22:00:24.806145   636 sgd_solver.cpp:105] Iteration 118700, lr = 0.001
I1016 22:00:33.991811   636 solver.cpp:218] Iteration 118800 (10.8868 iter/s, 9.1854s/100 iters), loss = 0.00199352
I1016 22:00:33.991811   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:00:33.991811   636 solver.cpp:237]     Train net output #1: loss = 0.00199328 (* 1 = 0.00199328 loss)
I1016 22:00:33.991811   636 sgd_solver.cpp:105] Iteration 118800, lr = 0.001
I1016 22:00:43.126178   636 solver.cpp:218] Iteration 118900 (10.9581 iter/s, 9.12569s/100 iters), loss = 0.000795019
I1016 22:00:43.126178   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:00:43.126178   636 solver.cpp:237]     Train net output #1: loss = 0.000794771 (* 1 = 0.000794771 loss)
I1016 22:00:43.126178   636 sgd_solver.cpp:105] Iteration 118900, lr = 0.001
I1016 22:00:51.805826  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:00:52.169888   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_119000.caffemodel
I1016 22:00:52.197887   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_119000.solverstate
I1016 22:00:52.209889   636 solver.cpp:330] Iteration 119000, Testing net (#0)
I1016 22:00:52.209889   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:00:54.500247  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:00:54.591256   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 22:00:54.591256   636 solver.cpp:397]     Test net output #1: loss = 0.206154 (* 1 = 0.206154 loss)
I1016 22:00:54.680264   636 solver.cpp:218] Iteration 119000 (8.65548 iter/s, 11.5534s/100 iters), loss = 0.0022739
I1016 22:00:54.680264   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:00:54.680264   636 solver.cpp:237]     Train net output #1: loss = 0.00227365 (* 1 = 0.00227365 loss)
I1016 22:00:54.680264   636 sgd_solver.cpp:105] Iteration 119000, lr = 0.001
I1016 22:01:03.838490   636 solver.cpp:218] Iteration 119100 (10.9197 iter/s, 9.15777s/100 iters), loss = 0.00144165
I1016 22:01:03.838490   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:01:03.838490   636 solver.cpp:237]     Train net output #1: loss = 0.0014414 (* 1 = 0.0014414 loss)
I1016 22:01:03.838490   636 sgd_solver.cpp:105] Iteration 119100, lr = 0.001
I1016 22:01:13.057390   636 solver.cpp:218] Iteration 119200 (10.8484 iter/s, 9.21798s/100 iters), loss = 0.00319445
I1016 22:01:13.057390   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:01:13.057390   636 solver.cpp:237]     Train net output #1: loss = 0.00319421 (* 1 = 0.00319421 loss)
I1016 22:01:13.057390   636 sgd_solver.cpp:105] Iteration 119200, lr = 0.001
I1016 22:01:22.253136   636 solver.cpp:218] Iteration 119300 (10.8743 iter/s, 9.19596s/100 iters), loss = 0.00242018
I1016 22:01:22.253136   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:01:22.254135   636 solver.cpp:237]     Train net output #1: loss = 0.00241993 (* 1 = 0.00241993 loss)
I1016 22:01:22.254135   636 sgd_solver.cpp:105] Iteration 119300, lr = 0.001
I1016 22:01:31.426028   636 solver.cpp:218] Iteration 119400 (10.8976 iter/s, 9.17632s/100 iters), loss = 0.00317551
I1016 22:01:31.426028   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:01:31.426028   636 solver.cpp:237]     Train net output #1: loss = 0.00317526 (* 1 = 0.00317526 loss)
I1016 22:01:31.426028   636 sgd_solver.cpp:105] Iteration 119400, lr = 0.001
I1016 22:01:40.099019  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:01:40.459318   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_119500.caffemodel
I1016 22:01:40.489346   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_119500.solverstate
I1016 22:01:40.499346   636 solver.cpp:330] Iteration 119500, Testing net (#0)
I1016 22:01:40.499346   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:01:42.762339  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:01:42.850843   636 solver.cpp:397]     Test net output #0: accuracy = 0.9452
I1016 22:01:42.850843   636 solver.cpp:397]     Test net output #1: loss = 0.207385 (* 1 = 0.207385 loss)
I1016 22:01:42.940866   636 solver.cpp:218] Iteration 119500 (8.68446 iter/s, 11.5148s/100 iters), loss = 0.00154031
I1016 22:01:42.940866   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:01:42.940866   636 solver.cpp:237]     Train net output #1: loss = 0.00154007 (* 1 = 0.00154007 loss)
I1016 22:01:42.940866   636 sgd_solver.cpp:105] Iteration 119500, lr = 0.001
I1016 22:01:52.135053   636 solver.cpp:218] Iteration 119600 (10.8826 iter/s, 9.18902s/100 iters), loss = 0.00207913
I1016 22:01:52.136055   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:01:52.136055   636 solver.cpp:237]     Train net output #1: loss = 0.00207888 (* 1 = 0.00207888 loss)
I1016 22:01:52.136055   636 sgd_solver.cpp:105] Iteration 119600, lr = 0.001
I1016 22:02:01.283283   636 solver.cpp:218] Iteration 119700 (10.9324 iter/s, 9.14709s/100 iters), loss = 0.00376052
I1016 22:02:01.283783   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:01.283783   636 solver.cpp:237]     Train net output #1: loss = 0.00376028 (* 1 = 0.00376028 loss)
I1016 22:02:01.283783   636 sgd_solver.cpp:105] Iteration 119700, lr = 0.001
I1016 22:02:10.413293   636 solver.cpp:218] Iteration 119800 (10.9529 iter/s, 9.12996s/100 iters), loss = 0.00139899
I1016 22:02:10.413293   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:10.413293   636 solver.cpp:237]     Train net output #1: loss = 0.00139874 (* 1 = 0.00139874 loss)
I1016 22:02:10.414294   636 sgd_solver.cpp:105] Iteration 119800, lr = 0.001
I1016 22:02:19.620702   636 solver.cpp:218] Iteration 119900 (10.8622 iter/s, 9.20626s/100 iters), loss = 0.000812465
I1016 22:02:19.620702   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:19.620702   636 solver.cpp:237]     Train net output #1: loss = 0.000812219 (* 1 = 0.000812219 loss)
I1016 22:02:19.620702   636 sgd_solver.cpp:105] Iteration 119900, lr = 0.001
I1016 22:02:28.318924  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:02:28.671504   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_120000.caffemodel
I1016 22:02:28.701508   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_120000.solverstate
I1016 22:02:28.711509   636 solver.cpp:330] Iteration 120000, Testing net (#0)
I1016 22:02:28.711509   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:02:30.981925  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:02:31.071931   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 22:02:31.071931   636 solver.cpp:397]     Test net output #1: loss = 0.206759 (* 1 = 0.206759 loss)
I1016 22:02:31.161936   636 solver.cpp:218] Iteration 120000 (8.66381 iter/s, 11.5423s/100 iters), loss = 0.00217634
I1016 22:02:31.161936   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:31.161936   636 solver.cpp:237]     Train net output #1: loss = 0.0021761 (* 1 = 0.0021761 loss)
I1016 22:02:31.161936   636 sgd_solver.cpp:105] Iteration 120000, lr = 0.001
I1016 22:02:40.340421   636 solver.cpp:218] Iteration 120100 (10.8974 iter/s, 9.17654s/100 iters), loss = 0.00146629
I1016 22:02:40.340922   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:40.340922   636 solver.cpp:237]     Train net output #1: loss = 0.00146605 (* 1 = 0.00146605 loss)
I1016 22:02:40.340922   636 sgd_solver.cpp:105] Iteration 120100, lr = 0.001
I1016 22:02:49.490991   636 solver.cpp:218] Iteration 120200 (10.9235 iter/s, 9.15458s/100 iters), loss = 0.00361398
I1016 22:02:49.490991   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:49.490991   636 solver.cpp:237]     Train net output #1: loss = 0.00361373 (* 1 = 0.00361373 loss)
I1016 22:02:49.490991   636 sgd_solver.cpp:105] Iteration 120200, lr = 0.001
I1016 22:02:58.634615   636 solver.cpp:218] Iteration 120300 (10.9399 iter/s, 9.14088s/100 iters), loss = 0.0056682
I1016 22:02:58.634615   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:02:58.634615   636 solver.cpp:237]     Train net output #1: loss = 0.00566795 (* 1 = 0.00566795 loss)
I1016 22:02:58.634615   636 sgd_solver.cpp:105] Iteration 120300, lr = 0.001
I1016 22:03:07.946935   636 solver.cpp:218] Iteration 120400 (10.7416 iter/s, 9.30957s/100 iters), loss = 0.00367493
I1016 22:03:07.946935   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:03:07.946935   636 solver.cpp:237]     Train net output #1: loss = 0.00367468 (* 1 = 0.00367468 loss)
I1016 22:03:07.946935   636 sgd_solver.cpp:105] Iteration 120400, lr = 0.001
I1016 22:03:16.680018  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:03:17.040628   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_120500.caffemodel
I1016 22:03:17.070139   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_120500.solverstate
I1016 22:03:17.080147   636 solver.cpp:330] Iteration 120500, Testing net (#0)
I1016 22:03:17.080147   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:03:19.352998  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:03:19.441505   636 solver.cpp:397]     Test net output #0: accuracy = 0.9453
I1016 22:03:19.441505   636 solver.cpp:397]     Test net output #1: loss = 0.207064 (* 1 = 0.207064 loss)
I1016 22:03:19.531513   636 solver.cpp:218] Iteration 120500 (8.62948 iter/s, 11.5882s/100 iters), loss = 0.00181657
I1016 22:03:19.531513   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:03:19.531513   636 solver.cpp:237]     Train net output #1: loss = 0.00181632 (* 1 = 0.00181632 loss)
I1016 22:03:19.531513   636 sgd_solver.cpp:105] Iteration 120500, lr = 0.001
I1016 22:03:28.689864   636 solver.cpp:218] Iteration 120600 (10.9236 iter/s, 9.15449s/100 iters), loss = 0.00278499
I1016 22:03:28.689864   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:03:28.689864   636 solver.cpp:237]     Train net output #1: loss = 0.00278474 (* 1 = 0.00278474 loss)
I1016 22:03:28.689864   636 sgd_solver.cpp:105] Iteration 120600, lr = 0.001
I1016 22:03:37.831507   636 solver.cpp:218] Iteration 120700 (10.9306 iter/s, 9.14861s/100 iters), loss = 0.00464354
I1016 22:03:37.831507   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:03:37.831507   636 solver.cpp:237]     Train net output #1: loss = 0.00464329 (* 1 = 0.00464329 loss)
I1016 22:03:37.831507   636 sgd_solver.cpp:105] Iteration 120700, lr = 0.001
I1016 22:03:46.986205   636 solver.cpp:218] Iteration 120800 (10.9236 iter/s, 9.15448s/100 iters), loss = 0.00117132
I1016 22:03:46.986205   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:03:46.986205   636 solver.cpp:237]     Train net output #1: loss = 0.00117108 (* 1 = 0.00117108 loss)
I1016 22:03:46.986205   636 sgd_solver.cpp:105] Iteration 120800, lr = 0.001
I1016 22:03:56.140677   636 solver.cpp:218] Iteration 120900 (10.9281 iter/s, 9.15076s/100 iters), loss = 0.00361022
I1016 22:03:56.140677   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:03:56.140677   636 solver.cpp:237]     Train net output #1: loss = 0.00360997 (* 1 = 0.00360997 loss)
I1016 22:03:56.140677   636 sgd_solver.cpp:105] Iteration 120900, lr = 0.001
I1016 22:04:04.834571  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:04:05.204452   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_121000.caffemodel
I1016 22:04:05.224459   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_121000.solverstate
I1016 22:04:05.234458   636 solver.cpp:330] Iteration 121000, Testing net (#0)
I1016 22:04:05.234458   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:04:07.507117  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:04:07.596109   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 22:04:07.596109   636 solver.cpp:397]     Test net output #1: loss = 0.207379 (* 1 = 0.207379 loss)
I1016 22:04:07.689115   636 solver.cpp:218] Iteration 121000 (8.66425 iter/s, 11.5417s/100 iters), loss = 0.00251578
I1016 22:04:07.689115   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:04:07.689115   636 solver.cpp:237]     Train net output #1: loss = 0.00251553 (* 1 = 0.00251553 loss)
I1016 22:04:07.689115   636 sgd_solver.cpp:105] Iteration 121000, lr = 0.001
I1016 22:04:16.830356   636 solver.cpp:218] Iteration 121100 (10.9306 iter/s, 9.14864s/100 iters), loss = 0.00205572
I1016 22:04:16.830356   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:04:16.830356   636 solver.cpp:237]     Train net output #1: loss = 0.00205547 (* 1 = 0.00205547 loss)
I1016 22:04:16.830356   636 sgd_solver.cpp:105] Iteration 121100, lr = 0.001
I1016 22:04:25.984107   636 solver.cpp:218] Iteration 121200 (10.9281 iter/s, 9.1507s/100 iters), loss = 0.00354927
I1016 22:04:25.984107   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:04:25.984107   636 solver.cpp:237]     Train net output #1: loss = 0.00354902 (* 1 = 0.00354902 loss)
I1016 22:04:25.984107   636 sgd_solver.cpp:105] Iteration 121200, lr = 0.001
I1016 22:04:35.141157   636 solver.cpp:218] Iteration 121300 (10.9269 iter/s, 9.15177s/100 iters), loss = 0.00208378
I1016 22:04:35.141157   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:04:35.141157   636 solver.cpp:237]     Train net output #1: loss = 0.00208354 (* 1 = 0.00208354 loss)
I1016 22:04:35.141157   636 sgd_solver.cpp:105] Iteration 121300, lr = 0.001
I1016 22:04:44.290108   636 solver.cpp:218] Iteration 121400 (10.9302 iter/s, 9.14894s/100 iters), loss = 0.0020343
I1016 22:04:44.290108   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:04:44.290108   636 solver.cpp:237]     Train net output #1: loss = 0.00203406 (* 1 = 0.00203406 loss)
I1016 22:04:44.290108   636 sgd_solver.cpp:105] Iteration 121400, lr = 0.001
I1016 22:04:52.991284  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:04:53.350440   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_121500.caffemodel
I1016 22:04:53.381433   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_121500.solverstate
I1016 22:04:53.391486   636 solver.cpp:330] Iteration 121500, Testing net (#0)
I1016 22:04:53.391486   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:04:55.657582  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:04:55.745821   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 22:04:55.745821   636 solver.cpp:397]     Test net output #1: loss = 0.206428 (* 1 = 0.206428 loss)
I1016 22:04:55.843344   636 solver.cpp:218] Iteration 121500 (8.65684 iter/s, 11.5516s/100 iters), loss = 0.00251518
I1016 22:04:55.843344   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:04:55.843344   636 solver.cpp:237]     Train net output #1: loss = 0.00251494 (* 1 = 0.00251494 loss)
I1016 22:04:55.843344   636 sgd_solver.cpp:105] Iteration 121500, lr = 0.001
I1016 22:05:04.990672   636 solver.cpp:218] Iteration 121600 (10.9226 iter/s, 9.15531s/100 iters), loss = 0.00204092
I1016 22:05:04.990672   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:05:04.990672   636 solver.cpp:237]     Train net output #1: loss = 0.00204067 (* 1 = 0.00204067 loss)
I1016 22:05:04.990672   636 sgd_solver.cpp:105] Iteration 121600, lr = 0.001
I1016 22:05:14.142627   636 solver.cpp:218] Iteration 121700 (10.9337 iter/s, 9.14604s/100 iters), loss = 0.0024551
I1016 22:05:14.142627   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:05:14.142627   636 solver.cpp:237]     Train net output #1: loss = 0.00245485 (* 1 = 0.00245485 loss)
I1016 22:05:14.142627   636 sgd_solver.cpp:105] Iteration 121700, lr = 0.001
I1016 22:05:23.294173   636 solver.cpp:218] Iteration 121800 (10.9316 iter/s, 9.14782s/100 iters), loss = 0.0042041
I1016 22:05:23.294173   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:05:23.294173   636 solver.cpp:237]     Train net output #1: loss = 0.00420385 (* 1 = 0.00420385 loss)
I1016 22:05:23.294173   636 sgd_solver.cpp:105] Iteration 121800, lr = 0.001
I1016 22:05:32.440363   636 solver.cpp:218] Iteration 121900 (10.9308 iter/s, 9.14844s/100 iters), loss = 0.00145508
I1016 22:05:32.440363   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:05:32.440363   636 solver.cpp:237]     Train net output #1: loss = 0.00145484 (* 1 = 0.00145484 loss)
I1016 22:05:32.440363   636 sgd_solver.cpp:105] Iteration 121900, lr = 0.001
I1016 22:05:41.153744  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:05:41.513590   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_122000.caffemodel
I1016 22:05:41.533594   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_122000.solverstate
I1016 22:05:41.543594   636 solver.cpp:330] Iteration 122000, Testing net (#0)
I1016 22:05:41.543594   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:05:43.814411  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:05:43.904423   636 solver.cpp:397]     Test net output #0: accuracy = 0.9453
I1016 22:05:43.904423   636 solver.cpp:397]     Test net output #1: loss = 0.207349 (* 1 = 0.207349 loss)
I1016 22:05:43.994427   636 solver.cpp:218] Iteration 122000 (8.6551 iter/s, 11.5539s/100 iters), loss = 0.00344026
I1016 22:05:43.994427   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:05:43.994427   636 solver.cpp:237]     Train net output #1: loss = 0.00344002 (* 1 = 0.00344002 loss)
I1016 22:05:43.994427   636 sgd_solver.cpp:105] Iteration 122000, lr = 0.001
I1016 22:05:53.149674   636 solver.cpp:218] Iteration 122100 (10.9182 iter/s, 9.159s/100 iters), loss = 0.0050323
I1016 22:05:53.149674   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:05:53.149674   636 solver.cpp:237]     Train net output #1: loss = 0.00503205 (* 1 = 0.00503205 loss)
I1016 22:05:53.149674   636 sgd_solver.cpp:105] Iteration 122100, lr = 0.001
I1016 22:06:02.315429   636 solver.cpp:218] Iteration 122200 (10.9179 iter/s, 9.15928s/100 iters), loss = 0.00496326
I1016 22:06:02.315429   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:02.315429   636 solver.cpp:237]     Train net output #1: loss = 0.00496302 (* 1 = 0.00496302 loss)
I1016 22:06:02.315429   636 sgd_solver.cpp:105] Iteration 122200, lr = 0.001
I1016 22:06:11.478293   636 solver.cpp:218] Iteration 122300 (10.9136 iter/s, 9.16285s/100 iters), loss = 0.00389609
I1016 22:06:11.478293   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:11.478293   636 solver.cpp:237]     Train net output #1: loss = 0.00389585 (* 1 = 0.00389585 loss)
I1016 22:06:11.478293   636 sgd_solver.cpp:105] Iteration 122300, lr = 0.001
I1016 22:06:20.643573   636 solver.cpp:218] Iteration 122400 (10.9134 iter/s, 9.16302s/100 iters), loss = 0.000775178
I1016 22:06:20.643573   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:20.643573   636 solver.cpp:237]     Train net output #1: loss = 0.000774938 (* 1 = 0.000774938 loss)
I1016 22:06:20.643573   636 sgd_solver.cpp:105] Iteration 122400, lr = 0.001
I1016 22:06:29.352702  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:06:29.716058   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_122500.caffemodel
I1016 22:06:29.739784   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_122500.solverstate
I1016 22:06:29.749761   636 solver.cpp:330] Iteration 122500, Testing net (#0)
I1016 22:06:29.749761   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:06:32.021373  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:06:32.112900   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 22:06:32.112900   636 solver.cpp:397]     Test net output #1: loss = 0.207491 (* 1 = 0.207491 loss)
I1016 22:06:32.196184   636 solver.cpp:218] Iteration 122500 (8.65293 iter/s, 11.5568s/100 iters), loss = 0.00193197
I1016 22:06:32.196184   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:32.196184   636 solver.cpp:237]     Train net output #1: loss = 0.00193173 (* 1 = 0.00193173 loss)
I1016 22:06:32.196184   636 sgd_solver.cpp:105] Iteration 122500, lr = 0.001
I1016 22:06:41.353075   636 solver.cpp:218] Iteration 122600 (10.9186 iter/s, 9.15866s/100 iters), loss = 0.00197317
I1016 22:06:41.353075   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:41.353075   636 solver.cpp:237]     Train net output #1: loss = 0.00197292 (* 1 = 0.00197292 loss)
I1016 22:06:41.353075   636 sgd_solver.cpp:105] Iteration 122600, lr = 0.001
I1016 22:06:50.515113   636 solver.cpp:218] Iteration 122700 (10.9226 iter/s, 9.15531s/100 iters), loss = 0.00262315
I1016 22:06:50.515113   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:50.515113   636 solver.cpp:237]     Train net output #1: loss = 0.00262291 (* 1 = 0.00262291 loss)
I1016 22:06:50.515113   636 sgd_solver.cpp:105] Iteration 122700, lr = 0.001
I1016 22:06:59.672046   636 solver.cpp:218] Iteration 122800 (10.9222 iter/s, 9.15568s/100 iters), loss = 0.00296317
I1016 22:06:59.672046   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:06:59.673048   636 solver.cpp:237]     Train net output #1: loss = 0.00296292 (* 1 = 0.00296292 loss)
I1016 22:06:59.673048   636 sgd_solver.cpp:105] Iteration 122800, lr = 0.001
I1016 22:07:08.836329   636 solver.cpp:218] Iteration 122900 (10.9138 iter/s, 9.16273s/100 iters), loss = 0.00211166
I1016 22:07:08.836329   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:07:08.836329   636 solver.cpp:237]     Train net output #1: loss = 0.00211142 (* 1 = 0.00211142 loss)
I1016 22:07:08.836329   636 sgd_solver.cpp:105] Iteration 122900, lr = 0.001
I1016 22:07:17.548594  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:07:17.911190   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_123000.caffemodel
I1016 22:07:17.937042   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_123000.solverstate
I1016 22:07:17.949556   636 solver.cpp:330] Iteration 123000, Testing net (#0)
I1016 22:07:17.949556   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:07:20.218324  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:07:20.309314   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 22:07:20.309314   636 solver.cpp:397]     Test net output #1: loss = 0.207663 (* 1 = 0.207663 loss)
I1016 22:07:20.398319   636 solver.cpp:218] Iteration 123000 (8.64927 iter/s, 11.5617s/100 iters), loss = 0.00175123
I1016 22:07:20.398319   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:07:20.398319   636 solver.cpp:237]     Train net output #1: loss = 0.00175099 (* 1 = 0.00175099 loss)
I1016 22:07:20.398319   636 sgd_solver.cpp:105] Iteration 123000, lr = 0.001
I1016 22:07:29.564455   636 solver.cpp:218] Iteration 123100 (10.9103 iter/s, 9.16564s/100 iters), loss = 0.00113699
I1016 22:07:29.564455   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:07:29.564455   636 solver.cpp:237]     Train net output #1: loss = 0.00113675 (* 1 = 0.00113675 loss)
I1016 22:07:29.564455   636 sgd_solver.cpp:105] Iteration 123100, lr = 0.001
I1016 22:07:38.716697   636 solver.cpp:218] Iteration 123200 (10.9185 iter/s, 9.15878s/100 iters), loss = 0.00412326
I1016 22:07:38.716697   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:07:38.716697   636 solver.cpp:237]     Train net output #1: loss = 0.00412302 (* 1 = 0.00412302 loss)
I1016 22:07:38.716697   636 sgd_solver.cpp:105] Iteration 123200, lr = 0.001
I1016 22:07:47.883239   636 solver.cpp:218] Iteration 123300 (10.9129 iter/s, 9.16348s/100 iters), loss = 0.00157727
I1016 22:07:47.883239   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:07:47.883239   636 solver.cpp:237]     Train net output #1: loss = 0.00157703 (* 1 = 0.00157703 loss)
I1016 22:07:47.883239   636 sgd_solver.cpp:105] Iteration 123300, lr = 0.001
I1016 22:07:57.040688   636 solver.cpp:218] Iteration 123400 (10.9148 iter/s, 9.16185s/100 iters), loss = 0.00125946
I1016 22:07:57.040688   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:07:57.040688   636 solver.cpp:237]     Train net output #1: loss = 0.00125922 (* 1 = 0.00125922 loss)
I1016 22:07:57.040688   636 sgd_solver.cpp:105] Iteration 123400, lr = 0.001
I1016 22:08:05.765177  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:08:06.117312   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_123500.caffemodel
I1016 22:08:06.147315   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_123500.solverstate
I1016 22:08:06.167345   636 solver.cpp:330] Iteration 123500, Testing net (#0)
I1016 22:08:06.167345   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:08:08.429672  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:08:08.519690   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:08:08.519690   636 solver.cpp:397]     Test net output #1: loss = 0.207273 (* 1 = 0.207273 loss)
I1016 22:08:08.614642   636 solver.cpp:218] Iteration 123500 (8.64629 iter/s, 11.5657s/100 iters), loss = 0.00148992
I1016 22:08:08.614642   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:08:08.614642   636 solver.cpp:237]     Train net output #1: loss = 0.00148968 (* 1 = 0.00148968 loss)
I1016 22:08:08.614642   636 sgd_solver.cpp:105] Iteration 123500, lr = 0.001
I1016 22:08:17.773566   636 solver.cpp:218] Iteration 123600 (10.9192 iter/s, 9.15818s/100 iters), loss = 0.00129714
I1016 22:08:17.773566   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:08:17.773566   636 solver.cpp:237]     Train net output #1: loss = 0.0012969 (* 1 = 0.0012969 loss)
I1016 22:08:17.773566   636 sgd_solver.cpp:105] Iteration 123600, lr = 0.001
I1016 22:08:26.938979   636 solver.cpp:218] Iteration 123700 (10.9127 iter/s, 9.16365s/100 iters), loss = 0.00288228
I1016 22:08:26.938979   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:08:26.938979   636 solver.cpp:237]     Train net output #1: loss = 0.00288203 (* 1 = 0.00288203 loss)
I1016 22:08:26.938979   636 sgd_solver.cpp:105] Iteration 123700, lr = 0.001
I1016 22:08:36.090260   636 solver.cpp:218] Iteration 123800 (10.9284 iter/s, 9.15047s/100 iters), loss = 0.0050098
I1016 22:08:36.090260   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:08:36.090260   636 solver.cpp:237]     Train net output #1: loss = 0.00500955 (* 1 = 0.00500955 loss)
I1016 22:08:36.090260   636 sgd_solver.cpp:105] Iteration 123800, lr = 0.001
I1016 22:08:45.246188   636 solver.cpp:218] Iteration 123900 (10.9159 iter/s, 9.16092s/100 iters), loss = 0.00120483
I1016 22:08:45.246188   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:08:45.246188   636 solver.cpp:237]     Train net output #1: loss = 0.00120459 (* 1 = 0.00120459 loss)
I1016 22:08:45.246188   636 sgd_solver.cpp:105] Iteration 123900, lr = 0.001
I1016 22:08:53.952386  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:08:54.317217   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_124000.caffemodel
I1016 22:08:54.338310   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_124000.solverstate
I1016 22:08:54.348311   636 solver.cpp:330] Iteration 124000, Testing net (#0)
I1016 22:08:54.348311   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:08:56.619524  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:08:56.703303   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 22:08:56.703303   636 solver.cpp:397]     Test net output #1: loss = 0.208493 (* 1 = 0.208493 loss)
I1016 22:08:56.793309   636 solver.cpp:218] Iteration 124000 (8.66034 iter/s, 11.5469s/100 iters), loss = 0.00157759
I1016 22:08:56.793309   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:08:56.793309   636 solver.cpp:237]     Train net output #1: loss = 0.00157735 (* 1 = 0.00157735 loss)
I1016 22:08:56.793309   636 sgd_solver.cpp:105] Iteration 124000, lr = 0.001
I1016 22:09:05.948415   636 solver.cpp:218] Iteration 124100 (10.9199 iter/s, 9.15756s/100 iters), loss = 0.00116686
I1016 22:09:05.948415   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:09:05.948415   636 solver.cpp:237]     Train net output #1: loss = 0.00116661 (* 1 = 0.00116661 loss)
I1016 22:09:05.948415   636 sgd_solver.cpp:105] Iteration 124100, lr = 0.001
I1016 22:09:15.111884   636 solver.cpp:218] Iteration 124200 (10.9195 iter/s, 9.15789s/100 iters), loss = 0.00468353
I1016 22:09:15.111884   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:09:15.111884   636 solver.cpp:237]     Train net output #1: loss = 0.00468328 (* 1 = 0.00468328 loss)
I1016 22:09:15.111884   636 sgd_solver.cpp:105] Iteration 124200, lr = 0.001
I1016 22:09:24.269661   636 solver.cpp:218] Iteration 124300 (10.9255 iter/s, 9.15288s/100 iters), loss = 0.00146561
I1016 22:09:24.269661   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:09:24.269661   636 solver.cpp:237]     Train net output #1: loss = 0.00146536 (* 1 = 0.00146536 loss)
I1016 22:09:24.269661   636 sgd_solver.cpp:105] Iteration 124300, lr = 0.001
I1016 22:09:33.430312   636 solver.cpp:218] Iteration 124400 (10.9123 iter/s, 9.16401s/100 iters), loss = 0.000949952
I1016 22:09:33.430312   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:09:33.430312   636 solver.cpp:237]     Train net output #1: loss = 0.000949704 (* 1 = 0.000949704 loss)
I1016 22:09:33.430312   636 sgd_solver.cpp:105] Iteration 124400, lr = 0.001
I1016 22:09:42.133661  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:09:42.503729   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_124500.caffemodel
I1016 22:09:42.523732   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_124500.solverstate
I1016 22:09:42.543732   636 solver.cpp:330] Iteration 124500, Testing net (#0)
I1016 22:09:42.543732   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:09:44.810827  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:09:44.894829   636 solver.cpp:397]     Test net output #0: accuracy = 0.9463
I1016 22:09:44.894829   636 solver.cpp:397]     Test net output #1: loss = 0.207045 (* 1 = 0.207045 loss)
I1016 22:09:44.984834   636 solver.cpp:218] Iteration 124500 (8.65355 iter/s, 11.556s/100 iters), loss = 0.00200875
I1016 22:09:44.984834   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:09:44.984834   636 solver.cpp:237]     Train net output #1: loss = 0.0020085 (* 1 = 0.0020085 loss)
I1016 22:09:44.984834   636 sgd_solver.cpp:105] Iteration 124500, lr = 0.001
I1016 22:09:54.141193   636 solver.cpp:218] Iteration 124600 (10.9223 iter/s, 9.15554s/100 iters), loss = 0.00191592
I1016 22:09:54.141193   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:09:54.141193   636 solver.cpp:237]     Train net output #1: loss = 0.00191567 (* 1 = 0.00191567 loss)
I1016 22:09:54.141193   636 sgd_solver.cpp:105] Iteration 124600, lr = 0.001
I1016 22:10:03.323520   636 solver.cpp:218] Iteration 124700 (10.8928 iter/s, 9.18038s/100 iters), loss = 0.00231064
I1016 22:10:03.323520   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:10:03.323520   636 solver.cpp:237]     Train net output #1: loss = 0.00231039 (* 1 = 0.00231039 loss)
I1016 22:10:03.323520   636 sgd_solver.cpp:105] Iteration 124700, lr = 0.001
I1016 22:10:12.477588   636 solver.cpp:218] Iteration 124800 (10.9281 iter/s, 9.1507s/100 iters), loss = 0.00269549
I1016 22:10:12.477588   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:10:12.477588   636 solver.cpp:237]     Train net output #1: loss = 0.00269524 (* 1 = 0.00269524 loss)
I1016 22:10:12.477588   636 sgd_solver.cpp:105] Iteration 124800, lr = 0.001
I1016 22:10:21.626690   636 solver.cpp:218] Iteration 124900 (10.9305 iter/s, 9.14875s/100 iters), loss = 0.00142216
I1016 22:10:21.626690   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:10:21.626690   636 solver.cpp:237]     Train net output #1: loss = 0.00142191 (* 1 = 0.00142191 loss)
I1016 22:10:21.626690   636 sgd_solver.cpp:105] Iteration 124900, lr = 0.001
I1016 22:10:30.322434  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:10:30.682368   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_125000.caffemodel
I1016 22:10:30.712376   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_125000.solverstate
I1016 22:10:30.722383   636 solver.cpp:330] Iteration 125000, Testing net (#0)
I1016 22:10:30.722383   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:10:32.983577  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:10:33.073568   636 solver.cpp:397]     Test net output #0: accuracy = 0.9467
I1016 22:10:33.073568   636 solver.cpp:397]     Test net output #1: loss = 0.205819 (* 1 = 0.205819 loss)
I1016 22:10:33.163856   636 solver.cpp:218] Iteration 125000 (8.66822 iter/s, 11.5364s/100 iters), loss = 0.00120693
I1016 22:10:33.163856   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:10:33.163856   636 solver.cpp:237]     Train net output #1: loss = 0.00120668 (* 1 = 0.00120668 loss)
I1016 22:10:33.163856   636 sgd_solver.cpp:105] Iteration 125000, lr = 0.001
I1016 22:10:42.327373   636 solver.cpp:218] Iteration 125100 (10.9144 iter/s, 9.16217s/100 iters), loss = 0.00358052
I1016 22:10:42.327373   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:10:42.327373   636 solver.cpp:237]     Train net output #1: loss = 0.00358027 (* 1 = 0.00358027 loss)
I1016 22:10:42.327373   636 sgd_solver.cpp:105] Iteration 125100, lr = 0.001
I1016 22:10:51.495766   636 solver.cpp:218] Iteration 125200 (10.908 iter/s, 9.16759s/100 iters), loss = 0.00253364
I1016 22:10:51.495766   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:10:51.495766   636 solver.cpp:237]     Train net output #1: loss = 0.00253339 (* 1 = 0.00253339 loss)
I1016 22:10:51.495766   636 sgd_solver.cpp:105] Iteration 125200, lr = 0.001
I1016 22:11:00.660604   636 solver.cpp:218] Iteration 125300 (10.9121 iter/s, 9.1641s/100 iters), loss = 0.00130342
I1016 22:11:00.660604   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:00.660604   636 solver.cpp:237]     Train net output #1: loss = 0.00130318 (* 1 = 0.00130318 loss)
I1016 22:11:00.660604   636 sgd_solver.cpp:105] Iteration 125300, lr = 0.001
I1016 22:11:09.823179   636 solver.cpp:218] Iteration 125400 (10.9143 iter/s, 9.16229s/100 iters), loss = 0.000753899
I1016 22:11:09.823179   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:09.823179   636 solver.cpp:237]     Train net output #1: loss = 0.000753655 (* 1 = 0.000753655 loss)
I1016 22:11:09.823179   636 sgd_solver.cpp:105] Iteration 125400, lr = 0.001
I1016 22:11:18.540937  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:11:18.902974   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_125500.caffemodel
I1016 22:11:18.927975   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_125500.solverstate
I1016 22:11:18.939976   636 solver.cpp:330] Iteration 125500, Testing net (#0)
I1016 22:11:18.939976   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:11:21.207165  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:11:21.298183   636 solver.cpp:397]     Test net output #0: accuracy = 0.9463
I1016 22:11:21.298183   636 solver.cpp:397]     Test net output #1: loss = 0.207106 (* 1 = 0.207106 loss)
I1016 22:11:21.388180   636 solver.cpp:218] Iteration 125500 (8.6477 iter/s, 11.5638s/100 iters), loss = 0.00149244
I1016 22:11:21.388180   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:21.388180   636 solver.cpp:237]     Train net output #1: loss = 0.00149219 (* 1 = 0.00149219 loss)
I1016 22:11:21.388180   636 sgd_solver.cpp:105] Iteration 125500, lr = 0.001
I1016 22:11:30.558434   636 solver.cpp:218] Iteration 125600 (10.9053 iter/s, 9.16984s/100 iters), loss = 0.00281347
I1016 22:11:30.558434   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:30.558434   636 solver.cpp:237]     Train net output #1: loss = 0.00281322 (* 1 = 0.00281322 loss)
I1016 22:11:30.558434   636 sgd_solver.cpp:105] Iteration 125600, lr = 0.001
I1016 22:11:39.731639   636 solver.cpp:218] Iteration 125700 (10.9021 iter/s, 9.17254s/100 iters), loss = 0.00147165
I1016 22:11:39.731639   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:39.731639   636 solver.cpp:237]     Train net output #1: loss = 0.0014714 (* 1 = 0.0014714 loss)
I1016 22:11:39.731639   636 sgd_solver.cpp:105] Iteration 125700, lr = 0.001
I1016 22:11:48.996915   636 solver.cpp:218] Iteration 125800 (10.7927 iter/s, 9.26551s/100 iters), loss = 0.00310955
I1016 22:11:48.996915   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:48.997915   636 solver.cpp:237]     Train net output #1: loss = 0.0031093 (* 1 = 0.0031093 loss)
I1016 22:11:48.997915   636 sgd_solver.cpp:105] Iteration 125800, lr = 0.001
I1016 22:11:58.166821   636 solver.cpp:218] Iteration 125900 (10.9068 iter/s, 9.16861s/100 iters), loss = 0.00138331
I1016 22:11:58.166821   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:11:58.166821   636 solver.cpp:237]     Train net output #1: loss = 0.00138306 (* 1 = 0.00138306 loss)
I1016 22:11:58.166821   636 sgd_solver.cpp:105] Iteration 125900, lr = 0.001
I1016 22:12:06.882532  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:12:07.244544   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_126000.caffemodel
I1016 22:12:07.270552   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_126000.solverstate
I1016 22:12:07.282553   636 solver.cpp:330] Iteration 126000, Testing net (#0)
I1016 22:12:07.282553   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:12:09.549763  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:12:09.640322   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 22:12:09.640322   636 solver.cpp:397]     Test net output #1: loss = 0.2061 (* 1 = 0.2061 loss)
I1016 22:12:09.729827   636 solver.cpp:218] Iteration 126000 (8.6486 iter/s, 11.5626s/100 iters), loss = 0.00373399
I1016 22:12:09.729827   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:12:09.729827   636 solver.cpp:237]     Train net output #1: loss = 0.00373375 (* 1 = 0.00373375 loss)
I1016 22:12:09.729827   636 sgd_solver.cpp:105] Iteration 126000, lr = 0.001
I1016 22:12:18.898320   636 solver.cpp:218] Iteration 126100 (10.9074 iter/s, 9.16809s/100 iters), loss = 0.00217343
I1016 22:12:18.898320   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:12:18.898320   636 solver.cpp:237]     Train net output #1: loss = 0.00217318 (* 1 = 0.00217318 loss)
I1016 22:12:18.898320   636 sgd_solver.cpp:105] Iteration 126100, lr = 0.001
I1016 22:12:28.070930   636 solver.cpp:218] Iteration 126200 (10.9027 iter/s, 9.17203s/100 iters), loss = 0.00684103
I1016 22:12:28.070930   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:12:28.070930   636 solver.cpp:237]     Train net output #1: loss = 0.00684079 (* 1 = 0.00684079 loss)
I1016 22:12:28.070930   636 sgd_solver.cpp:105] Iteration 126200, lr = 0.001
I1016 22:12:37.241750   636 solver.cpp:218] Iteration 126300 (10.905 iter/s, 9.17013s/100 iters), loss = 0.00184323
I1016 22:12:37.241750   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:12:37.241750   636 solver.cpp:237]     Train net output #1: loss = 0.00184298 (* 1 = 0.00184298 loss)
I1016 22:12:37.241750   636 sgd_solver.cpp:105] Iteration 126300, lr = 0.001
I1016 22:12:46.412819   636 solver.cpp:218] Iteration 126400 (10.9043 iter/s, 9.1707s/100 iters), loss = 0.0010962
I1016 22:12:46.412819   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:12:46.412819   636 solver.cpp:237]     Train net output #1: loss = 0.00109595 (* 1 = 0.00109595 loss)
I1016 22:12:46.412819   636 sgd_solver.cpp:105] Iteration 126400, lr = 0.001
I1016 22:12:55.131528  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:12:55.495561   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_126500.caffemodel
I1016 22:12:55.521561   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_126500.solverstate
I1016 22:12:55.533563   636 solver.cpp:330] Iteration 126500, Testing net (#0)
I1016 22:12:55.533563   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:12:57.800830  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:12:57.891834   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 22:12:57.891834   636 solver.cpp:397]     Test net output #1: loss = 0.207872 (* 1 = 0.207872 loss)
I1016 22:12:57.980839   636 solver.cpp:218] Iteration 126500 (8.64481 iter/s, 11.5676s/100 iters), loss = 0.00145565
I1016 22:12:57.980839   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:12:57.980839   636 solver.cpp:237]     Train net output #1: loss = 0.0014554 (* 1 = 0.0014554 loss)
I1016 22:12:57.980839   636 sgd_solver.cpp:105] Iteration 126500, lr = 0.001
I1016 22:13:07.151370   636 solver.cpp:218] Iteration 126600 (10.905 iter/s, 9.17013s/100 iters), loss = 0.00219582
I1016 22:13:07.151370   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:13:07.151370   636 solver.cpp:237]     Train net output #1: loss = 0.00219557 (* 1 = 0.00219557 loss)
I1016 22:13:07.151370   636 sgd_solver.cpp:105] Iteration 126600, lr = 0.001
I1016 22:13:16.325248   636 solver.cpp:218] Iteration 126700 (10.9011 iter/s, 9.17341s/100 iters), loss = 0.00334818
I1016 22:13:16.325248   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:13:16.325248   636 solver.cpp:237]     Train net output #1: loss = 0.00334794 (* 1 = 0.00334794 loss)
I1016 22:13:16.326248   636 sgd_solver.cpp:105] Iteration 126700, lr = 0.001
I1016 22:13:25.500627   636 solver.cpp:218] Iteration 126800 (10.8998 iter/s, 9.17448s/100 iters), loss = 0.00173888
I1016 22:13:25.500627   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:13:25.500627   636 solver.cpp:237]     Train net output #1: loss = 0.00173863 (* 1 = 0.00173863 loss)
I1016 22:13:25.500627   636 sgd_solver.cpp:105] Iteration 126800, lr = 0.001
I1016 22:13:34.670156   636 solver.cpp:218] Iteration 126900 (10.9066 iter/s, 9.16876s/100 iters), loss = 0.000583611
I1016 22:13:34.670156   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:13:34.670156   636 solver.cpp:237]     Train net output #1: loss = 0.000583364 (* 1 = 0.000583364 loss)
I1016 22:13:34.670156   636 sgd_solver.cpp:105] Iteration 126900, lr = 0.001
I1016 22:13:43.393131  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:13:43.755167   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_127000.caffemodel
I1016 22:13:43.781168   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_127000.solverstate
I1016 22:13:43.793169   636 solver.cpp:330] Iteration 127000, Testing net (#0)
I1016 22:13:43.793169   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:13:46.060326  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:13:46.151337   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 22:13:46.151337   636 solver.cpp:397]     Test net output #1: loss = 0.207832 (* 1 = 0.207832 loss)
I1016 22:13:46.240337   636 solver.cpp:218] Iteration 127000 (8.643 iter/s, 11.5701s/100 iters), loss = 0.00160844
I1016 22:13:46.240337   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:13:46.240337   636 solver.cpp:237]     Train net output #1: loss = 0.00160819 (* 1 = 0.00160819 loss)
I1016 22:13:46.240337   636 sgd_solver.cpp:105] Iteration 127000, lr = 0.001
I1016 22:13:55.410930   636 solver.cpp:218] Iteration 127100 (10.9054 iter/s, 9.16974s/100 iters), loss = 0.0022471
I1016 22:13:55.410930   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:13:55.410930   636 solver.cpp:237]     Train net output #1: loss = 0.00224685 (* 1 = 0.00224685 loss)
I1016 22:13:55.410930   636 sgd_solver.cpp:105] Iteration 127100, lr = 0.001
I1016 22:14:04.572486   636 solver.cpp:218] Iteration 127200 (10.9156 iter/s, 9.16118s/100 iters), loss = 0.00311817
I1016 22:14:04.572486   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:14:04.572486   636 solver.cpp:237]     Train net output #1: loss = 0.00311792 (* 1 = 0.00311792 loss)
I1016 22:14:04.572486   636 sgd_solver.cpp:105] Iteration 127200, lr = 0.001
I1016 22:14:13.741905   636 solver.cpp:218] Iteration 127300 (10.9062 iter/s, 9.1691s/100 iters), loss = 0.00187737
I1016 22:14:13.741905   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:14:13.741905   636 solver.cpp:237]     Train net output #1: loss = 0.00187712 (* 1 = 0.00187712 loss)
I1016 22:14:13.741905   636 sgd_solver.cpp:105] Iteration 127300, lr = 0.001
I1016 22:14:22.912602   636 solver.cpp:218] Iteration 127400 (10.905 iter/s, 9.17015s/100 iters), loss = 0.000394995
I1016 22:14:22.912602   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:14:22.912602   636 solver.cpp:237]     Train net output #1: loss = 0.000394745 (* 1 = 0.000394745 loss)
I1016 22:14:22.912602   636 sgd_solver.cpp:105] Iteration 127400, lr = 0.001
I1016 22:14:31.627398  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:14:31.989411   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_127500.caffemodel
I1016 22:14:32.014431   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_127500.solverstate
I1016 22:14:32.026430   636 solver.cpp:330] Iteration 127500, Testing net (#0)
I1016 22:14:32.027431   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:14:34.292657  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:14:34.384666   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 22:14:34.384666   636 solver.cpp:397]     Test net output #1: loss = 0.206827 (* 1 = 0.206827 loss)
I1016 22:14:34.473673   636 solver.cpp:218] Iteration 127500 (8.65067 iter/s, 11.5598s/100 iters), loss = 0.0016334
I1016 22:14:34.473673   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:14:34.473673   636 solver.cpp:237]     Train net output #1: loss = 0.00163314 (* 1 = 0.00163314 loss)
I1016 22:14:34.473673   636 sgd_solver.cpp:105] Iteration 127500, lr = 0.001
I1016 22:14:43.645460   636 solver.cpp:218] Iteration 127600 (10.9029 iter/s, 9.17186s/100 iters), loss = 0.00228988
I1016 22:14:43.645460   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:14:43.645460   636 solver.cpp:237]     Train net output #1: loss = 0.00228963 (* 1 = 0.00228963 loss)
I1016 22:14:43.645460   636 sgd_solver.cpp:105] Iteration 127600, lr = 0.001
I1016 22:14:52.806244   636 solver.cpp:218] Iteration 127700 (10.9175 iter/s, 9.15963s/100 iters), loss = 0.00283092
I1016 22:14:52.806244   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:14:52.806244   636 solver.cpp:237]     Train net output #1: loss = 0.00283067 (* 1 = 0.00283067 loss)
I1016 22:14:52.806244   636 sgd_solver.cpp:105] Iteration 127700, lr = 0.001
I1016 22:15:01.966097   636 solver.cpp:218] Iteration 127800 (10.9182 iter/s, 9.15902s/100 iters), loss = 0.0017908
I1016 22:15:01.966097   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:01.966097   636 solver.cpp:237]     Train net output #1: loss = 0.00179055 (* 1 = 0.00179055 loss)
I1016 22:15:01.966097   636 sgd_solver.cpp:105] Iteration 127800, lr = 0.001
I1016 22:15:11.111596   636 solver.cpp:218] Iteration 127900 (10.935 iter/s, 9.14496s/100 iters), loss = 0.00126948
I1016 22:15:11.111596   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:11.111596   636 solver.cpp:237]     Train net output #1: loss = 0.00126923 (* 1 = 0.00126923 loss)
I1016 22:15:11.111596   636 sgd_solver.cpp:105] Iteration 127900, lr = 0.001
I1016 22:15:19.814146  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:15:20.174144   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_128000.caffemodel
I1016 22:15:20.202646   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_128000.solverstate
I1016 22:15:20.215145   636 solver.cpp:330] Iteration 128000, Testing net (#0)
I1016 22:15:20.215145   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:15:22.475157  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:15:22.566160   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 22:15:22.566160   636 solver.cpp:397]     Test net output #1: loss = 0.205999 (* 1 = 0.205999 loss)
I1016 22:15:22.655165   636 solver.cpp:218] Iteration 128000 (8.66327 iter/s, 11.543s/100 iters), loss = 0.00113684
I1016 22:15:22.655165   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:22.655165   636 solver.cpp:237]     Train net output #1: loss = 0.00113659 (* 1 = 0.00113659 loss)
I1016 22:15:22.655165   636 sgd_solver.cpp:105] Iteration 128000, lr = 0.001
I1016 22:15:31.820175   636 solver.cpp:218] Iteration 128100 (10.9114 iter/s, 9.16475s/100 iters), loss = 0.0016239
I1016 22:15:31.820677   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:31.820677   636 solver.cpp:237]     Train net output #1: loss = 0.00162364 (* 1 = 0.00162364 loss)
I1016 22:15:31.820677   636 sgd_solver.cpp:105] Iteration 128100, lr = 0.001
I1016 22:15:40.975702   636 solver.cpp:218] Iteration 128200 (10.9233 iter/s, 9.15472s/100 iters), loss = 0.00282915
I1016 22:15:40.975702   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:40.975702   636 solver.cpp:237]     Train net output #1: loss = 0.0028289 (* 1 = 0.0028289 loss)
I1016 22:15:40.975702   636 sgd_solver.cpp:105] Iteration 128200, lr = 0.001
I1016 22:15:50.126216   636 solver.cpp:218] Iteration 128300 (10.9289 iter/s, 9.15005s/100 iters), loss = 0.00293864
I1016 22:15:50.126216   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:50.126216   636 solver.cpp:237]     Train net output #1: loss = 0.00293839 (* 1 = 0.00293839 loss)
I1016 22:15:50.126216   636 sgd_solver.cpp:105] Iteration 128300, lr = 0.001
I1016 22:15:59.284849   636 solver.cpp:218] Iteration 128400 (10.9196 iter/s, 9.15787s/100 iters), loss = 0.00256952
I1016 22:15:59.284849   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:15:59.284849   636 solver.cpp:237]     Train net output #1: loss = 0.00256927 (* 1 = 0.00256927 loss)
I1016 22:15:59.284849   636 sgd_solver.cpp:105] Iteration 128400, lr = 0.001
I1016 22:16:07.993932  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:16:08.356940   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_128500.caffemodel
I1016 22:16:08.381932   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_128500.solverstate
I1016 22:16:08.394443   636 solver.cpp:330] Iteration 128500, Testing net (#0)
I1016 22:16:08.394443   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:16:10.657433  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:16:10.748430   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 22:16:10.748430   636 solver.cpp:397]     Test net output #1: loss = 0.206158 (* 1 = 0.206158 loss)
I1016 22:16:10.837430   636 solver.cpp:218] Iteration 128500 (8.65663 iter/s, 11.5518s/100 iters), loss = 0.00125357
I1016 22:16:10.837430   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:16:10.837430   636 solver.cpp:237]     Train net output #1: loss = 0.00125332 (* 1 = 0.00125332 loss)
I1016 22:16:10.837430   636 sgd_solver.cpp:105] Iteration 128500, lr = 0.001
I1016 22:16:19.993464   636 solver.cpp:218] Iteration 128600 (10.9224 iter/s, 9.15553s/100 iters), loss = 0.000908877
I1016 22:16:19.993464   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:16:19.993464   636 solver.cpp:237]     Train net output #1: loss = 0.000908624 (* 1 = 0.000908624 loss)
I1016 22:16:19.993464   636 sgd_solver.cpp:105] Iteration 128600, lr = 0.001
I1016 22:16:29.154667   636 solver.cpp:218] Iteration 128700 (10.9162 iter/s, 9.16066s/100 iters), loss = 0.00210399
I1016 22:16:29.154667   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:16:29.154667   636 solver.cpp:237]     Train net output #1: loss = 0.00210374 (* 1 = 0.00210374 loss)
I1016 22:16:29.154667   636 sgd_solver.cpp:105] Iteration 128700, lr = 0.001
I1016 22:16:38.319207   636 solver.cpp:218] Iteration 128800 (10.9124 iter/s, 9.16388s/100 iters), loss = 0.000858329
I1016 22:16:38.319207   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:16:38.319207   636 solver.cpp:237]     Train net output #1: loss = 0.000858077 (* 1 = 0.000858077 loss)
I1016 22:16:38.319207   636 sgd_solver.cpp:105] Iteration 128800, lr = 0.001
I1016 22:16:47.486706   636 solver.cpp:218] Iteration 128900 (10.909 iter/s, 9.16676s/100 iters), loss = 0.00109377
I1016 22:16:47.486706   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:16:47.486706   636 solver.cpp:237]     Train net output #1: loss = 0.00109352 (* 1 = 0.00109352 loss)
I1016 22:16:47.486706   636 sgd_solver.cpp:105] Iteration 128900, lr = 0.001
I1016 22:16:56.195257  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:16:56.559754   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_129000.caffemodel
I1016 22:16:56.585754   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_129000.solverstate
I1016 22:16:56.597755   636 solver.cpp:330] Iteration 129000, Testing net (#0)
I1016 22:16:56.597755   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:16:58.861255  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:16:58.952755   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 22:16:58.952755   636 solver.cpp:397]     Test net output #1: loss = 0.205542 (* 1 = 0.205542 loss)
I1016 22:16:59.041754   636 solver.cpp:218] Iteration 129000 (8.65439 iter/s, 11.5548s/100 iters), loss = 0.00214001
I1016 22:16:59.042255   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:16:59.042255   636 solver.cpp:237]     Train net output #1: loss = 0.00213976 (* 1 = 0.00213976 loss)
I1016 22:16:59.042255   636 sgd_solver.cpp:105] Iteration 129000, lr = 0.001
I1016 22:17:08.193282   636 solver.cpp:218] Iteration 129100 (10.928 iter/s, 9.15079s/100 iters), loss = 0.00292683
I1016 22:17:08.193282   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:17:08.193282   636 solver.cpp:237]     Train net output #1: loss = 0.00292658 (* 1 = 0.00292658 loss)
I1016 22:17:08.193282   636 sgd_solver.cpp:105] Iteration 129100, lr = 0.001
I1016 22:17:17.346812   636 solver.cpp:218] Iteration 129200 (10.9253 iter/s, 9.15303s/100 iters), loss = 0.00444848
I1016 22:17:17.346812   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:17:17.347316   636 solver.cpp:237]     Train net output #1: loss = 0.00444823 (* 1 = 0.00444823 loss)
I1016 22:17:17.347316   636 sgd_solver.cpp:105] Iteration 129200, lr = 0.001
I1016 22:17:26.502856   636 solver.cpp:218] Iteration 129300 (10.9224 iter/s, 9.15548s/100 iters), loss = 0.00140284
I1016 22:17:26.503355   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:17:26.503355   636 solver.cpp:237]     Train net output #1: loss = 0.00140259 (* 1 = 0.00140259 loss)
I1016 22:17:26.503355   636 sgd_solver.cpp:105] Iteration 129300, lr = 0.001
I1016 22:17:35.673877   636 solver.cpp:218] Iteration 129400 (10.9048 iter/s, 9.17026s/100 iters), loss = 0.00194575
I1016 22:17:35.673877   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:17:35.673877   636 solver.cpp:237]     Train net output #1: loss = 0.0019455 (* 1 = 0.0019455 loss)
I1016 22:17:35.673877   636 sgd_solver.cpp:105] Iteration 129400, lr = 0.001
I1016 22:17:44.386035  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:17:44.747571   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_129500.caffemodel
I1016 22:17:44.771572   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_129500.solverstate
I1016 22:17:44.783572   636 solver.cpp:330] Iteration 129500, Testing net (#0)
I1016 22:17:44.783572   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:17:47.045146  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:17:47.136646   636 solver.cpp:397]     Test net output #0: accuracy = 0.9463
I1016 22:17:47.136646   636 solver.cpp:397]     Test net output #1: loss = 0.205774 (* 1 = 0.205774 loss)
I1016 22:17:47.225144   636 solver.cpp:218] Iteration 129500 (8.65745 iter/s, 11.5507s/100 iters), loss = 0.00368814
I1016 22:17:47.225654   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:17:47.225654   636 solver.cpp:237]     Train net output #1: loss = 0.00368788 (* 1 = 0.00368788 loss)
I1016 22:17:47.225654   636 sgd_solver.cpp:105] Iteration 129500, lr = 0.001
I1016 22:17:56.393208   636 solver.cpp:218] Iteration 129600 (10.9083 iter/s, 9.16731s/100 iters), loss = 0.0020374
I1016 22:17:56.393208   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:17:56.393208   636 solver.cpp:237]     Train net output #1: loss = 0.00203715 (* 1 = 0.00203715 loss)
I1016 22:17:56.393208   636 sgd_solver.cpp:105] Iteration 129600, lr = 0.001
I1016 22:18:05.589277   636 solver.cpp:218] Iteration 129700 (10.8744 iter/s, 9.19593s/100 iters), loss = 0.00213838
I1016 22:18:05.589277   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:18:05.590276   636 solver.cpp:237]     Train net output #1: loss = 0.00213812 (* 1 = 0.00213812 loss)
I1016 22:18:05.590276   636 sgd_solver.cpp:105] Iteration 129700, lr = 0.001
I1016 22:18:14.717443   636 solver.cpp:218] Iteration 129800 (10.9568 iter/s, 9.12674s/100 iters), loss = 0.00502576
I1016 22:18:14.717443   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:18:14.717443   636 solver.cpp:237]     Train net output #1: loss = 0.00502551 (* 1 = 0.00502551 loss)
I1016 22:18:14.717443   636 sgd_solver.cpp:105] Iteration 129800, lr = 0.001
I1016 22:18:23.837751   636 solver.cpp:218] Iteration 129900 (10.9651 iter/s, 9.11984s/100 iters), loss = 0.00241019
I1016 22:18:23.837751   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:18:23.837751   636 solver.cpp:237]     Train net output #1: loss = 0.00240994 (* 1 = 0.00240994 loss)
I1016 22:18:23.837751   636 sgd_solver.cpp:105] Iteration 129900, lr = 0.001
I1016 22:18:32.514338  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:18:32.875372   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_130000.caffemodel
I1016 22:18:32.899374   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_130000.solverstate
I1016 22:18:32.911877   636 solver.cpp:330] Iteration 130000, Testing net (#0)
I1016 22:18:32.911877   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:18:35.168718  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:18:35.259730   636 solver.cpp:397]     Test net output #0: accuracy = 0.9465
I1016 22:18:35.259730   636 solver.cpp:397]     Test net output #1: loss = 0.205381 (* 1 = 0.205381 loss)
I1016 22:18:35.347724   636 solver.cpp:218] Iteration 130000 (8.68814 iter/s, 11.5099s/100 iters), loss = 0.0009216
I1016 22:18:35.347724   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:18:35.347724   636 solver.cpp:237]     Train net output #1: loss = 0.000921348 (* 1 = 0.000921348 loss)
I1016 22:18:35.347724   636 sgd_solver.cpp:105] Iteration 130000, lr = 0.001
I1016 22:18:44.734048   636 solver.cpp:218] Iteration 130100 (10.6546 iter/s, 9.38559s/100 iters), loss = 0.00171585
I1016 22:18:44.734048   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:18:44.734048   636 solver.cpp:237]     Train net output #1: loss = 0.0017156 (* 1 = 0.0017156 loss)
I1016 22:18:44.734048   636 sgd_solver.cpp:105] Iteration 130100, lr = 0.001
I1016 22:18:53.945545   636 solver.cpp:218] Iteration 130200 (10.8572 iter/s, 9.21049s/100 iters), loss = 0.00273914
I1016 22:18:53.945545   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:18:53.945545   636 solver.cpp:237]     Train net output #1: loss = 0.00273889 (* 1 = 0.00273889 loss)
I1016 22:18:53.945545   636 sgd_solver.cpp:105] Iteration 130200, lr = 0.001
I1016 22:19:03.157436   636 solver.cpp:218] Iteration 130300 (10.8554 iter/s, 9.21197s/100 iters), loss = 0.00258624
I1016 22:19:03.157436   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:19:03.157436   636 solver.cpp:237]     Train net output #1: loss = 0.00258599 (* 1 = 0.00258599 loss)
I1016 22:19:03.157436   636 sgd_solver.cpp:105] Iteration 130300, lr = 0.001
I1016 22:19:12.485255   636 solver.cpp:218] Iteration 130400 (10.7212 iter/s, 9.32728s/100 iters), loss = 0.00108606
I1016 22:19:12.485255   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:19:12.485255   636 solver.cpp:237]     Train net output #1: loss = 0.00108581 (* 1 = 0.00108581 loss)
I1016 22:19:12.485255   636 sgd_solver.cpp:105] Iteration 130400, lr = 0.001
I1016 22:19:21.297153  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:19:21.658170   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_130500.caffemodel
I1016 22:19:21.683171   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_130500.solverstate
I1016 22:19:21.696172   636 solver.cpp:330] Iteration 130500, Testing net (#0)
I1016 22:19:21.696172   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:19:23.983537  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:19:24.074554   636 solver.cpp:397]     Test net output #0: accuracy = 0.9464
I1016 22:19:24.074554   636 solver.cpp:397]     Test net output #1: loss = 0.206497 (* 1 = 0.206497 loss)
I1016 22:19:24.163547   636 solver.cpp:218] Iteration 130500 (8.56339 iter/s, 11.6776s/100 iters), loss = 0.00108271
I1016 22:19:24.163547   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:19:24.163547   636 solver.cpp:237]     Train net output #1: loss = 0.00108246 (* 1 = 0.00108246 loss)
I1016 22:19:24.163547   636 sgd_solver.cpp:105] Iteration 130500, lr = 0.001
I1016 22:19:33.344899   636 solver.cpp:218] Iteration 130600 (10.8928 iter/s, 9.18038s/100 iters), loss = 0.00474187
I1016 22:19:33.344899   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:19:33.344899   636 solver.cpp:237]     Train net output #1: loss = 0.00474162 (* 1 = 0.00474162 loss)
I1016 22:19:33.344899   636 sgd_solver.cpp:105] Iteration 130600, lr = 0.001
I1016 22:19:42.530145   636 solver.cpp:218] Iteration 130700 (10.8874 iter/s, 9.18495s/100 iters), loss = 0.00582018
I1016 22:19:42.530145   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:19:42.530145   636 solver.cpp:237]     Train net output #1: loss = 0.00581993 (* 1 = 0.00581993 loss)
I1016 22:19:42.530145   636 sgd_solver.cpp:105] Iteration 130700, lr = 0.001
I1016 22:19:51.763981   636 solver.cpp:218] Iteration 130800 (10.8303 iter/s, 9.23338s/100 iters), loss = 0.00297685
I1016 22:19:51.763981   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:19:51.763981   636 solver.cpp:237]     Train net output #1: loss = 0.00297661 (* 1 = 0.00297661 loss)
I1016 22:19:51.763981   636 sgd_solver.cpp:105] Iteration 130800, lr = 0.001
I1016 22:20:00.965731   636 solver.cpp:218] Iteration 130900 (10.8684 iter/s, 9.20096s/100 iters), loss = 0.000927716
I1016 22:20:00.965731   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:20:00.965731   636 solver.cpp:237]     Train net output #1: loss = 0.000927468 (* 1 = 0.000927468 loss)
I1016 22:20:00.965731   636 sgd_solver.cpp:105] Iteration 130900, lr = 0.001
I1016 22:20:09.690001  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:20:10.052014   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_131000.caffemodel
I1016 22:20:10.079021   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_131000.solverstate
I1016 22:20:10.091022   636 solver.cpp:330] Iteration 131000, Testing net (#0)
I1016 22:20:10.091022   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:20:12.355227  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:20:12.446231   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:20:12.446231   636 solver.cpp:397]     Test net output #1: loss = 0.205459 (* 1 = 0.205459 loss)
I1016 22:20:12.535236   636 solver.cpp:218] Iteration 131000 (8.64386 iter/s, 11.5689s/100 iters), loss = 0.00186145
I1016 22:20:12.535236   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:20:12.535236   636 solver.cpp:237]     Train net output #1: loss = 0.0018612 (* 1 = 0.0018612 loss)
I1016 22:20:12.535236   636 sgd_solver.cpp:105] Iteration 131000, lr = 0.001
I1016 22:20:21.706976   636 solver.cpp:218] Iteration 131100 (10.9042 iter/s, 9.17077s/100 iters), loss = 0.00139125
I1016 22:20:21.706976   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:20:21.706976   636 solver.cpp:237]     Train net output #1: loss = 0.00139101 (* 1 = 0.00139101 loss)
I1016 22:20:21.706976   636 sgd_solver.cpp:105] Iteration 131100, lr = 0.001
I1016 22:20:30.968590   636 solver.cpp:218] Iteration 131200 (10.7978 iter/s, 9.26115s/100 iters), loss = 0.00217004
I1016 22:20:30.968590   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:20:30.968590   636 solver.cpp:237]     Train net output #1: loss = 0.0021698 (* 1 = 0.0021698 loss)
I1016 22:20:30.968590   636 sgd_solver.cpp:105] Iteration 131200, lr = 0.001
I1016 22:20:40.206040   636 solver.cpp:218] Iteration 131300 (10.8254 iter/s, 9.23753s/100 iters), loss = 0.000944803
I1016 22:20:40.206040   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:20:40.206040   636 solver.cpp:237]     Train net output #1: loss = 0.000944558 (* 1 = 0.000944558 loss)
I1016 22:20:40.206040   636 sgd_solver.cpp:105] Iteration 131300, lr = 0.001
I1016 22:20:49.396080   636 solver.cpp:218] Iteration 131400 (10.8824 iter/s, 9.18912s/100 iters), loss = 0.00220918
I1016 22:20:49.396080   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:20:49.396080   636 solver.cpp:237]     Train net output #1: loss = 0.00220894 (* 1 = 0.00220894 loss)
I1016 22:20:49.396080   636 sgd_solver.cpp:105] Iteration 131400, lr = 0.001
I1016 22:20:58.223670  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:20:58.599213   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_131500.caffemodel
I1016 22:20:58.626725   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_131500.solverstate
I1016 22:20:58.638725   636 solver.cpp:330] Iteration 131500, Testing net (#0)
I1016 22:20:58.639726   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:21:00.913058  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:21:01.002892   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 22:21:01.002892   636 solver.cpp:397]     Test net output #1: loss = 0.206134 (* 1 = 0.206134 loss)
I1016 22:21:01.100764   636 solver.cpp:218] Iteration 131500 (8.54395 iter/s, 11.7042s/100 iters), loss = 0.00230223
I1016 22:21:01.100764   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:01.101263   636 solver.cpp:237]     Train net output #1: loss = 0.00230198 (* 1 = 0.00230198 loss)
I1016 22:21:01.101263   636 sgd_solver.cpp:105] Iteration 131500, lr = 0.001
I1016 22:21:10.421715   636 solver.cpp:218] Iteration 131600 (10.7182 iter/s, 9.32996s/100 iters), loss = 0.00749097
I1016 22:21:10.431716   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:10.431716   636 solver.cpp:237]     Train net output #1: loss = 0.00749073 (* 1 = 0.00749073 loss)
I1016 22:21:10.431716   636 sgd_solver.cpp:105] Iteration 131600, lr = 0.001
I1016 22:21:19.708541   636 solver.cpp:218] Iteration 131700 (10.7797 iter/s, 9.27673s/100 iters), loss = 0.00284309
I1016 22:21:19.708541   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:19.709043   636 solver.cpp:237]     Train net output #1: loss = 0.00284284 (* 1 = 0.00284284 loss)
I1016 22:21:19.709043   636 sgd_solver.cpp:105] Iteration 131700, lr = 0.001
I1016 22:21:29.033993   636 solver.cpp:218] Iteration 131800 (10.7243 iter/s, 9.32463s/100 iters), loss = 0.00261257
I1016 22:21:29.033993   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:29.033993   636 solver.cpp:237]     Train net output #1: loss = 0.00261233 (* 1 = 0.00261233 loss)
I1016 22:21:29.033993   636 sgd_solver.cpp:105] Iteration 131800, lr = 0.001
I1016 22:21:38.361019   636 solver.cpp:218] Iteration 131900 (10.7214 iter/s, 9.32715s/100 iters), loss = 0.00291005
I1016 22:21:38.362020   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:38.362020   636 solver.cpp:237]     Train net output #1: loss = 0.00290981 (* 1 = 0.00290981 loss)
I1016 22:21:38.362020   636 sgd_solver.cpp:105] Iteration 131900, lr = 0.001
I1016 22:21:47.162138  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:21:47.537225   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_132000.caffemodel
I1016 22:21:47.564225   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_132000.solverstate
I1016 22:21:47.576225   636 solver.cpp:330] Iteration 132000, Testing net (#0)
I1016 22:21:47.576225   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:21:49.842424  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:21:49.933465   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 22:21:49.933465   636 solver.cpp:397]     Test net output #1: loss = 0.206671 (* 1 = 0.206671 loss)
I1016 22:21:50.022465   636 solver.cpp:218] Iteration 132000 (8.57606 iter/s, 11.6604s/100 iters), loss = 0.00239998
I1016 22:21:50.022465   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:50.022465   636 solver.cpp:237]     Train net output #1: loss = 0.00239974 (* 1 = 0.00239974 loss)
I1016 22:21:50.022465   636 sgd_solver.cpp:105] Iteration 132000, lr = 0.001
I1016 22:21:59.236783   636 solver.cpp:218] Iteration 132100 (10.8535 iter/s, 9.21364s/100 iters), loss = 0.00181845
I1016 22:21:59.236783   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:21:59.236783   636 solver.cpp:237]     Train net output #1: loss = 0.00181821 (* 1 = 0.00181821 loss)
I1016 22:21:59.236783   636 sgd_solver.cpp:105] Iteration 132100, lr = 0.001
I1016 22:22:08.390836   636 solver.cpp:218] Iteration 132200 (10.916 iter/s, 9.16082s/100 iters), loss = 0.00273716
I1016 22:22:08.390836   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:22:08.390836   636 solver.cpp:237]     Train net output #1: loss = 0.00273692 (* 1 = 0.00273692 loss)
I1016 22:22:08.390836   636 sgd_solver.cpp:105] Iteration 132200, lr = 0.001
I1016 22:22:17.524883   636 solver.cpp:218] Iteration 132300 (10.9534 iter/s, 9.12958s/100 iters), loss = 0.00188873
I1016 22:22:17.524883   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:22:17.524883   636 solver.cpp:237]     Train net output #1: loss = 0.00188849 (* 1 = 0.00188849 loss)
I1016 22:22:17.524883   636 sgd_solver.cpp:105] Iteration 132300, lr = 0.001
I1016 22:22:26.691748   636 solver.cpp:218] Iteration 132400 (10.9139 iter/s, 9.16265s/100 iters), loss = 0.00472822
I1016 22:22:26.691748   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:22:26.691748   636 solver.cpp:237]     Train net output #1: loss = 0.00472798 (* 1 = 0.00472798 loss)
I1016 22:22:26.691748   636 sgd_solver.cpp:105] Iteration 132400, lr = 0.001
I1016 22:22:35.499850  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:22:35.869699   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_132500.caffemodel
I1016 22:22:35.896211   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_132500.solverstate
I1016 22:22:35.909214   636 solver.cpp:330] Iteration 132500, Testing net (#0)
I1016 22:22:35.909214   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:22:38.180572  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:22:38.263419   636 solver.cpp:397]     Test net output #0: accuracy = 0.9448
I1016 22:22:38.263419   636 solver.cpp:397]     Test net output #1: loss = 0.207502 (* 1 = 0.207502 loss)
I1016 22:22:38.360692   636 solver.cpp:218] Iteration 132500 (8.57003 iter/s, 11.6686s/100 iters), loss = 0.00152133
I1016 22:22:38.360692   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:22:38.360692   636 solver.cpp:237]     Train net output #1: loss = 0.00152108 (* 1 = 0.00152108 loss)
I1016 22:22:38.360692   636 sgd_solver.cpp:105] Iteration 132500, lr = 0.001
I1016 22:22:47.585211   636 solver.cpp:218] Iteration 132600 (10.8416 iter/s, 9.22377s/100 iters), loss = 0.00244485
I1016 22:22:47.585211   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:22:47.585211   636 solver.cpp:237]     Train net output #1: loss = 0.00244461 (* 1 = 0.00244461 loss)
I1016 22:22:47.585211   636 sgd_solver.cpp:105] Iteration 132600, lr = 0.001
I1016 22:22:56.725469   636 solver.cpp:218] Iteration 132700 (10.9406 iter/s, 9.14031s/100 iters), loss = 0.00353198
I1016 22:22:56.725469   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:22:56.725469   636 solver.cpp:237]     Train net output #1: loss = 0.00353174 (* 1 = 0.00353174 loss)
I1016 22:22:56.725469   636 sgd_solver.cpp:105] Iteration 132700, lr = 0.001
I1016 22:23:05.871814   636 solver.cpp:218] Iteration 132800 (10.9344 iter/s, 9.14543s/100 iters), loss = 0.00557953
I1016 22:23:05.871814   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:23:05.871814   636 solver.cpp:237]     Train net output #1: loss = 0.00557928 (* 1 = 0.00557928 loss)
I1016 22:23:05.871814   636 sgd_solver.cpp:105] Iteration 132800, lr = 0.001
I1016 22:23:15.011394   636 solver.cpp:218] Iteration 132900 (10.9329 iter/s, 9.14673s/100 iters), loss = 0.000995207
I1016 22:23:15.011394   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:23:15.011394   636 solver.cpp:237]     Train net output #1: loss = 0.000994965 (* 1 = 0.000994965 loss)
I1016 22:23:15.011394   636 sgd_solver.cpp:105] Iteration 132900, lr = 0.001
I1016 22:23:23.726516  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:23:24.079392   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_133000.caffemodel
I1016 22:23:24.109381   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_133000.solverstate
I1016 22:23:24.119396   636 solver.cpp:330] Iteration 133000, Testing net (#0)
I1016 22:23:24.119396   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:23:26.376608  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:23:26.475788   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 22:23:26.475788   636 solver.cpp:397]     Test net output #1: loss = 0.206617 (* 1 = 0.206617 loss)
I1016 22:23:26.555943   636 solver.cpp:218] Iteration 133000 (8.66176 iter/s, 11.545s/100 iters), loss = 0.000938331
I1016 22:23:26.555943   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:23:26.555943   636 solver.cpp:237]     Train net output #1: loss = 0.00093809 (* 1 = 0.00093809 loss)
I1016 22:23:26.555943   636 sgd_solver.cpp:105] Iteration 133000, lr = 0.001
I1016 22:23:35.690726   636 solver.cpp:218] Iteration 133100 (10.9488 iter/s, 9.13341s/100 iters), loss = 0.00133306
I1016 22:23:35.690726   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:23:35.690726   636 solver.cpp:237]     Train net output #1: loss = 0.00133282 (* 1 = 0.00133282 loss)
I1016 22:23:35.690726   636 sgd_solver.cpp:105] Iteration 133100, lr = 0.001
I1016 22:23:44.832288   636 solver.cpp:218] Iteration 133200 (10.9386 iter/s, 9.14191s/100 iters), loss = 0.00469489
I1016 22:23:44.832288   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:23:44.832288   636 solver.cpp:237]     Train net output #1: loss = 0.00469465 (* 1 = 0.00469465 loss)
I1016 22:23:44.832288   636 sgd_solver.cpp:105] Iteration 133200, lr = 0.001
I1016 22:23:54.000896   636 solver.cpp:218] Iteration 133300 (10.9124 iter/s, 9.16385s/100 iters), loss = 0.00195602
I1016 22:23:54.000896   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:23:54.000896   636 solver.cpp:237]     Train net output #1: loss = 0.00195578 (* 1 = 0.00195578 loss)
I1016 22:23:54.000896   636 sgd_solver.cpp:105] Iteration 133300, lr = 0.001
I1016 22:24:03.146898   636 solver.cpp:218] Iteration 133400 (10.9383 iter/s, 9.14215s/100 iters), loss = 0.00379934
I1016 22:24:03.146898   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:24:03.146898   636 solver.cpp:237]     Train net output #1: loss = 0.0037991 (* 1 = 0.0037991 loss)
I1016 22:24:03.146898   636 sgd_solver.cpp:105] Iteration 133400, lr = 0.001
I1016 22:24:11.823359  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:24:12.183464   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_133500.caffemodel
I1016 22:24:12.213469   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_133500.solverstate
I1016 22:24:12.223469   636 solver.cpp:330] Iteration 133500, Testing net (#0)
I1016 22:24:12.223469   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:24:14.484315  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:24:14.578771   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 22:24:14.578771   636 solver.cpp:397]     Test net output #1: loss = 0.206229 (* 1 = 0.206229 loss)
I1016 22:24:14.664810   636 solver.cpp:218] Iteration 133500 (8.68125 iter/s, 11.5191s/100 iters), loss = 0.00166144
I1016 22:24:14.664810   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:24:14.664810   636 solver.cpp:237]     Train net output #1: loss = 0.0016612 (* 1 = 0.0016612 loss)
I1016 22:24:14.664810   636 sgd_solver.cpp:105] Iteration 133500, lr = 0.001
I1016 22:24:23.801257   636 solver.cpp:218] Iteration 133600 (10.9385 iter/s, 9.14202s/100 iters), loss = 0.00176981
I1016 22:24:23.801257   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:24:23.801257   636 solver.cpp:237]     Train net output #1: loss = 0.00176958 (* 1 = 0.00176958 loss)
I1016 22:24:23.801257   636 sgd_solver.cpp:105] Iteration 133600, lr = 0.001
I1016 22:24:32.990507   636 solver.cpp:218] Iteration 133700 (10.8937 iter/s, 9.17962s/100 iters), loss = 0.00279306
I1016 22:24:32.990507   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:24:32.990507   636 solver.cpp:237]     Train net output #1: loss = 0.00279282 (* 1 = 0.00279282 loss)
I1016 22:24:32.990507   636 sgd_solver.cpp:105] Iteration 133700, lr = 0.001
I1016 22:24:42.156347   636 solver.cpp:218] Iteration 133800 (10.9111 iter/s, 9.16501s/100 iters), loss = 0.00146386
I1016 22:24:42.156347   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:24:42.156347   636 solver.cpp:237]     Train net output #1: loss = 0.00146362 (* 1 = 0.00146362 loss)
I1016 22:24:42.156347   636 sgd_solver.cpp:105] Iteration 133800, lr = 0.001
I1016 22:24:51.368300   636 solver.cpp:218] Iteration 133900 (10.8557 iter/s, 9.21174s/100 iters), loss = 0.000701572
I1016 22:24:51.368300   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:24:51.368300   636 solver.cpp:237]     Train net output #1: loss = 0.000701334 (* 1 = 0.000701334 loss)
I1016 22:24:51.368300   636 sgd_solver.cpp:105] Iteration 133900, lr = 0.001
I1016 22:25:00.139379  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:25:00.504740   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_134000.caffemodel
I1016 22:25:00.531740   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_134000.solverstate
I1016 22:25:00.543740   636 solver.cpp:330] Iteration 134000, Testing net (#0)
I1016 22:25:00.543740   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:25:02.805668  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:25:02.896669   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 22:25:02.896669   636 solver.cpp:397]     Test net output #1: loss = 0.20734 (* 1 = 0.20734 loss)
I1016 22:25:02.985178   636 solver.cpp:218] Iteration 134000 (8.60856 iter/s, 11.6163s/100 iters), loss = 0.00243826
I1016 22:25:02.985178   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:25:02.985178   636 solver.cpp:237]     Train net output #1: loss = 0.00243802 (* 1 = 0.00243802 loss)
I1016 22:25:02.985678   636 sgd_solver.cpp:105] Iteration 134000, lr = 0.001
I1016 22:25:12.120594   636 solver.cpp:218] Iteration 134100 (10.9467 iter/s, 9.13519s/100 iters), loss = 0.00453423
I1016 22:25:12.120594   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:25:12.120594   636 solver.cpp:237]     Train net output #1: loss = 0.00453399 (* 1 = 0.00453399 loss)
I1016 22:25:12.120594   636 sgd_solver.cpp:105] Iteration 134100, lr = 0.001
I1016 22:25:21.258723   636 solver.cpp:218] Iteration 134200 (10.9419 iter/s, 9.13916s/100 iters), loss = 0.00209934
I1016 22:25:21.258723   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:25:21.258723   636 solver.cpp:237]     Train net output #1: loss = 0.0020991 (* 1 = 0.0020991 loss)
I1016 22:25:21.258723   636 sgd_solver.cpp:105] Iteration 134200, lr = 0.001
I1016 22:25:30.416563   636 solver.cpp:218] Iteration 134300 (10.9228 iter/s, 9.15519s/100 iters), loss = 0.00189575
I1016 22:25:30.416563   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:25:30.416563   636 solver.cpp:237]     Train net output #1: loss = 0.00189551 (* 1 = 0.00189551 loss)
I1016 22:25:30.416563   636 sgd_solver.cpp:105] Iteration 134300, lr = 0.001
I1016 22:25:39.657316   636 solver.cpp:218] Iteration 134400 (10.8195 iter/s, 9.24257s/100 iters), loss = 0.00187245
I1016 22:25:39.657316   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:25:39.657316   636 solver.cpp:237]     Train net output #1: loss = 0.00187222 (* 1 = 0.00187222 loss)
I1016 22:25:39.657316   636 sgd_solver.cpp:105] Iteration 134400, lr = 0.001
I1016 22:25:48.394222  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:25:48.752964   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_134500.caffemodel
I1016 22:25:48.782974   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_134500.solverstate
I1016 22:25:48.792966   636 solver.cpp:330] Iteration 134500, Testing net (#0)
I1016 22:25:48.792966   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:25:51.054404  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:25:51.143975   636 solver.cpp:397]     Test net output #0: accuracy = 0.9465
I1016 22:25:51.143975   636 solver.cpp:397]     Test net output #1: loss = 0.206965 (* 1 = 0.206965 loss)
I1016 22:25:51.235183   636 solver.cpp:218] Iteration 134500 (8.63835 iter/s, 11.5763s/100 iters), loss = 0.00207199
I1016 22:25:51.235183   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:25:51.235183   636 solver.cpp:237]     Train net output #1: loss = 0.00207175 (* 1 = 0.00207175 loss)
I1016 22:25:51.235183   636 sgd_solver.cpp:105] Iteration 134500, lr = 0.001
I1016 22:26:00.435132   636 solver.cpp:218] Iteration 134600 (10.872 iter/s, 9.19792s/100 iters), loss = 0.00439518
I1016 22:26:00.435132   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:00.435132   636 solver.cpp:237]     Train net output #1: loss = 0.00439494 (* 1 = 0.00439494 loss)
I1016 22:26:00.435132   636 sgd_solver.cpp:105] Iteration 134600, lr = 0.001
I1016 22:26:09.608017   636 solver.cpp:218] Iteration 134700 (10.9023 iter/s, 9.17234s/100 iters), loss = 0.00267484
I1016 22:26:09.608017   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:09.608017   636 solver.cpp:237]     Train net output #1: loss = 0.0026746 (* 1 = 0.0026746 loss)
I1016 22:26:09.608017   636 sgd_solver.cpp:105] Iteration 134700, lr = 0.001
I1016 22:26:18.870278   636 solver.cpp:218] Iteration 134800 (10.7973 iter/s, 9.26154s/100 iters), loss = 0.00135006
I1016 22:26:18.870278   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:18.870278   636 solver.cpp:237]     Train net output #1: loss = 0.00134982 (* 1 = 0.00134982 loss)
I1016 22:26:18.870278   636 sgd_solver.cpp:105] Iteration 134800, lr = 0.001
I1016 22:26:28.048681   636 solver.cpp:218] Iteration 134900 (10.896 iter/s, 9.17764s/100 iters), loss = 0.000806834
I1016 22:26:28.048681   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:28.048681   636 solver.cpp:237]     Train net output #1: loss = 0.000806594 (* 1 = 0.000806594 loss)
I1016 22:26:28.048681   636 sgd_solver.cpp:105] Iteration 134900, lr = 0.001
I1016 22:26:36.815816  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:26:37.182438   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_135000.caffemodel
I1016 22:26:37.212445   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_135000.solverstate
I1016 22:26:37.224440   636 solver.cpp:330] Iteration 135000, Testing net (#0)
I1016 22:26:37.224440   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:26:39.511956  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:26:39.602985   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 22:26:39.602985   636 solver.cpp:397]     Test net output #1: loss = 0.206778 (* 1 = 0.206778 loss)
I1016 22:26:39.692994   636 solver.cpp:218] Iteration 135000 (8.58795 iter/s, 11.6442s/100 iters), loss = 0.00176364
I1016 22:26:39.692994   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:39.692994   636 solver.cpp:237]     Train net output #1: loss = 0.0017634 (* 1 = 0.0017634 loss)
I1016 22:26:39.692994   636 sgd_solver.cpp:105] Iteration 135000, lr = 0.001
I1016 22:26:48.935400   636 solver.cpp:218] Iteration 135100 (10.8206 iter/s, 9.24165s/100 iters), loss = 0.00322717
I1016 22:26:48.935400   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:48.935400   636 solver.cpp:237]     Train net output #1: loss = 0.00322693 (* 1 = 0.00322693 loss)
I1016 22:26:48.935400   636 sgd_solver.cpp:105] Iteration 135100, lr = 0.001
I1016 22:26:58.154506   636 solver.cpp:218] Iteration 135200 (10.8408 iter/s, 9.22442s/100 iters), loss = 0.00572494
I1016 22:26:58.154506   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:26:58.154506   636 solver.cpp:237]     Train net output #1: loss = 0.0057247 (* 1 = 0.0057247 loss)
I1016 22:26:58.154506   636 sgd_solver.cpp:105] Iteration 135200, lr = 0.001
I1016 22:27:07.326611   636 solver.cpp:218] Iteration 135300 (10.8995 iter/s, 9.1747s/100 iters), loss = 0.00166898
I1016 22:27:07.326611   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:27:07.326611   636 solver.cpp:237]     Train net output #1: loss = 0.00166874 (* 1 = 0.00166874 loss)
I1016 22:27:07.326611   636 sgd_solver.cpp:105] Iteration 135300, lr = 0.001
I1016 22:27:16.510975   636 solver.cpp:218] Iteration 135400 (10.899 iter/s, 9.17516s/100 iters), loss = 0.00101124
I1016 22:27:16.510975   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:27:16.510975   636 solver.cpp:237]     Train net output #1: loss = 0.001011 (* 1 = 0.001011 loss)
I1016 22:27:16.510975   636 sgd_solver.cpp:105] Iteration 135400, lr = 0.001
I1016 22:27:25.212965  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:27:25.574820   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_135500.caffemodel
I1016 22:27:25.594825   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_135500.solverstate
I1016 22:27:25.604825   636 solver.cpp:330] Iteration 135500, Testing net (#0)
I1016 22:27:25.604825   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:27:27.906085  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:27:27.996949   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 22:27:27.996949   636 solver.cpp:397]     Test net output #1: loss = 0.207447 (* 1 = 0.207447 loss)
I1016 22:27:28.085968   636 solver.cpp:218] Iteration 135500 (8.64023 iter/s, 11.5738s/100 iters), loss = 0.00220746
I1016 22:27:28.085968   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:27:28.085968   636 solver.cpp:237]     Train net output #1: loss = 0.00220722 (* 1 = 0.00220722 loss)
I1016 22:27:28.085968   636 sgd_solver.cpp:105] Iteration 135500, lr = 0.001
I1016 22:27:37.348407   636 solver.cpp:218] Iteration 135600 (10.7967 iter/s, 9.26212s/100 iters), loss = 0.00422155
I1016 22:27:37.348407   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:27:37.348407   636 solver.cpp:237]     Train net output #1: loss = 0.0042213 (* 1 = 0.0042213 loss)
I1016 22:27:37.348407   636 sgd_solver.cpp:105] Iteration 135600, lr = 0.001
I1016 22:27:46.571811   636 solver.cpp:218] Iteration 135700 (10.8326 iter/s, 9.23136s/100 iters), loss = 0.00196234
I1016 22:27:46.571811   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:27:46.571811   636 solver.cpp:237]     Train net output #1: loss = 0.00196209 (* 1 = 0.00196209 loss)
I1016 22:27:46.571811   636 sgd_solver.cpp:105] Iteration 135700, lr = 0.001
I1016 22:27:55.887286   636 solver.cpp:218] Iteration 135800 (10.7454 iter/s, 9.30627s/100 iters), loss = 0.00261278
I1016 22:27:55.887286   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:27:55.887286   636 solver.cpp:237]     Train net output #1: loss = 0.00261254 (* 1 = 0.00261254 loss)
I1016 22:27:55.887286   636 sgd_solver.cpp:105] Iteration 135800, lr = 0.001
I1016 22:28:05.165915   636 solver.cpp:218] Iteration 135900 (10.7784 iter/s, 9.27777s/100 iters), loss = 0.0018309
I1016 22:28:05.165915   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:28:05.165915   636 solver.cpp:237]     Train net output #1: loss = 0.00183066 (* 1 = 0.00183066 loss)
I1016 22:28:05.165915   636 sgd_solver.cpp:105] Iteration 135900, lr = 0.001
I1016 22:28:14.029863  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:28:14.402909   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_136000.caffemodel
I1016 22:28:14.436906   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_136000.solverstate
I1016 22:28:14.450911   636 solver.cpp:330] Iteration 136000, Testing net (#0)
I1016 22:28:14.450911   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:28:16.734223  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:28:16.824617   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 22:28:16.824617   636 solver.cpp:397]     Test net output #1: loss = 0.207107 (* 1 = 0.207107 loss)
I1016 22:28:16.914623   636 solver.cpp:218] Iteration 136000 (8.50712 iter/s, 11.7549s/100 iters), loss = 0.00326431
I1016 22:28:16.914623   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:28:16.914623   636 solver.cpp:237]     Train net output #1: loss = 0.00326407 (* 1 = 0.00326407 loss)
I1016 22:28:16.914623   636 sgd_solver.cpp:105] Iteration 136000, lr = 0.001
I1016 22:28:26.129611   636 solver.cpp:218] Iteration 136100 (10.8546 iter/s, 9.21269s/100 iters), loss = 0.00212023
I1016 22:28:26.129611   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:28:26.129611   636 solver.cpp:237]     Train net output #1: loss = 0.00211999 (* 1 = 0.00211999 loss)
I1016 22:28:26.129611   636 sgd_solver.cpp:105] Iteration 136100, lr = 0.001
I1016 22:28:35.358446   636 solver.cpp:218] Iteration 136200 (10.8416 iter/s, 9.22376s/100 iters), loss = 0.0021879
I1016 22:28:35.358446   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:28:35.358446   636 solver.cpp:237]     Train net output #1: loss = 0.00218766 (* 1 = 0.00218766 loss)
I1016 22:28:35.358446   636 sgd_solver.cpp:105] Iteration 136200, lr = 0.001
I1016 22:28:44.550344   636 solver.cpp:218] Iteration 136300 (10.8713 iter/s, 9.19855s/100 iters), loss = 0.00174602
I1016 22:28:44.550344   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:28:44.550344   636 solver.cpp:237]     Train net output #1: loss = 0.00174578 (* 1 = 0.00174578 loss)
I1016 22:28:44.550344   636 sgd_solver.cpp:105] Iteration 136300, lr = 0.001
I1016 22:28:53.802202   636 solver.cpp:218] Iteration 136400 (10.8177 iter/s, 9.24407s/100 iters), loss = 0.000728451
I1016 22:28:53.802202   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:28:53.802202   636 solver.cpp:237]     Train net output #1: loss = 0.000728209 (* 1 = 0.000728209 loss)
I1016 22:28:53.802202   636 sgd_solver.cpp:105] Iteration 136400, lr = 0.001
I1016 22:29:02.527892  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:29:02.888909   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_136500.caffemodel
I1016 22:29:02.914909   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_136500.solverstate
I1016 22:29:02.926911   636 solver.cpp:330] Iteration 136500, Testing net (#0)
I1016 22:29:02.926911   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:29:05.186095  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:29:05.277598   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 22:29:05.277598   636 solver.cpp:397]     Test net output #1: loss = 0.207074 (* 1 = 0.207074 loss)
I1016 22:29:05.366098   636 solver.cpp:218] Iteration 136500 (8.6481 iter/s, 11.5632s/100 iters), loss = 0.00388303
I1016 22:29:05.366098   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:29:05.366098   636 solver.cpp:237]     Train net output #1: loss = 0.00388279 (* 1 = 0.00388279 loss)
I1016 22:29:05.366098   636 sgd_solver.cpp:105] Iteration 136500, lr = 0.001
I1016 22:29:14.531482   636 solver.cpp:218] Iteration 136600 (10.9114 iter/s, 9.16477s/100 iters), loss = 0.00310259
I1016 22:29:14.531482   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:29:14.531482   636 solver.cpp:237]     Train net output #1: loss = 0.00310235 (* 1 = 0.00310235 loss)
I1016 22:29:14.531482   636 sgd_solver.cpp:105] Iteration 136600, lr = 0.001
I1016 22:29:23.683161   636 solver.cpp:218] Iteration 136700 (10.926 iter/s, 9.15244s/100 iters), loss = 0.00167589
I1016 22:29:23.683161   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:29:23.683161   636 solver.cpp:237]     Train net output #1: loss = 0.00167565 (* 1 = 0.00167565 loss)
I1016 22:29:23.683161   636 sgd_solver.cpp:105] Iteration 136700, lr = 0.001
I1016 22:29:32.819468   636 solver.cpp:218] Iteration 136800 (10.9446 iter/s, 9.13689s/100 iters), loss = 0.0035951
I1016 22:29:32.819468   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:29:32.819468   636 solver.cpp:237]     Train net output #1: loss = 0.00359486 (* 1 = 0.00359486 loss)
I1016 22:29:32.819468   636 sgd_solver.cpp:105] Iteration 136800, lr = 0.001
I1016 22:29:41.953377   636 solver.cpp:218] Iteration 136900 (10.947 iter/s, 9.13492s/100 iters), loss = 0.000951968
I1016 22:29:41.953377   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:29:41.953377   636 solver.cpp:237]     Train net output #1: loss = 0.000951727 (* 1 = 0.000951727 loss)
I1016 22:29:41.953377   636 sgd_solver.cpp:105] Iteration 136900, lr = 0.001
I1016 22:29:50.636749  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:29:50.997018   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_137000.caffemodel
I1016 22:29:51.017021   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_137000.solverstate
I1016 22:29:51.037022   636 solver.cpp:330] Iteration 137000, Testing net (#0)
I1016 22:29:51.037022   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:29:53.287706  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:29:53.377884   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 22:29:53.377884   636 solver.cpp:397]     Test net output #1: loss = 0.208189 (* 1 = 0.208189 loss)
I1016 22:29:53.474793   636 solver.cpp:218] Iteration 137000 (8.6828 iter/s, 11.517s/100 iters), loss = 0.00183201
I1016 22:29:53.475294   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:29:53.475294   636 solver.cpp:237]     Train net output #1: loss = 0.00183176 (* 1 = 0.00183176 loss)
I1016 22:29:53.475294   636 sgd_solver.cpp:105] Iteration 137000, lr = 0.001
I1016 22:30:02.601784   636 solver.cpp:218] Iteration 137100 (10.952 iter/s, 9.13079s/100 iters), loss = 0.00157608
I1016 22:30:02.601784   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:02.601784   636 solver.cpp:237]     Train net output #1: loss = 0.00157584 (* 1 = 0.00157584 loss)
I1016 22:30:02.601784   636 sgd_solver.cpp:105] Iteration 137100, lr = 0.001
I1016 22:30:11.727185   636 solver.cpp:218] Iteration 137200 (10.9577 iter/s, 9.12601s/100 iters), loss = 0.00332675
I1016 22:30:11.727185   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:11.727185   636 solver.cpp:237]     Train net output #1: loss = 0.00332651 (* 1 = 0.00332651 loss)
I1016 22:30:11.727185   636 sgd_solver.cpp:105] Iteration 137200, lr = 0.001
I1016 22:30:20.872017   636 solver.cpp:218] Iteration 137300 (10.9421 iter/s, 9.13899s/100 iters), loss = 0.00107895
I1016 22:30:20.872017   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:20.872017   636 solver.cpp:237]     Train net output #1: loss = 0.00107871 (* 1 = 0.00107871 loss)
I1016 22:30:20.872017   636 sgd_solver.cpp:105] Iteration 137300, lr = 0.001
I1016 22:30:30.022233   636 solver.cpp:218] Iteration 137400 (10.9237 iter/s, 9.15441s/100 iters), loss = 0.00128909
I1016 22:30:30.022233   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:30.022233   636 solver.cpp:237]     Train net output #1: loss = 0.00128885 (* 1 = 0.00128885 loss)
I1016 22:30:30.022233   636 sgd_solver.cpp:105] Iteration 137400, lr = 0.001
I1016 22:30:38.699409  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:30:39.059634   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_137500.caffemodel
I1016 22:30:39.089411   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_137500.solverstate
I1016 22:30:39.099402   636 solver.cpp:330] Iteration 137500, Testing net (#0)
I1016 22:30:39.099402   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:30:41.363209  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:30:41.450742   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 22:30:41.450742   636 solver.cpp:397]     Test net output #1: loss = 0.208893 (* 1 = 0.208893 loss)
I1016 22:30:41.540803   636 solver.cpp:218] Iteration 137500 (8.68379 iter/s, 11.5157s/100 iters), loss = 0.00244303
I1016 22:30:41.540803   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:41.540803   636 solver.cpp:237]     Train net output #1: loss = 0.00244278 (* 1 = 0.00244278 loss)
I1016 22:30:41.540803   636 sgd_solver.cpp:105] Iteration 137500, lr = 0.001
I1016 22:30:50.747467   636 solver.cpp:218] Iteration 137600 (10.8643 iter/s, 9.20445s/100 iters), loss = 0.000794397
I1016 22:30:50.747467   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:50.747467   636 solver.cpp:237]     Train net output #1: loss = 0.000794155 (* 1 = 0.000794155 loss)
I1016 22:30:50.747467   636 sgd_solver.cpp:105] Iteration 137600, lr = 0.001
I1016 22:30:59.932301   636 solver.cpp:218] Iteration 137700 (10.8835 iter/s, 9.18819s/100 iters), loss = 0.00287959
I1016 22:30:59.932301   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:30:59.932301   636 solver.cpp:237]     Train net output #1: loss = 0.00287934 (* 1 = 0.00287934 loss)
I1016 22:30:59.932301   636 sgd_solver.cpp:105] Iteration 137700, lr = 0.001
I1016 22:31:09.066421   636 solver.cpp:218] Iteration 137800 (10.9476 iter/s, 9.1344s/100 iters), loss = 0.00142131
I1016 22:31:09.066421   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:31:09.066421   636 solver.cpp:237]     Train net output #1: loss = 0.00142106 (* 1 = 0.00142106 loss)
I1016 22:31:09.066421   636 sgd_solver.cpp:105] Iteration 137800, lr = 0.001
I1016 22:31:18.201439   636 solver.cpp:218] Iteration 137900 (10.9503 iter/s, 9.13217s/100 iters), loss = 0.00118637
I1016 22:31:18.201439   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:31:18.201439   636 solver.cpp:237]     Train net output #1: loss = 0.00118612 (* 1 = 0.00118612 loss)
I1016 22:31:18.201439   636 sgd_solver.cpp:105] Iteration 137900, lr = 0.001
I1016 22:31:26.876113  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:31:27.245637   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_138000.caffemodel
I1016 22:31:27.266149   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_138000.solverstate
I1016 22:31:27.276144   636 solver.cpp:330] Iteration 138000, Testing net (#0)
I1016 22:31:27.276144   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:31:29.541788  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:31:29.627810   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 22:31:29.627810   636 solver.cpp:397]     Test net output #1: loss = 0.207407 (* 1 = 0.207407 loss)
I1016 22:31:29.717803   636 solver.cpp:218] Iteration 138000 (8.68457 iter/s, 11.5147s/100 iters), loss = 0.00692361
I1016 22:31:29.717803   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:31:29.717803   636 solver.cpp:237]     Train net output #1: loss = 0.00692337 (* 1 = 0.00692337 loss)
I1016 22:31:29.717803   636 sgd_solver.cpp:105] Iteration 138000, lr = 0.001
I1016 22:31:38.965350   636 solver.cpp:218] Iteration 138100 (10.8171 iter/s, 9.24459s/100 iters), loss = 0.00255695
I1016 22:31:38.965350   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:31:38.965350   636 solver.cpp:237]     Train net output #1: loss = 0.00255671 (* 1 = 0.00255671 loss)
I1016 22:31:38.965350   636 sgd_solver.cpp:105] Iteration 138100, lr = 0.001
I1016 22:31:48.297446   636 solver.cpp:218] Iteration 138200 (10.709 iter/s, 9.33797s/100 iters), loss = 0.00329999
I1016 22:31:48.297446   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:31:48.297446   636 solver.cpp:237]     Train net output #1: loss = 0.00329975 (* 1 = 0.00329975 loss)
I1016 22:31:48.297446   636 sgd_solver.cpp:105] Iteration 138200, lr = 0.001
I1016 22:31:57.502115   636 solver.cpp:218] Iteration 138300 (10.8724 iter/s, 9.19762s/100 iters), loss = 0.00224814
I1016 22:31:57.502115   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:31:57.502115   636 solver.cpp:237]     Train net output #1: loss = 0.0022479 (* 1 = 0.0022479 loss)
I1016 22:31:57.502115   636 sgd_solver.cpp:105] Iteration 138300, lr = 0.001
I1016 22:32:06.656105   636 solver.cpp:218] Iteration 138400 (10.9244 iter/s, 9.1538s/100 iters), loss = 0.00077598
I1016 22:32:06.656105   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:32:06.656105   636 solver.cpp:237]     Train net output #1: loss = 0.000775738 (* 1 = 0.000775738 loss)
I1016 22:32:06.656105   636 sgd_solver.cpp:105] Iteration 138400, lr = 0.001
I1016 22:32:15.340587  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:32:15.709586   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_138500.caffemodel
I1016 22:32:15.731096   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_138500.solverstate
I1016 22:32:15.741093   636 solver.cpp:330] Iteration 138500, Testing net (#0)
I1016 22:32:15.741093   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:32:18.038957  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:32:18.131964   636 solver.cpp:397]     Test net output #0: accuracy = 0.9467
I1016 22:32:18.131964   636 solver.cpp:397]     Test net output #1: loss = 0.207798 (* 1 = 0.207798 loss)
I1016 22:32:18.224014   636 solver.cpp:218] Iteration 138500 (8.64539 iter/s, 11.5669s/100 iters), loss = 0.00145173
I1016 22:32:18.224014   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:32:18.224014   636 solver.cpp:237]     Train net output #1: loss = 0.00145148 (* 1 = 0.00145148 loss)
I1016 22:32:18.224014   636 sgd_solver.cpp:105] Iteration 138500, lr = 0.001
I1016 22:32:27.562548   636 solver.cpp:218] Iteration 138600 (10.7083 iter/s, 9.33851s/100 iters), loss = 0.00227779
I1016 22:32:27.562548   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:32:27.562548   636 solver.cpp:237]     Train net output #1: loss = 0.00227755 (* 1 = 0.00227755 loss)
I1016 22:32:27.562548   636 sgd_solver.cpp:105] Iteration 138600, lr = 0.001
I1016 22:32:36.722623   636 solver.cpp:218] Iteration 138700 (10.9133 iter/s, 9.1631s/100 iters), loss = 0.00332087
I1016 22:32:36.722623   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:32:36.722623   636 solver.cpp:237]     Train net output #1: loss = 0.00332062 (* 1 = 0.00332062 loss)
I1016 22:32:36.722623   636 sgd_solver.cpp:105] Iteration 138700, lr = 0.001
I1016 22:32:45.925302   636 solver.cpp:218] Iteration 138800 (10.8618 iter/s, 9.20661s/100 iters), loss = 0.00605474
I1016 22:32:45.925302   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:32:45.925302   636 solver.cpp:237]     Train net output #1: loss = 0.0060545 (* 1 = 0.0060545 loss)
I1016 22:32:45.925302   636 sgd_solver.cpp:105] Iteration 138800, lr = 0.001
I1016 22:32:55.115972   636 solver.cpp:218] Iteration 138900 (10.8913 iter/s, 9.18165s/100 iters), loss = 0.000680675
I1016 22:32:55.115972   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:32:55.115972   636 solver.cpp:237]     Train net output #1: loss = 0.000680431 (* 1 = 0.000680431 loss)
I1016 22:32:55.115972   636 sgd_solver.cpp:105] Iteration 138900, lr = 0.001
I1016 22:33:03.807126  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:33:04.166079   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_139000.caffemodel
I1016 22:33:04.194337   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_139000.solverstate
I1016 22:33:04.206841   636 solver.cpp:330] Iteration 139000, Testing net (#0)
I1016 22:33:04.206841   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:33:06.457283  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:33:06.547318   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 22:33:06.547318   636 solver.cpp:397]     Test net output #1: loss = 0.207381 (* 1 = 0.207381 loss)
I1016 22:33:06.637368   636 solver.cpp:218] Iteration 139000 (8.67393 iter/s, 11.5288s/100 iters), loss = 0.00122137
I1016 22:33:06.637368   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:33:06.637368   636 solver.cpp:237]     Train net output #1: loss = 0.00122112 (* 1 = 0.00122112 loss)
I1016 22:33:06.637368   636 sgd_solver.cpp:105] Iteration 139000, lr = 0.001
I1016 22:33:15.795461   636 solver.cpp:218] Iteration 139100 (10.9294 iter/s, 9.14964s/100 iters), loss = 0.0016446
I1016 22:33:15.795461   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:33:15.795461   636 solver.cpp:237]     Train net output #1: loss = 0.00164436 (* 1 = 0.00164436 loss)
I1016 22:33:15.795461   636 sgd_solver.cpp:105] Iteration 139100, lr = 0.001
I1016 22:33:25.025956   636 solver.cpp:218] Iteration 139200 (10.8347 iter/s, 9.22965s/100 iters), loss = 0.00210204
I1016 22:33:25.025956   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:33:25.025956   636 solver.cpp:237]     Train net output #1: loss = 0.0021018 (* 1 = 0.0021018 loss)
I1016 22:33:25.025956   636 sgd_solver.cpp:105] Iteration 139200, lr = 0.001
I1016 22:33:34.318061   636 solver.cpp:218] Iteration 139300 (10.7625 iter/s, 9.29156s/100 iters), loss = 0.00320303
I1016 22:33:34.318061   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:33:34.318061   636 solver.cpp:237]     Train net output #1: loss = 0.00320278 (* 1 = 0.00320278 loss)
I1016 22:33:34.318061   636 sgd_solver.cpp:105] Iteration 139300, lr = 0.001
I1016 22:33:43.459782   636 solver.cpp:218] Iteration 139400 (10.9303 iter/s, 9.14889s/100 iters), loss = 0.00308981
I1016 22:33:43.459782   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:33:43.459782   636 solver.cpp:237]     Train net output #1: loss = 0.00308957 (* 1 = 0.00308957 loss)
I1016 22:33:43.459782   636 sgd_solver.cpp:105] Iteration 139400, lr = 0.001
I1016 22:33:52.142144  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:33:52.512181   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_139500.caffemodel
I1016 22:33:52.538195   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_139500.solverstate
I1016 22:33:52.550211   636 solver.cpp:330] Iteration 139500, Testing net (#0)
I1016 22:33:52.550211   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:33:54.803406  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:33:54.895678   636 solver.cpp:397]     Test net output #0: accuracy = 0.9464
I1016 22:33:54.895678   636 solver.cpp:397]     Test net output #1: loss = 0.20587 (* 1 = 0.20587 loss)
I1016 22:33:54.983695   636 solver.cpp:218] Iteration 139500 (8.68108 iter/s, 11.5193s/100 iters), loss = 0.00132554
I1016 22:33:54.983695   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:33:54.983695   636 solver.cpp:237]     Train net output #1: loss = 0.0013253 (* 1 = 0.0013253 loss)
I1016 22:33:54.983695   636 sgd_solver.cpp:105] Iteration 139500, lr = 0.001
I1016 22:34:04.143273   636 solver.cpp:218] Iteration 139600 (10.9226 iter/s, 9.15532s/100 iters), loss = 0.000883549
I1016 22:34:04.143273   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:34:04.143273   636 solver.cpp:237]     Train net output #1: loss = 0.000883307 (* 1 = 0.000883307 loss)
I1016 22:34:04.143273   636 sgd_solver.cpp:105] Iteration 139600, lr = 0.001
I1016 22:34:13.284013   636 solver.cpp:218] Iteration 139700 (10.9307 iter/s, 9.14854s/100 iters), loss = 0.00278203
I1016 22:34:13.284013   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:34:13.284013   636 solver.cpp:237]     Train net output #1: loss = 0.00278179 (* 1 = 0.00278179 loss)
I1016 22:34:13.284013   636 sgd_solver.cpp:105] Iteration 139700, lr = 0.001
I1016 22:34:22.437932   636 solver.cpp:218] Iteration 139800 (10.9349 iter/s, 9.14507s/100 iters), loss = 0.00163167
I1016 22:34:22.437932   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:34:22.437932   636 solver.cpp:237]     Train net output #1: loss = 0.00163143 (* 1 = 0.00163143 loss)
I1016 22:34:22.437932   636 sgd_solver.cpp:105] Iteration 139800, lr = 0.001
I1016 22:34:31.598999   636 solver.cpp:218] Iteration 139900 (10.9164 iter/s, 9.1605s/100 iters), loss = 0.00109194
I1016 22:34:31.598999   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:34:31.598999   636 solver.cpp:237]     Train net output #1: loss = 0.00109169 (* 1 = 0.00109169 loss)
I1016 22:34:31.598999   636 sgd_solver.cpp:105] Iteration 139900, lr = 0.001
I1016 22:34:40.289180  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:34:40.652197   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_140000.caffemodel
I1016 22:34:40.678205   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_140000.solverstate
I1016 22:34:40.690217   636 solver.cpp:330] Iteration 140000, Testing net (#0)
I1016 22:34:40.690217   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:34:42.948401  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:34:43.040448   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 22:34:43.040448   636 solver.cpp:397]     Test net output #1: loss = 0.207964 (* 1 = 0.207964 loss)
I1016 22:34:43.128438   636 solver.cpp:218] Iteration 140000 (8.67318 iter/s, 11.5298s/100 iters), loss = 0.00108217
I1016 22:34:43.129439   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:34:43.129439   636 solver.cpp:237]     Train net output #1: loss = 0.00108193 (* 1 = 0.00108193 loss)
I1016 22:34:43.129439   636 sgd_solver.cpp:105] Iteration 140000, lr = 0.001
I1016 22:34:52.276772   636 solver.cpp:218] Iteration 140100 (10.9322 iter/s, 9.1473s/100 iters), loss = 0.00139086
I1016 22:34:52.277272   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:34:52.277272   636 solver.cpp:237]     Train net output #1: loss = 0.00139062 (* 1 = 0.00139062 loss)
I1016 22:34:52.277272   636 sgd_solver.cpp:105] Iteration 140100, lr = 0.001
I1016 22:35:01.431030   636 solver.cpp:218] Iteration 140200 (10.9222 iter/s, 9.15565s/100 iters), loss = 0.00239852
I1016 22:35:01.431030   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:01.431030   636 solver.cpp:237]     Train net output #1: loss = 0.00239828 (* 1 = 0.00239828 loss)
I1016 22:35:01.431030   636 sgd_solver.cpp:105] Iteration 140200, lr = 0.001
I1016 22:35:10.567117   636 solver.cpp:218] Iteration 140300 (10.9469 iter/s, 9.13499s/100 iters), loss = 0.00171121
I1016 22:35:10.567117   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:10.567117   636 solver.cpp:237]     Train net output #1: loss = 0.00171096 (* 1 = 0.00171096 loss)
I1016 22:35:10.567117   636 sgd_solver.cpp:105] Iteration 140300, lr = 0.001
I1016 22:35:19.712888   636 solver.cpp:218] Iteration 140400 (10.9363 iter/s, 9.1439s/100 iters), loss = 0.00222702
I1016 22:35:19.712888   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:19.712888   636 solver.cpp:237]     Train net output #1: loss = 0.00222677 (* 1 = 0.00222677 loss)
I1016 22:35:19.712888   636 sgd_solver.cpp:105] Iteration 140400, lr = 0.001
I1016 22:35:28.402277  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:35:28.757623   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_140500.caffemodel
I1016 22:35:28.787618   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_140500.solverstate
I1016 22:35:28.797618   636 solver.cpp:330] Iteration 140500, Testing net (#0)
I1016 22:35:28.797618   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:35:31.058665  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:35:31.148675   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 22:35:31.148675   636 solver.cpp:397]     Test net output #1: loss = 0.20739 (* 1 = 0.20739 loss)
I1016 22:35:31.238493   636 solver.cpp:218] Iteration 140500 (8.67672 iter/s, 11.5251s/100 iters), loss = 0.00230526
I1016 22:35:31.238493   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:31.238493   636 solver.cpp:237]     Train net output #1: loss = 0.00230502 (* 1 = 0.00230502 loss)
I1016 22:35:31.238493   636 sgd_solver.cpp:105] Iteration 140500, lr = 0.001
I1016 22:35:40.375006   636 solver.cpp:218] Iteration 140600 (10.9428 iter/s, 9.13847s/100 iters), loss = 0.00159158
I1016 22:35:40.375006   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:40.375006   636 solver.cpp:237]     Train net output #1: loss = 0.00159134 (* 1 = 0.00159134 loss)
I1016 22:35:40.375006   636 sgd_solver.cpp:105] Iteration 140600, lr = 0.001
I1016 22:35:49.517747   636 solver.cpp:218] Iteration 140700 (10.9306 iter/s, 9.14861s/100 iters), loss = 0.00304468
I1016 22:35:49.517747   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:49.517747   636 solver.cpp:237]     Train net output #1: loss = 0.00304443 (* 1 = 0.00304443 loss)
I1016 22:35:49.517747   636 sgd_solver.cpp:105] Iteration 140700, lr = 0.001
I1016 22:35:58.688088   636 solver.cpp:218] Iteration 140800 (10.9165 iter/s, 9.16045s/100 iters), loss = 0.00170638
I1016 22:35:58.688088   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:35:58.688088   636 solver.cpp:237]     Train net output #1: loss = 0.00170614 (* 1 = 0.00170614 loss)
I1016 22:35:58.688088   636 sgd_solver.cpp:105] Iteration 140800, lr = 0.001
I1016 22:36:08.006876   636 solver.cpp:218] Iteration 140900 (10.726 iter/s, 9.32314s/100 iters), loss = 0.00103098
I1016 22:36:08.006876   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:36:08.006876   636 solver.cpp:237]     Train net output #1: loss = 0.00103074 (* 1 = 0.00103074 loss)
I1016 22:36:08.006876   636 sgd_solver.cpp:105] Iteration 140900, lr = 0.001
I1016 22:36:16.720875  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:36:17.088413   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_141000.caffemodel
I1016 22:36:17.115931   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_141000.solverstate
I1016 22:36:17.127943   636 solver.cpp:330] Iteration 141000, Testing net (#0)
I1016 22:36:17.127943   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:36:19.424410  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:36:19.517413   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 22:36:19.517413   636 solver.cpp:397]     Test net output #1: loss = 0.208087 (* 1 = 0.208087 loss)
I1016 22:36:19.608433   636 solver.cpp:218] Iteration 141000 (8.62316 iter/s, 11.5967s/100 iters), loss = 0.00117024
I1016 22:36:19.608433   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:36:19.608433   636 solver.cpp:237]     Train net output #1: loss = 0.00117 (* 1 = 0.00117 loss)
I1016 22:36:19.608433   636 sgd_solver.cpp:105] Iteration 141000, lr = 0.001
I1016 22:36:28.908202   636 solver.cpp:218] Iteration 141100 (10.7541 iter/s, 9.29877s/100 iters), loss = 0.0020708
I1016 22:36:28.908202   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:36:28.908202   636 solver.cpp:237]     Train net output #1: loss = 0.00207056 (* 1 = 0.00207056 loss)
I1016 22:36:28.908202   636 sgd_solver.cpp:105] Iteration 141100, lr = 0.001
I1016 22:36:38.222126   636 solver.cpp:218] Iteration 141200 (10.7372 iter/s, 9.31341s/100 iters), loss = 0.00395311
I1016 22:36:38.222126   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:36:38.222126   636 solver.cpp:237]     Train net output #1: loss = 0.00395287 (* 1 = 0.00395287 loss)
I1016 22:36:38.222126   636 sgd_solver.cpp:105] Iteration 141200, lr = 0.001
I1016 22:36:47.424376   636 solver.cpp:218] Iteration 141300 (10.8678 iter/s, 9.2015s/100 iters), loss = 0.00261465
I1016 22:36:47.424376   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:36:47.424376   636 solver.cpp:237]     Train net output #1: loss = 0.00261441 (* 1 = 0.00261441 loss)
I1016 22:36:47.424376   636 sgd_solver.cpp:105] Iteration 141300, lr = 0.001
I1016 22:36:56.704614   636 solver.cpp:218] Iteration 141400 (10.7756 iter/s, 9.2802s/100 iters), loss = 0.00278745
I1016 22:36:56.704614   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:36:56.704614   636 solver.cpp:237]     Train net output #1: loss = 0.00278721 (* 1 = 0.00278721 loss)
I1016 22:36:56.704614   636 sgd_solver.cpp:105] Iteration 141400, lr = 0.001
I1016 22:37:05.516650  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:37:05.883363   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_141500.caffemodel
I1016 22:37:05.903369   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_141500.solverstate
I1016 22:37:05.913367   636 solver.cpp:330] Iteration 141500, Testing net (#0)
I1016 22:37:05.913367   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:37:08.201822  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:37:08.289032   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:37:08.289032   636 solver.cpp:397]     Test net output #1: loss = 0.207727 (* 1 = 0.207727 loss)
I1016 22:37:08.383031   636 solver.cpp:218] Iteration 141500 (8.56384 iter/s, 11.677s/100 iters), loss = 0.00125587
I1016 22:37:08.383031   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:37:08.383031   636 solver.cpp:237]     Train net output #1: loss = 0.00125563 (* 1 = 0.00125563 loss)
I1016 22:37:08.383031   636 sgd_solver.cpp:105] Iteration 141500, lr = 0.001
I1016 22:37:17.685494   636 solver.cpp:218] Iteration 141600 (10.7506 iter/s, 9.30181s/100 iters), loss = 0.00211581
I1016 22:37:17.685494   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:37:17.685494   636 solver.cpp:237]     Train net output #1: loss = 0.00211557 (* 1 = 0.00211557 loss)
I1016 22:37:17.685494   636 sgd_solver.cpp:105] Iteration 141600, lr = 0.001
I1016 22:37:26.864181   636 solver.cpp:218] Iteration 141700 (10.8899 iter/s, 9.18286s/100 iters), loss = 0.00305547
I1016 22:37:26.864181   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:37:26.864181   636 solver.cpp:237]     Train net output #1: loss = 0.00305523 (* 1 = 0.00305523 loss)
I1016 22:37:26.864181   636 sgd_solver.cpp:105] Iteration 141700, lr = 0.001
I1016 22:37:36.008167   636 solver.cpp:218] Iteration 141800 (10.9409 iter/s, 9.14006s/100 iters), loss = 0.00279677
I1016 22:37:36.008167   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:37:36.008167   636 solver.cpp:237]     Train net output #1: loss = 0.00279653 (* 1 = 0.00279653 loss)
I1016 22:37:36.008167   636 sgd_solver.cpp:105] Iteration 141800, lr = 0.001
I1016 22:37:45.186481   636 solver.cpp:218] Iteration 141900 (10.8974 iter/s, 9.1765s/100 iters), loss = 0.000911744
I1016 22:37:45.186481   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:37:45.186481   636 solver.cpp:237]     Train net output #1: loss = 0.000911505 (* 1 = 0.000911505 loss)
I1016 22:37:45.186481   636 sgd_solver.cpp:105] Iteration 141900, lr = 0.001
I1016 22:37:53.892048  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:37:54.268080   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_142000.caffemodel
I1016 22:37:54.295068   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_142000.solverstate
I1016 22:37:54.308068   636 solver.cpp:330] Iteration 142000, Testing net (#0)
I1016 22:37:54.308068   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:37:56.574363  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:37:56.664361   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 22:37:56.664361   636 solver.cpp:397]     Test net output #1: loss = 0.207916 (* 1 = 0.207916 loss)
I1016 22:37:56.754365   636 solver.cpp:218] Iteration 142000 (8.64125 iter/s, 11.5724s/100 iters), loss = 0.00209823
I1016 22:37:56.754365   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:37:56.754365   636 solver.cpp:237]     Train net output #1: loss = 0.00209799 (* 1 = 0.00209799 loss)
I1016 22:37:56.754365   636 sgd_solver.cpp:105] Iteration 142000, lr = 0.001
I1016 22:38:05.950100   636 solver.cpp:218] Iteration 142100 (10.8813 iter/s, 9.19009s/100 iters), loss = 0.00247955
I1016 22:38:05.950100   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:38:05.950100   636 solver.cpp:237]     Train net output #1: loss = 0.00247931 (* 1 = 0.00247931 loss)
I1016 22:38:05.950100   636 sgd_solver.cpp:105] Iteration 142100, lr = 0.001
I1016 22:38:15.094861   636 solver.cpp:218] Iteration 142200 (10.9309 iter/s, 9.14837s/100 iters), loss = 0.00323792
I1016 22:38:15.094861   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:38:15.094861   636 solver.cpp:237]     Train net output #1: loss = 0.00323768 (* 1 = 0.00323768 loss)
I1016 22:38:15.094861   636 sgd_solver.cpp:105] Iteration 142200, lr = 0.001
I1016 22:38:24.257377   636 solver.cpp:218] Iteration 142300 (10.9188 iter/s, 9.15853s/100 iters), loss = 0.00170422
I1016 22:38:24.257377   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:38:24.257377   636 solver.cpp:237]     Train net output #1: loss = 0.00170398 (* 1 = 0.00170398 loss)
I1016 22:38:24.257377   636 sgd_solver.cpp:105] Iteration 142300, lr = 0.001
I1016 22:38:33.423625   636 solver.cpp:218] Iteration 142400 (10.9029 iter/s, 9.17189s/100 iters), loss = 0.000500921
I1016 22:38:33.423625   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:38:33.423625   636 solver.cpp:237]     Train net output #1: loss = 0.000500682 (* 1 = 0.000500682 loss)
I1016 22:38:33.423625   636 sgd_solver.cpp:105] Iteration 142400, lr = 0.001
I1016 22:38:42.119675  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:38:42.490849   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_142500.caffemodel
I1016 22:38:42.516849   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_142500.solverstate
I1016 22:38:42.528851   636 solver.cpp:330] Iteration 142500, Testing net (#0)
I1016 22:38:42.528851   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:38:44.791505  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:38:44.891376   636 solver.cpp:397]     Test net output #0: accuracy = 0.9464
I1016 22:38:44.891376   636 solver.cpp:397]     Test net output #1: loss = 0.207659 (* 1 = 0.207659 loss)
I1016 22:38:44.971382   636 solver.cpp:218] Iteration 142500 (8.65879 iter/s, 11.549s/100 iters), loss = 0.00195974
I1016 22:38:44.971382   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:38:44.971382   636 solver.cpp:237]     Train net output #1: loss = 0.0019595 (* 1 = 0.0019595 loss)
I1016 22:38:44.971382   636 sgd_solver.cpp:105] Iteration 142500, lr = 0.001
I1016 22:38:54.148922   636 solver.cpp:218] Iteration 142600 (10.9043 iter/s, 9.17065s/100 iters), loss = 0.00309161
I1016 22:38:54.148922   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:38:54.148922   636 solver.cpp:237]     Train net output #1: loss = 0.00309137 (* 1 = 0.00309137 loss)
I1016 22:38:54.148922   636 sgd_solver.cpp:105] Iteration 142600, lr = 0.001
I1016 22:39:03.389917   636 solver.cpp:218] Iteration 142700 (10.8246 iter/s, 9.23818s/100 iters), loss = 0.00238862
I1016 22:39:03.389917   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:39:03.389917   636 solver.cpp:237]     Train net output #1: loss = 0.00238838 (* 1 = 0.00238838 loss)
I1016 22:39:03.389917   636 sgd_solver.cpp:105] Iteration 142700, lr = 0.001
I1016 22:39:12.600450   636 solver.cpp:218] Iteration 142800 (10.8578 iter/s, 9.20998s/100 iters), loss = 0.0016066
I1016 22:39:12.600450   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:39:12.600450   636 solver.cpp:237]     Train net output #1: loss = 0.00160636 (* 1 = 0.00160636 loss)
I1016 22:39:12.600450   636 sgd_solver.cpp:105] Iteration 142800, lr = 0.001
I1016 22:39:21.800794   636 solver.cpp:218] Iteration 142900 (10.8697 iter/s, 9.19988s/100 iters), loss = 0.00139355
I1016 22:39:21.800794   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:39:21.800794   636 solver.cpp:237]     Train net output #1: loss = 0.00139331 (* 1 = 0.00139331 loss)
I1016 22:39:21.800794   636 sgd_solver.cpp:105] Iteration 142900, lr = 0.001
I1016 22:39:30.575659  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:39:30.938555   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_143000.caffemodel
I1016 22:39:30.969557   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_143000.solverstate
I1016 22:39:30.982556   636 solver.cpp:330] Iteration 143000, Testing net (#0)
I1016 22:39:30.982556   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:39:33.299574  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:39:33.382359   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 22:39:33.382359   636 solver.cpp:397]     Test net output #1: loss = 0.207866 (* 1 = 0.207866 loss)
I1016 22:39:33.479919   636 solver.cpp:218] Iteration 143000 (8.56282 iter/s, 11.6784s/100 iters), loss = 0.00220863
I1016 22:39:33.479919   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:39:33.479919   636 solver.cpp:237]     Train net output #1: loss = 0.00220839 (* 1 = 0.00220839 loss)
I1016 22:39:33.479919   636 sgd_solver.cpp:105] Iteration 143000, lr = 0.001
I1016 22:39:42.775696   636 solver.cpp:218] Iteration 143100 (10.758 iter/s, 9.29544s/100 iters), loss = 0.00259417
I1016 22:39:42.775696   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:39:42.775696   636 solver.cpp:237]     Train net output #1: loss = 0.00259393 (* 1 = 0.00259393 loss)
I1016 22:39:42.775696   636 sgd_solver.cpp:105] Iteration 143100, lr = 0.001
I1016 22:39:52.046717   636 solver.cpp:218] Iteration 143200 (10.787 iter/s, 9.27043s/100 iters), loss = 0.00389812
I1016 22:39:52.046717   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:39:52.046717   636 solver.cpp:237]     Train net output #1: loss = 0.00389788 (* 1 = 0.00389788 loss)
I1016 22:39:52.046717   636 sgd_solver.cpp:105] Iteration 143200, lr = 0.001
I1016 22:40:01.352946   636 solver.cpp:218] Iteration 143300 (10.7416 iter/s, 9.30957s/100 iters), loss = 0.00157141
I1016 22:40:01.352946   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:01.352946   636 solver.cpp:237]     Train net output #1: loss = 0.00157117 (* 1 = 0.00157117 loss)
I1016 22:40:01.352946   636 sgd_solver.cpp:105] Iteration 143300, lr = 0.001
I1016 22:40:10.506464   636 solver.cpp:218] Iteration 143400 (10.9277 iter/s, 9.1511s/100 iters), loss = 0.000988189
I1016 22:40:10.506464   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:10.506464   636 solver.cpp:237]     Train net output #1: loss = 0.000987945 (* 1 = 0.000987945 loss)
I1016 22:40:10.506464   636 sgd_solver.cpp:105] Iteration 143400, lr = 0.001
I1016 22:40:19.417382  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:40:19.788446   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_143500.caffemodel
I1016 22:40:19.816447   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_143500.solverstate
I1016 22:40:19.828446   636 solver.cpp:330] Iteration 143500, Testing net (#0)
I1016 22:40:19.828446   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:40:22.140655  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:40:22.231662   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 22:40:22.231662   636 solver.cpp:397]     Test net output #1: loss = 0.207357 (* 1 = 0.207357 loss)
I1016 22:40:22.320976   636 solver.cpp:218] Iteration 143500 (8.4662 iter/s, 11.8117s/100 iters), loss = 0.00151242
I1016 22:40:22.320976   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:22.320976   636 solver.cpp:237]     Train net output #1: loss = 0.00151218 (* 1 = 0.00151218 loss)
I1016 22:40:22.320976   636 sgd_solver.cpp:105] Iteration 143500, lr = 0.001
I1016 22:40:31.580041   636 solver.cpp:218] Iteration 143600 (10.801 iter/s, 9.25839s/100 iters), loss = 0.00151257
I1016 22:40:31.580041   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:31.580041   636 solver.cpp:237]     Train net output #1: loss = 0.00151233 (* 1 = 0.00151233 loss)
I1016 22:40:31.580041   636 sgd_solver.cpp:105] Iteration 143600, lr = 0.001
I1016 22:40:40.889479   636 solver.cpp:218] Iteration 143700 (10.7347 iter/s, 9.3156s/100 iters), loss = 0.00381869
I1016 22:40:40.889479   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:40.889479   636 solver.cpp:237]     Train net output #1: loss = 0.00381845 (* 1 = 0.00381845 loss)
I1016 22:40:40.889479   636 sgd_solver.cpp:105] Iteration 143700, lr = 0.001
I1016 22:40:50.238010   636 solver.cpp:218] Iteration 143800 (10.7047 iter/s, 9.34173s/100 iters), loss = 0.00182921
I1016 22:40:50.238010   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:50.238010   636 solver.cpp:237]     Train net output #1: loss = 0.00182896 (* 1 = 0.00182896 loss)
I1016 22:40:50.238010   636 sgd_solver.cpp:105] Iteration 143800, lr = 0.001
I1016 22:40:59.471285   636 solver.cpp:218] Iteration 143900 (10.831 iter/s, 9.2328s/100 iters), loss = 0.0014851
I1016 22:40:59.471285   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:40:59.471285   636 solver.cpp:237]     Train net output #1: loss = 0.00148486 (* 1 = 0.00148486 loss)
I1016 22:40:59.471285   636 sgd_solver.cpp:105] Iteration 143900, lr = 0.001
I1016 22:41:08.252152  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:41:08.624213   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_144000.caffemodel
I1016 22:41:08.652214   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_144000.solverstate
I1016 22:41:08.665215   636 solver.cpp:330] Iteration 144000, Testing net (#0)
I1016 22:41:08.665215   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:41:10.949661  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:41:11.047957   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 22:41:11.047957   636 solver.cpp:397]     Test net output #1: loss = 0.206911 (* 1 = 0.206911 loss)
I1016 22:41:11.132558   636 solver.cpp:218] Iteration 144000 (8.57308 iter/s, 11.6644s/100 iters), loss = 0.00111226
I1016 22:41:11.132558   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:41:11.132558   636 solver.cpp:237]     Train net output #1: loss = 0.00111202 (* 1 = 0.00111202 loss)
I1016 22:41:11.132558   636 sgd_solver.cpp:105] Iteration 144000, lr = 0.001
I1016 22:41:20.348412   636 solver.cpp:218] Iteration 144100 (10.8495 iter/s, 9.21703s/100 iters), loss = 0.00549905
I1016 22:41:20.348412   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:41:20.348412   636 solver.cpp:237]     Train net output #1: loss = 0.00549881 (* 1 = 0.00549881 loss)
I1016 22:41:20.348412   636 sgd_solver.cpp:105] Iteration 144100, lr = 0.001
I1016 22:41:29.511476   636 solver.cpp:218] Iteration 144200 (10.921 iter/s, 9.15665s/100 iters), loss = 0.00249817
I1016 22:41:29.511476   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:41:29.511476   636 solver.cpp:237]     Train net output #1: loss = 0.00249793 (* 1 = 0.00249793 loss)
I1016 22:41:29.511476   636 sgd_solver.cpp:105] Iteration 144200, lr = 0.001
I1016 22:41:38.790931   636 solver.cpp:218] Iteration 144300 (10.7766 iter/s, 9.27933s/100 iters), loss = 0.00177149
I1016 22:41:38.790931   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:41:38.790931   636 solver.cpp:237]     Train net output #1: loss = 0.00177125 (* 1 = 0.00177125 loss)
I1016 22:41:38.790931   636 sgd_solver.cpp:105] Iteration 144300, lr = 0.001
I1016 22:41:48.103955   636 solver.cpp:218] Iteration 144400 (10.7384 iter/s, 9.31236s/100 iters), loss = 0.00200938
I1016 22:41:48.103955   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:41:48.103955   636 solver.cpp:237]     Train net output #1: loss = 0.00200913 (* 1 = 0.00200913 loss)
I1016 22:41:48.103955   636 sgd_solver.cpp:105] Iteration 144400, lr = 0.001
I1016 22:41:56.947613  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:41:57.317502   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_144500.caffemodel
I1016 22:41:57.344502   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_144500.solverstate
I1016 22:41:57.356506   636 solver.cpp:330] Iteration 144500, Testing net (#0)
I1016 22:41:57.357007   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:41:59.619006  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:41:59.718768   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:41:59.718768   636 solver.cpp:397]     Test net output #1: loss = 0.208479 (* 1 = 0.208479 loss)
I1016 22:41:59.799350   636 solver.cpp:218] Iteration 144500 (8.54437 iter/s, 11.7036s/100 iters), loss = 0.000943414
I1016 22:41:59.799350   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:41:59.799350   636 solver.cpp:237]     Train net output #1: loss = 0.000943172 (* 1 = 0.000943172 loss)
I1016 22:41:59.799350   636 sgd_solver.cpp:105] Iteration 144500, lr = 0.001
I1016 22:42:09.132426   636 solver.cpp:218] Iteration 144600 (10.7255 iter/s, 9.32354s/100 iters), loss = 0.00237124
I1016 22:42:09.132426   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:42:09.132426   636 solver.cpp:237]     Train net output #1: loss = 0.00237099 (* 1 = 0.00237099 loss)
I1016 22:42:09.132426   636 sgd_solver.cpp:105] Iteration 144600, lr = 0.001
I1016 22:42:18.432431   636 solver.cpp:218] Iteration 144700 (10.7532 iter/s, 9.29956s/100 iters), loss = 0.00522056
I1016 22:42:18.432431   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:42:18.432431   636 solver.cpp:237]     Train net output #1: loss = 0.00522031 (* 1 = 0.00522031 loss)
I1016 22:42:18.432431   636 sgd_solver.cpp:105] Iteration 144700, lr = 0.001
I1016 22:42:27.697365   636 solver.cpp:218] Iteration 144800 (10.7912 iter/s, 9.26679s/100 iters), loss = 0.0021796
I1016 22:42:27.697365   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:42:27.697365   636 solver.cpp:237]     Train net output #1: loss = 0.00217936 (* 1 = 0.00217936 loss)
I1016 22:42:27.697365   636 sgd_solver.cpp:105] Iteration 144800, lr = 0.001
I1016 22:42:36.892410   636 solver.cpp:218] Iteration 144900 (10.8738 iter/s, 9.19638s/100 iters), loss = 0.0015993
I1016 22:42:36.892410   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:42:36.892410   636 solver.cpp:237]     Train net output #1: loss = 0.00159906 (* 1 = 0.00159906 loss)
I1016 22:42:36.892410   636 sgd_solver.cpp:105] Iteration 144900, lr = 0.001
I1016 22:42:45.652284  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:42:46.019634   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_145000.caffemodel
I1016 22:42:46.045142   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_145000.solverstate
I1016 22:42:46.055142   636 solver.cpp:330] Iteration 145000, Testing net (#0)
I1016 22:42:46.055142   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:42:48.334808  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:42:48.428820   636 solver.cpp:397]     Test net output #0: accuracy = 0.9468
I1016 22:42:48.428820   636 solver.cpp:397]     Test net output #1: loss = 0.206807 (* 1 = 0.206807 loss)
I1016 22:42:48.523008   636 solver.cpp:218] Iteration 145000 (8.60236 iter/s, 11.6247s/100 iters), loss = 0.00167922
I1016 22:42:48.523008   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:42:48.523008   636 solver.cpp:237]     Train net output #1: loss = 0.00167898 (* 1 = 0.00167898 loss)
I1016 22:42:48.523008   636 sgd_solver.cpp:105] Iteration 145000, lr = 0.001
I1016 22:42:57.832449   636 solver.cpp:218] Iteration 145100 (10.7423 iter/s, 9.30902s/100 iters), loss = 0.00156129
I1016 22:42:57.832449   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:42:57.832449   636 solver.cpp:237]     Train net output #1: loss = 0.00156105 (* 1 = 0.00156105 loss)
I1016 22:42:57.832449   636 sgd_solver.cpp:105] Iteration 145100, lr = 0.001
I1016 22:43:07.233875   636 solver.cpp:218] Iteration 145200 (10.6371 iter/s, 9.40105s/100 iters), loss = 0.00214748
I1016 22:43:07.233875   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:43:07.233875   636 solver.cpp:237]     Train net output #1: loss = 0.00214724 (* 1 = 0.00214724 loss)
I1016 22:43:07.233875   636 sgd_solver.cpp:105] Iteration 145200, lr = 0.001
I1016 22:43:16.599823   636 solver.cpp:218] Iteration 145300 (10.6779 iter/s, 9.36518s/100 iters), loss = 0.00418865
I1016 22:43:16.599823   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:43:16.599823   636 solver.cpp:237]     Train net output #1: loss = 0.00418841 (* 1 = 0.00418841 loss)
I1016 22:43:16.599823   636 sgd_solver.cpp:105] Iteration 145300, lr = 0.001
I1016 22:43:25.936058   636 solver.cpp:218] Iteration 145400 (10.7047 iter/s, 9.3417s/100 iters), loss = 0.000819549
I1016 22:43:25.936058   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:43:25.936058   636 solver.cpp:237]     Train net output #1: loss = 0.000819305 (* 1 = 0.000819305 loss)
I1016 22:43:25.936058   636 sgd_solver.cpp:105] Iteration 145400, lr = 0.001
I1016 22:43:34.696615  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:43:35.059610   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_145500.caffemodel
I1016 22:43:35.088609   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_145500.solverstate
I1016 22:43:35.100620   636 solver.cpp:330] Iteration 145500, Testing net (#0)
I1016 22:43:35.100620   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:43:37.402737  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:43:37.495750   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 22:43:37.495750   636 solver.cpp:397]     Test net output #1: loss = 0.207133 (* 1 = 0.207133 loss)
I1016 22:43:37.588513   636 solver.cpp:218] Iteration 145500 (8.58685 iter/s, 11.6457s/100 iters), loss = 0.00292165
I1016 22:43:37.588513   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:43:37.588513   636 solver.cpp:237]     Train net output #1: loss = 0.00292141 (* 1 = 0.00292141 loss)
I1016 22:43:37.588513   636 sgd_solver.cpp:105] Iteration 145500, lr = 0.001
I1016 22:43:46.842267   636 solver.cpp:218] Iteration 145600 (10.8072 iter/s, 9.25306s/100 iters), loss = 0.00346087
I1016 22:43:46.842267   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:43:46.842267   636 solver.cpp:237]     Train net output #1: loss = 0.00346062 (* 1 = 0.00346062 loss)
I1016 22:43:46.842267   636 sgd_solver.cpp:105] Iteration 145600, lr = 0.001
I1016 22:43:56.108783   636 solver.cpp:218] Iteration 145700 (10.7914 iter/s, 9.26666s/100 iters), loss = 0.00382645
I1016 22:43:56.109783   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:43:56.109783   636 solver.cpp:237]     Train net output #1: loss = 0.0038262 (* 1 = 0.0038262 loss)
I1016 22:43:56.109783   636 sgd_solver.cpp:105] Iteration 145700, lr = 0.001
I1016 22:44:05.469005   636 solver.cpp:218] Iteration 145800 (10.6848 iter/s, 9.35907s/100 iters), loss = 0.00120591
I1016 22:44:05.469005   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:44:05.469005   636 solver.cpp:237]     Train net output #1: loss = 0.00120566 (* 1 = 0.00120566 loss)
I1016 22:44:05.469005   636 sgd_solver.cpp:105] Iteration 145800, lr = 0.001
I1016 22:44:14.799310   636 solver.cpp:218] Iteration 145900 (10.7181 iter/s, 9.33001s/100 iters), loss = 0.00145116
I1016 22:44:14.799310   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:44:14.799310   636 solver.cpp:237]     Train net output #1: loss = 0.00145091 (* 1 = 0.00145091 loss)
I1016 22:44:14.799310   636 sgd_solver.cpp:105] Iteration 145900, lr = 0.001
I1016 22:44:23.513501  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:44:23.873385   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_146000.caffemodel
I1016 22:44:23.893389   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_146000.solverstate
I1016 22:44:23.913390   636 solver.cpp:330] Iteration 146000, Testing net (#0)
I1016 22:44:23.913390   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:44:26.213929  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:44:26.304926   636 solver.cpp:397]     Test net output #0: accuracy = 0.9467
I1016 22:44:26.304926   636 solver.cpp:397]     Test net output #1: loss = 0.206715 (* 1 = 0.206715 loss)
I1016 22:44:26.393956   636 solver.cpp:218] Iteration 146000 (8.62521 iter/s, 11.5939s/100 iters), loss = 0.000871671
I1016 22:44:26.393956   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:44:26.393956   636 solver.cpp:237]     Train net output #1: loss = 0.000871426 (* 1 = 0.000871426 loss)
I1016 22:44:26.393956   636 sgd_solver.cpp:105] Iteration 146000, lr = 0.001
I1016 22:44:35.708495   636 solver.cpp:218] Iteration 146100 (10.7369 iter/s, 9.31364s/100 iters), loss = 0.00102605
I1016 22:44:35.708495   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:44:35.708495   636 solver.cpp:237]     Train net output #1: loss = 0.0010258 (* 1 = 0.0010258 loss)
I1016 22:44:35.708495   636 sgd_solver.cpp:105] Iteration 146100, lr = 0.001
I1016 22:44:44.893757   636 solver.cpp:218] Iteration 146200 (10.8877 iter/s, 9.18466s/100 iters), loss = 0.0019805
I1016 22:44:44.893757   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:44:44.893757   636 solver.cpp:237]     Train net output #1: loss = 0.00198026 (* 1 = 0.00198026 loss)
I1016 22:44:44.893757   636 sgd_solver.cpp:105] Iteration 146200, lr = 0.001
I1016 22:44:54.171232   636 solver.cpp:218] Iteration 146300 (10.7793 iter/s, 9.27701s/100 iters), loss = 0.0022389
I1016 22:44:54.171232   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:44:54.171232   636 solver.cpp:237]     Train net output #1: loss = 0.00223865 (* 1 = 0.00223865 loss)
I1016 22:44:54.171232   636 sgd_solver.cpp:105] Iteration 146300, lr = 0.001
I1016 22:45:03.331023   636 solver.cpp:218] Iteration 146400 (10.9185 iter/s, 9.15874s/100 iters), loss = 0.00161876
I1016 22:45:03.331023   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:45:03.331023   636 solver.cpp:237]     Train net output #1: loss = 0.00161851 (* 1 = 0.00161851 loss)
I1016 22:45:03.331023   636 sgd_solver.cpp:105] Iteration 146400, lr = 0.001
I1016 22:45:12.210974  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:45:12.565251   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_146500.caffemodel
I1016 22:45:12.595259   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_146500.solverstate
I1016 22:45:12.605267   636 solver.cpp:330] Iteration 146500, Testing net (#0)
I1016 22:45:12.605267   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:45:14.876126  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:45:14.974120   636 solver.cpp:397]     Test net output #0: accuracy = 0.9444
I1016 22:45:14.974120   636 solver.cpp:397]     Test net output #1: loss = 0.206903 (* 1 = 0.206903 loss)
I1016 22:45:15.066146   636 solver.cpp:218] Iteration 146500 (8.5214 iter/s, 11.7352s/100 iters), loss = 0.0012548
I1016 22:45:15.066146   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:45:15.066146   636 solver.cpp:237]     Train net output #1: loss = 0.00125456 (* 1 = 0.00125456 loss)
I1016 22:45:15.066146   636 sgd_solver.cpp:105] Iteration 146500, lr = 0.001
I1016 22:45:24.283102   636 solver.cpp:218] Iteration 146600 (10.8509 iter/s, 9.21581s/100 iters), loss = 0.00150878
I1016 22:45:24.283102   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:45:24.283102   636 solver.cpp:237]     Train net output #1: loss = 0.00150854 (* 1 = 0.00150854 loss)
I1016 22:45:24.283102   636 sgd_solver.cpp:105] Iteration 146600, lr = 0.001
I1016 22:45:33.454777   636 solver.cpp:218] Iteration 146700 (10.8994 iter/s, 9.17481s/100 iters), loss = 0.00270616
I1016 22:45:33.454777   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:45:33.454777   636 solver.cpp:237]     Train net output #1: loss = 0.00270591 (* 1 = 0.00270591 loss)
I1016 22:45:33.454777   636 sgd_solver.cpp:105] Iteration 146700, lr = 0.001
I1016 22:45:42.659559   636 solver.cpp:218] Iteration 146800 (10.8658 iter/s, 9.20323s/100 iters), loss = 0.00265269
I1016 22:45:42.659559   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:45:42.659559   636 solver.cpp:237]     Train net output #1: loss = 0.00265244 (* 1 = 0.00265244 loss)
I1016 22:45:42.659559   636 sgd_solver.cpp:105] Iteration 146800, lr = 0.001
I1016 22:45:51.813143   636 solver.cpp:218] Iteration 146900 (10.928 iter/s, 9.15077s/100 iters), loss = 0.00240604
I1016 22:45:51.813143   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:45:51.813143   636 solver.cpp:237]     Train net output #1: loss = 0.00240579 (* 1 = 0.00240579 loss)
I1016 22:45:51.813143   636 sgd_solver.cpp:105] Iteration 146900, lr = 0.001
I1016 22:46:00.510820  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:46:00.872925   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_147000.caffemodel
I1016 22:46:00.901926   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_147000.solverstate
I1016 22:46:00.913924   636 solver.cpp:330] Iteration 147000, Testing net (#0)
I1016 22:46:00.913924   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:46:03.219085  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:46:03.312100   636 solver.cpp:397]     Test net output #0: accuracy = 0.945
I1016 22:46:03.312100   636 solver.cpp:397]     Test net output #1: loss = 0.206881 (* 1 = 0.206881 loss)
I1016 22:46:03.404093   636 solver.cpp:218] Iteration 147000 (8.62832 iter/s, 11.5897s/100 iters), loss = 0.00139617
I1016 22:46:03.404093   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:46:03.404093   636 solver.cpp:237]     Train net output #1: loss = 0.00139593 (* 1 = 0.00139593 loss)
I1016 22:46:03.404093   636 sgd_solver.cpp:105] Iteration 147000, lr = 0.001
I1016 22:46:12.616988   636 solver.cpp:218] Iteration 147100 (10.8541 iter/s, 9.21311s/100 iters), loss = 0.00323824
I1016 22:46:12.616988   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:46:12.616988   636 solver.cpp:237]     Train net output #1: loss = 0.003238 (* 1 = 0.003238 loss)
I1016 22:46:12.616988   636 sgd_solver.cpp:105] Iteration 147100, lr = 0.001
I1016 22:46:21.886030   636 solver.cpp:218] Iteration 147200 (10.7897 iter/s, 9.26809s/100 iters), loss = 0.00298351
I1016 22:46:21.886030   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:46:21.886030   636 solver.cpp:237]     Train net output #1: loss = 0.00298327 (* 1 = 0.00298327 loss)
I1016 22:46:21.886030   636 sgd_solver.cpp:105] Iteration 147200, lr = 0.001
I1016 22:46:31.057178   636 solver.cpp:218] Iteration 147300 (10.9045 iter/s, 9.17051s/100 iters), loss = 0.00120205
I1016 22:46:31.057178   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:46:31.057178   636 solver.cpp:237]     Train net output #1: loss = 0.0012018 (* 1 = 0.0012018 loss)
I1016 22:46:31.057178   636 sgd_solver.cpp:105] Iteration 147300, lr = 0.001
I1016 22:46:40.285209   636 solver.cpp:218] Iteration 147400 (10.8372 iter/s, 9.22749s/100 iters), loss = 0.000961135
I1016 22:46:40.285209   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:46:40.285209   636 solver.cpp:237]     Train net output #1: loss = 0.000960889 (* 1 = 0.000960889 loss)
I1016 22:46:40.285209   636 sgd_solver.cpp:105] Iteration 147400, lr = 0.001
I1016 22:46:49.040000  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:46:49.403550   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_147500.caffemodel
I1016 22:46:49.437057   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_147500.solverstate
I1016 22:46:49.452057   636 solver.cpp:330] Iteration 147500, Testing net (#0)
I1016 22:46:49.452057   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:46:51.739626  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:46:51.832131   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 22:46:51.832131   636 solver.cpp:397]     Test net output #1: loss = 0.206448 (* 1 = 0.206448 loss)
I1016 22:46:51.923629   636 solver.cpp:218] Iteration 147500 (8.59267 iter/s, 11.6378s/100 iters), loss = 0.00107876
I1016 22:46:51.923629   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:46:51.923629   636 solver.cpp:237]     Train net output #1: loss = 0.00107851 (* 1 = 0.00107851 loss)
I1016 22:46:51.923629   636 sgd_solver.cpp:105] Iteration 147500, lr = 0.001
I1016 22:47:01.243535   636 solver.cpp:218] Iteration 147600 (10.73 iter/s, 9.31966s/100 iters), loss = 0.00216382
I1016 22:47:01.243535   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:01.243535   636 solver.cpp:237]     Train net output #1: loss = 0.00216358 (* 1 = 0.00216358 loss)
I1016 22:47:01.243535   636 sgd_solver.cpp:105] Iteration 147600, lr = 0.001
I1016 22:47:10.486676   636 solver.cpp:218] Iteration 147700 (10.82 iter/s, 9.2421s/100 iters), loss = 0.00196281
I1016 22:47:10.486676   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:10.486676   636 solver.cpp:237]     Train net output #1: loss = 0.00196256 (* 1 = 0.00196256 loss)
I1016 22:47:10.486676   636 sgd_solver.cpp:105] Iteration 147700, lr = 0.001
I1016 22:47:19.691237   636 solver.cpp:218] Iteration 147800 (10.8649 iter/s, 9.20399s/100 iters), loss = 0.00136459
I1016 22:47:19.691237   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:19.691237   636 solver.cpp:237]     Train net output #1: loss = 0.00136434 (* 1 = 0.00136434 loss)
I1016 22:47:19.691237   636 sgd_solver.cpp:105] Iteration 147800, lr = 0.001
I1016 22:47:28.903475   636 solver.cpp:218] Iteration 147900 (10.856 iter/s, 9.21152s/100 iters), loss = 0.00106372
I1016 22:47:28.903475   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:28.903475   636 solver.cpp:237]     Train net output #1: loss = 0.00106347 (* 1 = 0.00106347 loss)
I1016 22:47:28.903475   636 sgd_solver.cpp:105] Iteration 147900, lr = 0.001
I1016 22:47:37.722517  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:47:38.098619   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_148000.caffemodel
I1016 22:47:38.125622   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_148000.solverstate
I1016 22:47:38.139143   636 solver.cpp:330] Iteration 148000, Testing net (#0)
I1016 22:47:38.139143   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:47:40.399996  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:47:40.492007   636 solver.cpp:397]     Test net output #0: accuracy = 0.9465
I1016 22:47:40.492007   636 solver.cpp:397]     Test net output #1: loss = 0.206648 (* 1 = 0.206648 loss)
I1016 22:47:40.581008   636 solver.cpp:218] Iteration 148000 (8.56394 iter/s, 11.6769s/100 iters), loss = 0.00107048
I1016 22:47:40.581008   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:40.581008   636 solver.cpp:237]     Train net output #1: loss = 0.00107023 (* 1 = 0.00107023 loss)
I1016 22:47:40.581008   636 sgd_solver.cpp:105] Iteration 148000, lr = 0.001
I1016 22:47:49.735252   636 solver.cpp:218] Iteration 148100 (10.9245 iter/s, 9.15372s/100 iters), loss = 0.00214082
I1016 22:47:49.735252   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:49.735252   636 solver.cpp:237]     Train net output #1: loss = 0.00214058 (* 1 = 0.00214058 loss)
I1016 22:47:49.735252   636 sgd_solver.cpp:105] Iteration 148100, lr = 0.001
I1016 22:47:58.913089   636 solver.cpp:218] Iteration 148200 (10.8959 iter/s, 9.1778s/100 iters), loss = 0.00168923
I1016 22:47:58.913089   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:47:58.913089   636 solver.cpp:237]     Train net output #1: loss = 0.00168899 (* 1 = 0.00168899 loss)
I1016 22:47:58.913089   636 sgd_solver.cpp:105] Iteration 148200, lr = 0.001
I1016 22:48:08.069082   636 solver.cpp:218] Iteration 148300 (10.923 iter/s, 9.15502s/100 iters), loss = 0.00210983
I1016 22:48:08.069082   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:48:08.069082   636 solver.cpp:237]     Train net output #1: loss = 0.00210958 (* 1 = 0.00210958 loss)
I1016 22:48:08.069082   636 sgd_solver.cpp:105] Iteration 148300, lr = 0.001
I1016 22:48:17.323519   636 solver.cpp:218] Iteration 148400 (10.8057 iter/s, 9.25435s/100 iters), loss = 0.000594432
I1016 22:48:17.323519   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:48:17.323519   636 solver.cpp:237]     Train net output #1: loss = 0.000594185 (* 1 = 0.000594185 loss)
I1016 22:48:17.323519   636 sgd_solver.cpp:105] Iteration 148400, lr = 0.001
I1016 22:48:26.067791  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:48:26.438730   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_148500.caffemodel
I1016 22:48:26.466739   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_148500.solverstate
I1016 22:48:26.478741   636 solver.cpp:330] Iteration 148500, Testing net (#0)
I1016 22:48:26.479750   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:48:28.797894  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:48:28.891901   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 22:48:28.891901   636 solver.cpp:397]     Test net output #1: loss = 0.206214 (* 1 = 0.206214 loss)
I1016 22:48:28.983908   636 solver.cpp:218] Iteration 148500 (8.57657 iter/s, 11.6597s/100 iters), loss = 0.00209317
I1016 22:48:28.983908   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:48:28.983908   636 solver.cpp:237]     Train net output #1: loss = 0.00209293 (* 1 = 0.00209293 loss)
I1016 22:48:28.983908   636 sgd_solver.cpp:105] Iteration 148500, lr = 0.001
I1016 22:48:38.161398   636 solver.cpp:218] Iteration 148600 (10.8968 iter/s, 9.17699s/100 iters), loss = 0.00160577
I1016 22:48:38.161398   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:48:38.161398   636 solver.cpp:237]     Train net output #1: loss = 0.00160552 (* 1 = 0.00160552 loss)
I1016 22:48:38.161398   636 sgd_solver.cpp:105] Iteration 148600, lr = 0.001
I1016 22:48:47.368505   636 solver.cpp:218] Iteration 148700 (10.8619 iter/s, 9.20647s/100 iters), loss = 0.00151269
I1016 22:48:47.368505   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:48:47.368505   636 solver.cpp:237]     Train net output #1: loss = 0.00151244 (* 1 = 0.00151244 loss)
I1016 22:48:47.368505   636 sgd_solver.cpp:105] Iteration 148700, lr = 0.001
I1016 22:48:56.521319   636 solver.cpp:218] Iteration 148800 (10.9258 iter/s, 9.15262s/100 iters), loss = 0.00273505
I1016 22:48:56.522320   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:48:56.522320   636 solver.cpp:237]     Train net output #1: loss = 0.0027348 (* 1 = 0.0027348 loss)
I1016 22:48:56.522320   636 sgd_solver.cpp:105] Iteration 148800, lr = 0.001
I1016 22:49:05.721609   636 solver.cpp:218] Iteration 148900 (10.8701 iter/s, 9.19954s/100 iters), loss = 0.000739202
I1016 22:49:05.721609   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:49:05.721609   636 solver.cpp:237]     Train net output #1: loss = 0.000738953 (* 1 = 0.000738953 loss)
I1016 22:49:05.721609   636 sgd_solver.cpp:105] Iteration 148900, lr = 0.001
I1016 22:49:14.534581  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:49:14.908625   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_149000.caffemodel
I1016 22:49:14.936625   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_149000.solverstate
I1016 22:49:14.950127   636 solver.cpp:330] Iteration 149000, Testing net (#0)
I1016 22:49:14.950127   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:49:17.234889  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:49:17.325893   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 22:49:17.325893   636 solver.cpp:397]     Test net output #1: loss = 0.206843 (* 1 = 0.206843 loss)
I1016 22:49:17.414899   636 solver.cpp:218] Iteration 149000 (8.55279 iter/s, 11.6921s/100 iters), loss = 0.00270828
I1016 22:49:17.414899   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:49:17.414899   636 solver.cpp:237]     Train net output #1: loss = 0.00270804 (* 1 = 0.00270804 loss)
I1016 22:49:17.414899   636 sgd_solver.cpp:105] Iteration 149000, lr = 0.001
I1016 22:49:26.723143   636 solver.cpp:218] Iteration 149100 (10.7432 iter/s, 9.30819s/100 iters), loss = 0.0018121
I1016 22:49:26.723143   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:49:26.723143   636 solver.cpp:237]     Train net output #1: loss = 0.00181185 (* 1 = 0.00181185 loss)
I1016 22:49:26.723143   636 sgd_solver.cpp:105] Iteration 149100, lr = 0.001
I1016 22:49:35.965345   636 solver.cpp:218] Iteration 149200 (10.8211 iter/s, 9.24124s/100 iters), loss = 0.0019815
I1016 22:49:35.965345   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:49:35.965345   636 solver.cpp:237]     Train net output #1: loss = 0.00198126 (* 1 = 0.00198126 loss)
I1016 22:49:35.965345   636 sgd_solver.cpp:105] Iteration 149200, lr = 0.001
I1016 22:49:45.246932   636 solver.cpp:218] Iteration 149300 (10.7737 iter/s, 9.28185s/100 iters), loss = 0.00239613
I1016 22:49:45.247932   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:49:45.247932   636 solver.cpp:237]     Train net output #1: loss = 0.00239588 (* 1 = 0.00239588 loss)
I1016 22:49:45.247932   636 sgd_solver.cpp:105] Iteration 149300, lr = 0.001
I1016 22:49:54.427999   636 solver.cpp:218] Iteration 149400 (10.8932 iter/s, 9.18001s/100 iters), loss = 0.00103731
I1016 22:49:54.427999   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:49:54.427999   636 solver.cpp:237]     Train net output #1: loss = 0.00103706 (* 1 = 0.00103706 loss)
I1016 22:49:54.427999   636 sgd_solver.cpp:105] Iteration 149400, lr = 0.001
I1016 22:50:03.140791  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:50:03.503813   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_149500.caffemodel
I1016 22:50:03.530813   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_149500.solverstate
I1016 22:50:03.543813   636 solver.cpp:330] Iteration 149500, Testing net (#0)
I1016 22:50:03.543813   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:50:05.804994  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:50:05.895998   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 22:50:05.895998   636 solver.cpp:397]     Test net output #1: loss = 0.207609 (* 1 = 0.207609 loss)
I1016 22:50:05.984998   636 solver.cpp:218] Iteration 149500 (8.65355 iter/s, 11.556s/100 iters), loss = 0.00410914
I1016 22:50:05.984998   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:50:05.984998   636 solver.cpp:237]     Train net output #1: loss = 0.00410889 (* 1 = 0.00410889 loss)
I1016 22:50:05.984998   636 sgd_solver.cpp:105] Iteration 149500, lr = 0.001
I1016 22:50:15.214692   636 solver.cpp:218] Iteration 149600 (10.8343 iter/s, 9.2299s/100 iters), loss = 0.00202838
I1016 22:50:15.214692   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:50:15.214692   636 solver.cpp:237]     Train net output #1: loss = 0.00202813 (* 1 = 0.00202813 loss)
I1016 22:50:15.214692   636 sgd_solver.cpp:105] Iteration 149600, lr = 0.001
I1016 22:50:24.372589   636 solver.cpp:218] Iteration 149700 (10.9208 iter/s, 9.15687s/100 iters), loss = 0.00231922
I1016 22:50:24.372589   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:50:24.372589   636 solver.cpp:237]     Train net output #1: loss = 0.00231897 (* 1 = 0.00231897 loss)
I1016 22:50:24.372589   636 sgd_solver.cpp:105] Iteration 149700, lr = 0.001
I1016 22:50:33.535336   636 solver.cpp:218] Iteration 149800 (10.9139 iter/s, 9.16262s/100 iters), loss = 0.00283677
I1016 22:50:33.535336   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:50:33.535336   636 solver.cpp:237]     Train net output #1: loss = 0.00283652 (* 1 = 0.00283652 loss)
I1016 22:50:33.535336   636 sgd_solver.cpp:105] Iteration 149800, lr = 0.001
I1016 22:50:42.774241   636 solver.cpp:218] Iteration 149900 (10.8248 iter/s, 9.23801s/100 iters), loss = 0.000941139
I1016 22:50:42.774241   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:50:42.774241   636 solver.cpp:237]     Train net output #1: loss = 0.000940891 (* 1 = 0.000940891 loss)
I1016 22:50:42.774241   636 sgd_solver.cpp:105] Iteration 149900, lr = 0.001
I1016 22:50:51.609127  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:50:51.981847   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_150000.caffemodel
I1016 22:50:52.008337   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_150000.solverstate
I1016 22:50:52.022351   636 solver.cpp:330] Iteration 150000, Testing net (#0)
I1016 22:50:52.022351   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:50:54.345064  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:50:54.438606   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 22:50:54.438606   636 solver.cpp:397]     Test net output #1: loss = 0.205978 (* 1 = 0.205978 loss)
I1016 22:50:54.529667   636 solver.cpp:218] Iteration 150000 (8.50718 iter/s, 11.7548s/100 iters), loss = 0.00127032
I1016 22:50:54.529667   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:50:54.529667   636 solver.cpp:237]     Train net output #1: loss = 0.00127007 (* 1 = 0.00127007 loss)
I1016 22:50:54.529667   636 sgd_solver.cpp:105] Iteration 150000, lr = 0.001
I1016 22:51:03.846750   636 solver.cpp:218] Iteration 150100 (10.7331 iter/s, 9.31696s/100 iters), loss = 0.00340399
I1016 22:51:03.846750   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:51:03.846750   636 solver.cpp:237]     Train net output #1: loss = 0.00340374 (* 1 = 0.00340374 loss)
I1016 22:51:03.846750   636 sgd_solver.cpp:105] Iteration 150100, lr = 0.001
I1016 22:51:13.156703   636 solver.cpp:218] Iteration 150200 (10.7427 iter/s, 9.30863s/100 iters), loss = 0.00159861
I1016 22:51:13.156703   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:51:13.156703   636 solver.cpp:237]     Train net output #1: loss = 0.00159836 (* 1 = 0.00159836 loss)
I1016 22:51:13.156703   636 sgd_solver.cpp:105] Iteration 150200, lr = 0.001
I1016 22:51:22.349668   636 solver.cpp:218] Iteration 150300 (10.8784 iter/s, 9.19251s/100 iters), loss = 0.00154725
I1016 22:51:22.349668   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:51:22.349668   636 solver.cpp:237]     Train net output #1: loss = 0.001547 (* 1 = 0.001547 loss)
I1016 22:51:22.349668   636 sgd_solver.cpp:105] Iteration 150300, lr = 0.001
I1016 22:51:31.746152   636 solver.cpp:218] Iteration 150400 (10.6431 iter/s, 9.39573s/100 iters), loss = 0.00117424
I1016 22:51:31.746152   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:51:31.746152   636 solver.cpp:237]     Train net output #1: loss = 0.00117399 (* 1 = 0.00117399 loss)
I1016 22:51:31.746152   636 sgd_solver.cpp:105] Iteration 150400, lr = 0.001
I1016 22:51:40.586369  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:51:40.957424   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_150500.caffemodel
I1016 22:51:40.983415   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_150500.solverstate
I1016 22:51:40.996421   636 solver.cpp:330] Iteration 150500, Testing net (#0)
I1016 22:51:40.996922   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:51:43.270644  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:51:43.362649   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:51:43.362649   636 solver.cpp:397]     Test net output #1: loss = 0.205803 (* 1 = 0.205803 loss)
I1016 22:51:43.453660   636 solver.cpp:218] Iteration 150500 (8.54146 iter/s, 11.7076s/100 iters), loss = 0.00113763
I1016 22:51:43.453660   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:51:43.454661   636 solver.cpp:237]     Train net output #1: loss = 0.00113739 (* 1 = 0.00113739 loss)
I1016 22:51:43.454661   636 sgd_solver.cpp:105] Iteration 150500, lr = 0.001
I1016 22:51:52.704759   636 solver.cpp:218] Iteration 150600 (10.8108 iter/s, 9.24997s/100 iters), loss = 0.000926044
I1016 22:51:52.704759   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:51:52.704759   636 solver.cpp:237]     Train net output #1: loss = 0.000925796 (* 1 = 0.000925796 loss)
I1016 22:51:52.704759   636 sgd_solver.cpp:105] Iteration 150600, lr = 0.001
I1016 22:52:01.992542   636 solver.cpp:218] Iteration 150700 (10.767 iter/s, 9.28761s/100 iters), loss = 0.00192393
I1016 22:52:01.992542   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:01.992542   636 solver.cpp:237]     Train net output #1: loss = 0.00192368 (* 1 = 0.00192368 loss)
I1016 22:52:01.992542   636 sgd_solver.cpp:105] Iteration 150700, lr = 0.001
I1016 22:52:11.167254   636 solver.cpp:218] Iteration 150800 (10.9009 iter/s, 9.17359s/100 iters), loss = 0.00408838
I1016 22:52:11.167254   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:11.167254   636 solver.cpp:237]     Train net output #1: loss = 0.00408813 (* 1 = 0.00408813 loss)
I1016 22:52:11.167254   636 sgd_solver.cpp:105] Iteration 150800, lr = 0.001
I1016 22:52:20.315696   636 solver.cpp:218] Iteration 150900 (10.9316 iter/s, 9.14777s/100 iters), loss = 0.000893339
I1016 22:52:20.315696   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:20.315696   636 solver.cpp:237]     Train net output #1: loss = 0.000893091 (* 1 = 0.000893091 loss)
I1016 22:52:20.315696   636 sgd_solver.cpp:105] Iteration 150900, lr = 0.001
I1016 22:52:29.009042  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:52:29.370571   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_151000.caffemodel
I1016 22:52:29.395572   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_151000.solverstate
I1016 22:52:29.407577   636 solver.cpp:330] Iteration 151000, Testing net (#0)
I1016 22:52:29.407577   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:52:31.667325  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:52:31.758333   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 22:52:31.758333   636 solver.cpp:397]     Test net output #1: loss = 0.207412 (* 1 = 0.207412 loss)
I1016 22:52:31.847332   636 solver.cpp:218] Iteration 151000 (8.6722 iter/s, 11.5311s/100 iters), loss = 0.00185185
I1016 22:52:31.847332   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:31.847332   636 solver.cpp:237]     Train net output #1: loss = 0.0018516 (* 1 = 0.0018516 loss)
I1016 22:52:31.847332   636 sgd_solver.cpp:105] Iteration 151000, lr = 0.001
I1016 22:52:40.993274   636 solver.cpp:218] Iteration 151100 (10.9339 iter/s, 9.14588s/100 iters), loss = 0.00194963
I1016 22:52:40.993274   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:40.993274   636 solver.cpp:237]     Train net output #1: loss = 0.00194938 (* 1 = 0.00194938 loss)
I1016 22:52:40.993274   636 sgd_solver.cpp:105] Iteration 151100, lr = 0.001
I1016 22:52:50.135651   636 solver.cpp:218] Iteration 151200 (10.9394 iter/s, 9.14127s/100 iters), loss = 0.00431134
I1016 22:52:50.135651   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:50.135651   636 solver.cpp:237]     Train net output #1: loss = 0.0043111 (* 1 = 0.0043111 loss)
I1016 22:52:50.135651   636 sgd_solver.cpp:105] Iteration 151200, lr = 0.001
I1016 22:52:59.278909   636 solver.cpp:218] Iteration 151300 (10.9377 iter/s, 9.14266s/100 iters), loss = 0.00175772
I1016 22:52:59.278909   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:52:59.278909   636 solver.cpp:237]     Train net output #1: loss = 0.00175747 (* 1 = 0.00175747 loss)
I1016 22:52:59.278909   636 sgd_solver.cpp:105] Iteration 151300, lr = 0.001
I1016 22:53:08.419533   636 solver.cpp:218] Iteration 151400 (10.9405 iter/s, 9.14039s/100 iters), loss = 0.00174647
I1016 22:53:08.419533   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:53:08.419533   636 solver.cpp:237]     Train net output #1: loss = 0.00174622 (* 1 = 0.00174622 loss)
I1016 22:53:08.419533   636 sgd_solver.cpp:105] Iteration 151400, lr = 0.001
I1016 22:53:17.121644  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:53:17.482156   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_151500.caffemodel
I1016 22:53:17.508661   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_151500.solverstate
I1016 22:53:17.519660   636 solver.cpp:330] Iteration 151500, Testing net (#0)
I1016 22:53:17.520661   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:53:19.779597  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:53:19.870602   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 22:53:19.870602   636 solver.cpp:397]     Test net output #1: loss = 0.206885 (* 1 = 0.206885 loss)
I1016 22:53:19.960620   636 solver.cpp:218] Iteration 151500 (8.66486 iter/s, 11.5409s/100 iters), loss = 0.00230284
I1016 22:53:19.960620   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:53:19.960620   636 solver.cpp:237]     Train net output #1: loss = 0.00230259 (* 1 = 0.00230259 loss)
I1016 22:53:19.960620   636 sgd_solver.cpp:105] Iteration 151500, lr = 0.001
I1016 22:53:29.184644   636 solver.cpp:218] Iteration 151600 (10.8417 iter/s, 9.22366s/100 iters), loss = 0.00204116
I1016 22:53:29.184644   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:53:29.184644   636 solver.cpp:237]     Train net output #1: loss = 0.00204091 (* 1 = 0.00204091 loss)
I1016 22:53:29.185645   636 sgd_solver.cpp:105] Iteration 151600, lr = 0.001
I1016 22:53:38.349566   636 solver.cpp:218] Iteration 151700 (10.9126 iter/s, 9.16371s/100 iters), loss = 0.00247705
I1016 22:53:38.349566   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:53:38.349566   636 solver.cpp:237]     Train net output #1: loss = 0.0024768 (* 1 = 0.0024768 loss)
I1016 22:53:38.349566   636 sgd_solver.cpp:105] Iteration 151700, lr = 0.001
I1016 22:53:47.643699   636 solver.cpp:218] Iteration 151800 (10.7598 iter/s, 9.29386s/100 iters), loss = 0.00247884
I1016 22:53:47.643699   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:53:47.643699   636 solver.cpp:237]     Train net output #1: loss = 0.0024786 (* 1 = 0.0024786 loss)
I1016 22:53:47.643699   636 sgd_solver.cpp:105] Iteration 151800, lr = 0.001
I1016 22:53:56.830827   636 solver.cpp:218] Iteration 151900 (10.8854 iter/s, 9.1866s/100 iters), loss = 0.00153374
I1016 22:53:56.830827   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:53:56.830827   636 solver.cpp:237]     Train net output #1: loss = 0.0015335 (* 1 = 0.0015335 loss)
I1016 22:53:56.830827   636 sgd_solver.cpp:105] Iteration 151900, lr = 0.001
I1016 22:54:05.583487  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:54:05.946707   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_152000.caffemodel
I1016 22:54:05.971707   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_152000.solverstate
I1016 22:54:05.984707   636 solver.cpp:330] Iteration 152000, Testing net (#0)
I1016 22:54:05.984707   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:54:08.246256  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:54:08.337261   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 22:54:08.337261   636 solver.cpp:397]     Test net output #1: loss = 0.205845 (* 1 = 0.205845 loss)
I1016 22:54:08.425262   636 solver.cpp:218] Iteration 152000 (8.62512 iter/s, 11.594s/100 iters), loss = 0.00149218
I1016 22:54:08.425262   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:54:08.425262   636 solver.cpp:237]     Train net output #1: loss = 0.00149193 (* 1 = 0.00149193 loss)
I1016 22:54:08.425262   636 sgd_solver.cpp:105] Iteration 152000, lr = 0.001
I1016 22:54:17.572705   636 solver.cpp:218] Iteration 152100 (10.9335 iter/s, 9.14618s/100 iters), loss = 0.00274114
I1016 22:54:17.572705   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:54:17.572705   636 solver.cpp:237]     Train net output #1: loss = 0.0027409 (* 1 = 0.0027409 loss)
I1016 22:54:17.572705   636 sgd_solver.cpp:105] Iteration 152100, lr = 0.001
I1016 22:54:26.747474   636 solver.cpp:218] Iteration 152200 (10.8997 iter/s, 9.17459s/100 iters), loss = 0.00248595
I1016 22:54:26.747474   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:54:26.747474   636 solver.cpp:237]     Train net output #1: loss = 0.0024857 (* 1 = 0.0024857 loss)
I1016 22:54:26.747474   636 sgd_solver.cpp:105] Iteration 152200, lr = 0.001
I1016 22:54:35.890890   636 solver.cpp:218] Iteration 152300 (10.9376 iter/s, 9.14274s/100 iters), loss = 0.00184956
I1016 22:54:35.890890   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:54:35.890890   636 solver.cpp:237]     Train net output #1: loss = 0.00184932 (* 1 = 0.00184932 loss)
I1016 22:54:35.890890   636 sgd_solver.cpp:105] Iteration 152300, lr = 0.001
I1016 22:54:45.059017   636 solver.cpp:218] Iteration 152400 (10.908 iter/s, 9.16758s/100 iters), loss = 0.00124001
I1016 22:54:45.059017   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:54:45.059017   636 solver.cpp:237]     Train net output #1: loss = 0.00123976 (* 1 = 0.00123976 loss)
I1016 22:54:45.059017   636 sgd_solver.cpp:105] Iteration 152400, lr = 0.001
I1016 22:54:53.755889  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:54:54.123980   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_152500.caffemodel
I1016 22:54:54.153981   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_152500.solverstate
I1016 22:54:54.165983   636 solver.cpp:330] Iteration 152500, Testing net (#0)
I1016 22:54:54.165983   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:54:56.434813  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:54:56.525854   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 22:54:56.525854   636 solver.cpp:397]     Test net output #1: loss = 0.206917 (* 1 = 0.206917 loss)
I1016 22:54:56.614847   636 solver.cpp:218] Iteration 152500 (8.65397 iter/s, 11.5554s/100 iters), loss = 0.000960417
I1016 22:54:56.615348   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:54:56.615348   636 solver.cpp:237]     Train net output #1: loss = 0.000960169 (* 1 = 0.000960169 loss)
I1016 22:54:56.615348   636 sgd_solver.cpp:105] Iteration 152500, lr = 0.001
I1016 22:55:05.749125   636 solver.cpp:218] Iteration 152600 (10.9486 iter/s, 9.13357s/100 iters), loss = 0.00112906
I1016 22:55:05.749125   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:55:05.749125   636 solver.cpp:237]     Train net output #1: loss = 0.00112881 (* 1 = 0.00112881 loss)
I1016 22:55:05.749125   636 sgd_solver.cpp:105] Iteration 152600, lr = 0.001
I1016 22:55:14.888407   636 solver.cpp:218] Iteration 152700 (10.9416 iter/s, 9.13941s/100 iters), loss = 0.00251936
I1016 22:55:14.889407   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:55:14.889407   636 solver.cpp:237]     Train net output #1: loss = 0.00251911 (* 1 = 0.00251911 loss)
I1016 22:55:14.889407   636 sgd_solver.cpp:105] Iteration 152700, lr = 0.001
I1016 22:55:24.068120   636 solver.cpp:218] Iteration 152800 (10.8948 iter/s, 9.17865s/100 iters), loss = 0.00170137
I1016 22:55:24.068120   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:55:24.068120   636 solver.cpp:237]     Train net output #1: loss = 0.00170112 (* 1 = 0.00170112 loss)
I1016 22:55:24.068621   636 sgd_solver.cpp:105] Iteration 152800, lr = 0.001
I1016 22:55:33.311426   636 solver.cpp:218] Iteration 152900 (10.8193 iter/s, 9.24273s/100 iters), loss = 0.00106795
I1016 22:55:33.311426   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:55:33.311426   636 solver.cpp:237]     Train net output #1: loss = 0.0010677 (* 1 = 0.0010677 loss)
I1016 22:55:33.311426   636 sgd_solver.cpp:105] Iteration 152900, lr = 0.001
I1016 22:55:42.217722  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:55:42.579241   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_153000.caffemodel
I1016 22:55:42.605753   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_153000.solverstate
I1016 22:55:42.617753   636 solver.cpp:330] Iteration 153000, Testing net (#0)
I1016 22:55:42.617753   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:55:44.912472  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:55:45.004480   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 22:55:45.004480   636 solver.cpp:397]     Test net output #1: loss = 0.20578 (* 1 = 0.20578 loss)
I1016 22:55:45.092483   636 solver.cpp:218] Iteration 153000 (8.48867 iter/s, 11.7804s/100 iters), loss = 0.00305252
I1016 22:55:45.092483   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:55:45.092483   636 solver.cpp:237]     Train net output #1: loss = 0.00305227 (* 1 = 0.00305227 loss)
I1016 22:55:45.092483   636 sgd_solver.cpp:46] MultiStep Status: Iteration 153000, step = 3
I1016 22:55:45.092483   636 sgd_solver.cpp:105] Iteration 153000, lr = 0.0001
I1016 22:55:54.333817   636 solver.cpp:218] Iteration 153100 (10.8219 iter/s, 9.24051s/100 iters), loss = 0.00178618
I1016 22:55:54.333817   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:55:54.333817   636 solver.cpp:237]     Train net output #1: loss = 0.00178593 (* 1 = 0.00178593 loss)
I1016 22:55:54.333817   636 sgd_solver.cpp:105] Iteration 153100, lr = 0.0001
I1016 22:56:03.644847   636 solver.cpp:218] Iteration 153200 (10.74 iter/s, 9.31098s/100 iters), loss = 0.00271595
I1016 22:56:03.644847   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:56:03.644847   636 solver.cpp:237]     Train net output #1: loss = 0.00271571 (* 1 = 0.00271571 loss)
I1016 22:56:03.644847   636 sgd_solver.cpp:105] Iteration 153200, lr = 0.0001
I1016 22:56:12.946378   636 solver.cpp:218] Iteration 153300 (10.7519 iter/s, 9.3007s/100 iters), loss = 0.00177184
I1016 22:56:12.946879   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:56:12.946879   636 solver.cpp:237]     Train net output #1: loss = 0.00177159 (* 1 = 0.00177159 loss)
I1016 22:56:12.946879   636 sgd_solver.cpp:105] Iteration 153300, lr = 0.0001
I1016 22:56:22.118984   636 solver.cpp:218] Iteration 153400 (10.9023 iter/s, 9.17234s/100 iters), loss = 0.00123933
I1016 22:56:22.118984   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:56:22.118984   636 solver.cpp:237]     Train net output #1: loss = 0.00123908 (* 1 = 0.00123908 loss)
I1016 22:56:22.118984   636 sgd_solver.cpp:105] Iteration 153400, lr = 0.0001
I1016 22:56:30.897495  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:56:31.259532   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_153500.caffemodel
I1016 22:56:31.285531   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_153500.solverstate
I1016 22:56:31.297531   636 solver.cpp:330] Iteration 153500, Testing net (#0)
I1016 22:56:31.297531   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:56:33.570153  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:56:33.661167   636 solver.cpp:397]     Test net output #0: accuracy = 0.9463
I1016 22:56:33.661167   636 solver.cpp:397]     Test net output #1: loss = 0.205767 (* 1 = 0.205767 loss)
I1016 22:56:33.750164   636 solver.cpp:218] Iteration 153500 (8.59854 iter/s, 11.6299s/100 iters), loss = 0.00390856
I1016 22:56:33.750164   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:56:33.750164   636 solver.cpp:237]     Train net output #1: loss = 0.00390832 (* 1 = 0.00390832 loss)
I1016 22:56:33.750164   636 sgd_solver.cpp:105] Iteration 153500, lr = 0.0001
I1016 22:56:42.941969   636 solver.cpp:218] Iteration 153600 (10.8797 iter/s, 9.19139s/100 iters), loss = 0.00164544
I1016 22:56:42.941969   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:56:42.941969   636 solver.cpp:237]     Train net output #1: loss = 0.0016452 (* 1 = 0.0016452 loss)
I1016 22:56:42.941969   636 sgd_solver.cpp:105] Iteration 153600, lr = 0.0001
I1016 22:56:52.240563   636 solver.cpp:218] Iteration 153700 (10.7549 iter/s, 9.29809s/100 iters), loss = 0.00133896
I1016 22:56:52.240563   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:56:52.240563   636 solver.cpp:237]     Train net output #1: loss = 0.00133872 (* 1 = 0.00133872 loss)
I1016 22:56:52.240563   636 sgd_solver.cpp:105] Iteration 153700, lr = 0.0001
I1016 22:57:01.562646   636 solver.cpp:218] Iteration 153800 (10.7275 iter/s, 9.32182s/100 iters), loss = 0.00289728
I1016 22:57:01.562646   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:01.562646   636 solver.cpp:237]     Train net output #1: loss = 0.00289703 (* 1 = 0.00289703 loss)
I1016 22:57:01.562646   636 sgd_solver.cpp:105] Iteration 153800, lr = 0.0001
I1016 22:57:10.900967   636 solver.cpp:218] Iteration 153900 (10.7059 iter/s, 9.34068s/100 iters), loss = 0.00144222
I1016 22:57:10.900967   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:10.900967   636 solver.cpp:237]     Train net output #1: loss = 0.00144198 (* 1 = 0.00144198 loss)
I1016 22:57:10.900967   636 sgd_solver.cpp:105] Iteration 153900, lr = 0.0001
I1016 22:57:19.792637  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:57:20.165657   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_154000.caffemodel
I1016 22:57:20.192656   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_154000.solverstate
I1016 22:57:20.203657   636 solver.cpp:330] Iteration 154000, Testing net (#0)
I1016 22:57:20.203657   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:57:22.520799  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:57:22.613806   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:57:22.613806   636 solver.cpp:397]     Test net output #1: loss = 0.20555 (* 1 = 0.20555 loss)
I1016 22:57:22.704821   636 solver.cpp:218] Iteration 154000 (8.47425 iter/s, 11.8004s/100 iters), loss = 0.00298243
I1016 22:57:22.704821   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:22.705821   636 solver.cpp:237]     Train net output #1: loss = 0.00298219 (* 1 = 0.00298219 loss)
I1016 22:57:22.705821   636 sgd_solver.cpp:105] Iteration 154000, lr = 0.0001
I1016 22:57:31.935570   636 solver.cpp:218] Iteration 154100 (10.834 iter/s, 9.23016s/100 iters), loss = 0.00152723
I1016 22:57:31.936571   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:31.936571   636 solver.cpp:237]     Train net output #1: loss = 0.00152698 (* 1 = 0.00152698 loss)
I1016 22:57:31.936571   636 sgd_solver.cpp:105] Iteration 154100, lr = 0.0001
I1016 22:57:41.206074   636 solver.cpp:218] Iteration 154200 (10.7875 iter/s, 9.26997s/100 iters), loss = 0.00207798
I1016 22:57:41.207083   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:41.207083   636 solver.cpp:237]     Train net output #1: loss = 0.00207773 (* 1 = 0.00207773 loss)
I1016 22:57:41.207083   636 sgd_solver.cpp:105] Iteration 154200, lr = 0.0001
I1016 22:57:50.434273   636 solver.cpp:218] Iteration 154300 (10.8374 iter/s, 9.22733s/100 iters), loss = 0.00210833
I1016 22:57:50.434273   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:50.434273   636 solver.cpp:237]     Train net output #1: loss = 0.00210809 (* 1 = 0.00210809 loss)
I1016 22:57:50.434273   636 sgd_solver.cpp:105] Iteration 154300, lr = 0.0001
I1016 22:57:59.615392   636 solver.cpp:218] Iteration 154400 (10.893 iter/s, 9.18022s/100 iters), loss = 0.00178736
I1016 22:57:59.615392   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:57:59.615392   636 solver.cpp:237]     Train net output #1: loss = 0.00178711 (* 1 = 0.00178711 loss)
I1016 22:57:59.615392   636 sgd_solver.cpp:105] Iteration 154400, lr = 0.0001
I1016 22:58:08.409344  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:58:08.774863   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_154500.caffemodel
I1016 22:58:08.801368   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_154500.solverstate
I1016 22:58:08.813371   636 solver.cpp:330] Iteration 154500, Testing net (#0)
I1016 22:58:08.813371   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:58:11.095716  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:58:11.186724   636 solver.cpp:397]     Test net output #0: accuracy = 0.9463
I1016 22:58:11.187216   636 solver.cpp:397]     Test net output #1: loss = 0.205553 (* 1 = 0.205553 loss)
I1016 22:58:11.276216   636 solver.cpp:218] Iteration 154500 (8.57639 iter/s, 11.6599s/100 iters), loss = 0.00113865
I1016 22:58:11.276216   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:58:11.276216   636 solver.cpp:237]     Train net output #1: loss = 0.00113841 (* 1 = 0.00113841 loss)
I1016 22:58:11.276216   636 sgd_solver.cpp:105] Iteration 154500, lr = 0.0001
I1016 22:58:20.595762   636 solver.cpp:218] Iteration 154600 (10.7308 iter/s, 9.31898s/100 iters), loss = 0.00279488
I1016 22:58:20.595762   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:58:20.595762   636 solver.cpp:237]     Train net output #1: loss = 0.00279463 (* 1 = 0.00279463 loss)
I1016 22:58:20.595762   636 sgd_solver.cpp:105] Iteration 154600, lr = 0.0001
I1016 22:58:29.903583   636 solver.cpp:218] Iteration 154700 (10.7444 iter/s, 9.30717s/100 iters), loss = 0.0019885
I1016 22:58:29.903583   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:58:29.903583   636 solver.cpp:237]     Train net output #1: loss = 0.00198826 (* 1 = 0.00198826 loss)
I1016 22:58:29.903583   636 sgd_solver.cpp:105] Iteration 154700, lr = 0.0001
I1016 22:58:39.214452   636 solver.cpp:218] Iteration 154800 (10.7406 iter/s, 9.31043s/100 iters), loss = 0.00122959
I1016 22:58:39.214452   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:58:39.214452   636 solver.cpp:237]     Train net output #1: loss = 0.00122934 (* 1 = 0.00122934 loss)
I1016 22:58:39.214452   636 sgd_solver.cpp:105] Iteration 154800, lr = 0.0001
I1016 22:58:48.494463   636 solver.cpp:218] Iteration 154900 (10.7767 iter/s, 9.27929s/100 iters), loss = 0.000766255
I1016 22:58:48.494463   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:58:48.494463   636 solver.cpp:237]     Train net output #1: loss = 0.000766012 (* 1 = 0.000766012 loss)
I1016 22:58:48.494463   636 sgd_solver.cpp:105] Iteration 154900, lr = 0.0001
I1016 22:58:57.271200  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:58:57.637267   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_155000.caffemodel
I1016 22:58:57.663266   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_155000.solverstate
I1016 22:58:57.675282   636 solver.cpp:330] Iteration 155000, Testing net (#0)
I1016 22:58:57.675282   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:58:59.965483  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:59:00.058487   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 22:59:00.058487   636 solver.cpp:397]     Test net output #1: loss = 0.205685 (* 1 = 0.205685 loss)
I1016 22:59:00.150506   636 solver.cpp:218] Iteration 155000 (8.57938 iter/s, 11.6559s/100 iters), loss = 0.0020094
I1016 22:59:00.150506   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:00.150506   636 solver.cpp:237]     Train net output #1: loss = 0.00200915 (* 1 = 0.00200915 loss)
I1016 22:59:00.150506   636 sgd_solver.cpp:105] Iteration 155000, lr = 0.0001
I1016 22:59:09.456564   636 solver.cpp:218] Iteration 155100 (10.7461 iter/s, 9.30568s/100 iters), loss = 0.00188991
I1016 22:59:09.456564   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:09.456564   636 solver.cpp:237]     Train net output #1: loss = 0.00188967 (* 1 = 0.00188967 loss)
I1016 22:59:09.456564   636 sgd_solver.cpp:105] Iteration 155100, lr = 0.0001
I1016 22:59:18.762033   636 solver.cpp:218] Iteration 155200 (10.7474 iter/s, 9.30458s/100 iters), loss = 0.00253575
I1016 22:59:18.762033   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:18.762033   636 solver.cpp:237]     Train net output #1: loss = 0.00253551 (* 1 = 0.00253551 loss)
I1016 22:59:18.762033   636 sgd_solver.cpp:105] Iteration 155200, lr = 0.0001
I1016 22:59:28.113461   636 solver.cpp:218] Iteration 155300 (10.6939 iter/s, 9.35117s/100 iters), loss = 0.00156949
I1016 22:59:28.113461   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:28.113461   636 solver.cpp:237]     Train net output #1: loss = 0.00156925 (* 1 = 0.00156925 loss)
I1016 22:59:28.113461   636 sgd_solver.cpp:105] Iteration 155300, lr = 0.0001
I1016 22:59:37.331233   636 solver.cpp:218] Iteration 155400 (10.8493 iter/s, 9.21721s/100 iters), loss = 0.00150609
I1016 22:59:37.331233   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:37.331233   636 solver.cpp:237]     Train net output #1: loss = 0.00150585 (* 1 = 0.00150585 loss)
I1016 22:59:37.331233   636 sgd_solver.cpp:105] Iteration 155400, lr = 0.0001
I1016 22:59:46.035596  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:59:46.396611   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_155500.caffemodel
I1016 22:59:46.422617   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_155500.solverstate
I1016 22:59:46.434618   636 solver.cpp:330] Iteration 155500, Testing net (#0)
I1016 22:59:46.434618   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 22:59:48.694056  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 22:59:48.785059   636 solver.cpp:397]     Test net output #0: accuracy = 0.9462
I1016 22:59:48.785059   636 solver.cpp:397]     Test net output #1: loss = 0.205704 (* 1 = 0.205704 loss)
I1016 22:59:48.873065   636 solver.cpp:218] Iteration 155500 (8.66444 iter/s, 11.5414s/100 iters), loss = 0.00179501
I1016 22:59:48.873065   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:48.874066   636 solver.cpp:237]     Train net output #1: loss = 0.00179477 (* 1 = 0.00179477 loss)
I1016 22:59:48.874066   636 sgd_solver.cpp:105] Iteration 155500, lr = 0.0001
I1016 22:59:58.013926   636 solver.cpp:218] Iteration 155600 (10.9411 iter/s, 9.13984s/100 iters), loss = 0.00186344
I1016 22:59:58.013926   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 22:59:58.014426   636 solver.cpp:237]     Train net output #1: loss = 0.0018632 (* 1 = 0.0018632 loss)
I1016 22:59:58.014426   636 sgd_solver.cpp:105] Iteration 155600, lr = 0.0001
I1016 23:00:07.158288   636 solver.cpp:218] Iteration 155700 (10.9358 iter/s, 9.14425s/100 iters), loss = 0.00178512
I1016 23:00:07.158288   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:00:07.158288   636 solver.cpp:237]     Train net output #1: loss = 0.00178488 (* 1 = 0.00178488 loss)
I1016 23:00:07.158288   636 sgd_solver.cpp:105] Iteration 155700, lr = 0.0001
I1016 23:00:16.302842   636 solver.cpp:218] Iteration 155800 (10.9367 iter/s, 9.14351s/100 iters), loss = 0.00104308
I1016 23:00:16.302842   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:00:16.302842   636 solver.cpp:237]     Train net output #1: loss = 0.00104283 (* 1 = 0.00104283 loss)
I1016 23:00:16.302842   636 sgd_solver.cpp:105] Iteration 155800, lr = 0.0001
I1016 23:00:25.459301   636 solver.cpp:218] Iteration 155900 (10.9219 iter/s, 9.15591s/100 iters), loss = 0.00152797
I1016 23:00:25.459301   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:00:25.459301   636 solver.cpp:237]     Train net output #1: loss = 0.00152773 (* 1 = 0.00152773 loss)
I1016 23:00:25.459301   636 sgd_solver.cpp:105] Iteration 155900, lr = 0.0001
I1016 23:00:34.170253  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:00:34.532299   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_156000.caffemodel
I1016 23:00:34.559296   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_156000.solverstate
I1016 23:00:34.572311   636 solver.cpp:330] Iteration 156000, Testing net (#0)
I1016 23:00:34.572311   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:00:36.866508  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:00:36.958549   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 23:00:36.958549   636 solver.cpp:397]     Test net output #1: loss = 0.2057 (* 1 = 0.2057 loss)
I1016 23:00:37.047600   636 solver.cpp:218] Iteration 156000 (8.6298 iter/s, 11.5878s/100 iters), loss = 0.00217024
I1016 23:00:37.047600   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:00:37.047600   636 solver.cpp:237]     Train net output #1: loss = 0.00217 (* 1 = 0.00217 loss)
I1016 23:00:37.047600   636 sgd_solver.cpp:105] Iteration 156000, lr = 0.0001
I1016 23:00:46.239832   636 solver.cpp:218] Iteration 156100 (10.8796 iter/s, 9.19153s/100 iters), loss = 0.0013932
I1016 23:00:46.239832   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:00:46.239832   636 solver.cpp:237]     Train net output #1: loss = 0.00139296 (* 1 = 0.00139296 loss)
I1016 23:00:46.239832   636 sgd_solver.cpp:105] Iteration 156100, lr = 0.0001
I1016 23:00:55.394212   636 solver.cpp:218] Iteration 156200 (10.9245 iter/s, 9.1537s/100 iters), loss = 0.00141977
I1016 23:00:55.394212   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:00:55.394212   636 solver.cpp:237]     Train net output #1: loss = 0.00141952 (* 1 = 0.00141952 loss)
I1016 23:00:55.394212   636 sgd_solver.cpp:105] Iteration 156200, lr = 0.0001
I1016 23:01:04.581117   636 solver.cpp:218] Iteration 156300 (10.8846 iter/s, 9.18733s/100 iters), loss = 0.00124702
I1016 23:01:04.582103   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:01:04.582103   636 solver.cpp:237]     Train net output #1: loss = 0.00124677 (* 1 = 0.00124677 loss)
I1016 23:01:04.582103   636 sgd_solver.cpp:105] Iteration 156300, lr = 0.0001
I1016 23:01:13.741812   636 solver.cpp:218] Iteration 156400 (10.9171 iter/s, 9.1599s/100 iters), loss = 0.00160684
I1016 23:01:13.741812   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:01:13.741812   636 solver.cpp:237]     Train net output #1: loss = 0.00160659 (* 1 = 0.00160659 loss)
I1016 23:01:13.741812   636 sgd_solver.cpp:105] Iteration 156400, lr = 0.0001
I1016 23:01:22.461030  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:01:22.826059   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_156500.caffemodel
I1016 23:01:22.853557   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_156500.solverstate
I1016 23:01:22.865062   636 solver.cpp:330] Iteration 156500, Testing net (#0)
I1016 23:01:22.865062   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:01:25.134886  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:01:25.225911   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 23:01:25.225911   636 solver.cpp:397]     Test net output #1: loss = 0.205667 (* 1 = 0.205667 loss)
I1016 23:01:25.314924   636 solver.cpp:218] Iteration 156500 (8.64117 iter/s, 11.5725s/100 iters), loss = 0.00402703
I1016 23:01:25.314924   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:01:25.314924   636 solver.cpp:237]     Train net output #1: loss = 0.00402679 (* 1 = 0.00402679 loss)
I1016 23:01:25.314924   636 sgd_solver.cpp:105] Iteration 156500, lr = 0.0001
I1016 23:01:34.456151   636 solver.cpp:218] Iteration 156600 (10.9408 iter/s, 9.14007s/100 iters), loss = 0.00155117
I1016 23:01:34.456151   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:01:34.456151   636 solver.cpp:237]     Train net output #1: loss = 0.00155093 (* 1 = 0.00155093 loss)
I1016 23:01:34.456151   636 sgd_solver.cpp:105] Iteration 156600, lr = 0.0001
I1016 23:01:43.628244   636 solver.cpp:218] Iteration 156700 (10.9027 iter/s, 9.17201s/100 iters), loss = 0.00319778
I1016 23:01:43.628244   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:01:43.628244   636 solver.cpp:237]     Train net output #1: loss = 0.00319754 (* 1 = 0.00319754 loss)
I1016 23:01:43.628244   636 sgd_solver.cpp:105] Iteration 156700, lr = 0.0001
I1016 23:01:52.851872   636 solver.cpp:218] Iteration 156800 (10.842 iter/s, 9.2234s/100 iters), loss = 0.00189271
I1016 23:01:52.851872   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:01:52.852874   636 solver.cpp:237]     Train net output #1: loss = 0.00189247 (* 1 = 0.00189247 loss)
I1016 23:01:52.852874   636 sgd_solver.cpp:105] Iteration 156800, lr = 0.0001
I1016 23:02:02.149432   636 solver.cpp:218] Iteration 156900 (10.7569 iter/s, 9.29634s/100 iters), loss = 0.00132767
I1016 23:02:02.149432   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:02:02.149432   636 solver.cpp:237]     Train net output #1: loss = 0.00132743 (* 1 = 0.00132743 loss)
I1016 23:02:02.149432   636 sgd_solver.cpp:105] Iteration 156900, lr = 0.0001
I1016 23:02:11.021755  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:02:11.390774   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_157000.caffemodel
I1016 23:02:11.417774   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_157000.solverstate
I1016 23:02:11.429774   636 solver.cpp:330] Iteration 157000, Testing net (#0)
I1016 23:02:11.430775   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:02:13.699092  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:02:13.788107   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 23:02:13.789108   636 solver.cpp:397]     Test net output #1: loss = 0.20587 (* 1 = 0.20587 loss)
I1016 23:02:13.878109   636 solver.cpp:218] Iteration 157000 (8.52672 iter/s, 11.7278s/100 iters), loss = 0.00127947
I1016 23:02:13.878109   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:02:13.878109   636 solver.cpp:237]     Train net output #1: loss = 0.00127923 (* 1 = 0.00127923 loss)
I1016 23:02:13.878109   636 sgd_solver.cpp:105] Iteration 157000, lr = 0.0001
I1016 23:02:23.128072   636 solver.cpp:218] Iteration 157100 (10.8105 iter/s, 9.25024s/100 iters), loss = 0.00488309
I1016 23:02:23.129072   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:02:23.129072   636 solver.cpp:237]     Train net output #1: loss = 0.00488285 (* 1 = 0.00488285 loss)
I1016 23:02:23.129072   636 sgd_solver.cpp:105] Iteration 157100, lr = 0.0001
I1016 23:02:32.360971   636 solver.cpp:218] Iteration 157200 (10.8322 iter/s, 9.23176s/100 iters), loss = 0.0025652
I1016 23:02:32.360971   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:02:32.360971   636 solver.cpp:237]     Train net output #1: loss = 0.00256496 (* 1 = 0.00256496 loss)
I1016 23:02:32.360971   636 sgd_solver.cpp:105] Iteration 157200, lr = 0.0001
I1016 23:02:41.602257   636 solver.cpp:218] Iteration 157300 (10.822 iter/s, 9.24044s/100 iters), loss = 0.0013716
I1016 23:02:41.602257   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:02:41.602257   636 solver.cpp:237]     Train net output #1: loss = 0.00137136 (* 1 = 0.00137136 loss)
I1016 23:02:41.602257   636 sgd_solver.cpp:105] Iteration 157300, lr = 0.0001
I1016 23:02:50.797493   636 solver.cpp:218] Iteration 157400 (10.8749 iter/s, 9.19549s/100 iters), loss = 0.00106345
I1016 23:02:50.797493   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:02:50.797493   636 solver.cpp:237]     Train net output #1: loss = 0.00106322 (* 1 = 0.00106322 loss)
I1016 23:02:50.798494   636 sgd_solver.cpp:105] Iteration 157400, lr = 0.0001
I1016 23:02:59.523887  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:02:59.886431   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_157500.caffemodel
I1016 23:02:59.911934   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_157500.solverstate
I1016 23:02:59.923934   636 solver.cpp:330] Iteration 157500, Testing net (#0)
I1016 23:02:59.923934   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:03:02.185400  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:03:02.276414   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 23:03:02.276414   636 solver.cpp:397]     Test net output #1: loss = 0.205694 (* 1 = 0.205694 loss)
I1016 23:03:02.364914   636 solver.cpp:218] Iteration 157500 (8.64561 iter/s, 11.5666s/100 iters), loss = 0.00145107
I1016 23:03:02.364914   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:02.364914   636 solver.cpp:237]     Train net output #1: loss = 0.00145083 (* 1 = 0.00145083 loss)
I1016 23:03:02.364914   636 sgd_solver.cpp:105] Iteration 157500, lr = 0.0001
I1016 23:03:11.534929   636 solver.cpp:218] Iteration 157600 (10.9061 iter/s, 9.16922s/100 iters), loss = 0.00136265
I1016 23:03:11.534929   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:11.534929   636 solver.cpp:237]     Train net output #1: loss = 0.00136241 (* 1 = 0.00136241 loss)
I1016 23:03:11.534929   636 sgd_solver.cpp:105] Iteration 157600, lr = 0.0001
I1016 23:03:20.725597   636 solver.cpp:218] Iteration 157700 (10.8812 iter/s, 9.1902s/100 iters), loss = 0.00350745
I1016 23:03:20.725597   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:20.725597   636 solver.cpp:237]     Train net output #1: loss = 0.00350721 (* 1 = 0.00350721 loss)
I1016 23:03:20.725597   636 sgd_solver.cpp:105] Iteration 157700, lr = 0.0001
I1016 23:03:29.883828   636 solver.cpp:218] Iteration 157800 (10.92 iter/s, 9.1575s/100 iters), loss = 0.00155297
I1016 23:03:29.883828   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:29.883828   636 solver.cpp:237]     Train net output #1: loss = 0.00155273 (* 1 = 0.00155273 loss)
I1016 23:03:29.883828   636 sgd_solver.cpp:105] Iteration 157800, lr = 0.0001
I1016 23:03:39.046953   636 solver.cpp:218] Iteration 157900 (10.9133 iter/s, 9.16311s/100 iters), loss = 0.00105311
I1016 23:03:39.046953   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:39.046953   636 solver.cpp:237]     Train net output #1: loss = 0.00105287 (* 1 = 0.00105287 loss)
I1016 23:03:39.046953   636 sgd_solver.cpp:105] Iteration 157900, lr = 0.0001
I1016 23:03:47.753407  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:03:48.115154   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_158000.caffemodel
I1016 23:03:48.139659   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_158000.solverstate
I1016 23:03:48.151661   636 solver.cpp:330] Iteration 158000, Testing net (#0)
I1016 23:03:48.151661   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:03:50.412896  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:03:50.503907   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 23:03:50.503907   636 solver.cpp:397]     Test net output #1: loss = 0.206134 (* 1 = 0.206134 loss)
I1016 23:03:50.592905   636 solver.cpp:218] Iteration 158000 (8.66201 iter/s, 11.5447s/100 iters), loss = 0.00174198
I1016 23:03:50.592905   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:50.592905   636 solver.cpp:237]     Train net output #1: loss = 0.00174174 (* 1 = 0.00174174 loss)
I1016 23:03:50.592905   636 sgd_solver.cpp:105] Iteration 158000, lr = 0.0001
I1016 23:03:59.736680   636 solver.cpp:218] Iteration 158100 (10.9368 iter/s, 9.1434s/100 iters), loss = 0.00151263
I1016 23:03:59.736680   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:03:59.736680   636 solver.cpp:237]     Train net output #1: loss = 0.00151239 (* 1 = 0.00151239 loss)
I1016 23:03:59.736680   636 sgd_solver.cpp:105] Iteration 158100, lr = 0.0001
I1016 23:04:08.986830   636 solver.cpp:218] Iteration 158200 (10.8113 iter/s, 9.24959s/100 iters), loss = 0.0036549
I1016 23:04:08.986830   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:04:08.986830   636 solver.cpp:237]     Train net output #1: loss = 0.00365466 (* 1 = 0.00365466 loss)
I1016 23:04:08.986830   636 sgd_solver.cpp:105] Iteration 158200, lr = 0.0001
I1016 23:04:18.206046   636 solver.cpp:218] Iteration 158300 (10.8471 iter/s, 9.21903s/100 iters), loss = 0.000953189
I1016 23:04:18.206046   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:04:18.206046   636 solver.cpp:237]     Train net output #1: loss = 0.000952948 (* 1 = 0.000952948 loss)
I1016 23:04:18.206046   636 sgd_solver.cpp:105] Iteration 158300, lr = 0.0001
I1016 23:04:27.533735   636 solver.cpp:218] Iteration 158400 (10.7218 iter/s, 9.32683s/100 iters), loss = 0.000599944
I1016 23:04:27.533735   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:04:27.533735   636 solver.cpp:237]     Train net output #1: loss = 0.000599704 (* 1 = 0.000599704 loss)
I1016 23:04:27.533735   636 sgd_solver.cpp:105] Iteration 158400, lr = 0.0001
I1016 23:04:36.290169  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:04:36.654199   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_158500.caffemodel
I1016 23:04:36.685199   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_158500.solverstate
I1016 23:04:36.697708   636 solver.cpp:330] Iteration 158500, Testing net (#0)
I1016 23:04:36.697708   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:04:38.992982  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:04:39.088325   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:04:39.088325   636 solver.cpp:397]     Test net output #1: loss = 0.206179 (* 1 = 0.206179 loss)
I1016 23:04:39.182829   636 solver.cpp:218] Iteration 158500 (8.58457 iter/s, 11.6488s/100 iters), loss = 0.0010516
I1016 23:04:39.183828   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:04:39.183828   636 solver.cpp:237]     Train net output #1: loss = 0.00105136 (* 1 = 0.00105136 loss)
I1016 23:04:39.183828   636 sgd_solver.cpp:105] Iteration 158500, lr = 0.0001
I1016 23:04:48.444097   636 solver.cpp:218] Iteration 158600 (10.7989 iter/s, 9.26023s/100 iters), loss = 0.00119142
I1016 23:04:48.444097   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:04:48.444097   636 solver.cpp:237]     Train net output #1: loss = 0.00119119 (* 1 = 0.00119119 loss)
I1016 23:04:48.444097   636 sgd_solver.cpp:105] Iteration 158600, lr = 0.0001
I1016 23:04:57.638893   636 solver.cpp:218] Iteration 158700 (10.8771 iter/s, 9.1936s/100 iters), loss = 0.0034031
I1016 23:04:57.638893   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:04:57.638893   636 solver.cpp:237]     Train net output #1: loss = 0.00340287 (* 1 = 0.00340287 loss)
I1016 23:04:57.638893   636 sgd_solver.cpp:105] Iteration 158700, lr = 0.0001
I1016 23:05:06.793375   636 solver.cpp:218] Iteration 158800 (10.9237 iter/s, 9.15445s/100 iters), loss = 0.0011282
I1016 23:05:06.793375   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:05:06.793375   636 solver.cpp:237]     Train net output #1: loss = 0.00112796 (* 1 = 0.00112796 loss)
I1016 23:05:06.793375   636 sgd_solver.cpp:105] Iteration 158800, lr = 0.0001
I1016 23:05:15.985002   636 solver.cpp:218] Iteration 158900 (10.8806 iter/s, 9.19069s/100 iters), loss = 0.000790629
I1016 23:05:15.985002   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:05:15.985002   636 solver.cpp:237]     Train net output #1: loss = 0.000790392 (* 1 = 0.000790392 loss)
I1016 23:05:15.985002   636 sgd_solver.cpp:105] Iteration 158900, lr = 0.0001
I1016 23:05:24.740945  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:05:25.107136   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_159000.caffemodel
I1016 23:05:25.133638   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_159000.solverstate
I1016 23:05:25.145143   636 solver.cpp:330] Iteration 159000, Testing net (#0)
I1016 23:05:25.145143   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:05:27.421303  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:05:27.511806   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 23:05:27.511806   636 solver.cpp:397]     Test net output #1: loss = 0.206073 (* 1 = 0.206073 loss)
I1016 23:05:27.599808   636 solver.cpp:218] Iteration 159000 (8.60968 iter/s, 11.6148s/100 iters), loss = 0.00138336
I1016 23:05:27.600813   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:05:27.600813   636 solver.cpp:237]     Train net output #1: loss = 0.00138312 (* 1 = 0.00138312 loss)
I1016 23:05:27.600813   636 sgd_solver.cpp:105] Iteration 159000, lr = 0.0001
I1016 23:05:36.759485   636 solver.cpp:218] Iteration 159100 (10.9184 iter/s, 9.15887s/100 iters), loss = 0.00211149
I1016 23:05:36.759485   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:05:36.759485   636 solver.cpp:237]     Train net output #1: loss = 0.00211125 (* 1 = 0.00211125 loss)
I1016 23:05:36.759485   636 sgd_solver.cpp:105] Iteration 159100, lr = 0.0001
I1016 23:05:45.938241   636 solver.cpp:218] Iteration 159200 (10.8962 iter/s, 9.17748s/100 iters), loss = 0.00247959
I1016 23:05:45.938241   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:05:45.938241   636 solver.cpp:237]     Train net output #1: loss = 0.00247935 (* 1 = 0.00247935 loss)
I1016 23:05:45.938241   636 sgd_solver.cpp:105] Iteration 159200, lr = 0.0001
I1016 23:05:55.109539   636 solver.cpp:218] Iteration 159300 (10.9037 iter/s, 9.17124s/100 iters), loss = 0.00108185
I1016 23:05:55.109539   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:05:55.109539   636 solver.cpp:237]     Train net output #1: loss = 0.00108161 (* 1 = 0.00108161 loss)
I1016 23:05:55.109539   636 sgd_solver.cpp:105] Iteration 159300, lr = 0.0001
I1016 23:06:04.270812   636 solver.cpp:218] Iteration 159400 (10.9162 iter/s, 9.16069s/100 iters), loss = 0.000876006
I1016 23:06:04.270812   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:06:04.270812   636 solver.cpp:237]     Train net output #1: loss = 0.00087577 (* 1 = 0.00087577 loss)
I1016 23:06:04.270812   636 sgd_solver.cpp:105] Iteration 159400, lr = 0.0001
I1016 23:06:13.002560  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:06:13.363775   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_159500.caffemodel
I1016 23:06:13.388777   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_159500.solverstate
I1016 23:06:13.400789   636 solver.cpp:330] Iteration 159500, Testing net (#0)
I1016 23:06:13.401779   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:06:15.661543  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:06:15.752562   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 23:06:15.752562   636 solver.cpp:397]     Test net output #1: loss = 0.206313 (* 1 = 0.206313 loss)
I1016 23:06:15.840565   636 solver.cpp:218] Iteration 159500 (8.64355 iter/s, 11.5693s/100 iters), loss = 0.00165181
I1016 23:06:15.840565   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:06:15.840565   636 solver.cpp:237]     Train net output #1: loss = 0.00165158 (* 1 = 0.00165158 loss)
I1016 23:06:15.840565   636 sgd_solver.cpp:105] Iteration 159500, lr = 0.0001
I1016 23:06:25.039579   636 solver.cpp:218] Iteration 159600 (10.8725 iter/s, 9.19755s/100 iters), loss = 0.00146426
I1016 23:06:25.039579   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:06:25.039579   636 solver.cpp:237]     Train net output #1: loss = 0.00146403 (* 1 = 0.00146403 loss)
I1016 23:06:25.039579   636 sgd_solver.cpp:105] Iteration 159600, lr = 0.0001
I1016 23:06:34.207285   636 solver.cpp:218] Iteration 159700 (10.9082 iter/s, 9.16743s/100 iters), loss = 0.00258069
I1016 23:06:34.207285   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:06:34.207285   636 solver.cpp:237]     Train net output #1: loss = 0.00258045 (* 1 = 0.00258045 loss)
I1016 23:06:34.207285   636 sgd_solver.cpp:105] Iteration 159700, lr = 0.0001
I1016 23:06:43.394047   636 solver.cpp:218] Iteration 159800 (10.8855 iter/s, 9.18656s/100 iters), loss = 0.000784761
I1016 23:06:43.394047   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:06:43.394047   636 solver.cpp:237]     Train net output #1: loss = 0.000784525 (* 1 = 0.000784525 loss)
I1016 23:06:43.394047   636 sgd_solver.cpp:105] Iteration 159800, lr = 0.0001
I1016 23:06:52.550395   636 solver.cpp:218] Iteration 159900 (10.9226 iter/s, 9.15537s/100 iters), loss = 0.00089594
I1016 23:06:52.550395   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:06:52.550395   636 solver.cpp:237]     Train net output #1: loss = 0.000895703 (* 1 = 0.000895703 loss)
I1016 23:06:52.550395   636 sgd_solver.cpp:105] Iteration 159900, lr = 0.0001
I1016 23:07:01.238648  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:07:01.606266   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_160000.caffemodel
I1016 23:07:01.626268   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_160000.solverstate
I1016 23:07:01.646283   636 solver.cpp:330] Iteration 160000, Testing net (#0)
I1016 23:07:01.646283   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:07:03.897459  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:07:03.987483   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 23:07:03.987483   636 solver.cpp:397]     Test net output #1: loss = 0.206211 (* 1 = 0.206211 loss)
I1016 23:07:04.084985   636 solver.cpp:218] Iteration 160000 (8.66996 iter/s, 11.5341s/100 iters), loss = 0.00245078
I1016 23:07:04.084985   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:07:04.084985   636 solver.cpp:237]     Train net output #1: loss = 0.00245054 (* 1 = 0.00245054 loss)
I1016 23:07:04.084985   636 sgd_solver.cpp:105] Iteration 160000, lr = 0.0001
I1016 23:07:13.222419   636 solver.cpp:218] Iteration 160100 (10.9449 iter/s, 9.13665s/100 iters), loss = 0.00153568
I1016 23:07:13.222419   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:07:13.222419   636 solver.cpp:237]     Train net output #1: loss = 0.00153544 (* 1 = 0.00153544 loss)
I1016 23:07:13.222419   636 sgd_solver.cpp:105] Iteration 160100, lr = 0.0001
I1016 23:07:22.368507   636 solver.cpp:218] Iteration 160200 (10.9262 iter/s, 9.1523s/100 iters), loss = 0.00342222
I1016 23:07:22.368507   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:07:22.368507   636 solver.cpp:237]     Train net output #1: loss = 0.00342199 (* 1 = 0.00342199 loss)
I1016 23:07:22.368507   636 sgd_solver.cpp:105] Iteration 160200, lr = 0.0001
I1016 23:07:31.501044   636 solver.cpp:218] Iteration 160300 (10.9483 iter/s, 9.13383s/100 iters), loss = 0.00112231
I1016 23:07:31.501044   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:07:31.501044   636 solver.cpp:237]     Train net output #1: loss = 0.00112208 (* 1 = 0.00112208 loss)
I1016 23:07:31.501044   636 sgd_solver.cpp:105] Iteration 160300, lr = 0.0001
I1016 23:07:40.646273   636 solver.cpp:218] Iteration 160400 (10.942 iter/s, 9.13907s/100 iters), loss = 0.00111564
I1016 23:07:40.646273   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:07:40.646273   636 solver.cpp:237]     Train net output #1: loss = 0.0011154 (* 1 = 0.0011154 loss)
I1016 23:07:40.646273   636 sgd_solver.cpp:105] Iteration 160400, lr = 0.0001
I1016 23:07:49.354584  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:07:49.712610   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_160500.caffemodel
I1016 23:07:49.742614   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_160500.solverstate
I1016 23:07:49.752640   636 solver.cpp:330] Iteration 160500, Testing net (#0)
I1016 23:07:49.752640   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:07:52.013885  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:07:52.103912   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 23:07:52.103912   636 solver.cpp:397]     Test net output #1: loss = 0.206415 (* 1 = 0.206415 loss)
I1016 23:07:52.193897   636 solver.cpp:218] Iteration 160500 (8.66065 iter/s, 11.5465s/100 iters), loss = 0.00149762
I1016 23:07:52.193897   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:07:52.193897   636 solver.cpp:237]     Train net output #1: loss = 0.00149739 (* 1 = 0.00149739 loss)
I1016 23:07:52.193897   636 sgd_solver.cpp:105] Iteration 160500, lr = 0.0001
I1016 23:08:01.321944   636 solver.cpp:218] Iteration 160600 (10.947 iter/s, 9.13494s/100 iters), loss = 0.00260112
I1016 23:08:01.321944   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:01.321944   636 solver.cpp:237]     Train net output #1: loss = 0.00260088 (* 1 = 0.00260088 loss)
I1016 23:08:01.321944   636 sgd_solver.cpp:105] Iteration 160600, lr = 0.0001
I1016 23:08:10.517858   636 solver.cpp:218] Iteration 160700 (10.8866 iter/s, 9.18557s/100 iters), loss = 0.00133407
I1016 23:08:10.517858   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:10.517858   636 solver.cpp:237]     Train net output #1: loss = 0.00133383 (* 1 = 0.00133383 loss)
I1016 23:08:10.517858   636 sgd_solver.cpp:105] Iteration 160700, lr = 0.0001
I1016 23:08:19.724946   636 solver.cpp:218] Iteration 160800 (10.8617 iter/s, 9.20664s/100 iters), loss = 0.000912582
I1016 23:08:19.724946   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:19.724946   636 solver.cpp:237]     Train net output #1: loss = 0.000912347 (* 1 = 0.000912347 loss)
I1016 23:08:19.724946   636 sgd_solver.cpp:105] Iteration 160800, lr = 0.0001
I1016 23:08:28.877882   636 solver.cpp:218] Iteration 160900 (10.921 iter/s, 9.1567s/100 iters), loss = 0.000821352
I1016 23:08:28.877882   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:28.877882   636 solver.cpp:237]     Train net output #1: loss = 0.000821118 (* 1 = 0.000821118 loss)
I1016 23:08:28.877882   636 sgd_solver.cpp:105] Iteration 160900, lr = 0.0001
I1016 23:08:37.551764  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:08:37.921800   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_161000.caffemodel
I1016 23:08:37.941803   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_161000.solverstate
I1016 23:08:37.951802   636 solver.cpp:330] Iteration 161000, Testing net (#0)
I1016 23:08:37.951802   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:08:40.213202  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:08:40.307760   636 solver.cpp:397]     Test net output #0: accuracy = 0.9455
I1016 23:08:40.307760   636 solver.cpp:397]     Test net output #1: loss = 0.206354 (* 1 = 0.206354 loss)
I1016 23:08:40.396699   636 solver.cpp:218] Iteration 161000 (8.68511 iter/s, 11.514s/100 iters), loss = 0.00190004
I1016 23:08:40.396699   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:40.396699   636 solver.cpp:237]     Train net output #1: loss = 0.0018998 (* 1 = 0.0018998 loss)
I1016 23:08:40.396699   636 sgd_solver.cpp:105] Iteration 161000, lr = 0.0001
I1016 23:08:49.546627   636 solver.cpp:218] Iteration 161100 (10.9248 iter/s, 9.15346s/100 iters), loss = 0.00250238
I1016 23:08:49.546627   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:49.546627   636 solver.cpp:237]     Train net output #1: loss = 0.00250214 (* 1 = 0.00250214 loss)
I1016 23:08:49.546627   636 sgd_solver.cpp:105] Iteration 161100, lr = 0.0001
I1016 23:08:58.752792   636 solver.cpp:218] Iteration 161200 (10.8678 iter/s, 9.20146s/100 iters), loss = 0.00333215
I1016 23:08:58.752792   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:08:58.752792   636 solver.cpp:237]     Train net output #1: loss = 0.00333192 (* 1 = 0.00333192 loss)
I1016 23:08:58.752792   636 sgd_solver.cpp:105] Iteration 161200, lr = 0.0001
I1016 23:09:07.914913   636 solver.cpp:218] Iteration 161300 (10.9149 iter/s, 9.16179s/100 iters), loss = 0.00136315
I1016 23:09:07.914913   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:09:07.914913   636 solver.cpp:237]     Train net output #1: loss = 0.00136292 (* 1 = 0.00136292 loss)
I1016 23:09:07.914913   636 sgd_solver.cpp:105] Iteration 161300, lr = 0.0001
I1016 23:09:17.231994   636 solver.cpp:218] Iteration 161400 (10.7334 iter/s, 9.31667s/100 iters), loss = 0.00100924
I1016 23:09:17.231994   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:09:17.231994   636 solver.cpp:237]     Train net output #1: loss = 0.001009 (* 1 = 0.001009 loss)
I1016 23:09:17.231994   636 sgd_solver.cpp:105] Iteration 161400, lr = 0.0001
I1016 23:09:26.072391  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:09:26.449445   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_161500.caffemodel
I1016 23:09:26.476446   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_161500.solverstate
I1016 23:09:26.489440   636 solver.cpp:330] Iteration 161500, Testing net (#0)
I1016 23:09:26.489440   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:09:28.780159  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:09:28.863487   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 23:09:28.863487   636 solver.cpp:397]     Test net output #1: loss = 0.206278 (* 1 = 0.206278 loss)
I1016 23:09:28.960695   636 solver.cpp:218] Iteration 161500 (8.5262 iter/s, 11.7285s/100 iters), loss = 0.00131227
I1016 23:09:28.960695   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:09:28.960695   636 solver.cpp:237]     Train net output #1: loss = 0.00131204 (* 1 = 0.00131204 loss)
I1016 23:09:28.960695   636 sgd_solver.cpp:105] Iteration 161500, lr = 0.0001
I1016 23:09:38.274196   636 solver.cpp:218] Iteration 161600 (10.7384 iter/s, 9.31234s/100 iters), loss = 0.00236014
I1016 23:09:38.274196   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:09:38.274196   636 solver.cpp:237]     Train net output #1: loss = 0.00235991 (* 1 = 0.00235991 loss)
I1016 23:09:38.274196   636 sgd_solver.cpp:105] Iteration 161600, lr = 0.0001
I1016 23:09:47.506345   636 solver.cpp:218] Iteration 161700 (10.8318 iter/s, 9.23207s/100 iters), loss = 0.00181184
I1016 23:09:47.506345   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:09:47.506345   636 solver.cpp:237]     Train net output #1: loss = 0.00181161 (* 1 = 0.00181161 loss)
I1016 23:09:47.506345   636 sgd_solver.cpp:105] Iteration 161700, lr = 0.0001
I1016 23:09:56.731823   636 solver.cpp:218] Iteration 161800 (10.8406 iter/s, 9.22455s/100 iters), loss = 0.00219077
I1016 23:09:56.731823   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:09:56.731823   636 solver.cpp:237]     Train net output #1: loss = 0.00219054 (* 1 = 0.00219054 loss)
I1016 23:09:56.731823   636 sgd_solver.cpp:105] Iteration 161800, lr = 0.0001
I1016 23:10:05.900773   636 solver.cpp:218] Iteration 161900 (10.9075 iter/s, 9.16804s/100 iters), loss = 0.00212104
I1016 23:10:05.900773   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:10:05.900773   636 solver.cpp:237]     Train net output #1: loss = 0.00212081 (* 1 = 0.00212081 loss)
I1016 23:10:05.900773   636 sgd_solver.cpp:105] Iteration 161900, lr = 0.0001
I1016 23:10:14.646183  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:10:15.019214   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_162000.caffemodel
I1016 23:10:15.046216   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_162000.solverstate
I1016 23:10:15.058214   636 solver.cpp:330] Iteration 162000, Testing net (#0)
I1016 23:10:15.058214   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:10:17.376570  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:10:17.469579   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 23:10:17.469579   636 solver.cpp:397]     Test net output #1: loss = 0.206291 (* 1 = 0.206291 loss)
I1016 23:10:17.560583   636 solver.cpp:218] Iteration 162000 (8.57679 iter/s, 11.6594s/100 iters), loss = 0.00281011
I1016 23:10:17.560583   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:10:17.560583   636 solver.cpp:237]     Train net output #1: loss = 0.00280988 (* 1 = 0.00280988 loss)
I1016 23:10:17.560583   636 sgd_solver.cpp:105] Iteration 162000, lr = 0.0001
I1016 23:10:26.786660   636 solver.cpp:218] Iteration 162100 (10.8395 iter/s, 9.22554s/100 iters), loss = 0.00233227
I1016 23:10:26.786660   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:10:26.786660   636 solver.cpp:237]     Train net output #1: loss = 0.00233204 (* 1 = 0.00233204 loss)
I1016 23:10:26.786660   636 sgd_solver.cpp:105] Iteration 162100, lr = 0.0001
I1016 23:10:36.051748   636 solver.cpp:218] Iteration 162200 (10.7939 iter/s, 9.26447s/100 iters), loss = 0.00365147
I1016 23:10:36.051748   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:10:36.051748   636 solver.cpp:237]     Train net output #1: loss = 0.00365124 (* 1 = 0.00365124 loss)
I1016 23:10:36.051748   636 sgd_solver.cpp:105] Iteration 162200, lr = 0.0001
I1016 23:10:45.320385   636 solver.cpp:218] Iteration 162300 (10.7899 iter/s, 9.26789s/100 iters), loss = 0.00203172
I1016 23:10:45.320385   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:10:45.320385   636 solver.cpp:237]     Train net output #1: loss = 0.0020315 (* 1 = 0.0020315 loss)
I1016 23:10:45.320385   636 sgd_solver.cpp:105] Iteration 162300, lr = 0.0001
I1016 23:10:54.577282   636 solver.cpp:218] Iteration 162400 (10.8029 iter/s, 9.25676s/100 iters), loss = 0.00147342
I1016 23:10:54.577282   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:10:54.577282   636 solver.cpp:237]     Train net output #1: loss = 0.00147319 (* 1 = 0.00147319 loss)
I1016 23:10:54.577282   636 sgd_solver.cpp:105] Iteration 162400, lr = 0.0001
I1016 23:11:03.358798  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:11:03.712352   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_162500.caffemodel
I1016 23:11:03.742355   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_162500.solverstate
I1016 23:11:03.752354   636 solver.cpp:330] Iteration 162500, Testing net (#0)
I1016 23:11:03.752354   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:11:06.028242  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:11:06.119249   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:11:06.119249   636 solver.cpp:397]     Test net output #1: loss = 0.206252 (* 1 = 0.206252 loss)
I1016 23:11:06.208254   636 solver.cpp:218] Iteration 162500 (8.59869 iter/s, 11.6297s/100 iters), loss = 0.00177283
I1016 23:11:06.208254   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:11:06.208254   636 solver.cpp:237]     Train net output #1: loss = 0.0017726 (* 1 = 0.0017726 loss)
I1016 23:11:06.208254   636 sgd_solver.cpp:105] Iteration 162500, lr = 0.0001
I1016 23:11:15.351363   636 solver.cpp:218] Iteration 162600 (10.9261 iter/s, 9.15239s/100 iters), loss = 0.00148978
I1016 23:11:15.351363   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:11:15.351363   636 solver.cpp:237]     Train net output #1: loss = 0.00148955 (* 1 = 0.00148955 loss)
I1016 23:11:15.351363   636 sgd_solver.cpp:105] Iteration 162600, lr = 0.0001
I1016 23:11:24.517932   636 solver.cpp:218] Iteration 162700 (10.9206 iter/s, 9.15701s/100 iters), loss = 0.0030628
I1016 23:11:24.517932   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:11:24.517932   636 solver.cpp:237]     Train net output #1: loss = 0.00306257 (* 1 = 0.00306257 loss)
I1016 23:11:24.517932   636 sgd_solver.cpp:105] Iteration 162700, lr = 0.0001
I1016 23:11:33.660935   636 solver.cpp:218] Iteration 162800 (10.9343 iter/s, 9.14554s/100 iters), loss = 0.00314872
I1016 23:11:33.660935   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:11:33.660935   636 solver.cpp:237]     Train net output #1: loss = 0.00314849 (* 1 = 0.00314849 loss)
I1016 23:11:33.660935   636 sgd_solver.cpp:105] Iteration 162800, lr = 0.0001
I1016 23:11:42.815188   636 solver.cpp:218] Iteration 162900 (10.9286 iter/s, 9.15034s/100 iters), loss = 0.00146006
I1016 23:11:42.815678   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:11:42.815678   636 solver.cpp:237]     Train net output #1: loss = 0.00145983 (* 1 = 0.00145983 loss)
I1016 23:11:42.815678   636 sgd_solver.cpp:105] Iteration 162900, lr = 0.0001
I1016 23:11:51.494191  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:11:51.861323   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_163000.caffemodel
I1016 23:11:51.881464   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_163000.solverstate
I1016 23:11:51.901464   636 solver.cpp:330] Iteration 163000, Testing net (#0)
I1016 23:11:51.901464   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:11:54.155772  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:11:54.245622   636 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1016 23:11:54.245622   636 solver.cpp:397]     Test net output #1: loss = 0.206245 (* 1 = 0.206245 loss)
I1016 23:11:54.335651   636 solver.cpp:218] Iteration 163000 (8.67677 iter/s, 11.525s/100 iters), loss = 0.00183426
I1016 23:11:54.335651   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:11:54.335651   636 solver.cpp:237]     Train net output #1: loss = 0.00183404 (* 1 = 0.00183404 loss)
I1016 23:11:54.335651   636 sgd_solver.cpp:105] Iteration 163000, lr = 0.0001
I1016 23:12:03.578946   636 solver.cpp:218] Iteration 163100 (10.8199 iter/s, 9.24225s/100 iters), loss = 0.00202706
I1016 23:12:03.578946   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:12:03.578946   636 solver.cpp:237]     Train net output #1: loss = 0.00202683 (* 1 = 0.00202683 loss)
I1016 23:12:03.578946   636 sgd_solver.cpp:105] Iteration 163100, lr = 0.0001
I1016 23:12:12.759469   636 solver.cpp:218] Iteration 163200 (10.8982 iter/s, 9.17583s/100 iters), loss = 0.00237607
I1016 23:12:12.760469   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:12:12.760469   636 solver.cpp:237]     Train net output #1: loss = 0.00237585 (* 1 = 0.00237585 loss)
I1016 23:12:12.760469   636 sgd_solver.cpp:105] Iteration 163200, lr = 0.0001
I1016 23:12:21.947083   636 solver.cpp:218] Iteration 163300 (10.8862 iter/s, 9.18594s/100 iters), loss = 0.00178348
I1016 23:12:21.947083   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:12:21.947083   636 solver.cpp:237]     Train net output #1: loss = 0.00178326 (* 1 = 0.00178326 loss)
I1016 23:12:21.947083   636 sgd_solver.cpp:105] Iteration 163300, lr = 0.0001
I1016 23:12:31.288552   636 solver.cpp:218] Iteration 163400 (10.7054 iter/s, 9.34109s/100 iters), loss = 0.00108348
I1016 23:12:31.288552   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:12:31.288552   636 solver.cpp:237]     Train net output #1: loss = 0.00108325 (* 1 = 0.00108325 loss)
I1016 23:12:31.288552   636 sgd_solver.cpp:105] Iteration 163400, lr = 0.0001
I1016 23:12:40.153909  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:12:40.520910   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_163500.caffemodel
I1016 23:12:40.546409   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_163500.solverstate
I1016 23:12:40.558409   636 solver.cpp:330] Iteration 163500, Testing net (#0)
I1016 23:12:40.558409   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:12:42.820914  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:12:42.914911   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:12:42.914911   636 solver.cpp:397]     Test net output #1: loss = 0.206307 (* 1 = 0.206307 loss)
I1016 23:12:43.006419   636 solver.cpp:218] Iteration 163500 (8.5345 iter/s, 11.7171s/100 iters), loss = 0.00133331
I1016 23:12:43.006419   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:12:43.006419   636 solver.cpp:237]     Train net output #1: loss = 0.00133308 (* 1 = 0.00133308 loss)
I1016 23:12:43.006419   636 sgd_solver.cpp:105] Iteration 163500, lr = 0.0001
I1016 23:12:52.261862   636 solver.cpp:218] Iteration 163600 (10.8052 iter/s, 9.25485s/100 iters), loss = 0.00154653
I1016 23:12:52.261862   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:12:52.261862   636 solver.cpp:237]     Train net output #1: loss = 0.0015463 (* 1 = 0.0015463 loss)
I1016 23:12:52.261862   636 sgd_solver.cpp:105] Iteration 163600, lr = 0.0001
I1016 23:13:01.469420   636 solver.cpp:218] Iteration 163700 (10.8614 iter/s, 9.20694s/100 iters), loss = 0.00125693
I1016 23:13:01.469420   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:01.469420   636 solver.cpp:237]     Train net output #1: loss = 0.00125671 (* 1 = 0.00125671 loss)
I1016 23:13:01.469420   636 sgd_solver.cpp:105] Iteration 163700, lr = 0.0001
I1016 23:13:10.762797   636 solver.cpp:218] Iteration 163800 (10.76 iter/s, 9.29368s/100 iters), loss = 0.00317863
I1016 23:13:10.763797   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:10.763797   636 solver.cpp:237]     Train net output #1: loss = 0.0031784 (* 1 = 0.0031784 loss)
I1016 23:13:10.763797   636 sgd_solver.cpp:105] Iteration 163800, lr = 0.0001
I1016 23:13:19.971797   636 solver.cpp:218] Iteration 163900 (10.86 iter/s, 9.20806s/100 iters), loss = 0.000988633
I1016 23:13:19.971797   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:19.971797   636 solver.cpp:237]     Train net output #1: loss = 0.000988404 (* 1 = 0.000988404 loss)
I1016 23:13:19.971797   636 sgd_solver.cpp:105] Iteration 163900, lr = 0.0001
I1016 23:13:28.693320  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:13:29.057412   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_164000.caffemodel
I1016 23:13:29.084131   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_164000.solverstate
I1016 23:13:29.097126   636 solver.cpp:330] Iteration 164000, Testing net (#0)
I1016 23:13:29.097126   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:13:31.359889  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:13:31.452392   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 23:13:31.452392   636 solver.cpp:397]     Test net output #1: loss = 0.206484 (* 1 = 0.206484 loss)
I1016 23:13:31.540894   636 solver.cpp:218] Iteration 164000 (8.64393 iter/s, 11.5688s/100 iters), loss = 0.00146293
I1016 23:13:31.540894   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:31.540894   636 solver.cpp:237]     Train net output #1: loss = 0.00146271 (* 1 = 0.00146271 loss)
I1016 23:13:31.540894   636 sgd_solver.cpp:105] Iteration 164000, lr = 0.0001
I1016 23:13:40.703719   636 solver.cpp:218] Iteration 164100 (10.9145 iter/s, 9.16214s/100 iters), loss = 0.00300393
I1016 23:13:40.703719   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:40.703719   636 solver.cpp:237]     Train net output #1: loss = 0.0030037 (* 1 = 0.0030037 loss)
I1016 23:13:40.703719   636 sgd_solver.cpp:105] Iteration 164100, lr = 0.0001
I1016 23:13:49.876473   636 solver.cpp:218] Iteration 164200 (10.903 iter/s, 9.17179s/100 iters), loss = 0.00245075
I1016 23:13:49.876473   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:49.876473   636 solver.cpp:237]     Train net output #1: loss = 0.00245052 (* 1 = 0.00245052 loss)
I1016 23:13:49.876473   636 sgd_solver.cpp:105] Iteration 164200, lr = 0.0001
I1016 23:13:59.043123   636 solver.cpp:218] Iteration 164300 (10.9093 iter/s, 9.16645s/100 iters), loss = 0.00141274
I1016 23:13:59.044124   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:13:59.044124   636 solver.cpp:237]     Train net output #1: loss = 0.00141251 (* 1 = 0.00141251 loss)
I1016 23:13:59.044124   636 sgd_solver.cpp:105] Iteration 164300, lr = 0.0001
I1016 23:14:08.208853   636 solver.cpp:218] Iteration 164400 (10.9118 iter/s, 9.16437s/100 iters), loss = 0.000435112
I1016 23:14:08.208853   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:14:08.208853   636 solver.cpp:237]     Train net output #1: loss = 0.000434884 (* 1 = 0.000434884 loss)
I1016 23:14:08.208853   636 sgd_solver.cpp:105] Iteration 164400, lr = 0.0001
I1016 23:14:16.943516  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:14:17.305541   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_164500.caffemodel
I1016 23:14:17.334542   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_164500.solverstate
I1016 23:14:17.347048   636 solver.cpp:330] Iteration 164500, Testing net (#0)
I1016 23:14:17.347048   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:14:19.615023  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:14:19.706065   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:14:19.706065   636 solver.cpp:397]     Test net output #1: loss = 0.206258 (* 1 = 0.206258 loss)
I1016 23:14:19.795066   636 solver.cpp:218] Iteration 164500 (8.63142 iter/s, 11.5856s/100 iters), loss = 0.00161776
I1016 23:14:19.795066   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:14:19.795066   636 solver.cpp:237]     Train net output #1: loss = 0.00161754 (* 1 = 0.00161754 loss)
I1016 23:14:19.795066   636 sgd_solver.cpp:105] Iteration 164500, lr = 0.0001
I1016 23:14:28.954201   636 solver.cpp:218] Iteration 164600 (10.9186 iter/s, 9.1587s/100 iters), loss = 0.00158548
I1016 23:14:28.954201   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:14:28.954201   636 solver.cpp:237]     Train net output #1: loss = 0.00158525 (* 1 = 0.00158525 loss)
I1016 23:14:28.954201   636 sgd_solver.cpp:105] Iteration 164600, lr = 0.0001
I1016 23:14:38.122409   636 solver.cpp:218] Iteration 164700 (10.9078 iter/s, 9.16774s/100 iters), loss = 0.0020588
I1016 23:14:38.122409   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:14:38.122409   636 solver.cpp:237]     Train net output #1: loss = 0.00205858 (* 1 = 0.00205858 loss)
I1016 23:14:38.122409   636 sgd_solver.cpp:105] Iteration 164700, lr = 0.0001
I1016 23:14:47.276268   636 solver.cpp:218] Iteration 164800 (10.9252 iter/s, 9.15317s/100 iters), loss = 0.00345163
I1016 23:14:47.276268   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:14:47.276268   636 solver.cpp:237]     Train net output #1: loss = 0.0034514 (* 1 = 0.0034514 loss)
I1016 23:14:47.276268   636 sgd_solver.cpp:105] Iteration 164800, lr = 0.0001
I1016 23:14:56.583945   636 solver.cpp:218] Iteration 164900 (10.7441 iter/s, 9.30742s/100 iters), loss = 0.00118876
I1016 23:14:56.583945   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:14:56.583945   636 solver.cpp:237]     Train net output #1: loss = 0.00118854 (* 1 = 0.00118854 loss)
I1016 23:14:56.583945   636 sgd_solver.cpp:105] Iteration 164900, lr = 0.0001
I1016 23:15:05.336611  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:15:05.704654   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_165000.caffemodel
I1016 23:15:05.730654   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_165000.solverstate
I1016 23:15:05.742672   636 solver.cpp:330] Iteration 165000, Testing net (#0)
I1016 23:15:05.742672   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:15:08.037858  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:15:08.128859   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:15:08.128859   636 solver.cpp:397]     Test net output #1: loss = 0.206292 (* 1 = 0.206292 loss)
I1016 23:15:08.217864   636 solver.cpp:218] Iteration 165000 (8.59622 iter/s, 11.633s/100 iters), loss = 0.00197721
I1016 23:15:08.217864   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:15:08.217864   636 solver.cpp:237]     Train net output #1: loss = 0.00197699 (* 1 = 0.00197699 loss)
I1016 23:15:08.217864   636 sgd_solver.cpp:105] Iteration 165000, lr = 0.0001
I1016 23:15:17.557438   636 solver.cpp:218] Iteration 165100 (10.7076 iter/s, 9.33913s/100 iters), loss = 0.00122769
I1016 23:15:17.557438   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:15:17.557438   636 solver.cpp:237]     Train net output #1: loss = 0.00122746 (* 1 = 0.00122746 loss)
I1016 23:15:17.557438   636 sgd_solver.cpp:105] Iteration 165100, lr = 0.0001
I1016 23:15:26.835031   636 solver.cpp:218] Iteration 165200 (10.7784 iter/s, 9.27785s/100 iters), loss = 0.00195692
I1016 23:15:26.836031   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:15:26.836031   636 solver.cpp:237]     Train net output #1: loss = 0.0019567 (* 1 = 0.0019567 loss)
I1016 23:15:26.836031   636 sgd_solver.cpp:105] Iteration 165200, lr = 0.0001
I1016 23:15:35.999783   636 solver.cpp:218] Iteration 165300 (10.9129 iter/s, 9.16349s/100 iters), loss = 0.00227525
I1016 23:15:35.999783   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:15:35.999783   636 solver.cpp:237]     Train net output #1: loss = 0.00227502 (* 1 = 0.00227502 loss)
I1016 23:15:35.999783   636 sgd_solver.cpp:105] Iteration 165300, lr = 0.0001
I1016 23:15:45.264247   636 solver.cpp:218] Iteration 165400 (10.7949 iter/s, 9.26366s/100 iters), loss = 0.00200307
I1016 23:15:45.264247   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:15:45.264247   636 solver.cpp:237]     Train net output #1: loss = 0.00200284 (* 1 = 0.00200284 loss)
I1016 23:15:45.264247   636 sgd_solver.cpp:105] Iteration 165400, lr = 0.0001
I1016 23:15:54.069103  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:15:54.431607   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_165500.caffemodel
I1016 23:15:54.460609   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_165500.solverstate
I1016 23:15:54.473611   636 solver.cpp:330] Iteration 165500, Testing net (#0)
I1016 23:15:54.473611   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:15:56.765792  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:15:56.856796   636 solver.cpp:397]     Test net output #0: accuracy = 0.9454
I1016 23:15:56.856796   636 solver.cpp:397]     Test net output #1: loss = 0.206317 (* 1 = 0.206317 loss)
I1016 23:15:56.947824   636 solver.cpp:218] Iteration 165500 (8.55923 iter/s, 11.6833s/100 iters), loss = 0.00200955
I1016 23:15:56.947824   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:15:56.947824   636 solver.cpp:237]     Train net output #1: loss = 0.00200932 (* 1 = 0.00200932 loss)
I1016 23:15:56.947824   636 sgd_solver.cpp:105] Iteration 165500, lr = 0.0001
I1016 23:16:06.292238   636 solver.cpp:218] Iteration 165600 (10.7023 iter/s, 9.34375s/100 iters), loss = 0.00159731
I1016 23:16:06.292238   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:16:06.292238   636 solver.cpp:237]     Train net output #1: loss = 0.00159708 (* 1 = 0.00159708 loss)
I1016 23:16:06.292238   636 sgd_solver.cpp:105] Iteration 165600, lr = 0.0001
I1016 23:16:15.566591   636 solver.cpp:218] Iteration 165700 (10.7832 iter/s, 9.27367s/100 iters), loss = 0.00303646
I1016 23:16:15.566591   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:16:15.566591   636 solver.cpp:237]     Train net output #1: loss = 0.00303624 (* 1 = 0.00303624 loss)
I1016 23:16:15.566591   636 sgd_solver.cpp:105] Iteration 165700, lr = 0.0001
I1016 23:16:24.849234   636 solver.cpp:218] Iteration 165800 (10.7734 iter/s, 9.28214s/100 iters), loss = 0.00161998
I1016 23:16:24.849234   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:16:24.849234   636 solver.cpp:237]     Train net output #1: loss = 0.00161975 (* 1 = 0.00161975 loss)
I1016 23:16:24.849234   636 sgd_solver.cpp:105] Iteration 165800, lr = 0.0001
I1016 23:16:34.150048   636 solver.cpp:218] Iteration 165900 (10.7521 iter/s, 9.30055s/100 iters), loss = 0.00068474
I1016 23:16:34.150048   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:16:34.150048   636 solver.cpp:237]     Train net output #1: loss = 0.000684513 (* 1 = 0.000684513 loss)
I1016 23:16:34.150048   636 sgd_solver.cpp:105] Iteration 165900, lr = 0.0001
I1016 23:16:42.952705  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:16:43.314724   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_166000.caffemodel
I1016 23:16:43.342723   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_166000.solverstate
I1016 23:16:43.354728   636 solver.cpp:330] Iteration 166000, Testing net (#0)
I1016 23:16:43.354728   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:16:45.621902  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:16:45.712905   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:16:45.712905   636 solver.cpp:397]     Test net output #1: loss = 0.20603 (* 1 = 0.20603 loss)
I1016 23:16:45.800925   636 solver.cpp:218] Iteration 166000 (8.58315 iter/s, 11.6507s/100 iters), loss = 0.00371916
I1016 23:16:45.800925   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:16:45.800925   636 solver.cpp:237]     Train net output #1: loss = 0.00371894 (* 1 = 0.00371894 loss)
I1016 23:16:45.800925   636 sgd_solver.cpp:105] Iteration 166000, lr = 0.0001
I1016 23:16:55.018702   636 solver.cpp:218] Iteration 166100 (10.85 iter/s, 9.21656s/100 iters), loss = 0.00100671
I1016 23:16:55.018702   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:16:55.018702   636 solver.cpp:237]     Train net output #1: loss = 0.00100649 (* 1 = 0.00100649 loss)
I1016 23:16:55.018702   636 sgd_solver.cpp:105] Iteration 166100, lr = 0.0001
I1016 23:17:04.341271   636 solver.cpp:218] Iteration 166200 (10.7275 iter/s, 9.32185s/100 iters), loss = 0.00305914
I1016 23:17:04.341271   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:17:04.341271   636 solver.cpp:237]     Train net output #1: loss = 0.00305892 (* 1 = 0.00305892 loss)
I1016 23:17:04.341271   636 sgd_solver.cpp:105] Iteration 166200, lr = 0.0001
I1016 23:17:13.535326   636 solver.cpp:218] Iteration 166300 (10.8772 iter/s, 9.19355s/100 iters), loss = 0.00124731
I1016 23:17:13.535326   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:17:13.535326   636 solver.cpp:237]     Train net output #1: loss = 0.00124708 (* 1 = 0.00124708 loss)
I1016 23:17:13.535326   636 sgd_solver.cpp:105] Iteration 166300, lr = 0.0001
I1016 23:17:22.819574   636 solver.cpp:218] Iteration 166400 (10.7714 iter/s, 9.28384s/100 iters), loss = 0.000790883
I1016 23:17:22.819574   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:17:22.819574   636 solver.cpp:237]     Train net output #1: loss = 0.000790655 (* 1 = 0.000790655 loss)
I1016 23:17:22.819574   636 sgd_solver.cpp:105] Iteration 166400, lr = 0.0001
I1016 23:17:31.541959  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:17:31.901131   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_166500.caffemodel
I1016 23:17:31.931125   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_166500.solverstate
I1016 23:17:31.943249   636 solver.cpp:330] Iteration 166500, Testing net (#0)
I1016 23:17:31.943249   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:17:34.203255  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:17:34.293449   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 23:17:34.293449   636 solver.cpp:397]     Test net output #1: loss = 0.206247 (* 1 = 0.206247 loss)
I1016 23:17:34.390468   636 solver.cpp:218] Iteration 166500 (8.64204 iter/s, 11.5713s/100 iters), loss = 0.00142832
I1016 23:17:34.390468   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:17:34.390468   636 solver.cpp:237]     Train net output #1: loss = 0.00142809 (* 1 = 0.00142809 loss)
I1016 23:17:34.390468   636 sgd_solver.cpp:105] Iteration 166500, lr = 0.0001
I1016 23:17:43.571847   636 solver.cpp:218] Iteration 166600 (10.8933 iter/s, 9.17993s/100 iters), loss = 0.00133018
I1016 23:17:43.571847   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:17:43.571847   636 solver.cpp:237]     Train net output #1: loss = 0.00132995 (* 1 = 0.00132995 loss)
I1016 23:17:43.571847   636 sgd_solver.cpp:105] Iteration 166600, lr = 0.0001
I1016 23:17:52.733892   636 solver.cpp:218] Iteration 166700 (10.9156 iter/s, 9.16124s/100 iters), loss = 0.00142505
I1016 23:17:52.733892   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:17:52.733892   636 solver.cpp:237]     Train net output #1: loss = 0.00142482 (* 1 = 0.00142482 loss)
I1016 23:17:52.733892   636 sgd_solver.cpp:105] Iteration 166700, lr = 0.0001
I1016 23:18:01.970849   636 solver.cpp:218] Iteration 166800 (10.8269 iter/s, 9.23628s/100 iters), loss = 0.0012103
I1016 23:18:01.970849   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:01.970849   636 solver.cpp:237]     Train net output #1: loss = 0.00121007 (* 1 = 0.00121007 loss)
I1016 23:18:01.970849   636 sgd_solver.cpp:105] Iteration 166800, lr = 0.0001
I1016 23:18:11.188508   636 solver.cpp:218] Iteration 166900 (10.8493 iter/s, 9.21722s/100 iters), loss = 0.00079584
I1016 23:18:11.188508   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:11.188508   636 solver.cpp:237]     Train net output #1: loss = 0.000795612 (* 1 = 0.000795612 loss)
I1016 23:18:11.188508   636 sgd_solver.cpp:105] Iteration 166900, lr = 0.0001
I1016 23:18:20.032074  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:18:20.405861   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_167000.caffemodel
I1016 23:18:20.430862   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_167000.solverstate
I1016 23:18:20.443424   636 solver.cpp:330] Iteration 167000, Testing net (#0)
I1016 23:18:20.443424   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:18:22.738906  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:18:22.833412   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:18:22.833412   636 solver.cpp:397]     Test net output #1: loss = 0.206407 (* 1 = 0.206407 loss)
I1016 23:18:22.924449   636 solver.cpp:218] Iteration 167000 (8.52076 iter/s, 11.736s/100 iters), loss = 0.00182133
I1016 23:18:22.924449   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:22.924449   636 solver.cpp:237]     Train net output #1: loss = 0.0018211 (* 1 = 0.0018211 loss)
I1016 23:18:22.925456   636 sgd_solver.cpp:105] Iteration 167000, lr = 0.0001
I1016 23:18:32.105357   636 solver.cpp:218] Iteration 167100 (10.8939 iter/s, 9.17946s/100 iters), loss = 0.00229251
I1016 23:18:32.105357   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:32.105357   636 solver.cpp:237]     Train net output #1: loss = 0.00229228 (* 1 = 0.00229228 loss)
I1016 23:18:32.105357   636 sgd_solver.cpp:105] Iteration 167100, lr = 0.0001
I1016 23:18:41.383649   636 solver.cpp:218] Iteration 167200 (10.7777 iter/s, 9.27844s/100 iters), loss = 0.00224037
I1016 23:18:41.383649   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:41.383649   636 solver.cpp:237]     Train net output #1: loss = 0.00224015 (* 1 = 0.00224015 loss)
I1016 23:18:41.383649   636 sgd_solver.cpp:105] Iteration 167200, lr = 0.0001
I1016 23:18:50.578790   636 solver.cpp:218] Iteration 167300 (10.8758 iter/s, 9.19475s/100 iters), loss = 0.00196252
I1016 23:18:50.578790   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:50.578790   636 solver.cpp:237]     Train net output #1: loss = 0.0019623 (* 1 = 0.0019623 loss)
I1016 23:18:50.578790   636 sgd_solver.cpp:105] Iteration 167300, lr = 0.0001
I1016 23:18:59.712709   636 solver.cpp:218] Iteration 167400 (10.9386 iter/s, 9.14193s/100 iters), loss = 0.00163361
I1016 23:18:59.712709   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:18:59.712709   636 solver.cpp:237]     Train net output #1: loss = 0.00163338 (* 1 = 0.00163338 loss)
I1016 23:18:59.712709   636 sgd_solver.cpp:105] Iteration 167400, lr = 0.0001
I1016 23:19:08.476248  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:19:08.840425   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_167500.caffemodel
I1016 23:19:08.869812   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_167500.solverstate
I1016 23:19:08.879822   636 solver.cpp:330] Iteration 167500, Testing net (#0)
I1016 23:19:08.879822   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:19:11.146250  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:19:11.237253   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 23:19:11.237253   636 solver.cpp:397]     Test net output #1: loss = 0.206301 (* 1 = 0.206301 loss)
I1016 23:19:11.326380   636 solver.cpp:218] Iteration 167500 (8.61794 iter/s, 11.6037s/100 iters), loss = 0.00232651
I1016 23:19:11.326380   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:19:11.326380   636 solver.cpp:237]     Train net output #1: loss = 0.00232629 (* 1 = 0.00232629 loss)
I1016 23:19:11.326380   636 sgd_solver.cpp:105] Iteration 167500, lr = 0.0001
I1016 23:19:20.521419   636 solver.cpp:218] Iteration 167600 (10.8656 iter/s, 9.20333s/100 iters), loss = 0.00110067
I1016 23:19:20.521419   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:19:20.521419   636 solver.cpp:237]     Train net output #1: loss = 0.00110045 (* 1 = 0.00110045 loss)
I1016 23:19:20.521419   636 sgd_solver.cpp:105] Iteration 167600, lr = 0.0001
I1016 23:19:29.695219   636 solver.cpp:218] Iteration 167700 (10.9084 iter/s, 9.16727s/100 iters), loss = 0.0022842
I1016 23:19:29.695219   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:19:29.695219   636 solver.cpp:237]     Train net output #1: loss = 0.00228398 (* 1 = 0.00228398 loss)
I1016 23:19:29.695219   636 sgd_solver.cpp:105] Iteration 167700, lr = 0.0001
I1016 23:19:38.921283   636 solver.cpp:218] Iteration 167800 (10.8325 iter/s, 9.2315s/100 iters), loss = 0.00370226
I1016 23:19:38.921283   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:19:38.921283   636 solver.cpp:237]     Train net output #1: loss = 0.00370203 (* 1 = 0.00370203 loss)
I1016 23:19:38.921283   636 sgd_solver.cpp:105] Iteration 167800, lr = 0.0001
I1016 23:19:48.105890   636 solver.cpp:218] Iteration 167900 (10.8994 iter/s, 9.17479s/100 iters), loss = 0.00143311
I1016 23:19:48.105890   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:19:48.105890   636 solver.cpp:237]     Train net output #1: loss = 0.00143288 (* 1 = 0.00143288 loss)
I1016 23:19:48.105890   636 sgd_solver.cpp:105] Iteration 167900, lr = 0.0001
I1016 23:19:56.821682  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:19:57.181483   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_168000.caffemodel
I1016 23:19:57.211493   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_168000.solverstate
I1016 23:19:57.221487   636 solver.cpp:330] Iteration 168000, Testing net (#0)
I1016 23:19:57.221487   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:19:59.483577  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:19:59.573621   636 solver.cpp:397]     Test net output #0: accuracy = 0.9457
I1016 23:19:59.573621   636 solver.cpp:397]     Test net output #1: loss = 0.206262 (* 1 = 0.206262 loss)
I1016 23:19:59.663734   636 solver.cpp:218] Iteration 168000 (8.64764 iter/s, 11.5638s/100 iters), loss = 0.00265368
I1016 23:19:59.663734   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:19:59.663734   636 solver.cpp:237]     Train net output #1: loss = 0.00265346 (* 1 = 0.00265346 loss)
I1016 23:19:59.663734   636 sgd_solver.cpp:105] Iteration 168000, lr = 0.0001
I1016 23:20:08.882792   636 solver.cpp:218] Iteration 168100 (10.8443 iter/s, 9.2214s/100 iters), loss = 0.00208368
I1016 23:20:08.882792   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:20:08.882792   636 solver.cpp:237]     Train net output #1: loss = 0.00208346 (* 1 = 0.00208346 loss)
I1016 23:20:08.882792   636 sgd_solver.cpp:105] Iteration 168100, lr = 0.0001
I1016 23:20:18.102135   636 solver.cpp:218] Iteration 168200 (10.8515 iter/s, 9.21529s/100 iters), loss = 0.00178798
I1016 23:20:18.102135   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:20:18.102135   636 solver.cpp:237]     Train net output #1: loss = 0.00178775 (* 1 = 0.00178775 loss)
I1016 23:20:18.102135   636 sgd_solver.cpp:105] Iteration 168200, lr = 0.0001
I1016 23:20:27.289443   636 solver.cpp:218] Iteration 168300 (10.885 iter/s, 9.18699s/100 iters), loss = 0.00105605
I1016 23:20:27.289443   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:20:27.289443   636 solver.cpp:237]     Train net output #1: loss = 0.00105582 (* 1 = 0.00105582 loss)
I1016 23:20:27.289443   636 sgd_solver.cpp:105] Iteration 168300, lr = 0.0001
I1016 23:20:36.484107   636 solver.cpp:218] Iteration 168400 (10.8726 iter/s, 9.19745s/100 iters), loss = 0.000613364
I1016 23:20:36.484107   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:20:36.484107   636 solver.cpp:237]     Train net output #1: loss = 0.000613137 (* 1 = 0.000613137 loss)
I1016 23:20:36.484107   636 sgd_solver.cpp:105] Iteration 168400, lr = 0.0001
I1016 23:20:45.167677  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:20:45.527966   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_168500.caffemodel
I1016 23:20:45.557970   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_168500.solverstate
I1016 23:20:45.567971   636 solver.cpp:330] Iteration 168500, Testing net (#0)
I1016 23:20:45.567971   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:20:47.828693  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:20:47.918890   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 23:20:47.918890   636 solver.cpp:397]     Test net output #1: loss = 0.206336 (* 1 = 0.206336 loss)
I1016 23:20:47.998895   636 solver.cpp:218] Iteration 168500 (8.68468 iter/s, 11.5145s/100 iters), loss = 0.00248248
I1016 23:20:48.008896   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:20:48.008896   636 solver.cpp:237]     Train net output #1: loss = 0.00248226 (* 1 = 0.00248226 loss)
I1016 23:20:48.008896   636 sgd_solver.cpp:105] Iteration 168500, lr = 0.0001
I1016 23:20:57.136374   636 solver.cpp:218] Iteration 168600 (10.9564 iter/s, 9.12709s/100 iters), loss = 0.0017567
I1016 23:20:57.136374   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:20:57.136374   636 solver.cpp:237]     Train net output #1: loss = 0.00175647 (* 1 = 0.00175647 loss)
I1016 23:20:57.136374   636 sgd_solver.cpp:105] Iteration 168600, lr = 0.0001
I1016 23:21:06.266183   636 solver.cpp:218] Iteration 168700 (10.9516 iter/s, 9.13105s/100 iters), loss = 0.0024792
I1016 23:21:06.266183   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:21:06.266183   636 solver.cpp:237]     Train net output #1: loss = 0.00247898 (* 1 = 0.00247898 loss)
I1016 23:21:06.266183   636 sgd_solver.cpp:105] Iteration 168700, lr = 0.0001
I1016 23:21:15.392423   636 solver.cpp:218] Iteration 168800 (10.9579 iter/s, 9.12582s/100 iters), loss = 0.000873753
I1016 23:21:15.392423   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:21:15.392423   636 solver.cpp:237]     Train net output #1: loss = 0.000873527 (* 1 = 0.000873527 loss)
I1016 23:21:15.392423   636 sgd_solver.cpp:105] Iteration 168800, lr = 0.0001
I1016 23:21:24.516844   636 solver.cpp:218] Iteration 168900 (10.9581 iter/s, 9.12568s/100 iters), loss = 0.000687239
I1016 23:21:24.516844   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:21:24.516844   636 solver.cpp:237]     Train net output #1: loss = 0.000687013 (* 1 = 0.000687013 loss)
I1016 23:21:24.516844   636 sgd_solver.cpp:105] Iteration 168900, lr = 0.0001
I1016 23:21:33.191716  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:21:33.551715   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_169000.caffemodel
I1016 23:21:33.571729   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_169000.solverstate
I1016 23:21:33.591722   636 solver.cpp:330] Iteration 169000, Testing net (#0)
I1016 23:21:33.591722   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:21:35.851166  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:21:35.932296   636 solver.cpp:397]     Test net output #0: accuracy = 0.946
I1016 23:21:35.932296   636 solver.cpp:397]     Test net output #1: loss = 0.206148 (* 1 = 0.206148 loss)
I1016 23:21:36.023303   636 solver.cpp:218] Iteration 169000 (8.68811 iter/s, 11.51s/100 iters), loss = 0.00138122
I1016 23:21:36.023303   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:21:36.023303   636 solver.cpp:237]     Train net output #1: loss = 0.00138099 (* 1 = 0.00138099 loss)
I1016 23:21:36.023303   636 sgd_solver.cpp:105] Iteration 169000, lr = 0.0001
I1016 23:21:45.157100   636 solver.cpp:218] Iteration 169100 (10.951 iter/s, 9.13159s/100 iters), loss = 0.00118377
I1016 23:21:45.157100   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:21:45.157100   636 solver.cpp:237]     Train net output #1: loss = 0.00118355 (* 1 = 0.00118355 loss)
I1016 23:21:45.157100   636 sgd_solver.cpp:105] Iteration 169100, lr = 0.0001
I1016 23:21:54.293175   636 solver.cpp:218] Iteration 169200 (10.9501 iter/s, 9.13236s/100 iters), loss = 0.00305273
I1016 23:21:54.293175   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:21:54.293175   636 solver.cpp:237]     Train net output #1: loss = 0.0030525 (* 1 = 0.0030525 loss)
I1016 23:21:54.293175   636 sgd_solver.cpp:105] Iteration 169200, lr = 0.0001
I1016 23:22:03.426472   636 solver.cpp:218] Iteration 169300 (10.9515 iter/s, 9.13118s/100 iters), loss = 0.00287304
I1016 23:22:03.426472   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:22:03.426472   636 solver.cpp:237]     Train net output #1: loss = 0.00287282 (* 1 = 0.00287282 loss)
I1016 23:22:03.426472   636 sgd_solver.cpp:105] Iteration 169300, lr = 0.0001
I1016 23:22:12.551319   636 solver.cpp:218] Iteration 169400 (10.9529 iter/s, 9.12999s/100 iters), loss = 0.00133852
I1016 23:22:12.551319   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:22:12.551319   636 solver.cpp:237]     Train net output #1: loss = 0.00133829 (* 1 = 0.00133829 loss)
I1016 23:22:12.551319   636 sgd_solver.cpp:105] Iteration 169400, lr = 0.0001
I1016 23:22:21.237993  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:22:21.596917   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_169500.caffemodel
I1016 23:22:21.626925   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_169500.solverstate
I1016 23:22:21.636922   636 solver.cpp:330] Iteration 169500, Testing net (#0)
I1016 23:22:21.636922   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:22:23.887197  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:22:23.987185   636 solver.cpp:397]     Test net output #0: accuracy = 0.9461
I1016 23:22:23.987185   636 solver.cpp:397]     Test net output #1: loss = 0.206177 (* 1 = 0.206177 loss)
I1016 23:22:24.076666   636 solver.cpp:218] Iteration 169500 (8.68239 iter/s, 11.5176s/100 iters), loss = 0.000820062
I1016 23:22:24.076798   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:22:24.076798   636 solver.cpp:237]     Train net output #1: loss = 0.000819836 (* 1 = 0.000819836 loss)
I1016 23:22:24.076798   636 sgd_solver.cpp:105] Iteration 169500, lr = 0.0001
I1016 23:22:33.210963   636 solver.cpp:218] Iteration 169600 (10.9481 iter/s, 9.134s/100 iters), loss = 0.00147593
I1016 23:22:33.210963   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:22:33.210963   636 solver.cpp:237]     Train net output #1: loss = 0.0014757 (* 1 = 0.0014757 loss)
I1016 23:22:33.210963   636 sgd_solver.cpp:105] Iteration 169600, lr = 0.0001
I1016 23:22:42.337788   636 solver.cpp:218] Iteration 169700 (10.9482 iter/s, 9.13388s/100 iters), loss = 0.00200374
I1016 23:22:42.337788   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:22:42.337788   636 solver.cpp:237]     Train net output #1: loss = 0.00200352 (* 1 = 0.00200352 loss)
I1016 23:22:42.337788   636 sgd_solver.cpp:105] Iteration 169700, lr = 0.0001
I1016 23:22:51.470115   636 solver.cpp:218] Iteration 169800 (10.9502 iter/s, 9.13222s/100 iters), loss = 0.0012317
I1016 23:22:51.470115   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:22:51.470115   636 solver.cpp:237]     Train net output #1: loss = 0.00123147 (* 1 = 0.00123147 loss)
I1016 23:22:51.470115   636 sgd_solver.cpp:105] Iteration 169800, lr = 0.0001
I1016 23:23:00.605270   636 solver.cpp:218] Iteration 169900 (10.9505 iter/s, 9.132s/100 iters), loss = 0.0016441
I1016 23:23:00.605270   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:23:00.605270   636 solver.cpp:237]     Train net output #1: loss = 0.00164387 (* 1 = 0.00164387 loss)
I1016 23:23:00.605270   636 sgd_solver.cpp:105] Iteration 169900, lr = 0.0001
I1016 23:23:09.289290  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:23:09.649633   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_170000.caffemodel
I1016 23:23:09.679646   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_170000.solverstate
I1016 23:23:09.689644   636 solver.cpp:330] Iteration 170000, Testing net (#0)
I1016 23:23:09.689644   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:23:11.950732  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:23:12.042749   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 23:23:12.042749   636 solver.cpp:397]     Test net output #1: loss = 0.206262 (* 1 = 0.206262 loss)
I1016 23:23:12.130760   636 solver.cpp:218] Iteration 170000 (8.68057 iter/s, 11.52s/100 iters), loss = 0.00100226
I1016 23:23:12.130760   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:23:12.130760   636 solver.cpp:237]     Train net output #1: loss = 0.00100204 (* 1 = 0.00100204 loss)
I1016 23:23:12.130760   636 sgd_solver.cpp:105] Iteration 170000, lr = 0.0001
I1016 23:23:21.253104   636 solver.cpp:218] Iteration 170100 (10.9535 iter/s, 9.12948s/100 iters), loss = 0.00276207
I1016 23:23:21.253104   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:23:21.253104   636 solver.cpp:237]     Train net output #1: loss = 0.00276184 (* 1 = 0.00276184 loss)
I1016 23:23:21.253104   636 sgd_solver.cpp:105] Iteration 170100, lr = 0.0001
I1016 23:23:30.385459   636 solver.cpp:218] Iteration 170200 (10.9608 iter/s, 9.12342s/100 iters), loss = 0.00375197
I1016 23:23:30.385459   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:23:30.385459   636 solver.cpp:237]     Train net output #1: loss = 0.00375175 (* 1 = 0.00375175 loss)
I1016 23:23:30.385459   636 sgd_solver.cpp:105] Iteration 170200, lr = 0.0001
I1016 23:23:39.515977   636 solver.cpp:218] Iteration 170300 (10.9513 iter/s, 9.1313s/100 iters), loss = 0.00134032
I1016 23:23:39.515977   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:23:39.515977   636 solver.cpp:237]     Train net output #1: loss = 0.00134009 (* 1 = 0.00134009 loss)
I1016 23:23:39.515977   636 sgd_solver.cpp:105] Iteration 170300, lr = 0.0001
I1016 23:23:48.639961   636 solver.cpp:218] Iteration 170400 (10.9528 iter/s, 9.13005s/100 iters), loss = 0.00124363
I1016 23:23:48.639961   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:23:48.639961   636 solver.cpp:237]     Train net output #1: loss = 0.0012434 (* 1 = 0.0012434 loss)
I1016 23:23:48.639961   636 sgd_solver.cpp:105] Iteration 170400, lr = 0.0001
I1016 23:23:57.328030  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:23:57.690346   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_170500.caffemodel
I1016 23:23:57.713361   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_170500.solverstate
I1016 23:23:57.723356   636 solver.cpp:330] Iteration 170500, Testing net (#0)
I1016 23:23:57.723356   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:23:59.988680  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:24:00.074697   636 solver.cpp:397]     Test net output #0: accuracy = 0.9458
I1016 23:24:00.074697   636 solver.cpp:397]     Test net output #1: loss = 0.206197 (* 1 = 0.206197 loss)
I1016 23:24:00.164716   636 solver.cpp:218] Iteration 170500 (8.68044 iter/s, 11.5202s/100 iters), loss = 0.00188536
I1016 23:24:00.164716   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:00.164716   636 solver.cpp:237]     Train net output #1: loss = 0.00188513 (* 1 = 0.00188513 loss)
I1016 23:24:00.164716   636 sgd_solver.cpp:105] Iteration 170500, lr = 0.0001
I1016 23:24:09.298780   636 solver.cpp:218] Iteration 170600 (10.9535 iter/s, 9.12949s/100 iters), loss = 0.00180872
I1016 23:24:09.298780   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:09.298780   636 solver.cpp:237]     Train net output #1: loss = 0.0018085 (* 1 = 0.0018085 loss)
I1016 23:24:09.298780   636 sgd_solver.cpp:105] Iteration 170600, lr = 0.0001
I1016 23:24:18.424588   636 solver.cpp:218] Iteration 170700 (10.9479 iter/s, 9.13418s/100 iters), loss = 0.00180406
I1016 23:24:18.424588   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:18.424588   636 solver.cpp:237]     Train net output #1: loss = 0.00180384 (* 1 = 0.00180384 loss)
I1016 23:24:18.424588   636 sgd_solver.cpp:105] Iteration 170700, lr = 0.0001
I1016 23:24:27.561166   636 solver.cpp:218] Iteration 170800 (10.955 iter/s, 9.12826s/100 iters), loss = 0.00147116
I1016 23:24:27.561166   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:27.561166   636 solver.cpp:237]     Train net output #1: loss = 0.00147093 (* 1 = 0.00147093 loss)
I1016 23:24:27.561166   636 sgd_solver.cpp:105] Iteration 170800, lr = 0.0001
I1016 23:24:36.689478   636 solver.cpp:218] Iteration 170900 (10.9511 iter/s, 9.13152s/100 iters), loss = 0.000958155
I1016 23:24:36.689478   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:36.689478   636 solver.cpp:237]     Train net output #1: loss = 0.000957928 (* 1 = 0.000957928 loss)
I1016 23:24:36.689478   636 sgd_solver.cpp:105] Iteration 170900, lr = 0.0001
I1016 23:24:45.377218  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:24:45.736340   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_171000.caffemodel
I1016 23:24:45.766345   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_171000.solverstate
I1016 23:24:45.776363   636 solver.cpp:330] Iteration 171000, Testing net (#0)
I1016 23:24:45.776363   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:24:48.038149  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:24:48.128166   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 23:24:48.128166   636 solver.cpp:397]     Test net output #1: loss = 0.206355 (* 1 = 0.206355 loss)
I1016 23:24:48.218170   636 solver.cpp:218] Iteration 171000 (8.67598 iter/s, 11.5261s/100 iters), loss = 0.00228915
I1016 23:24:48.218170   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:48.218170   636 solver.cpp:237]     Train net output #1: loss = 0.00228892 (* 1 = 0.00228892 loss)
I1016 23:24:48.218170   636 sgd_solver.cpp:105] Iteration 171000, lr = 0.0001
I1016 23:24:57.355497   636 solver.cpp:218] Iteration 171100 (10.9431 iter/s, 9.13819s/100 iters), loss = 0.00146986
I1016 23:24:57.355497   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:24:57.355497   636 solver.cpp:237]     Train net output #1: loss = 0.00146964 (* 1 = 0.00146964 loss)
I1016 23:24:57.355497   636 sgd_solver.cpp:105] Iteration 171100, lr = 0.0001
I1016 23:25:06.496299   636 solver.cpp:218] Iteration 171200 (10.9396 iter/s, 9.14112s/100 iters), loss = 0.00297105
I1016 23:25:06.496299   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:25:06.496299   636 solver.cpp:237]     Train net output #1: loss = 0.00297083 (* 1 = 0.00297083 loss)
I1016 23:25:06.496299   636 sgd_solver.cpp:105] Iteration 171200, lr = 0.0001
I1016 23:25:15.836138   636 solver.cpp:218] Iteration 171300 (10.7134 iter/s, 9.33407s/100 iters), loss = 0.00174585
I1016 23:25:15.836138   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:25:15.836138   636 solver.cpp:237]     Train net output #1: loss = 0.00174562 (* 1 = 0.00174562 loss)
I1016 23:25:15.836138   636 sgd_solver.cpp:105] Iteration 171300, lr = 0.0001
I1016 23:25:25.103746   636 solver.cpp:218] Iteration 171400 (10.782 iter/s, 9.27475s/100 iters), loss = 0.00129767
I1016 23:25:25.103746   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:25:25.103746   636 solver.cpp:237]     Train net output #1: loss = 0.00129744 (* 1 = 0.00129744 loss)
I1016 23:25:25.103746   636 sgd_solver.cpp:105] Iteration 171400, lr = 0.0001
I1016 23:25:33.798990  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:25:34.168928   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_171500.caffemodel
I1016 23:25:34.198930   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_171500.solverstate
I1016 23:25:34.208930   636 solver.cpp:330] Iteration 171500, Testing net (#0)
I1016 23:25:34.208930   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:25:36.471302  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:25:36.561336   636 solver.cpp:397]     Test net output #0: accuracy = 0.9459
I1016 23:25:36.561336   636 solver.cpp:397]     Test net output #1: loss = 0.20638 (* 1 = 0.20638 loss)
I1016 23:25:36.650842   636 solver.cpp:218] Iteration 171500 (8.66409 iter/s, 11.5419s/100 iters), loss = 0.0012607
I1016 23:25:36.650842   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:25:36.650842   636 solver.cpp:237]     Train net output #1: loss = 0.00126048 (* 1 = 0.00126048 loss)
I1016 23:25:36.650842   636 sgd_solver.cpp:105] Iteration 171500, lr = 0.0001
I1016 23:25:45.788275   636 solver.cpp:218] Iteration 171600 (10.9444 iter/s, 9.13705s/100 iters), loss = 0.00246592
I1016 23:25:45.788275   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:25:45.788275   636 solver.cpp:237]     Train net output #1: loss = 0.00246569 (* 1 = 0.00246569 loss)
I1016 23:25:45.788275   636 sgd_solver.cpp:105] Iteration 171600, lr = 0.0001
I1016 23:25:54.929339   636 solver.cpp:218] Iteration 171700 (10.9384 iter/s, 9.14214s/100 iters), loss = 0.00357946
I1016 23:25:54.929339   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:25:54.929339   636 solver.cpp:237]     Train net output #1: loss = 0.00357923 (* 1 = 0.00357923 loss)
I1016 23:25:54.929339   636 sgd_solver.cpp:105] Iteration 171700, lr = 0.0001
I1016 23:26:04.075155   636 solver.cpp:218] Iteration 171800 (10.9379 iter/s, 9.14252s/100 iters), loss = 0.00239916
I1016 23:26:04.075155   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:26:04.075155   636 solver.cpp:237]     Train net output #1: loss = 0.00239893 (* 1 = 0.00239893 loss)
I1016 23:26:04.075155   636 sgd_solver.cpp:105] Iteration 171800, lr = 0.0001
I1016 23:26:13.217962   636 solver.cpp:218] Iteration 171900 (10.9392 iter/s, 9.14144s/100 iters), loss = 0.00141419
I1016 23:26:13.217962   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:26:13.217962   636 solver.cpp:237]     Train net output #1: loss = 0.00141397 (* 1 = 0.00141397 loss)
I1016 23:26:13.217962   636 sgd_solver.cpp:105] Iteration 171900, lr = 0.0001
I1016 23:26:21.912164  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:26:22.278950   636 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/snaps/slimnet_1M__iter_172000.caffemodel
I1016 23:26:22.298946   636 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/snaps/slimnet_1M__iter_172000.solverstate
I1016 23:26:22.308945   636 solver.cpp:330] Iteration 172000, Testing net (#0)
I1016 23:26:22.308945   636 net.cpp:676] Ignoring source layer accuracy_training
I1016 23:26:24.573814  8920 data_layer.cpp:73] Restarting data prefetching from start.
I1016 23:26:24.663827   636 solver.cpp:397]     Test net output #0: accuracy = 0.9456
I1016 23:26:24.663827   636 solver.cpp:397]     Test net output #1: loss = 0.206534 (* 1 = 0.206534 loss)
I1016 23:26:24.753835   636 solver.cpp:218] Iteration 172000 (8.66678 iter/s, 11.5383s/100 iters), loss = 0.00231104
I1016 23:26:24.753835   636 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1016 23:26:24.753835   636 solver.cpp:237]     Train net output #1: loss = 0.00231082 (* 1 = 0.00231082 loss)
I1016 23:26:24.753835   636 sgd_solver.cpp:105] Iteration 172000, lr = 0.0001
I1016 23:26:33.889370   636 solver.cpp:218] Iteration 172100 (10.9429 iter/s, 9.13837s/100 iters), loss = 0.00110692
I1016 23:26:33.889370   636 solver.cpp:237]     Train net output #0: accuracy_t