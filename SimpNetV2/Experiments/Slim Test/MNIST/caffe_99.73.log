
G:\Caffe\examples\mnist>REM going to the caffe root 

G:\Caffe\examples\mnist>CD ../../ 

G:\Caffe>SET TOOLS=Build/x64/Release 

G:\Caffe>"Build/x64/Release/caffe.exe" train --solver=examples/mnist/lenet_solver.prototxt 
I1021 16:54:25.564915 14900 caffe.cpp:219] Using GPUs 0
I1021 16:54:25.761458 14900 caffe.cpp:224] GPU 0: GeForce GTX 1080
I1021 16:54:26.063894 14900 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1021 16:54:26.078894 14900 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 600
base_lr: 0.1
display: 100
max_iter: 37000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.003
snapshot: 600
snapshot_prefix: "examples/mnist/snaps/mnist_slimnet_300k_"
solver_mode: GPU
device_id: 0
random_seed: 786
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 5000
stepvalue: 9500
stepvalue: 22000
stepvalue: 29600
stepvalue: 32000
stepvalue: 37000
type: "AdaDelta"
I1021 16:54:26.079895 14900 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1021 16:54:26.079895 14900 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/mnist/lenet_train_test.prototxt
I1021 16:54:26.079895 14900 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3_1
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv11
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_conv12
I1021 16:54:26.079895 14900 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1021 16:54:26.080895 14900 net.cpp:51] Initializing net from parameters: 
name: "MNIST_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_maxdrp_300k"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb_norm2"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "pool4_2"
  top: "pool4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "drop12"
  type: "Dropout"
  bottom: "poolcp6"
  top: "poolcp6"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1021 16:54:26.100930 14900 layer_factory.cpp:58] Creating layer mnist
I1021 16:54:26.106909 14900 db_lmdb.cpp:40] Opened lmdb examples/mnist/mnist_train_lmdb_norm2
I1021 16:54:26.106909 14900 net.cpp:84] Creating Layer mnist
I1021 16:54:26.106909 14900 net.cpp:380] mnist -> data
I1021 16:54:26.106909 14900 net.cpp:380] mnist -> label
I1021 16:54:26.107909 14900 data_layer.cpp:45] output data size: 100,1,28,28
I1021 16:54:26.110905 14900 net.cpp:122] Setting up mnist
I1021 16:54:26.110905 14900 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1021 16:54:26.110905 14900 net.cpp:129] Top shape: 100 (100)
I1021 16:54:26.110905 14900 net.cpp:137] Memory required for data: 314000
I1021 16:54:26.110905 14900 layer_factory.cpp:58] Creating layer label_mnist_1_split
I1021 16:54:26.110905 14900 net.cpp:84] Creating Layer label_mnist_1_split
I1021 16:54:26.110905 14900 net.cpp:406] label_mnist_1_split <- label
I1021 16:54:26.110905 14900 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1021 16:54:26.110905 14900 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1021 16:54:26.110905 14900 net.cpp:122] Setting up label_mnist_1_split
I1021 16:54:26.110905 14900 net.cpp:129] Top shape: 100 (100)
I1021 16:54:26.110905 14900 net.cpp:129] Top shape: 100 (100)
I1021 16:54:26.110905 14900 net.cpp:137] Memory required for data: 314800
I1021 16:54:26.110905 14900 layer_factory.cpp:58] Creating layer conv1
I1021 16:54:26.110905 14900 net.cpp:84] Creating Layer conv1
I1021 16:54:26.110905 14900 net.cpp:406] conv1 <- data
I1021 16:54:26.110905 14900 net.cpp:380] conv1 -> conv1
I1021 16:54:26.111899  2868 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1021 16:54:26.361517 14900 net.cpp:122] Setting up conv1
I1021 16:54:26.361517 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.361517 14900 net.cpp:137] Memory required for data: 9722800
I1021 16:54:26.361517 14900 layer_factory.cpp:58] Creating layer bn1
I1021 16:54:26.361517 14900 net.cpp:84] Creating Layer bn1
I1021 16:54:26.361517 14900 net.cpp:406] bn1 <- conv1
I1021 16:54:26.361517 14900 net.cpp:367] bn1 -> conv1 (in-place)
I1021 16:54:26.362016 14900 net.cpp:122] Setting up bn1
I1021 16:54:26.362016 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.362016 14900 net.cpp:137] Memory required for data: 19130800
I1021 16:54:26.362016 14900 layer_factory.cpp:58] Creating layer scale1
I1021 16:54:26.362016 14900 net.cpp:84] Creating Layer scale1
I1021 16:54:26.362016 14900 net.cpp:406] scale1 <- conv1
I1021 16:54:26.362016 14900 net.cpp:367] scale1 -> conv1 (in-place)
I1021 16:54:26.362016 14900 layer_factory.cpp:58] Creating layer scale1
I1021 16:54:26.362016 14900 net.cpp:122] Setting up scale1
I1021 16:54:26.362016 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.362016 14900 net.cpp:137] Memory required for data: 28538800
I1021 16:54:26.362016 14900 layer_factory.cpp:58] Creating layer relu1
I1021 16:54:26.362016 14900 net.cpp:84] Creating Layer relu1
I1021 16:54:26.362016 14900 net.cpp:406] relu1 <- conv1
I1021 16:54:26.362016 14900 net.cpp:367] relu1 -> conv1 (in-place)
I1021 16:54:26.362016 14900 net.cpp:122] Setting up relu1
I1021 16:54:26.362016 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.362016 14900 net.cpp:137] Memory required for data: 37946800
I1021 16:54:26.362016 14900 layer_factory.cpp:58] Creating layer conv1_0
I1021 16:54:26.362016 14900 net.cpp:84] Creating Layer conv1_0
I1021 16:54:26.362016 14900 net.cpp:406] conv1_0 <- conv1
I1021 16:54:26.362516 14900 net.cpp:380] conv1_0 -> conv1_0
I1021 16:54:26.364019 14900 net.cpp:122] Setting up conv1_0
I1021 16:54:26.364019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.364019 14900 net.cpp:137] Memory required for data: 50490800
I1021 16:54:26.364019 14900 layer_factory.cpp:58] Creating layer bn1_0
I1021 16:54:26.364019 14900 net.cpp:84] Creating Layer bn1_0
I1021 16:54:26.364019 14900 net.cpp:406] bn1_0 <- conv1_0
I1021 16:54:26.364019 14900 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1021 16:54:26.364019 14900 net.cpp:122] Setting up bn1_0
I1021 16:54:26.364019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.364019 14900 net.cpp:137] Memory required for data: 63034800
I1021 16:54:26.364019 14900 layer_factory.cpp:58] Creating layer scale1_0
I1021 16:54:26.364019 14900 net.cpp:84] Creating Layer scale1_0
I1021 16:54:26.364019 14900 net.cpp:406] scale1_0 <- conv1_0
I1021 16:54:26.364019 14900 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1021 16:54:26.364019 14900 layer_factory.cpp:58] Creating layer scale1_0
I1021 16:54:26.364019 14900 net.cpp:122] Setting up scale1_0
I1021 16:54:26.364019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.364019 14900 net.cpp:137] Memory required for data: 75578800
I1021 16:54:26.364019 14900 layer_factory.cpp:58] Creating layer relu1_0
I1021 16:54:26.364019 14900 net.cpp:84] Creating Layer relu1_0
I1021 16:54:26.364019 14900 net.cpp:406] relu1_0 <- conv1_0
I1021 16:54:26.364019 14900 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1021 16:54:26.365020 14900 net.cpp:122] Setting up relu1_0
I1021 16:54:26.365020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.365020 14900 net.cpp:137] Memory required for data: 88122800
I1021 16:54:26.365020 14900 layer_factory.cpp:58] Creating layer conv2
I1021 16:54:26.365020 14900 net.cpp:84] Creating Layer conv2
I1021 16:54:26.365020 14900 net.cpp:406] conv2 <- conv1_0
I1021 16:54:26.365020 14900 net.cpp:380] conv2 -> conv2
I1021 16:54:26.365020 14900 net.cpp:122] Setting up conv2
I1021 16:54:26.366019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.366019 14900 net.cpp:137] Memory required for data: 100666800
I1021 16:54:26.366019 14900 layer_factory.cpp:58] Creating layer bn2
I1021 16:54:26.366019 14900 net.cpp:84] Creating Layer bn2
I1021 16:54:26.366019 14900 net.cpp:406] bn2 <- conv2
I1021 16:54:26.366019 14900 net.cpp:367] bn2 -> conv2 (in-place)
I1021 16:54:26.366019 14900 net.cpp:122] Setting up bn2
I1021 16:54:26.366019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.366019 14900 net.cpp:137] Memory required for data: 113210800
I1021 16:54:26.366019 14900 layer_factory.cpp:58] Creating layer scale2
I1021 16:54:26.366019 14900 net.cpp:84] Creating Layer scale2
I1021 16:54:26.366019 14900 net.cpp:406] scale2 <- conv2
I1021 16:54:26.366019 14900 net.cpp:367] scale2 -> conv2 (in-place)
I1021 16:54:26.366019 14900 layer_factory.cpp:58] Creating layer scale2
I1021 16:54:26.366019 14900 net.cpp:122] Setting up scale2
I1021 16:54:26.366019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.366019 14900 net.cpp:137] Memory required for data: 125754800
I1021 16:54:26.366019 14900 layer_factory.cpp:58] Creating layer relu2
I1021 16:54:26.366019 14900 net.cpp:84] Creating Layer relu2
I1021 16:54:26.366019 14900 net.cpp:406] relu2 <- conv2
I1021 16:54:26.366019 14900 net.cpp:367] relu2 -> conv2 (in-place)
I1021 16:54:26.366019 14900 net.cpp:122] Setting up relu2
I1021 16:54:26.366019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.366019 14900 net.cpp:137] Memory required for data: 138298800
I1021 16:54:26.366019 14900 layer_factory.cpp:58] Creating layer conv2_1
I1021 16:54:26.366019 14900 net.cpp:84] Creating Layer conv2_1
I1021 16:54:26.366019 14900 net.cpp:406] conv2_1 <- conv2
I1021 16:54:26.366019 14900 net.cpp:380] conv2_1 -> conv2_1
I1021 16:54:26.368021 14900 net.cpp:122] Setting up conv2_1
I1021 16:54:26.368021 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.368021 14900 net.cpp:137] Memory required for data: 150842800
I1021 16:54:26.368021 14900 layer_factory.cpp:58] Creating layer bn2_1
I1021 16:54:26.368021 14900 net.cpp:84] Creating Layer bn2_1
I1021 16:54:26.368021 14900 net.cpp:406] bn2_1 <- conv2_1
I1021 16:54:26.368021 14900 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1021 16:54:26.368021 14900 net.cpp:122] Setting up bn2_1
I1021 16:54:26.368021 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.368021 14900 net.cpp:137] Memory required for data: 163386800
I1021 16:54:26.368021 14900 layer_factory.cpp:58] Creating layer scale2_1
I1021 16:54:26.368021 14900 net.cpp:84] Creating Layer scale2_1
I1021 16:54:26.368021 14900 net.cpp:406] scale2_1 <- conv2_1
I1021 16:54:26.368021 14900 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1021 16:54:26.368021 14900 layer_factory.cpp:58] Creating layer scale2_1
I1021 16:54:26.368021 14900 net.cpp:122] Setting up scale2_1
I1021 16:54:26.368021 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.368021 14900 net.cpp:137] Memory required for data: 175930800
I1021 16:54:26.368021 14900 layer_factory.cpp:58] Creating layer relu2_1
I1021 16:54:26.368021 14900 net.cpp:84] Creating Layer relu2_1
I1021 16:54:26.368021 14900 net.cpp:406] relu2_1 <- conv2_1
I1021 16:54:26.368021 14900 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1021 16:54:26.368021 14900 net.cpp:122] Setting up relu2_1
I1021 16:54:26.368021 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.368021 14900 net.cpp:137] Memory required for data: 188474800
I1021 16:54:26.368021 14900 layer_factory.cpp:58] Creating layer conv2_2
I1021 16:54:26.368021 14900 net.cpp:84] Creating Layer conv2_2
I1021 16:54:26.368021 14900 net.cpp:406] conv2_2 <- conv2_1
I1021 16:54:26.368021 14900 net.cpp:380] conv2_2 -> conv2_2
I1021 16:54:26.370020 14900 net.cpp:122] Setting up conv2_2
I1021 16:54:26.370020 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.370020 14900 net.cpp:137] Memory required for data: 204154800
I1021 16:54:26.370020 14900 layer_factory.cpp:58] Creating layer bn2_2
I1021 16:54:26.370020 14900 net.cpp:84] Creating Layer bn2_2
I1021 16:54:26.370020 14900 net.cpp:406] bn2_2 <- conv2_2
I1021 16:54:26.370020 14900 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1021 16:54:26.370020 14900 net.cpp:122] Setting up bn2_2
I1021 16:54:26.370020 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.370020 14900 net.cpp:137] Memory required for data: 219834800
I1021 16:54:26.370020 14900 layer_factory.cpp:58] Creating layer scale2_2
I1021 16:54:26.370020 14900 net.cpp:84] Creating Layer scale2_2
I1021 16:54:26.370020 14900 net.cpp:406] scale2_2 <- conv2_2
I1021 16:54:26.370020 14900 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1021 16:54:26.370020 14900 layer_factory.cpp:58] Creating layer scale2_2
I1021 16:54:26.370020 14900 net.cpp:122] Setting up scale2_2
I1021 16:54:26.370020 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.370020 14900 net.cpp:137] Memory required for data: 235514800
I1021 16:54:26.370020 14900 layer_factory.cpp:58] Creating layer relu2_2
I1021 16:54:26.370020 14900 net.cpp:84] Creating Layer relu2_2
I1021 16:54:26.370020 14900 net.cpp:406] relu2_2 <- conv2_2
I1021 16:54:26.371021 14900 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1021 16:54:26.371021 14900 net.cpp:122] Setting up relu2_2
I1021 16:54:26.371021 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.371021 14900 net.cpp:137] Memory required for data: 251194800
I1021 16:54:26.371021 14900 layer_factory.cpp:58] Creating layer pool2_1
I1021 16:54:26.371021 14900 net.cpp:84] Creating Layer pool2_1
I1021 16:54:26.371021 14900 net.cpp:406] pool2_1 <- conv2_2
I1021 16:54:26.371021 14900 net.cpp:380] pool2_1 -> pool2_1
I1021 16:54:26.371021 14900 net.cpp:122] Setting up pool2_1
I1021 16:54:26.371021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.371021 14900 net.cpp:137] Memory required for data: 255114800
I1021 16:54:26.371021 14900 layer_factory.cpp:58] Creating layer drop5
I1021 16:54:26.371021 14900 net.cpp:84] Creating Layer drop5
I1021 16:54:26.371021 14900 net.cpp:406] drop5 <- pool2_1
I1021 16:54:26.371021 14900 net.cpp:367] drop5 -> pool2_1 (in-place)
I1021 16:54:26.371021 14900 net.cpp:122] Setting up drop5
I1021 16:54:26.371021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.371021 14900 net.cpp:137] Memory required for data: 259034800
I1021 16:54:26.371021 14900 layer_factory.cpp:58] Creating layer conv3
I1021 16:54:26.371021 14900 net.cpp:84] Creating Layer conv3
I1021 16:54:26.371021 14900 net.cpp:406] conv3 <- pool2_1
I1021 16:54:26.371021 14900 net.cpp:380] conv3 -> conv3
I1021 16:54:26.372020 14900 net.cpp:122] Setting up conv3
I1021 16:54:26.372020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.372020 14900 net.cpp:137] Memory required for data: 262954800
I1021 16:54:26.372020 14900 layer_factory.cpp:58] Creating layer bn3
I1021 16:54:26.372020 14900 net.cpp:84] Creating Layer bn3
I1021 16:54:26.372020 14900 net.cpp:406] bn3 <- conv3
I1021 16:54:26.372020 14900 net.cpp:367] bn3 -> conv3 (in-place)
I1021 16:54:26.372020 14900 net.cpp:122] Setting up bn3
I1021 16:54:26.372020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.372020 14900 net.cpp:137] Memory required for data: 266874800
I1021 16:54:26.372020 14900 layer_factory.cpp:58] Creating layer scale3
I1021 16:54:26.372020 14900 net.cpp:84] Creating Layer scale3
I1021 16:54:26.372020 14900 net.cpp:406] scale3 <- conv3
I1021 16:54:26.372020 14900 net.cpp:367] scale3 -> conv3 (in-place)
I1021 16:54:26.372020 14900 layer_factory.cpp:58] Creating layer scale3
I1021 16:54:26.372020 14900 net.cpp:122] Setting up scale3
I1021 16:54:26.372020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.372020 14900 net.cpp:137] Memory required for data: 270794800
I1021 16:54:26.372020 14900 layer_factory.cpp:58] Creating layer relu3
I1021 16:54:26.372020 14900 net.cpp:84] Creating Layer relu3
I1021 16:54:26.372020 14900 net.cpp:406] relu3 <- conv3
I1021 16:54:26.372020 14900 net.cpp:367] relu3 -> conv3 (in-place)
I1021 16:54:26.373019 14900 net.cpp:122] Setting up relu3
I1021 16:54:26.373019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.373019 14900 net.cpp:137] Memory required for data: 274714800
I1021 16:54:26.373019 14900 layer_factory.cpp:58] Creating layer conv3_1
I1021 16:54:26.373019 14900 net.cpp:84] Creating Layer conv3_1
I1021 16:54:26.373019 14900 net.cpp:406] conv3_1 <- conv3
I1021 16:54:26.373019 14900 net.cpp:380] conv3_1 -> conv3_1
I1021 16:54:26.374019 14900 net.cpp:122] Setting up conv3_1
I1021 16:54:26.374019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.374019 14900 net.cpp:137] Memory required for data: 278634800
I1021 16:54:26.374019 14900 layer_factory.cpp:58] Creating layer bn3_1
I1021 16:54:26.374019 14900 net.cpp:84] Creating Layer bn3_1
I1021 16:54:26.374019 14900 net.cpp:406] bn3_1 <- conv3_1
I1021 16:54:26.374019 14900 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1021 16:54:26.374019 14900 net.cpp:122] Setting up bn3_1
I1021 16:54:26.374019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.374019 14900 net.cpp:137] Memory required for data: 282554800
I1021 16:54:26.374019 14900 layer_factory.cpp:58] Creating layer scale3_1
I1021 16:54:26.374019 14900 net.cpp:84] Creating Layer scale3_1
I1021 16:54:26.374019 14900 net.cpp:406] scale3_1 <- conv3_1
I1021 16:54:26.374019 14900 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1021 16:54:26.374019 14900 layer_factory.cpp:58] Creating layer scale3_1
I1021 16:54:26.375020 14900 net.cpp:122] Setting up scale3_1
I1021 16:54:26.375020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.375020 14900 net.cpp:137] Memory required for data: 286474800
I1021 16:54:26.375020 14900 layer_factory.cpp:58] Creating layer relu3_1
I1021 16:54:26.375020 14900 net.cpp:84] Creating Layer relu3_1
I1021 16:54:26.375020 14900 net.cpp:406] relu3_1 <- conv3_1
I1021 16:54:26.375020 14900 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1021 16:54:26.375020 14900 net.cpp:122] Setting up relu3_1
I1021 16:54:26.375020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.375020 14900 net.cpp:137] Memory required for data: 290394800
I1021 16:54:26.375020 14900 layer_factory.cpp:58] Creating layer conv4
I1021 16:54:26.375020 14900 net.cpp:84] Creating Layer conv4
I1021 16:54:26.375020 14900 net.cpp:406] conv4 <- conv3_1
I1021 16:54:26.375020 14900 net.cpp:380] conv4 -> conv4
I1021 16:54:26.376020 14900 net.cpp:122] Setting up conv4
I1021 16:54:26.376020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.376020 14900 net.cpp:137] Memory required for data: 294314800
I1021 16:54:26.376020 14900 layer_factory.cpp:58] Creating layer bn4
I1021 16:54:26.376020 14900 net.cpp:84] Creating Layer bn4
I1021 16:54:26.376020 14900 net.cpp:406] bn4 <- conv4
I1021 16:54:26.376020 14900 net.cpp:367] bn4 -> conv4 (in-place)
I1021 16:54:26.376020 14900 net.cpp:122] Setting up bn4
I1021 16:54:26.376020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.376020 14900 net.cpp:137] Memory required for data: 298234800
I1021 16:54:26.376020 14900 layer_factory.cpp:58] Creating layer scale4
I1021 16:54:26.376020 14900 net.cpp:84] Creating Layer scale4
I1021 16:54:26.376020 14900 net.cpp:406] scale4 <- conv4
I1021 16:54:26.376020 14900 net.cpp:367] scale4 -> conv4 (in-place)
I1021 16:54:26.376020 14900 layer_factory.cpp:58] Creating layer scale4
I1021 16:54:26.376020 14900 net.cpp:122] Setting up scale4
I1021 16:54:26.376020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.376020 14900 net.cpp:137] Memory required for data: 302154800
I1021 16:54:26.376020 14900 layer_factory.cpp:58] Creating layer relu4
I1021 16:54:26.376020 14900 net.cpp:84] Creating Layer relu4
I1021 16:54:26.376020 14900 net.cpp:406] relu4 <- conv4
I1021 16:54:26.376020 14900 net.cpp:367] relu4 -> conv4 (in-place)
I1021 16:54:26.377020 14900 net.cpp:122] Setting up relu4
I1021 16:54:26.377020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.377020 14900 net.cpp:137] Memory required for data: 306074800
I1021 16:54:26.377020 14900 layer_factory.cpp:58] Creating layer conv4_1
I1021 16:54:26.377020 14900 net.cpp:84] Creating Layer conv4_1
I1021 16:54:26.377020 14900 net.cpp:406] conv4_1 <- conv4
I1021 16:54:26.377020 14900 net.cpp:380] conv4_1 -> conv4_1
I1021 16:54:26.378020 14900 net.cpp:122] Setting up conv4_1
I1021 16:54:26.378020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.378020 14900 net.cpp:137] Memory required for data: 309994800
I1021 16:54:26.378020 14900 layer_factory.cpp:58] Creating layer bn4_1
I1021 16:54:26.378020 14900 net.cpp:84] Creating Layer bn4_1
I1021 16:54:26.378020 14900 net.cpp:406] bn4_1 <- conv4_1
I1021 16:54:26.378020 14900 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1021 16:54:26.378020 14900 net.cpp:122] Setting up bn4_1
I1021 16:54:26.378020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.378020 14900 net.cpp:137] Memory required for data: 313914800
I1021 16:54:26.378020 14900 layer_factory.cpp:58] Creating layer scale4_1
I1021 16:54:26.378020 14900 net.cpp:84] Creating Layer scale4_1
I1021 16:54:26.378020 14900 net.cpp:406] scale4_1 <- conv4_1
I1021 16:54:26.378020 14900 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1021 16:54:26.378020 14900 layer_factory.cpp:58] Creating layer scale4_1
I1021 16:54:26.378020 14900 net.cpp:122] Setting up scale4_1
I1021 16:54:26.378020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.378020 14900 net.cpp:137] Memory required for data: 317834800
I1021 16:54:26.378020 14900 layer_factory.cpp:58] Creating layer relu4_1
I1021 16:54:26.378020 14900 net.cpp:84] Creating Layer relu4_1
I1021 16:54:26.378020 14900 net.cpp:406] relu4_1 <- conv4_1
I1021 16:54:26.378020 14900 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1021 16:54:26.379019 14900 net.cpp:122] Setting up relu4_1
I1021 16:54:26.379019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.379019 14900 net.cpp:137] Memory required for data: 321754800
I1021 16:54:26.379019 14900 layer_factory.cpp:58] Creating layer conv4_2
I1021 16:54:26.379019 14900 net.cpp:84] Creating Layer conv4_2
I1021 16:54:26.379019 14900 net.cpp:406] conv4_2 <- conv4_1
I1021 16:54:26.379019 14900 net.cpp:380] conv4_2 -> conv4_2
I1021 16:54:26.380020 14900 net.cpp:122] Setting up conv4_2
I1021 16:54:26.380020 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.380020 14900 net.cpp:137] Memory required for data: 326302000
I1021 16:54:26.380020 14900 layer_factory.cpp:58] Creating layer bn4_2
I1021 16:54:26.380020 14900 net.cpp:84] Creating Layer bn4_2
I1021 16:54:26.380020 14900 net.cpp:406] bn4_2 <- conv4_2
I1021 16:54:26.380020 14900 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1021 16:54:26.380020 14900 net.cpp:122] Setting up bn4_2
I1021 16:54:26.380020 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.380020 14900 net.cpp:137] Memory required for data: 330849200
I1021 16:54:26.380020 14900 layer_factory.cpp:58] Creating layer scale4_2
I1021 16:54:26.380020 14900 net.cpp:84] Creating Layer scale4_2
I1021 16:54:26.380020 14900 net.cpp:406] scale4_2 <- conv4_2
I1021 16:54:26.380020 14900 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1021 16:54:26.380020 14900 layer_factory.cpp:58] Creating layer scale4_2
I1021 16:54:26.380020 14900 net.cpp:122] Setting up scale4_2
I1021 16:54:26.380020 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.381021 14900 net.cpp:137] Memory required for data: 335396400
I1021 16:54:26.381021 14900 layer_factory.cpp:58] Creating layer relu4_2
I1021 16:54:26.381021 14900 net.cpp:84] Creating Layer relu4_2
I1021 16:54:26.381021 14900 net.cpp:406] relu4_2 <- conv4_2
I1021 16:54:26.381021 14900 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1021 16:54:26.381021 14900 net.cpp:122] Setting up relu4_2
I1021 16:54:26.381021 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.381021 14900 net.cpp:137] Memory required for data: 339943600
I1021 16:54:26.381021 14900 layer_factory.cpp:58] Creating layer pool4_2
I1021 16:54:26.381021 14900 net.cpp:84] Creating Layer pool4_2
I1021 16:54:26.381021 14900 net.cpp:406] pool4_2 <- conv4_2
I1021 16:54:26.381021 14900 net.cpp:380] pool4_2 -> pool4_2
I1021 16:54:26.381021 14900 net.cpp:122] Setting up pool4_2
I1021 16:54:26.381021 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.381021 14900 net.cpp:137] Memory required for data: 341080400
I1021 16:54:26.381021 14900 layer_factory.cpp:58] Creating layer drop9
I1021 16:54:26.381021 14900 net.cpp:84] Creating Layer drop9
I1021 16:54:26.381021 14900 net.cpp:406] drop9 <- pool4_2
I1021 16:54:26.381021 14900 net.cpp:367] drop9 -> pool4_2 (in-place)
I1021 16:54:26.381021 14900 net.cpp:122] Setting up drop9
I1021 16:54:26.381021 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.381021 14900 net.cpp:137] Memory required for data: 342217200
I1021 16:54:26.381021 14900 layer_factory.cpp:58] Creating layer conv4_0
I1021 16:54:26.381021 14900 net.cpp:84] Creating Layer conv4_0
I1021 16:54:26.381021 14900 net.cpp:406] conv4_0 <- pool4_2
I1021 16:54:26.381021 14900 net.cpp:380] conv4_0 -> conv4_0
I1021 16:54:26.382019 14900 net.cpp:122] Setting up conv4_0
I1021 16:54:26.382019 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.382019 14900 net.cpp:137] Memory required for data: 343354000
I1021 16:54:26.382019 14900 layer_factory.cpp:58] Creating layer bn4_0
I1021 16:54:26.382019 14900 net.cpp:84] Creating Layer bn4_0
I1021 16:54:26.382019 14900 net.cpp:406] bn4_0 <- conv4_0
I1021 16:54:26.382019 14900 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1021 16:54:26.382019 14900 net.cpp:122] Setting up bn4_0
I1021 16:54:26.382019 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.382019 14900 net.cpp:137] Memory required for data: 344490800
I1021 16:54:26.382019 14900 layer_factory.cpp:58] Creating layer scale4_0
I1021 16:54:26.382019 14900 net.cpp:84] Creating Layer scale4_0
I1021 16:54:26.382019 14900 net.cpp:406] scale4_0 <- conv4_0
I1021 16:54:26.382019 14900 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1021 16:54:26.382019 14900 layer_factory.cpp:58] Creating layer scale4_0
I1021 16:54:26.382019 14900 net.cpp:122] Setting up scale4_0
I1021 16:54:26.382019 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.382019 14900 net.cpp:137] Memory required for data: 345627600
I1021 16:54:26.382019 14900 layer_factory.cpp:58] Creating layer relu4_0
I1021 16:54:26.382019 14900 net.cpp:84] Creating Layer relu4_0
I1021 16:54:26.382019 14900 net.cpp:406] relu4_0 <- conv4_0
I1021 16:54:26.382019 14900 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1021 16:54:26.383019 14900 net.cpp:122] Setting up relu4_0
I1021 16:54:26.383019 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.383019 14900 net.cpp:137] Memory required for data: 346764400
I1021 16:54:26.383019 14900 layer_factory.cpp:58] Creating layer conv11
I1021 16:54:26.383019 14900 net.cpp:84] Creating Layer conv11
I1021 16:54:26.383019 14900 net.cpp:406] conv11 <- conv4_0
I1021 16:54:26.383019 14900 net.cpp:380] conv11 -> conv11
I1021 16:54:26.384019 14900 net.cpp:122] Setting up conv11
I1021 16:54:26.384019 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.384019 14900 net.cpp:137] Memory required for data: 348136400
I1021 16:54:26.384019 14900 layer_factory.cpp:58] Creating layer bn_conv11
I1021 16:54:26.384019 14900 net.cpp:84] Creating Layer bn_conv11
I1021 16:54:26.384019 14900 net.cpp:406] bn_conv11 <- conv11
I1021 16:54:26.384019 14900 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1021 16:54:26.385020 14900 net.cpp:122] Setting up bn_conv11
I1021 16:54:26.385020 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.385020 14900 net.cpp:137] Memory required for data: 349508400
I1021 16:54:26.385020 14900 layer_factory.cpp:58] Creating layer scale_conv11
I1021 16:54:26.385020 14900 net.cpp:84] Creating Layer scale_conv11
I1021 16:54:26.385020 14900 net.cpp:406] scale_conv11 <- conv11
I1021 16:54:26.385020 14900 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1021 16:54:26.385020 14900 layer_factory.cpp:58] Creating layer scale_conv11
I1021 16:54:26.385020 14900 net.cpp:122] Setting up scale_conv11
I1021 16:54:26.385020 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.385020 14900 net.cpp:137] Memory required for data: 350880400
I1021 16:54:26.385020 14900 layer_factory.cpp:58] Creating layer relu_conv11
I1021 16:54:26.385020 14900 net.cpp:84] Creating Layer relu_conv11
I1021 16:54:26.385020 14900 net.cpp:406] relu_conv11 <- conv11
I1021 16:54:26.385020 14900 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1021 16:54:26.385020 14900 net.cpp:122] Setting up relu_conv11
I1021 16:54:26.385020 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.385020 14900 net.cpp:137] Memory required for data: 352252400
I1021 16:54:26.385020 14900 layer_factory.cpp:58] Creating layer conv12
I1021 16:54:26.385020 14900 net.cpp:84] Creating Layer conv12
I1021 16:54:26.385020 14900 net.cpp:406] conv12 <- conv11
I1021 16:54:26.385020 14900 net.cpp:380] conv12 -> conv12
I1021 16:54:26.387023 14900 net.cpp:122] Setting up conv12
I1021 16:54:26.387023 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.387023 14900 net.cpp:137] Memory required for data: 354016400
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer bn_conv12
I1021 16:54:26.387023 14900 net.cpp:84] Creating Layer bn_conv12
I1021 16:54:26.387023 14900 net.cpp:406] bn_conv12 <- conv12
I1021 16:54:26.387023 14900 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1021 16:54:26.387023 14900 net.cpp:122] Setting up bn_conv12
I1021 16:54:26.387023 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.387023 14900 net.cpp:137] Memory required for data: 355780400
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer scale_conv12
I1021 16:54:26.387023 14900 net.cpp:84] Creating Layer scale_conv12
I1021 16:54:26.387023 14900 net.cpp:406] scale_conv12 <- conv12
I1021 16:54:26.387023 14900 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer scale_conv12
I1021 16:54:26.387023 14900 net.cpp:122] Setting up scale_conv12
I1021 16:54:26.387023 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.387023 14900 net.cpp:137] Memory required for data: 357544400
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer relu_conv12
I1021 16:54:26.387023 14900 net.cpp:84] Creating Layer relu_conv12
I1021 16:54:26.387023 14900 net.cpp:406] relu_conv12 <- conv12
I1021 16:54:26.387023 14900 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1021 16:54:26.387023 14900 net.cpp:122] Setting up relu_conv12
I1021 16:54:26.387023 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.387023 14900 net.cpp:137] Memory required for data: 359308400
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer poolcp6
I1021 16:54:26.387023 14900 net.cpp:84] Creating Layer poolcp6
I1021 16:54:26.387023 14900 net.cpp:406] poolcp6 <- conv12
I1021 16:54:26.387023 14900 net.cpp:380] poolcp6 -> poolcp6
I1021 16:54:26.387023 14900 net.cpp:122] Setting up poolcp6
I1021 16:54:26.387023 14900 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1021 16:54:26.387023 14900 net.cpp:137] Memory required for data: 359344400
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer drop12
I1021 16:54:26.387023 14900 net.cpp:84] Creating Layer drop12
I1021 16:54:26.387023 14900 net.cpp:406] drop12 <- poolcp6
I1021 16:54:26.387023 14900 net.cpp:367] drop12 -> poolcp6 (in-place)
I1021 16:54:26.387023 14900 net.cpp:122] Setting up drop12
I1021 16:54:26.387023 14900 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1021 16:54:26.387023 14900 net.cpp:137] Memory required for data: 359380400
I1021 16:54:26.387023 14900 layer_factory.cpp:58] Creating layer ip1
I1021 16:54:26.387023 14900 net.cpp:84] Creating Layer ip1
I1021 16:54:26.387023 14900 net.cpp:406] ip1 <- poolcp6
I1021 16:54:26.387023 14900 net.cpp:380] ip1 -> ip1
I1021 16:54:26.388020 14900 net.cpp:122] Setting up ip1
I1021 16:54:26.388020 14900 net.cpp:129] Top shape: 100 10 (1000)
I1021 16:54:26.388020 14900 net.cpp:137] Memory required for data: 359384400
I1021 16:54:26.388020 14900 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1021 16:54:26.388020 14900 net.cpp:84] Creating Layer ip1_ip1_0_split
I1021 16:54:26.388020 14900 net.cpp:406] ip1_ip1_0_split <- ip1
I1021 16:54:26.388020 14900 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1021 16:54:26.388020 14900 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1021 16:54:26.388020 14900 net.cpp:122] Setting up ip1_ip1_0_split
I1021 16:54:26.388020 14900 net.cpp:129] Top shape: 100 10 (1000)
I1021 16:54:26.388020 14900 net.cpp:129] Top shape: 100 10 (1000)
I1021 16:54:26.388020 14900 net.cpp:137] Memory required for data: 359392400
I1021 16:54:26.388020 14900 layer_factory.cpp:58] Creating layer accuracy_training
I1021 16:54:26.388020 14900 net.cpp:84] Creating Layer accuracy_training
I1021 16:54:26.388020 14900 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I1021 16:54:26.388020 14900 net.cpp:406] accuracy_training <- label_mnist_1_split_0
I1021 16:54:26.388020 14900 net.cpp:380] accuracy_training -> accuracy_training
I1021 16:54:26.388020 14900 net.cpp:122] Setting up accuracy_training
I1021 16:54:26.388020 14900 net.cpp:129] Top shape: (1)
I1021 16:54:26.388020 14900 net.cpp:137] Memory required for data: 359392404
I1021 16:54:26.388020 14900 layer_factory.cpp:58] Creating layer loss
I1021 16:54:26.388020 14900 net.cpp:84] Creating Layer loss
I1021 16:54:26.388020 14900 net.cpp:406] loss <- ip1_ip1_0_split_1
I1021 16:54:26.388020 14900 net.cpp:406] loss <- label_mnist_1_split_1
I1021 16:54:26.388020 14900 net.cpp:380] loss -> loss
I1021 16:54:26.388020 14900 layer_factory.cpp:58] Creating layer loss
I1021 16:54:26.388020 14900 net.cpp:122] Setting up loss
I1021 16:54:26.388020 14900 net.cpp:129] Top shape: (1)
I1021 16:54:26.388020 14900 net.cpp:132]     with loss weight 1
I1021 16:54:26.388020 14900 net.cpp:137] Memory required for data: 359392408
I1021 16:54:26.388020 14900 net.cpp:198] loss needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:200] accuracy_training does not need backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] ip1 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] drop12 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] poolcp6 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] relu_conv12 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] scale_conv12 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] bn_conv12 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] conv12 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] relu_conv11 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] scale_conv11 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] bn_conv11 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] conv11 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] relu4_0 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] scale4_0 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] bn4_0 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] conv4_0 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] drop9 needs backward computation.
I1021 16:54:26.388020 14900 net.cpp:198] pool4_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu4_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale4_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn4_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv4_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu4_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale4_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn4_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv4_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu4 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale4 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn4 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv4 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu3_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale3_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn3_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv3_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu3 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale3 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn3 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv3 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] drop5 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] pool2_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu2_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale2_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn2_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv2_2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu2_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale2_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn2_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv2_1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv2 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu1_0 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale1_0 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn1_0 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv1_0 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] relu1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] scale1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] bn1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:198] conv1 needs backward computation.
I1021 16:54:26.389020 14900 net.cpp:200] label_mnist_1_split does not need backward computation.
I1021 16:54:26.389020 14900 net.cpp:200] mnist does not need backward computation.
I1021 16:54:26.389020 14900 net.cpp:242] This network produces output accuracy_training
I1021 16:54:26.389020 14900 net.cpp:242] This network produces output loss
I1021 16:54:26.389020 14900 net.cpp:255] Network initialization done.
I1021 16:54:26.390020 14900 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/mnist/lenet_train_test.prototxt
I1021 16:54:26.390020 14900 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1021 16:54:26.390020 14900 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3_1
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv11
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_conv12
I1021 16:54:26.390020 14900 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I1021 16:54:26.390020 14900 net.cpp:51] Initializing net from parameters: 
name: "MNIST_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_maxdrp_300k"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb_norm2"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 30
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 40
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "pool4_2"
  top: "pool4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 58
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv4_0"
  top: "conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 70
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv11"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 90
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.99
  }
}
layer {
  name: "scale_conv12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_conv12"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "conv12"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "drop12"
  type: "Dropout"
  bottom: "poolcp6"
  top: "poolcp6"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1021 16:54:26.390020 14900 layer_factory.cpp:58] Creating layer mnist
I1021 16:54:26.396030 14900 db_lmdb.cpp:40] Opened lmdb examples/mnist/mnist_test_lmdb_norm2
I1021 16:54:26.396030 14900 net.cpp:84] Creating Layer mnist
I1021 16:54:26.396030 14900 net.cpp:380] mnist -> data
I1021 16:54:26.396030 14900 net.cpp:380] mnist -> label
I1021 16:54:26.396030 14900 data_layer.cpp:45] output data size: 100,1,28,28
I1021 16:54:26.399020 14900 net.cpp:122] Setting up mnist
I1021 16:54:26.399020 14900 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1021 16:54:26.399020 14900 net.cpp:129] Top shape: 100 (100)
I1021 16:54:26.399020 14900 net.cpp:137] Memory required for data: 314000
I1021 16:54:26.399020 14900 layer_factory.cpp:58] Creating layer label_mnist_1_split
I1021 16:54:26.399020 14900 net.cpp:84] Creating Layer label_mnist_1_split
I1021 16:54:26.399020 14900 net.cpp:406] label_mnist_1_split <- label
I1021 16:54:26.399020 14900 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1021 16:54:26.399020 14900 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1021 16:54:26.399020 14900 net.cpp:122] Setting up label_mnist_1_split
I1021 16:54:26.399020 14900 net.cpp:129] Top shape: 100 (100)
I1021 16:54:26.399020 14900 net.cpp:129] Top shape: 100 (100)
I1021 16:54:26.399020 14900 net.cpp:137] Memory required for data: 314800
I1021 16:54:26.399020 14900 layer_factory.cpp:58] Creating layer conv1
I1021 16:54:26.399020 14900 net.cpp:84] Creating Layer conv1
I1021 16:54:26.399020 14900 net.cpp:406] conv1 <- data
I1021 16:54:26.399020 14900 net.cpp:380] conv1 -> conv1
I1021 16:54:26.401020 14900 net.cpp:122] Setting up conv1
I1021 16:54:26.401020 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.401020 14900 net.cpp:137] Memory required for data: 9722800
I1021 16:54:26.401020 14900 layer_factory.cpp:58] Creating layer bn1
I1021 16:54:26.401020 14900 net.cpp:84] Creating Layer bn1
I1021 16:54:26.401020 14900 net.cpp:406] bn1 <- conv1
I1021 16:54:26.401020 14900 net.cpp:367] bn1 -> conv1 (in-place)
I1021 16:54:26.401020 17916 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1021 16:54:26.401020 14900 net.cpp:122] Setting up bn1
I1021 16:54:26.401020 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.401020 14900 net.cpp:137] Memory required for data: 19130800
I1021 16:54:26.401020 14900 layer_factory.cpp:58] Creating layer scale1
I1021 16:54:26.401020 14900 net.cpp:84] Creating Layer scale1
I1021 16:54:26.401020 14900 net.cpp:406] scale1 <- conv1
I1021 16:54:26.401020 14900 net.cpp:367] scale1 -> conv1 (in-place)
I1021 16:54:26.401020 14900 layer_factory.cpp:58] Creating layer scale1
I1021 16:54:26.401020 14900 net.cpp:122] Setting up scale1
I1021 16:54:26.401020 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.401020 14900 net.cpp:137] Memory required for data: 28538800
I1021 16:54:26.401020 14900 layer_factory.cpp:58] Creating layer relu1
I1021 16:54:26.401020 14900 net.cpp:84] Creating Layer relu1
I1021 16:54:26.401020 14900 net.cpp:406] relu1 <- conv1
I1021 16:54:26.401020 14900 net.cpp:367] relu1 -> conv1 (in-place)
I1021 16:54:26.401020 14900 net.cpp:122] Setting up relu1
I1021 16:54:26.402020 14900 net.cpp:129] Top shape: 100 30 28 28 (2352000)
I1021 16:54:26.402020 14900 net.cpp:137] Memory required for data: 37946800
I1021 16:54:26.402020 14900 layer_factory.cpp:58] Creating layer conv1_0
I1021 16:54:26.402020 14900 net.cpp:84] Creating Layer conv1_0
I1021 16:54:26.402020 14900 net.cpp:406] conv1_0 <- conv1
I1021 16:54:26.402020 14900 net.cpp:380] conv1_0 -> conv1_0
I1021 16:54:26.403020 14900 net.cpp:122] Setting up conv1_0
I1021 16:54:26.403020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.403020 14900 net.cpp:137] Memory required for data: 50490800
I1021 16:54:26.403020 14900 layer_factory.cpp:58] Creating layer bn1_0
I1021 16:54:26.403020 14900 net.cpp:84] Creating Layer bn1_0
I1021 16:54:26.403020 14900 net.cpp:406] bn1_0 <- conv1_0
I1021 16:54:26.403020 14900 net.cpp:367] bn1_0 -> conv1_0 (in-place)
I1021 16:54:26.403020 14900 net.cpp:122] Setting up bn1_0
I1021 16:54:26.403020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.403020 14900 net.cpp:137] Memory required for data: 63034800
I1021 16:54:26.403020 14900 layer_factory.cpp:58] Creating layer scale1_0
I1021 16:54:26.403020 14900 net.cpp:84] Creating Layer scale1_0
I1021 16:54:26.403020 14900 net.cpp:406] scale1_0 <- conv1_0
I1021 16:54:26.403020 14900 net.cpp:367] scale1_0 -> conv1_0 (in-place)
I1021 16:54:26.404021 14900 layer_factory.cpp:58] Creating layer scale1_0
I1021 16:54:26.404021 14900 net.cpp:122] Setting up scale1_0
I1021 16:54:26.404021 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.404021 14900 net.cpp:137] Memory required for data: 75578800
I1021 16:54:26.404021 14900 layer_factory.cpp:58] Creating layer relu1_0
I1021 16:54:26.404021 14900 net.cpp:84] Creating Layer relu1_0
I1021 16:54:26.404021 14900 net.cpp:406] relu1_0 <- conv1_0
I1021 16:54:26.404021 14900 net.cpp:367] relu1_0 -> conv1_0 (in-place)
I1021 16:54:26.404021 14900 net.cpp:122] Setting up relu1_0
I1021 16:54:26.404021 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.404021 14900 net.cpp:137] Memory required for data: 88122800
I1021 16:54:26.404021 14900 layer_factory.cpp:58] Creating layer conv2
I1021 16:54:26.404021 14900 net.cpp:84] Creating Layer conv2
I1021 16:54:26.404021 14900 net.cpp:406] conv2 <- conv1_0
I1021 16:54:26.404021 14900 net.cpp:380] conv2 -> conv2
I1021 16:54:26.406019 14900 net.cpp:122] Setting up conv2
I1021 16:54:26.406019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.406019 14900 net.cpp:137] Memory required for data: 100666800
I1021 16:54:26.406019 14900 layer_factory.cpp:58] Creating layer bn2
I1021 16:54:26.406019 14900 net.cpp:84] Creating Layer bn2
I1021 16:54:26.406019 14900 net.cpp:406] bn2 <- conv2
I1021 16:54:26.406019 14900 net.cpp:367] bn2 -> conv2 (in-place)
I1021 16:54:26.406019 14900 net.cpp:122] Setting up bn2
I1021 16:54:26.406019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.406019 14900 net.cpp:137] Memory required for data: 113210800
I1021 16:54:26.406019 14900 layer_factory.cpp:58] Creating layer scale2
I1021 16:54:26.406019 14900 net.cpp:84] Creating Layer scale2
I1021 16:54:26.406019 14900 net.cpp:406] scale2 <- conv2
I1021 16:54:26.406019 14900 net.cpp:367] scale2 -> conv2 (in-place)
I1021 16:54:26.406019 14900 layer_factory.cpp:58] Creating layer scale2
I1021 16:54:26.406019 14900 net.cpp:122] Setting up scale2
I1021 16:54:26.407019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.407019 14900 net.cpp:137] Memory required for data: 125754800
I1021 16:54:26.407019 14900 layer_factory.cpp:58] Creating layer relu2
I1021 16:54:26.407019 14900 net.cpp:84] Creating Layer relu2
I1021 16:54:26.407019 14900 net.cpp:406] relu2 <- conv2
I1021 16:54:26.407019 14900 net.cpp:367] relu2 -> conv2 (in-place)
I1021 16:54:26.407019 14900 net.cpp:122] Setting up relu2
I1021 16:54:26.407019 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.407019 14900 net.cpp:137] Memory required for data: 138298800
I1021 16:54:26.407019 14900 layer_factory.cpp:58] Creating layer conv2_1
I1021 16:54:26.407019 14900 net.cpp:84] Creating Layer conv2_1
I1021 16:54:26.407019 14900 net.cpp:406] conv2_1 <- conv2
I1021 16:54:26.407019 14900 net.cpp:380] conv2_1 -> conv2_1
I1021 16:54:26.408020 14900 net.cpp:122] Setting up conv2_1
I1021 16:54:26.408020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.408020 14900 net.cpp:137] Memory required for data: 150842800
I1021 16:54:26.408020 14900 layer_factory.cpp:58] Creating layer bn2_1
I1021 16:54:26.408020 14900 net.cpp:84] Creating Layer bn2_1
I1021 16:54:26.408020 14900 net.cpp:406] bn2_1 <- conv2_1
I1021 16:54:26.408020 14900 net.cpp:367] bn2_1 -> conv2_1 (in-place)
I1021 16:54:26.408020 14900 net.cpp:122] Setting up bn2_1
I1021 16:54:26.408020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.408020 14900 net.cpp:137] Memory required for data: 163386800
I1021 16:54:26.408020 14900 layer_factory.cpp:58] Creating layer scale2_1
I1021 16:54:26.408020 14900 net.cpp:84] Creating Layer scale2_1
I1021 16:54:26.408020 14900 net.cpp:406] scale2_1 <- conv2_1
I1021 16:54:26.408020 14900 net.cpp:367] scale2_1 -> conv2_1 (in-place)
I1021 16:54:26.408020 14900 layer_factory.cpp:58] Creating layer scale2_1
I1021 16:54:26.409020 14900 net.cpp:122] Setting up scale2_1
I1021 16:54:26.409020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.409020 14900 net.cpp:137] Memory required for data: 175930800
I1021 16:54:26.409020 14900 layer_factory.cpp:58] Creating layer relu2_1
I1021 16:54:26.409020 14900 net.cpp:84] Creating Layer relu2_1
I1021 16:54:26.409020 14900 net.cpp:406] relu2_1 <- conv2_1
I1021 16:54:26.409020 14900 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I1021 16:54:26.409020 14900 net.cpp:122] Setting up relu2_1
I1021 16:54:26.409020 14900 net.cpp:129] Top shape: 100 40 28 28 (3136000)
I1021 16:54:26.409020 14900 net.cpp:137] Memory required for data: 188474800
I1021 16:54:26.409020 14900 layer_factory.cpp:58] Creating layer conv2_2
I1021 16:54:26.409020 14900 net.cpp:84] Creating Layer conv2_2
I1021 16:54:26.409020 14900 net.cpp:406] conv2_2 <- conv2_1
I1021 16:54:26.409020 14900 net.cpp:380] conv2_2 -> conv2_2
I1021 16:54:26.410020 14900 net.cpp:122] Setting up conv2_2
I1021 16:54:26.410020 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.410020 14900 net.cpp:137] Memory required for data: 204154800
I1021 16:54:26.410020 14900 layer_factory.cpp:58] Creating layer bn2_2
I1021 16:54:26.410020 14900 net.cpp:84] Creating Layer bn2_2
I1021 16:54:26.410020 14900 net.cpp:406] bn2_2 <- conv2_2
I1021 16:54:26.410020 14900 net.cpp:367] bn2_2 -> conv2_2 (in-place)
I1021 16:54:26.410020 14900 net.cpp:122] Setting up bn2_2
I1021 16:54:26.410020 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.410020 14900 net.cpp:137] Memory required for data: 219834800
I1021 16:54:26.410020 14900 layer_factory.cpp:58] Creating layer scale2_2
I1021 16:54:26.410020 14900 net.cpp:84] Creating Layer scale2_2
I1021 16:54:26.410020 14900 net.cpp:406] scale2_2 <- conv2_2
I1021 16:54:26.410020 14900 net.cpp:367] scale2_2 -> conv2_2 (in-place)
I1021 16:54:26.410020 14900 layer_factory.cpp:58] Creating layer scale2_2
I1021 16:54:26.411021 14900 net.cpp:122] Setting up scale2_2
I1021 16:54:26.411021 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.411021 14900 net.cpp:137] Memory required for data: 235514800
I1021 16:54:26.411021 14900 layer_factory.cpp:58] Creating layer relu2_2
I1021 16:54:26.411021 14900 net.cpp:84] Creating Layer relu2_2
I1021 16:54:26.411021 14900 net.cpp:406] relu2_2 <- conv2_2
I1021 16:54:26.411021 14900 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I1021 16:54:26.411021 14900 net.cpp:122] Setting up relu2_2
I1021 16:54:26.411021 14900 net.cpp:129] Top shape: 100 50 28 28 (3920000)
I1021 16:54:26.411021 14900 net.cpp:137] Memory required for data: 251194800
I1021 16:54:26.411021 14900 layer_factory.cpp:58] Creating layer pool2_1
I1021 16:54:26.411021 14900 net.cpp:84] Creating Layer pool2_1
I1021 16:54:26.411021 14900 net.cpp:406] pool2_1 <- conv2_2
I1021 16:54:26.411021 14900 net.cpp:380] pool2_1 -> pool2_1
I1021 16:54:26.411021 14900 net.cpp:122] Setting up pool2_1
I1021 16:54:26.411021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.411021 14900 net.cpp:137] Memory required for data: 255114800
I1021 16:54:26.411021 14900 layer_factory.cpp:58] Creating layer drop5
I1021 16:54:26.411021 14900 net.cpp:84] Creating Layer drop5
I1021 16:54:26.411021 14900 net.cpp:406] drop5 <- pool2_1
I1021 16:54:26.411021 14900 net.cpp:367] drop5 -> pool2_1 (in-place)
I1021 16:54:26.411021 14900 net.cpp:122] Setting up drop5
I1021 16:54:26.411021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.411021 14900 net.cpp:137] Memory required for data: 259034800
I1021 16:54:26.411021 14900 layer_factory.cpp:58] Creating layer conv3
I1021 16:54:26.411021 14900 net.cpp:84] Creating Layer conv3
I1021 16:54:26.411021 14900 net.cpp:406] conv3 <- pool2_1
I1021 16:54:26.411021 14900 net.cpp:380] conv3 -> conv3
I1021 16:54:26.413019 14900 net.cpp:122] Setting up conv3
I1021 16:54:26.413019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.413019 14900 net.cpp:137] Memory required for data: 262954800
I1021 16:54:26.413019 14900 layer_factory.cpp:58] Creating layer bn3
I1021 16:54:26.413019 14900 net.cpp:84] Creating Layer bn3
I1021 16:54:26.413019 14900 net.cpp:406] bn3 <- conv3
I1021 16:54:26.413019 14900 net.cpp:367] bn3 -> conv3 (in-place)
I1021 16:54:26.413019 14900 net.cpp:122] Setting up bn3
I1021 16:54:26.413019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.413019 14900 net.cpp:137] Memory required for data: 266874800
I1021 16:54:26.413019 14900 layer_factory.cpp:58] Creating layer scale3
I1021 16:54:26.413019 14900 net.cpp:84] Creating Layer scale3
I1021 16:54:26.413019 14900 net.cpp:406] scale3 <- conv3
I1021 16:54:26.413019 14900 net.cpp:367] scale3 -> conv3 (in-place)
I1021 16:54:26.413019 14900 layer_factory.cpp:58] Creating layer scale3
I1021 16:54:26.413019 14900 net.cpp:122] Setting up scale3
I1021 16:54:26.413019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.413019 14900 net.cpp:137] Memory required for data: 270794800
I1021 16:54:26.413019 14900 layer_factory.cpp:58] Creating layer relu3
I1021 16:54:26.413019 14900 net.cpp:84] Creating Layer relu3
I1021 16:54:26.413019 14900 net.cpp:406] relu3 <- conv3
I1021 16:54:26.413019 14900 net.cpp:367] relu3 -> conv3 (in-place)
I1021 16:54:26.413019 14900 net.cpp:122] Setting up relu3
I1021 16:54:26.414019 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.414019 14900 net.cpp:137] Memory required for data: 274714800
I1021 16:54:26.414019 14900 layer_factory.cpp:58] Creating layer conv3_1
I1021 16:54:26.414019 14900 net.cpp:84] Creating Layer conv3_1
I1021 16:54:26.414019 14900 net.cpp:406] conv3_1 <- conv3
I1021 16:54:26.414019 14900 net.cpp:380] conv3_1 -> conv3_1
I1021 16:54:26.415020 14900 net.cpp:122] Setting up conv3_1
I1021 16:54:26.415020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.415020 14900 net.cpp:137] Memory required for data: 278634800
I1021 16:54:26.415020 14900 layer_factory.cpp:58] Creating layer bn3_1
I1021 16:54:26.415020 14900 net.cpp:84] Creating Layer bn3_1
I1021 16:54:26.415020 14900 net.cpp:406] bn3_1 <- conv3_1
I1021 16:54:26.415020 14900 net.cpp:367] bn3_1 -> conv3_1 (in-place)
I1021 16:54:26.415020 14900 net.cpp:122] Setting up bn3_1
I1021 16:54:26.415020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.415020 14900 net.cpp:137] Memory required for data: 282554800
I1021 16:54:26.415020 14900 layer_factory.cpp:58] Creating layer scale3_1
I1021 16:54:26.415020 14900 net.cpp:84] Creating Layer scale3_1
I1021 16:54:26.415020 14900 net.cpp:406] scale3_1 <- conv3_1
I1021 16:54:26.415020 14900 net.cpp:367] scale3_1 -> conv3_1 (in-place)
I1021 16:54:26.415020 14900 layer_factory.cpp:58] Creating layer scale3_1
I1021 16:54:26.415020 14900 net.cpp:122] Setting up scale3_1
I1021 16:54:26.415020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.415020 14900 net.cpp:137] Memory required for data: 286474800
I1021 16:54:26.415020 14900 layer_factory.cpp:58] Creating layer relu3_1
I1021 16:54:26.415020 14900 net.cpp:84] Creating Layer relu3_1
I1021 16:54:26.415020 14900 net.cpp:406] relu3_1 <- conv3_1
I1021 16:54:26.415020 14900 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I1021 16:54:26.416020 14900 net.cpp:122] Setting up relu3_1
I1021 16:54:26.416020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.416020 14900 net.cpp:137] Memory required for data: 290394800
I1021 16:54:26.416020 14900 layer_factory.cpp:58] Creating layer conv4
I1021 16:54:26.416020 14900 net.cpp:84] Creating Layer conv4
I1021 16:54:26.416020 14900 net.cpp:406] conv4 <- conv3_1
I1021 16:54:26.416020 14900 net.cpp:380] conv4 -> conv4
I1021 16:54:26.417021 14900 net.cpp:122] Setting up conv4
I1021 16:54:26.417021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.417021 14900 net.cpp:137] Memory required for data: 294314800
I1021 16:54:26.417021 14900 layer_factory.cpp:58] Creating layer bn4
I1021 16:54:26.417021 14900 net.cpp:84] Creating Layer bn4
I1021 16:54:26.417021 14900 net.cpp:406] bn4 <- conv4
I1021 16:54:26.417021 14900 net.cpp:367] bn4 -> conv4 (in-place)
I1021 16:54:26.417021 14900 net.cpp:122] Setting up bn4
I1021 16:54:26.417021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.417021 14900 net.cpp:137] Memory required for data: 298234800
I1021 16:54:26.417021 14900 layer_factory.cpp:58] Creating layer scale4
I1021 16:54:26.417021 14900 net.cpp:84] Creating Layer scale4
I1021 16:54:26.417021 14900 net.cpp:406] scale4 <- conv4
I1021 16:54:26.417021 14900 net.cpp:367] scale4 -> conv4 (in-place)
I1021 16:54:26.417021 14900 layer_factory.cpp:58] Creating layer scale4
I1021 16:54:26.417021 14900 net.cpp:122] Setting up scale4
I1021 16:54:26.417021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.417021 14900 net.cpp:137] Memory required for data: 302154800
I1021 16:54:26.417021 14900 layer_factory.cpp:58] Creating layer relu4
I1021 16:54:26.417021 14900 net.cpp:84] Creating Layer relu4
I1021 16:54:26.417021 14900 net.cpp:406] relu4 <- conv4
I1021 16:54:26.417021 14900 net.cpp:367] relu4 -> conv4 (in-place)
I1021 16:54:26.417021 14900 net.cpp:122] Setting up relu4
I1021 16:54:26.417021 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.417021 14900 net.cpp:137] Memory required for data: 306074800
I1021 16:54:26.417021 14900 layer_factory.cpp:58] Creating layer conv4_1
I1021 16:54:26.417021 14900 net.cpp:84] Creating Layer conv4_1
I1021 16:54:26.417021 14900 net.cpp:406] conv4_1 <- conv4
I1021 16:54:26.417021 14900 net.cpp:380] conv4_1 -> conv4_1
I1021 16:54:26.419020 14900 net.cpp:122] Setting up conv4_1
I1021 16:54:26.419020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.419020 14900 net.cpp:137] Memory required for data: 309994800
I1021 16:54:26.419020 14900 layer_factory.cpp:58] Creating layer bn4_1
I1021 16:54:26.419020 14900 net.cpp:84] Creating Layer bn4_1
I1021 16:54:26.419020 14900 net.cpp:406] bn4_1 <- conv4_1
I1021 16:54:26.419020 14900 net.cpp:367] bn4_1 -> conv4_1 (in-place)
I1021 16:54:26.419020 14900 net.cpp:122] Setting up bn4_1
I1021 16:54:26.419020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.419020 14900 net.cpp:137] Memory required for data: 313914800
I1021 16:54:26.419020 14900 layer_factory.cpp:58] Creating layer scale4_1
I1021 16:54:26.419020 14900 net.cpp:84] Creating Layer scale4_1
I1021 16:54:26.419020 14900 net.cpp:406] scale4_1 <- conv4_1
I1021 16:54:26.419020 14900 net.cpp:367] scale4_1 -> conv4_1 (in-place)
I1021 16:54:26.419020 14900 layer_factory.cpp:58] Creating layer scale4_1
I1021 16:54:26.420020 14900 net.cpp:122] Setting up scale4_1
I1021 16:54:26.420020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.420020 14900 net.cpp:137] Memory required for data: 317834800
I1021 16:54:26.420020 14900 layer_factory.cpp:58] Creating layer relu4_1
I1021 16:54:26.420020 14900 net.cpp:84] Creating Layer relu4_1
I1021 16:54:26.420020 14900 net.cpp:406] relu4_1 <- conv4_1
I1021 16:54:26.420020 14900 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I1021 16:54:26.420020 14900 net.cpp:122] Setting up relu4_1
I1021 16:54:26.420020 14900 net.cpp:129] Top shape: 100 50 14 14 (980000)
I1021 16:54:26.420020 14900 net.cpp:137] Memory required for data: 321754800
I1021 16:54:26.420020 14900 layer_factory.cpp:58] Creating layer conv4_2
I1021 16:54:26.420020 14900 net.cpp:84] Creating Layer conv4_2
I1021 16:54:26.420020 14900 net.cpp:406] conv4_2 <- conv4_1
I1021 16:54:26.420020 14900 net.cpp:380] conv4_2 -> conv4_2
I1021 16:54:26.421020 14900 net.cpp:122] Setting up conv4_2
I1021 16:54:26.421020 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.421020 14900 net.cpp:137] Memory required for data: 326302000
I1021 16:54:26.421020 14900 layer_factory.cpp:58] Creating layer bn4_2
I1021 16:54:26.421020 14900 net.cpp:84] Creating Layer bn4_2
I1021 16:54:26.421020 14900 net.cpp:406] bn4_2 <- conv4_2
I1021 16:54:26.421020 14900 net.cpp:367] bn4_2 -> conv4_2 (in-place)
I1021 16:54:26.421020 14900 net.cpp:122] Setting up bn4_2
I1021 16:54:26.421020 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.421020 14900 net.cpp:137] Memory required for data: 330849200
I1021 16:54:26.421020 14900 layer_factory.cpp:58] Creating layer scale4_2
I1021 16:54:26.421020 14900 net.cpp:84] Creating Layer scale4_2
I1021 16:54:26.421020 14900 net.cpp:406] scale4_2 <- conv4_2
I1021 16:54:26.421020 14900 net.cpp:367] scale4_2 -> conv4_2 (in-place)
I1021 16:54:26.421020 14900 layer_factory.cpp:58] Creating layer scale4_2
I1021 16:54:26.422019 14900 net.cpp:122] Setting up scale4_2
I1021 16:54:26.422019 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.422019 14900 net.cpp:137] Memory required for data: 335396400
I1021 16:54:26.422019 14900 layer_factory.cpp:58] Creating layer relu4_2
I1021 16:54:26.422019 14900 net.cpp:84] Creating Layer relu4_2
I1021 16:54:26.422019 14900 net.cpp:406] relu4_2 <- conv4_2
I1021 16:54:26.422019 14900 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I1021 16:54:26.422019 14900 net.cpp:122] Setting up relu4_2
I1021 16:54:26.422019 14900 net.cpp:129] Top shape: 100 58 14 14 (1136800)
I1021 16:54:26.422019 14900 net.cpp:137] Memory required for data: 339943600
I1021 16:54:26.422019 14900 layer_factory.cpp:58] Creating layer pool4_2
I1021 16:54:26.422019 14900 net.cpp:84] Creating Layer pool4_2
I1021 16:54:26.422019 14900 net.cpp:406] pool4_2 <- conv4_2
I1021 16:54:26.422019 14900 net.cpp:380] pool4_2 -> pool4_2
I1021 16:54:26.422019 14900 net.cpp:122] Setting up pool4_2
I1021 16:54:26.422019 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.422019 14900 net.cpp:137] Memory required for data: 341080400
I1021 16:54:26.422019 14900 layer_factory.cpp:58] Creating layer drop9
I1021 16:54:26.422019 14900 net.cpp:84] Creating Layer drop9
I1021 16:54:26.422019 14900 net.cpp:406] drop9 <- pool4_2
I1021 16:54:26.422019 14900 net.cpp:367] drop9 -> pool4_2 (in-place)
I1021 16:54:26.422019 14900 net.cpp:122] Setting up drop9
I1021 16:54:26.422019 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.422019 14900 net.cpp:137] Memory required for data: 342217200
I1021 16:54:26.422019 14900 layer_factory.cpp:58] Creating layer conv4_0
I1021 16:54:26.422019 14900 net.cpp:84] Creating Layer conv4_0
I1021 16:54:26.422019 14900 net.cpp:406] conv4_0 <- pool4_2
I1021 16:54:26.422019 14900 net.cpp:380] conv4_0 -> conv4_0
I1021 16:54:26.424021 14900 net.cpp:122] Setting up conv4_0
I1021 16:54:26.424021 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.424021 14900 net.cpp:137] Memory required for data: 343354000
I1021 16:54:26.424021 14900 layer_factory.cpp:58] Creating layer bn4_0
I1021 16:54:26.424021 14900 net.cpp:84] Creating Layer bn4_0
I1021 16:54:26.424021 14900 net.cpp:406] bn4_0 <- conv4_0
I1021 16:54:26.424021 14900 net.cpp:367] bn4_0 -> conv4_0 (in-place)
I1021 16:54:26.424021 14900 net.cpp:122] Setting up bn4_0
I1021 16:54:26.424021 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.424021 14900 net.cpp:137] Memory required for data: 344490800
I1021 16:54:26.424021 14900 layer_factory.cpp:58] Creating layer scale4_0
I1021 16:54:26.424021 14900 net.cpp:84] Creating Layer scale4_0
I1021 16:54:26.424021 14900 net.cpp:406] scale4_0 <- conv4_0
I1021 16:54:26.424021 14900 net.cpp:367] scale4_0 -> conv4_0 (in-place)
I1021 16:54:26.424021 14900 layer_factory.cpp:58] Creating layer scale4_0
I1021 16:54:26.424021 14900 net.cpp:122] Setting up scale4_0
I1021 16:54:26.424021 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.424021 14900 net.cpp:137] Memory required for data: 345627600
I1021 16:54:26.424021 14900 layer_factory.cpp:58] Creating layer relu4_0
I1021 16:54:26.424021 14900 net.cpp:84] Creating Layer relu4_0
I1021 16:54:26.424021 14900 net.cpp:406] relu4_0 <- conv4_0
I1021 16:54:26.424021 14900 net.cpp:367] relu4_0 -> conv4_0 (in-place)
I1021 16:54:26.425020 14900 net.cpp:122] Setting up relu4_0
I1021 16:54:26.425020 14900 net.cpp:129] Top shape: 100 58 7 7 (284200)
I1021 16:54:26.425020 14900 net.cpp:137] Memory required for data: 346764400
I1021 16:54:26.425020 14900 layer_factory.cpp:58] Creating layer conv11
I1021 16:54:26.425020 14900 net.cpp:84] Creating Layer conv11
I1021 16:54:26.425020 14900 net.cpp:406] conv11 <- conv4_0
I1021 16:54:26.425020 14900 net.cpp:380] conv11 -> conv11
I1021 16:54:26.426020 14900 net.cpp:122] Setting up conv11
I1021 16:54:26.426020 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.426020 14900 net.cpp:137] Memory required for data: 348136400
I1021 16:54:26.426020 14900 layer_factory.cpp:58] Creating layer bn_conv11
I1021 16:54:26.426020 14900 net.cpp:84] Creating Layer bn_conv11
I1021 16:54:26.426020 14900 net.cpp:406] bn_conv11 <- conv11
I1021 16:54:26.426020 14900 net.cpp:367] bn_conv11 -> conv11 (in-place)
I1021 16:54:26.426020 14900 net.cpp:122] Setting up bn_conv11
I1021 16:54:26.426020 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.426020 14900 net.cpp:137] Memory required for data: 349508400
I1021 16:54:26.426020 14900 layer_factory.cpp:58] Creating layer scale_conv11
I1021 16:54:26.426020 14900 net.cpp:84] Creating Layer scale_conv11
I1021 16:54:26.426020 14900 net.cpp:406] scale_conv11 <- conv11
I1021 16:54:26.426020 14900 net.cpp:367] scale_conv11 -> conv11 (in-place)
I1021 16:54:26.426020 14900 layer_factory.cpp:58] Creating layer scale_conv11
I1021 16:54:26.426020 14900 net.cpp:122] Setting up scale_conv11
I1021 16:54:26.426020 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.426020 14900 net.cpp:137] Memory required for data: 350880400
I1021 16:54:26.426020 14900 layer_factory.cpp:58] Creating layer relu_conv11
I1021 16:54:26.426020 14900 net.cpp:84] Creating Layer relu_conv11
I1021 16:54:26.426020 14900 net.cpp:406] relu_conv11 <- conv11
I1021 16:54:26.426020 14900 net.cpp:367] relu_conv11 -> conv11 (in-place)
I1021 16:54:26.427026 14900 net.cpp:122] Setting up relu_conv11
I1021 16:54:26.427026 14900 net.cpp:129] Top shape: 100 70 7 7 (343000)
I1021 16:54:26.427026 14900 net.cpp:137] Memory required for data: 352252400
I1021 16:54:26.427026 14900 layer_factory.cpp:58] Creating layer conv12
I1021 16:54:26.427026 14900 net.cpp:84] Creating Layer conv12
I1021 16:54:26.427026 14900 net.cpp:406] conv12 <- conv11
I1021 16:54:26.427026 14900 net.cpp:380] conv12 -> conv12
I1021 16:54:26.429020 14900 net.cpp:122] Setting up conv12
I1021 16:54:26.429020 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.429020 14900 net.cpp:137] Memory required for data: 354016400
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer bn_conv12
I1021 16:54:26.429020 14900 net.cpp:84] Creating Layer bn_conv12
I1021 16:54:26.429020 14900 net.cpp:406] bn_conv12 <- conv12
I1021 16:54:26.429020 14900 net.cpp:367] bn_conv12 -> conv12 (in-place)
I1021 16:54:26.429020 14900 net.cpp:122] Setting up bn_conv12
I1021 16:54:26.429020 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.429020 14900 net.cpp:137] Memory required for data: 355780400
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer scale_conv12
I1021 16:54:26.429020 14900 net.cpp:84] Creating Layer scale_conv12
I1021 16:54:26.429020 14900 net.cpp:406] scale_conv12 <- conv12
I1021 16:54:26.429020 14900 net.cpp:367] scale_conv12 -> conv12 (in-place)
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer scale_conv12
I1021 16:54:26.429020 14900 net.cpp:122] Setting up scale_conv12
I1021 16:54:26.429020 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.429020 14900 net.cpp:137] Memory required for data: 357544400
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer relu_conv12
I1021 16:54:26.429020 14900 net.cpp:84] Creating Layer relu_conv12
I1021 16:54:26.429020 14900 net.cpp:406] relu_conv12 <- conv12
I1021 16:54:26.429020 14900 net.cpp:367] relu_conv12 -> conv12 (in-place)
I1021 16:54:26.429020 14900 net.cpp:122] Setting up relu_conv12
I1021 16:54:26.429020 14900 net.cpp:129] Top shape: 100 90 7 7 (441000)
I1021 16:54:26.429020 14900 net.cpp:137] Memory required for data: 359308400
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer poolcp6
I1021 16:54:26.429020 14900 net.cpp:84] Creating Layer poolcp6
I1021 16:54:26.429020 14900 net.cpp:406] poolcp6 <- conv12
I1021 16:54:26.429020 14900 net.cpp:380] poolcp6 -> poolcp6
I1021 16:54:26.429020 14900 net.cpp:122] Setting up poolcp6
I1021 16:54:26.429020 14900 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1021 16:54:26.429020 14900 net.cpp:137] Memory required for data: 359344400
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer drop12
I1021 16:54:26.429020 14900 net.cpp:84] Creating Layer drop12
I1021 16:54:26.429020 14900 net.cpp:406] drop12 <- poolcp6
I1021 16:54:26.429020 14900 net.cpp:367] drop12 -> poolcp6 (in-place)
I1021 16:54:26.429020 14900 net.cpp:122] Setting up drop12
I1021 16:54:26.429020 14900 net.cpp:129] Top shape: 100 90 1 1 (9000)
I1021 16:54:26.429020 14900 net.cpp:137] Memory required for data: 359380400
I1021 16:54:26.429020 14900 layer_factory.cpp:58] Creating layer ip1
I1021 16:54:26.429020 14900 net.cpp:84] Creating Layer ip1
I1021 16:54:26.430022 14900 net.cpp:406] ip1 <- poolcp6
I1021 16:54:26.430022 14900 net.cpp:380] ip1 -> ip1
I1021 16:54:26.430022 14900 net.cpp:122] Setting up ip1
I1021 16:54:26.430022 14900 net.cpp:129] Top shape: 100 10 (1000)
I1021 16:54:26.430022 14900 net.cpp:137] Memory required for data: 359384400
I1021 16:54:26.430022 14900 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I1021 16:54:26.430022 14900 net.cpp:84] Creating Layer ip1_ip1_0_split
I1021 16:54:26.430022 14900 net.cpp:406] ip1_ip1_0_split <- ip1
I1021 16:54:26.430022 14900 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1021 16:54:26.430022 14900 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1021 16:54:26.430022 14900 net.cpp:122] Setting up ip1_ip1_0_split
I1021 16:54:26.430022 14900 net.cpp:129] Top shape: 100 10 (1000)
I1021 16:54:26.430022 14900 net.cpp:129] Top shape: 100 10 (1000)
I1021 16:54:26.430022 14900 net.cpp:137] Memory required for data: 359392400
I1021 16:54:26.430022 14900 layer_factory.cpp:58] Creating layer accuracy
I1021 16:54:26.430022 14900 net.cpp:84] Creating Layer accuracy
I1021 16:54:26.430022 14900 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I1021 16:54:26.430022 14900 net.cpp:406] accuracy <- label_mnist_1_split_0
I1021 16:54:26.430022 14900 net.cpp:380] accuracy -> accuracy
I1021 16:54:26.430022 14900 net.cpp:122] Setting up accuracy
I1021 16:54:26.430022 14900 net.cpp:129] Top shape: (1)
I1021 16:54:26.430022 14900 net.cpp:137] Memory required for data: 359392404
I1021 16:54:26.430022 14900 layer_factory.cpp:58] Creating layer loss
I1021 16:54:26.430022 14900 net.cpp:84] Creating Layer loss
I1021 16:54:26.430022 14900 net.cpp:406] loss <- ip1_ip1_0_split_1
I1021 16:54:26.430022 14900 net.cpp:406] loss <- label_mnist_1_split_1
I1021 16:54:26.430022 14900 net.cpp:380] loss -> loss
I1021 16:54:26.430022 14900 layer_factory.cpp:58] Creating layer loss
I1021 16:54:26.430022 14900 net.cpp:122] Setting up loss
I1021 16:54:26.430022 14900 net.cpp:129] Top shape: (1)
I1021 16:54:26.430022 14900 net.cpp:132]     with loss weight 1
I1021 16:54:26.430022 14900 net.cpp:137] Memory required for data: 359392408
I1021 16:54:26.430022 14900 net.cpp:198] loss needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:200] accuracy does not need backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] ip1_ip1_0_split needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] ip1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] drop12 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] poolcp6 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu_conv12 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale_conv12 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn_conv12 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv12 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu_conv11 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale_conv11 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn_conv11 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv11 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu4_0 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale4_0 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn4_0 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv4_0 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] drop9 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] pool4_2 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu4_2 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale4_2 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn4_2 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv4_2 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu4_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale4_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn4_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv4_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu4 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale4 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn4 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv4 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu3_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale3_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn3_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv3_1 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] relu3 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] scale3 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] bn3 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] conv3 needs backward computation.
I1021 16:54:26.430022 14900 net.cpp:198] drop5 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] pool2_1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] relu2_2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] scale2_2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] bn2_2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] conv2_2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] relu2_1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] scale2_1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] bn2_1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] conv2_1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] relu2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] scale2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] bn2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] conv2 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] relu1_0 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] scale1_0 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] bn1_0 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] conv1_0 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] relu1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] scale1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] bn1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:198] conv1 needs backward computation.
I1021 16:54:26.431021 14900 net.cpp:200] label_mnist_1_split does not need backward computation.
I1021 16:54:26.431021 14900 net.cpp:200] mnist does not need backward computation.
I1021 16:54:26.431021 14900 net.cpp:242] This network produces output accuracy
I1021 16:54:26.431021 14900 net.cpp:242] This network produces output loss
I1021 16:54:26.431021 14900 net.cpp:255] Network initialization done.
I1021 16:54:26.431021 14900 solver.cpp:56] Solver scaffolding done.
I1021 16:54:26.435020 14900 caffe.cpp:249] Starting Optimization
I1021 16:54:26.435020 14900 solver.cpp:272] Solving MNIST_SimpleNet_GP_13L_Simple_NoGrpCon_NoDrp_maxdrp_300k
I1021 16:54:26.435020 14900 solver.cpp:273] Learning Rate Policy: multistep
I1021 16:54:26.437021 14900 solver.cpp:330] Iteration 0, Testing net (#0)
I1021 16:54:26.438019 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:54:27.541005 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:54:27.585036 14900 solver.cpp:397]     Test net output #0: accuracy = 0.1032
I1021 16:54:27.585036 14900 solver.cpp:397]     Test net output #1: loss = 78.3234 (* 1 = 78.3234 loss)
I1021 16:54:27.683740 14900 solver.cpp:218] Iteration 0 (0 iter/s, 1.24758s/100 iters), loss = 4.38969
I1021 16:54:27.683740 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.08
I1021 16:54:27.683740 14900 solver.cpp:237]     Train net output #1: loss = 4.38969 (* 1 = 4.38969 loss)
I1021 16:54:27.683740 14900 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1021 16:54:32.233647 14900 solver.cpp:218] Iteration 100 (21.9801 iter/s, 4.54958s/100 iters), loss = 0.241712
I1021 16:54:32.233647 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I1021 16:54:32.233647 14900 solver.cpp:237]     Train net output #1: loss = 0.241712 (* 1 = 0.241712 loss)
I1021 16:54:32.233647 14900 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1021 16:54:36.769793 14900 solver.cpp:218] Iteration 200 (22.0454 iter/s, 4.53609s/100 iters), loss = 0.17372
I1021 16:54:36.769793 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I1021 16:54:36.769793 14900 solver.cpp:237]     Train net output #1: loss = 0.17372 (* 1 = 0.17372 loss)
I1021 16:54:36.769793 14900 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1021 16:54:41.300262 14900 solver.cpp:218] Iteration 300 (22.0718 iter/s, 4.53067s/100 iters), loss = 0.0677184
I1021 16:54:41.300262 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:54:41.301249 14900 solver.cpp:237]     Train net output #1: loss = 0.0677184 (* 1 = 0.0677184 loss)
I1021 16:54:41.301249 14900 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1021 16:54:45.863937 14900 solver.cpp:218] Iteration 400 (21.9171 iter/s, 4.56265s/100 iters), loss = 0.0989262
I1021 16:54:45.863937 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1021 16:54:45.863937 14900 solver.cpp:237]     Train net output #1: loss = 0.0989263 (* 1 = 0.0989263 loss)
I1021 16:54:45.863937 14900 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1021 16:54:50.404047 14900 solver.cpp:218] Iteration 500 (22.0291 iter/s, 4.53945s/100 iters), loss = 0.0962742
I1021 16:54:50.404047 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:54:50.404047 14900 solver.cpp:237]     Train net output #1: loss = 0.0962743 (* 1 = 0.0962743 loss)
I1021 16:54:50.404047 14900 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1021 16:54:54.720306  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:54:54.899313 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_600.caffemodel
I1021 16:54:54.917315 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_600.solverstate
I1021 16:54:54.921315 14900 solver.cpp:330] Iteration 600, Testing net (#0)
I1021 16:54:54.921315 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:54:55.984381 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:54:56.028370 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9627
I1021 16:54:56.028370 14900 solver.cpp:397]     Test net output #1: loss = 0.147156 (* 1 = 0.147156 loss)
I1021 16:54:56.071382 14900 solver.cpp:218] Iteration 600 (17.6453 iter/s, 5.66722s/100 iters), loss = 0.0886983
I1021 16:54:56.071382 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I1021 16:54:56.071382 14900 solver.cpp:237]     Train net output #1: loss = 0.0886983 (* 1 = 0.0886983 loss)
I1021 16:54:56.071382 14900 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1021 16:55:00.615687 14900 solver.cpp:218] Iteration 700 (22.0083 iter/s, 4.54374s/100 iters), loss = 0.118614
I1021 16:55:00.615687 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1021 16:55:00.615687 14900 solver.cpp:237]     Train net output #1: loss = 0.118614 (* 1 = 0.118614 loss)
I1021 16:55:00.615687 14900 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1021 16:55:05.156011 14900 solver.cpp:218] Iteration 800 (22.0245 iter/s, 4.54039s/100 iters), loss = 0.0751481
I1021 16:55:05.156011 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1021 16:55:05.156011 14900 solver.cpp:237]     Train net output #1: loss = 0.0751481 (* 1 = 0.0751481 loss)
I1021 16:55:05.156011 14900 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1021 16:55:09.706362 14900 solver.cpp:218] Iteration 900 (21.9788 iter/s, 4.54985s/100 iters), loss = 0.0178092
I1021 16:55:09.706362 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:55:09.706362 14900 solver.cpp:237]     Train net output #1: loss = 0.0178093 (* 1 = 0.0178093 loss)
I1021 16:55:09.706362 14900 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1021 16:55:14.262621 14900 solver.cpp:218] Iteration 1000 (21.9492 iter/s, 4.55596s/100 iters), loss = 0.0411682
I1021 16:55:14.262621 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:55:14.262621 14900 solver.cpp:237]     Train net output #1: loss = 0.0411683 (* 1 = 0.0411683 loss)
I1021 16:55:14.262621 14900 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1021 16:55:18.812961 14900 solver.cpp:218] Iteration 1100 (21.9786 iter/s, 4.54987s/100 iters), loss = 0.0269553
I1021 16:55:18.812961 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:55:18.812961 14900 solver.cpp:237]     Train net output #1: loss = 0.0269553 (* 1 = 0.0269553 loss)
I1021 16:55:18.812961 14900 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1021 16:55:23.153288  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:55:23.334321 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_1200.caffemodel
I1021 16:55:23.347321 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_1200.solverstate
I1021 16:55:23.351321 14900 solver.cpp:330] Iteration 1200, Testing net (#0)
I1021 16:55:23.351321 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:55:24.416445 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:55:24.460436 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9023
I1021 16:55:24.460436 14900 solver.cpp:397]     Test net output #1: loss = 0.307396 (* 1 = 0.307396 loss)
I1021 16:55:24.503448 14900 solver.cpp:218] Iteration 1200 (17.5734 iter/s, 5.69042s/100 iters), loss = 0.0728975
I1021 16:55:24.503448 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I1021 16:55:24.503448 14900 solver.cpp:237]     Train net output #1: loss = 0.0728976 (* 1 = 0.0728976 loss)
I1021 16:55:24.503448 14900 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1021 16:55:29.073794 14900 solver.cpp:218] Iteration 1300 (21.8847 iter/s, 4.5694s/100 iters), loss = 0.0247713
I1021 16:55:29.073794 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:55:29.073794 14900 solver.cpp:237]     Train net output #1: loss = 0.0247714 (* 1 = 0.0247714 loss)
I1021 16:55:29.073794 14900 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1021 16:55:33.640086 14900 solver.cpp:218] Iteration 1400 (21.9001 iter/s, 4.56618s/100 iters), loss = 0.0344526
I1021 16:55:33.640086 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:55:33.640086 14900 solver.cpp:237]     Train net output #1: loss = 0.0344527 (* 1 = 0.0344527 loss)
I1021 16:55:33.640086 14900 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1021 16:55:38.203410 14900 solver.cpp:218] Iteration 1500 (21.9172 iter/s, 4.56263s/100 iters), loss = 0.0103467
I1021 16:55:38.203410 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:55:38.203410 14900 solver.cpp:237]     Train net output #1: loss = 0.0103468 (* 1 = 0.0103468 loss)
I1021 16:55:38.203410 14900 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1021 16:55:42.771772 14900 solver.cpp:218] Iteration 1600 (21.8922 iter/s, 4.56784s/100 iters), loss = 0.0277638
I1021 16:55:42.771772 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:55:42.771772 14900 solver.cpp:237]     Train net output #1: loss = 0.0277638 (* 1 = 0.0277638 loss)
I1021 16:55:42.771772 14900 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1021 16:55:47.336060 14900 solver.cpp:218] Iteration 1700 (21.9113 iter/s, 4.56386s/100 iters), loss = 0.0218502
I1021 16:55:47.336060 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:55:47.336060 14900 solver.cpp:237]     Train net output #1: loss = 0.0218503 (* 1 = 0.0218503 loss)
I1021 16:55:47.336060 14900 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1021 16:55:51.677834  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:55:51.859341 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_1800.caffemodel
I1021 16:55:51.871345 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_1800.solverstate
I1021 16:55:51.875345 14900 solver.cpp:330] Iteration 1800, Testing net (#0)
I1021 16:55:51.875345 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:55:52.940452 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:55:52.984457 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9451
I1021 16:55:52.984457 14900 solver.cpp:397]     Test net output #1: loss = 0.201612 (* 1 = 0.201612 loss)
I1021 16:55:53.027458 14900 solver.cpp:218] Iteration 1800 (17.5705 iter/s, 5.69137s/100 iters), loss = 0.0517002
I1021 16:55:53.027458 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:55:53.027458 14900 solver.cpp:237]     Train net output #1: loss = 0.0517003 (* 1 = 0.0517003 loss)
I1021 16:55:53.027458 14900 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1021 16:55:57.586781 14900 solver.cpp:218] Iteration 1900 (21.9354 iter/s, 4.55884s/100 iters), loss = 0.0351333
I1021 16:55:57.586781 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:55:57.586781 14900 solver.cpp:237]     Train net output #1: loss = 0.0351333 (* 1 = 0.0351333 loss)
I1021 16:55:57.586781 14900 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1021 16:56:02.144155 14900 solver.cpp:218] Iteration 2000 (21.9439 iter/s, 4.55707s/100 iters), loss = 0.0353949
I1021 16:56:02.144155 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:56:02.144155 14900 solver.cpp:237]     Train net output #1: loss = 0.0353949 (* 1 = 0.0353949 loss)
I1021 16:56:02.144155 14900 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1021 16:56:06.697489 14900 solver.cpp:218] Iteration 2100 (21.9655 iter/s, 4.5526s/100 iters), loss = 0.0335405
I1021 16:56:06.697489 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:06.697489 14900 solver.cpp:237]     Train net output #1: loss = 0.0335405 (* 1 = 0.0335405 loss)
I1021 16:56:06.697489 14900 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1021 16:56:11.258663 14900 solver.cpp:218] Iteration 2200 (21.9234 iter/s, 4.56134s/100 iters), loss = 0.0268808
I1021 16:56:11.258663 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:11.258663 14900 solver.cpp:237]     Train net output #1: loss = 0.0268809 (* 1 = 0.0268809 loss)
I1021 16:56:11.258663 14900 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1021 16:56:15.820999 14900 solver.cpp:218] Iteration 2300 (21.9213 iter/s, 4.56178s/100 iters), loss = 0.0325802
I1021 16:56:15.820999 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:56:15.820999 14900 solver.cpp:237]     Train net output #1: loss = 0.0325802 (* 1 = 0.0325802 loss)
I1021 16:56:15.820999 14900 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1021 16:56:20.159319  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:56:20.339329 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_2400.caffemodel
I1021 16:56:20.353332 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_2400.solverstate
I1021 16:56:20.357331 14900 solver.cpp:330] Iteration 2400, Testing net (#0)
I1021 16:56:20.357331 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:56:21.424408 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:56:21.467407 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9373
I1021 16:56:21.468407 14900 solver.cpp:397]     Test net output #1: loss = 0.222489 (* 1 = 0.222489 loss)
I1021 16:56:21.510413 14900 solver.cpp:218] Iteration 2400 (17.5776 iter/s, 5.68906s/100 iters), loss = 0.0366224
I1021 16:56:21.510413 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:21.510413 14900 solver.cpp:237]     Train net output #1: loss = 0.0366225 (* 1 = 0.0366225 loss)
I1021 16:56:21.510413 14900 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1021 16:56:26.073207 14900 solver.cpp:218] Iteration 2500 (21.921 iter/s, 4.56184s/100 iters), loss = 0.0323243
I1021 16:56:26.073207 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:26.073207 14900 solver.cpp:237]     Train net output #1: loss = 0.0323243 (* 1 = 0.0323243 loss)
I1021 16:56:26.073207 14900 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1021 16:56:30.629977 14900 solver.cpp:218] Iteration 2600 (21.944 iter/s, 4.55706s/100 iters), loss = 0.0154521
I1021 16:56:30.629977 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:56:30.629977 14900 solver.cpp:237]     Train net output #1: loss = 0.0154521 (* 1 = 0.0154521 loss)
I1021 16:56:30.629977 14900 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1021 16:56:35.191298 14900 solver.cpp:218] Iteration 2700 (21.9282 iter/s, 4.56034s/100 iters), loss = 0.0258897
I1021 16:56:35.191298 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:35.191298 14900 solver.cpp:237]     Train net output #1: loss = 0.0258898 (* 1 = 0.0258898 loss)
I1021 16:56:35.191298 14900 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1021 16:56:39.750099 14900 solver.cpp:218] Iteration 2800 (21.9341 iter/s, 4.55911s/100 iters), loss = 0.0127881
I1021 16:56:39.750099 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:39.750099 14900 solver.cpp:237]     Train net output #1: loss = 0.0127882 (* 1 = 0.0127882 loss)
I1021 16:56:39.750099 14900 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1021 16:56:44.313529 14900 solver.cpp:218] Iteration 2900 (21.9147 iter/s, 4.56316s/100 iters), loss = 0.0299003
I1021 16:56:44.313529 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:44.313529 14900 solver.cpp:237]     Train net output #1: loss = 0.0299004 (* 1 = 0.0299004 loss)
I1021 16:56:44.313529 14900 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1021 16:56:48.647819  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:56:48.828827 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_3000.caffemodel
I1021 16:56:48.840827 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_3000.solverstate
I1021 16:56:48.844827 14900 solver.cpp:330] Iteration 3000, Testing net (#0)
I1021 16:56:48.844827 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:56:49.912948 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:56:49.956957 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9706
I1021 16:56:49.956957 14900 solver.cpp:397]     Test net output #1: loss = 0.120253 (* 1 = 0.120253 loss)
I1021 16:56:49.999956 14900 solver.cpp:218] Iteration 3000 (17.5882 iter/s, 5.68563s/100 iters), loss = 0.0128061
I1021 16:56:49.999956 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:56:49.999956 14900 solver.cpp:237]     Train net output #1: loss = 0.0128062 (* 1 = 0.0128062 loss)
I1021 16:56:49.999956 14900 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1021 16:56:54.559262 14900 solver.cpp:218] Iteration 3100 (21.9366 iter/s, 4.55859s/100 iters), loss = 0.0312608
I1021 16:56:54.559262 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:54.559262 14900 solver.cpp:237]     Train net output #1: loss = 0.0312609 (* 1 = 0.0312609 loss)
I1021 16:56:54.559262 14900 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1021 16:56:59.109592 14900 solver.cpp:218] Iteration 3200 (21.9773 iter/s, 4.55014s/100 iters), loss = 0.0184227
I1021 16:56:59.109592 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:56:59.109592 14900 solver.cpp:237]     Train net output #1: loss = 0.0184227 (* 1 = 0.0184227 loss)
I1021 16:56:59.109592 14900 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1021 16:57:03.666033 14900 solver.cpp:218] Iteration 3300 (21.9471 iter/s, 4.55642s/100 iters), loss = 0.0114431
I1021 16:57:03.666033 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:57:03.666033 14900 solver.cpp:237]     Train net output #1: loss = 0.0114432 (* 1 = 0.0114432 loss)
I1021 16:57:03.666033 14900 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1021 16:57:08.216344 14900 solver.cpp:218] Iteration 3400 (21.979 iter/s, 4.54981s/100 iters), loss = 0.0249951
I1021 16:57:08.216344 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:57:08.216344 14900 solver.cpp:237]     Train net output #1: loss = 0.0249952 (* 1 = 0.0249952 loss)
I1021 16:57:08.216344 14900 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1021 16:57:12.769738 14900 solver.cpp:218] Iteration 3500 (21.9642 iter/s, 4.55286s/100 iters), loss = 0.0179398
I1021 16:57:12.769738 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:57:12.769738 14900 solver.cpp:237]     Train net output #1: loss = 0.0179399 (* 1 = 0.0179399 loss)
I1021 16:57:12.769738 14900 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1021 16:57:17.108175  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:57:17.288681 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_3600.caffemodel
I1021 16:57:17.301184 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_3600.solverstate
I1021 16:57:17.305184 14900 solver.cpp:330] Iteration 3600, Testing net (#0)
I1021 16:57:17.305184 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:57:18.371243 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:57:18.415249 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9744
I1021 16:57:18.415249 14900 solver.cpp:397]     Test net output #1: loss = 0.101036 (* 1 = 0.101036 loss)
I1021 16:57:18.458248 14900 solver.cpp:218] Iteration 3600 (17.5802 iter/s, 5.6882s/100 iters), loss = 0.0143496
I1021 16:57:18.458248 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:57:18.458248 14900 solver.cpp:237]     Train net output #1: loss = 0.0143497 (* 1 = 0.0143497 loss)
I1021 16:57:18.458248 14900 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1021 16:57:23.023540 14900 solver.cpp:218] Iteration 3700 (21.9061 iter/s, 4.56493s/100 iters), loss = 0.0342423
I1021 16:57:23.023540 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:57:23.023540 14900 solver.cpp:237]     Train net output #1: loss = 0.0342424 (* 1 = 0.0342424 loss)
I1021 16:57:23.023540 14900 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1021 16:57:27.590988 14900 solver.cpp:218] Iteration 3800 (21.8974 iter/s, 4.56676s/100 iters), loss = 0.0132545
I1021 16:57:27.590988 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:57:27.590988 14900 solver.cpp:237]     Train net output #1: loss = 0.0132546 (* 1 = 0.0132546 loss)
I1021 16:57:27.590988 14900 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1021 16:57:32.146889 14900 solver.cpp:218] Iteration 3900 (21.954 iter/s, 4.55498s/100 iters), loss = 0.00781592
I1021 16:57:32.146889 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:57:32.146889 14900 solver.cpp:237]     Train net output #1: loss = 0.00781604 (* 1 = 0.00781604 loss)
I1021 16:57:32.146889 14900 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1021 16:57:36.703794 14900 solver.cpp:218] Iteration 4000 (21.9446 iter/s, 4.55693s/100 iters), loss = 0.0411735
I1021 16:57:36.703794 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:57:36.703794 14900 solver.cpp:237]     Train net output #1: loss = 0.0411737 (* 1 = 0.0411737 loss)
I1021 16:57:36.703794 14900 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1021 16:57:41.261585 14900 solver.cpp:218] Iteration 4100 (21.9424 iter/s, 4.55739s/100 iters), loss = 0.0153043
I1021 16:57:41.261585 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:57:41.262087 14900 solver.cpp:237]     Train net output #1: loss = 0.0153045 (* 1 = 0.0153045 loss)
I1021 16:57:41.262087 14900 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1021 16:57:45.598376  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:57:45.779368 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_4200.caffemodel
I1021 16:57:45.792388 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_4200.solverstate
I1021 16:57:45.796391 14900 solver.cpp:330] Iteration 4200, Testing net (#0)
I1021 16:57:45.796391 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:57:46.863481 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:57:46.906483 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9747
I1021 16:57:46.906483 14900 solver.cpp:397]     Test net output #1: loss = 0.11423 (* 1 = 0.11423 loss)
I1021 16:57:46.950485 14900 solver.cpp:218] Iteration 4200 (17.5806 iter/s, 5.68809s/100 iters), loss = 0.0452983
I1021 16:57:46.950485 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:57:46.950485 14900 solver.cpp:237]     Train net output #1: loss = 0.0452985 (* 1 = 0.0452985 loss)
I1021 16:57:46.950485 14900 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1021 16:57:51.507776 14900 solver.cpp:218] Iteration 4300 (21.9409 iter/s, 4.55769s/100 iters), loss = 0.0602163
I1021 16:57:51.507776 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:57:51.507776 14900 solver.cpp:237]     Train net output #1: loss = 0.0602164 (* 1 = 0.0602164 loss)
I1021 16:57:51.507776 14900 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1021 16:57:56.072244 14900 solver.cpp:218] Iteration 4400 (21.9102 iter/s, 4.56409s/100 iters), loss = 0.0618195
I1021 16:57:56.072244 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:57:56.072244 14900 solver.cpp:237]     Train net output #1: loss = 0.0618197 (* 1 = 0.0618197 loss)
I1021 16:57:56.072244 14900 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1021 16:58:00.632516 14900 solver.cpp:218] Iteration 4500 (21.9332 iter/s, 4.55929s/100 iters), loss = 0.0187879
I1021 16:58:00.632516 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:58:00.632516 14900 solver.cpp:237]     Train net output #1: loss = 0.018788 (* 1 = 0.018788 loss)
I1021 16:58:00.632516 14900 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1021 16:58:05.188766 14900 solver.cpp:218] Iteration 4600 (21.9497 iter/s, 4.55588s/100 iters), loss = 0.0116779
I1021 16:58:05.188766 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:58:05.188766 14900 solver.cpp:237]     Train net output #1: loss = 0.0116781 (* 1 = 0.0116781 loss)
I1021 16:58:05.188766 14900 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1021 16:58:09.743922 14900 solver.cpp:218] Iteration 4700 (21.9564 iter/s, 4.55448s/100 iters), loss = 0.0150175
I1021 16:58:09.743922 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:58:09.743922 14900 solver.cpp:237]     Train net output #1: loss = 0.0150177 (* 1 = 0.0150177 loss)
I1021 16:58:09.743922 14900 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1021 16:58:14.073196  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:58:14.255203 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_4800.caffemodel
I1021 16:58:14.268203 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_4800.solverstate
I1021 16:58:14.272207 14900 solver.cpp:330] Iteration 4800, Testing net (#0)
I1021 16:58:14.272207 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:58:15.338196 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:58:15.381191 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9685
I1021 16:58:15.381191 14900 solver.cpp:397]     Test net output #1: loss = 0.11261 (* 1 = 0.11261 loss)
I1021 16:58:15.424190 14900 solver.cpp:218] Iteration 4800 (17.6036 iter/s, 5.68066s/100 iters), loss = 0.0224817
I1021 16:58:15.424190 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:58:15.424190 14900 solver.cpp:237]     Train net output #1: loss = 0.0224819 (* 1 = 0.0224819 loss)
I1021 16:58:15.424190 14900 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1021 16:58:19.987000 14900 solver.cpp:218] Iteration 4900 (21.921 iter/s, 4.56183s/100 iters), loss = 0.0207046
I1021 16:58:19.987000 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:58:19.987000 14900 solver.cpp:237]     Train net output #1: loss = 0.0207048 (* 1 = 0.0207048 loss)
I1021 16:58:19.987000 14900 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1021 16:58:24.555296 14900 solver.cpp:218] Iteration 5000 (21.8912 iter/s, 4.56804s/100 iters), loss = 0.0332478
I1021 16:58:24.555296 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:58:24.555296 14900 solver.cpp:237]     Train net output #1: loss = 0.033248 (* 1 = 0.033248 loss)
I1021 16:58:24.555296 14900 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I1021 16:58:24.555296 14900 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1021 16:58:29.113903 14900 solver.cpp:218] Iteration 5100 (21.9378 iter/s, 4.55835s/100 iters), loss = 0.0316136
I1021 16:58:29.113903 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:58:29.113903 14900 solver.cpp:237]     Train net output #1: loss = 0.0316138 (* 1 = 0.0316138 loss)
I1021 16:58:29.113903 14900 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1021 16:58:33.682293 14900 solver.cpp:218] Iteration 5200 (21.8935 iter/s, 4.56756s/100 iters), loss = 0.0053485
I1021 16:58:33.682293 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:58:33.682293 14900 solver.cpp:237]     Train net output #1: loss = 0.00534869 (* 1 = 0.00534869 loss)
I1021 16:58:33.682293 14900 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1021 16:58:38.246675 14900 solver.cpp:218] Iteration 5300 (21.9092 iter/s, 4.56429s/100 iters), loss = 0.00435018
I1021 16:58:38.246675 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:58:38.246675 14900 solver.cpp:237]     Train net output #1: loss = 0.00435038 (* 1 = 0.00435038 loss)
I1021 16:58:38.246675 14900 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1021 16:58:42.584412  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:58:42.766417 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_5400.caffemodel
I1021 16:58:42.778420 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_5400.solverstate
I1021 16:58:42.782420 14900 solver.cpp:330] Iteration 5400, Testing net (#0)
I1021 16:58:42.782420 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:58:43.849524 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:58:43.892537 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9959
I1021 16:58:43.892537 14900 solver.cpp:397]     Test net output #1: loss = 0.0126537 (* 1 = 0.0126537 loss)
I1021 16:58:43.935536 14900 solver.cpp:218] Iteration 5400 (17.5783 iter/s, 5.68882s/100 iters), loss = 0.00481035
I1021 16:58:43.935536 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:58:43.935536 14900 solver.cpp:237]     Train net output #1: loss = 0.00481053 (* 1 = 0.00481053 loss)
I1021 16:58:43.935536 14900 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1021 16:58:48.497885 14900 solver.cpp:218] Iteration 5500 (21.9238 iter/s, 4.56125s/100 iters), loss = 0.0285094
I1021 16:58:48.497885 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I1021 16:58:48.497885 14900 solver.cpp:237]     Train net output #1: loss = 0.0285096 (* 1 = 0.0285096 loss)
I1021 16:58:48.497885 14900 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1021 16:58:53.047191 14900 solver.cpp:218] Iteration 5600 (21.9824 iter/s, 4.54909s/100 iters), loss = 0.00738064
I1021 16:58:53.047191 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:58:53.047191 14900 solver.cpp:237]     Train net output #1: loss = 0.00738082 (* 1 = 0.00738082 loss)
I1021 16:58:53.047191 14900 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1021 16:58:57.601466 14900 solver.cpp:218] Iteration 5700 (21.957 iter/s, 4.55436s/100 iters), loss = 0.0311957
I1021 16:58:57.601466 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:58:57.601466 14900 solver.cpp:237]     Train net output #1: loss = 0.0311959 (* 1 = 0.0311959 loss)
I1021 16:58:57.601466 14900 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1021 16:59:02.159811 14900 solver.cpp:218] Iteration 5800 (21.9416 iter/s, 4.55754s/100 iters), loss = 0.00277139
I1021 16:59:02.159811 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:02.159811 14900 solver.cpp:237]     Train net output #1: loss = 0.00277158 (* 1 = 0.00277158 loss)
I1021 16:59:02.159811 14900 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1021 16:59:06.717294 14900 solver.cpp:218] Iteration 5900 (21.9438 iter/s, 4.5571s/100 iters), loss = 0.00267109
I1021 16:59:06.717294 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:06.717294 14900 solver.cpp:237]     Train net output #1: loss = 0.00267128 (* 1 = 0.00267128 loss)
I1021 16:59:06.717294 14900 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1021 16:59:11.048028  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:59:11.229043 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_6000.caffemodel
I1021 16:59:11.241034 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_6000.solverstate
I1021 16:59:11.245033 14900 solver.cpp:330] Iteration 6000, Testing net (#0)
I1021 16:59:11.245033 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:59:12.313185 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:59:12.357188 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9965
I1021 16:59:12.357188 14900 solver.cpp:397]     Test net output #1: loss = 0.0113505 (* 1 = 0.0113505 loss)
I1021 16:59:12.400190 14900 solver.cpp:218] Iteration 6000 (17.5968 iter/s, 5.68286s/100 iters), loss = 0.00376627
I1021 16:59:12.400190 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:12.400190 14900 solver.cpp:237]     Train net output #1: loss = 0.00376646 (* 1 = 0.00376646 loss)
I1021 16:59:12.400190 14900 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1021 16:59:16.971495 14900 solver.cpp:218] Iteration 6100 (21.8774 iter/s, 4.57093s/100 iters), loss = 0.0107004
I1021 16:59:16.971495 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:59:16.971495 14900 solver.cpp:237]     Train net output #1: loss = 0.0107006 (* 1 = 0.0107006 loss)
I1021 16:59:16.971495 14900 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1021 16:59:21.530849 14900 solver.cpp:218] Iteration 6200 (21.9386 iter/s, 4.55817s/100 iters), loss = 0.00463499
I1021 16:59:21.530849 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:21.530849 14900 solver.cpp:237]     Train net output #1: loss = 0.00463518 (* 1 = 0.00463518 loss)
I1021 16:59:21.530849 14900 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1021 16:59:26.090245 14900 solver.cpp:218] Iteration 6300 (21.9315 iter/s, 4.55964s/100 iters), loss = 0.0337343
I1021 16:59:26.090245 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:59:26.090245 14900 solver.cpp:237]     Train net output #1: loss = 0.0337344 (* 1 = 0.0337344 loss)
I1021 16:59:26.090245 14900 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1021 16:59:30.655608 14900 solver.cpp:218] Iteration 6400 (21.9062 iter/s, 4.56492s/100 iters), loss = 0.0108537
I1021 16:59:30.655608 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:59:30.655608 14900 solver.cpp:237]     Train net output #1: loss = 0.0108538 (* 1 = 0.0108538 loss)
I1021 16:59:30.655608 14900 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1021 16:59:35.213891 14900 solver.cpp:218] Iteration 6500 (21.9402 iter/s, 4.55785s/100 iters), loss = 0.00469714
I1021 16:59:35.213891 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:35.213891 14900 solver.cpp:237]     Train net output #1: loss = 0.00469731 (* 1 = 0.00469731 loss)
I1021 16:59:35.213891 14900 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1021 16:59:39.558223  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:59:39.738240 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_6600.caffemodel
I1021 16:59:39.751240 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_6600.solverstate
I1021 16:59:39.755240 14900 solver.cpp:330] Iteration 6600, Testing net (#0)
I1021 16:59:39.755240 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 16:59:40.819347 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 16:59:40.863364 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9967
I1021 16:59:40.863364 14900 solver.cpp:397]     Test net output #1: loss = 0.0115415 (* 1 = 0.0115415 loss)
I1021 16:59:40.906342 14900 solver.cpp:218] Iteration 6600 (17.5693 iter/s, 5.69175s/100 iters), loss = 0.00165595
I1021 16:59:40.906342 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:40.906342 14900 solver.cpp:237]     Train net output #1: loss = 0.00165611 (* 1 = 0.00165611 loss)
I1021 16:59:40.906342 14900 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1021 16:59:45.464682 14900 solver.cpp:218] Iteration 6700 (21.9371 iter/s, 4.55849s/100 iters), loss = 0.0141298
I1021 16:59:45.464682 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:59:45.464682 14900 solver.cpp:237]     Train net output #1: loss = 0.01413 (* 1 = 0.01413 loss)
I1021 16:59:45.464682 14900 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1021 16:59:50.026087 14900 solver.cpp:218] Iteration 6800 (21.9283 iter/s, 4.56031s/100 iters), loss = 0.0049336
I1021 16:59:50.026087 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:50.026087 14900 solver.cpp:237]     Train net output #1: loss = 0.00493376 (* 1 = 0.00493376 loss)
I1021 16:59:50.026087 14900 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1021 16:59:54.592480 14900 solver.cpp:218] Iteration 6900 (21.8981 iter/s, 4.56661s/100 iters), loss = 0.0130412
I1021 16:59:54.592480 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 16:59:54.592480 14900 solver.cpp:237]     Train net output #1: loss = 0.0130414 (* 1 = 0.0130414 loss)
I1021 16:59:54.592480 14900 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1021 16:59:59.163796 14900 solver.cpp:218] Iteration 7000 (21.8773 iter/s, 4.57094s/100 iters), loss = 0.00212784
I1021 16:59:59.163796 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 16:59:59.163796 14900 solver.cpp:237]     Train net output #1: loss = 0.00212799 (* 1 = 0.00212799 loss)
I1021 16:59:59.163796 14900 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1021 17:00:03.758190 14900 solver.cpp:218] Iteration 7100 (21.7713 iter/s, 4.59319s/100 iters), loss = 0.00385432
I1021 17:00:03.758190 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:03.758190 14900 solver.cpp:237]     Train net output #1: loss = 0.00385447 (* 1 = 0.00385447 loss)
I1021 17:00:03.758190 14900 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1021 17:00:08.097982  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:00:08.280990 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_7200.caffemodel
I1021 17:00:08.292990 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_7200.solverstate
I1021 17:00:08.298991 14900 solver.cpp:330] Iteration 7200, Testing net (#0)
I1021 17:00:08.298991 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:00:09.365176 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:00:09.409176 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9968
I1021 17:00:09.409176 14900 solver.cpp:397]     Test net output #1: loss = 0.0118479 (* 1 = 0.0118479 loss)
I1021 17:00:09.452178 14900 solver.cpp:218] Iteration 7200 (17.5629 iter/s, 5.69381s/100 iters), loss = 0.00417626
I1021 17:00:09.452178 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:09.452178 14900 solver.cpp:237]     Train net output #1: loss = 0.00417641 (* 1 = 0.00417641 loss)
I1021 17:00:09.452178 14900 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1021 17:00:14.010462 14900 solver.cpp:218] Iteration 7300 (21.9389 iter/s, 4.55811s/100 iters), loss = 0.00982892
I1021 17:00:14.010462 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:14.010462 14900 solver.cpp:237]     Train net output #1: loss = 0.00982906 (* 1 = 0.00982906 loss)
I1021 17:00:14.010462 14900 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1021 17:00:18.562777 14900 solver.cpp:218] Iteration 7400 (21.971 iter/s, 4.55145s/100 iters), loss = 0.00940588
I1021 17:00:18.562777 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:18.562777 14900 solver.cpp:237]     Train net output #1: loss = 0.00940603 (* 1 = 0.00940603 loss)
I1021 17:00:18.562777 14900 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1021 17:00:23.114099 14900 solver.cpp:218] Iteration 7500 (21.9708 iter/s, 4.5515s/100 iters), loss = 0.0194835
I1021 17:00:23.114099 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:00:23.114099 14900 solver.cpp:237]     Train net output #1: loss = 0.0194836 (* 1 = 0.0194836 loss)
I1021 17:00:23.114099 14900 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1021 17:00:27.672461 14900 solver.cpp:218] Iteration 7600 (21.9402 iter/s, 4.55784s/100 iters), loss = 0.00692944
I1021 17:00:27.672461 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:27.672461 14900 solver.cpp:237]     Train net output #1: loss = 0.00692957 (* 1 = 0.00692957 loss)
I1021 17:00:27.672461 14900 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1021 17:00:32.238070 14900 solver.cpp:218] Iteration 7700 (21.9026 iter/s, 4.56568s/100 iters), loss = 0.00334797
I1021 17:00:32.239070 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:32.239070 14900 solver.cpp:237]     Train net output #1: loss = 0.00334811 (* 1 = 0.00334811 loss)
I1021 17:00:32.239070 14900 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1021 17:00:36.582667  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:00:36.762678 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_7800.caffemodel
I1021 17:00:36.775678 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_7800.solverstate
I1021 17:00:36.779678 14900 solver.cpp:330] Iteration 7800, Testing net (#0)
I1021 17:00:36.779678 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:00:37.845764 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:00:37.889783 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9973
I1021 17:00:37.889783 14900 solver.cpp:397]     Test net output #1: loss = 0.0107667 (* 1 = 0.0107667 loss)
I1021 17:00:37.931777 14900 solver.cpp:218] Iteration 7800 (17.5647 iter/s, 5.69324s/100 iters), loss = 0.00333987
I1021 17:00:37.932776 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:37.932776 14900 solver.cpp:237]     Train net output #1: loss = 0.00334001 (* 1 = 0.00334001 loss)
I1021 17:00:37.932776 14900 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1021 17:00:42.480110 14900 solver.cpp:218] Iteration 7900 (21.9892 iter/s, 4.54769s/100 iters), loss = 0.0170396
I1021 17:00:42.480110 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:00:42.480110 14900 solver.cpp:237]     Train net output #1: loss = 0.0170398 (* 1 = 0.0170398 loss)
I1021 17:00:42.480110 14900 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1021 17:00:47.029392 14900 solver.cpp:218] Iteration 8000 (21.9858 iter/s, 4.54838s/100 iters), loss = 0.0127483
I1021 17:00:47.029392 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:47.029392 14900 solver.cpp:237]     Train net output #1: loss = 0.0127485 (* 1 = 0.0127485 loss)
I1021 17:00:47.029392 14900 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1021 17:00:51.587676 14900 solver.cpp:218] Iteration 8100 (21.9405 iter/s, 4.55779s/100 iters), loss = 0.00672366
I1021 17:00:51.587676 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:51.587676 14900 solver.cpp:237]     Train net output #1: loss = 0.0067238 (* 1 = 0.0067238 loss)
I1021 17:00:51.587676 14900 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1021 17:00:56.147131 14900 solver.cpp:218] Iteration 8200 (21.9337 iter/s, 4.55919s/100 iters), loss = 0.000860188
I1021 17:00:56.147131 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:00:56.147131 14900 solver.cpp:237]     Train net output #1: loss = 0.000860325 (* 1 = 0.000860325 loss)
I1021 17:00:56.147131 14900 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1021 17:01:00.705539 14900 solver.cpp:218] Iteration 8300 (21.9394 iter/s, 4.55801s/100 iters), loss = 0.00289431
I1021 17:01:00.705539 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:00.705539 14900 solver.cpp:237]     Train net output #1: loss = 0.00289446 (* 1 = 0.00289446 loss)
I1021 17:01:00.705539 14900 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1021 17:01:05.035876  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:01:05.216886 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_8400.caffemodel
I1021 17:01:05.228886 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_8400.solverstate
I1021 17:01:05.232887 14900 solver.cpp:330] Iteration 8400, Testing net (#0)
I1021 17:01:05.232887 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:01:06.298954 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:01:06.341953 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9964
I1021 17:01:06.342953 14900 solver.cpp:397]     Test net output #1: loss = 0.0119375 (* 1 = 0.0119375 loss)
I1021 17:01:06.384973 14900 solver.cpp:218] Iteration 8400 (17.6065 iter/s, 5.67973s/100 iters), loss = 0.0041009
I1021 17:01:06.384973 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:06.385972 14900 solver.cpp:237]     Train net output #1: loss = 0.00410104 (* 1 = 0.00410104 loss)
I1021 17:01:06.385972 14900 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1021 17:01:10.944981 14900 solver.cpp:218] Iteration 8500 (21.9337 iter/s, 4.5592s/100 iters), loss = 0.0155387
I1021 17:01:10.944981 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:01:10.944981 14900 solver.cpp:237]     Train net output #1: loss = 0.0155389 (* 1 = 0.0155389 loss)
I1021 17:01:10.944981 14900 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1021 17:01:15.499961 14900 solver.cpp:218] Iteration 8600 (21.9554 iter/s, 4.55469s/100 iters), loss = 0.00760176
I1021 17:01:15.499961 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:15.499961 14900 solver.cpp:237]     Train net output #1: loss = 0.00760191 (* 1 = 0.00760191 loss)
I1021 17:01:15.499961 14900 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1021 17:01:20.058657 14900 solver.cpp:218] Iteration 8700 (21.9405 iter/s, 4.55777s/100 iters), loss = 0.00810028
I1021 17:01:20.058657 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:20.058657 14900 solver.cpp:237]     Train net output #1: loss = 0.00810044 (* 1 = 0.00810044 loss)
I1021 17:01:20.058657 14900 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1021 17:01:24.618621 14900 solver.cpp:218] Iteration 8800 (21.9319 iter/s, 4.55956s/100 iters), loss = 0.00129088
I1021 17:01:24.618621 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:24.618621 14900 solver.cpp:237]     Train net output #1: loss = 0.00129103 (* 1 = 0.00129103 loss)
I1021 17:01:24.618621 14900 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1021 17:01:29.180128 14900 solver.cpp:218] Iteration 8900 (21.9243 iter/s, 4.56116s/100 iters), loss = 0.00190804
I1021 17:01:29.180128 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:29.180128 14900 solver.cpp:237]     Train net output #1: loss = 0.0019082 (* 1 = 0.0019082 loss)
I1021 17:01:29.180128 14900 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1021 17:01:33.510442  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:01:33.692451 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_9000.caffemodel
I1021 17:01:33.704450 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_9000.solverstate
I1021 17:01:33.708451 14900 solver.cpp:330] Iteration 9000, Testing net (#0)
I1021 17:01:33.709451 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:01:34.776515 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:01:34.819514 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9968
I1021 17:01:34.819514 14900 solver.cpp:397]     Test net output #1: loss = 0.011357 (* 1 = 0.011357 loss)
I1021 17:01:34.863016 14900 solver.cpp:218] Iteration 9000 (17.5983 iter/s, 5.68237s/100 iters), loss = 0.00290786
I1021 17:01:34.863016 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:34.863016 14900 solver.cpp:237]     Train net output #1: loss = 0.00290803 (* 1 = 0.00290803 loss)
I1021 17:01:34.863016 14900 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1021 17:01:39.427825 14900 solver.cpp:218] Iteration 9100 (21.9067 iter/s, 4.56481s/100 iters), loss = 0.0161553
I1021 17:01:39.427825 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:01:39.427825 14900 solver.cpp:237]     Train net output #1: loss = 0.0161555 (* 1 = 0.0161555 loss)
I1021 17:01:39.427825 14900 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1021 17:01:43.996336 14900 solver.cpp:218] Iteration 9200 (21.891 iter/s, 4.56808s/100 iters), loss = 0.0151659
I1021 17:01:43.996336 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:43.996336 14900 solver.cpp:237]     Train net output #1: loss = 0.0151661 (* 1 = 0.0151661 loss)
I1021 17:01:43.996336 14900 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1021 17:01:48.562525 14900 solver.cpp:218] Iteration 9300 (21.9038 iter/s, 4.56542s/100 iters), loss = 0.0155259
I1021 17:01:48.562525 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:01:48.562525 14900 solver.cpp:237]     Train net output #1: loss = 0.0155261 (* 1 = 0.0155261 loss)
I1021 17:01:48.562525 14900 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1021 17:01:53.124409 14900 solver.cpp:218] Iteration 9400 (21.9197 iter/s, 4.5621s/100 iters), loss = 0.00221378
I1021 17:01:53.124409 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:53.124409 14900 solver.cpp:237]     Train net output #1: loss = 0.00221395 (* 1 = 0.00221395 loss)
I1021 17:01:53.124409 14900 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1021 17:01:57.691859 14900 solver.cpp:218] Iteration 9500 (21.8976 iter/s, 4.56671s/100 iters), loss = 0.00374133
I1021 17:01:57.691859 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:01:57.691859 14900 solver.cpp:237]     Train net output #1: loss = 0.0037415 (* 1 = 0.0037415 loss)
I1021 17:01:57.691859 14900 sgd_solver.cpp:46] MultiStep Status: Iteration 9500, step = 2
I1021 17:01:57.691859 14900 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1021 17:02:02.034119  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:02:02.215133 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_9600.caffemodel
I1021 17:02:02.227133 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_9600.solverstate
I1021 17:02:02.232133 14900 solver.cpp:330] Iteration 9600, Testing net (#0)
I1021 17:02:02.232133 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:02:03.298204 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:02:03.342193 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9969
I1021 17:02:03.342193 14900 solver.cpp:397]     Test net output #1: loss = 0.0107472 (* 1 = 0.0107472 loss)
I1021 17:02:03.385197 14900 solver.cpp:218] Iteration 9600 (17.5666 iter/s, 5.69262s/100 iters), loss = 0.00392562
I1021 17:02:03.385197 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:03.385197 14900 solver.cpp:237]     Train net output #1: loss = 0.0039258 (* 1 = 0.0039258 loss)
I1021 17:02:03.385197 14900 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I1021 17:02:07.948534 14900 solver.cpp:218] Iteration 9700 (21.9144 iter/s, 4.5632s/100 iters), loss = 0.0029581
I1021 17:02:07.948534 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:07.948534 14900 solver.cpp:237]     Train net output #1: loss = 0.00295828 (* 1 = 0.00295828 loss)
I1021 17:02:07.948534 14900 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I1021 17:02:12.510890 14900 solver.cpp:218] Iteration 9800 (21.9215 iter/s, 4.56173s/100 iters), loss = 0.00396761
I1021 17:02:12.510890 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:12.510890 14900 solver.cpp:237]     Train net output #1: loss = 0.00396779 (* 1 = 0.00396779 loss)
I1021 17:02:12.510890 14900 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I1021 17:02:17.063750 14900 solver.cpp:218] Iteration 9900 (21.9662 iter/s, 4.55245s/100 iters), loss = 0.00463639
I1021 17:02:17.063750 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:17.063750 14900 solver.cpp:237]     Train net output #1: loss = 0.00463657 (* 1 = 0.00463657 loss)
I1021 17:02:17.063750 14900 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I1021 17:02:21.624627 14900 solver.cpp:218] Iteration 10000 (21.927 iter/s, 4.5606s/100 iters), loss = 0.00212232
I1021 17:02:21.624627 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:21.624627 14900 solver.cpp:237]     Train net output #1: loss = 0.0021225 (* 1 = 0.0021225 loss)
I1021 17:02:21.624627 14900 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1021 17:02:26.172008 14900 solver.cpp:218] Iteration 10100 (21.9905 iter/s, 4.54741s/100 iters), loss = 0.002168
I1021 17:02:26.172008 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:26.172008 14900 solver.cpp:237]     Train net output #1: loss = 0.00216818 (* 1 = 0.00216818 loss)
I1021 17:02:26.172008 14900 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I1021 17:02:30.507361  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:02:30.688371 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_10200.caffemodel
I1021 17:02:30.704372 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_10200.solverstate
I1021 17:02:30.709372 14900 solver.cpp:330] Iteration 10200, Testing net (#0)
I1021 17:02:30.709372 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:02:31.773473 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:02:31.816471 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9972
I1021 17:02:31.817473 14900 solver.cpp:397]     Test net output #1: loss = 0.0101674 (* 1 = 0.0101674 loss)
I1021 17:02:31.859972 14900 solver.cpp:218] Iteration 10200 (17.5833 iter/s, 5.68722s/100 iters), loss = 0.00186105
I1021 17:02:31.859972 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:31.859972 14900 solver.cpp:237]     Train net output #1: loss = 0.00186123 (* 1 = 0.00186123 loss)
I1021 17:02:31.859972 14900 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I1021 17:02:36.420836 14900 solver.cpp:218] Iteration 10300 (21.9276 iter/s, 4.56046s/100 iters), loss = 0.0046697
I1021 17:02:36.420836 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:36.420836 14900 solver.cpp:237]     Train net output #1: loss = 0.00466989 (* 1 = 0.00466989 loss)
I1021 17:02:36.420836 14900 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I1021 17:02:40.986403 14900 solver.cpp:218] Iteration 10400 (21.906 iter/s, 4.56497s/100 iters), loss = 0.00538076
I1021 17:02:40.986403 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:40.986403 14900 solver.cpp:237]     Train net output #1: loss = 0.00538094 (* 1 = 0.00538094 loss)
I1021 17:02:40.986403 14900 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I1021 17:02:45.554635 14900 solver.cpp:218] Iteration 10500 (21.8915 iter/s, 4.56798s/100 iters), loss = 0.00295209
I1021 17:02:45.554635 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:45.554635 14900 solver.cpp:237]     Train net output #1: loss = 0.00295228 (* 1 = 0.00295228 loss)
I1021 17:02:45.554635 14900 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1021 17:02:50.117954 14900 solver.cpp:218] Iteration 10600 (21.9164 iter/s, 4.56279s/100 iters), loss = 0.00231221
I1021 17:02:50.117954 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:50.117954 14900 solver.cpp:237]     Train net output #1: loss = 0.0023124 (* 1 = 0.0023124 loss)
I1021 17:02:50.117954 14900 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I1021 17:02:54.684300 14900 solver.cpp:218] Iteration 10700 (21.8979 iter/s, 4.56665s/100 iters), loss = 0.00282829
I1021 17:02:54.684300 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:02:54.684300 14900 solver.cpp:237]     Train net output #1: loss = 0.00282848 (* 1 = 0.00282848 loss)
I1021 17:02:54.684300 14900 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I1021 17:02:59.024605  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:02:59.206612 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_10800.caffemodel
I1021 17:02:59.219612 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_10800.solverstate
I1021 17:02:59.223613 14900 solver.cpp:330] Iteration 10800, Testing net (#0)
I1021 17:02:59.223613 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:03:00.289758 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:03:00.333760 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9972
I1021 17:03:00.333760 14900 solver.cpp:397]     Test net output #1: loss = 0.0100409 (* 1 = 0.0100409 loss)
I1021 17:03:00.376762 14900 solver.cpp:218] Iteration 10800 (17.5688 iter/s, 5.69192s/100 iters), loss = 0.00570898
I1021 17:03:00.376762 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:00.376762 14900 solver.cpp:237]     Train net output #1: loss = 0.00570916 (* 1 = 0.00570916 loss)
I1021 17:03:00.376762 14900 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I1021 17:03:04.931057 14900 solver.cpp:218] Iteration 10900 (21.9594 iter/s, 4.55386s/100 iters), loss = 0.00387391
I1021 17:03:04.931057 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:04.931057 14900 solver.cpp:237]     Train net output #1: loss = 0.0038741 (* 1 = 0.0038741 loss)
I1021 17:03:04.931057 14900 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I1021 17:03:09.488379 14900 solver.cpp:218] Iteration 11000 (21.9465 iter/s, 4.55654s/100 iters), loss = 0.00574388
I1021 17:03:09.488379 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:09.488379 14900 solver.cpp:237]     Train net output #1: loss = 0.00574407 (* 1 = 0.00574407 loss)
I1021 17:03:09.488379 14900 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1021 17:03:14.041678 14900 solver.cpp:218] Iteration 11100 (21.9608 iter/s, 4.55356s/100 iters), loss = 0.030037
I1021 17:03:14.041678 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:03:14.041678 14900 solver.cpp:237]     Train net output #1: loss = 0.0300372 (* 1 = 0.0300372 loss)
I1021 17:03:14.041678 14900 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I1021 17:03:18.600015 14900 solver.cpp:218] Iteration 11200 (21.9436 iter/s, 4.55715s/100 iters), loss = 0.0012336
I1021 17:03:18.600015 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:18.600015 14900 solver.cpp:237]     Train net output #1: loss = 0.0012338 (* 1 = 0.0012338 loss)
I1021 17:03:18.600015 14900 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I1021 17:03:23.156225 14900 solver.cpp:218] Iteration 11300 (21.9492 iter/s, 4.55597s/100 iters), loss = 0.00447028
I1021 17:03:23.156225 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:23.156225 14900 solver.cpp:237]     Train net output #1: loss = 0.00447048 (* 1 = 0.00447048 loss)
I1021 17:03:23.156225 14900 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I1021 17:03:27.481601  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:03:27.665120 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_11400.caffemodel
I1021 17:03:27.676625 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_11400.solverstate
I1021 17:03:27.680624 14900 solver.cpp:330] Iteration 11400, Testing net (#0)
I1021 17:03:27.680624 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:03:28.744702 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:03:28.787708 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9972
I1021 17:03:28.787708 14900 solver.cpp:397]     Test net output #1: loss = 0.0100416 (* 1 = 0.0100416 loss)
I1021 17:03:28.830708 14900 solver.cpp:218] Iteration 11400 (17.6223 iter/s, 5.67464s/100 iters), loss = 0.00270632
I1021 17:03:28.830708 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:28.830708 14900 solver.cpp:237]     Train net output #1: loss = 0.00270651 (* 1 = 0.00270651 loss)
I1021 17:03:28.830708 14900 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I1021 17:03:33.405040 14900 solver.cpp:218] Iteration 11500 (21.8659 iter/s, 4.57334s/100 iters), loss = 0.00466363
I1021 17:03:33.405040 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:33.405040 14900 solver.cpp:237]     Train net output #1: loss = 0.00466383 (* 1 = 0.00466383 loss)
I1021 17:03:33.405040 14900 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1021 17:03:37.969885 14900 solver.cpp:218] Iteration 11600 (21.9072 iter/s, 4.56472s/100 iters), loss = 0.00912696
I1021 17:03:37.969885 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:37.969885 14900 solver.cpp:237]     Train net output #1: loss = 0.00912716 (* 1 = 0.00912716 loss)
I1021 17:03:37.969885 14900 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I1021 17:03:42.552685 14900 solver.cpp:218] Iteration 11700 (21.8214 iter/s, 4.58265s/100 iters), loss = 0.0119964
I1021 17:03:42.552685 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:42.552685 14900 solver.cpp:237]     Train net output #1: loss = 0.0119966 (* 1 = 0.0119966 loss)
I1021 17:03:42.552685 14900 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I1021 17:03:47.121369 14900 solver.cpp:218] Iteration 11800 (21.8921 iter/s, 4.56786s/100 iters), loss = 0.00222652
I1021 17:03:47.121369 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:47.121369 14900 solver.cpp:237]     Train net output #1: loss = 0.00222672 (* 1 = 0.00222672 loss)
I1021 17:03:47.121369 14900 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I1021 17:03:51.674736 14900 solver.cpp:218] Iteration 11900 (21.9625 iter/s, 4.55321s/100 iters), loss = 0.00196145
I1021 17:03:51.674736 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:51.675236 14900 solver.cpp:237]     Train net output #1: loss = 0.00196165 (* 1 = 0.00196165 loss)
I1021 17:03:51.675236 14900 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I1021 17:03:56.007040  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:03:56.187084 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_12000.caffemodel
I1021 17:03:56.201087 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_12000.solverstate
I1021 17:03:56.205087 14900 solver.cpp:330] Iteration 12000, Testing net (#0)
I1021 17:03:56.205087 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:03:57.270684 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:03:57.314175 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:03:57.314175 14900 solver.cpp:397]     Test net output #1: loss = 0.0100667 (* 1 = 0.0100667 loss)
I1021 17:03:57.358175 14900 solver.cpp:218] Iteration 12000 (17.5976 iter/s, 5.68258s/100 iters), loss = 0.00268504
I1021 17:03:57.358175 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:03:57.358175 14900 solver.cpp:237]     Train net output #1: loss = 0.00268523 (* 1 = 0.00268523 loss)
I1021 17:03:57.358175 14900 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1021 17:04:01.931470 14900 solver.cpp:218] Iteration 12100 (21.8654 iter/s, 4.57343s/100 iters), loss = 0.00768536
I1021 17:04:01.931470 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:01.931470 14900 solver.cpp:237]     Train net output #1: loss = 0.00768554 (* 1 = 0.00768554 loss)
I1021 17:04:01.931470 14900 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I1021 17:04:06.504956 14900 solver.cpp:218] Iteration 12200 (21.8688 iter/s, 4.57272s/100 iters), loss = 0.00413299
I1021 17:04:06.504956 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:06.504956 14900 solver.cpp:237]     Train net output #1: loss = 0.00413317 (* 1 = 0.00413317 loss)
I1021 17:04:06.504956 14900 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I1021 17:04:11.075254 14900 solver.cpp:218] Iteration 12300 (21.8823 iter/s, 4.56989s/100 iters), loss = 0.00879908
I1021 17:04:11.075254 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:11.075254 14900 solver.cpp:237]     Train net output #1: loss = 0.00879927 (* 1 = 0.00879927 loss)
I1021 17:04:11.075254 14900 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I1021 17:04:15.643556 14900 solver.cpp:218] Iteration 12400 (21.889 iter/s, 4.56851s/100 iters), loss = 0.00142724
I1021 17:04:15.643556 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:15.643556 14900 solver.cpp:237]     Train net output #1: loss = 0.00142742 (* 1 = 0.00142742 loss)
I1021 17:04:15.643556 14900 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I1021 17:04:20.207876 14900 solver.cpp:218] Iteration 12500 (21.913 iter/s, 4.56351s/100 iters), loss = 0.00129661
I1021 17:04:20.207876 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:20.207876 14900 solver.cpp:237]     Train net output #1: loss = 0.00129678 (* 1 = 0.00129678 loss)
I1021 17:04:20.207876 14900 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1021 17:04:24.548144  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:04:24.728164 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_12600.caffemodel
I1021 17:04:24.741164 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_12600.solverstate
I1021 17:04:24.745164 14900 solver.cpp:330] Iteration 12600, Testing net (#0)
I1021 17:04:24.745164 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:04:25.810271 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:04:25.854307 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:04:25.854307 14900 solver.cpp:397]     Test net output #1: loss = 0.0100551 (* 1 = 0.0100551 loss)
I1021 17:04:25.897306 14900 solver.cpp:218] Iteration 12600 (17.5777 iter/s, 5.68901s/100 iters), loss = 0.00390308
I1021 17:04:25.897306 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:25.897306 14900 solver.cpp:237]     Train net output #1: loss = 0.00390325 (* 1 = 0.00390325 loss)
I1021 17:04:25.897306 14900 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I1021 17:04:30.460661 14900 solver.cpp:218] Iteration 12700 (21.9148 iter/s, 4.56312s/100 iters), loss = 0.00432988
I1021 17:04:30.460661 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:30.460661 14900 solver.cpp:237]     Train net output #1: loss = 0.00433005 (* 1 = 0.00433005 loss)
I1021 17:04:30.460661 14900 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I1021 17:04:35.029964 14900 solver.cpp:218] Iteration 12800 (21.8876 iter/s, 4.5688s/100 iters), loss = 0.00588553
I1021 17:04:35.029964 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:35.030464 14900 solver.cpp:237]     Train net output #1: loss = 0.00588571 (* 1 = 0.00588571 loss)
I1021 17:04:35.030464 14900 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I1021 17:04:39.597260 14900 solver.cpp:218] Iteration 12900 (21.898 iter/s, 4.56663s/100 iters), loss = 0.00792602
I1021 17:04:39.597260 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:39.597260 14900 solver.cpp:237]     Train net output #1: loss = 0.00792618 (* 1 = 0.00792618 loss)
I1021 17:04:39.597260 14900 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I1021 17:04:44.157344 14900 solver.cpp:218] Iteration 13000 (21.9305 iter/s, 4.55986s/100 iters), loss = 0.00320755
I1021 17:04:44.157344 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:44.157344 14900 solver.cpp:237]     Train net output #1: loss = 0.00320772 (* 1 = 0.00320772 loss)
I1021 17:04:44.157344 14900 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1021 17:04:48.720968 14900 solver.cpp:218] Iteration 13100 (21.9153 iter/s, 4.56302s/100 iters), loss = 0.00171786
I1021 17:04:48.720968 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:48.720968 14900 solver.cpp:237]     Train net output #1: loss = 0.00171803 (* 1 = 0.00171803 loss)
I1021 17:04:48.720968 14900 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I1021 17:04:53.059294  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:04:53.241335 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_13200.caffemodel
I1021 17:04:53.253336 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_13200.solverstate
I1021 17:04:53.258342 14900 solver.cpp:330] Iteration 13200, Testing net (#0)
I1021 17:04:53.258342 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:04:54.324903 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:04:54.367403 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9968
I1021 17:04:54.367403 14900 solver.cpp:397]     Test net output #1: loss = 0.0100485 (* 1 = 0.0100485 loss)
I1021 17:04:54.410403 14900 solver.cpp:218] Iteration 13200 (17.5756 iter/s, 5.68971s/100 iters), loss = 0.00599379
I1021 17:04:54.410403 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:54.410403 14900 solver.cpp:237]     Train net output #1: loss = 0.00599396 (* 1 = 0.00599396 loss)
I1021 17:04:54.410403 14900 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I1021 17:04:58.968715 14900 solver.cpp:218] Iteration 13300 (21.9433 iter/s, 4.5572s/100 iters), loss = 0.00562442
I1021 17:04:58.968715 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:04:58.968715 14900 solver.cpp:237]     Train net output #1: loss = 0.00562459 (* 1 = 0.00562459 loss)
I1021 17:04:58.968715 14900 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I1021 17:05:03.539909 14900 solver.cpp:218] Iteration 13400 (21.8777 iter/s, 4.57086s/100 iters), loss = 0.0147026
I1021 17:05:03.539909 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:05:03.539909 14900 solver.cpp:237]     Train net output #1: loss = 0.0147028 (* 1 = 0.0147028 loss)
I1021 17:05:03.539909 14900 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I1021 17:05:08.100823 14900 solver.cpp:218] Iteration 13500 (21.9278 iter/s, 4.56042s/100 iters), loss = 0.0179279
I1021 17:05:08.100823 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:05:08.100823 14900 solver.cpp:237]     Train net output #1: loss = 0.0179281 (* 1 = 0.0179281 loss)
I1021 17:05:08.100823 14900 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1021 17:05:12.656741 14900 solver.cpp:218] Iteration 13600 (21.9487 iter/s, 4.55608s/100 iters), loss = 0.00566706
I1021 17:05:12.656741 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:12.656741 14900 solver.cpp:237]     Train net output #1: loss = 0.00566722 (* 1 = 0.00566722 loss)
I1021 17:05:12.656741 14900 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I1021 17:05:17.217386 14900 solver.cpp:218] Iteration 13700 (21.9292 iter/s, 4.56013s/100 iters), loss = 0.00155757
I1021 17:05:17.217386 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:17.217386 14900 solver.cpp:237]     Train net output #1: loss = 0.00155774 (* 1 = 0.00155774 loss)
I1021 17:05:17.217386 14900 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I1021 17:05:21.555694  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:05:21.737705 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_13800.caffemodel
I1021 17:05:21.749706 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_13800.solverstate
I1021 17:05:21.754706 14900 solver.cpp:330] Iteration 13800, Testing net (#0)
I1021 17:05:21.754706 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:05:22.819896 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:05:22.862890 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:05:22.862890 14900 solver.cpp:397]     Test net output #1: loss = 0.0100471 (* 1 = 0.0100471 loss)
I1021 17:05:22.906392 14900 solver.cpp:218] Iteration 13800 (17.5802 iter/s, 5.68823s/100 iters), loss = 0.00168508
I1021 17:05:22.906392 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:22.906392 14900 solver.cpp:237]     Train net output #1: loss = 0.00168525 (* 1 = 0.00168525 loss)
I1021 17:05:22.906392 14900 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I1021 17:05:27.473400 14900 solver.cpp:218] Iteration 13900 (21.8964 iter/s, 4.56696s/100 iters), loss = 0.00394718
I1021 17:05:27.473400 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:27.473400 14900 solver.cpp:237]     Train net output #1: loss = 0.00394735 (* 1 = 0.00394735 loss)
I1021 17:05:27.473400 14900 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I1021 17:05:32.040725 14900 solver.cpp:218] Iteration 14000 (21.8957 iter/s, 4.5671s/100 iters), loss = 0.00350679
I1021 17:05:32.040725 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:32.040725 14900 solver.cpp:237]     Train net output #1: loss = 0.00350696 (* 1 = 0.00350696 loss)
I1021 17:05:32.040725 14900 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I1021 17:05:36.606894 14900 solver.cpp:218] Iteration 14100 (21.9025 iter/s, 4.56569s/100 iters), loss = 0.0153617
I1021 17:05:36.607395 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:05:36.607395 14900 solver.cpp:237]     Train net output #1: loss = 0.0153618 (* 1 = 0.0153618 loss)
I1021 17:05:36.607395 14900 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I1021 17:05:41.176753 14900 solver.cpp:218] Iteration 14200 (21.8821 iter/s, 4.56995s/100 iters), loss = 0.00164837
I1021 17:05:41.177753 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:41.177753 14900 solver.cpp:237]     Train net output #1: loss = 0.00164854 (* 1 = 0.00164854 loss)
I1021 17:05:41.177753 14900 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I1021 17:05:45.738591 14900 solver.cpp:218] Iteration 14300 (21.9246 iter/s, 4.56109s/100 iters), loss = 0.00248777
I1021 17:05:45.738591 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:45.738591 14900 solver.cpp:237]     Train net output #1: loss = 0.00248794 (* 1 = 0.00248794 loss)
I1021 17:05:45.738591 14900 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I1021 17:05:50.074036  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:05:50.254045 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_14400.caffemodel
I1021 17:05:50.266046 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_14400.solverstate
I1021 17:05:50.270045 14900 solver.cpp:330] Iteration 14400, Testing net (#0)
I1021 17:05:50.270045 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:05:51.335160 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:05:51.378157 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:05:51.379159 14900 solver.cpp:397]     Test net output #1: loss = 0.0100148 (* 1 = 0.0100148 loss)
I1021 17:05:51.422163 14900 solver.cpp:218] Iteration 14400 (17.5977 iter/s, 5.68256s/100 iters), loss = 0.00406217
I1021 17:05:51.422163 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:05:51.422163 14900 solver.cpp:237]     Train net output #1: loss = 0.00406234 (* 1 = 0.00406234 loss)
I1021 17:05:51.422163 14900 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I1021 17:05:55.981463 14900 solver.cpp:218] Iteration 14500 (21.9346 iter/s, 4.55902s/100 iters), loss = 0.0102343
I1021 17:05:55.981463 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:05:55.981463 14900 solver.cpp:237]     Train net output #1: loss = 0.0102345 (* 1 = 0.0102345 loss)
I1021 17:05:55.981463 14900 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I1021 17:06:00.550771 14900 solver.cpp:218] Iteration 14600 (21.887 iter/s, 4.56893s/100 iters), loss = 0.00422338
I1021 17:06:00.550771 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:00.550771 14900 solver.cpp:237]     Train net output #1: loss = 0.00422355 (* 1 = 0.00422355 loss)
I1021 17:06:00.550771 14900 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I1021 17:06:05.115479 14900 solver.cpp:218] Iteration 14700 (21.9086 iter/s, 4.56442s/100 iters), loss = 0.0110159
I1021 17:06:05.115479 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:06:05.115479 14900 solver.cpp:237]     Train net output #1: loss = 0.0110161 (* 1 = 0.0110161 loss)
I1021 17:06:05.115479 14900 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I1021 17:06:09.673790 14900 solver.cpp:218] Iteration 14800 (21.9366 iter/s, 4.55859s/100 iters), loss = 0.00426212
I1021 17:06:09.673790 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:09.674790 14900 solver.cpp:237]     Train net output #1: loss = 0.00426229 (* 1 = 0.00426229 loss)
I1021 17:06:09.674790 14900 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I1021 17:06:14.236099 14900 solver.cpp:218] Iteration 14900 (21.9215 iter/s, 4.56173s/100 iters), loss = 0.00258118
I1021 17:06:14.236099 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:14.236099 14900 solver.cpp:237]     Train net output #1: loss = 0.00258135 (* 1 = 0.00258135 loss)
I1021 17:06:14.236099 14900 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I1021 17:06:18.572412  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:06:18.753429 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_15000.caffemodel
I1021 17:06:18.767422 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_15000.solverstate
I1021 17:06:18.771422 14900 solver.cpp:330] Iteration 15000, Testing net (#0)
I1021 17:06:18.771422 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:06:19.837591 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:06:19.881590 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9969
I1021 17:06:19.881590 14900 solver.cpp:397]     Test net output #1: loss = 0.0100082 (* 1 = 0.0100082 loss)
I1021 17:06:19.924594 14900 solver.cpp:218] Iteration 15000 (17.5811 iter/s, 5.68791s/100 iters), loss = 0.00275864
I1021 17:06:19.924594 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:19.924594 14900 solver.cpp:237]     Train net output #1: loss = 0.0027588 (* 1 = 0.0027588 loss)
I1021 17:06:19.924594 14900 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I1021 17:06:24.476955 14900 solver.cpp:218] Iteration 15100 (21.97 iter/s, 4.55165s/100 iters), loss = 0.00228187
I1021 17:06:24.476955 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:24.476955 14900 solver.cpp:237]     Train net output #1: loss = 0.00228204 (* 1 = 0.00228204 loss)
I1021 17:06:24.476955 14900 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I1021 17:06:29.034325 14900 solver.cpp:218] Iteration 15200 (21.9434 iter/s, 4.55718s/100 iters), loss = 0.00649198
I1021 17:06:29.034325 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:29.034325 14900 solver.cpp:237]     Train net output #1: loss = 0.00649215 (* 1 = 0.00649215 loss)
I1021 17:06:29.034325 14900 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I1021 17:06:33.601482 14900 solver.cpp:218] Iteration 15300 (21.8977 iter/s, 4.5667s/100 iters), loss = 0.00231333
I1021 17:06:33.601482 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:33.601482 14900 solver.cpp:237]     Train net output #1: loss = 0.0023135 (* 1 = 0.0023135 loss)
I1021 17:06:33.601482 14900 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I1021 17:06:38.162801 14900 solver.cpp:218] Iteration 15400 (21.9228 iter/s, 4.56145s/100 iters), loss = 0.00423226
I1021 17:06:38.162801 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:38.162801 14900 solver.cpp:237]     Train net output #1: loss = 0.00423243 (* 1 = 0.00423243 loss)
I1021 17:06:38.162801 14900 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I1021 17:06:42.728164 14900 solver.cpp:218] Iteration 15500 (21.9088 iter/s, 4.56438s/100 iters), loss = 0.00219264
I1021 17:06:42.728164 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:42.728164 14900 solver.cpp:237]     Train net output #1: loss = 0.00219281 (* 1 = 0.00219281 loss)
I1021 17:06:42.728164 14900 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I1021 17:06:47.068467  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:06:47.250516 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_15600.caffemodel
I1021 17:06:47.267518 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_15600.solverstate
I1021 17:06:47.271517 14900 solver.cpp:330] Iteration 15600, Testing net (#0)
I1021 17:06:47.271517 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:06:48.335584 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:06:48.379587 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:06:48.379587 14900 solver.cpp:397]     Test net output #1: loss = 0.0100328 (* 1 = 0.0100328 loss)
I1021 17:06:48.422585 14900 solver.cpp:218] Iteration 15600 (17.5624 iter/s, 5.69399s/100 iters), loss = 0.00268419
I1021 17:06:48.422585 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:48.422585 14900 solver.cpp:237]     Train net output #1: loss = 0.00268437 (* 1 = 0.00268437 loss)
I1021 17:06:48.422585 14900 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I1021 17:06:52.996173 14900 solver.cpp:218] Iteration 15700 (21.8654 iter/s, 4.57344s/100 iters), loss = 0.00400499
I1021 17:06:52.996173 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:06:52.996173 14900 solver.cpp:237]     Train net output #1: loss = 0.00400516 (* 1 = 0.00400516 loss)
I1021 17:06:52.996173 14900 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I1021 17:06:57.552264 14900 solver.cpp:218] Iteration 15800 (21.9526 iter/s, 4.55526s/100 iters), loss = 0.0166818
I1021 17:06:57.552264 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:06:57.552264 14900 solver.cpp:237]     Train net output #1: loss = 0.016682 (* 1 = 0.016682 loss)
I1021 17:06:57.552264 14900 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I1021 17:07:02.118456 14900 solver.cpp:218] Iteration 15900 (21.9018 iter/s, 4.56583s/100 iters), loss = 0.00974973
I1021 17:07:02.118456 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:07:02.118456 14900 solver.cpp:237]     Train net output #1: loss = 0.00974991 (* 1 = 0.00974991 loss)
I1021 17:07:02.118456 14900 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I1021 17:07:06.687697 14900 solver.cpp:218] Iteration 16000 (21.8857 iter/s, 4.5692s/100 iters), loss = 0.001056
I1021 17:07:06.687697 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:06.687697 14900 solver.cpp:237]     Train net output #1: loss = 0.00105618 (* 1 = 0.00105618 loss)
I1021 17:07:06.687697 14900 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I1021 17:07:11.265908 14900 solver.cpp:218] Iteration 16100 (21.8447 iter/s, 4.57777s/100 iters), loss = 0.00336123
I1021 17:07:11.265908 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:11.265908 14900 solver.cpp:237]     Train net output #1: loss = 0.00336142 (* 1 = 0.00336142 loss)
I1021 17:07:11.265908 14900 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I1021 17:07:15.609279  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:07:15.791293 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_16200.caffemodel
I1021 17:07:15.804293 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_16200.solverstate
I1021 17:07:15.808293 14900 solver.cpp:330] Iteration 16200, Testing net (#0)
I1021 17:07:15.808293 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:07:16.874351 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:07:16.918360 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9969
I1021 17:07:16.918360 14900 solver.cpp:397]     Test net output #1: loss = 0.00998733 (* 1 = 0.00998733 loss)
I1021 17:07:16.961355 14900 solver.cpp:218] Iteration 16200 (17.56 iter/s, 5.69477s/100 iters), loss = 0.00281169
I1021 17:07:16.961355 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:16.961355 14900 solver.cpp:237]     Train net output #1: loss = 0.00281187 (* 1 = 0.00281187 loss)
I1021 17:07:16.961355 14900 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I1021 17:07:21.513687 14900 solver.cpp:218] Iteration 16300 (21.969 iter/s, 4.55186s/100 iters), loss = 0.0037792
I1021 17:07:21.513687 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:21.513687 14900 solver.cpp:237]     Train net output #1: loss = 0.00377938 (* 1 = 0.00377938 loss)
I1021 17:07:21.513687 14900 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I1021 17:07:26.067019 14900 solver.cpp:218] Iteration 16400 (21.9619 iter/s, 4.55334s/100 iters), loss = 0.00815452
I1021 17:07:26.067019 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:26.067019 14900 solver.cpp:237]     Train net output #1: loss = 0.00815471 (* 1 = 0.00815471 loss)
I1021 17:07:26.067019 14900 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I1021 17:07:30.621377 14900 solver.cpp:218] Iteration 16500 (21.9576 iter/s, 4.55422s/100 iters), loss = 0.0131896
I1021 17:07:30.621377 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:07:30.621377 14900 solver.cpp:237]     Train net output #1: loss = 0.0131898 (* 1 = 0.0131898 loss)
I1021 17:07:30.621377 14900 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I1021 17:07:35.176321 14900 solver.cpp:218] Iteration 16600 (21.958 iter/s, 4.55414s/100 iters), loss = 0.00171639
I1021 17:07:35.176822 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:35.176822 14900 solver.cpp:237]     Train net output #1: loss = 0.00171657 (* 1 = 0.00171657 loss)
I1021 17:07:35.176822 14900 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I1021 17:07:39.729143 14900 solver.cpp:218] Iteration 16700 (21.966 iter/s, 4.55248s/100 iters), loss = 0.00165217
I1021 17:07:39.729143 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:39.729143 14900 solver.cpp:237]     Train net output #1: loss = 0.00165236 (* 1 = 0.00165236 loss)
I1021 17:07:39.729143 14900 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I1021 17:07:44.069453  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:07:44.251462 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_16800.caffemodel
I1021 17:07:44.263463 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_16800.solverstate
I1021 17:07:44.267463 14900 solver.cpp:330] Iteration 16800, Testing net (#0)
I1021 17:07:44.267463 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:07:45.331522 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:07:45.375527 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9969
I1021 17:07:45.375527 14900 solver.cpp:397]     Test net output #1: loss = 0.0100275 (* 1 = 0.0100275 loss)
I1021 17:07:45.418534 14900 solver.cpp:218] Iteration 16800 (17.5787 iter/s, 5.6887s/100 iters), loss = 0.001683
I1021 17:07:45.418534 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:45.418534 14900 solver.cpp:237]     Train net output #1: loss = 0.00168318 (* 1 = 0.00168318 loss)
I1021 17:07:45.418534 14900 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I1021 17:07:49.988842 14900 solver.cpp:218] Iteration 16900 (21.882 iter/s, 4.56996s/100 iters), loss = 0.00253573
I1021 17:07:49.988842 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:49.989343 14900 solver.cpp:237]     Train net output #1: loss = 0.00253593 (* 1 = 0.00253593 loss)
I1021 17:07:49.989343 14900 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I1021 17:07:54.559125 14900 solver.cpp:218] Iteration 17000 (21.8832 iter/s, 4.56972s/100 iters), loss = 0.00624323
I1021 17:07:54.559125 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:54.559125 14900 solver.cpp:237]     Train net output #1: loss = 0.00624343 (* 1 = 0.00624343 loss)
I1021 17:07:54.559125 14900 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I1021 17:07:59.129359 14900 solver.cpp:218] Iteration 17100 (21.8804 iter/s, 4.57029s/100 iters), loss = 0.00268804
I1021 17:07:59.129359 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:07:59.129359 14900 solver.cpp:237]     Train net output #1: loss = 0.00268823 (* 1 = 0.00268823 loss)
I1021 17:07:59.129359 14900 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I1021 17:08:03.703996 14900 solver.cpp:218] Iteration 17200 (21.8617 iter/s, 4.57421s/100 iters), loss = 0.00616174
I1021 17:08:03.703996 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:03.703996 14900 solver.cpp:237]     Train net output #1: loss = 0.00616194 (* 1 = 0.00616194 loss)
I1021 17:08:03.703996 14900 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I1021 17:08:08.271597 14900 solver.cpp:218] Iteration 17300 (21.8972 iter/s, 4.56679s/100 iters), loss = 0.00201535
I1021 17:08:08.271597 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:08.271597 14900 solver.cpp:237]     Train net output #1: loss = 0.00201555 (* 1 = 0.00201555 loss)
I1021 17:08:08.271597 14900 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I1021 17:08:12.620054  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:08:12.801048 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_17400.caffemodel
I1021 17:08:12.813047 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_17400.solverstate
I1021 17:08:12.817047 14900 solver.cpp:330] Iteration 17400, Testing net (#0)
I1021 17:08:12.817047 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:08:13.884645 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:08:13.927162 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9968
I1021 17:08:13.927162 14900 solver.cpp:397]     Test net output #1: loss = 0.0101236 (* 1 = 0.0101236 loss)
I1021 17:08:13.970155 14900 solver.cpp:218] Iteration 17400 (17.5477 iter/s, 5.69876s/100 iters), loss = 0.00361083
I1021 17:08:13.971154 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:13.971154 14900 solver.cpp:237]     Train net output #1: loss = 0.00361103 (* 1 = 0.00361103 loss)
I1021 17:08:13.971154 14900 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I1021 17:08:18.540518 14900 solver.cpp:218] Iteration 17500 (21.8838 iter/s, 4.56958s/100 iters), loss = 0.00547686
I1021 17:08:18.540518 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:18.540518 14900 solver.cpp:237]     Train net output #1: loss = 0.00547706 (* 1 = 0.00547706 loss)
I1021 17:08:18.540518 14900 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I1021 17:08:23.106842 14900 solver.cpp:218] Iteration 17600 (21.9005 iter/s, 4.56612s/100 iters), loss = 0.00383571
I1021 17:08:23.106842 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:23.106842 14900 solver.cpp:237]     Train net output #1: loss = 0.0038359 (* 1 = 0.0038359 loss)
I1021 17:08:23.106842 14900 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I1021 17:08:27.670192 14900 solver.cpp:218] Iteration 17700 (21.9145 iter/s, 4.56318s/100 iters), loss = 0.0100018
I1021 17:08:27.670192 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:08:27.671191 14900 solver.cpp:237]     Train net output #1: loss = 0.010002 (* 1 = 0.010002 loss)
I1021 17:08:27.671191 14900 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I1021 17:08:32.238600 14900 solver.cpp:218] Iteration 17800 (21.8952 iter/s, 4.5672s/100 iters), loss = 0.00186127
I1021 17:08:32.238600 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:32.238600 14900 solver.cpp:237]     Train net output #1: loss = 0.00186147 (* 1 = 0.00186147 loss)
I1021 17:08:32.238600 14900 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I1021 17:08:36.808972 14900 solver.cpp:218] Iteration 17900 (21.8799 iter/s, 4.57041s/100 iters), loss = 0.00415712
I1021 17:08:36.808972 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:36.808972 14900 solver.cpp:237]     Train net output #1: loss = 0.00415732 (* 1 = 0.00415732 loss)
I1021 17:08:36.808972 14900 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I1021 17:08:41.145328  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:08:41.326340 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_18000.caffemodel
I1021 17:08:41.343358 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_18000.solverstate
I1021 17:08:41.347358 14900 solver.cpp:330] Iteration 18000, Testing net (#0)
I1021 17:08:41.347358 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:08:42.413434 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:08:42.457433 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:08:42.457433 14900 solver.cpp:397]     Test net output #1: loss = 0.0100162 (* 1 = 0.0100162 loss)
I1021 17:08:42.500443 14900 solver.cpp:218] Iteration 18000 (17.5727 iter/s, 5.69065s/100 iters), loss = 0.00176767
I1021 17:08:42.500443 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:42.500443 14900 solver.cpp:237]     Train net output #1: loss = 0.00176788 (* 1 = 0.00176788 loss)
I1021 17:08:42.500443 14900 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I1021 17:08:47.066774 14900 solver.cpp:218] Iteration 18100 (21.8988 iter/s, 4.56645s/100 iters), loss = 0.013375
I1021 17:08:47.066774 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:08:47.066774 14900 solver.cpp:237]     Train net output #1: loss = 0.0133752 (* 1 = 0.0133752 loss)
I1021 17:08:47.066774 14900 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I1021 17:08:51.629478 14900 solver.cpp:218] Iteration 18200 (21.9205 iter/s, 4.56194s/100 iters), loss = 0.00570622
I1021 17:08:51.629478 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:51.629478 14900 solver.cpp:237]     Train net output #1: loss = 0.00570642 (* 1 = 0.00570642 loss)
I1021 17:08:51.629478 14900 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I1021 17:08:56.192627 14900 solver.cpp:218] Iteration 18300 (21.9152 iter/s, 4.56303s/100 iters), loss = 0.00904055
I1021 17:08:56.192627 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:08:56.192627 14900 solver.cpp:237]     Train net output #1: loss = 0.00904074 (* 1 = 0.00904074 loss)
I1021 17:08:56.192627 14900 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I1021 17:09:00.758038 14900 solver.cpp:218] Iteration 18400 (21.9039 iter/s, 4.5654s/100 iters), loss = 0.00141651
I1021 17:09:00.758038 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:00.758038 14900 solver.cpp:237]     Train net output #1: loss = 0.0014167 (* 1 = 0.0014167 loss)
I1021 17:09:00.758038 14900 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I1021 17:09:05.324398 14900 solver.cpp:218] Iteration 18500 (21.9031 iter/s, 4.56555s/100 iters), loss = 0.00431845
I1021 17:09:05.324398 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:05.324899 14900 solver.cpp:237]     Train net output #1: loss = 0.00431865 (* 1 = 0.00431865 loss)
I1021 17:09:05.324899 14900 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I1021 17:09:09.665632  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:09:09.846649 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_18600.caffemodel
I1021 17:09:09.858649 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_18600.solverstate
I1021 17:09:09.862650 14900 solver.cpp:330] Iteration 18600, Testing net (#0)
I1021 17:09:09.862650 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:09:10.928750 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:09:10.971757 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9972
I1021 17:09:10.971757 14900 solver.cpp:397]     Test net output #1: loss = 0.0100892 (* 1 = 0.0100892 loss)
I1021 17:09:11.014750 14900 solver.cpp:218] Iteration 18600 (17.5735 iter/s, 5.6904s/100 iters), loss = 0.00372918
I1021 17:09:11.014750 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:11.014750 14900 solver.cpp:237]     Train net output #1: loss = 0.00372937 (* 1 = 0.00372937 loss)
I1021 17:09:11.014750 14900 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I1021 17:09:15.580165 14900 solver.cpp:218] Iteration 18700 (21.9089 iter/s, 4.56434s/100 iters), loss = 0.00836186
I1021 17:09:15.580165 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:15.580165 14900 solver.cpp:237]     Train net output #1: loss = 0.00836205 (* 1 = 0.00836205 loss)
I1021 17:09:15.580165 14900 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I1021 17:09:20.144567 14900 solver.cpp:218] Iteration 18800 (21.9077 iter/s, 4.56461s/100 iters), loss = 0.0067638
I1021 17:09:20.144567 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:20.144567 14900 solver.cpp:237]     Train net output #1: loss = 0.00676399 (* 1 = 0.00676399 loss)
I1021 17:09:20.144567 14900 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I1021 17:09:24.760813 14900 solver.cpp:218] Iteration 18900 (21.6666 iter/s, 4.6154s/100 iters), loss = 0.0302237
I1021 17:09:24.760813 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:09:24.760813 14900 solver.cpp:237]     Train net output #1: loss = 0.0302239 (* 1 = 0.0302239 loss)
I1021 17:09:24.760813 14900 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I1021 17:09:29.321729 14900 solver.cpp:218] Iteration 19000 (21.9271 iter/s, 4.56056s/100 iters), loss = 0.00252766
I1021 17:09:29.321729 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:29.321729 14900 solver.cpp:237]     Train net output #1: loss = 0.00252784 (* 1 = 0.00252784 loss)
I1021 17:09:29.321729 14900 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I1021 17:09:33.869840 14900 solver.cpp:218] Iteration 19100 (21.9903 iter/s, 4.54746s/100 iters), loss = 0.00341158
I1021 17:09:33.869840 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:33.869840 14900 solver.cpp:237]     Train net output #1: loss = 0.00341176 (* 1 = 0.00341176 loss)
I1021 17:09:33.869840 14900 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I1021 17:09:38.193087  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:09:38.374094 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_19200.caffemodel
I1021 17:09:38.391098 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_19200.solverstate
I1021 17:09:38.395098 14900 solver.cpp:330] Iteration 19200, Testing net (#0)
I1021 17:09:38.395098 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:09:39.457082 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:09:39.501087 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:09:39.501087 14900 solver.cpp:397]     Test net output #1: loss = 0.00991583 (* 1 = 0.00991583 loss)
I1021 17:09:39.544083 14900 solver.cpp:218] Iteration 19200 (17.6238 iter/s, 5.67414s/100 iters), loss = 0.00351787
I1021 17:09:39.544083 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:39.544083 14900 solver.cpp:237]     Train net output #1: loss = 0.00351805 (* 1 = 0.00351805 loss)
I1021 17:09:39.544083 14900 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I1021 17:09:44.098521 14900 solver.cpp:218] Iteration 19300 (21.958 iter/s, 4.55416s/100 iters), loss = 0.00627323
I1021 17:09:44.098521 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:44.098521 14900 solver.cpp:237]     Train net output #1: loss = 0.00627341 (* 1 = 0.00627341 loss)
I1021 17:09:44.098521 14900 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I1021 17:09:48.651801 14900 solver.cpp:218] Iteration 19400 (21.9638 iter/s, 4.55294s/100 iters), loss = 0.00358493
I1021 17:09:48.651801 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:48.651801 14900 solver.cpp:237]     Train net output #1: loss = 0.00358511 (* 1 = 0.00358511 loss)
I1021 17:09:48.651801 14900 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I1021 17:09:53.203094 14900 solver.cpp:218] Iteration 19500 (21.9761 iter/s, 4.5504s/100 iters), loss = 0.0175739
I1021 17:09:53.203094 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:09:53.203094 14900 solver.cpp:237]     Train net output #1: loss = 0.0175741 (* 1 = 0.0175741 loss)
I1021 17:09:53.203094 14900 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I1021 17:09:57.759402 14900 solver.cpp:218] Iteration 19600 (21.9461 iter/s, 4.55661s/100 iters), loss = 0.00252433
I1021 17:09:57.759402 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:09:57.759402 14900 solver.cpp:237]     Train net output #1: loss = 0.00252451 (* 1 = 0.00252451 loss)
I1021 17:09:57.759402 14900 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I1021 17:10:02.325718 14900 solver.cpp:218] Iteration 19700 (21.9043 iter/s, 4.56531s/100 iters), loss = 0.00240967
I1021 17:10:02.325718 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:02.325718 14900 solver.cpp:237]     Train net output #1: loss = 0.00240986 (* 1 = 0.00240986 loss)
I1021 17:10:02.325718 14900 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I1021 17:10:06.661262  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:10:06.843272 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_19800.caffemodel
I1021 17:10:06.854272 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_19800.solverstate
I1021 17:10:06.858273 14900 solver.cpp:330] Iteration 19800, Testing net (#0)
I1021 17:10:06.858273 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:10:07.921335 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:10:07.965335 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:10:07.965335 14900 solver.cpp:397]     Test net output #1: loss = 0.00999877 (* 1 = 0.00999877 loss)
I1021 17:10:08.007339 14900 solver.cpp:218] Iteration 19800 (17.5997 iter/s, 5.68191s/100 iters), loss = 0.00659377
I1021 17:10:08.007339 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:08.007339 14900 solver.cpp:237]     Train net output #1: loss = 0.00659395 (* 1 = 0.00659395 loss)
I1021 17:10:08.007339 14900 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I1021 17:10:12.549660 14900 solver.cpp:218] Iteration 19900 (22.0204 iter/s, 4.54125s/100 iters), loss = 0.00642187
I1021 17:10:12.549660 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:12.549660 14900 solver.cpp:237]     Train net output #1: loss = 0.00642205 (* 1 = 0.00642205 loss)
I1021 17:10:12.549660 14900 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I1021 17:10:17.090988 14900 solver.cpp:218] Iteration 20000 (22.0189 iter/s, 4.54156s/100 iters), loss = 0.0060097
I1021 17:10:17.090988 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:17.090988 14900 solver.cpp:237]     Train net output #1: loss = 0.00600988 (* 1 = 0.00600988 loss)
I1021 17:10:17.090988 14900 sgd_solver.cpp:105] Iteration 20000, lr = 0.001
I1021 17:10:21.633231 14900 solver.cpp:218] Iteration 20100 (22.0181 iter/s, 4.54171s/100 iters), loss = 0.00971987
I1021 17:10:21.633231 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:10:21.633231 14900 solver.cpp:237]     Train net output #1: loss = 0.00972005 (* 1 = 0.00972005 loss)
I1021 17:10:21.633231 14900 sgd_solver.cpp:105] Iteration 20100, lr = 0.001
I1021 17:10:26.179008 14900 solver.cpp:218] Iteration 20200 (22.0014 iter/s, 4.54516s/100 iters), loss = 0.00192522
I1021 17:10:26.179008 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:26.179008 14900 solver.cpp:237]     Train net output #1: loss = 0.0019254 (* 1 = 0.0019254 loss)
I1021 17:10:26.179008 14900 sgd_solver.cpp:105] Iteration 20200, lr = 0.001
I1021 17:10:30.723032 14900 solver.cpp:218] Iteration 20300 (22.0081 iter/s, 4.54378s/100 iters), loss = 0.0015932
I1021 17:10:30.723032 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:30.723032 14900 solver.cpp:237]     Train net output #1: loss = 0.00159338 (* 1 = 0.00159338 loss)
I1021 17:10:30.723032 14900 sgd_solver.cpp:105] Iteration 20300, lr = 0.001
I1021 17:10:35.038350  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:10:35.218366 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_20400.caffemodel
I1021 17:10:35.230365 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_20400.solverstate
I1021 17:10:35.234366 14900 solver.cpp:330] Iteration 20400, Testing net (#0)
I1021 17:10:35.234366 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:10:36.296718 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:10:36.340725 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:10:36.340725 14900 solver.cpp:397]     Test net output #1: loss = 0.00998302 (* 1 = 0.00998302 loss)
I1021 17:10:36.383719 14900 solver.cpp:218] Iteration 20400 (17.6674 iter/s, 5.66014s/100 iters), loss = 0.001798
I1021 17:10:36.383719 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:36.383719 14900 solver.cpp:237]     Train net output #1: loss = 0.00179819 (* 1 = 0.00179819 loss)
I1021 17:10:36.383719 14900 sgd_solver.cpp:105] Iteration 20400, lr = 0.001
I1021 17:10:40.936039 14900 solver.cpp:218] Iteration 20500 (21.9683 iter/s, 4.55202s/100 iters), loss = 0.00477125
I1021 17:10:40.936039 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:40.936039 14900 solver.cpp:237]     Train net output #1: loss = 0.00477144 (* 1 = 0.00477144 loss)
I1021 17:10:40.936039 14900 sgd_solver.cpp:105] Iteration 20500, lr = 0.001
I1021 17:10:45.490404 14900 solver.cpp:218] Iteration 20600 (21.9599 iter/s, 4.55375s/100 iters), loss = 0.00758512
I1021 17:10:45.490404 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:45.490404 14900 solver.cpp:237]     Train net output #1: loss = 0.00758532 (* 1 = 0.00758532 loss)
I1021 17:10:45.490404 14900 sgd_solver.cpp:105] Iteration 20600, lr = 0.001
I1021 17:10:50.044812 14900 solver.cpp:218] Iteration 20700 (21.9573 iter/s, 4.55429s/100 iters), loss = 0.00997179
I1021 17:10:50.044812 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:10:50.044812 14900 solver.cpp:237]     Train net output #1: loss = 0.00997199 (* 1 = 0.00997199 loss)
I1021 17:10:50.044812 14900 sgd_solver.cpp:105] Iteration 20700, lr = 0.001
I1021 17:10:54.598063 14900 solver.cpp:218] Iteration 20800 (21.9645 iter/s, 4.55281s/100 iters), loss = 0.0052401
I1021 17:10:54.598063 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:54.598063 14900 solver.cpp:237]     Train net output #1: loss = 0.0052403 (* 1 = 0.0052403 loss)
I1021 17:10:54.598063 14900 sgd_solver.cpp:105] Iteration 20800, lr = 0.001
I1021 17:10:59.156453 14900 solver.cpp:218] Iteration 20900 (21.9377 iter/s, 4.55835s/100 iters), loss = 0.00565209
I1021 17:10:59.157454 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:10:59.157454 14900 solver.cpp:237]     Train net output #1: loss = 0.00565228 (* 1 = 0.00565228 loss)
I1021 17:10:59.157454 14900 sgd_solver.cpp:105] Iteration 20900, lr = 0.001
I1021 17:11:03.496738  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:11:03.678248 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_21000.caffemodel
I1021 17:11:03.691745 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_21000.solverstate
I1021 17:11:03.695745 14900 solver.cpp:330] Iteration 21000, Testing net (#0)
I1021 17:11:03.695745 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:11:04.758862 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:11:04.801872 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:11:04.801872 14900 solver.cpp:397]     Test net output #1: loss = 0.00991238 (* 1 = 0.00991238 loss)
I1021 17:11:04.843873 14900 solver.cpp:218] Iteration 21000 (17.5839 iter/s, 5.68702s/100 iters), loss = 0.00379624
I1021 17:11:04.843873 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:04.844873 14900 solver.cpp:237]     Train net output #1: loss = 0.00379644 (* 1 = 0.00379644 loss)
I1021 17:11:04.844873 14900 sgd_solver.cpp:105] Iteration 21000, lr = 0.001
I1021 17:11:09.398263 14900 solver.cpp:218] Iteration 21100 (21.9608 iter/s, 4.55356s/100 iters), loss = 0.0115785
I1021 17:11:09.398263 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:09.398263 14900 solver.cpp:237]     Train net output #1: loss = 0.0115787 (* 1 = 0.0115787 loss)
I1021 17:11:09.398263 14900 sgd_solver.cpp:105] Iteration 21100, lr = 0.001
I1021 17:11:13.950472 14900 solver.cpp:218] Iteration 21200 (21.9681 iter/s, 4.55205s/100 iters), loss = 0.0024555
I1021 17:11:13.950472 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:13.950472 14900 solver.cpp:237]     Train net output #1: loss = 0.00245569 (* 1 = 0.00245569 loss)
I1021 17:11:13.950472 14900 sgd_solver.cpp:105] Iteration 21200, lr = 0.001
I1021 17:11:18.505800 14900 solver.cpp:218] Iteration 21300 (21.9537 iter/s, 4.55504s/100 iters), loss = 0.00502357
I1021 17:11:18.505800 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:18.505800 14900 solver.cpp:237]     Train net output #1: loss = 0.00502376 (* 1 = 0.00502376 loss)
I1021 17:11:18.505800 14900 sgd_solver.cpp:105] Iteration 21300, lr = 0.001
I1021 17:11:23.057029 14900 solver.cpp:218] Iteration 21400 (21.975 iter/s, 4.55063s/100 iters), loss = 0.00277459
I1021 17:11:23.057029 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:23.057029 14900 solver.cpp:237]     Train net output #1: loss = 0.00277479 (* 1 = 0.00277479 loss)
I1021 17:11:23.057029 14900 sgd_solver.cpp:105] Iteration 21400, lr = 0.001
I1021 17:11:27.610327 14900 solver.cpp:218] Iteration 21500 (21.9649 iter/s, 4.55273s/100 iters), loss = 0.0044046
I1021 17:11:27.610327 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:27.610327 14900 solver.cpp:237]     Train net output #1: loss = 0.00440479 (* 1 = 0.00440479 loss)
I1021 17:11:27.610327 14900 sgd_solver.cpp:105] Iteration 21500, lr = 0.001
I1021 17:11:31.941649  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:11:32.122659 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_21600.caffemodel
I1021 17:11:32.135659 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_21600.solverstate
I1021 17:11:32.139659 14900 solver.cpp:330] Iteration 21600, Testing net (#0)
I1021 17:11:32.139659 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:11:33.202776 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:11:33.245775 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:11:33.245775 14900 solver.cpp:397]     Test net output #1: loss = 0.00996825 (* 1 = 0.00996825 loss)
I1021 17:11:33.288789 14900 solver.cpp:218] Iteration 21600 (17.6125 iter/s, 5.6778s/100 iters), loss = 0.00323391
I1021 17:11:33.288789 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:33.288789 14900 solver.cpp:237]     Train net output #1: loss = 0.0032341 (* 1 = 0.0032341 loss)
I1021 17:11:33.288789 14900 sgd_solver.cpp:105] Iteration 21600, lr = 0.001
I1021 17:11:37.848958 14900 solver.cpp:218] Iteration 21700 (21.9319 iter/s, 4.55957s/100 iters), loss = 0.00768629
I1021 17:11:37.848958 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:37.848958 14900 solver.cpp:237]     Train net output #1: loss = 0.00768649 (* 1 = 0.00768649 loss)
I1021 17:11:37.848958 14900 sgd_solver.cpp:105] Iteration 21700, lr = 0.001
I1021 17:11:42.394244 14900 solver.cpp:218] Iteration 21800 (22.0012 iter/s, 4.54521s/100 iters), loss = 0.00689096
I1021 17:11:42.394244 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:42.394244 14900 solver.cpp:237]     Train net output #1: loss = 0.00689116 (* 1 = 0.00689116 loss)
I1021 17:11:42.394244 14900 sgd_solver.cpp:105] Iteration 21800, lr = 0.001
I1021 17:11:46.945590 14900 solver.cpp:218] Iteration 21900 (21.9734 iter/s, 4.55096s/100 iters), loss = 0.00793757
I1021 17:11:46.945590 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:46.945590 14900 solver.cpp:237]     Train net output #1: loss = 0.00793778 (* 1 = 0.00793778 loss)
I1021 17:11:46.945590 14900 sgd_solver.cpp:105] Iteration 21900, lr = 0.001
I1021 17:11:51.502656 14900 solver.cpp:218] Iteration 22000 (21.9443 iter/s, 4.55699s/100 iters), loss = 0.00280985
I1021 17:11:51.502656 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:51.502656 14900 solver.cpp:237]     Train net output #1: loss = 0.00281005 (* 1 = 0.00281005 loss)
I1021 17:11:51.502656 14900 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 3
I1021 17:11:51.502656 14900 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I1021 17:11:56.050818 14900 solver.cpp:218] Iteration 22100 (21.992 iter/s, 4.5471s/100 iters), loss = 0.00336107
I1021 17:11:56.050818 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:11:56.050818 14900 solver.cpp:237]     Train net output #1: loss = 0.00336128 (* 1 = 0.00336128 loss)
I1021 17:11:56.050818 14900 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I1021 17:12:00.372761  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:12:00.553786 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_22200.caffemodel
I1021 17:12:00.571768 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_22200.solverstate
I1021 17:12:00.576279 14900 solver.cpp:330] Iteration 22200, Testing net (#0)
I1021 17:12:00.576279 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:12:01.638849 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:12:01.682351 14900 solver.cpp:397]     Test net output #0: accuracy = 0.9969
I1021 17:12:01.682351 14900 solver.cpp:397]     Test net output #1: loss = 0.00992643 (* 1 = 0.00992643 loss)
I1021 17:12:01.724853 14900 solver.cpp:218] Iteration 22200 (17.6245 iter/s, 5.67391s/100 iters), loss = 0.00263028
I1021 17:12:01.724853 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:01.724853 14900 solver.cpp:237]     Train net output #1: loss = 0.00263048 (* 1 = 0.00263048 loss)
I1021 17:12:01.724853 14900 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I1021 17:12:06.277396 14900 solver.cpp:218] Iteration 22300 (21.9688 iter/s, 4.5519s/100 iters), loss = 0.00690615
I1021 17:12:06.277396 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:06.277396 14900 solver.cpp:237]     Train net output #1: loss = 0.00690636 (* 1 = 0.00690636 loss)
I1021 17:12:06.277396 14900 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I1021 17:12:10.829748 14900 solver.cpp:218] Iteration 22400 (21.9681 iter/s, 4.55205s/100 iters), loss = 0.00503522
I1021 17:12:10.829748 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:10.829748 14900 solver.cpp:237]     Train net output #1: loss = 0.00503543 (* 1 = 0.00503543 loss)
I1021 17:12:10.829748 14900 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I1021 17:12:15.382066 14900 solver.cpp:218] Iteration 22500 (21.9683 iter/s, 4.55201s/100 iters), loss = 0.00302482
I1021 17:12:15.382066 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:15.382066 14900 solver.cpp:237]     Train net output #1: loss = 0.00302503 (* 1 = 0.00302503 loss)
I1021 17:12:15.382066 14900 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I1021 17:12:19.941562 14900 solver.cpp:218] Iteration 22600 (21.9352 iter/s, 4.55889s/100 iters), loss = 0.00149746
I1021 17:12:19.941562 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:19.941562 14900 solver.cpp:237]     Train net output #1: loss = 0.00149767 (* 1 = 0.00149767 loss)
I1021 17:12:19.941562 14900 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I1021 17:12:24.493546 14900 solver.cpp:218] Iteration 22700 (21.9689 iter/s, 4.55188s/100 iters), loss = 0.002694
I1021 17:12:24.493546 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:24.493546 14900 solver.cpp:237]     Train net output #1: loss = 0.00269421 (* 1 = 0.00269421 loss)
I1021 17:12:24.493546 14900 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I1021 17:12:28.826517  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:12:29.006533 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_22800.caffemodel
I1021 17:12:29.018527 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_22800.solverstate
I1021 17:12:29.023526 14900 solver.cpp:330] Iteration 22800, Testing net (#0)
I1021 17:12:29.023526 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:12:30.085613 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:12:30.128629 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:12:30.128629 14900 solver.cpp:397]     Test net output #1: loss = 0.00989456 (* 1 = 0.00989456 loss)
I1021 17:12:30.172631 14900 solver.cpp:218] Iteration 22800 (17.6094 iter/s, 5.67878s/100 iters), loss = 0.00267019
I1021 17:12:30.172631 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:30.172631 14900 solver.cpp:237]     Train net output #1: loss = 0.00267041 (* 1 = 0.00267041 loss)
I1021 17:12:30.172631 14900 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I1021 17:12:34.727182 14900 solver.cpp:218] Iteration 22900 (21.9581 iter/s, 4.55412s/100 iters), loss = 0.00560979
I1021 17:12:34.727182 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:34.727182 14900 solver.cpp:237]     Train net output #1: loss = 0.00561002 (* 1 = 0.00561002 loss)
I1021 17:12:34.727182 14900 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I1021 17:12:39.277523 14900 solver.cpp:218] Iteration 23000 (21.9798 iter/s, 4.54963s/100 iters), loss = 0.00608597
I1021 17:12:39.277523 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:39.277523 14900 solver.cpp:237]     Train net output #1: loss = 0.0060862 (* 1 = 0.0060862 loss)
I1021 17:12:39.277523 14900 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I1021 17:12:43.823909 14900 solver.cpp:218] Iteration 23100 (21.9968 iter/s, 4.54611s/100 iters), loss = 0.00178212
I1021 17:12:43.823909 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:43.823909 14900 solver.cpp:237]     Train net output #1: loss = 0.00178235 (* 1 = 0.00178235 loss)
I1021 17:12:43.823909 14900 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I1021 17:12:48.381309 14900 solver.cpp:218] Iteration 23200 (21.9451 iter/s, 4.55682s/100 iters), loss = 0.00117915
I1021 17:12:48.381309 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:48.381309 14900 solver.cpp:237]     Train net output #1: loss = 0.00117939 (* 1 = 0.00117939 loss)
I1021 17:12:48.381309 14900 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I1021 17:12:52.924692 14900 solver.cpp:218] Iteration 23300 (22.0121 iter/s, 4.54296s/100 iters), loss = 0.00297857
I1021 17:12:52.924692 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:52.924692 14900 solver.cpp:237]     Train net output #1: loss = 0.0029788 (* 1 = 0.0029788 loss)
I1021 17:12:52.924692 14900 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I1021 17:12:57.241045  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:12:57.421066 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_23400.caffemodel
I1021 17:12:57.434067 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_23400.solverstate
I1021 17:12:57.438067 14900 solver.cpp:330] Iteration 23400, Testing net (#0)
I1021 17:12:57.438067 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:12:58.500156 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:12:58.544153 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:12:58.544153 14900 solver.cpp:397]     Test net output #1: loss = 0.00991015 (* 1 = 0.00991015 loss)
I1021 17:12:58.587157 14900 solver.cpp:218] Iteration 23400 (17.6605 iter/s, 5.66234s/100 iters), loss = 0.00466519
I1021 17:12:58.587157 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:12:58.587157 14900 solver.cpp:237]     Train net output #1: loss = 0.00466542 (* 1 = 0.00466542 loss)
I1021 17:12:58.587656 14900 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I1021 17:13:03.140552 14900 solver.cpp:218] Iteration 23500 (21.9633 iter/s, 4.55304s/100 iters), loss = 0.00350744
I1021 17:13:03.140552 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:03.140552 14900 solver.cpp:237]     Train net output #1: loss = 0.00350768 (* 1 = 0.00350768 loss)
I1021 17:13:03.140552 14900 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I1021 17:13:07.691354 14900 solver.cpp:218] Iteration 23600 (21.9792 iter/s, 4.54976s/100 iters), loss = 0.00596314
I1021 17:13:07.691354 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:07.691354 14900 solver.cpp:237]     Train net output #1: loss = 0.00596337 (* 1 = 0.00596337 loss)
I1021 17:13:07.691354 14900 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I1021 17:13:12.250201 14900 solver.cpp:218] Iteration 23700 (21.9346 iter/s, 4.559s/100 iters), loss = 0.0031547
I1021 17:13:12.250201 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:12.250201 14900 solver.cpp:237]     Train net output #1: loss = 0.00315493 (* 1 = 0.00315493 loss)
I1021 17:13:12.250201 14900 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I1021 17:13:16.799623 14900 solver.cpp:218] Iteration 23800 (21.983 iter/s, 4.54897s/100 iters), loss = 0.00143494
I1021 17:13:16.799623 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:16.799623 14900 solver.cpp:237]     Train net output #1: loss = 0.00143517 (* 1 = 0.00143517 loss)
I1021 17:13:16.799623 14900 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I1021 17:13:21.352151 14900 solver.cpp:218] Iteration 23900 (21.9688 iter/s, 4.5519s/100 iters), loss = 0.00471535
I1021 17:13:21.352151 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:21.352151 14900 solver.cpp:237]     Train net output #1: loss = 0.00471558 (* 1 = 0.00471558 loss)
I1021 17:13:21.352151 14900 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I1021 17:13:25.680512  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:13:25.860520 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_24000.caffemodel
I1021 17:13:25.872520 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_24000.solverstate
I1021 17:13:25.876521 14900 solver.cpp:330] Iteration 24000, Testing net (#0)
I1021 17:13:25.876521 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:13:26.939139 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:13:26.982642 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:13:26.982642 14900 solver.cpp:397]     Test net output #1: loss = 0.00991809 (* 1 = 0.00991809 loss)
I1021 17:13:27.025149 14900 solver.cpp:218] Iteration 24000 (17.6289 iter/s, 5.6725s/100 iters), loss = 0.00208619
I1021 17:13:27.025149 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:27.025149 14900 solver.cpp:237]     Train net output #1: loss = 0.00208643 (* 1 = 0.00208643 loss)
I1021 17:13:27.025149 14900 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I1021 17:13:31.573734 14900 solver.cpp:218] Iteration 24100 (21.987 iter/s, 4.54814s/100 iters), loss = 0.00306353
I1021 17:13:31.573734 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:31.573734 14900 solver.cpp:237]     Train net output #1: loss = 0.00306377 (* 1 = 0.00306377 loss)
I1021 17:13:31.573734 14900 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I1021 17:13:36.124344 14900 solver.cpp:218] Iteration 24200 (21.9752 iter/s, 4.55059s/100 iters), loss = 0.00437775
I1021 17:13:36.124344 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:36.124344 14900 solver.cpp:237]     Train net output #1: loss = 0.00437799 (* 1 = 0.00437799 loss)
I1021 17:13:36.124344 14900 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I1021 17:13:40.672993 14900 solver.cpp:218] Iteration 24300 (21.9879 iter/s, 4.54795s/100 iters), loss = 0.00709964
I1021 17:13:40.672993 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:40.672993 14900 solver.cpp:237]     Train net output #1: loss = 0.00709988 (* 1 = 0.00709988 loss)
I1021 17:13:40.672993 14900 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I1021 17:13:45.215220 14900 solver.cpp:218] Iteration 24400 (22.0179 iter/s, 4.54176s/100 iters), loss = 0.00157598
I1021 17:13:45.215220 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:45.215220 14900 solver.cpp:237]     Train net output #1: loss = 0.00157623 (* 1 = 0.00157623 loss)
I1021 17:13:45.215220 14900 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I1021 17:13:49.762540 14900 solver.cpp:218] Iteration 24500 (21.9909 iter/s, 4.54733s/100 iters), loss = 0.00264317
I1021 17:13:49.762540 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:49.762540 14900 solver.cpp:237]     Train net output #1: loss = 0.00264341 (* 1 = 0.00264341 loss)
I1021 17:13:49.762540 14900 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I1021 17:13:54.091862  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:13:54.270874 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_24600.caffemodel
I1021 17:13:54.282873 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_24600.solverstate
I1021 17:13:54.286873 14900 solver.cpp:330] Iteration 24600, Testing net (#0)
I1021 17:13:54.286873 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:13:55.350939 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:13:55.393939 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:13:55.393939 14900 solver.cpp:397]     Test net output #1: loss = 0.0099158 (* 1 = 0.0099158 loss)
I1021 17:13:55.436440 14900 solver.cpp:218] Iteration 24600 (17.6262 iter/s, 5.67336s/100 iters), loss = 0.00227095
I1021 17:13:55.436440 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:55.436440 14900 solver.cpp:237]     Train net output #1: loss = 0.00227119 (* 1 = 0.00227119 loss)
I1021 17:13:55.436440 14900 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I1021 17:13:59.983247 14900 solver.cpp:218] Iteration 24700 (21.9944 iter/s, 4.54662s/100 iters), loss = 0.00383735
I1021 17:13:59.983247 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:13:59.983247 14900 solver.cpp:237]     Train net output #1: loss = 0.00383759 (* 1 = 0.00383759 loss)
I1021 17:13:59.983247 14900 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I1021 17:14:04.526479 14900 solver.cpp:218] Iteration 24800 (22.0109 iter/s, 4.5432s/100 iters), loss = 0.00694755
I1021 17:14:04.526479 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:04.526479 14900 solver.cpp:237]     Train net output #1: loss = 0.00694779 (* 1 = 0.00694779 loss)
I1021 17:14:04.526479 14900 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I1021 17:14:09.085887 14900 solver.cpp:218] Iteration 24900 (21.9342 iter/s, 4.5591s/100 iters), loss = 0.00474571
I1021 17:14:09.086887 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:09.086887 14900 solver.cpp:237]     Train net output #1: loss = 0.00474595 (* 1 = 0.00474595 loss)
I1021 17:14:09.086887 14900 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I1021 17:14:13.641237 14900 solver.cpp:218] Iteration 25000 (21.9573 iter/s, 4.5543s/100 iters), loss = 0.00104192
I1021 17:14:13.641237 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:13.641237 14900 solver.cpp:237]     Train net output #1: loss = 0.00104216 (* 1 = 0.00104216 loss)
I1021 17:14:13.641237 14900 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I1021 17:14:18.191556 14900 solver.cpp:218] Iteration 25100 (21.9754 iter/s, 4.55055s/100 iters), loss = 0.00194782
I1021 17:14:18.192561 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:18.192561 14900 solver.cpp:237]     Train net output #1: loss = 0.00194806 (* 1 = 0.00194806 loss)
I1021 17:14:18.192561 14900 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I1021 17:14:22.519969  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:14:22.700978 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_25200.caffemodel
I1021 17:14:22.712978 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_25200.solverstate
I1021 17:14:22.716979 14900 solver.cpp:330] Iteration 25200, Testing net (#0)
I1021 17:14:22.716979 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:14:23.780071 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:14:23.823070 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:14:23.823070 14900 solver.cpp:397]     Test net output #1: loss = 0.00991242 (* 1 = 0.00991242 loss)
I1021 17:14:23.867076 14900 solver.cpp:218] Iteration 25200 (17.6239 iter/s, 5.67412s/100 iters), loss = 0.00130501
I1021 17:14:23.867076 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:23.867076 14900 solver.cpp:237]     Train net output #1: loss = 0.00130525 (* 1 = 0.00130525 loss)
I1021 17:14:23.867076 14900 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I1021 17:14:28.414458 14900 solver.cpp:218] Iteration 25300 (21.9923 iter/s, 4.54705s/100 iters), loss = 0.00170241
I1021 17:14:28.414458 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:28.414458 14900 solver.cpp:237]     Train net output #1: loss = 0.00170265 (* 1 = 0.00170265 loss)
I1021 17:14:28.414458 14900 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I1021 17:14:32.969730 14900 solver.cpp:218] Iteration 25400 (21.9541 iter/s, 4.55496s/100 iters), loss = 0.00649605
I1021 17:14:32.969730 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:32.969730 14900 solver.cpp:237]     Train net output #1: loss = 0.0064963 (* 1 = 0.0064963 loss)
I1021 17:14:32.969730 14900 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I1021 17:14:37.516098 14900 solver.cpp:218] Iteration 25500 (21.9972 iter/s, 4.54602s/100 iters), loss = 0.00413924
I1021 17:14:37.516098 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:37.516098 14900 solver.cpp:237]     Train net output #1: loss = 0.00413949 (* 1 = 0.00413949 loss)
I1021 17:14:37.516098 14900 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I1021 17:14:42.063683 14900 solver.cpp:218] Iteration 25600 (21.9915 iter/s, 4.54721s/100 iters), loss = 0.00112745
I1021 17:14:42.063683 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:42.063683 14900 solver.cpp:237]     Train net output #1: loss = 0.0011277 (* 1 = 0.0011277 loss)
I1021 17:14:42.063683 14900 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I1021 17:14:46.614081 14900 solver.cpp:218] Iteration 25700 (21.9742 iter/s, 4.55079s/100 iters), loss = 0.00214629
I1021 17:14:46.615082 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:46.615082 14900 solver.cpp:237]     Train net output #1: loss = 0.00214653 (* 1 = 0.00214653 loss)
I1021 17:14:46.615082 14900 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I1021 17:14:50.939416  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:14:51.120429 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_25800.caffemodel
I1021 17:14:51.132931 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_25800.solverstate
I1021 17:14:51.137432 14900 solver.cpp:330] Iteration 25800, Testing net (#0)
I1021 17:14:51.137432 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:14:52.200733 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:14:52.243736 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:14:52.243736 14900 solver.cpp:397]     Test net output #1: loss = 0.00991073 (* 1 = 0.00991073 loss)
I1021 17:14:52.286737 14900 solver.cpp:218] Iteration 25800 (17.6298 iter/s, 5.67221s/100 iters), loss = 0.00246264
I1021 17:14:52.286737 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:52.286737 14900 solver.cpp:237]     Train net output #1: loss = 0.00246289 (* 1 = 0.00246289 loss)
I1021 17:14:52.286737 14900 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I1021 17:14:56.838425 14900 solver.cpp:218] Iteration 25900 (21.9749 iter/s, 4.55065s/100 iters), loss = 0.00103101
I1021 17:14:56.838425 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:14:56.838425 14900 solver.cpp:237]     Train net output #1: loss = 0.00103125 (* 1 = 0.00103125 loss)
I1021 17:14:56.838425 14900 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I1021 17:15:01.394215 14900 solver.cpp:218] Iteration 26000 (21.9484 iter/s, 4.55614s/100 iters), loss = 0.00747981
I1021 17:15:01.394215 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:01.395216 14900 solver.cpp:237]     Train net output #1: loss = 0.00748005 (* 1 = 0.00748005 loss)
I1021 17:15:01.395216 14900 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I1021 17:15:05.943743 14900 solver.cpp:218] Iteration 26100 (21.9844 iter/s, 4.54868s/100 iters), loss = 0.00266972
I1021 17:15:05.943743 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:05.943743 14900 solver.cpp:237]     Train net output #1: loss = 0.00266996 (* 1 = 0.00266996 loss)
I1021 17:15:05.943743 14900 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I1021 17:15:10.493010 14900 solver.cpp:218] Iteration 26200 (21.9836 iter/s, 4.54885s/100 iters), loss = 0.00101337
I1021 17:15:10.493010 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:10.493010 14900 solver.cpp:237]     Train net output #1: loss = 0.00101361 (* 1 = 0.00101361 loss)
I1021 17:15:10.493010 14900 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I1021 17:15:15.044277 14900 solver.cpp:218] Iteration 26300 (21.9712 iter/s, 4.5514s/100 iters), loss = 0.00289773
I1021 17:15:15.044277 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:15.044277 14900 solver.cpp:237]     Train net output #1: loss = 0.00289797 (* 1 = 0.00289797 loss)
I1021 17:15:15.044277 14900 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I1021 17:15:19.364621  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:15:19.545629 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_26400.caffemodel
I1021 17:15:19.559628 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_26400.solverstate
I1021 17:15:19.563628 14900 solver.cpp:330] Iteration 26400, Testing net (#0)
I1021 17:15:19.564628 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:15:20.624721 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:15:20.668727 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:15:20.668727 14900 solver.cpp:397]     Test net output #1: loss = 0.00991199 (* 1 = 0.00991199 loss)
I1021 17:15:20.710726 14900 solver.cpp:218] Iteration 26400 (17.6489 iter/s, 5.66609s/100 iters), loss = 0.00148277
I1021 17:15:20.711726 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:20.711726 14900 solver.cpp:237]     Train net output #1: loss = 0.00148301 (* 1 = 0.00148301 loss)
I1021 17:15:20.711726 14900 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I1021 17:15:25.266026 14900 solver.cpp:218] Iteration 26500 (21.955 iter/s, 4.55476s/100 iters), loss = 0.00529378
I1021 17:15:25.266026 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:25.266026 14900 solver.cpp:237]     Train net output #1: loss = 0.00529403 (* 1 = 0.00529403 loss)
I1021 17:15:25.266026 14900 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I1021 17:15:29.824311 14900 solver.cpp:218] Iteration 26600 (21.9404 iter/s, 4.55781s/100 iters), loss = 0.0135759
I1021 17:15:29.824311 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:29.824311 14900 solver.cpp:237]     Train net output #1: loss = 0.0135762 (* 1 = 0.0135762 loss)
I1021 17:15:29.824311 14900 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I1021 17:15:34.388625 14900 solver.cpp:218] Iteration 26700 (21.9123 iter/s, 4.56364s/100 iters), loss = 0.00171945
I1021 17:15:34.388625 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:34.388625 14900 solver.cpp:237]     Train net output #1: loss = 0.0017197 (* 1 = 0.0017197 loss)
I1021 17:15:34.388625 14900 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I1021 17:15:38.944928 14900 solver.cpp:218] Iteration 26800 (21.9478 iter/s, 4.55626s/100 iters), loss = 0.00135666
I1021 17:15:38.944928 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:38.944928 14900 solver.cpp:237]     Train net output #1: loss = 0.00135691 (* 1 = 0.00135691 loss)
I1021 17:15:38.944928 14900 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I1021 17:15:43.494432 14900 solver.cpp:218] Iteration 26900 (21.9825 iter/s, 4.54907s/100 iters), loss = 0.00347538
I1021 17:15:43.494432 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:43.494432 14900 solver.cpp:237]     Train net output #1: loss = 0.00347563 (* 1 = 0.00347563 loss)
I1021 17:15:43.494432 14900 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I1021 17:15:47.826722  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:15:48.006742 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_27000.caffemodel
I1021 17:15:48.018741 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_27000.solverstate
I1021 17:15:48.023742 14900 solver.cpp:330] Iteration 27000, Testing net (#0)
I1021 17:15:48.023742 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:15:49.087839 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:15:49.130842 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:15:49.131342 14900 solver.cpp:397]     Test net output #1: loss = 0.00991743 (* 1 = 0.00991743 loss)
I1021 17:15:49.173844 14900 solver.cpp:218] Iteration 27000 (17.61 iter/s, 5.67858s/100 iters), loss = 0.000916235
I1021 17:15:49.173844 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:49.173844 14900 solver.cpp:237]     Train net output #1: loss = 0.000916483 (* 1 = 0.000916483 loss)
I1021 17:15:49.173844 14900 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I1021 17:15:53.730172 14900 solver.cpp:218] Iteration 27100 (21.9511 iter/s, 4.55559s/100 iters), loss = 0.00764912
I1021 17:15:53.730172 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:53.730172 14900 solver.cpp:237]     Train net output #1: loss = 0.00764936 (* 1 = 0.00764936 loss)
I1021 17:15:53.730172 14900 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I1021 17:15:58.286450 14900 solver.cpp:218] Iteration 27200 (21.9495 iter/s, 4.55591s/100 iters), loss = 0.00561544
I1021 17:15:58.286450 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:15:58.286450 14900 solver.cpp:237]     Train net output #1: loss = 0.00561568 (* 1 = 0.00561568 loss)
I1021 17:15:58.286450 14900 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I1021 17:16:02.840308 14900 solver.cpp:218] Iteration 27300 (21.9603 iter/s, 4.55366s/100 iters), loss = 0.0133797
I1021 17:16:02.840308 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:16:02.840308 14900 solver.cpp:237]     Train net output #1: loss = 0.01338 (* 1 = 0.01338 loss)
I1021 17:16:02.840308 14900 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I1021 17:16:07.401232 14900 solver.cpp:218] Iteration 27400 (21.9273 iter/s, 4.56053s/100 iters), loss = 0.0103502
I1021 17:16:07.401232 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:16:07.401232 14900 solver.cpp:237]     Train net output #1: loss = 0.0103505 (* 1 = 0.0103505 loss)
I1021 17:16:07.401232 14900 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I1021 17:16:11.954533 14900 solver.cpp:218] Iteration 27500 (21.9635 iter/s, 4.55301s/100 iters), loss = 0.00164731
I1021 17:16:11.954533 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:11.954533 14900 solver.cpp:237]     Train net output #1: loss = 0.00164755 (* 1 = 0.00164755 loss)
I1021 17:16:11.954533 14900 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I1021 17:16:16.295802  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:16:16.476811 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_27600.caffemodel
I1021 17:16:16.489812 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_27600.solverstate
I1021 17:16:16.493813 14900 solver.cpp:330] Iteration 27600, Testing net (#0)
I1021 17:16:16.493813 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:16:17.556869 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:16:17.599866 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:16:17.599866 14900 solver.cpp:397]     Test net output #1: loss = 0.00990713 (* 1 = 0.00990713 loss)
I1021 17:16:17.643368 14900 solver.cpp:218] Iteration 27600 (17.5796 iter/s, 5.6884s/100 iters), loss = 0.00161193
I1021 17:16:17.643368 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:17.643368 14900 solver.cpp:237]     Train net output #1: loss = 0.00161217 (* 1 = 0.00161217 loss)
I1021 17:16:17.643368 14900 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I1021 17:16:22.191092 14900 solver.cpp:218] Iteration 27700 (21.99 iter/s, 4.54752s/100 iters), loss = 0.0025252
I1021 17:16:22.191092 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:22.191092 14900 solver.cpp:237]     Train net output #1: loss = 0.00252545 (* 1 = 0.00252545 loss)
I1021 17:16:22.191092 14900 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I1021 17:16:26.739002 14900 solver.cpp:218] Iteration 27800 (21.991 iter/s, 4.54732s/100 iters), loss = 0.00692557
I1021 17:16:26.739002 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:26.739002 14900 solver.cpp:237]     Train net output #1: loss = 0.00692582 (* 1 = 0.00692582 loss)
I1021 17:16:26.739002 14900 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I1021 17:16:31.277814 14900 solver.cpp:218] Iteration 27900 (22.0323 iter/s, 4.53879s/100 iters), loss = 0.0124859
I1021 17:16:31.277814 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:16:31.277814 14900 solver.cpp:237]     Train net output #1: loss = 0.0124862 (* 1 = 0.0124862 loss)
I1021 17:16:31.277814 14900 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I1021 17:16:35.830070 14900 solver.cpp:218] Iteration 28000 (21.9692 iter/s, 4.55182s/100 iters), loss = 0.00290712
I1021 17:16:35.830070 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:35.830070 14900 solver.cpp:237]     Train net output #1: loss = 0.00290737 (* 1 = 0.00290737 loss)
I1021 17:16:35.830070 14900 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I1021 17:16:40.377367 14900 solver.cpp:218] Iteration 28100 (21.9927 iter/s, 4.54697s/100 iters), loss = 0.00266418
I1021 17:16:40.377367 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:40.377367 14900 solver.cpp:237]     Train net output #1: loss = 0.00266443 (* 1 = 0.00266443 loss)
I1021 17:16:40.377367 14900 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I1021 17:16:44.694984  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:16:44.873993 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_28200.caffemodel
I1021 17:16:44.885994 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_28200.solverstate
I1021 17:16:44.889993 14900 solver.cpp:330] Iteration 28200, Testing net (#0)
I1021 17:16:44.889993 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:16:45.952400 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:16:45.995399 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:16:45.995399 14900 solver.cpp:397]     Test net output #1: loss = 0.00990606 (* 1 = 0.00990606 loss)
I1021 17:16:46.038411 14900 solver.cpp:218] Iteration 28200 (17.6676 iter/s, 5.66007s/100 iters), loss = 0.00351644
I1021 17:16:46.038411 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:46.038411 14900 solver.cpp:237]     Train net output #1: loss = 0.00351671 (* 1 = 0.00351671 loss)
I1021 17:16:46.038411 14900 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I1021 17:16:50.589758 14900 solver.cpp:218] Iteration 28300 (21.9721 iter/s, 4.55123s/100 iters), loss = 0.00396985
I1021 17:16:50.589758 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:50.589758 14900 solver.cpp:237]     Train net output #1: loss = 0.00397011 (* 1 = 0.00397011 loss)
I1021 17:16:50.589758 14900 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I1021 17:16:55.144827 14900 solver.cpp:218] Iteration 28400 (21.9556 iter/s, 4.55465s/100 iters), loss = 0.00535065
I1021 17:16:55.144827 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:55.144827 14900 solver.cpp:237]     Train net output #1: loss = 0.00535091 (* 1 = 0.00535091 loss)
I1021 17:16:55.144827 14900 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I1021 17:16:59.690678 14900 solver.cpp:218] Iteration 28500 (21.9989 iter/s, 4.54569s/100 iters), loss = 0.00238798
I1021 17:16:59.690678 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:16:59.690678 14900 solver.cpp:237]     Train net output #1: loss = 0.00238824 (* 1 = 0.00238824 loss)
I1021 17:16:59.690678 14900 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I1021 17:17:04.239466 14900 solver.cpp:218] Iteration 28600 (21.9879 iter/s, 4.54795s/100 iters), loss = 0.00102326
I1021 17:17:04.239466 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:04.239466 14900 solver.cpp:237]     Train net output #1: loss = 0.00102351 (* 1 = 0.00102351 loss)
I1021 17:17:04.239466 14900 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I1021 17:17:08.788779 14900 solver.cpp:218] Iteration 28700 (21.9824 iter/s, 4.5491s/100 iters), loss = 0.00433398
I1021 17:17:08.788779 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:08.788779 14900 solver.cpp:237]     Train net output #1: loss = 0.00433424 (* 1 = 0.00433424 loss)
I1021 17:17:08.788779 14900 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I1021 17:17:13.117588  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:17:13.297592 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_28800.caffemodel
I1021 17:17:13.309595 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_28800.solverstate
I1021 17:17:13.313596 14900 solver.cpp:330] Iteration 28800, Testing net (#0)
I1021 17:17:13.313596 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:17:14.375967 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:17:14.418974 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:17:14.419975 14900 solver.cpp:397]     Test net output #1: loss = 0.00991259 (* 1 = 0.00991259 loss)
I1021 17:17:14.462975 14900 solver.cpp:218] Iteration 28800 (17.6247 iter/s, 5.67386s/100 iters), loss = 0.00365955
I1021 17:17:14.462975 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:14.462975 14900 solver.cpp:237]     Train net output #1: loss = 0.00365981 (* 1 = 0.00365981 loss)
I1021 17:17:14.462975 14900 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I1021 17:17:19.017266 14900 solver.cpp:218] Iteration 28900 (21.9562 iter/s, 4.55452s/100 iters), loss = 0.00333332
I1021 17:17:19.017266 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:19.017266 14900 solver.cpp:237]     Train net output #1: loss = 0.00333358 (* 1 = 0.00333358 loss)
I1021 17:17:19.018266 14900 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I1021 17:17:23.570608 14900 solver.cpp:218] Iteration 29000 (21.9637 iter/s, 4.55297s/100 iters), loss = 0.00243264
I1021 17:17:23.570608 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:23.570608 14900 solver.cpp:237]     Train net output #1: loss = 0.00243291 (* 1 = 0.00243291 loss)
I1021 17:17:23.571609 14900 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I1021 17:17:28.119995 14900 solver.cpp:218] Iteration 29100 (21.9872 iter/s, 4.54811s/100 iters), loss = 0.00232762
I1021 17:17:28.119995 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:28.119995 14900 solver.cpp:237]     Train net output #1: loss = 0.00232789 (* 1 = 0.00232789 loss)
I1021 17:17:28.119995 14900 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I1021 17:17:32.671262 14900 solver.cpp:218] Iteration 29200 (21.9707 iter/s, 4.55151s/100 iters), loss = 0.00311013
I1021 17:17:32.671262 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:32.671262 14900 solver.cpp:237]     Train net output #1: loss = 0.0031104 (* 1 = 0.0031104 loss)
I1021 17:17:32.671262 14900 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I1021 17:17:37.221189 14900 solver.cpp:218] Iteration 29300 (21.9812 iter/s, 4.54935s/100 iters), loss = 0.00260277
I1021 17:17:37.221189 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:37.221189 14900 solver.cpp:237]     Train net output #1: loss = 0.00260304 (* 1 = 0.00260304 loss)
I1021 17:17:37.221189 14900 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I1021 17:17:41.545791  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:17:41.726809 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_29400.caffemodel
I1021 17:17:41.738809 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_29400.solverstate
I1021 17:17:41.742810 14900 solver.cpp:330] Iteration 29400, Testing net (#0)
I1021 17:17:41.742810 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:17:42.804987 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:17:42.847986 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:17:42.847986 14900 solver.cpp:397]     Test net output #1: loss = 0.00991843 (* 1 = 0.00991843 loss)
I1021 17:17:42.891487 14900 solver.cpp:218] Iteration 29400 (17.6376 iter/s, 5.66971s/100 iters), loss = 0.00200737
I1021 17:17:42.891487 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:42.891487 14900 solver.cpp:237]     Train net output #1: loss = 0.00200764 (* 1 = 0.00200764 loss)
I1021 17:17:42.891487 14900 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I1021 17:17:47.444329 14900 solver.cpp:218] Iteration 29500 (21.9667 iter/s, 4.55234s/100 iters), loss = 0.00899829
I1021 17:17:47.444329 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:47.444329 14900 solver.cpp:237]     Train net output #1: loss = 0.00899857 (* 1 = 0.00899857 loss)
I1021 17:17:47.444329 14900 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I1021 17:17:52.000254 14900 solver.cpp:218] Iteration 29600 (21.9524 iter/s, 4.55532s/100 iters), loss = 0.00703693
I1021 17:17:52.000254 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:17:52.000254 14900 solver.cpp:237]     Train net output #1: loss = 0.0070372 (* 1 = 0.0070372 loss)
I1021 17:17:52.000254 14900 sgd_solver.cpp:46] MultiStep Status: Iteration 29600, step = 4
I1021 17:17:52.000254 14900 sgd_solver.cpp:105] Iteration 29600, lr = 1e-05
I1021 17:17:56.550062 14900 solver.cpp:218] Iteration 29700 (21.9782 iter/s, 4.54996s/100 iters), loss = 0.0174969
I1021 17:17:56.550062 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:17:56.550062 14900 solver.cpp:237]     Train net output #1: loss = 0.0174971 (* 1 = 0.0174971 loss)
I1021 17:17:56.550062 14900 sgd_solver.cpp:105] Iteration 29700, lr = 1e-05
I1021 17:18:01.111476 14900 solver.cpp:218] Iteration 29800 (21.9232 iter/s, 4.56138s/100 iters), loss = 0.00572667
I1021 17:18:01.111476 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:01.112478 14900 solver.cpp:237]     Train net output #1: loss = 0.00572694 (* 1 = 0.00572694 loss)
I1021 17:18:01.112478 14900 sgd_solver.cpp:105] Iteration 29800, lr = 1e-05
I1021 17:18:05.668773 14900 solver.cpp:218] Iteration 29900 (21.9483 iter/s, 4.55615s/100 iters), loss = 0.00155031
I1021 17:18:05.668773 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:05.668773 14900 solver.cpp:237]     Train net output #1: loss = 0.00155059 (* 1 = 0.00155059 loss)
I1021 17:18:05.668773 14900 sgd_solver.cpp:105] Iteration 29900, lr = 1e-05
I1021 17:18:09.996575  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:18:10.176082 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_30000.caffemodel
I1021 17:18:10.188081 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_30000.solverstate
I1021 17:18:10.192585 14900 solver.cpp:330] Iteration 30000, Testing net (#0)
I1021 17:18:10.192585 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:18:11.255158 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:18:11.298660 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:18:11.298660 14900 solver.cpp:397]     Test net output #1: loss = 0.00992212 (* 1 = 0.00992212 loss)
I1021 17:18:11.341161 14900 solver.cpp:218] Iteration 30000 (17.6282 iter/s, 5.67272s/100 iters), loss = 0.00152832
I1021 17:18:11.341161 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:11.341161 14900 solver.cpp:237]     Train net output #1: loss = 0.0015286 (* 1 = 0.0015286 loss)
I1021 17:18:11.341161 14900 sgd_solver.cpp:105] Iteration 30000, lr = 1e-05
I1021 17:18:15.890897 14900 solver.cpp:218] Iteration 30100 (21.983 iter/s, 4.54896s/100 iters), loss = 0.00712135
I1021 17:18:15.890897 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:15.890897 14900 solver.cpp:237]     Train net output #1: loss = 0.00712162 (* 1 = 0.00712162 loss)
I1021 17:18:15.890897 14900 sgd_solver.cpp:105] Iteration 30100, lr = 1e-05
I1021 17:18:20.440206 14900 solver.cpp:218] Iteration 30200 (21.9855 iter/s, 4.54846s/100 iters), loss = 0.0050258
I1021 17:18:20.440206 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:20.440206 14900 solver.cpp:237]     Train net output #1: loss = 0.00502606 (* 1 = 0.00502606 loss)
I1021 17:18:20.440206 14900 sgd_solver.cpp:105] Iteration 30200, lr = 1e-05
I1021 17:18:24.983728 14900 solver.cpp:218] Iteration 30300 (22.0084 iter/s, 4.54372s/100 iters), loss = 0.00510488
I1021 17:18:24.983728 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:24.983728 14900 solver.cpp:237]     Train net output #1: loss = 0.00510515 (* 1 = 0.00510515 loss)
I1021 17:18:24.983728 14900 sgd_solver.cpp:105] Iteration 30300, lr = 1e-05
I1021 17:18:29.531116 14900 solver.cpp:218] Iteration 30400 (21.9912 iter/s, 4.54727s/100 iters), loss = 0.00134307
I1021 17:18:29.531116 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:29.531116 14900 solver.cpp:237]     Train net output #1: loss = 0.00134334 (* 1 = 0.00134334 loss)
I1021 17:18:29.531116 14900 sgd_solver.cpp:105] Iteration 30400, lr = 1e-05
I1021 17:18:34.086002 14900 solver.cpp:218] Iteration 30500 (21.9592 iter/s, 4.55389s/100 iters), loss = 0.00121426
I1021 17:18:34.086002 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:34.086002 14900 solver.cpp:237]     Train net output #1: loss = 0.00121454 (* 1 = 0.00121454 loss)
I1021 17:18:34.086002 14900 sgd_solver.cpp:105] Iteration 30500, lr = 1e-05
I1021 17:18:38.410801  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:18:38.592810 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_30600.caffemodel
I1021 17:18:38.604813 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_30600.solverstate
I1021 17:18:38.608817 14900 solver.cpp:330] Iteration 30600, Testing net (#0)
I1021 17:18:38.608817 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:18:39.672899 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:18:39.715948 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:18:39.715948 14900 solver.cpp:397]     Test net output #1: loss = 0.00991861 (* 1 = 0.00991861 loss)
I1021 17:18:39.758932 14900 solver.cpp:218] Iteration 30600 (17.6281 iter/s, 5.67277s/100 iters), loss = 0.00169083
I1021 17:18:39.758932 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:39.758932 14900 solver.cpp:237]     Train net output #1: loss = 0.00169109 (* 1 = 0.00169109 loss)
I1021 17:18:39.758932 14900 sgd_solver.cpp:105] Iteration 30600, lr = 1e-05
I1021 17:18:44.303526 14900 solver.cpp:218] Iteration 30700 (22.0078 iter/s, 4.54385s/100 iters), loss = 0.00581614
I1021 17:18:44.303526 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:44.303526 14900 solver.cpp:237]     Train net output #1: loss = 0.0058164 (* 1 = 0.0058164 loss)
I1021 17:18:44.303526 14900 sgd_solver.cpp:105] Iteration 30700, lr = 1e-05
I1021 17:18:48.853586 14900 solver.cpp:218] Iteration 30800 (21.9785 iter/s, 4.5499s/100 iters), loss = 0.00403213
I1021 17:18:48.853586 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:48.853586 14900 solver.cpp:237]     Train net output #1: loss = 0.00403239 (* 1 = 0.00403239 loss)
I1021 17:18:48.853586 14900 sgd_solver.cpp:105] Iteration 30800, lr = 1e-05
I1021 17:18:53.399098 14900 solver.cpp:218] Iteration 30900 (22.0012 iter/s, 4.5452s/100 iters), loss = 0.0194855
I1021 17:18:53.399098 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:18:53.399098 14900 solver.cpp:237]     Train net output #1: loss = 0.0194858 (* 1 = 0.0194858 loss)
I1021 17:18:53.399098 14900 sgd_solver.cpp:105] Iteration 30900, lr = 1e-05
I1021 17:18:57.944468 14900 solver.cpp:218] Iteration 31000 (22.0045 iter/s, 4.54452s/100 iters), loss = 0.00567687
I1021 17:18:57.944468 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:18:57.944468 14900 solver.cpp:237]     Train net output #1: loss = 0.00567713 (* 1 = 0.00567713 loss)
I1021 17:18:57.944468 14900 sgd_solver.cpp:105] Iteration 31000, lr = 1e-05
I1021 17:19:02.490957 14900 solver.cpp:218] Iteration 31100 (21.9932 iter/s, 4.54686s/100 iters), loss = 0.0028489
I1021 17:19:02.490957 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:02.490957 14900 solver.cpp:237]     Train net output #1: loss = 0.00284916 (* 1 = 0.00284916 loss)
I1021 17:19:02.490957 14900 sgd_solver.cpp:105] Iteration 31100, lr = 1e-05
I1021 17:19:06.819902  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:19:07.000411 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_31200.caffemodel
I1021 17:19:07.012409 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_31200.solverstate
I1021 17:19:07.016412 14900 solver.cpp:330] Iteration 31200, Testing net (#0)
I1021 17:19:07.016412 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:19:08.080821 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:19:08.123322 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:19:08.123322 14900 solver.cpp:397]     Test net output #1: loss = 0.00992417 (* 1 = 0.00992417 loss)
I1021 17:19:08.165822 14900 solver.cpp:218] Iteration 31200 (17.6232 iter/s, 5.67435s/100 iters), loss = 0.00177777
I1021 17:19:08.165822 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:08.165822 14900 solver.cpp:237]     Train net output #1: loss = 0.00177803 (* 1 = 0.00177803 loss)
I1021 17:19:08.165822 14900 sgd_solver.cpp:105] Iteration 31200, lr = 1e-05
I1021 17:19:12.718097 14900 solver.cpp:218] Iteration 31300 (21.9689 iter/s, 4.55188s/100 iters), loss = 0.00306294
I1021 17:19:12.718097 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:12.718097 14900 solver.cpp:237]     Train net output #1: loss = 0.0030632 (* 1 = 0.0030632 loss)
I1021 17:19:12.718097 14900 sgd_solver.cpp:105] Iteration 31300, lr = 1e-05
I1021 17:19:17.270406 14900 solver.cpp:218] Iteration 31400 (21.9699 iter/s, 4.55168s/100 iters), loss = 0.00262045
I1021 17:19:17.270406 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:17.270406 14900 solver.cpp:237]     Train net output #1: loss = 0.0026207 (* 1 = 0.0026207 loss)
I1021 17:19:17.270406 14900 sgd_solver.cpp:105] Iteration 31400, lr = 1e-05
I1021 17:19:21.820869 14900 solver.cpp:218] Iteration 31500 (21.9773 iter/s, 4.55016s/100 iters), loss = 0.0029345
I1021 17:19:21.820869 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:21.820869 14900 solver.cpp:237]     Train net output #1: loss = 0.00293476 (* 1 = 0.00293476 loss)
I1021 17:19:21.820869 14900 sgd_solver.cpp:105] Iteration 31500, lr = 1e-05
I1021 17:19:26.360231 14900 solver.cpp:218] Iteration 31600 (22.03 iter/s, 4.53926s/100 iters), loss = 0.00158899
I1021 17:19:26.360231 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:26.360231 14900 solver.cpp:237]     Train net output #1: loss = 0.00158924 (* 1 = 0.00158924 loss)
I1021 17:19:26.360231 14900 sgd_solver.cpp:105] Iteration 31600, lr = 1e-05
I1021 17:19:30.912724 14900 solver.cpp:218] Iteration 31700 (21.969 iter/s, 4.55187s/100 iters), loss = 0.00249499
I1021 17:19:30.912724 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:30.912724 14900 solver.cpp:237]     Train net output #1: loss = 0.00249524 (* 1 = 0.00249524 loss)
I1021 17:19:30.912724 14900 sgd_solver.cpp:105] Iteration 31700, lr = 1e-05
I1021 17:19:35.241114  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:19:35.421125 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_31800.caffemodel
I1021 17:19:35.434125 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_31800.solverstate
I1021 17:19:35.438125 14900 solver.cpp:330] Iteration 31800, Testing net (#0)
I1021 17:19:35.438125 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:19:36.501204 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:19:36.544214 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:19:36.544214 14900 solver.cpp:397]     Test net output #1: loss = 0.00992118 (* 1 = 0.00992118 loss)
I1021 17:19:36.587206 14900 solver.cpp:218] Iteration 31800 (17.6226 iter/s, 5.67452s/100 iters), loss = 0.00193812
I1021 17:19:36.588207 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:36.588207 14900 solver.cpp:237]     Train net output #1: loss = 0.00193837 (* 1 = 0.00193837 loss)
I1021 17:19:36.588207 14900 sgd_solver.cpp:105] Iteration 31800, lr = 1e-05
I1021 17:19:41.138468 14900 solver.cpp:218] Iteration 31900 (21.9771 iter/s, 4.5502s/100 iters), loss = 0.016051
I1021 17:19:41.138468 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:19:41.138468 14900 solver.cpp:237]     Train net output #1: loss = 0.0160512 (* 1 = 0.0160512 loss)
I1021 17:19:41.138468 14900 sgd_solver.cpp:105] Iteration 31900, lr = 1e-05
I1021 17:19:45.694772 14900 solver.cpp:218] Iteration 32000 (21.9494 iter/s, 4.55594s/100 iters), loss = 0.00346488
I1021 17:19:45.694772 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:45.694772 14900 solver.cpp:237]     Train net output #1: loss = 0.00346513 (* 1 = 0.00346513 loss)
I1021 17:19:45.694772 14900 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 5
I1021 17:19:45.694772 14900 sgd_solver.cpp:105] Iteration 32000, lr = 1e-06
I1021 17:19:50.244091 14900 solver.cpp:218] Iteration 32100 (21.9839 iter/s, 4.54879s/100 iters), loss = 0.00544069
I1021 17:19:50.244091 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:50.244091 14900 solver.cpp:237]     Train net output #1: loss = 0.00544094 (* 1 = 0.00544094 loss)
I1021 17:19:50.244091 14900 sgd_solver.cpp:105] Iteration 32100, lr = 1e-06
I1021 17:19:54.791772 14900 solver.cpp:218] Iteration 32200 (21.9909 iter/s, 4.54734s/100 iters), loss = 0.00141112
I1021 17:19:54.791772 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:54.791772 14900 solver.cpp:237]     Train net output #1: loss = 0.00141136 (* 1 = 0.00141136 loss)
I1021 17:19:54.791772 14900 sgd_solver.cpp:105] Iteration 32200, lr = 1e-06
I1021 17:19:59.338361 14900 solver.cpp:218] Iteration 32300 (21.9943 iter/s, 4.54664s/100 iters), loss = 0.00344161
I1021 17:19:59.338361 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:19:59.338361 14900 solver.cpp:237]     Train net output #1: loss = 0.00344184 (* 1 = 0.00344184 loss)
I1021 17:19:59.338361 14900 sgd_solver.cpp:105] Iteration 32300, lr = 1e-06
I1021 17:20:03.656643  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:20:03.835656 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_32400.caffemodel
I1021 17:20:03.848650 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_32400.solverstate
I1021 17:20:03.852650 14900 solver.cpp:330] Iteration 32400, Testing net (#0)
I1021 17:20:03.852650 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:20:04.916728 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:20:04.959725 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:20:04.959725 14900 solver.cpp:397]     Test net output #1: loss = 0.00992117 (* 1 = 0.00992117 loss)
I1021 17:20:05.003733 14900 solver.cpp:218] Iteration 32400 (17.6538 iter/s, 5.66451s/100 iters), loss = 0.00814641
I1021 17:20:05.003733 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:05.003733 14900 solver.cpp:237]     Train net output #1: loss = 0.00814665 (* 1 = 0.00814665 loss)
I1021 17:20:05.003733 14900 sgd_solver.cpp:105] Iteration 32400, lr = 1e-06
I1021 17:20:09.561102 14900 solver.cpp:218] Iteration 32500 (21.9429 iter/s, 4.55728s/100 iters), loss = 0.0061361
I1021 17:20:09.561102 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:09.561102 14900 solver.cpp:237]     Train net output #1: loss = 0.00613633 (* 1 = 0.00613633 loss)
I1021 17:20:09.561102 14900 sgd_solver.cpp:105] Iteration 32500, lr = 1e-06
I1021 17:20:14.113247 14900 solver.cpp:218] Iteration 32600 (21.9717 iter/s, 4.55132s/100 iters), loss = 0.00455127
I1021 17:20:14.113247 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:14.113247 14900 solver.cpp:237]     Train net output #1: loss = 0.00455151 (* 1 = 0.00455151 loss)
I1021 17:20:14.113247 14900 sgd_solver.cpp:105] Iteration 32600, lr = 1e-06
I1021 17:20:18.657104 14900 solver.cpp:218] Iteration 32700 (22.0057 iter/s, 4.54427s/100 iters), loss = 0.00671152
I1021 17:20:18.657104 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:18.657104 14900 solver.cpp:237]     Train net output #1: loss = 0.00671175 (* 1 = 0.00671175 loss)
I1021 17:20:18.657104 14900 sgd_solver.cpp:105] Iteration 32700, lr = 1e-06
I1021 17:20:23.201196 14900 solver.cpp:218] Iteration 32800 (22.0083 iter/s, 4.54375s/100 iters), loss = 0.000891292
I1021 17:20:23.201196 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:23.201196 14900 solver.cpp:237]     Train net output #1: loss = 0.000891522 (* 1 = 0.000891522 loss)
I1021 17:20:23.201196 14900 sgd_solver.cpp:105] Iteration 32800, lr = 1e-06
I1021 17:20:27.740384 14900 solver.cpp:218] Iteration 32900 (22.0344 iter/s, 4.53835s/100 iters), loss = 0.00285868
I1021 17:20:27.740384 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:27.740384 14900 solver.cpp:237]     Train net output #1: loss = 0.00285892 (* 1 = 0.00285892 loss)
I1021 17:20:27.740384 14900 sgd_solver.cpp:105] Iteration 32900, lr = 1e-06
I1021 17:20:32.062662  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:20:32.242669 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_33000.caffemodel
I1021 17:20:32.254670 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_33000.solverstate
I1021 17:20:32.258669 14900 solver.cpp:330] Iteration 33000, Testing net (#0)
I1021 17:20:32.259670 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:20:33.323757 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:20:33.367250 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:20:33.367250 14900 solver.cpp:397]     Test net output #1: loss = 0.00992471 (* 1 = 0.00992471 loss)
I1021 17:20:33.409751 14900 solver.cpp:218] Iteration 33000 (17.6385 iter/s, 5.66943s/100 iters), loss = 0.00196268
I1021 17:20:33.409751 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:33.409751 14900 solver.cpp:237]     Train net output #1: loss = 0.00196293 (* 1 = 0.00196293 loss)
I1021 17:20:33.409751 14900 sgd_solver.cpp:105] Iteration 33000, lr = 1e-06
I1021 17:20:37.970651 14900 solver.cpp:218] Iteration 33100 (21.9306 iter/s, 4.55984s/100 iters), loss = 0.0152363
I1021 17:20:37.970651 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:20:37.970651 14900 solver.cpp:237]     Train net output #1: loss = 0.0152365 (* 1 = 0.0152365 loss)
I1021 17:20:37.970651 14900 sgd_solver.cpp:105] Iteration 33100, lr = 1e-06
I1021 17:20:42.525516 14900 solver.cpp:218] Iteration 33200 (21.9557 iter/s, 4.55463s/100 iters), loss = 0.00503014
I1021 17:20:42.525516 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:42.525516 14900 solver.cpp:237]     Train net output #1: loss = 0.00503038 (* 1 = 0.00503038 loss)
I1021 17:20:42.525516 14900 sgd_solver.cpp:105] Iteration 33200, lr = 1e-06
I1021 17:20:47.074445 14900 solver.cpp:218] Iteration 33300 (21.9858 iter/s, 4.54839s/100 iters), loss = 0.00635665
I1021 17:20:47.074445 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:47.074445 14900 solver.cpp:237]     Train net output #1: loss = 0.00635688 (* 1 = 0.00635688 loss)
I1021 17:20:47.074445 14900 sgd_solver.cpp:105] Iteration 33300, lr = 1e-06
I1021 17:20:51.625041 14900 solver.cpp:218] Iteration 33400 (21.976 iter/s, 4.55043s/100 iters), loss = 0.0024465
I1021 17:20:51.625041 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:51.625041 14900 solver.cpp:237]     Train net output #1: loss = 0.00244674 (* 1 = 0.00244674 loss)
I1021 17:20:51.625041 14900 sgd_solver.cpp:105] Iteration 33400, lr = 1e-06
I1021 17:20:56.176337 14900 solver.cpp:218] Iteration 33500 (21.9748 iter/s, 4.55066s/100 iters), loss = 0.00310898
I1021 17:20:56.176337 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:20:56.176337 14900 solver.cpp:237]     Train net output #1: loss = 0.00310922 (* 1 = 0.00310922 loss)
I1021 17:20:56.176337 14900 sgd_solver.cpp:105] Iteration 33500, lr = 1e-06
I1021 17:21:00.502945  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:21:00.683957 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_33600.caffemodel
I1021 17:21:00.695957 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_33600.solverstate
I1021 17:21:00.699957 14900 solver.cpp:330] Iteration 33600, Testing net (#0)
I1021 17:21:00.699957 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:21:01.764029 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:21:01.807031 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:21:01.807031 14900 solver.cpp:397]     Test net output #1: loss = 0.00992292 (* 1 = 0.00992292 loss)
I1021 17:21:01.850031 14900 solver.cpp:218] Iteration 33600 (17.6242 iter/s, 5.67401s/100 iters), loss = 0.00585965
I1021 17:21:01.850031 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:01.850031 14900 solver.cpp:237]     Train net output #1: loss = 0.00585988 (* 1 = 0.00585988 loss)
I1021 17:21:01.850031 14900 sgd_solver.cpp:105] Iteration 33600, lr = 1e-06
I1021 17:21:06.398331 14900 solver.cpp:218] Iteration 33700 (21.9884 iter/s, 4.54785s/100 iters), loss = 0.0022326
I1021 17:21:06.398331 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:06.398331 14900 solver.cpp:237]     Train net output #1: loss = 0.00223283 (* 1 = 0.00223283 loss)
I1021 17:21:06.398331 14900 sgd_solver.cpp:105] Iteration 33700, lr = 1e-06
I1021 17:21:10.948599 14900 solver.cpp:218] Iteration 33800 (21.9812 iter/s, 4.54935s/100 iters), loss = 0.00518184
I1021 17:21:10.948599 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:10.948599 14900 solver.cpp:237]     Train net output #1: loss = 0.00518207 (* 1 = 0.00518207 loss)
I1021 17:21:10.948599 14900 sgd_solver.cpp:105] Iteration 33800, lr = 1e-06
I1021 17:21:15.499881 14900 solver.cpp:218] Iteration 33900 (21.9707 iter/s, 4.55151s/100 iters), loss = 0.013353
I1021 17:21:15.499881 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:21:15.500879 14900 solver.cpp:237]     Train net output #1: loss = 0.0133533 (* 1 = 0.0133533 loss)
I1021 17:21:15.500879 14900 sgd_solver.cpp:105] Iteration 33900, lr = 1e-06
I1021 17:21:20.054164 14900 solver.cpp:218] Iteration 34000 (21.9641 iter/s, 4.55288s/100 iters), loss = 0.00253981
I1021 17:21:20.054164 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:20.054164 14900 solver.cpp:237]     Train net output #1: loss = 0.00254004 (* 1 = 0.00254004 loss)
I1021 17:21:20.054164 14900 sgd_solver.cpp:105] Iteration 34000, lr = 1e-06
I1021 17:21:24.604547 14900 solver.cpp:218] Iteration 34100 (21.9762 iter/s, 4.55037s/100 iters), loss = 0.00291844
I1021 17:21:24.604547 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:24.604547 14900 solver.cpp:237]     Train net output #1: loss = 0.00291866 (* 1 = 0.00291866 loss)
I1021 17:21:24.604547 14900 sgd_solver.cpp:105] Iteration 34100, lr = 1e-06
I1021 17:21:28.925839  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:21:29.105856 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_34200.caffemodel
I1021 17:21:29.118856 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_34200.solverstate
I1021 17:21:29.121875 14900 solver.cpp:330] Iteration 34200, Testing net (#0)
I1021 17:21:29.122874 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:21:30.184989 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:21:30.227988 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:21:30.227988 14900 solver.cpp:397]     Test net output #1: loss = 0.00992402 (* 1 = 0.00992402 loss)
I1021 17:21:30.271495 14900 solver.cpp:218] Iteration 34200 (17.6478 iter/s, 5.66642s/100 iters), loss = 0.00254179
I1021 17:21:30.271495 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:30.271495 14900 solver.cpp:237]     Train net output #1: loss = 0.00254202 (* 1 = 0.00254202 loss)
I1021 17:21:30.271495 14900 sgd_solver.cpp:105] Iteration 34200, lr = 1e-06
I1021 17:21:34.827293 14900 solver.cpp:218] Iteration 34300 (21.9509 iter/s, 4.55561s/100 iters), loss = 0.00258277
I1021 17:21:34.827293 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:34.827293 14900 solver.cpp:237]     Train net output #1: loss = 0.00258301 (* 1 = 0.00258301 loss)
I1021 17:21:34.827293 14900 sgd_solver.cpp:105] Iteration 34300, lr = 1e-06
I1021 17:21:39.376106 14900 solver.cpp:218] Iteration 34400 (21.9866 iter/s, 4.54823s/100 iters), loss = 0.00681117
I1021 17:21:39.376106 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:39.376106 14900 solver.cpp:237]     Train net output #1: loss = 0.00681141 (* 1 = 0.00681141 loss)
I1021 17:21:39.376106 14900 sgd_solver.cpp:105] Iteration 34400, lr = 1e-06
I1021 17:21:43.939923 14900 solver.cpp:218] Iteration 34500 (21.9113 iter/s, 4.56386s/100 iters), loss = 0.0117287
I1021 17:21:43.939923 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:21:43.939923 14900 solver.cpp:237]     Train net output #1: loss = 0.0117289 (* 1 = 0.0117289 loss)
I1021 17:21:43.939923 14900 sgd_solver.cpp:105] Iteration 34500, lr = 1e-06
I1021 17:21:48.498209 14900 solver.cpp:218] Iteration 34600 (21.9427 iter/s, 4.55733s/100 iters), loss = 0.00379622
I1021 17:21:48.498209 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:48.498209 14900 solver.cpp:237]     Train net output #1: loss = 0.00379646 (* 1 = 0.00379646 loss)
I1021 17:21:48.498209 14900 sgd_solver.cpp:105] Iteration 34600, lr = 1e-06
I1021 17:21:53.052486 14900 solver.cpp:218] Iteration 34700 (21.9615 iter/s, 4.55343s/100 iters), loss = 0.0051963
I1021 17:21:53.052486 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:53.052486 14900 solver.cpp:237]     Train net output #1: loss = 0.00519654 (* 1 = 0.00519654 loss)
I1021 17:21:53.052486 14900 sgd_solver.cpp:105] Iteration 34700, lr = 1e-06
I1021 17:21:57.381278  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:21:57.562872 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_34800.caffemodel
I1021 17:21:57.578892 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_34800.solverstate
I1021 17:21:57.582906 14900 solver.cpp:330] Iteration 34800, Testing net (#0)
I1021 17:21:57.582906 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:21:58.644134 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:21:58.688138 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:21:58.688138 14900 solver.cpp:397]     Test net output #1: loss = 0.00992057 (* 1 = 0.00992057 loss)
I1021 17:21:58.731137 14900 solver.cpp:218] Iteration 34800 (17.6109 iter/s, 5.67831s/100 iters), loss = 0.00120459
I1021 17:21:58.731137 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:21:58.731137 14900 solver.cpp:237]     Train net output #1: loss = 0.00120483 (* 1 = 0.00120483 loss)
I1021 17:21:58.731137 14900 sgd_solver.cpp:105] Iteration 34800, lr = 1e-06
I1021 17:22:03.283489 14900 solver.cpp:218] Iteration 34900 (21.9686 iter/s, 4.55195s/100 iters), loss = 0.0138024
I1021 17:22:03.283489 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:22:03.283489 14900 solver.cpp:237]     Train net output #1: loss = 0.0138027 (* 1 = 0.0138027 loss)
I1021 17:22:03.283489 14900 sgd_solver.cpp:105] Iteration 34900, lr = 1e-06
I1021 17:22:07.829776 14900 solver.cpp:218] Iteration 35000 (21.9956 iter/s, 4.54636s/100 iters), loss = 0.00528579
I1021 17:22:07.829776 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:07.829776 14900 solver.cpp:237]     Train net output #1: loss = 0.00528604 (* 1 = 0.00528604 loss)
I1021 17:22:07.829776 14900 sgd_solver.cpp:105] Iteration 35000, lr = 1e-06
I1021 17:22:12.361047 14900 solver.cpp:218] Iteration 35100 (22.0695 iter/s, 4.53114s/100 iters), loss = 0.00552403
I1021 17:22:12.361047 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:12.361047 14900 solver.cpp:237]     Train net output #1: loss = 0.00552428 (* 1 = 0.00552428 loss)
I1021 17:22:12.361047 14900 sgd_solver.cpp:105] Iteration 35100, lr = 1e-06
I1021 17:22:16.907364 14900 solver.cpp:218] Iteration 35200 (21.9994 iter/s, 4.54558s/100 iters), loss = 0.00254223
I1021 17:22:16.907364 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:16.907364 14900 solver.cpp:237]     Train net output #1: loss = 0.00254248 (* 1 = 0.00254248 loss)
I1021 17:22:16.907364 14900 sgd_solver.cpp:105] Iteration 35200, lr = 1e-06
I1021 17:22:21.448801 14900 solver.cpp:218] Iteration 35300 (22.0229 iter/s, 4.54073s/100 iters), loss = 0.00317759
I1021 17:22:21.448801 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:21.448801 14900 solver.cpp:237]     Train net output #1: loss = 0.00317784 (* 1 = 0.00317784 loss)
I1021 17:22:21.448801 14900 sgd_solver.cpp:105] Iteration 35300, lr = 1e-06
I1021 17:22:25.771145  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:22:25.950150 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_35400.caffemodel
I1021 17:22:25.962149 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_35400.solverstate
I1021 17:22:25.966154 14900 solver.cpp:330] Iteration 35400, Testing net (#0)
I1021 17:22:25.966154 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:22:27.027271 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:22:27.071285 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:22:27.071285 14900 solver.cpp:397]     Test net output #1: loss = 0.00991904 (* 1 = 0.00991904 loss)
I1021 17:22:27.114274 14900 solver.cpp:218] Iteration 35400 (17.6517 iter/s, 5.66518s/100 iters), loss = 0.00818363
I1021 17:22:27.114274 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:27.114274 14900 solver.cpp:237]     Train net output #1: loss = 0.00818388 (* 1 = 0.00818388 loss)
I1021 17:22:27.114274 14900 sgd_solver.cpp:105] Iteration 35400, lr = 1e-06
I1021 17:22:31.667389 14900 solver.cpp:218] Iteration 35500 (21.966 iter/s, 4.5525s/100 iters), loss = 0.00557208
I1021 17:22:31.667389 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:31.667389 14900 solver.cpp:237]     Train net output #1: loss = 0.00557234 (* 1 = 0.00557234 loss)
I1021 17:22:31.667389 14900 sgd_solver.cpp:105] Iteration 35500, lr = 1e-06
I1021 17:22:36.229874 14900 solver.cpp:218] Iteration 35600 (21.9153 iter/s, 4.56302s/100 iters), loss = 0.0132237
I1021 17:22:36.230878 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:36.230878 14900 solver.cpp:237]     Train net output #1: loss = 0.013224 (* 1 = 0.013224 loss)
I1021 17:22:36.230878 14900 sgd_solver.cpp:105] Iteration 35600, lr = 1e-06
I1021 17:22:40.785648 14900 solver.cpp:218] Iteration 35700 (21.9561 iter/s, 4.55455s/100 iters), loss = 0.013794
I1021 17:22:40.785648 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:22:40.785648 14900 solver.cpp:237]     Train net output #1: loss = 0.0137942 (* 1 = 0.0137942 loss)
I1021 17:22:40.785648 14900 sgd_solver.cpp:105] Iteration 35700, lr = 1e-06
I1021 17:22:45.334261 14900 solver.cpp:218] Iteration 35800 (21.983 iter/s, 4.54896s/100 iters), loss = 0.00591866
I1021 17:22:45.334261 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:45.335263 14900 solver.cpp:237]     Train net output #1: loss = 0.00591891 (* 1 = 0.00591891 loss)
I1021 17:22:45.335263 14900 sgd_solver.cpp:105] Iteration 35800, lr = 1e-06
I1021 17:22:49.887593 14900 solver.cpp:218] Iteration 35900 (21.968 iter/s, 4.55207s/100 iters), loss = 0.00184918
I1021 17:22:49.887593 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:49.887593 14900 solver.cpp:237]     Train net output #1: loss = 0.00184944 (* 1 = 0.00184944 loss)
I1021 17:22:49.887593 14900 sgd_solver.cpp:105] Iteration 35900, lr = 1e-06
I1021 17:22:54.216960  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:22:54.396973 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_36000.caffemodel
I1021 17:22:54.409973 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_36000.solverstate
I1021 17:22:54.414477 14900 solver.cpp:330] Iteration 36000, Testing net (#0)
I1021 17:22:54.414978 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:22:55.475103 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:22:55.520128 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:22:55.520128 14900 solver.cpp:397]     Test net output #1: loss = 0.00991994 (* 1 = 0.00991994 loss)
I1021 17:22:55.563107 14900 solver.cpp:218] Iteration 36000 (17.6196 iter/s, 5.67549s/100 iters), loss = 0.00148349
I1021 17:22:55.563107 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:22:55.563107 14900 solver.cpp:237]     Train net output #1: loss = 0.00148376 (* 1 = 0.00148376 loss)
I1021 17:22:55.563107 14900 sgd_solver.cpp:105] Iteration 36000, lr = 1e-06
I1021 17:23:00.122431 14900 solver.cpp:218] Iteration 36100 (21.9355 iter/s, 4.55883s/100 iters), loss = 0.00343946
I1021 17:23:00.122431 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:00.122431 14900 solver.cpp:237]     Train net output #1: loss = 0.00343972 (* 1 = 0.00343972 loss)
I1021 17:23:00.122431 14900 sgd_solver.cpp:105] Iteration 36100, lr = 1e-06
I1021 17:23:04.694775 14900 solver.cpp:218] Iteration 36200 (21.872 iter/s, 4.57205s/100 iters), loss = 0.00927384
I1021 17:23:04.694775 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:04.694775 14900 solver.cpp:237]     Train net output #1: loss = 0.0092741 (* 1 = 0.0092741 loss)
I1021 17:23:04.694775 14900 sgd_solver.cpp:105] Iteration 36200, lr = 1e-06
I1021 17:23:09.255100 14900 solver.cpp:218] Iteration 36300 (21.9302 iter/s, 4.55992s/100 iters), loss = 0.00628113
I1021 17:23:09.255100 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:09.255100 14900 solver.cpp:237]     Train net output #1: loss = 0.00628139 (* 1 = 0.00628139 loss)
I1021 17:23:09.255100 14900 sgd_solver.cpp:105] Iteration 36300, lr = 1e-06
I1021 17:23:13.806593 14900 solver.cpp:218] Iteration 36400 (21.9716 iter/s, 4.55133s/100 iters), loss = 0.000893287
I1021 17:23:13.806593 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:13.806593 14900 solver.cpp:237]     Train net output #1: loss = 0.000893549 (* 1 = 0.000893549 loss)
I1021 17:23:13.806593 14900 sgd_solver.cpp:105] Iteration 36400, lr = 1e-06
I1021 17:23:18.352939 14900 solver.cpp:218] Iteration 36500 (21.9978 iter/s, 4.5459s/100 iters), loss = 0.00444997
I1021 17:23:18.352939 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:18.352939 14900 solver.cpp:237]     Train net output #1: loss = 0.00445023 (* 1 = 0.00445023 loss)
I1021 17:23:18.352939 14900 sgd_solver.cpp:105] Iteration 36500, lr = 1e-06
I1021 17:23:22.669167  2868 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:23:22.850175 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_36600.caffemodel
I1021 17:23:22.863175 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_36600.solverstate
I1021 17:23:22.867175 14900 solver.cpp:330] Iteration 36600, Testing net (#0)
I1021 17:23:22.867175 14900 net.cpp:676] Ignoring source layer accuracy_training
I1021 17:23:23.931243 17916 data_layer.cpp:73] Restarting data prefetching from start.
I1021 17:23:23.976243 14900 solver.cpp:397]     Test net output #0: accuracy = 0.997
I1021 17:23:23.976243 14900 solver.cpp:397]     Test net output #1: loss = 0.00992098 (* 1 = 0.00992098 loss)
I1021 17:23:24.019251 14900 solver.cpp:218] Iteration 36600 (17.6496 iter/s, 5.66583s/100 iters), loss = 0.0018931
I1021 17:23:24.019752 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:24.019752 14900 solver.cpp:237]     Train net output #1: loss = 0.00189335 (* 1 = 0.00189335 loss)
I1021 17:23:24.019752 14900 sgd_solver.cpp:105] Iteration 36600, lr = 1e-06
I1021 17:23:28.570598 14900 solver.cpp:218] Iteration 36700 (21.9735 iter/s, 4.55093s/100 iters), loss = 0.00482712
I1021 17:23:28.570598 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:28.570598 14900 solver.cpp:237]     Train net output #1: loss = 0.00482737 (* 1 = 0.00482737 loss)
I1021 17:23:28.570598 14900 sgd_solver.cpp:105] Iteration 36700, lr = 1e-06
I1021 17:23:33.126421 14900 solver.cpp:218] Iteration 36800 (21.9531 iter/s, 4.55517s/100 iters), loss = 0.00429695
I1021 17:23:33.126421 14900 solver.cpp:237]     Train net output #0: accuracy_training = 1
I1021 17:23:33.126421 14900 solver.cpp:237]     Train net output #1: loss = 0.00429719 (* 1 = 0.00429719 loss)
I1021 17:23:33.126421 14900 sgd_solver.cpp:105] Iteration 36800, lr = 1e-06
I1021 17:23:37.677352 14900 solver.cpp:218] Iteration 36900 (21.9745 iter/s, 4.55073s/100 iters), loss = 0.00849073
I1021 17:23:37.677352 14900 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I1021 17:23:37.677352 14900 solver.cpp:237]     Train net output #1: loss = 0.00849098 (* 1 = 0.00849098 loss)
I1021 17:23:37.677352 14900 sgd_solver.cpp:105] Iteration 36900, lr = 1e-06
I1021 17:23:42.181658 14900 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_37000.caffemodel
I1021 17:23:42.193656 14900 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/mnist_slimnet_300k__iter_37000.solverstate
I1021 17:23:42.210656 14900 solver.cpp:310] Iteration 37000, loss = 0.00367994
I1021 17:23:42.210656 14900 solver.cpp:315] Optimization Done.
I1021 17:23:42.210656 14900 caffe.cpp:260] Optimization Done.
