
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0626 01:07:52.890422 17260 caffe.cpp:219] Using GPUs 0
I0626 01:07:53.083673 17260 caffe.cpp:224] GPU 0: GeForce GTX 1080
I0626 01:07:53.429081 17260 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0626 01:07:53.449080 17260 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 234000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "examples/cifar10/Shallow_wide_1M_6L"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 32000
stepvalue: 48000
stepvalue: 54000
stepvalue: 74000
type: "Nesterov"
I0626 01:07:53.449080 17260 solver.cpp:87] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0626 01:07:53.449080 17260 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0626 01:07:53.449080 17260 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0626 01:07:53.449080 17260 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0626 01:07:53.449080 17260 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_Shallow_wide_1M_NoDrp_6L"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1_0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "pool_GP"
  type: "Pooling"
  bottom: "relu3"
  top: "pool_GP"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool_GP"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0626 01:07:53.469084 17260 layer_factory.cpp:58] Creating layer cifar
I0626 01:07:53.489084 17260 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0626 01:07:53.489084 17260 net.cpp:84] Creating Layer cifar
I0626 01:07:53.489084 17260 net.cpp:380] cifar -> data
I0626 01:07:53.489084 17260 net.cpp:380] cifar -> label
I0626 01:07:53.489084 17260 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0626 01:07:53.489084 17260 data_layer.cpp:45] output data size: 100,3,32,32
I0626 01:07:53.501098 17260 net.cpp:122] Setting up cifar
I0626 01:07:53.501098 17260 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0626 01:07:53.501098 17260 net.cpp:129] Top shape: 100 (100)
I0626 01:07:53.501098 17260 net.cpp:137] Memory required for data: 1229200
I0626 01:07:53.501098 17260 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0626 01:07:53.501098 17260 net.cpp:84] Creating Layer label_cifar_1_split
I0626 01:07:53.501098 17260 net.cpp:406] label_cifar_1_split <- label
I0626 01:07:53.501098 17260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0626 01:07:53.501098 17260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0626 01:07:53.501598 17260 net.cpp:122] Setting up label_cifar_1_split
I0626 01:07:53.501598 17260 net.cpp:129] Top shape: 100 (100)
I0626 01:07:53.501598 17260 net.cpp:129] Top shape: 100 (100)
I0626 01:07:53.501598 17260 net.cpp:137] Memory required for data: 1230000
I0626 01:07:53.501598 17260 layer_factory.cpp:58] Creating layer conv1
I0626 01:07:53.501598 17260 net.cpp:84] Creating Layer conv1
I0626 01:07:53.501598 17260 net.cpp:406] conv1 <- data
I0626 01:07:53.501598 17260 net.cpp:380] conv1 -> conv1
I0626 01:07:53.502099 14952 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0626 01:07:53.759397 17260 net.cpp:122] Setting up conv1
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 27444400
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer bn1
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer bn1
I0626 01:07:53.759397 17260 net.cpp:406] bn1 <- conv1
I0626 01:07:53.759397 17260 net.cpp:380] bn1 -> bn1
I0626 01:07:53.759397 17260 net.cpp:122] Setting up bn1
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 53658800
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer scale1
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer scale1
I0626 01:07:53.759397 17260 net.cpp:406] scale1 <- bn1
I0626 01:07:53.759397 17260 net.cpp:380] scale1 -> scale1
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer scale1
I0626 01:07:53.759397 17260 net.cpp:122] Setting up scale1
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 79873200
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer relu1
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer relu1
I0626 01:07:53.759397 17260 net.cpp:406] relu1 <- scale1
I0626 01:07:53.759397 17260 net.cpp:380] relu1 -> relu1
I0626 01:07:53.759397 17260 net.cpp:122] Setting up relu1
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 106087600
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer conv1_0
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer conv1_0
I0626 01:07:53.759397 17260 net.cpp:406] conv1_0 <- relu1
I0626 01:07:53.759397 17260 net.cpp:380] conv1_0 -> conv1_0
I0626 01:07:53.759397 17260 net.cpp:122] Setting up conv1_0
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 132302000
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer bn1_0
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer bn1_0
I0626 01:07:53.759397 17260 net.cpp:406] bn1_0 <- conv1_0
I0626 01:07:53.759397 17260 net.cpp:380] bn1_0 -> bn1_0
I0626 01:07:53.759397 17260 net.cpp:122] Setting up bn1_0
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 158516400
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer scale1_0
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer scale1_0
I0626 01:07:53.759397 17260 net.cpp:406] scale1_0 <- bn1_0
I0626 01:07:53.759397 17260 net.cpp:380] scale1_0 -> scale1_0
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer scale1_0
I0626 01:07:53.759397 17260 net.cpp:122] Setting up scale1_0
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 184730800
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer relu1_0
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer relu1_0
I0626 01:07:53.759397 17260 net.cpp:406] relu1_0 <- scale1_0
I0626 01:07:53.759397 17260 net.cpp:380] relu1_0 -> relu1_0
I0626 01:07:53.759397 17260 net.cpp:122] Setting up relu1_0
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 210945200
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer pool1
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer pool1
I0626 01:07:53.759397 17260 net.cpp:406] pool1 <- relu1_0
I0626 01:07:53.759397 17260 net.cpp:380] pool1 -> pool1
I0626 01:07:53.759397 17260 net.cpp:122] Setting up pool1
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 217498800
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer conv2
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer conv2
I0626 01:07:53.759397 17260 net.cpp:406] conv2 <- pool1
I0626 01:07:53.759397 17260 net.cpp:380] conv2 -> conv2
I0626 01:07:53.759397 17260 net.cpp:122] Setting up conv2
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 230606000
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer bn2
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer bn2
I0626 01:07:53.759397 17260 net.cpp:406] bn2 <- conv2
I0626 01:07:53.759397 17260 net.cpp:380] bn2 -> bn2
I0626 01:07:53.759397 17260 net.cpp:122] Setting up bn2
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 243713200
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer scale2
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer scale2
I0626 01:07:53.759397 17260 net.cpp:406] scale2 <- bn2
I0626 01:07:53.759397 17260 net.cpp:380] scale2 -> scale2
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer scale2
I0626 01:07:53.759397 17260 net.cpp:122] Setting up scale2
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 256820400
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer relu2
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer relu2
I0626 01:07:53.759397 17260 net.cpp:406] relu2 <- scale2
I0626 01:07:53.759397 17260 net.cpp:380] relu2 -> relu2
I0626 01:07:53.759397 17260 net.cpp:122] Setting up relu2
I0626 01:07:53.759397 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.759397 17260 net.cpp:137] Memory required for data: 269927600
I0626 01:07:53.759397 17260 layer_factory.cpp:58] Creating layer conv2_1
I0626 01:07:53.759397 17260 net.cpp:84] Creating Layer conv2_1
I0626 01:07:53.759397 17260 net.cpp:406] conv2_1 <- relu2
I0626 01:07:53.759397 17260 net.cpp:380] conv2_1 -> conv2_1
I0626 01:07:53.772485 17260 net.cpp:122] Setting up conv2_1
I0626 01:07:53.772485 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.772485 17260 net.cpp:137] Memory required for data: 283034800
I0626 01:07:53.772485 17260 layer_factory.cpp:58] Creating layer bn2_1
I0626 01:07:53.772485 17260 net.cpp:84] Creating Layer bn2_1
I0626 01:07:53.772485 17260 net.cpp:406] bn2_1 <- conv2_1
I0626 01:07:53.772485 17260 net.cpp:380] bn2_1 -> bn2_1
I0626 01:07:53.772485 17260 net.cpp:122] Setting up bn2_1
I0626 01:07:53.772485 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.772485 17260 net.cpp:137] Memory required for data: 296142000
I0626 01:07:53.772485 17260 layer_factory.cpp:58] Creating layer scale2_1
I0626 01:07:53.772485 17260 net.cpp:84] Creating Layer scale2_1
I0626 01:07:53.772485 17260 net.cpp:406] scale2_1 <- bn2_1
I0626 01:07:53.772485 17260 net.cpp:380] scale2_1 -> scale2_1
I0626 01:07:53.772485 17260 layer_factory.cpp:58] Creating layer scale2_1
I0626 01:07:53.772485 17260 net.cpp:122] Setting up scale2_1
I0626 01:07:53.772485 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.772485 17260 net.cpp:137] Memory required for data: 309249200
I0626 01:07:53.772485 17260 layer_factory.cpp:58] Creating layer relu2_1
I0626 01:07:53.772485 17260 net.cpp:84] Creating Layer relu2_1
I0626 01:07:53.772485 17260 net.cpp:406] relu2_1 <- scale2_1
I0626 01:07:53.772485 17260 net.cpp:380] relu2_1 -> relu2_1
I0626 01:07:53.772485 17260 net.cpp:122] Setting up relu2_1
I0626 01:07:53.772485 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.772485 17260 net.cpp:137] Memory required for data: 322356400
I0626 01:07:53.772485 17260 layer_factory.cpp:58] Creating layer pool2_1
I0626 01:07:53.772485 17260 net.cpp:84] Creating Layer pool2_1
I0626 01:07:53.772485 17260 net.cpp:406] pool2_1 <- relu2_1
I0626 01:07:53.772485 17260 net.cpp:380] pool2_1 -> pool2_1
I0626 01:07:53.772485 17260 net.cpp:122] Setting up pool2_1
I0626 01:07:53.772485 17260 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0626 01:07:53.772485 17260 net.cpp:137] Memory required for data: 325633200
I0626 01:07:53.772485 17260 layer_factory.cpp:58] Creating layer conv2_2
I0626 01:07:53.772485 17260 net.cpp:84] Creating Layer conv2_2
I0626 01:07:53.772485 17260 net.cpp:406] conv2_2 <- pool2_1
I0626 01:07:53.772485 17260 net.cpp:380] conv2_2 -> conv2_2
I0626 01:07:53.777493 17260 net.cpp:122] Setting up conv2_2
I0626 01:07:53.777493 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.777493 17260 net.cpp:137] Memory required for data: 332186800
I0626 01:07:53.778493 17260 layer_factory.cpp:58] Creating layer bn2_2
I0626 01:07:53.778493 17260 net.cpp:84] Creating Layer bn2_2
I0626 01:07:53.778493 17260 net.cpp:406] bn2_2 <- conv2_2
I0626 01:07:53.778493 17260 net.cpp:380] bn2_2 -> bn2_2
I0626 01:07:53.778493 17260 net.cpp:122] Setting up bn2_2
I0626 01:07:53.778493 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.778493 17260 net.cpp:137] Memory required for data: 338740400
I0626 01:07:53.778493 17260 layer_factory.cpp:58] Creating layer scale2_2
I0626 01:07:53.778493 17260 net.cpp:84] Creating Layer scale2_2
I0626 01:07:53.778493 17260 net.cpp:406] scale2_2 <- bn2_2
I0626 01:07:53.778493 17260 net.cpp:380] scale2_2 -> scale2_2
I0626 01:07:53.778493 17260 layer_factory.cpp:58] Creating layer scale2_2
I0626 01:07:53.778493 17260 net.cpp:122] Setting up scale2_2
I0626 01:07:53.778493 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.778493 17260 net.cpp:137] Memory required for data: 345294000
I0626 01:07:53.778493 17260 layer_factory.cpp:58] Creating layer relu2_2
I0626 01:07:53.778493 17260 net.cpp:84] Creating Layer relu2_2
I0626 01:07:53.778493 17260 net.cpp:406] relu2_2 <- scale2_2
I0626 01:07:53.778493 17260 net.cpp:380] relu2_2 -> relu2_2
I0626 01:07:53.779489 17260 net.cpp:122] Setting up relu2_2
I0626 01:07:53.779489 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.779489 17260 net.cpp:137] Memory required for data: 351847600
I0626 01:07:53.779489 17260 layer_factory.cpp:58] Creating layer conv3
I0626 01:07:53.779489 17260 net.cpp:84] Creating Layer conv3
I0626 01:07:53.779489 17260 net.cpp:406] conv3 <- relu2_2
I0626 01:07:53.779489 17260 net.cpp:380] conv3 -> conv3
I0626 01:07:53.785492 17260 net.cpp:122] Setting up conv3
I0626 01:07:53.785492 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.785492 17260 net.cpp:137] Memory required for data: 358401200
I0626 01:07:53.785492 17260 layer_factory.cpp:58] Creating layer bn3
I0626 01:07:53.785492 17260 net.cpp:84] Creating Layer bn3
I0626 01:07:53.785492 17260 net.cpp:406] bn3 <- conv3
I0626 01:07:53.785492 17260 net.cpp:380] bn3 -> bn3
I0626 01:07:53.785492 17260 net.cpp:122] Setting up bn3
I0626 01:07:53.785492 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.785492 17260 net.cpp:137] Memory required for data: 364954800
I0626 01:07:53.785492 17260 layer_factory.cpp:58] Creating layer scale3
I0626 01:07:53.785492 17260 net.cpp:84] Creating Layer scale3
I0626 01:07:53.785492 17260 net.cpp:406] scale3 <- bn3
I0626 01:07:53.785492 17260 net.cpp:380] scale3 -> scale3
I0626 01:07:53.785492 17260 layer_factory.cpp:58] Creating layer scale3
I0626 01:07:53.785492 17260 net.cpp:122] Setting up scale3
I0626 01:07:53.785492 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.785492 17260 net.cpp:137] Memory required for data: 371508400
I0626 01:07:53.785492 17260 layer_factory.cpp:58] Creating layer relu3
I0626 01:07:53.785492 17260 net.cpp:84] Creating Layer relu3
I0626 01:07:53.785492 17260 net.cpp:406] relu3 <- scale3
I0626 01:07:53.785492 17260 net.cpp:380] relu3 -> relu3
I0626 01:07:53.785492 17260 net.cpp:122] Setting up relu3
I0626 01:07:53.785492 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.785492 17260 net.cpp:137] Memory required for data: 378062000
I0626 01:07:53.785492 17260 layer_factory.cpp:58] Creating layer pool_GP
I0626 01:07:53.785492 17260 net.cpp:84] Creating Layer pool_GP
I0626 01:07:53.785492 17260 net.cpp:406] pool_GP <- relu3
I0626 01:07:53.785492 17260 net.cpp:380] pool_GP -> pool_GP
I0626 01:07:53.785492 17260 net.cpp:122] Setting up pool_GP
I0626 01:07:53.786492 17260 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0626 01:07:53.786492 17260 net.cpp:137] Memory required for data: 378164400
I0626 01:07:53.786492 17260 layer_factory.cpp:58] Creating layer ip1
I0626 01:07:53.786492 17260 net.cpp:84] Creating Layer ip1
I0626 01:07:53.786492 17260 net.cpp:406] ip1 <- pool_GP
I0626 01:07:53.786492 17260 net.cpp:380] ip1 -> ip1
I0626 01:07:53.786492 17260 net.cpp:122] Setting up ip1
I0626 01:07:53.786492 17260 net.cpp:129] Top shape: 100 10 (1000)
I0626 01:07:53.786492 17260 net.cpp:137] Memory required for data: 378168400
I0626 01:07:53.786492 17260 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0626 01:07:53.786492 17260 net.cpp:84] Creating Layer ip1_ip1_0_split
I0626 01:07:53.786492 17260 net.cpp:406] ip1_ip1_0_split <- ip1
I0626 01:07:53.786492 17260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0626 01:07:53.786492 17260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0626 01:07:53.786492 17260 net.cpp:122] Setting up ip1_ip1_0_split
I0626 01:07:53.786492 17260 net.cpp:129] Top shape: 100 10 (1000)
I0626 01:07:53.786492 17260 net.cpp:129] Top shape: 100 10 (1000)
I0626 01:07:53.786492 17260 net.cpp:137] Memory required for data: 378176400
I0626 01:07:53.786492 17260 layer_factory.cpp:58] Creating layer accuracy_training
I0626 01:07:53.786492 17260 net.cpp:84] Creating Layer accuracy_training
I0626 01:07:53.786492 17260 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0626 01:07:53.786492 17260 net.cpp:406] accuracy_training <- label_cifar_1_split_0
I0626 01:07:53.786492 17260 net.cpp:380] accuracy_training -> accuracy_training
I0626 01:07:53.786492 17260 net.cpp:122] Setting up accuracy_training
I0626 01:07:53.786492 17260 net.cpp:129] Top shape: (1)
I0626 01:07:53.786492 17260 net.cpp:137] Memory required for data: 378176404
I0626 01:07:53.786492 17260 layer_factory.cpp:58] Creating layer loss
I0626 01:07:53.786492 17260 net.cpp:84] Creating Layer loss
I0626 01:07:53.786492 17260 net.cpp:406] loss <- ip1_ip1_0_split_1
I0626 01:07:53.786492 17260 net.cpp:406] loss <- label_cifar_1_split_1
I0626 01:07:53.786492 17260 net.cpp:380] loss -> loss
I0626 01:07:53.786492 17260 layer_factory.cpp:58] Creating layer loss
I0626 01:07:53.786492 17260 net.cpp:122] Setting up loss
I0626 01:07:53.786492 17260 net.cpp:129] Top shape: (1)
I0626 01:07:53.786492 17260 net.cpp:132]     with loss weight 1
I0626 01:07:53.786492 17260 net.cpp:137] Memory required for data: 378176408
I0626 01:07:53.786492 17260 net.cpp:198] loss needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:200] accuracy_training does not need backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] ip1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] pool_GP needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] relu3 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] scale3 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] bn3 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] conv3 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] relu2_2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] scale2_2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] bn2_2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] conv2_2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] pool2_1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] relu2_1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] scale2_1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] bn2_1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] conv2_1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] relu2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] scale2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] bn2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] conv2 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] pool1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] relu1_0 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] scale1_0 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] bn1_0 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] conv1_0 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] relu1 needs backward computation.
I0626 01:07:53.786492 17260 net.cpp:198] scale1 needs backward computation.
I0626 01:07:53.787493 17260 net.cpp:198] bn1 needs backward computation.
I0626 01:07:53.787493 17260 net.cpp:198] conv1 needs backward computation.
I0626 01:07:53.787493 17260 net.cpp:200] label_cifar_1_split does not need backward computation.
I0626 01:07:53.787493 17260 net.cpp:200] cifar does not need backward computation.
I0626 01:07:53.787493 17260 net.cpp:242] This network produces output accuracy_training
I0626 01:07:53.787493 17260 net.cpp:242] This network produces output loss
I0626 01:07:53.787493 17260 net.cpp:255] Network initialization done.
I0626 01:07:53.787493 17260 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0626 01:07:53.787493 17260 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0626 01:07:53.787493 17260 solver.cpp:172] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0626 01:07:53.787493 17260 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0626 01:07:53.787493 17260 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_Shallow_wide_1M_NoDrp_6L"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1_0"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "pool_GP"
  type: "Pooling"
  bottom: "relu3"
  top: "pool_GP"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool_GP"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0626 01:07:53.788493 17260 layer_factory.cpp:58] Creating layer cifar
I0626 01:07:53.793503 17260 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0626 01:07:53.793503 17260 net.cpp:84] Creating Layer cifar
I0626 01:07:53.793503 17260 net.cpp:380] cifar -> data
I0626 01:07:53.793503 17260 net.cpp:380] cifar -> label
I0626 01:07:53.794005 17260 data_layer.cpp:45] output data size: 100,3,32,32
I0626 01:07:53.800010 17260 net.cpp:122] Setting up cifar
I0626 01:07:53.800010 17260 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0626 01:07:53.800010 17260 net.cpp:129] Top shape: 100 (100)
I0626 01:07:53.800010 17260 net.cpp:137] Memory required for data: 1229200
I0626 01:07:53.800010 17260 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0626 01:07:53.800010 17260 net.cpp:84] Creating Layer label_cifar_1_split
I0626 01:07:53.800010 17260 net.cpp:406] label_cifar_1_split <- label
I0626 01:07:53.800010 17260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0626 01:07:53.800010 17260 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0626 01:07:53.800010 17260 net.cpp:122] Setting up label_cifar_1_split
I0626 01:07:53.800010 17260 net.cpp:129] Top shape: 100 (100)
I0626 01:07:53.800010 17260 net.cpp:129] Top shape: 100 (100)
I0626 01:07:53.800010 17260 net.cpp:137] Memory required for data: 1230000
I0626 01:07:53.800010 17260 layer_factory.cpp:58] Creating layer conv1
I0626 01:07:53.800509 17260 net.cpp:84] Creating Layer conv1
I0626 01:07:53.800509 17260 net.cpp:406] conv1 <- data
I0626 01:07:53.800509 17260 net.cpp:380] conv1 -> conv1
I0626 01:07:53.801009  9280 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0626 01:07:53.801511 17260 net.cpp:122] Setting up conv1
I0626 01:07:53.801511 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.801511 17260 net.cpp:137] Memory required for data: 27444400
I0626 01:07:53.801511 17260 layer_factory.cpp:58] Creating layer bn1
I0626 01:07:53.801511 17260 net.cpp:84] Creating Layer bn1
I0626 01:07:53.801511 17260 net.cpp:406] bn1 <- conv1
I0626 01:07:53.801511 17260 net.cpp:380] bn1 -> bn1
I0626 01:07:53.802011 17260 net.cpp:122] Setting up bn1
I0626 01:07:53.802011 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.802011 17260 net.cpp:137] Memory required for data: 53658800
I0626 01:07:53.802011 17260 layer_factory.cpp:58] Creating layer scale1
I0626 01:07:53.802011 17260 net.cpp:84] Creating Layer scale1
I0626 01:07:53.802011 17260 net.cpp:406] scale1 <- bn1
I0626 01:07:53.802011 17260 net.cpp:380] scale1 -> scale1
I0626 01:07:53.802011 17260 layer_factory.cpp:58] Creating layer scale1
I0626 01:07:53.802011 17260 net.cpp:122] Setting up scale1
I0626 01:07:53.802011 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.802011 17260 net.cpp:137] Memory required for data: 79873200
I0626 01:07:53.802011 17260 layer_factory.cpp:58] Creating layer relu1
I0626 01:07:53.802011 17260 net.cpp:84] Creating Layer relu1
I0626 01:07:53.802011 17260 net.cpp:406] relu1 <- scale1
I0626 01:07:53.802011 17260 net.cpp:380] relu1 -> relu1
I0626 01:07:53.802512 17260 net.cpp:122] Setting up relu1
I0626 01:07:53.802512 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.802512 17260 net.cpp:137] Memory required for data: 106087600
I0626 01:07:53.802512 17260 layer_factory.cpp:58] Creating layer conv1_0
I0626 01:07:53.802512 17260 net.cpp:84] Creating Layer conv1_0
I0626 01:07:53.802512 17260 net.cpp:406] conv1_0 <- relu1
I0626 01:07:53.802512 17260 net.cpp:380] conv1_0 -> conv1_0
I0626 01:07:53.804013 17260 net.cpp:122] Setting up conv1_0
I0626 01:07:53.804013 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.804013 17260 net.cpp:137] Memory required for data: 132302000
I0626 01:07:53.804013 17260 layer_factory.cpp:58] Creating layer bn1_0
I0626 01:07:53.804013 17260 net.cpp:84] Creating Layer bn1_0
I0626 01:07:53.804013 17260 net.cpp:406] bn1_0 <- conv1_0
I0626 01:07:53.804013 17260 net.cpp:380] bn1_0 -> bn1_0
I0626 01:07:53.804013 17260 net.cpp:122] Setting up bn1_0
I0626 01:07:53.804013 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.804013 17260 net.cpp:137] Memory required for data: 158516400
I0626 01:07:53.804013 17260 layer_factory.cpp:58] Creating layer scale1_0
I0626 01:07:53.804013 17260 net.cpp:84] Creating Layer scale1_0
I0626 01:07:53.804512 17260 net.cpp:406] scale1_0 <- bn1_0
I0626 01:07:53.804512 17260 net.cpp:380] scale1_0 -> scale1_0
I0626 01:07:53.804512 17260 layer_factory.cpp:58] Creating layer scale1_0
I0626 01:07:53.804512 17260 net.cpp:122] Setting up scale1_0
I0626 01:07:53.804512 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.804512 17260 net.cpp:137] Memory required for data: 184730800
I0626 01:07:53.804512 17260 layer_factory.cpp:58] Creating layer relu1_0
I0626 01:07:53.804512 17260 net.cpp:84] Creating Layer relu1_0
I0626 01:07:53.804512 17260 net.cpp:406] relu1_0 <- scale1_0
I0626 01:07:53.804512 17260 net.cpp:380] relu1_0 -> relu1_0
I0626 01:07:53.805012 17260 net.cpp:122] Setting up relu1_0
I0626 01:07:53.805012 17260 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0626 01:07:53.805012 17260 net.cpp:137] Memory required for data: 210945200
I0626 01:07:53.805012 17260 layer_factory.cpp:58] Creating layer pool1
I0626 01:07:53.805012 17260 net.cpp:84] Creating Layer pool1
I0626 01:07:53.805012 17260 net.cpp:406] pool1 <- relu1_0
I0626 01:07:53.805012 17260 net.cpp:380] pool1 -> pool1
I0626 01:07:53.805012 17260 net.cpp:122] Setting up pool1
I0626 01:07:53.805012 17260 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0626 01:07:53.805012 17260 net.cpp:137] Memory required for data: 217498800
I0626 01:07:53.805012 17260 layer_factory.cpp:58] Creating layer conv2
I0626 01:07:53.805012 17260 net.cpp:84] Creating Layer conv2
I0626 01:07:53.805012 17260 net.cpp:406] conv2 <- pool1
I0626 01:07:53.805012 17260 net.cpp:380] conv2 -> conv2
I0626 01:07:53.808017 17260 net.cpp:122] Setting up conv2
I0626 01:07:53.808017 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.808017 17260 net.cpp:137] Memory required for data: 230606000
I0626 01:07:53.808017 17260 layer_factory.cpp:58] Creating layer bn2
I0626 01:07:53.808017 17260 net.cpp:84] Creating Layer bn2
I0626 01:07:53.808017 17260 net.cpp:406] bn2 <- conv2
I0626 01:07:53.808017 17260 net.cpp:380] bn2 -> bn2
I0626 01:07:53.808017 17260 net.cpp:122] Setting up bn2
I0626 01:07:53.808017 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.808017 17260 net.cpp:137] Memory required for data: 243713200
I0626 01:07:53.808017 17260 layer_factory.cpp:58] Creating layer scale2
I0626 01:07:53.808017 17260 net.cpp:84] Creating Layer scale2
I0626 01:07:53.808017 17260 net.cpp:406] scale2 <- bn2
I0626 01:07:53.808017 17260 net.cpp:380] scale2 -> scale2
I0626 01:07:53.808517 17260 layer_factory.cpp:58] Creating layer scale2
I0626 01:07:53.808517 17260 net.cpp:122] Setting up scale2
I0626 01:07:53.808517 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.808517 17260 net.cpp:137] Memory required for data: 256820400
I0626 01:07:53.808517 17260 layer_factory.cpp:58] Creating layer relu2
I0626 01:07:53.808517 17260 net.cpp:84] Creating Layer relu2
I0626 01:07:53.808517 17260 net.cpp:406] relu2 <- scale2
I0626 01:07:53.808517 17260 net.cpp:380] relu2 -> relu2
I0626 01:07:53.808517 17260 net.cpp:122] Setting up relu2
I0626 01:07:53.809017 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.809017 17260 net.cpp:137] Memory required for data: 269927600
I0626 01:07:53.809017 17260 layer_factory.cpp:58] Creating layer conv2_1
I0626 01:07:53.809017 17260 net.cpp:84] Creating Layer conv2_1
I0626 01:07:53.809017 17260 net.cpp:406] conv2_1 <- relu2
I0626 01:07:53.809017 17260 net.cpp:380] conv2_1 -> conv2_1
I0626 01:07:53.809520 17260 net.cpp:122] Setting up conv2_1
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 283034800
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer bn2_1
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer bn2_1
I0626 01:07:53.809520 17260 net.cpp:406] bn2_1 <- conv2_1
I0626 01:07:53.809520 17260 net.cpp:380] bn2_1 -> bn2_1
I0626 01:07:53.809520 17260 net.cpp:122] Setting up bn2_1
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 296142000
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer scale2_1
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer scale2_1
I0626 01:07:53.809520 17260 net.cpp:406] scale2_1 <- bn2_1
I0626 01:07:53.809520 17260 net.cpp:380] scale2_1 -> scale2_1
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer scale2_1
I0626 01:07:53.809520 17260 net.cpp:122] Setting up scale2_1
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 309249200
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer relu2_1
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer relu2_1
I0626 01:07:53.809520 17260 net.cpp:406] relu2_1 <- scale2_1
I0626 01:07:53.809520 17260 net.cpp:380] relu2_1 -> relu2_1
I0626 01:07:53.809520 17260 net.cpp:122] Setting up relu2_1
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 322356400
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer pool2_1
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer pool2_1
I0626 01:07:53.809520 17260 net.cpp:406] pool2_1 <- relu2_1
I0626 01:07:53.809520 17260 net.cpp:380] pool2_1 -> pool2_1
I0626 01:07:53.809520 17260 net.cpp:122] Setting up pool2_1
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 325633200
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer conv2_2
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer conv2_2
I0626 01:07:53.809520 17260 net.cpp:406] conv2_2 <- pool2_1
I0626 01:07:53.809520 17260 net.cpp:380] conv2_2 -> conv2_2
I0626 01:07:53.809520 17260 net.cpp:122] Setting up conv2_2
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 332186800
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer bn2_2
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer bn2_2
I0626 01:07:53.809520 17260 net.cpp:406] bn2_2 <- conv2_2
I0626 01:07:53.809520 17260 net.cpp:380] bn2_2 -> bn2_2
I0626 01:07:53.809520 17260 net.cpp:122] Setting up bn2_2
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 338740400
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer scale2_2
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer scale2_2
I0626 01:07:53.809520 17260 net.cpp:406] scale2_2 <- bn2_2
I0626 01:07:53.809520 17260 net.cpp:380] scale2_2 -> scale2_2
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer scale2_2
I0626 01:07:53.809520 17260 net.cpp:122] Setting up scale2_2
I0626 01:07:53.809520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.809520 17260 net.cpp:137] Memory required for data: 345294000
I0626 01:07:53.809520 17260 layer_factory.cpp:58] Creating layer relu2_2
I0626 01:07:53.809520 17260 net.cpp:84] Creating Layer relu2_2
I0626 01:07:53.809520 17260 net.cpp:406] relu2_2 <- scale2_2
I0626 01:07:53.809520 17260 net.cpp:380] relu2_2 -> relu2_2
I0626 01:07:53.819520 17260 net.cpp:122] Setting up relu2_2
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 351847600
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer conv3
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer conv3
I0626 01:07:53.819520 17260 net.cpp:406] conv3 <- relu2_2
I0626 01:07:53.819520 17260 net.cpp:380] conv3 -> conv3
I0626 01:07:53.819520 17260 net.cpp:122] Setting up conv3
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 358401200
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer bn3
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer bn3
I0626 01:07:53.819520 17260 net.cpp:406] bn3 <- conv3
I0626 01:07:53.819520 17260 net.cpp:380] bn3 -> bn3
I0626 01:07:53.819520 17260 net.cpp:122] Setting up bn3
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 364954800
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer scale3
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer scale3
I0626 01:07:53.819520 17260 net.cpp:406] scale3 <- bn3
I0626 01:07:53.819520 17260 net.cpp:380] scale3 -> scale3
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer scale3
I0626 01:07:53.819520 17260 net.cpp:122] Setting up scale3
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 371508400
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer relu3
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer relu3
I0626 01:07:53.819520 17260 net.cpp:406] relu3 <- scale3
I0626 01:07:53.819520 17260 net.cpp:380] relu3 -> relu3
I0626 01:07:53.819520 17260 net.cpp:122] Setting up relu3
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 378062000
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer pool_GP
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer pool_GP
I0626 01:07:53.819520 17260 net.cpp:406] pool_GP <- relu3
I0626 01:07:53.819520 17260 net.cpp:380] pool_GP -> pool_GP
I0626 01:07:53.819520 17260 net.cpp:122] Setting up pool_GP
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 378164400
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer ip1
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer ip1
I0626 01:07:53.819520 17260 net.cpp:406] ip1 <- pool_GP
I0626 01:07:53.819520 17260 net.cpp:380] ip1 -> ip1
I0626 01:07:53.819520 17260 net.cpp:122] Setting up ip1
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 10 (1000)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 378168400
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer ip1_ip1_0_split
I0626 01:07:53.819520 17260 net.cpp:406] ip1_ip1_0_split <- ip1
I0626 01:07:53.819520 17260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0626 01:07:53.819520 17260 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0626 01:07:53.819520 17260 net.cpp:122] Setting up ip1_ip1_0_split
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 10 (1000)
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: 100 10 (1000)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 378176400
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer accuracy
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer accuracy
I0626 01:07:53.819520 17260 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0626 01:07:53.819520 17260 net.cpp:406] accuracy <- label_cifar_1_split_0
I0626 01:07:53.819520 17260 net.cpp:380] accuracy -> accuracy
I0626 01:07:53.819520 17260 net.cpp:122] Setting up accuracy
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: (1)
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 378176404
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer loss
I0626 01:07:53.819520 17260 net.cpp:84] Creating Layer loss
I0626 01:07:53.819520 17260 net.cpp:406] loss <- ip1_ip1_0_split_1
I0626 01:07:53.819520 17260 net.cpp:406] loss <- label_cifar_1_split_1
I0626 01:07:53.819520 17260 net.cpp:380] loss -> loss
I0626 01:07:53.819520 17260 layer_factory.cpp:58] Creating layer loss
I0626 01:07:53.819520 17260 net.cpp:122] Setting up loss
I0626 01:07:53.819520 17260 net.cpp:129] Top shape: (1)
I0626 01:07:53.819520 17260 net.cpp:132]     with loss weight 1
I0626 01:07:53.819520 17260 net.cpp:137] Memory required for data: 378176408
I0626 01:07:53.819520 17260 net.cpp:198] loss needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:200] accuracy does not need backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] ip1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] pool_GP needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] relu3 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] scale3 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] bn3 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] conv3 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] relu2_2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] scale2_2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] bn2_2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] conv2_2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] pool2_1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] relu2_1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] scale2_1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] bn2_1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] conv2_1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] relu2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] scale2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] bn2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] conv2 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] pool1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] relu1_0 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] scale1_0 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] bn1_0 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] conv1_0 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] relu1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] scale1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] bn1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:198] conv1 needs backward computation.
I0626 01:07:53.819520 17260 net.cpp:200] label_cifar_1_split does not need backward computation.
I0626 01:07:53.819520 17260 net.cpp:200] cifar does not need backward computation.
I0626 01:07:53.819520 17260 net.cpp:242] This network produces output accuracy
I0626 01:07:53.819520 17260 net.cpp:242] This network produces output loss
I0626 01:07:53.819520 17260 net.cpp:255] Network initialization done.
I0626 01:07:53.819520 17260 solver.cpp:56] Solver scaffolding done.
I0626 01:07:53.819520 17260 caffe.cpp:249] Starting Optimization
I0626 01:07:53.819520 17260 solver.cpp:272] Solving CIFAR10_Shallow_wide_1M_NoDrp_6L
I0626 01:07:53.819520 17260 solver.cpp:273] Learning Rate Policy: multistep
I0626 01:07:53.829538 17260 solver.cpp:330] Iteration 0, Testing net (#0)
I0626 01:07:53.829538 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:07:54.980080  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:07:55.020594 17260 solver.cpp:397]     Test net output #0: accuracy = 0.1008
I0626 01:07:55.020594 17260 solver.cpp:397]     Test net output #1: loss = 78.533 (* 1 = 78.533 loss)
I0626 01:07:55.108245 17260 solver.cpp:218] Iteration 0 (0 iter/s, 1.27874s/100 iters), loss = 2.92929
I0626 01:07:55.108245 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.16
I0626 01:07:55.108245 17260 solver.cpp:237]     Train net output #1: loss = 2.92929 (* 1 = 2.92929 loss)
I0626 01:07:55.108245 17260 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0626 01:07:59.143445 17260 solver.cpp:218] Iteration 100 (24.7636 iter/s, 4.03818s/100 iters), loss = 1.51984
I0626 01:07:59.143445 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.48
I0626 01:07:59.143445 17260 solver.cpp:237]     Train net output #1: loss = 1.51984 (* 1 = 1.51984 loss)
I0626 01:07:59.143445 17260 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0626 01:08:03.204329 17260 solver.cpp:218] Iteration 200 (24.6474 iter/s, 4.05722s/100 iters), loss = 1.31087
I0626 01:08:03.204329 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.53
I0626 01:08:03.204329 17260 solver.cpp:237]     Train net output #1: loss = 1.31087 (* 1 = 1.31087 loss)
I0626 01:08:03.204329 17260 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0626 01:08:07.268339 17260 solver.cpp:218] Iteration 300 (24.5985 iter/s, 4.06529s/100 iters), loss = 1.12057
I0626 01:08:07.268339 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.66
I0626 01:08:07.268339 17260 solver.cpp:237]     Train net output #1: loss = 1.12057 (* 1 = 1.12057 loss)
I0626 01:08:07.268339 17260 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0626 01:08:11.298141 17260 solver.cpp:218] Iteration 400 (24.8271 iter/s, 4.02786s/100 iters), loss = 0.96627
I0626 01:08:11.298141 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.7
I0626 01:08:11.298141 17260 solver.cpp:237]     Train net output #1: loss = 0.96627 (* 1 = 0.96627 loss)
I0626 01:08:11.298141 17260 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0626 01:08:15.153013 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:08:15.356981 17260 solver.cpp:218] Iteration 500 (24.64 iter/s, 4.05844s/100 iters), loss = 0.938021
I0626 01:08:15.357482 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.68
I0626 01:08:15.357482 17260 solver.cpp:237]     Train net output #1: loss = 0.938021 (* 1 = 0.938021 loss)
I0626 01:08:15.357482 17260 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0626 01:08:19.379922 17260 solver.cpp:218] Iteration 600 (24.808 iter/s, 4.03095s/100 iters), loss = 0.874256
I0626 01:08:19.379922 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.71
I0626 01:08:19.379922 17260 solver.cpp:237]     Train net output #1: loss = 0.874256 (* 1 = 0.874256 loss)
I0626 01:08:19.379922 17260 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0626 01:08:23.409446 17260 solver.cpp:218] Iteration 700 (24.8595 iter/s, 4.0226s/100 iters), loss = 0.792214
I0626 01:08:23.409446 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.75
I0626 01:08:23.409446 17260 solver.cpp:237]     Train net output #1: loss = 0.792214 (* 1 = 0.792214 loss)
I0626 01:08:23.409446 17260 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0626 01:08:27.440312 17260 solver.cpp:218] Iteration 800 (24.8212 iter/s, 4.02881s/100 iters), loss = 0.752647
I0626 01:08:27.440312 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.73
I0626 01:08:27.440312 17260 solver.cpp:237]     Train net output #1: loss = 0.752647 (* 1 = 0.752647 loss)
I0626 01:08:27.440312 17260 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0626 01:08:31.503051 17260 solver.cpp:218] Iteration 900 (24.5983 iter/s, 4.06533s/100 iters), loss = 0.664828
I0626 01:08:31.503051 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.72
I0626 01:08:31.503051 17260 solver.cpp:237]     Train net output #1: loss = 0.664828 (* 1 = 0.664828 loss)
I0626 01:08:31.503051 17260 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0626 01:08:35.349998 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:08:35.515105 17260 solver.cpp:330] Iteration 1000, Testing net (#0)
I0626 01:08:35.515105 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:08:36.628569  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:08:36.665395 17260 solver.cpp:397]     Test net output #0: accuracy = 0.7396
I0626 01:08:36.665395 17260 solver.cpp:397]     Test net output #1: loss = 0.739624 (* 1 = 0.739624 loss)
I0626 01:08:36.705400 17260 solver.cpp:218] Iteration 1000 (19.2253 iter/s, 5.20149s/100 iters), loss = 0.580902
I0626 01:08:36.705400 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0626 01:08:36.705400 17260 solver.cpp:237]     Train net output #1: loss = 0.580902 (* 1 = 0.580902 loss)
I0626 01:08:36.705400 17260 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0626 01:08:40.740252 17260 solver.cpp:218] Iteration 1100 (24.8034 iter/s, 4.0317s/100 iters), loss = 0.43606
I0626 01:08:40.740252 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:08:40.740252 17260 solver.cpp:237]     Train net output #1: loss = 0.43606 (* 1 = 0.43606 loss)
I0626 01:08:40.740252 17260 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0626 01:08:44.769183 17260 solver.cpp:218] Iteration 1200 (24.7723 iter/s, 4.03677s/100 iters), loss = 0.650144
I0626 01:08:44.769183 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0626 01:08:44.769183 17260 solver.cpp:237]     Train net output #1: loss = 0.650144 (* 1 = 0.650144 loss)
I0626 01:08:44.769183 17260 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0626 01:08:48.941316 17260 solver.cpp:218] Iteration 1300 (23.982 iter/s, 4.1698s/100 iters), loss = 0.660831
I0626 01:08:48.941316 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.77
I0626 01:08:48.941316 17260 solver.cpp:237]     Train net output #1: loss = 0.660831 (* 1 = 0.660831 loss)
I0626 01:08:48.941316 17260 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0626 01:08:52.964385 17260 solver.cpp:218] Iteration 1400 (24.873 iter/s, 4.02042s/100 iters), loss = 0.580861
I0626 01:08:52.964385 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0626 01:08:52.964385 17260 solver.cpp:237]     Train net output #1: loss = 0.580861 (* 1 = 0.580861 loss)
I0626 01:08:52.964385 17260 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0626 01:08:56.797345 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:08:57.118005 17260 solver.cpp:218] Iteration 1500 (24.1027 iter/s, 4.14891s/100 iters), loss = 0.553963
I0626 01:08:57.118005 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0626 01:08:57.118005 17260 solver.cpp:237]     Train net output #1: loss = 0.553963 (* 1 = 0.553963 loss)
I0626 01:08:57.118005 17260 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0626 01:09:01.130368 17260 solver.cpp:218] Iteration 1600 (24.8743 iter/s, 4.02021s/100 iters), loss = 0.380845
I0626 01:09:01.130368 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:09:01.130368 17260 solver.cpp:237]     Train net output #1: loss = 0.380845 (* 1 = 0.380845 loss)
I0626 01:09:01.130368 17260 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0626 01:09:05.151595 17260 solver.cpp:218] Iteration 1700 (24.8637 iter/s, 4.02192s/100 iters), loss = 0.633901
I0626 01:09:05.151595 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.76
I0626 01:09:05.151595 17260 solver.cpp:237]     Train net output #1: loss = 0.633901 (* 1 = 0.633901 loss)
I0626 01:09:05.151595 17260 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0626 01:09:09.175914 17260 solver.cpp:218] Iteration 1800 (24.9092 iter/s, 4.01459s/100 iters), loss = 0.501079
I0626 01:09:09.175914 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0626 01:09:09.175914 17260 solver.cpp:237]     Train net output #1: loss = 0.501079 (* 1 = 0.501079 loss)
I0626 01:09:09.175914 17260 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0626 01:09:13.191169 17260 solver.cpp:218] Iteration 1900 (24.8884 iter/s, 4.01793s/100 iters), loss = 0.476828
I0626 01:09:13.191169 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0626 01:09:13.191169 17260 solver.cpp:237]     Train net output #1: loss = 0.476828 (* 1 = 0.476828 loss)
I0626 01:09:13.191169 17260 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0626 01:09:17.052842 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:09:17.217732 17260 solver.cpp:330] Iteration 2000, Testing net (#0)
I0626 01:09:17.217732 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:09:18.328574  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:09:18.374040 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8121
I0626 01:09:18.374040 17260 solver.cpp:397]     Test net output #1: loss = 0.543631 (* 1 = 0.543631 loss)
I0626 01:09:18.405050 17260 solver.cpp:218] Iteration 2000 (19.1632 iter/s, 5.21835s/100 iters), loss = 0.460551
I0626 01:09:18.405050 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0626 01:09:18.405050 17260 solver.cpp:237]     Train net output #1: loss = 0.460551 (* 1 = 0.460551 loss)
I0626 01:09:18.405050 17260 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0626 01:09:22.429220 17260 solver.cpp:218] Iteration 2100 (24.8457 iter/s, 4.02484s/100 iters), loss = 0.344684
I0626 01:09:22.429220 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0626 01:09:22.429220 17260 solver.cpp:237]     Train net output #1: loss = 0.344684 (* 1 = 0.344684 loss)
I0626 01:09:22.429220 17260 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0626 01:09:26.461449 17260 solver.cpp:218] Iteration 2200 (24.8015 iter/s, 4.03202s/100 iters), loss = 0.498975
I0626 01:09:26.461449 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.79
I0626 01:09:26.461449 17260 solver.cpp:237]     Train net output #1: loss = 0.498975 (* 1 = 0.498975 loss)
I0626 01:09:26.461449 17260 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0626 01:09:30.490726 17260 solver.cpp:218] Iteration 2300 (24.8771 iter/s, 4.01977s/100 iters), loss = 0.423335
I0626 01:09:30.491225 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0626 01:09:30.491225 17260 solver.cpp:237]     Train net output #1: loss = 0.423335 (* 1 = 0.423335 loss)
I0626 01:09:30.491225 17260 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0626 01:09:34.508661 17260 solver.cpp:218] Iteration 2400 (24.843 iter/s, 4.02527s/100 iters), loss = 0.375232
I0626 01:09:34.508661 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:09:34.508661 17260 solver.cpp:237]     Train net output #1: loss = 0.375232 (* 1 = 0.375232 loss)
I0626 01:09:34.508661 17260 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0626 01:09:38.351856 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:09:38.550346 17260 solver.cpp:218] Iteration 2500 (24.7946 iter/s, 4.03314s/100 iters), loss = 0.393566
I0626 01:09:38.550346 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.81
I0626 01:09:38.550346 17260 solver.cpp:237]     Train net output #1: loss = 0.393566 (* 1 = 0.393566 loss)
I0626 01:09:38.550346 17260 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0626 01:09:42.573613 17260 solver.cpp:218] Iteration 2600 (24.7977 iter/s, 4.03263s/100 iters), loss = 0.418057
I0626 01:09:42.583614 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0626 01:09:42.583614 17260 solver.cpp:237]     Train net output #1: loss = 0.418057 (* 1 = 0.418057 loss)
I0626 01:09:42.583614 17260 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0626 01:09:46.610249 17260 solver.cpp:218] Iteration 2700 (24.805 iter/s, 4.03145s/100 iters), loss = 0.449683
I0626 01:09:46.610249 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.85
I0626 01:09:46.610249 17260 solver.cpp:237]     Train net output #1: loss = 0.449683 (* 1 = 0.449683 loss)
I0626 01:09:46.610249 17260 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0626 01:09:50.659939 17260 solver.cpp:218] Iteration 2800 (24.7262 iter/s, 4.0443s/100 iters), loss = 0.37833
I0626 01:09:50.660440 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:09:50.660440 17260 solver.cpp:237]     Train net output #1: loss = 0.37833 (* 1 = 0.37833 loss)
I0626 01:09:50.660440 17260 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0626 01:09:54.693423 17260 solver.cpp:218] Iteration 2900 (24.7562 iter/s, 4.03939s/100 iters), loss = 0.331171
I0626 01:09:54.693423 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:09:54.693423 17260 solver.cpp:237]     Train net output #1: loss = 0.331171 (* 1 = 0.331171 loss)
I0626 01:09:54.693423 17260 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0626 01:09:58.565714 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:09:58.732069 17260 solver.cpp:330] Iteration 3000, Testing net (#0)
I0626 01:09:58.732069 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:09:59.851258  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:09:59.886337 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8362
I0626 01:09:59.886337 17260 solver.cpp:397]     Test net output #1: loss = 0.48575 (* 1 = 0.48575 loss)
I0626 01:09:59.926338 17260 solver.cpp:218] Iteration 3000 (19.1079 iter/s, 5.23343s/100 iters), loss = 0.350557
I0626 01:09:59.926338 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:09:59.926338 17260 solver.cpp:237]     Train net output #1: loss = 0.350557 (* 1 = 0.350557 loss)
I0626 01:09:59.926338 17260 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0626 01:10:03.991519 17260 solver.cpp:218] Iteration 3100 (24.6052 iter/s, 4.06418s/100 iters), loss = 0.349856
I0626 01:10:03.991519 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:10:03.991519 17260 solver.cpp:237]     Train net output #1: loss = 0.349856 (* 1 = 0.349856 loss)
I0626 01:10:03.991519 17260 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0626 01:10:08.042716 17260 solver.cpp:218] Iteration 3200 (24.6963 iter/s, 4.04919s/100 iters), loss = 0.468693
I0626 01:10:08.042716 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.82
I0626 01:10:08.042716 17260 solver.cpp:237]     Train net output #1: loss = 0.468693 (* 1 = 0.468693 loss)
I0626 01:10:08.042716 17260 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0626 01:10:12.120067 17260 solver.cpp:218] Iteration 3300 (24.5369 iter/s, 4.07549s/100 iters), loss = 0.342449
I0626 01:10:12.120067 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:10:12.120067 17260 solver.cpp:237]     Train net output #1: loss = 0.342449 (* 1 = 0.342449 loss)
I0626 01:10:12.120067 17260 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0626 01:10:16.177538 17260 solver.cpp:218] Iteration 3400 (24.6727 iter/s, 4.05307s/100 iters), loss = 0.372153
I0626 01:10:16.177538 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0626 01:10:16.177538 17260 solver.cpp:237]     Train net output #1: loss = 0.372153 (* 1 = 0.372153 loss)
I0626 01:10:16.177538 17260 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0626 01:10:20.030652 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:10:20.230693 17260 solver.cpp:218] Iteration 3500 (24.6488 iter/s, 4.057s/100 iters), loss = 0.277461
I0626 01:10:20.230693 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:10:20.230693 17260 solver.cpp:237]     Train net output #1: loss = 0.277461 (* 1 = 0.277461 loss)
I0626 01:10:20.230693 17260 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0626 01:10:24.313315 17260 solver.cpp:218] Iteration 3600 (24.5094 iter/s, 4.08006s/100 iters), loss = 0.371156
I0626 01:10:24.313315 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0626 01:10:24.313315 17260 solver.cpp:237]     Train net output #1: loss = 0.371156 (* 1 = 0.371156 loss)
I0626 01:10:24.313315 17260 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0626 01:10:28.349895 17260 solver.cpp:218] Iteration 3700 (24.7568 iter/s, 4.0393s/100 iters), loss = 0.372961
I0626 01:10:28.349895 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0626 01:10:28.349895 17260 solver.cpp:237]     Train net output #1: loss = 0.372961 (* 1 = 0.372961 loss)
I0626 01:10:28.349895 17260 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0626 01:10:32.386442 17260 solver.cpp:218] Iteration 3800 (24.7743 iter/s, 4.03644s/100 iters), loss = 0.36404
I0626 01:10:32.386442 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0626 01:10:32.386442 17260 solver.cpp:237]     Train net output #1: loss = 0.36404 (* 1 = 0.36404 loss)
I0626 01:10:32.386442 17260 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0626 01:10:36.438755 17260 solver.cpp:218] Iteration 3900 (24.7127 iter/s, 4.04649s/100 iters), loss = 0.211354
I0626 01:10:36.438755 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:10:36.438755 17260 solver.cpp:237]     Train net output #1: loss = 0.211354 (* 1 = 0.211354 loss)
I0626 01:10:36.438755 17260 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0626 01:10:40.410845 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:10:40.581522 17260 solver.cpp:330] Iteration 4000, Testing net (#0)
I0626 01:10:40.582023 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:10:41.691404  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:10:41.742888 17260 solver.cpp:397]     Test net output #0: accuracy = 0.852
I0626 01:10:41.742888 17260 solver.cpp:397]     Test net output #1: loss = 0.436336 (* 1 = 0.436336 loss)
I0626 01:10:41.772905 17260 solver.cpp:218] Iteration 4000 (18.7164 iter/s, 5.34292s/100 iters), loss = 0.272253
I0626 01:10:41.772905 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:10:41.772905 17260 solver.cpp:237]     Train net output #1: loss = 0.272253 (* 1 = 0.272253 loss)
I0626 01:10:41.772905 17260 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0626 01:10:45.825327 17260 solver.cpp:218] Iteration 4100 (24.7149 iter/s, 4.04613s/100 iters), loss = 0.3115
I0626 01:10:45.825327 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:10:45.825327 17260 solver.cpp:237]     Train net output #1: loss = 0.3115 (* 1 = 0.3115 loss)
I0626 01:10:45.825327 17260 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0626 01:10:49.870532 17260 solver.cpp:218] Iteration 4200 (24.7204 iter/s, 4.04525s/100 iters), loss = 0.381688
I0626 01:10:49.870532 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.86
I0626 01:10:49.870532 17260 solver.cpp:237]     Train net output #1: loss = 0.381688 (* 1 = 0.381688 loss)
I0626 01:10:49.870532 17260 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0626 01:10:53.919015 17260 solver.cpp:218] Iteration 4300 (24.7132 iter/s, 4.04642s/100 iters), loss = 0.281986
I0626 01:10:53.919015 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:10:53.919015 17260 solver.cpp:237]     Train net output #1: loss = 0.281986 (* 1 = 0.281986 loss)
I0626 01:10:53.919015 17260 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0626 01:10:57.961611 17260 solver.cpp:218] Iteration 4400 (24.7002 iter/s, 4.04855s/100 iters), loss = 0.249617
I0626 01:10:57.961611 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:10:57.961611 17260 solver.cpp:237]     Train net output #1: loss = 0.249617 (* 1 = 0.249617 loss)
I0626 01:10:57.961611 17260 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0626 01:11:01.804189 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:11:02.003548 17260 solver.cpp:218] Iteration 4500 (24.7765 iter/s, 4.03609s/100 iters), loss = 0.298514
I0626 01:11:02.003548 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.84
I0626 01:11:02.003548 17260 solver.cpp:237]     Train net output #1: loss = 0.298514 (* 1 = 0.298514 loss)
I0626 01:11:02.003548 17260 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0626 01:11:06.037436 17260 solver.cpp:218] Iteration 4600 (24.7514 iter/s, 4.04017s/100 iters), loss = 0.270305
I0626 01:11:06.037436 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:11:06.037436 17260 solver.cpp:237]     Train net output #1: loss = 0.270305 (* 1 = 0.270305 loss)
I0626 01:11:06.037436 17260 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0626 01:11:10.092043 17260 solver.cpp:218] Iteration 4700 (24.7244 iter/s, 4.04459s/100 iters), loss = 0.345061
I0626 01:11:10.092043 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:11:10.092043 17260 solver.cpp:237]     Train net output #1: loss = 0.345061 (* 1 = 0.345061 loss)
I0626 01:11:10.092043 17260 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0626 01:11:14.136549 17260 solver.cpp:218] Iteration 4800 (24.7253 iter/s, 4.04444s/100 iters), loss = 0.244562
I0626 01:11:14.136549 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:11:14.136549 17260 solver.cpp:237]     Train net output #1: loss = 0.244562 (* 1 = 0.244562 loss)
I0626 01:11:14.136549 17260 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0626 01:11:18.180179 17260 solver.cpp:218] Iteration 4900 (24.6775 iter/s, 4.05228s/100 iters), loss = 0.236008
I0626 01:11:18.180179 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0626 01:11:18.180179 17260 solver.cpp:237]     Train net output #1: loss = 0.236008 (* 1 = 0.236008 loss)
I0626 01:11:18.180179 17260 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0626 01:11:22.039010 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:11:22.199070 17260 solver.cpp:330] Iteration 5000, Testing net (#0)
I0626 01:11:22.199070 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:11:23.319798  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:11:23.360096 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8706
I0626 01:11:23.360096 17260 solver.cpp:397]     Test net output #1: loss = 0.389803 (* 1 = 0.389803 loss)
I0626 01:11:23.400099 17260 solver.cpp:218] Iteration 5000 (19.1902 iter/s, 5.211s/100 iters), loss = 0.262111
I0626 01:11:23.400099 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.87
I0626 01:11:23.400099 17260 solver.cpp:237]     Train net output #1: loss = 0.262111 (* 1 = 0.262111 loss)
I0626 01:11:23.400099 17260 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0626 01:11:27.582321 17260 solver.cpp:218] Iteration 5100 (23.9092 iter/s, 4.18249s/100 iters), loss = 0.215914
I0626 01:11:27.582321 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:11:27.582321 17260 solver.cpp:237]     Train net output #1: loss = 0.215914 (* 1 = 0.215914 loss)
I0626 01:11:27.582321 17260 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0626 01:11:31.610590 17260 solver.cpp:218] Iteration 5200 (24.79 iter/s, 4.03389s/100 iters), loss = 0.343403
I0626 01:11:31.610590 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:11:31.610590 17260 solver.cpp:237]     Train net output #1: loss = 0.343403 (* 1 = 0.343403 loss)
I0626 01:11:31.610590 17260 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0626 01:11:35.654778 17260 solver.cpp:218] Iteration 5300 (24.7771 iter/s, 4.03599s/100 iters), loss = 0.223054
I0626 01:11:35.654778 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:11:35.654778 17260 solver.cpp:237]     Train net output #1: loss = 0.223054 (* 1 = 0.223054 loss)
I0626 01:11:35.654778 17260 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0626 01:11:39.699146 17260 solver.cpp:218] Iteration 5400 (24.7158 iter/s, 4.04599s/100 iters), loss = 0.190189
I0626 01:11:39.699146 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:11:39.699146 17260 solver.cpp:237]     Train net output #1: loss = 0.190189 (* 1 = 0.190189 loss)
I0626 01:11:39.699146 17260 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0626 01:11:43.542004 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:11:43.731529 17260 solver.cpp:218] Iteration 5500 (24.7737 iter/s, 4.03653s/100 iters), loss = 0.217087
I0626 01:11:43.731529 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:11:43.731529 17260 solver.cpp:237]     Train net output #1: loss = 0.217087 (* 1 = 0.217087 loss)
I0626 01:11:43.731529 17260 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0626 01:11:47.780906 17260 solver.cpp:218] Iteration 5600 (24.7386 iter/s, 4.04227s/100 iters), loss = 0.268313
I0626 01:11:47.780906 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:11:47.780906 17260 solver.cpp:237]     Train net output #1: loss = 0.268313 (* 1 = 0.268313 loss)
I0626 01:11:47.780906 17260 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0626 01:11:51.821281 17260 solver.cpp:218] Iteration 5700 (24.7493 iter/s, 4.04052s/100 iters), loss = 0.246758
I0626 01:11:51.821281 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.88
I0626 01:11:51.821281 17260 solver.cpp:237]     Train net output #1: loss = 0.246758 (* 1 = 0.246758 loss)
I0626 01:11:51.821281 17260 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0626 01:11:55.874248 17260 solver.cpp:218] Iteration 5800 (24.6779 iter/s, 4.0522s/100 iters), loss = 0.277674
I0626 01:11:55.874248 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0626 01:11:55.874248 17260 solver.cpp:237]     Train net output #1: loss = 0.277674 (* 1 = 0.277674 loss)
I0626 01:11:55.874248 17260 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0626 01:12:00.048162 17260 solver.cpp:218] Iteration 5900 (23.9571 iter/s, 4.17413s/100 iters), loss = 0.241575
I0626 01:12:00.048162 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.89
I0626 01:12:00.048162 17260 solver.cpp:237]     Train net output #1: loss = 0.241575 (* 1 = 0.241575 loss)
I0626 01:12:00.048162 17260 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0626 01:12:03.890297 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:12:04.040002 17260 solver.cpp:330] Iteration 6000, Testing net (#0)
I0626 01:12:04.040002 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:12:05.157333  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:12:05.201875 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8634
I0626 01:12:05.201875 17260 solver.cpp:397]     Test net output #1: loss = 0.420644 (* 1 = 0.420644 loss)
I0626 01:12:05.243990 17260 solver.cpp:218] Iteration 6000 (19.2476 iter/s, 5.19546s/100 iters), loss = 0.241361
I0626 01:12:05.244982 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:12:05.244982 17260 solver.cpp:237]     Train net output #1: loss = 0.241361 (* 1 = 0.241361 loss)
I0626 01:12:05.244982 17260 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0626 01:12:09.301053 17260 solver.cpp:218] Iteration 6100 (24.6024 iter/s, 4.06464s/100 iters), loss = 0.265678
I0626 01:12:09.301053 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:12:09.301053 17260 solver.cpp:237]     Train net output #1: loss = 0.265678 (* 1 = 0.265678 loss)
I0626 01:12:09.301053 17260 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0626 01:12:13.371265 17260 solver.cpp:218] Iteration 6200 (24.6024 iter/s, 4.06465s/100 iters), loss = 0.252257
I0626 01:12:13.371265 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:12:13.371265 17260 solver.cpp:237]     Train net output #1: loss = 0.252257 (* 1 = 0.252257 loss)
I0626 01:12:13.371265 17260 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0626 01:12:17.431365 17260 solver.cpp:218] Iteration 6300 (24.6545 iter/s, 4.05606s/100 iters), loss = 0.202961
I0626 01:12:17.431365 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:12:17.431365 17260 solver.cpp:237]     Train net output #1: loss = 0.202961 (* 1 = 0.202961 loss)
I0626 01:12:17.431365 17260 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0626 01:12:21.486089 17260 solver.cpp:218] Iteration 6400 (24.6553 iter/s, 4.05592s/100 iters), loss = 0.15285
I0626 01:12:21.486089 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:12:21.486089 17260 solver.cpp:237]     Train net output #1: loss = 0.15285 (* 1 = 0.15285 loss)
I0626 01:12:21.486089 17260 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0626 01:12:25.329233 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:12:25.535953 17260 solver.cpp:218] Iteration 6500 (24.7033 iter/s, 4.04804s/100 iters), loss = 0.199584
I0626 01:12:25.535953 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:12:25.535953 17260 solver.cpp:237]     Train net output #1: loss = 0.199584 (* 1 = 0.199584 loss)
I0626 01:12:25.535953 17260 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0626 01:12:29.603772 17260 solver.cpp:218] Iteration 6600 (24.5851 iter/s, 4.0675s/100 iters), loss = 0.228676
I0626 01:12:29.603772 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:12:29.604272 17260 solver.cpp:237]     Train net output #1: loss = 0.228676 (* 1 = 0.228676 loss)
I0626 01:12:29.604272 17260 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0626 01:12:33.650740 17260 solver.cpp:218] Iteration 6700 (24.6607 iter/s, 4.05503s/100 iters), loss = 0.27922
I0626 01:12:33.650740 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:12:33.650740 17260 solver.cpp:237]     Train net output #1: loss = 0.27922 (* 1 = 0.27922 loss)
I0626 01:12:33.650740 17260 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0626 01:12:37.712191 17260 solver.cpp:218] Iteration 6800 (24.6777 iter/s, 4.05224s/100 iters), loss = 0.17106
I0626 01:12:37.712191 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:12:37.712191 17260 solver.cpp:237]     Train net output #1: loss = 0.17106 (* 1 = 0.17106 loss)
I0626 01:12:37.712191 17260 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0626 01:12:41.756153 17260 solver.cpp:218] Iteration 6900 (24.696 iter/s, 4.04924s/100 iters), loss = 0.194031
I0626 01:12:41.756153 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:12:41.756153 17260 solver.cpp:237]     Train net output #1: loss = 0.194031 (* 1 = 0.194031 loss)
I0626 01:12:41.756153 17260 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0626 01:12:45.618417 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:12:45.769467 17260 solver.cpp:330] Iteration 7000, Testing net (#0)
I0626 01:12:45.769467 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:12:46.901551  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:12:46.946671 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8602
I0626 01:12:46.946671 17260 solver.cpp:397]     Test net output #1: loss = 0.436022 (* 1 = 0.436022 loss)
I0626 01:12:46.988775 17260 solver.cpp:218] Iteration 7000 (19.1325 iter/s, 5.22672s/100 iters), loss = 0.229766
I0626 01:12:46.988775 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:12:46.988775 17260 solver.cpp:237]     Train net output #1: loss = 0.229766 (* 1 = 0.229766 loss)
I0626 01:12:46.988775 17260 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0626 01:12:51.042946 17260 solver.cpp:218] Iteration 7100 (24.6506 iter/s, 4.05669s/100 iters), loss = 0.2544
I0626 01:12:51.042946 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:12:51.042946 17260 solver.cpp:237]     Train net output #1: loss = 0.2544 (* 1 = 0.2544 loss)
I0626 01:12:51.042946 17260 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0626 01:12:55.113548 17260 solver.cpp:218] Iteration 7200 (24.5859 iter/s, 4.06736s/100 iters), loss = 0.303824
I0626 01:12:55.113548 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:12:55.113548 17260 solver.cpp:237]     Train net output #1: loss = 0.303824 (* 1 = 0.303824 loss)
I0626 01:12:55.114050 17260 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0626 01:12:59.188344 17260 solver.cpp:218] Iteration 7300 (24.49 iter/s, 4.0833s/100 iters), loss = 0.196037
I0626 01:12:59.188344 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:12:59.188344 17260 solver.cpp:237]     Train net output #1: loss = 0.196037 (* 1 = 0.196037 loss)
I0626 01:12:59.188344 17260 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0626 01:13:03.277102 17260 solver.cpp:218] Iteration 7400 (24.5134 iter/s, 4.0794s/100 iters), loss = 0.189004
I0626 01:13:03.277102 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:13:03.277102 17260 solver.cpp:237]     Train net output #1: loss = 0.189004 (* 1 = 0.189004 loss)
I0626 01:13:03.277102 17260 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0626 01:13:07.140792 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:13:07.330691 17260 solver.cpp:218] Iteration 7500 (24.6186 iter/s, 4.06197s/100 iters), loss = 0.159788
I0626 01:13:07.330691 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:13:07.330691 17260 solver.cpp:237]     Train net output #1: loss = 0.159788 (* 1 = 0.159788 loss)
I0626 01:13:07.330691 17260 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0626 01:13:11.391388 17260 solver.cpp:218] Iteration 7600 (24.6614 iter/s, 4.05492s/100 iters), loss = 0.222702
I0626 01:13:11.391388 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:13:11.391388 17260 solver.cpp:237]     Train net output #1: loss = 0.222702 (* 1 = 0.222702 loss)
I0626 01:13:11.391388 17260 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0626 01:13:15.566316 17260 solver.cpp:218] Iteration 7700 (23.9356 iter/s, 4.17788s/100 iters), loss = 0.207468
I0626 01:13:15.566316 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:13:15.566316 17260 solver.cpp:237]     Train net output #1: loss = 0.207468 (* 1 = 0.207468 loss)
I0626 01:13:15.566316 17260 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0626 01:13:19.611774 17260 solver.cpp:218] Iteration 7800 (24.7622 iter/s, 4.03841s/100 iters), loss = 0.166052
I0626 01:13:19.611774 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:13:19.611774 17260 solver.cpp:237]     Train net output #1: loss = 0.166052 (* 1 = 0.166052 loss)
I0626 01:13:19.612776 17260 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0626 01:13:23.651278 17260 solver.cpp:218] Iteration 7900 (24.7568 iter/s, 4.03929s/100 iters), loss = 0.159294
I0626 01:13:23.651278 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:13:23.651278 17260 solver.cpp:237]     Train net output #1: loss = 0.159294 (* 1 = 0.159294 loss)
I0626 01:13:23.651278 17260 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0626 01:13:27.485656 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:13:27.641618 17260 solver.cpp:330] Iteration 8000, Testing net (#0)
I0626 01:13:27.641618 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:13:28.753326  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:13:28.795370 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8662
I0626 01:13:28.795370 17260 solver.cpp:397]     Test net output #1: loss = 0.413403 (* 1 = 0.413403 loss)
I0626 01:13:28.835368 17260 solver.cpp:218] Iteration 8000 (19.27 iter/s, 5.18942s/100 iters), loss = 0.175363
I0626 01:13:28.835368 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:13:28.835368 17260 solver.cpp:237]     Train net output #1: loss = 0.175363 (* 1 = 0.175363 loss)
I0626 01:13:28.835368 17260 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0626 01:13:32.871526 17260 solver.cpp:218] Iteration 8100 (24.7636 iter/s, 4.03818s/100 iters), loss = 0.139657
I0626 01:13:32.871526 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:13:32.871526 17260 solver.cpp:237]     Train net output #1: loss = 0.139657 (* 1 = 0.139657 loss)
I0626 01:13:32.871526 17260 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0626 01:13:36.911523 17260 solver.cpp:218] Iteration 8200 (24.8053 iter/s, 4.0314s/100 iters), loss = 0.160683
I0626 01:13:36.911523 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:13:36.911523 17260 solver.cpp:237]     Train net output #1: loss = 0.160683 (* 1 = 0.160683 loss)
I0626 01:13:36.911523 17260 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0626 01:13:40.994436 17260 solver.cpp:218] Iteration 8300 (24.4927 iter/s, 4.08285s/100 iters), loss = 0.198195
I0626 01:13:40.994436 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:13:40.994436 17260 solver.cpp:237]     Train net output #1: loss = 0.198195 (* 1 = 0.198195 loss)
I0626 01:13:40.994436 17260 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0626 01:13:45.077718 17260 solver.cpp:218] Iteration 8400 (24.4455 iter/s, 4.09073s/100 iters), loss = 0.211978
I0626 01:13:45.077718 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:13:45.077718 17260 solver.cpp:237]     Train net output #1: loss = 0.211977 (* 1 = 0.211977 loss)
I0626 01:13:45.077718 17260 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0626 01:13:48.951256 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:13:49.153311 17260 solver.cpp:218] Iteration 8500 (24.5925 iter/s, 4.06628s/100 iters), loss = 0.123814
I0626 01:13:49.153311 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:13:49.153311 17260 solver.cpp:237]     Train net output #1: loss = 0.123814 (* 1 = 0.123814 loss)
I0626 01:13:49.153311 17260 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0626 01:13:53.215039 17260 solver.cpp:218] Iteration 8600 (24.6209 iter/s, 4.06158s/100 iters), loss = 0.218525
I0626 01:13:53.215039 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.9
I0626 01:13:53.215039 17260 solver.cpp:237]     Train net output #1: loss = 0.218525 (* 1 = 0.218525 loss)
I0626 01:13:53.215039 17260 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0626 01:13:57.304515 17260 solver.cpp:218] Iteration 8700 (24.4575 iter/s, 4.08873s/100 iters), loss = 0.117367
I0626 01:13:57.304515 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:13:57.304515 17260 solver.cpp:237]     Train net output #1: loss = 0.117367 (* 1 = 0.117367 loss)
I0626 01:13:57.304515 17260 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0626 01:14:01.345507 17260 solver.cpp:218] Iteration 8800 (24.7442 iter/s, 4.04136s/100 iters), loss = 0.0838605
I0626 01:14:01.345507 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:14:01.345507 17260 solver.cpp:237]     Train net output #1: loss = 0.0838604 (* 1 = 0.0838604 loss)
I0626 01:14:01.346498 17260 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0626 01:14:05.372642 17260 solver.cpp:218] Iteration 8900 (24.834 iter/s, 4.02674s/100 iters), loss = 0.101455
I0626 01:14:05.373641 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:14:05.373641 17260 solver.cpp:237]     Train net output #1: loss = 0.101454 (* 1 = 0.101454 loss)
I0626 01:14:05.373641 17260 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0626 01:14:09.246582 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:14:09.403744 17260 solver.cpp:330] Iteration 9000, Testing net (#0)
I0626 01:14:09.404237 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:14:10.520339  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:14:10.565371 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8736
I0626 01:14:10.565371 17260 solver.cpp:397]     Test net output #1: loss = 0.389665 (* 1 = 0.389665 loss)
I0626 01:14:10.602900 17260 solver.cpp:218] Iteration 9000 (19.1233 iter/s, 5.22923s/100 iters), loss = 0.113038
I0626 01:14:10.602900 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:14:10.602900 17260 solver.cpp:237]     Train net output #1: loss = 0.113038 (* 1 = 0.113038 loss)
I0626 01:14:10.602900 17260 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0626 01:14:14.641978 17260 solver.cpp:218] Iteration 9100 (24.7606 iter/s, 4.03868s/100 iters), loss = 0.164367
I0626 01:14:14.641978 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:14:14.641978 17260 solver.cpp:237]     Train net output #1: loss = 0.164367 (* 1 = 0.164367 loss)
I0626 01:14:14.641978 17260 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0626 01:14:18.696508 17260 solver.cpp:218] Iteration 9200 (24.6666 iter/s, 4.05407s/100 iters), loss = 0.155511
I0626 01:14:18.696508 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:14:18.696508 17260 solver.cpp:237]     Train net output #1: loss = 0.155511 (* 1 = 0.155511 loss)
I0626 01:14:18.696508 17260 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0626 01:14:22.751737 17260 solver.cpp:218] Iteration 9300 (24.6632 iter/s, 4.05463s/100 iters), loss = 0.212255
I0626 01:14:22.751737 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:14:22.751737 17260 solver.cpp:237]     Train net output #1: loss = 0.212255 (* 1 = 0.212255 loss)
I0626 01:14:22.751737 17260 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0626 01:14:26.789733 17260 solver.cpp:218] Iteration 9400 (24.7629 iter/s, 4.03829s/100 iters), loss = 0.184713
I0626 01:14:26.789733 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:14:26.789733 17260 solver.cpp:237]     Train net output #1: loss = 0.184712 (* 1 = 0.184712 loss)
I0626 01:14:26.789733 17260 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0626 01:14:30.632073 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:14:30.840592 17260 solver.cpp:218] Iteration 9500 (24.6914 iter/s, 4.04999s/100 iters), loss = 0.168787
I0626 01:14:30.840592 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:14:30.840592 17260 solver.cpp:237]     Train net output #1: loss = 0.168787 (* 1 = 0.168787 loss)
I0626 01:14:30.840592 17260 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0626 01:14:34.900879 17260 solver.cpp:218] Iteration 9600 (24.6318 iter/s, 4.05979s/100 iters), loss = 0.217015
I0626 01:14:34.900879 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:14:34.900879 17260 solver.cpp:237]     Train net output #1: loss = 0.217015 (* 1 = 0.217015 loss)
I0626 01:14:34.900879 17260 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0626 01:14:38.949193 17260 solver.cpp:218] Iteration 9700 (24.7028 iter/s, 4.04813s/100 iters), loss = 0.142709
I0626 01:14:38.949193 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:14:38.949193 17260 solver.cpp:237]     Train net output #1: loss = 0.142709 (* 1 = 0.142709 loss)
I0626 01:14:38.949193 17260 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0626 01:14:43.004792 17260 solver.cpp:218] Iteration 9800 (24.6561 iter/s, 4.05578s/100 iters), loss = 0.160588
I0626 01:14:43.004792 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:14:43.004792 17260 solver.cpp:237]     Train net output #1: loss = 0.160588 (* 1 = 0.160588 loss)
I0626 01:14:43.004792 17260 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0626 01:14:47.040900 17260 solver.cpp:218] Iteration 9900 (24.7814 iter/s, 4.03528s/100 iters), loss = 0.0834755
I0626 01:14:47.040900 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:14:47.040900 17260 solver.cpp:237]     Train net output #1: loss = 0.0834755 (* 1 = 0.0834755 loss)
I0626 01:14:47.041401 17260 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0626 01:14:50.913981 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:14:51.069108 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_10000.caffemodel
I0626 01:14:51.101131 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_10000.solverstate
I0626 01:14:51.135140 17260 solver.cpp:330] Iteration 10000, Testing net (#0)
I0626 01:14:51.135140 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:14:52.250295  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:14:52.293329 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8715
I0626 01:14:52.293329 17260 solver.cpp:397]     Test net output #1: loss = 0.409966 (* 1 = 0.409966 loss)
I0626 01:14:52.331356 17260 solver.cpp:218] Iteration 10000 (18.9015 iter/s, 5.29058s/100 iters), loss = 0.172077
I0626 01:14:52.332356 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:14:52.332356 17260 solver.cpp:237]     Train net output #1: loss = 0.172077 (* 1 = 0.172077 loss)
I0626 01:14:52.332356 17260 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0626 01:14:56.375316 17260 solver.cpp:218] Iteration 10100 (24.7318 iter/s, 4.04338s/100 iters), loss = 0.163813
I0626 01:14:56.375316 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:14:56.375316 17260 solver.cpp:237]     Train net output #1: loss = 0.163813 (* 1 = 0.163813 loss)
I0626 01:14:56.375316 17260 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0626 01:15:00.409646 17260 solver.cpp:218] Iteration 10200 (24.7955 iter/s, 4.033s/100 iters), loss = 0.118925
I0626 01:15:00.409646 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:15:00.409646 17260 solver.cpp:237]     Train net output #1: loss = 0.118925 (* 1 = 0.118925 loss)
I0626 01:15:00.409646 17260 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0626 01:15:04.458619 17260 solver.cpp:218] Iteration 10300 (24.6977 iter/s, 4.04896s/100 iters), loss = 0.0851509
I0626 01:15:04.458619 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:15:04.458619 17260 solver.cpp:237]     Train net output #1: loss = 0.0851508 (* 1 = 0.0851508 loss)
I0626 01:15:04.458619 17260 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0626 01:15:08.505523 17260 solver.cpp:218] Iteration 10400 (24.7129 iter/s, 4.04647s/100 iters), loss = 0.154647
I0626 01:15:08.505523 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:15:08.505523 17260 solver.cpp:237]     Train net output #1: loss = 0.154647 (* 1 = 0.154647 loss)
I0626 01:15:08.505523 17260 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0626 01:15:12.351313 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:15:12.548091 17260 solver.cpp:218] Iteration 10500 (24.6968 iter/s, 4.04911s/100 iters), loss = 0.132951
I0626 01:15:12.548091 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:15:12.548091 17260 solver.cpp:237]     Train net output #1: loss = 0.132951 (* 1 = 0.132951 loss)
I0626 01:15:12.548091 17260 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0626 01:15:16.612802 17260 solver.cpp:218] Iteration 10600 (24.6447 iter/s, 4.05767s/100 iters), loss = 0.127773
I0626 01:15:16.613804 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:15:16.613804 17260 solver.cpp:237]     Train net output #1: loss = 0.127773 (* 1 = 0.127773 loss)
I0626 01:15:16.613804 17260 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0626 01:15:20.675783 17260 solver.cpp:218] Iteration 10700 (24.6019 iter/s, 4.06472s/100 iters), loss = 0.201266
I0626 01:15:20.675783 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:15:20.675783 17260 solver.cpp:237]     Train net output #1: loss = 0.201266 (* 1 = 0.201266 loss)
I0626 01:15:20.675783 17260 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0626 01:15:24.718147 17260 solver.cpp:218] Iteration 10800 (24.7577 iter/s, 4.03915s/100 iters), loss = 0.108174
I0626 01:15:24.718648 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:15:24.718648 17260 solver.cpp:237]     Train net output #1: loss = 0.108174 (* 1 = 0.108174 loss)
I0626 01:15:24.718648 17260 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0626 01:15:28.753235 17260 solver.cpp:218] Iteration 10900 (24.735 iter/s, 4.04286s/100 iters), loss = 0.122004
I0626 01:15:28.753235 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:15:28.753235 17260 solver.cpp:237]     Train net output #1: loss = 0.122004 (* 1 = 0.122004 loss)
I0626 01:15:28.753235 17260 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0626 01:15:32.601505 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:15:32.761209 17260 solver.cpp:330] Iteration 11000, Testing net (#0)
I0626 01:15:32.762215 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:15:33.872650  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:15:33.923164 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8817
I0626 01:15:33.923164 17260 solver.cpp:397]     Test net output #1: loss = 0.383621 (* 1 = 0.383621 loss)
I0626 01:15:33.954735 17260 solver.cpp:218] Iteration 11000 (19.2306 iter/s, 5.20005s/100 iters), loss = 0.127223
I0626 01:15:33.954735 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:15:33.954735 17260 solver.cpp:237]     Train net output #1: loss = 0.127223 (* 1 = 0.127223 loss)
I0626 01:15:33.954735 17260 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0626 01:15:38.047775 17260 solver.cpp:218] Iteration 11100 (24.4429 iter/s, 4.09117s/100 iters), loss = 0.122445
I0626 01:15:38.047775 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:15:38.047775 17260 solver.cpp:237]     Train net output #1: loss = 0.122445 (* 1 = 0.122445 loss)
I0626 01:15:38.047775 17260 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0626 01:15:42.101642 17260 solver.cpp:218] Iteration 11200 (24.6855 iter/s, 4.05096s/100 iters), loss = 0.14003
I0626 01:15:42.101642 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:15:42.101642 17260 solver.cpp:237]     Train net output #1: loss = 0.14003 (* 1 = 0.14003 loss)
I0626 01:15:42.101642 17260 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0626 01:15:46.162523 17260 solver.cpp:218] Iteration 11300 (24.6424 iter/s, 4.05805s/100 iters), loss = 0.149876
I0626 01:15:46.162523 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:15:46.162523 17260 solver.cpp:237]     Train net output #1: loss = 0.149876 (* 1 = 0.149876 loss)
I0626 01:15:46.162523 17260 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0626 01:15:50.194756 17260 solver.cpp:218] Iteration 11400 (24.7534 iter/s, 4.03985s/100 iters), loss = 0.11576
I0626 01:15:50.194756 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:15:50.194756 17260 solver.cpp:237]     Train net output #1: loss = 0.11576 (* 1 = 0.11576 loss)
I0626 01:15:50.194756 17260 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0626 01:15:54.167893 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:15:54.367954 17260 solver.cpp:218] Iteration 11500 (24.0143 iter/s, 4.16419s/100 iters), loss = 0.135824
I0626 01:15:54.367954 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:15:54.367954 17260 solver.cpp:237]     Train net output #1: loss = 0.135824 (* 1 = 0.135824 loss)
I0626 01:15:54.367954 17260 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0626 01:15:58.429575 17260 solver.cpp:218] Iteration 11600 (24.5809 iter/s, 4.0682s/100 iters), loss = 0.125084
I0626 01:15:58.429575 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:15:58.429575 17260 solver.cpp:237]     Train net output #1: loss = 0.125084 (* 1 = 0.125084 loss)
I0626 01:15:58.429575 17260 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0626 01:16:02.530393 17260 solver.cpp:218] Iteration 11700 (24.4285 iter/s, 4.09358s/100 iters), loss = 0.110033
I0626 01:16:02.530393 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:16:02.530393 17260 solver.cpp:237]     Train net output #1: loss = 0.110033 (* 1 = 0.110033 loss)
I0626 01:16:02.530393 17260 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0626 01:16:06.648406 17260 solver.cpp:218] Iteration 11800 (24.2854 iter/s, 4.11769s/100 iters), loss = 0.0637337
I0626 01:16:06.648406 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:16:06.648406 17260 solver.cpp:237]     Train net output #1: loss = 0.0637337 (* 1 = 0.0637337 loss)
I0626 01:16:06.648406 17260 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0626 01:16:10.731590 17260 solver.cpp:218] Iteration 11900 (24.4388 iter/s, 4.09186s/100 iters), loss = 0.139736
I0626 01:16:10.731590 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:16:10.731590 17260 solver.cpp:237]     Train net output #1: loss = 0.139736 (* 1 = 0.139736 loss)
I0626 01:16:10.731590 17260 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0626 01:16:14.610884 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:16:14.763713 17260 solver.cpp:330] Iteration 12000, Testing net (#0)
I0626 01:16:14.763713 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:16:15.885538  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:16:15.925611 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8649
I0626 01:16:15.925611 17260 solver.cpp:397]     Test net output #1: loss = 0.459752 (* 1 = 0.459752 loss)
I0626 01:16:15.967676 17260 solver.cpp:218] Iteration 12000 (19.1335 iter/s, 5.22644s/100 iters), loss = 0.109704
I0626 01:16:15.967676 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:16:15.967676 17260 solver.cpp:237]     Train net output #1: loss = 0.109704 (* 1 = 0.109704 loss)
I0626 01:16:15.967676 17260 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0626 01:16:20.008483 17260 solver.cpp:218] Iteration 12100 (24.7428 iter/s, 4.04158s/100 iters), loss = 0.166637
I0626 01:16:20.008483 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:16:20.008483 17260 solver.cpp:237]     Train net output #1: loss = 0.166637 (* 1 = 0.166637 loss)
I0626 01:16:20.008483 17260 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0626 01:16:24.071933 17260 solver.cpp:218] Iteration 12200 (24.5982 iter/s, 4.06534s/100 iters), loss = 0.105808
I0626 01:16:24.071933 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:16:24.071933 17260 solver.cpp:237]     Train net output #1: loss = 0.105808 (* 1 = 0.105808 loss)
I0626 01:16:24.071933 17260 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0626 01:16:28.131635 17260 solver.cpp:218] Iteration 12300 (24.6376 iter/s, 4.05883s/100 iters), loss = 0.113752
I0626 01:16:28.131635 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:16:28.131635 17260 solver.cpp:237]     Train net output #1: loss = 0.113752 (* 1 = 0.113752 loss)
I0626 01:16:28.131635 17260 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0626 01:16:32.245116 17260 solver.cpp:218] Iteration 12400 (24.332 iter/s, 4.10982s/100 iters), loss = 0.126929
I0626 01:16:32.245116 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:16:32.245116 17260 solver.cpp:237]     Train net output #1: loss = 0.126929 (* 1 = 0.126929 loss)
I0626 01:16:32.245116 17260 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0626 01:16:36.087265 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:16:36.293422 17260 solver.cpp:218] Iteration 12500 (24.7 iter/s, 4.04859s/100 iters), loss = 0.102036
I0626 01:16:36.293422 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:16:36.293422 17260 solver.cpp:237]     Train net output #1: loss = 0.102036 (* 1 = 0.102036 loss)
I0626 01:16:36.293422 17260 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0626 01:16:40.346904 17260 solver.cpp:218] Iteration 12600 (24.6775 iter/s, 4.05228s/100 iters), loss = 0.0601733
I0626 01:16:40.346904 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:16:40.346904 17260 solver.cpp:237]     Train net output #1: loss = 0.0601733 (* 1 = 0.0601733 loss)
I0626 01:16:40.346904 17260 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0626 01:16:44.382428 17260 solver.cpp:218] Iteration 12700 (24.7237 iter/s, 4.04471s/100 iters), loss = 0.157404
I0626 01:16:44.382428 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.91
I0626 01:16:44.382428 17260 solver.cpp:237]     Train net output #1: loss = 0.157404 (* 1 = 0.157404 loss)
I0626 01:16:44.382428 17260 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0626 01:16:48.426709 17260 solver.cpp:218] Iteration 12800 (24.7502 iter/s, 4.04037s/100 iters), loss = 0.0945277
I0626 01:16:48.426709 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:16:48.426709 17260 solver.cpp:237]     Train net output #1: loss = 0.0945277 (* 1 = 0.0945277 loss)
I0626 01:16:48.426709 17260 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0626 01:16:52.480672 17260 solver.cpp:218] Iteration 12900 (24.7059 iter/s, 4.04762s/100 iters), loss = 0.0862773
I0626 01:16:52.480672 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:16:52.480672 17260 solver.cpp:237]     Train net output #1: loss = 0.0862773 (* 1 = 0.0862773 loss)
I0626 01:16:52.480672 17260 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0626 01:16:56.323101 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:16:56.473475 17260 solver.cpp:330] Iteration 13000, Testing net (#0)
I0626 01:16:56.473475 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:16:57.601742  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:16:57.643834 17260 solver.cpp:397]     Test net output #0: accuracy = 0.887
I0626 01:16:57.643834 17260 solver.cpp:397]     Test net output #1: loss = 0.366478 (* 1 = 0.366478 loss)
I0626 01:16:57.683852 17260 solver.cpp:218] Iteration 13000 (19.2213 iter/s, 5.20256s/100 iters), loss = 0.0777179
I0626 01:16:57.683852 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:16:57.683852 17260 solver.cpp:237]     Train net output #1: loss = 0.0777178 (* 1 = 0.0777178 loss)
I0626 01:16:57.683852 17260 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0626 01:17:01.739617 17260 solver.cpp:218] Iteration 13100 (24.653 iter/s, 4.05631s/100 iters), loss = 0.0485693
I0626 01:17:01.739617 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:17:01.739617 17260 solver.cpp:237]     Train net output #1: loss = 0.0485693 (* 1 = 0.0485693 loss)
I0626 01:17:01.739617 17260 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0626 01:17:05.772445 17260 solver.cpp:218] Iteration 13200 (24.7792 iter/s, 4.03564s/100 iters), loss = 0.114325
I0626 01:17:05.772445 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:17:05.772445 17260 solver.cpp:237]     Train net output #1: loss = 0.114325 (* 1 = 0.114325 loss)
I0626 01:17:05.772445 17260 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0626 01:17:09.803382 17260 solver.cpp:218] Iteration 13300 (24.8038 iter/s, 4.03164s/100 iters), loss = 0.0495999
I0626 01:17:09.803382 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:17:09.803382 17260 solver.cpp:237]     Train net output #1: loss = 0.0495999 (* 1 = 0.0495999 loss)
I0626 01:17:09.803382 17260 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0626 01:17:13.836385 17260 solver.cpp:218] Iteration 13400 (24.8293 iter/s, 4.0275s/100 iters), loss = 0.169989
I0626 01:17:13.836385 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:17:13.836385 17260 solver.cpp:237]     Train net output #1: loss = 0.169989 (* 1 = 0.169989 loss)
I0626 01:17:13.836385 17260 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0626 01:17:17.667735 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:17:17.874251 17260 solver.cpp:218] Iteration 13500 (24.7704 iter/s, 4.03708s/100 iters), loss = 0.0557317
I0626 01:17:17.874251 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:17:17.874251 17260 solver.cpp:237]     Train net output #1: loss = 0.0557318 (* 1 = 0.0557318 loss)
I0626 01:17:17.874251 17260 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0626 01:17:21.964494 17260 solver.cpp:218] Iteration 13600 (24.4495 iter/s, 4.09007s/100 iters), loss = 0.131723
I0626 01:17:21.964494 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:17:21.964494 17260 solver.cpp:237]     Train net output #1: loss = 0.131723 (* 1 = 0.131723 loss)
I0626 01:17:21.964494 17260 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0626 01:17:26.014999 17260 solver.cpp:218] Iteration 13700 (24.6929 iter/s, 4.04974s/100 iters), loss = 0.0810712
I0626 01:17:26.014999 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:17:26.014999 17260 solver.cpp:237]     Train net output #1: loss = 0.0810712 (* 1 = 0.0810712 loss)
I0626 01:17:26.014999 17260 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0626 01:17:30.062000 17260 solver.cpp:218] Iteration 13800 (24.7127 iter/s, 4.0465s/100 iters), loss = 0.158962
I0626 01:17:30.062000 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:17:30.062000 17260 solver.cpp:237]     Train net output #1: loss = 0.158962 (* 1 = 0.158962 loss)
I0626 01:17:30.062000 17260 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0626 01:17:34.102270 17260 solver.cpp:218] Iteration 13900 (24.7501 iter/s, 4.04038s/100 iters), loss = 0.140005
I0626 01:17:34.102270 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:17:34.102270 17260 solver.cpp:237]     Train net output #1: loss = 0.140005 (* 1 = 0.140005 loss)
I0626 01:17:34.102270 17260 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0626 01:17:37.933585 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:17:38.094095 17260 solver.cpp:330] Iteration 14000, Testing net (#0)
I0626 01:17:38.094095 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:17:39.204700  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:17:39.242440 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8801
I0626 01:17:39.242440 17260 solver.cpp:397]     Test net output #1: loss = 0.401497 (* 1 = 0.401497 loss)
I0626 01:17:39.289746 17260 solver.cpp:218] Iteration 14000 (19.2804 iter/s, 5.1866s/100 iters), loss = 0.124709
I0626 01:17:39.289746 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:17:39.289746 17260 solver.cpp:237]     Train net output #1: loss = 0.124709 (* 1 = 0.124709 loss)
I0626 01:17:39.289746 17260 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0626 01:17:43.326339 17260 solver.cpp:218] Iteration 14100 (24.747 iter/s, 4.04089s/100 iters), loss = 0.094299
I0626 01:17:43.326339 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:17:43.326339 17260 solver.cpp:237]     Train net output #1: loss = 0.094299 (* 1 = 0.094299 loss)
I0626 01:17:43.326339 17260 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0626 01:17:47.385399 17260 solver.cpp:218] Iteration 14200 (24.6638 iter/s, 4.05452s/100 iters), loss = 0.104717
I0626 01:17:47.385399 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:17:47.385399 17260 solver.cpp:237]     Train net output #1: loss = 0.104717 (* 1 = 0.104717 loss)
I0626 01:17:47.385399 17260 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0626 01:17:51.480240 17260 solver.cpp:218] Iteration 14300 (24.4068 iter/s, 4.09721s/100 iters), loss = 0.143656
I0626 01:17:51.480240 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:17:51.480240 17260 solver.cpp:237]     Train net output #1: loss = 0.143656 (* 1 = 0.143656 loss)
I0626 01:17:51.480240 17260 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0626 01:17:55.523617 17260 solver.cpp:218] Iteration 14400 (24.7556 iter/s, 4.0395s/100 iters), loss = 0.106965
I0626 01:17:55.523617 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:17:55.523617 17260 solver.cpp:237]     Train net output #1: loss = 0.106965 (* 1 = 0.106965 loss)
I0626 01:17:55.523617 17260 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0626 01:17:59.392802 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:17:59.586419 17260 solver.cpp:218] Iteration 14500 (24.613 iter/s, 4.06289s/100 iters), loss = 0.0599729
I0626 01:17:59.586419 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:17:59.586419 17260 solver.cpp:237]     Train net output #1: loss = 0.0599728 (* 1 = 0.0599728 loss)
I0626 01:17:59.586419 17260 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0626 01:18:03.631395 17260 solver.cpp:218] Iteration 14600 (24.7275 iter/s, 4.04407s/100 iters), loss = 0.157373
I0626 01:18:03.631395 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.92
I0626 01:18:03.631395 17260 solver.cpp:237]     Train net output #1: loss = 0.157373 (* 1 = 0.157373 loss)
I0626 01:18:03.631395 17260 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0626 01:18:07.671478 17260 solver.cpp:218] Iteration 14700 (24.7348 iter/s, 4.04288s/100 iters), loss = 0.163036
I0626 01:18:07.671478 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:18:07.671478 17260 solver.cpp:237]     Train net output #1: loss = 0.163036 (* 1 = 0.163036 loss)
I0626 01:18:07.671478 17260 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0626 01:18:11.709409 17260 solver.cpp:218] Iteration 14800 (24.7693 iter/s, 4.03726s/100 iters), loss = 0.0643009
I0626 01:18:11.709409 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:18:11.709409 17260 solver.cpp:237]     Train net output #1: loss = 0.0643009 (* 1 = 0.0643009 loss)
I0626 01:18:11.709409 17260 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0626 01:18:15.754353 17260 solver.cpp:218] Iteration 14900 (24.7141 iter/s, 4.04627s/100 iters), loss = 0.0703595
I0626 01:18:15.754353 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:18:15.754353 17260 solver.cpp:237]     Train net output #1: loss = 0.0703594 (* 1 = 0.0703594 loss)
I0626 01:18:15.754353 17260 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0626 01:18:19.602705 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:18:19.757231 17260 solver.cpp:330] Iteration 15000, Testing net (#0)
I0626 01:18:19.757231 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:18:20.882158  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:18:20.932212 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8796
I0626 01:18:20.932212 17260 solver.cpp:397]     Test net output #1: loss = 0.398034 (* 1 = 0.398034 loss)
I0626 01:18:20.968191 17260 solver.cpp:218] Iteration 15000 (19.1868 iter/s, 5.21193s/100 iters), loss = 0.0483577
I0626 01:18:20.968191 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:18:20.968191 17260 solver.cpp:237]     Train net output #1: loss = 0.0483576 (* 1 = 0.0483576 loss)
I0626 01:18:20.968191 17260 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0626 01:18:25.033597 17260 solver.cpp:218] Iteration 15100 (24.6173 iter/s, 4.06219s/100 iters), loss = 0.127148
I0626 01:18:25.033597 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.93
I0626 01:18:25.033597 17260 solver.cpp:237]     Train net output #1: loss = 0.127148 (* 1 = 0.127148 loss)
I0626 01:18:25.033597 17260 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0626 01:18:29.089594 17260 solver.cpp:218] Iteration 15200 (24.6554 iter/s, 4.05591s/100 iters), loss = 0.108226
I0626 01:18:29.089594 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:18:29.089594 17260 solver.cpp:237]     Train net output #1: loss = 0.108226 (* 1 = 0.108226 loss)
I0626 01:18:29.089594 17260 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0626 01:18:33.155270 17260 solver.cpp:218] Iteration 15300 (24.5913 iter/s, 4.06648s/100 iters), loss = 0.125308
I0626 01:18:33.155270 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:18:33.155270 17260 solver.cpp:237]     Train net output #1: loss = 0.125308 (* 1 = 0.125308 loss)
I0626 01:18:33.155270 17260 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0626 01:18:37.199225 17260 solver.cpp:218] Iteration 15400 (24.704 iter/s, 4.04794s/100 iters), loss = 0.0963283
I0626 01:18:37.199225 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:18:37.199225 17260 solver.cpp:237]     Train net output #1: loss = 0.0963282 (* 1 = 0.0963282 loss)
I0626 01:18:37.199225 17260 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0626 01:18:41.071045 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:18:41.271464 17260 solver.cpp:218] Iteration 15500 (24.58 iter/s, 4.06835s/100 iters), loss = 0.0756101
I0626 01:18:41.271464 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:18:41.271464 17260 solver.cpp:237]     Train net output #1: loss = 0.07561 (* 1 = 0.07561 loss)
I0626 01:18:41.271464 17260 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0626 01:18:45.351985 17260 solver.cpp:218] Iteration 15600 (24.527 iter/s, 4.07714s/100 iters), loss = 0.0970082
I0626 01:18:45.351985 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:18:45.351985 17260 solver.cpp:237]     Train net output #1: loss = 0.0970082 (* 1 = 0.0970082 loss)
I0626 01:18:45.351985 17260 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0626 01:18:49.389210 17260 solver.cpp:218] Iteration 15700 (24.7221 iter/s, 4.04496s/100 iters), loss = 0.141398
I0626 01:18:49.389210 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:18:49.389210 17260 solver.cpp:237]     Train net output #1: loss = 0.141398 (* 1 = 0.141398 loss)
I0626 01:18:49.389210 17260 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0626 01:18:53.443079 17260 solver.cpp:218] Iteration 15800 (24.6857 iter/s, 4.05093s/100 iters), loss = 0.100453
I0626 01:18:53.443079 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:18:53.443079 17260 solver.cpp:237]     Train net output #1: loss = 0.100453 (* 1 = 0.100453 loss)
I0626 01:18:53.443079 17260 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0626 01:18:57.494552 17260 solver.cpp:218] Iteration 15900 (24.6981 iter/s, 4.04889s/100 iters), loss = 0.0798596
I0626 01:18:57.494552 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:18:57.494552 17260 solver.cpp:237]     Train net output #1: loss = 0.0798596 (* 1 = 0.0798596 loss)
I0626 01:18:57.494552 17260 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0626 01:19:01.363008 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:19:01.517853 17260 solver.cpp:330] Iteration 16000, Testing net (#0)
I0626 01:19:01.517853 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:19:02.638670  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:19:02.678673 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8822
I0626 01:19:02.678673 17260 solver.cpp:397]     Test net output #1: loss = 0.391528 (* 1 = 0.391528 loss)
I0626 01:19:02.718183 17260 solver.cpp:218] Iteration 16000 (19.1327 iter/s, 5.22665s/100 iters), loss = 0.051349
I0626 01:19:02.718183 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:19:02.718183 17260 solver.cpp:237]     Train net output #1: loss = 0.0513489 (* 1 = 0.0513489 loss)
I0626 01:19:02.718183 17260 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0626 01:19:06.770586 17260 solver.cpp:218] Iteration 16100 (24.7163 iter/s, 4.04591s/100 iters), loss = 0.0797704
I0626 01:19:06.770586 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:19:06.770586 17260 solver.cpp:237]     Train net output #1: loss = 0.0797704 (* 1 = 0.0797704 loss)
I0626 01:19:06.770586 17260 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0626 01:19:10.823066 17260 solver.cpp:218] Iteration 16200 (24.6813 iter/s, 4.05166s/100 iters), loss = 0.0778564
I0626 01:19:10.823570 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:19:10.823570 17260 solver.cpp:237]     Train net output #1: loss = 0.0778563 (* 1 = 0.0778563 loss)
I0626 01:19:10.823570 17260 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0626 01:19:14.856755 17260 solver.cpp:218] Iteration 16300 (24.7957 iter/s, 4.03295s/100 iters), loss = 0.0704767
I0626 01:19:14.856755 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:19:14.856755 17260 solver.cpp:237]     Train net output #1: loss = 0.0704767 (* 1 = 0.0704767 loss)
I0626 01:19:14.856755 17260 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0626 01:19:18.899570 17260 solver.cpp:218] Iteration 16400 (24.7335 iter/s, 4.0431s/100 iters), loss = 0.115848
I0626 01:19:18.899570 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:19:18.899570 17260 solver.cpp:237]     Train net output #1: loss = 0.115848 (* 1 = 0.115848 loss)
I0626 01:19:18.899570 17260 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0626 01:19:22.811198 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:19:23.013366 17260 solver.cpp:218] Iteration 16500 (24.3123 iter/s, 4.11314s/100 iters), loss = 0.10843
I0626 01:19:23.013366 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:19:23.013366 17260 solver.cpp:237]     Train net output #1: loss = 0.108429 (* 1 = 0.108429 loss)
I0626 01:19:23.013366 17260 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0626 01:19:27.081039 17260 solver.cpp:218] Iteration 16600 (24.5954 iter/s, 4.0658s/100 iters), loss = 0.102008
I0626 01:19:27.081039 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:19:27.081039 17260 solver.cpp:237]     Train net output #1: loss = 0.102007 (* 1 = 0.102007 loss)
I0626 01:19:27.081039 17260 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0626 01:19:31.142581 17260 solver.cpp:218] Iteration 16700 (24.5759 iter/s, 4.06902s/100 iters), loss = 0.101926
I0626 01:19:31.142581 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:19:31.142581 17260 solver.cpp:237]     Train net output #1: loss = 0.101926 (* 1 = 0.101926 loss)
I0626 01:19:31.142581 17260 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0626 01:19:35.210288 17260 solver.cpp:218] Iteration 16800 (24.6298 iter/s, 4.06012s/100 iters), loss = 0.072945
I0626 01:19:35.210288 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:19:35.210288 17260 solver.cpp:237]     Train net output #1: loss = 0.0729449 (* 1 = 0.0729449 loss)
I0626 01:19:35.210288 17260 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0626 01:19:39.275429 17260 solver.cpp:218] Iteration 16900 (24.6045 iter/s, 4.0643s/100 iters), loss = 0.0908481
I0626 01:19:39.275429 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:19:39.275429 17260 solver.cpp:237]     Train net output #1: loss = 0.0908481 (* 1 = 0.0908481 loss)
I0626 01:19:39.275913 17260 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0626 01:19:43.153326 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:19:43.311318 17260 solver.cpp:330] Iteration 17000, Testing net (#0)
I0626 01:19:43.311318 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:19:44.420189  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:19:44.471714 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8867
I0626 01:19:44.471714 17260 solver.cpp:397]     Test net output #1: loss = 0.386006 (* 1 = 0.386006 loss)
I0626 01:19:44.510740 17260 solver.cpp:218] Iteration 17000 (19.0984 iter/s, 5.23604s/100 iters), loss = 0.0975297
I0626 01:19:44.510740 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:19:44.510740 17260 solver.cpp:237]     Train net output #1: loss = 0.0975296 (* 1 = 0.0975296 loss)
I0626 01:19:44.510740 17260 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0626 01:19:48.549525 17260 solver.cpp:218] Iteration 17100 (24.7676 iter/s, 4.03754s/100 iters), loss = 0.0753549
I0626 01:19:48.549525 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:19:48.549525 17260 solver.cpp:237]     Train net output #1: loss = 0.0753549 (* 1 = 0.0753549 loss)
I0626 01:19:48.549525 17260 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0626 01:19:52.587154 17260 solver.cpp:218] Iteration 17200 (24.7247 iter/s, 4.04454s/100 iters), loss = 0.148615
I0626 01:19:52.587154 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:19:52.587154 17260 solver.cpp:237]     Train net output #1: loss = 0.148615 (* 1 = 0.148615 loss)
I0626 01:19:52.587154 17260 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0626 01:19:56.633096 17260 solver.cpp:218] Iteration 17300 (24.7109 iter/s, 4.0468s/100 iters), loss = 0.0711859
I0626 01:19:56.633096 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:19:56.633096 17260 solver.cpp:237]     Train net output #1: loss = 0.0711859 (* 1 = 0.0711859 loss)
I0626 01:19:56.633096 17260 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0626 01:20:00.701298 17260 solver.cpp:218] Iteration 17400 (24.6386 iter/s, 4.05867s/100 iters), loss = 0.0609739
I0626 01:20:00.701298 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:20:00.701298 17260 solver.cpp:237]     Train net output #1: loss = 0.0609739 (* 1 = 0.0609739 loss)
I0626 01:20:00.701298 17260 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0626 01:20:04.553619 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:20:04.756899 17260 solver.cpp:218] Iteration 17500 (24.6576 iter/s, 4.05554s/100 iters), loss = 0.149468
I0626 01:20:04.756899 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:20:04.756899 17260 solver.cpp:237]     Train net output #1: loss = 0.149468 (* 1 = 0.149468 loss)
I0626 01:20:04.756899 17260 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0626 01:20:08.803429 17260 solver.cpp:218] Iteration 17600 (24.7145 iter/s, 4.04621s/100 iters), loss = 0.0799359
I0626 01:20:08.803429 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:20:08.803429 17260 solver.cpp:237]     Train net output #1: loss = 0.0799358 (* 1 = 0.0799358 loss)
I0626 01:20:08.803429 17260 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0626 01:20:12.851246 17260 solver.cpp:218] Iteration 17700 (24.7101 iter/s, 4.04693s/100 iters), loss = 0.10633
I0626 01:20:12.851246 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:20:12.851246 17260 solver.cpp:237]     Train net output #1: loss = 0.10633 (* 1 = 0.10633 loss)
I0626 01:20:12.851246 17260 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0626 01:20:16.901942 17260 solver.cpp:218] Iteration 17800 (24.6898 iter/s, 4.05026s/100 iters), loss = 0.107869
I0626 01:20:16.901942 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:20:16.901942 17260 solver.cpp:237]     Train net output #1: loss = 0.107869 (* 1 = 0.107869 loss)
I0626 01:20:16.901942 17260 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0626 01:20:20.941953 17260 solver.cpp:218] Iteration 17900 (24.7359 iter/s, 4.04271s/100 iters), loss = 0.0772666
I0626 01:20:20.941953 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:20:20.941953 17260 solver.cpp:237]     Train net output #1: loss = 0.0772667 (* 1 = 0.0772667 loss)
I0626 01:20:20.941953 17260 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0626 01:20:24.788374 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:20:24.937219 17260 solver.cpp:330] Iteration 18000, Testing net (#0)
I0626 01:20:24.937219 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:20:26.057904  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:20:26.102573 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0626 01:20:26.102573 17260 solver.cpp:397]     Test net output #1: loss = 0.351568 (* 1 = 0.351568 loss)
I0626 01:20:26.138080 17260 solver.cpp:218] Iteration 18000 (19.2447 iter/s, 5.19623s/100 iters), loss = 0.153011
I0626 01:20:26.138080 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:20:26.138080 17260 solver.cpp:237]     Train net output #1: loss = 0.153011 (* 1 = 0.153011 loss)
I0626 01:20:26.138080 17260 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0626 01:20:30.180222 17260 solver.cpp:218] Iteration 18100 (24.7335 iter/s, 4.0431s/100 iters), loss = 0.111928
I0626 01:20:30.180222 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:20:30.180222 17260 solver.cpp:237]     Train net output #1: loss = 0.111928 (* 1 = 0.111928 loss)
I0626 01:20:30.180222 17260 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0626 01:20:34.233260 17260 solver.cpp:218] Iteration 18200 (24.69 iter/s, 4.05022s/100 iters), loss = 0.10216
I0626 01:20:34.233260 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:20:34.233260 17260 solver.cpp:237]     Train net output #1: loss = 0.10216 (* 1 = 0.10216 loss)
I0626 01:20:34.233260 17260 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0626 01:20:38.288975 17260 solver.cpp:218] Iteration 18300 (24.678 iter/s, 4.0522s/100 iters), loss = 0.0926309
I0626 01:20:38.288975 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:20:38.288975 17260 solver.cpp:237]     Train net output #1: loss = 0.0926309 (* 1 = 0.0926309 loss)
I0626 01:20:38.288975 17260 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0626 01:20:42.319911 17260 solver.cpp:218] Iteration 18400 (24.7783 iter/s, 4.03578s/100 iters), loss = 0.0535859
I0626 01:20:42.319911 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:20:42.319911 17260 solver.cpp:237]     Train net output #1: loss = 0.0535859 (* 1 = 0.0535859 loss)
I0626 01:20:42.319911 17260 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0626 01:20:46.152598 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:20:46.351214 17260 solver.cpp:218] Iteration 18500 (24.837 iter/s, 4.02625s/100 iters), loss = 0.106821
I0626 01:20:46.351214 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:20:46.351214 17260 solver.cpp:237]     Train net output #1: loss = 0.106821 (* 1 = 0.106821 loss)
I0626 01:20:46.351214 17260 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0626 01:20:50.384992 17260 solver.cpp:218] Iteration 18600 (24.7768 iter/s, 4.03603s/100 iters), loss = 0.049321
I0626 01:20:50.384992 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:20:50.384992 17260 solver.cpp:237]     Train net output #1: loss = 0.0493211 (* 1 = 0.0493211 loss)
I0626 01:20:50.384992 17260 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0626 01:20:54.447661 17260 solver.cpp:218] Iteration 18700 (24.635 iter/s, 4.05926s/100 iters), loss = 0.084154
I0626 01:20:54.447661 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:20:54.447661 17260 solver.cpp:237]     Train net output #1: loss = 0.0841541 (* 1 = 0.0841541 loss)
I0626 01:20:54.447661 17260 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0626 01:20:58.488296 17260 solver.cpp:218] Iteration 18800 (24.7506 iter/s, 4.04031s/100 iters), loss = 0.0632765
I0626 01:20:58.488296 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:20:58.488296 17260 solver.cpp:237]     Train net output #1: loss = 0.0632766 (* 1 = 0.0632766 loss)
I0626 01:20:58.488296 17260 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0626 01:21:02.524894 17260 solver.cpp:218] Iteration 18900 (24.7338 iter/s, 4.04305s/100 iters), loss = 0.0603458
I0626 01:21:02.524894 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:21:02.524894 17260 solver.cpp:237]     Train net output #1: loss = 0.0603459 (* 1 = 0.0603459 loss)
I0626 01:21:02.524894 17260 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0626 01:21:06.376868 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:21:06.527279 17260 solver.cpp:330] Iteration 19000, Testing net (#0)
I0626 01:21:06.527279 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:21:07.646981  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:21:07.687522 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8854
I0626 01:21:07.687522 17260 solver.cpp:397]     Test net output #1: loss = 0.397646 (* 1 = 0.397646 loss)
I0626 01:21:07.727524 17260 solver.cpp:218] Iteration 19000 (19.2333 iter/s, 5.19933s/100 iters), loss = 0.0788738
I0626 01:21:07.727524 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:21:07.727524 17260 solver.cpp:237]     Train net output #1: loss = 0.0788739 (* 1 = 0.0788739 loss)
I0626 01:21:07.727524 17260 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0626 01:21:11.785894 17260 solver.cpp:218] Iteration 19100 (24.6717 iter/s, 4.05323s/100 iters), loss = 0.0557947
I0626 01:21:11.785894 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:21:11.785894 17260 solver.cpp:237]     Train net output #1: loss = 0.0557948 (* 1 = 0.0557948 loss)
I0626 01:21:11.785894 17260 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0626 01:21:15.816612 17260 solver.cpp:218] Iteration 19200 (24.7702 iter/s, 4.03711s/100 iters), loss = 0.0730016
I0626 01:21:15.816612 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:21:15.816612 17260 solver.cpp:237]     Train net output #1: loss = 0.0730017 (* 1 = 0.0730017 loss)
I0626 01:21:15.816612 17260 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0626 01:21:19.873955 17260 solver.cpp:218] Iteration 19300 (24.6397 iter/s, 4.05848s/100 iters), loss = 0.08527
I0626 01:21:19.873955 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:21:19.873955 17260 solver.cpp:237]     Train net output #1: loss = 0.0852701 (* 1 = 0.0852701 loss)
I0626 01:21:19.873955 17260 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0626 01:21:23.926933 17260 solver.cpp:218] Iteration 19400 (24.6979 iter/s, 4.04893s/100 iters), loss = 0.0905224
I0626 01:21:23.926933 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:21:23.926933 17260 solver.cpp:237]     Train net output #1: loss = 0.0905225 (* 1 = 0.0905225 loss)
I0626 01:21:23.926933 17260 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0626 01:21:27.769127 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:21:27.969477 17260 solver.cpp:218] Iteration 19500 (24.7584 iter/s, 4.03903s/100 iters), loss = 0.0456059
I0626 01:21:27.969477 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:21:27.969477 17260 solver.cpp:237]     Train net output #1: loss = 0.045606 (* 1 = 0.045606 loss)
I0626 01:21:27.969477 17260 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0626 01:21:32.036597 17260 solver.cpp:218] Iteration 19600 (24.5954 iter/s, 4.06579s/100 iters), loss = 0.0508938
I0626 01:21:32.036597 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:21:32.036597 17260 solver.cpp:237]     Train net output #1: loss = 0.0508939 (* 1 = 0.0508939 loss)
I0626 01:21:32.036597 17260 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0626 01:21:36.068307 17260 solver.cpp:218] Iteration 19700 (24.8066 iter/s, 4.03119s/100 iters), loss = 0.103871
I0626 01:21:36.068307 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:21:36.068307 17260 solver.cpp:237]     Train net output #1: loss = 0.103872 (* 1 = 0.103872 loss)
I0626 01:21:36.068807 17260 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0626 01:21:40.101176 17260 solver.cpp:218] Iteration 19800 (24.7992 iter/s, 4.03239s/100 iters), loss = 0.066385
I0626 01:21:40.101176 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:21:40.101176 17260 solver.cpp:237]     Train net output #1: loss = 0.066385 (* 1 = 0.066385 loss)
I0626 01:21:40.101176 17260 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0626 01:21:44.138154 17260 solver.cpp:218] Iteration 19900 (24.7717 iter/s, 4.03686s/100 iters), loss = 0.0322632
I0626 01:21:44.138154 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:21:44.138154 17260 solver.cpp:237]     Train net output #1: loss = 0.0322632 (* 1 = 0.0322632 loss)
I0626 01:21:44.138154 17260 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0626 01:21:48.005820 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:21:48.162927 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_20000.caffemodel
I0626 01:21:48.185943 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_20000.solverstate
I0626 01:21:48.245949 17260 solver.cpp:330] Iteration 20000, Testing net (#0)
I0626 01:21:48.245949 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:21:49.363842  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:21:49.407364 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8826
I0626 01:21:49.407364 17260 solver.cpp:397]     Test net output #1: loss = 0.394468 (* 1 = 0.394468 loss)
I0626 01:21:49.440541 17260 solver.cpp:218] Iteration 20000 (18.8348 iter/s, 5.30932s/100 iters), loss = 0.0682255
I0626 01:21:49.440541 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:21:49.440541 17260 solver.cpp:237]     Train net output #1: loss = 0.0682255 (* 1 = 0.0682255 loss)
I0626 01:21:49.440541 17260 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0626 01:21:53.482192 17260 solver.cpp:218] Iteration 20100 (24.7935 iter/s, 4.03332s/100 iters), loss = 0.0527236
I0626 01:21:53.482192 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:21:53.482192 17260 solver.cpp:237]     Train net output #1: loss = 0.0527237 (* 1 = 0.0527237 loss)
I0626 01:21:53.482192 17260 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0626 01:21:57.538588 17260 solver.cpp:218] Iteration 20200 (24.6553 iter/s, 4.05592s/100 iters), loss = 0.0525478
I0626 01:21:57.538588 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:21:57.538588 17260 solver.cpp:237]     Train net output #1: loss = 0.0525478 (* 1 = 0.0525478 loss)
I0626 01:21:57.538588 17260 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0626 01:22:01.556092 17260 solver.cpp:218] Iteration 20300 (24.8719 iter/s, 4.0206s/100 iters), loss = 0.0492196
I0626 01:22:01.556092 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:22:01.556092 17260 solver.cpp:237]     Train net output #1: loss = 0.0492197 (* 1 = 0.0492197 loss)
I0626 01:22:01.556092 17260 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0626 01:22:05.719290 17260 solver.cpp:218] Iteration 20400 (24.031 iter/s, 4.16129s/100 iters), loss = 0.0815244
I0626 01:22:05.719290 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:22:05.719290 17260 solver.cpp:237]     Train net output #1: loss = 0.0815245 (* 1 = 0.0815245 loss)
I0626 01:22:05.719290 17260 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0626 01:22:09.582125 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:22:09.782999 17260 solver.cpp:218] Iteration 20500 (24.6225 iter/s, 4.06133s/100 iters), loss = 0.042065
I0626 01:22:09.782999 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:22:09.782999 17260 solver.cpp:237]     Train net output #1: loss = 0.0420651 (* 1 = 0.0420651 loss)
I0626 01:22:09.782999 17260 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0626 01:22:13.838537 17260 solver.cpp:218] Iteration 20600 (24.6611 iter/s, 4.05496s/100 iters), loss = 0.0350215
I0626 01:22:13.838537 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:22:13.838537 17260 solver.cpp:237]     Train net output #1: loss = 0.0350216 (* 1 = 0.0350216 loss)
I0626 01:22:13.838537 17260 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0626 01:22:17.897476 17260 solver.cpp:218] Iteration 20700 (24.6392 iter/s, 4.05857s/100 iters), loss = 0.0559531
I0626 01:22:17.897476 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:22:17.897476 17260 solver.cpp:237]     Train net output #1: loss = 0.0559532 (* 1 = 0.0559532 loss)
I0626 01:22:17.897476 17260 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0626 01:22:21.947482 17260 solver.cpp:218] Iteration 20800 (24.6891 iter/s, 4.05038s/100 iters), loss = 0.100235
I0626 01:22:21.947482 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:22:21.947482 17260 solver.cpp:237]     Train net output #1: loss = 0.100235 (* 1 = 0.100235 loss)
I0626 01:22:21.947482 17260 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0626 01:22:25.994029 17260 solver.cpp:218] Iteration 20900 (24.6888 iter/s, 4.05042s/100 iters), loss = 0.0549081
I0626 01:22:25.994029 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:22:25.994029 17260 solver.cpp:237]     Train net output #1: loss = 0.0549081 (* 1 = 0.0549081 loss)
I0626 01:22:25.994029 17260 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0626 01:22:29.850427 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:22:30.006235 17260 solver.cpp:330] Iteration 21000, Testing net (#0)
I0626 01:22:30.006235 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:22:31.123661  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:22:31.163661 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8869
I0626 01:22:31.163661 17260 solver.cpp:397]     Test net output #1: loss = 0.391538 (* 1 = 0.391538 loss)
I0626 01:22:31.207275 17260 solver.cpp:218] Iteration 21000 (19.2018 iter/s, 5.20785s/100 iters), loss = 0.0650867
I0626 01:22:31.207275 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:22:31.207275 17260 solver.cpp:237]     Train net output #1: loss = 0.0650867 (* 1 = 0.0650867 loss)
I0626 01:22:31.207275 17260 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0626 01:22:35.269536 17260 solver.cpp:218] Iteration 21100 (24.6212 iter/s, 4.06154s/100 iters), loss = 0.0965018
I0626 01:22:35.269536 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:22:35.269536 17260 solver.cpp:237]     Train net output #1: loss = 0.0965018 (* 1 = 0.0965018 loss)
I0626 01:22:35.269536 17260 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0626 01:22:39.305073 17260 solver.cpp:218] Iteration 21200 (24.7511 iter/s, 4.04022s/100 iters), loss = 0.168122
I0626 01:22:39.305073 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:22:39.305073 17260 solver.cpp:237]     Train net output #1: loss = 0.168122 (* 1 = 0.168122 loss)
I0626 01:22:39.305073 17260 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0626 01:22:43.405568 17260 solver.cpp:218] Iteration 21300 (24.3841 iter/s, 4.10103s/100 iters), loss = 0.074205
I0626 01:22:43.405568 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:22:43.405568 17260 solver.cpp:237]     Train net output #1: loss = 0.074205 (* 1 = 0.074205 loss)
I0626 01:22:43.405568 17260 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0626 01:22:47.442363 17260 solver.cpp:218] Iteration 21400 (24.7808 iter/s, 4.03539s/100 iters), loss = 0.0334212
I0626 01:22:47.442363 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:22:47.442363 17260 solver.cpp:237]     Train net output #1: loss = 0.0334211 (* 1 = 0.0334211 loss)
I0626 01:22:47.442363 17260 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0626 01:22:51.289186 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:22:51.486655 17260 solver.cpp:218] Iteration 21500 (24.7572 iter/s, 4.03922s/100 iters), loss = 0.064472
I0626 01:22:51.486655 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:22:51.486655 17260 solver.cpp:237]     Train net output #1: loss = 0.064472 (* 1 = 0.064472 loss)
I0626 01:22:51.486655 17260 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0626 01:22:55.522239 17260 solver.cpp:218] Iteration 21600 (24.783 iter/s, 4.03503s/100 iters), loss = 0.0646738
I0626 01:22:55.522239 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:22:55.522239 17260 solver.cpp:237]     Train net output #1: loss = 0.0646739 (* 1 = 0.0646739 loss)
I0626 01:22:55.522239 17260 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0626 01:22:59.573071 17260 solver.cpp:218] Iteration 21700 (24.6629 iter/s, 4.05467s/100 iters), loss = 0.047021
I0626 01:22:59.573071 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:22:59.573071 17260 solver.cpp:237]     Train net output #1: loss = 0.047021 (* 1 = 0.047021 loss)
I0626 01:22:59.573071 17260 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0626 01:23:03.769783 17260 solver.cpp:218] Iteration 21800 (23.8362 iter/s, 4.1953s/100 iters), loss = 0.073293
I0626 01:23:03.769783 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:23:03.769783 17260 solver.cpp:237]     Train net output #1: loss = 0.073293 (* 1 = 0.073293 loss)
I0626 01:23:03.769783 17260 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0626 01:23:07.818426 17260 solver.cpp:218] Iteration 21900 (24.7162 iter/s, 4.04593s/100 iters), loss = 0.0562389
I0626 01:23:07.819417 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:23:07.819417 17260 solver.cpp:237]     Train net output #1: loss = 0.0562389 (* 1 = 0.0562389 loss)
I0626 01:23:07.819417 17260 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0626 01:23:11.664355 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:23:11.823237 17260 solver.cpp:330] Iteration 22000, Testing net (#0)
I0626 01:23:11.823237 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:23:12.942899  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:23:12.982913 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8899
I0626 01:23:12.982913 17260 solver.cpp:397]     Test net output #1: loss = 0.392834 (* 1 = 0.392834 loss)
I0626 01:23:13.023473 17260 solver.cpp:218] Iteration 22000 (19.2013 iter/s, 5.20798s/100 iters), loss = 0.0905691
I0626 01:23:13.023473 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:23:13.023473 17260 solver.cpp:237]     Train net output #1: loss = 0.0905691 (* 1 = 0.0905691 loss)
I0626 01:23:13.023473 17260 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0626 01:23:17.196280 17260 solver.cpp:218] Iteration 22100 (23.9442 iter/s, 4.17638s/100 iters), loss = 0.130287
I0626 01:23:17.196280 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:23:17.196280 17260 solver.cpp:237]     Train net output #1: loss = 0.130287 (* 1 = 0.130287 loss)
I0626 01:23:17.196280 17260 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0626 01:23:21.249150 17260 solver.cpp:218] Iteration 22200 (24.689 iter/s, 4.05039s/100 iters), loss = 0.0930349
I0626 01:23:21.249150 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:23:21.249150 17260 solver.cpp:237]     Train net output #1: loss = 0.0930349 (* 1 = 0.0930349 loss)
I0626 01:23:21.249150 17260 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0626 01:23:25.292225 17260 solver.cpp:218] Iteration 22300 (24.7685 iter/s, 4.03739s/100 iters), loss = 0.120052
I0626 01:23:25.292225 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:23:25.293226 17260 solver.cpp:237]     Train net output #1: loss = 0.120052 (* 1 = 0.120052 loss)
I0626 01:23:25.293226 17260 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0626 01:23:29.320086 17260 solver.cpp:218] Iteration 22400 (24.7845 iter/s, 4.03479s/100 iters), loss = 0.100958
I0626 01:23:29.320086 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:23:29.320086 17260 solver.cpp:237]     Train net output #1: loss = 0.100958 (* 1 = 0.100958 loss)
I0626 01:23:29.320086 17260 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0626 01:23:33.202610 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:23:33.402678 17260 solver.cpp:218] Iteration 22500 (24.5339 iter/s, 4.07599s/100 iters), loss = 0.114441
I0626 01:23:33.402678 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:23:33.402678 17260 solver.cpp:237]     Train net output #1: loss = 0.114441 (* 1 = 0.114441 loss)
I0626 01:23:33.402678 17260 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0626 01:23:37.444443 17260 solver.cpp:218] Iteration 22600 (24.7129 iter/s, 4.04646s/100 iters), loss = 0.0469554
I0626 01:23:37.444443 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:23:37.444443 17260 solver.cpp:237]     Train net output #1: loss = 0.0469555 (* 1 = 0.0469555 loss)
I0626 01:23:37.444443 17260 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0626 01:23:41.496075 17260 solver.cpp:218] Iteration 22700 (24.7287 iter/s, 4.04388s/100 iters), loss = 0.0561432
I0626 01:23:41.496075 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:23:41.496075 17260 solver.cpp:237]     Train net output #1: loss = 0.0561432 (* 1 = 0.0561432 loss)
I0626 01:23:41.496075 17260 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0626 01:23:45.538621 17260 solver.cpp:218] Iteration 22800 (24.7247 iter/s, 4.04454s/100 iters), loss = 0.0727746
I0626 01:23:45.538621 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:23:45.538621 17260 solver.cpp:237]     Train net output #1: loss = 0.0727747 (* 1 = 0.0727747 loss)
I0626 01:23:45.538621 17260 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0626 01:23:49.572633 17260 solver.cpp:218] Iteration 22900 (24.768 iter/s, 4.03746s/100 iters), loss = 0.0385008
I0626 01:23:49.572633 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:23:49.572633 17260 solver.cpp:237]     Train net output #1: loss = 0.0385008 (* 1 = 0.0385008 loss)
I0626 01:23:49.572633 17260 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0626 01:23:53.424391 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:23:53.595501 17260 solver.cpp:330] Iteration 23000, Testing net (#0)
I0626 01:23:53.596002 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:23:54.705129  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:23:54.745136 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8901
I0626 01:23:54.745136 17260 solver.cpp:397]     Test net output #1: loss = 0.389892 (* 1 = 0.389892 loss)
I0626 01:23:54.789289 17260 solver.cpp:218] Iteration 23000 (19.1949 iter/s, 5.20973s/100 iters), loss = 0.0617542
I0626 01:23:54.789289 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:23:54.789289 17260 solver.cpp:237]     Train net output #1: loss = 0.0617542 (* 1 = 0.0617542 loss)
I0626 01:23:54.789289 17260 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0626 01:23:58.863839 17260 solver.cpp:218] Iteration 23100 (24.5133 iter/s, 4.07943s/100 iters), loss = 0.0841866
I0626 01:23:58.863839 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:23:58.863839 17260 solver.cpp:237]     Train net output #1: loss = 0.0841866 (* 1 = 0.0841866 loss)
I0626 01:23:58.863839 17260 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0626 01:24:02.895094 17260 solver.cpp:218] Iteration 23200 (24.7865 iter/s, 4.03445s/100 iters), loss = 0.0663662
I0626 01:24:02.895094 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:24:02.895094 17260 solver.cpp:237]     Train net output #1: loss = 0.0663662 (* 1 = 0.0663662 loss)
I0626 01:24:02.895094 17260 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0626 01:24:06.913708 17260 solver.cpp:218] Iteration 23300 (24.9224 iter/s, 4.01245s/100 iters), loss = 0.113047
I0626 01:24:06.913708 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:24:06.913708 17260 solver.cpp:237]     Train net output #1: loss = 0.113047 (* 1 = 0.113047 loss)
I0626 01:24:06.913708 17260 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0626 01:24:10.956055 17260 solver.cpp:218] Iteration 23400 (24.7227 iter/s, 4.04486s/100 iters), loss = 0.0506229
I0626 01:24:10.956055 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:24:10.956055 17260 solver.cpp:237]     Train net output #1: loss = 0.0506229 (* 1 = 0.0506229 loss)
I0626 01:24:10.956055 17260 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0626 01:24:14.837139 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:24:15.027793 17260 solver.cpp:218] Iteration 23500 (24.5659 iter/s, 4.07069s/100 iters), loss = 0.0577466
I0626 01:24:15.027793 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:24:15.027793 17260 solver.cpp:237]     Train net output #1: loss = 0.0577466 (* 1 = 0.0577466 loss)
I0626 01:24:15.027793 17260 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0626 01:24:19.138052 17260 solver.cpp:218] Iteration 23600 (24.3643 iter/s, 4.10436s/100 iters), loss = 0.104969
I0626 01:24:19.138052 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:24:19.138052 17260 solver.cpp:237]     Train net output #1: loss = 0.104969 (* 1 = 0.104969 loss)
I0626 01:24:19.138052 17260 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0626 01:24:23.368253 17260 solver.cpp:218] Iteration 23700 (23.6186 iter/s, 4.23394s/100 iters), loss = 0.08979
I0626 01:24:23.368253 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:24:23.368253 17260 solver.cpp:237]     Train net output #1: loss = 0.08979 (* 1 = 0.08979 loss)
I0626 01:24:23.368253 17260 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0626 01:24:27.470922 17260 solver.cpp:218] Iteration 23800 (24.3898 iter/s, 4.10008s/100 iters), loss = 0.0985796
I0626 01:24:27.470922 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:24:27.470922 17260 solver.cpp:237]     Train net output #1: loss = 0.0985796 (* 1 = 0.0985796 loss)
I0626 01:24:27.470922 17260 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0626 01:24:31.548223 17260 solver.cpp:218] Iteration 23900 (24.4878 iter/s, 4.08367s/100 iters), loss = 0.0292809
I0626 01:24:31.548223 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:24:31.548223 17260 solver.cpp:237]     Train net output #1: loss = 0.029281 (* 1 = 0.029281 loss)
I0626 01:24:31.548223 17260 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0626 01:24:35.436120 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:24:35.599046 17260 solver.cpp:330] Iteration 24000, Testing net (#0)
I0626 01:24:35.599046 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:24:36.727975  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:24:36.770998 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8868
I0626 01:24:36.770998 17260 solver.cpp:397]     Test net output #1: loss = 0.400028 (* 1 = 0.400028 loss)
I0626 01:24:36.806505 17260 solver.cpp:218] Iteration 24000 (19.0361 iter/s, 5.25318s/100 iters), loss = 0.0547284
I0626 01:24:36.806505 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:24:36.806505 17260 solver.cpp:237]     Train net output #1: loss = 0.0547284 (* 1 = 0.0547284 loss)
I0626 01:24:36.806505 17260 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0626 01:24:40.845448 17260 solver.cpp:218] Iteration 24100 (24.7882 iter/s, 4.03418s/100 iters), loss = 0.0483245
I0626 01:24:40.845448 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:24:40.845448 17260 solver.cpp:237]     Train net output #1: loss = 0.0483245 (* 1 = 0.0483245 loss)
I0626 01:24:40.845448 17260 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0626 01:24:44.881738 17260 solver.cpp:218] Iteration 24200 (24.7565 iter/s, 4.03934s/100 iters), loss = 0.142696
I0626 01:24:44.881738 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:24:44.881738 17260 solver.cpp:237]     Train net output #1: loss = 0.142696 (* 1 = 0.142696 loss)
I0626 01:24:44.881738 17260 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0626 01:24:48.903813 17260 solver.cpp:218] Iteration 24300 (24.8288 iter/s, 4.02757s/100 iters), loss = 0.103477
I0626 01:24:48.903813 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:24:48.903813 17260 solver.cpp:237]     Train net output #1: loss = 0.103477 (* 1 = 0.103477 loss)
I0626 01:24:48.903813 17260 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0626 01:24:52.946807 17260 solver.cpp:218] Iteration 24400 (24.7939 iter/s, 4.03325s/100 iters), loss = 0.0665273
I0626 01:24:52.946807 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:24:52.946807 17260 solver.cpp:237]     Train net output #1: loss = 0.0665274 (* 1 = 0.0665274 loss)
I0626 01:24:52.946807 17260 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0626 01:24:56.791939 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:24:56.986986 17260 solver.cpp:218] Iteration 24500 (24.7412 iter/s, 4.04184s/100 iters), loss = 0.0502216
I0626 01:24:56.986986 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:24:56.986986 17260 solver.cpp:237]     Train net output #1: loss = 0.0502216 (* 1 = 0.0502216 loss)
I0626 01:24:56.986986 17260 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0626 01:25:01.066973 17260 solver.cpp:218] Iteration 24600 (24.5244 iter/s, 4.07758s/100 iters), loss = 0.0511527
I0626 01:25:01.067473 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:25:01.067473 17260 solver.cpp:237]     Train net output #1: loss = 0.0511527 (* 1 = 0.0511527 loss)
I0626 01:25:01.067473 17260 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0626 01:25:05.144335 17260 solver.cpp:218] Iteration 24700 (24.5293 iter/s, 4.07675s/100 iters), loss = 0.0898808
I0626 01:25:05.144335 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:25:05.144335 17260 solver.cpp:237]     Train net output #1: loss = 0.0898808 (* 1 = 0.0898808 loss)
I0626 01:25:05.144335 17260 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0626 01:25:09.255875 17260 solver.cpp:218] Iteration 24800 (24.3217 iter/s, 4.11156s/100 iters), loss = 0.108408
I0626 01:25:09.255875 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:25:09.255875 17260 solver.cpp:237]     Train net output #1: loss = 0.108408 (* 1 = 0.108408 loss)
I0626 01:25:09.255875 17260 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0626 01:25:13.404693 17260 solver.cpp:218] Iteration 24900 (24.1042 iter/s, 4.14865s/100 iters), loss = 0.0445939
I0626 01:25:13.404693 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:25:13.404693 17260 solver.cpp:237]     Train net output #1: loss = 0.0445939 (* 1 = 0.0445939 loss)
I0626 01:25:13.404693 17260 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0626 01:25:17.308513 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:25:17.470340 17260 solver.cpp:330] Iteration 25000, Testing net (#0)
I0626 01:25:17.471324 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:25:18.600842  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:25:18.643935 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8944
I0626 01:25:18.643935 17260 solver.cpp:397]     Test net output #1: loss = 0.370326 (* 1 = 0.370326 loss)
I0626 01:25:18.684980 17260 solver.cpp:218] Iteration 25000 (18.9432 iter/s, 5.27893s/100 iters), loss = 0.0723146
I0626 01:25:18.684980 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:25:18.684980 17260 solver.cpp:237]     Train net output #1: loss = 0.0723146 (* 1 = 0.0723146 loss)
I0626 01:25:18.684980 17260 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0626 01:25:22.724201 17260 solver.cpp:218] Iteration 25100 (24.7013 iter/s, 4.04837s/100 iters), loss = 0.11148
I0626 01:25:22.724201 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:25:22.724201 17260 solver.cpp:237]     Train net output #1: loss = 0.11148 (* 1 = 0.11148 loss)
I0626 01:25:22.724201 17260 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0626 01:25:26.769142 17260 solver.cpp:218] Iteration 25200 (24.7799 iter/s, 4.03554s/100 iters), loss = 0.0946516
I0626 01:25:26.769142 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:25:26.769142 17260 solver.cpp:237]     Train net output #1: loss = 0.0946516 (* 1 = 0.0946516 loss)
I0626 01:25:26.769142 17260 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0626 01:25:30.795163 17260 solver.cpp:218] Iteration 25300 (24.7897 iter/s, 4.03393s/100 iters), loss = 0.120452
I0626 01:25:30.795163 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.94
I0626 01:25:30.795163 17260 solver.cpp:237]     Train net output #1: loss = 0.120452 (* 1 = 0.120452 loss)
I0626 01:25:30.795163 17260 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0626 01:25:34.843154 17260 solver.cpp:218] Iteration 25400 (24.7585 iter/s, 4.03901s/100 iters), loss = 0.0812126
I0626 01:25:34.843154 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:25:34.843154 17260 solver.cpp:237]     Train net output #1: loss = 0.0812126 (* 1 = 0.0812126 loss)
I0626 01:25:34.843154 17260 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0626 01:25:38.674926 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:25:38.875527 17260 solver.cpp:218] Iteration 25500 (24.745 iter/s, 4.04122s/100 iters), loss = 0.081279
I0626 01:25:38.875527 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:25:38.875527 17260 solver.cpp:237]     Train net output #1: loss = 0.081279 (* 1 = 0.081279 loss)
I0626 01:25:38.875527 17260 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0626 01:25:42.917213 17260 solver.cpp:218] Iteration 25600 (24.8048 iter/s, 4.03148s/100 iters), loss = 0.122091
I0626 01:25:42.917213 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:25:42.917213 17260 solver.cpp:237]     Train net output #1: loss = 0.122091 (* 1 = 0.122091 loss)
I0626 01:25:42.917213 17260 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0626 01:25:46.969480 17260 solver.cpp:218] Iteration 25700 (24.6792 iter/s, 4.052s/100 iters), loss = 0.0472441
I0626 01:25:46.969480 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:25:46.969480 17260 solver.cpp:237]     Train net output #1: loss = 0.0472441 (* 1 = 0.0472441 loss)
I0626 01:25:46.969480 17260 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0626 01:25:51.013294 17260 solver.cpp:218] Iteration 25800 (24.7105 iter/s, 4.04686s/100 iters), loss = 0.0492804
I0626 01:25:51.013294 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:25:51.013294 17260 solver.cpp:237]     Train net output #1: loss = 0.0492804 (* 1 = 0.0492804 loss)
I0626 01:25:51.013294 17260 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0626 01:25:55.047263 17260 solver.cpp:218] Iteration 25900 (24.7889 iter/s, 4.03407s/100 iters), loss = 0.0370575
I0626 01:25:55.047263 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:25:55.047263 17260 solver.cpp:237]     Train net output #1: loss = 0.0370575 (* 1 = 0.0370575 loss)
I0626 01:25:55.047263 17260 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0626 01:25:58.899034 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:25:59.060675 17260 solver.cpp:330] Iteration 26000, Testing net (#0)
I0626 01:25:59.060675 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:26:00.179716  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:26:00.219718 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8974
I0626 01:26:00.219718 17260 solver.cpp:397]     Test net output #1: loss = 0.38505 (* 1 = 0.38505 loss)
I0626 01:26:00.251734 17260 solver.cpp:218] Iteration 26000 (19.1983 iter/s, 5.20879s/100 iters), loss = 0.12775
I0626 01:26:00.251734 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:26:00.251734 17260 solver.cpp:237]     Train net output #1: loss = 0.12775 (* 1 = 0.12775 loss)
I0626 01:26:00.251734 17260 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0626 01:26:04.295037 17260 solver.cpp:218] Iteration 26100 (24.7837 iter/s, 4.03491s/100 iters), loss = 0.0739038
I0626 01:26:04.295037 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:26:04.295037 17260 solver.cpp:237]     Train net output #1: loss = 0.0739038 (* 1 = 0.0739038 loss)
I0626 01:26:04.295037 17260 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0626 01:26:08.338652 17260 solver.cpp:218] Iteration 26200 (24.7352 iter/s, 4.04283s/100 iters), loss = 0.0440974
I0626 01:26:08.338652 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:26:08.338652 17260 solver.cpp:237]     Train net output #1: loss = 0.0440974 (* 1 = 0.0440974 loss)
I0626 01:26:08.338652 17260 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0626 01:26:12.389118 17260 solver.cpp:218] Iteration 26300 (24.6841 iter/s, 4.05119s/100 iters), loss = 0.0574524
I0626 01:26:12.389118 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:26:12.389118 17260 solver.cpp:237]     Train net output #1: loss = 0.0574523 (* 1 = 0.0574523 loss)
I0626 01:26:12.389118 17260 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0626 01:26:16.415047 17260 solver.cpp:218] Iteration 26400 (24.8032 iter/s, 4.03173s/100 iters), loss = 0.0680917
I0626 01:26:16.415047 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:26:16.415047 17260 solver.cpp:237]     Train net output #1: loss = 0.0680917 (* 1 = 0.0680917 loss)
I0626 01:26:16.415047 17260 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0626 01:26:20.265041 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:26:20.464964 17260 solver.cpp:218] Iteration 26500 (24.7012 iter/s, 4.04838s/100 iters), loss = 0.035668
I0626 01:26:20.464964 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:26:20.464964 17260 solver.cpp:237]     Train net output #1: loss = 0.0356679 (* 1 = 0.0356679 loss)
I0626 01:26:20.464964 17260 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0626 01:26:24.526263 17260 solver.cpp:218] Iteration 26600 (24.6443 iter/s, 4.05773s/100 iters), loss = 0.0774568
I0626 01:26:24.526263 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:26:24.526263 17260 solver.cpp:237]     Train net output #1: loss = 0.0774568 (* 1 = 0.0774568 loss)
I0626 01:26:24.526263 17260 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0626 01:26:28.570485 17260 solver.cpp:218] Iteration 26700 (24.7286 iter/s, 4.04389s/100 iters), loss = 0.0680708
I0626 01:26:28.570485 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:26:28.570485 17260 solver.cpp:237]     Train net output #1: loss = 0.0680707 (* 1 = 0.0680707 loss)
I0626 01:26:28.570485 17260 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0626 01:26:32.604449 17260 solver.cpp:218] Iteration 26800 (24.7861 iter/s, 4.03452s/100 iters), loss = 0.0807534
I0626 01:26:32.604449 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:26:32.604449 17260 solver.cpp:237]     Train net output #1: loss = 0.0807534 (* 1 = 0.0807534 loss)
I0626 01:26:32.604449 17260 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0626 01:26:36.644335 17260 solver.cpp:218] Iteration 26900 (24.7223 iter/s, 4.04494s/100 iters), loss = 0.0350977
I0626 01:26:36.644335 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:26:36.644335 17260 solver.cpp:237]     Train net output #1: loss = 0.0350977 (* 1 = 0.0350977 loss)
I0626 01:26:36.644335 17260 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0626 01:26:40.493280 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:26:40.661711 17260 solver.cpp:330] Iteration 27000, Testing net (#0)
I0626 01:26:40.662210 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:26:41.792897  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:26:41.834913 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8948
I0626 01:26:41.834913 17260 solver.cpp:397]     Test net output #1: loss = 0.379602 (* 1 = 0.379602 loss)
I0626 01:26:41.873945 17260 solver.cpp:218] Iteration 27000 (19.1586 iter/s, 5.21958s/100 iters), loss = 0.0311654
I0626 01:26:41.873945 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:26:41.873945 17260 solver.cpp:237]     Train net output #1: loss = 0.0311653 (* 1 = 0.0311653 loss)
I0626 01:26:41.873945 17260 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0626 01:26:45.973345 17260 solver.cpp:218] Iteration 27100 (24.3941 iter/s, 4.09935s/100 iters), loss = 0.0403576
I0626 01:26:45.973845 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:26:45.973845 17260 solver.cpp:237]     Train net output #1: loss = 0.0403575 (* 1 = 0.0403575 loss)
I0626 01:26:45.973845 17260 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0626 01:26:50.017945 17260 solver.cpp:218] Iteration 27200 (24.7259 iter/s, 4.04434s/100 iters), loss = 0.0761261
I0626 01:26:50.017945 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:26:50.017945 17260 solver.cpp:237]     Train net output #1: loss = 0.0761261 (* 1 = 0.0761261 loss)
I0626 01:26:50.017945 17260 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0626 01:26:54.051168 17260 solver.cpp:218] Iteration 27300 (24.7979 iter/s, 4.0326s/100 iters), loss = 0.0390789
I0626 01:26:54.051669 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:26:54.051669 17260 solver.cpp:237]     Train net output #1: loss = 0.0390789 (* 1 = 0.0390789 loss)
I0626 01:26:54.051669 17260 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0626 01:26:58.074755 17260 solver.cpp:218] Iteration 27400 (24.8126 iter/s, 4.0302s/100 iters), loss = 0.0332725
I0626 01:26:58.074755 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:26:58.074755 17260 solver.cpp:237]     Train net output #1: loss = 0.0332724 (* 1 = 0.0332724 loss)
I0626 01:26:58.074755 17260 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0626 01:27:01.917613 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:27:02.114400 17260 solver.cpp:218] Iteration 27500 (24.7446 iter/s, 4.04128s/100 iters), loss = 0.0920673
I0626 01:27:02.114400 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:27:02.114400 17260 solver.cpp:237]     Train net output #1: loss = 0.0920672 (* 1 = 0.0920672 loss)
I0626 01:27:02.114400 17260 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0626 01:27:06.155124 17260 solver.cpp:218] Iteration 27600 (24.7477 iter/s, 4.04077s/100 iters), loss = 0.0503191
I0626 01:27:06.155124 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:27:06.155124 17260 solver.cpp:237]     Train net output #1: loss = 0.0503191 (* 1 = 0.0503191 loss)
I0626 01:27:06.155124 17260 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0626 01:27:10.200387 17260 solver.cpp:218] Iteration 27700 (24.7724 iter/s, 4.03674s/100 iters), loss = 0.0724301
I0626 01:27:10.200387 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:27:10.200387 17260 solver.cpp:237]     Train net output #1: loss = 0.0724301 (* 1 = 0.0724301 loss)
I0626 01:27:10.200387 17260 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0626 01:27:14.232306 17260 solver.cpp:218] Iteration 27800 (24.7775 iter/s, 4.03592s/100 iters), loss = 0.0553933
I0626 01:27:14.232306 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:27:14.232306 17260 solver.cpp:237]     Train net output #1: loss = 0.0553933 (* 1 = 0.0553933 loss)
I0626 01:27:14.232306 17260 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0626 01:27:18.275395 17260 solver.cpp:218] Iteration 27900 (24.7721 iter/s, 4.03679s/100 iters), loss = 0.0285327
I0626 01:27:18.275395 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:27:18.275395 17260 solver.cpp:237]     Train net output #1: loss = 0.0285326 (* 1 = 0.0285326 loss)
I0626 01:27:18.275395 17260 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0626 01:27:22.105016 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:27:22.266158 17260 solver.cpp:330] Iteration 28000, Testing net (#0)
I0626 01:27:22.266158 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:27:23.387246  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:27:23.427770 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8923
I0626 01:27:23.427770 17260 solver.cpp:397]     Test net output #1: loss = 0.389164 (* 1 = 0.389164 loss)
I0626 01:27:23.467761 17260 solver.cpp:218] Iteration 28000 (19.2621 iter/s, 5.19155s/100 iters), loss = 0.0931247
I0626 01:27:23.467761 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:27:23.467761 17260 solver.cpp:237]     Train net output #1: loss = 0.0931247 (* 1 = 0.0931247 loss)
I0626 01:27:23.467761 17260 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0626 01:27:27.500875 17260 solver.cpp:218] Iteration 28100 (24.7981 iter/s, 4.03257s/100 iters), loss = 0.0472293
I0626 01:27:27.500875 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:27:27.500875 17260 solver.cpp:237]     Train net output #1: loss = 0.0472293 (* 1 = 0.0472293 loss)
I0626 01:27:27.500875 17260 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0626 01:27:31.548068 17260 solver.cpp:218] Iteration 28200 (24.7094 iter/s, 4.04705s/100 iters), loss = 0.0655324
I0626 01:27:31.548068 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:27:31.548068 17260 solver.cpp:237]     Train net output #1: loss = 0.0655323 (* 1 = 0.0655323 loss)
I0626 01:27:31.548068 17260 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0626 01:27:35.604467 17260 solver.cpp:218] Iteration 28300 (24.6563 iter/s, 4.05576s/100 iters), loss = 0.121051
I0626 01:27:35.604467 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:27:35.604467 17260 solver.cpp:237]     Train net output #1: loss = 0.121051 (* 1 = 0.121051 loss)
I0626 01:27:35.604467 17260 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0626 01:27:39.658069 17260 solver.cpp:218] Iteration 28400 (24.6601 iter/s, 4.05514s/100 iters), loss = 0.0645387
I0626 01:27:39.658069 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:27:39.658069 17260 solver.cpp:237]     Train net output #1: loss = 0.0645386 (* 1 = 0.0645386 loss)
I0626 01:27:39.658069 17260 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0626 01:27:43.532176 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:27:43.731319 17260 solver.cpp:218] Iteration 28500 (24.5344 iter/s, 4.07591s/100 iters), loss = 0.0353302
I0626 01:27:43.731319 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:27:43.731319 17260 solver.cpp:237]     Train net output #1: loss = 0.0353302 (* 1 = 0.0353302 loss)
I0626 01:27:43.731319 17260 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0626 01:27:47.824256 17260 solver.cpp:218] Iteration 28600 (24.4454 iter/s, 4.09075s/100 iters), loss = 0.0668291
I0626 01:27:47.824256 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:27:47.824256 17260 solver.cpp:237]     Train net output #1: loss = 0.066829 (* 1 = 0.066829 loss)
I0626 01:27:47.824256 17260 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0626 01:27:51.878064 17260 solver.cpp:218] Iteration 28700 (24.6708 iter/s, 4.05337s/100 iters), loss = 0.0751754
I0626 01:27:51.878064 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:27:51.878064 17260 solver.cpp:237]     Train net output #1: loss = 0.0751753 (* 1 = 0.0751753 loss)
I0626 01:27:51.878064 17260 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0626 01:27:55.941396 17260 solver.cpp:218] Iteration 28800 (24.6131 iter/s, 4.06288s/100 iters), loss = 0.0850776
I0626 01:27:55.941396 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:27:55.941396 17260 solver.cpp:237]     Train net output #1: loss = 0.0850776 (* 1 = 0.0850776 loss)
I0626 01:27:55.941396 17260 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0626 01:27:59.984601 17260 solver.cpp:218] Iteration 28900 (24.7464 iter/s, 4.04099s/100 iters), loss = 0.0870219
I0626 01:27:59.984601 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:27:59.984601 17260 solver.cpp:237]     Train net output #1: loss = 0.0870218 (* 1 = 0.0870218 loss)
I0626 01:27:59.984601 17260 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0626 01:28:03.827632 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:28:03.988111 17260 solver.cpp:330] Iteration 29000, Testing net (#0)
I0626 01:28:03.988111 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:28:05.104518  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:28:05.148535 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8824
I0626 01:28:05.148535 17260 solver.cpp:397]     Test net output #1: loss = 0.432446 (* 1 = 0.432446 loss)
I0626 01:28:05.188539 17260 solver.cpp:218] Iteration 29000 (19.195 iter/s, 5.20968s/100 iters), loss = 0.104376
I0626 01:28:05.188539 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:28:05.188539 17260 solver.cpp:237]     Train net output #1: loss = 0.104376 (* 1 = 0.104376 loss)
I0626 01:28:05.188539 17260 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0626 01:28:09.375531 17260 solver.cpp:218] Iteration 29100 (23.8991 iter/s, 4.18426s/100 iters), loss = 0.0591135
I0626 01:28:09.375531 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:28:09.375531 17260 solver.cpp:237]     Train net output #1: loss = 0.0591134 (* 1 = 0.0591134 loss)
I0626 01:28:09.375531 17260 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0626 01:28:13.463115 17260 solver.cpp:218] Iteration 29200 (24.4641 iter/s, 4.08762s/100 iters), loss = 0.116221
I0626 01:28:13.463115 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.95
I0626 01:28:13.463115 17260 solver.cpp:237]     Train net output #1: loss = 0.11622 (* 1 = 0.11622 loss)
I0626 01:28:13.463115 17260 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0626 01:28:17.779381 17260 solver.cpp:218] Iteration 29300 (23.2007 iter/s, 4.31021s/100 iters), loss = 0.112675
I0626 01:28:17.779381 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:28:17.779381 17260 solver.cpp:237]     Train net output #1: loss = 0.112675 (* 1 = 0.112675 loss)
I0626 01:28:17.779381 17260 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0626 01:28:22.134697 17260 solver.cpp:218] Iteration 29400 (22.9165 iter/s, 4.36366s/100 iters), loss = 0.0434906
I0626 01:28:22.134697 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:28:22.134697 17260 solver.cpp:237]     Train net output #1: loss = 0.0434905 (* 1 = 0.0434905 loss)
I0626 01:28:22.134697 17260 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0626 01:28:25.990721 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:28:26.190953 17260 solver.cpp:218] Iteration 29500 (24.7114 iter/s, 4.04671s/100 iters), loss = 0.0635514
I0626 01:28:26.190953 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:28:26.190953 17260 solver.cpp:237]     Train net output #1: loss = 0.0635513 (* 1 = 0.0635513 loss)
I0626 01:28:26.190953 17260 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0626 01:28:30.351346 17260 solver.cpp:218] Iteration 29600 (24.035 iter/s, 4.1606s/100 iters), loss = 0.0565379
I0626 01:28:30.351346 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:28:30.351346 17260 solver.cpp:237]     Train net output #1: loss = 0.0565378 (* 1 = 0.0565378 loss)
I0626 01:28:30.351346 17260 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0626 01:28:34.434166 17260 solver.cpp:218] Iteration 29700 (24.499 iter/s, 4.08179s/100 iters), loss = 0.0899023
I0626 01:28:34.434166 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:28:34.434166 17260 solver.cpp:237]     Train net output #1: loss = 0.0899021 (* 1 = 0.0899021 loss)
I0626 01:28:34.434166 17260 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0626 01:28:38.999116 17260 solver.cpp:218] Iteration 29800 (21.9131 iter/s, 4.56347s/100 iters), loss = 0.0918062
I0626 01:28:38.999116 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:28:38.999116 17260 solver.cpp:237]     Train net output #1: loss = 0.091806 (* 1 = 0.091806 loss)
I0626 01:28:38.999116 17260 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0626 01:28:43.386034 17260 solver.cpp:218] Iteration 29900 (22.7968 iter/s, 4.38659s/100 iters), loss = 0.0727394
I0626 01:28:43.386534 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:28:43.386534 17260 solver.cpp:237]     Train net output #1: loss = 0.0727393 (* 1 = 0.0727393 loss)
I0626 01:28:43.386534 17260 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0626 01:28:47.736533 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:28:47.940155 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_30000.caffemodel
I0626 01:28:48.074894 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_30000.solverstate
I0626 01:28:48.104915 17260 solver.cpp:330] Iteration 30000, Testing net (#0)
I0626 01:28:48.104915 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:28:48.258528 17260 blocking_queue.cpp:49] Waiting for data
I0626 01:28:49.542306  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:28:49.572309 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8959
I0626 01:28:49.572309 17260 solver.cpp:397]     Test net output #1: loss = 0.38787 (* 1 = 0.38787 loss)
I0626 01:28:49.621810 17260 solver.cpp:218] Iteration 30000 (16.0391 iter/s, 6.23476s/100 iters), loss = 0.0681409
I0626 01:28:49.621810 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:28:49.621810 17260 solver.cpp:237]     Train net output #1: loss = 0.0681408 (* 1 = 0.0681408 loss)
I0626 01:28:49.621810 17260 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0626 01:28:54.033388 17260 solver.cpp:218] Iteration 30100 (22.6707 iter/s, 4.41098s/100 iters), loss = 0.0809318
I0626 01:28:54.033388 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:28:54.033388 17260 solver.cpp:237]     Train net output #1: loss = 0.0809316 (* 1 = 0.0809316 loss)
I0626 01:28:54.033388 17260 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0626 01:28:58.440271 17260 solver.cpp:218] Iteration 30200 (22.6962 iter/s, 4.40603s/100 iters), loss = 0.0722705
I0626 01:28:58.440271 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:28:58.440271 17260 solver.cpp:237]     Train net output #1: loss = 0.0722704 (* 1 = 0.0722704 loss)
I0626 01:28:58.440271 17260 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0626 01:29:02.919113 17260 solver.cpp:218] Iteration 30300 (22.3785 iter/s, 4.46857s/100 iters), loss = 0.0865751
I0626 01:29:02.919113 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:29:02.919615 17260 solver.cpp:237]     Train net output #1: loss = 0.086575 (* 1 = 0.086575 loss)
I0626 01:29:02.919615 17260 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0626 01:29:07.377470 17260 solver.cpp:218] Iteration 30400 (22.4873 iter/s, 4.44696s/100 iters), loss = 0.0404572
I0626 01:29:07.377470 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:29:07.377470 17260 solver.cpp:237]     Train net output #1: loss = 0.040457 (* 1 = 0.040457 loss)
I0626 01:29:07.377470 17260 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0626 01:29:12.946154 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:29:13.207875 17260 solver.cpp:218] Iteration 30500 (17.189 iter/s, 5.81767s/100 iters), loss = 0.0517772
I0626 01:29:13.207875 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:29:13.207875 17260 solver.cpp:237]     Train net output #1: loss = 0.051777 (* 1 = 0.051777 loss)
I0626 01:29:13.207875 17260 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0626 01:29:18.546305 17260 solver.cpp:218] Iteration 30600 (18.8257 iter/s, 5.31189s/100 iters), loss = 0.0320276
I0626 01:29:18.546807 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:29:18.546807 17260 solver.cpp:237]     Train net output #1: loss = 0.0320275 (* 1 = 0.0320275 loss)
I0626 01:29:18.546807 17260 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0626 01:29:22.955816 17260 solver.cpp:218] Iteration 30700 (22.6884 iter/s, 4.40754s/100 iters), loss = 0.115365
I0626 01:29:22.959319 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:29:22.959319 17260 solver.cpp:237]     Train net output #1: loss = 0.115365 (* 1 = 0.115365 loss)
I0626 01:29:22.959319 17260 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0626 01:29:27.368301 17260 solver.cpp:218] Iteration 30800 (22.6953 iter/s, 4.4062s/100 iters), loss = 0.0848134
I0626 01:29:27.368803 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:29:27.368803 17260 solver.cpp:237]     Train net output #1: loss = 0.0848132 (* 1 = 0.0848132 loss)
I0626 01:29:27.368803 17260 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0626 01:29:31.766257 17260 solver.cpp:218] Iteration 30900 (22.7433 iter/s, 4.3969s/100 iters), loss = 0.0348694
I0626 01:29:31.766257 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:29:31.766257 17260 solver.cpp:237]     Train net output #1: loss = 0.0348692 (* 1 = 0.0348692 loss)
I0626 01:29:31.766257 17260 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0626 01:29:35.978469 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:29:36.117069 17260 solver.cpp:330] Iteration 31000, Testing net (#0)
I0626 01:29:36.117069 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:29:37.544083  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:29:37.563097 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8945
I0626 01:29:37.563097 17260 solver.cpp:397]     Test net output #1: loss = 0.387882 (* 1 = 0.387882 loss)
I0626 01:29:37.601124 17260 solver.cpp:218] Iteration 31000 (17.1399 iter/s, 5.83434s/100 iters), loss = 0.0672743
I0626 01:29:37.601124 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:29:37.601124 17260 solver.cpp:237]     Train net output #1: loss = 0.0672741 (* 1 = 0.0672741 loss)
I0626 01:29:37.601124 17260 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0626 01:29:41.951139 17260 solver.cpp:218] Iteration 31100 (23.0246 iter/s, 4.34318s/100 iters), loss = 0.0319791
I0626 01:29:41.951139 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:29:41.951139 17260 solver.cpp:237]     Train net output #1: loss = 0.031979 (* 1 = 0.031979 loss)
I0626 01:29:41.951139 17260 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0626 01:29:46.432886 17260 solver.cpp:218] Iteration 31200 (22.3147 iter/s, 4.48135s/100 iters), loss = 0.125116
I0626 01:29:46.433387 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.96
I0626 01:29:46.433387 17260 solver.cpp:237]     Train net output #1: loss = 0.125116 (* 1 = 0.125116 loss)
I0626 01:29:46.433387 17260 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0626 01:29:52.556709 17260 solver.cpp:218] Iteration 31300 (16.3322 iter/s, 6.12289s/100 iters), loss = 0.0455163
I0626 01:29:52.556709 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:29:52.556709 17260 solver.cpp:237]     Train net output #1: loss = 0.0455161 (* 1 = 0.0455161 loss)
I0626 01:29:52.556709 17260 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0626 01:29:58.681658 17260 solver.cpp:218] Iteration 31400 (16.3271 iter/s, 6.12478s/100 iters), loss = 0.0615894
I0626 01:29:58.681658 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:29:58.681658 17260 solver.cpp:237]     Train net output #1: loss = 0.0615892 (* 1 = 0.0615892 loss)
I0626 01:29:58.681658 17260 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0626 01:30:04.477645 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:30:04.867422 17260 solver.cpp:218] Iteration 31500 (16.2198 iter/s, 6.1653s/100 iters), loss = 0.0741095
I0626 01:30:04.867422 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:30:04.867422 17260 solver.cpp:237]     Train net output #1: loss = 0.0741094 (* 1 = 0.0741094 loss)
I0626 01:30:04.867422 17260 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0626 01:30:10.705883 17260 solver.cpp:218] Iteration 31600 (17.1413 iter/s, 5.83386s/100 iters), loss = 0.0512873
I0626 01:30:10.705883 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:30:10.705883 17260 solver.cpp:237]     Train net output #1: loss = 0.0512871 (* 1 = 0.0512871 loss)
I0626 01:30:10.705883 17260 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0626 01:30:17.600814 17260 solver.cpp:218] Iteration 31700 (14.5056 iter/s, 6.89389s/100 iters), loss = 0.0743355
I0626 01:30:17.600814 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:30:17.600814 17260 solver.cpp:237]     Train net output #1: loss = 0.0743353 (* 1 = 0.0743353 loss)
I0626 01:30:17.600814 17260 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0626 01:30:23.676597 17260 solver.cpp:218] Iteration 31800 (16.4596 iter/s, 6.07547s/100 iters), loss = 0.0654034
I0626 01:30:23.676597 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:30:23.676597 17260 solver.cpp:237]     Train net output #1: loss = 0.0654032 (* 1 = 0.0654032 loss)
I0626 01:30:23.676597 17260 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0626 01:30:30.367890 17260 solver.cpp:218] Iteration 31900 (14.946 iter/s, 6.69077s/100 iters), loss = 0.0438853
I0626 01:30:30.368391 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:30:30.368391 17260 solver.cpp:237]     Train net output #1: loss = 0.0438851 (* 1 = 0.0438851 loss)
I0626 01:30:30.368391 17260 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0626 01:30:36.334115 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:30:36.509758 17260 solver.cpp:330] Iteration 32000, Testing net (#0)
I0626 01:30:36.509758 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:30:38.986893  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:30:39.079459 17260 solver.cpp:397]     Test net output #0: accuracy = 0.8909
I0626 01:30:39.079459 17260 solver.cpp:397]     Test net output #1: loss = 0.400198 (* 1 = 0.400198 loss)
I0626 01:30:39.126493 17260 solver.cpp:218] Iteration 32000 (11.4184 iter/s, 8.75777s/100 iters), loss = 0.0270376
I0626 01:30:39.126993 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:30:39.126993 17260 solver.cpp:237]     Train net output #1: loss = 0.0270375 (* 1 = 0.0270375 loss)
I0626 01:30:39.126993 17260 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0626 01:30:39.126993 17260 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0626 01:30:45.210862 17260 solver.cpp:218] Iteration 32100 (16.4386 iter/s, 6.08324s/100 iters), loss = 0.0200372
I0626 01:30:45.210862 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:30:45.210862 17260 solver.cpp:237]     Train net output #1: loss = 0.0200369 (* 1 = 0.0200369 loss)
I0626 01:30:45.210862 17260 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0626 01:30:50.613699 17260 solver.cpp:218] Iteration 32200 (18.5104 iter/s, 5.40235s/100 iters), loss = 0.0601833
I0626 01:30:50.613699 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:30:50.613699 17260 solver.cpp:237]     Train net output #1: loss = 0.0601831 (* 1 = 0.0601831 loss)
I0626 01:30:50.613699 17260 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0626 01:30:57.405580 17260 solver.cpp:218] Iteration 32300 (14.725 iter/s, 6.79116s/100 iters), loss = 0.0553988
I0626 01:30:57.405580 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:30:57.405580 17260 solver.cpp:237]     Train net output #1: loss = 0.0553986 (* 1 = 0.0553986 loss)
I0626 01:30:57.405580 17260 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0626 01:31:03.305450 17260 solver.cpp:218] Iteration 32400 (16.9564 iter/s, 5.89747s/100 iters), loss = 0.0157538
I0626 01:31:03.305450 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:31:03.305450 17260 solver.cpp:237]     Train net output #1: loss = 0.0157536 (* 1 = 0.0157536 loss)
I0626 01:31:03.305450 17260 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0626 01:31:08.977887 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:31:09.230077 17260 solver.cpp:218] Iteration 32500 (16.8818 iter/s, 5.92356s/100 iters), loss = 0.0359916
I0626 01:31:09.230077 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:31:09.230077 17260 solver.cpp:237]     Train net output #1: loss = 0.0359914 (* 1 = 0.0359914 loss)
I0626 01:31:09.230077 17260 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0626 01:31:15.708158 17260 solver.cpp:218] Iteration 32600 (15.4383 iter/s, 6.47741s/100 iters), loss = 0.0337855
I0626 01:31:15.708158 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:31:15.708158 17260 solver.cpp:237]     Train net output #1: loss = 0.0337853 (* 1 = 0.0337853 loss)
I0626 01:31:15.708158 17260 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0626 01:31:22.444353 17260 solver.cpp:218] Iteration 32700 (14.8457 iter/s, 6.73594s/100 iters), loss = 0.0336203
I0626 01:31:22.444353 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:31:22.444353 17260 solver.cpp:237]     Train net output #1: loss = 0.0336201 (* 1 = 0.0336201 loss)
I0626 01:31:22.444353 17260 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0626 01:31:28.205953 17260 solver.cpp:218] Iteration 32800 (17.3575 iter/s, 5.76121s/100 iters), loss = 0.0329764
I0626 01:31:28.206454 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:31:28.206454 17260 solver.cpp:237]     Train net output #1: loss = 0.0329762 (* 1 = 0.0329762 loss)
I0626 01:31:28.206454 17260 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0626 01:31:34.399726 17260 solver.cpp:218] Iteration 32900 (16.1486 iter/s, 6.19248s/100 iters), loss = 0.00741595
I0626 01:31:34.399726 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:31:34.399726 17260 solver.cpp:237]     Train net output #1: loss = 0.00741575 (* 1 = 0.00741575 loss)
I0626 01:31:34.399726 17260 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0626 01:31:40.433902 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:31:40.653558 17260 solver.cpp:330] Iteration 33000, Testing net (#0)
I0626 01:31:40.653558 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:31:42.558768  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:31:42.577970 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9155
I0626 01:31:42.577970 17260 solver.cpp:397]     Test net output #1: loss = 0.302081 (* 1 = 0.302081 loss)
I0626 01:31:42.629621 17260 solver.cpp:218] Iteration 33000 (12.1683 iter/s, 8.21809s/100 iters), loss = 0.0299475
I0626 01:31:42.639618 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:31:42.639618 17260 solver.cpp:237]     Train net output #1: loss = 0.0299473 (* 1 = 0.0299473 loss)
I0626 01:31:42.639618 17260 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0626 01:31:49.125974 17260 solver.cpp:218] Iteration 33100 (15.4558 iter/s, 6.47006s/100 iters), loss = 0.0437027
I0626 01:31:49.125974 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:31:49.125974 17260 solver.cpp:237]     Train net output #1: loss = 0.0437025 (* 1 = 0.0437025 loss)
I0626 01:31:49.125974 17260 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0626 01:31:55.325539 17260 solver.cpp:218] Iteration 33200 (16.1311 iter/s, 6.19922s/100 iters), loss = 0.0104918
I0626 01:31:55.326040 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:31:55.326040 17260 solver.cpp:237]     Train net output #1: loss = 0.0104916 (* 1 = 0.0104916 loss)
I0626 01:31:55.326040 17260 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0626 01:32:01.458485 17260 solver.cpp:218] Iteration 33300 (16.3079 iter/s, 6.13201s/100 iters), loss = 0.0123791
I0626 01:32:01.458986 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:32:01.458986 17260 solver.cpp:237]     Train net output #1: loss = 0.012379 (* 1 = 0.012379 loss)
I0626 01:32:01.458986 17260 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0626 01:32:07.487565 17260 solver.cpp:218] Iteration 33400 (16.6505 iter/s, 6.00584s/100 iters), loss = 0.00931867
I0626 01:32:07.487565 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:32:07.487565 17260 solver.cpp:237]     Train net output #1: loss = 0.0093185 (* 1 = 0.0093185 loss)
I0626 01:32:07.487565 17260 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0626 01:32:13.044538 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:32:13.523879 17260 solver.cpp:218] Iteration 33500 (16.5683 iter/s, 6.03561s/100 iters), loss = 0.0175762
I0626 01:32:13.523879 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:32:13.523879 17260 solver.cpp:237]     Train net output #1: loss = 0.017576 (* 1 = 0.017576 loss)
I0626 01:32:13.523879 17260 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0626 01:32:19.994971 17260 solver.cpp:218] Iteration 33600 (15.4541 iter/s, 6.47079s/100 iters), loss = 0.0164198
I0626 01:32:19.995471 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:32:19.995471 17260 solver.cpp:237]     Train net output #1: loss = 0.0164196 (* 1 = 0.0164196 loss)
I0626 01:32:19.995471 17260 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0626 01:32:26.301491 17260 solver.cpp:218] Iteration 33700 (15.8934 iter/s, 6.29191s/100 iters), loss = 0.025845
I0626 01:32:26.301491 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 01:32:26.301491 17260 solver.cpp:237]     Train net output #1: loss = 0.0258448 (* 1 = 0.0258448 loss)
I0626 01:32:26.301491 17260 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0626 01:32:32.838176 17260 solver.cpp:218] Iteration 33800 (15.3478 iter/s, 6.51558s/100 iters), loss = 0.0100919
I0626 01:32:32.838176 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:32:32.838677 17260 solver.cpp:237]     Train net output #1: loss = 0.0100917 (* 1 = 0.0100917 loss)
I0626 01:32:32.838677 17260 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0626 01:32:38.830394 17260 solver.cpp:218] Iteration 33900 (16.8706 iter/s, 5.92745s/100 iters), loss = 0.00806198
I0626 01:32:38.830394 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:32:38.830394 17260 solver.cpp:237]     Train net output #1: loss = 0.0080618 (* 1 = 0.0080618 loss)
I0626 01:32:38.830394 17260 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0626 01:32:44.506268 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:32:44.741936 17260 solver.cpp:330] Iteration 34000, Testing net (#0)
I0626 01:32:44.741936 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:32:46.462479  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:32:46.519019 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9168
I0626 01:32:46.519019 17260 solver.cpp:397]     Test net output #1: loss = 0.293601 (* 1 = 0.293601 loss)
I0626 01:32:46.562050 17260 solver.cpp:218] Iteration 34000 (12.9373 iter/s, 7.72957s/100 iters), loss = 0.0126735
I0626 01:32:46.562050 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:32:46.562050 17260 solver.cpp:237]     Train net output #1: loss = 0.0126733 (* 1 = 0.0126733 loss)
I0626 01:32:46.562050 17260 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0626 01:32:53.104674 17260 solver.cpp:218] Iteration 34100 (15.2903 iter/s, 6.54008s/100 iters), loss = 0.0109396
I0626 01:32:53.104674 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:32:53.104674 17260 solver.cpp:237]     Train net output #1: loss = 0.0109394 (* 1 = 0.0109394 loss)
I0626 01:32:53.104674 17260 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0626 01:32:59.936450 17260 solver.cpp:218] Iteration 34200 (14.6386 iter/s, 6.83125s/100 iters), loss = 0.0231831
I0626 01:32:59.936450 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:32:59.936450 17260 solver.cpp:237]     Train net output #1: loss = 0.0231829 (* 1 = 0.0231829 loss)
I0626 01:32:59.936450 17260 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0626 01:33:06.524282 17260 solver.cpp:218] Iteration 34300 (15.2172 iter/s, 6.57153s/100 iters), loss = 0.0145045
I0626 01:33:06.524282 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:06.524282 17260 solver.cpp:237]     Train net output #1: loss = 0.0145043 (* 1 = 0.0145043 loss)
I0626 01:33:06.524282 17260 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0626 01:33:13.377300 17260 solver.cpp:218] Iteration 34400 (14.5929 iter/s, 6.85265s/100 iters), loss = 0.00784931
I0626 01:33:13.377300 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:13.377300 17260 solver.cpp:237]     Train net output #1: loss = 0.00784912 (* 1 = 0.00784912 loss)
I0626 01:33:13.377300 17260 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0626 01:33:19.508339 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:33:19.795922 17260 solver.cpp:218] Iteration 34500 (15.5583 iter/s, 6.42742s/100 iters), loss = 0.0171905
I0626 01:33:19.795922 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:19.795922 17260 solver.cpp:237]     Train net output #1: loss = 0.0171903 (* 1 = 0.0171903 loss)
I0626 01:33:19.795922 17260 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0626 01:33:25.751708 17260 solver.cpp:218] Iteration 34600 (16.9372 iter/s, 5.90417s/100 iters), loss = 0.0216547
I0626 01:33:25.751708 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:25.751708 17260 solver.cpp:237]     Train net output #1: loss = 0.0216545 (* 1 = 0.0216545 loss)
I0626 01:33:25.751708 17260 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0626 01:33:32.275774 17260 solver.cpp:218] Iteration 34700 (15.3297 iter/s, 6.5233s/100 iters), loss = 0.0163863
I0626 01:33:32.275774 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:32.275774 17260 solver.cpp:237]     Train net output #1: loss = 0.0163862 (* 1 = 0.0163862 loss)
I0626 01:33:32.275774 17260 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0626 01:33:38.706373 17260 solver.cpp:218] Iteration 34800 (15.5517 iter/s, 6.43016s/100 iters), loss = 0.00739802
I0626 01:33:38.706373 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:38.706373 17260 solver.cpp:237]     Train net output #1: loss = 0.00739787 (* 1 = 0.00739787 loss)
I0626 01:33:38.706373 17260 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0626 01:33:45.004834 17260 solver.cpp:218] Iteration 34900 (15.9601 iter/s, 6.26562s/100 iters), loss = 0.00329492
I0626 01:33:45.004834 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:45.004834 17260 solver.cpp:237]     Train net output #1: loss = 0.00329476 (* 1 = 0.00329476 loss)
I0626 01:33:45.004834 17260 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0626 01:33:51.129606 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:33:51.350786 17260 solver.cpp:330] Iteration 35000, Testing net (#0)
I0626 01:33:51.350786 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:33:53.517328  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:33:53.572368 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9168
I0626 01:33:53.572368 17260 solver.cpp:397]     Test net output #1: loss = 0.294111 (* 1 = 0.294111 loss)
I0626 01:33:53.645920 17260 solver.cpp:218] Iteration 35000 (11.6142 iter/s, 8.61017s/100 iters), loss = 0.00798335
I0626 01:33:53.645920 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:33:53.645920 17260 solver.cpp:237]     Train net output #1: loss = 0.00798319 (* 1 = 0.00798319 loss)
I0626 01:33:53.645920 17260 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0626 01:33:59.504561 17260 solver.cpp:218] Iteration 35100 (17.1203 iter/s, 5.84103s/100 iters), loss = 0.0209474
I0626 01:33:59.504561 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:33:59.504561 17260 solver.cpp:237]     Train net output #1: loss = 0.0209472 (* 1 = 0.0209472 loss)
I0626 01:33:59.504561 17260 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0626 01:34:05.753346 17260 solver.cpp:218] Iteration 35200 (16.0043 iter/s, 6.24831s/100 iters), loss = 0.0553763
I0626 01:34:05.753346 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.97
I0626 01:34:05.753346 17260 solver.cpp:237]     Train net output #1: loss = 0.0553762 (* 1 = 0.0553762 loss)
I0626 01:34:05.753346 17260 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0626 01:34:11.948861 17260 solver.cpp:218] Iteration 35300 (16.1422 iter/s, 6.19493s/100 iters), loss = 0.012515
I0626 01:34:11.951362 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:11.951362 17260 solver.cpp:237]     Train net output #1: loss = 0.0125149 (* 1 = 0.0125149 loss)
I0626 01:34:11.951362 17260 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0626 01:34:17.905737 17260 solver.cpp:218] Iteration 35400 (16.7965 iter/s, 5.95363s/100 iters), loss = 0.00744218
I0626 01:34:17.905737 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:17.905737 17260 solver.cpp:237]     Train net output #1: loss = 0.00744201 (* 1 = 0.00744201 loss)
I0626 01:34:17.905737 17260 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0626 01:34:23.275607 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:34:23.611853 17260 solver.cpp:218] Iteration 35500 (17.6525 iter/s, 5.66492s/100 iters), loss = 0.011127
I0626 01:34:23.611853 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:23.611853 17260 solver.cpp:237]     Train net output #1: loss = 0.0111268 (* 1 = 0.0111268 loss)
I0626 01:34:23.611853 17260 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0626 01:34:29.759014 17260 solver.cpp:218] Iteration 35600 (16.2704 iter/s, 6.14612s/100 iters), loss = 0.0139847
I0626 01:34:29.759014 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:29.759014 17260 solver.cpp:237]     Train net output #1: loss = 0.0139845 (* 1 = 0.0139845 loss)
I0626 01:34:29.759014 17260 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0626 01:34:36.305332 17260 solver.cpp:218] Iteration 35700 (15.3317 iter/s, 6.52242s/100 iters), loss = 0.0117196
I0626 01:34:36.305332 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:36.305332 17260 solver.cpp:237]     Train net output #1: loss = 0.0117195 (* 1 = 0.0117195 loss)
I0626 01:34:36.305332 17260 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0626 01:34:42.596016 17260 solver.cpp:218] Iteration 35800 (15.9105 iter/s, 6.28516s/100 iters), loss = 0.0161627
I0626 01:34:42.596016 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:34:42.596016 17260 solver.cpp:237]     Train net output #1: loss = 0.0161626 (* 1 = 0.0161626 loss)
I0626 01:34:42.596016 17260 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0626 01:34:48.619310 17260 solver.cpp:218] Iteration 35900 (16.6025 iter/s, 6.02318s/100 iters), loss = 0.017263
I0626 01:34:48.619310 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:48.619310 17260 solver.cpp:237]     Train net output #1: loss = 0.0172629 (* 1 = 0.0172629 loss)
I0626 01:34:48.619310 17260 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0626 01:34:54.151551 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:34:54.316414 17260 solver.cpp:330] Iteration 36000, Testing net (#0)
I0626 01:34:54.316414 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:34:56.575582  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:34:56.734695 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9191
I0626 01:34:56.734695 17260 solver.cpp:397]     Test net output #1: loss = 0.292278 (* 1 = 0.292278 loss)
I0626 01:34:56.772222 17260 solver.cpp:218] Iteration 36000 (12.2669 iter/s, 8.15204s/100 iters), loss = 0.0103398
I0626 01:34:56.772222 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:34:56.772222 17260 solver.cpp:237]     Train net output #1: loss = 0.0103397 (* 1 = 0.0103397 loss)
I0626 01:34:56.772222 17260 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0626 01:35:03.246922 17260 solver.cpp:218] Iteration 36100 (15.4462 iter/s, 6.47408s/100 iters), loss = 0.0046466
I0626 01:35:03.246922 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:03.246922 17260 solver.cpp:237]     Train net output #1: loss = 0.00464646 (* 1 = 0.00464646 loss)
I0626 01:35:03.247423 17260 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0626 01:35:09.507998 17260 solver.cpp:218] Iteration 36200 (15.9683 iter/s, 6.2624s/100 iters), loss = 0.022589
I0626 01:35:09.507998 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:35:09.507998 17260 solver.cpp:237]     Train net output #1: loss = 0.0225888 (* 1 = 0.0225888 loss)
I0626 01:35:09.507998 17260 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0626 01:35:15.843644 17260 solver.cpp:218] Iteration 36300 (15.7907 iter/s, 6.33284s/100 iters), loss = 0.00975715
I0626 01:35:15.844146 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:15.844146 17260 solver.cpp:237]     Train net output #1: loss = 0.00975701 (* 1 = 0.00975701 loss)
I0626 01:35:15.844146 17260 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0626 01:35:22.526657 17260 solver.cpp:218] Iteration 36400 (14.9655 iter/s, 6.68202s/100 iters), loss = 0.00333827
I0626 01:35:22.526657 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:22.526657 17260 solver.cpp:237]     Train net output #1: loss = 0.00333814 (* 1 = 0.00333814 loss)
I0626 01:35:22.526657 17260 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0626 01:35:27.944314 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:35:28.229017 17260 solver.cpp:218] Iteration 36500 (17.5766 iter/s, 5.68937s/100 iters), loss = 0.00601246
I0626 01:35:28.229017 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:28.229017 17260 solver.cpp:237]     Train net output #1: loss = 0.00601233 (* 1 = 0.00601233 loss)
I0626 01:35:28.229017 17260 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0626 01:35:34.435372 17260 solver.cpp:218] Iteration 36600 (16.1142 iter/s, 6.20572s/100 iters), loss = 0.041525
I0626 01:35:34.435372 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:35:34.435372 17260 solver.cpp:237]     Train net output #1: loss = 0.0415249 (* 1 = 0.0415249 loss)
I0626 01:35:34.435372 17260 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0626 01:35:40.553834 17260 solver.cpp:218] Iteration 36700 (16.3533 iter/s, 6.11498s/100 iters), loss = 0.016886
I0626 01:35:40.554335 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:40.554335 17260 solver.cpp:237]     Train net output #1: loss = 0.0168858 (* 1 = 0.0168858 loss)
I0626 01:35:40.554335 17260 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0626 01:35:47.168284 17260 solver.cpp:218] Iteration 36800 (15.1206 iter/s, 6.61351s/100 iters), loss = 0.0209133
I0626 01:35:47.168284 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:47.168783 17260 solver.cpp:237]     Train net output #1: loss = 0.0209132 (* 1 = 0.0209132 loss)
I0626 01:35:47.168783 17260 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0626 01:35:54.009817 17260 solver.cpp:218] Iteration 36900 (14.6181 iter/s, 6.84082s/100 iters), loss = 0.00424734
I0626 01:35:54.009817 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:35:54.009817 17260 solver.cpp:237]     Train net output #1: loss = 0.00424722 (* 1 = 0.00424722 loss)
I0626 01:35:54.010323 17260 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0626 01:36:00.130805 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:36:00.586629 17260 solver.cpp:330] Iteration 37000, Testing net (#0)
I0626 01:36:00.587129 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:36:02.781642  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:36:02.844687 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9189
I0626 01:36:02.844687 17260 solver.cpp:397]     Test net output #1: loss = 0.292938 (* 1 = 0.292938 loss)
I0626 01:36:02.886217 17260 solver.cpp:218] Iteration 37000 (11.2702 iter/s, 8.87293s/100 iters), loss = 0.012916
I0626 01:36:02.886217 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:02.886217 17260 solver.cpp:237]     Train net output #1: loss = 0.0129159 (* 1 = 0.0129159 loss)
I0626 01:36:02.886217 17260 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0626 01:36:09.148730 17260 solver.cpp:218] Iteration 37100 (15.969 iter/s, 6.26212s/100 iters), loss = 0.0132989
I0626 01:36:09.148730 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:09.148730 17260 solver.cpp:237]     Train net output #1: loss = 0.0132987 (* 1 = 0.0132987 loss)
I0626 01:36:09.148730 17260 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0626 01:36:15.392280 17260 solver.cpp:218] Iteration 37200 (16.0178 iter/s, 6.24304s/100 iters), loss = 0.016767
I0626 01:36:15.392280 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:36:15.392280 17260 solver.cpp:237]     Train net output #1: loss = 0.0167669 (* 1 = 0.0167669 loss)
I0626 01:36:15.392280 17260 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0626 01:36:21.342526 17260 solver.cpp:218] Iteration 37300 (16.8083 iter/s, 5.94942s/100 iters), loss = 0.0194975
I0626 01:36:21.342526 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:36:21.342526 17260 solver.cpp:237]     Train net output #1: loss = 0.0194974 (* 1 = 0.0194974 loss)
I0626 01:36:21.342526 17260 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0626 01:36:27.880797 17260 solver.cpp:218] Iteration 37400 (15.3786 iter/s, 6.50256s/100 iters), loss = 0.00385842
I0626 01:36:27.880797 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:27.880797 17260 solver.cpp:237]     Train net output #1: loss = 0.0038583 (* 1 = 0.0038583 loss)
I0626 01:36:27.880797 17260 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0626 01:36:33.198590 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:36:33.340189 17260 solver.cpp:218] Iteration 37500 (18.3196 iter/s, 5.45863s/100 iters), loss = 0.0084447
I0626 01:36:33.340189 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:33.340189 17260 solver.cpp:237]     Train net output #1: loss = 0.00844457 (* 1 = 0.00844457 loss)
I0626 01:36:33.340189 17260 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0626 01:36:39.789788 17260 solver.cpp:218] Iteration 37600 (15.585 iter/s, 6.41642s/100 iters), loss = 0.00732903
I0626 01:36:39.789788 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:39.789788 17260 solver.cpp:237]     Train net output #1: loss = 0.00732891 (* 1 = 0.00732891 loss)
I0626 01:36:39.789788 17260 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0626 01:36:45.895066 17260 solver.cpp:218] Iteration 37700 (16.381 iter/s, 6.10462s/100 iters), loss = 0.00724164
I0626 01:36:45.895066 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:45.895347 17260 solver.cpp:237]     Train net output #1: loss = 0.00724152 (* 1 = 0.00724152 loss)
I0626 01:36:45.895347 17260 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0626 01:36:52.777706 17260 solver.cpp:218] Iteration 37800 (14.615 iter/s, 6.8423s/100 iters), loss = 0.00868279
I0626 01:36:52.777706 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:52.777706 17260 solver.cpp:237]     Train net output #1: loss = 0.00868267 (* 1 = 0.00868267 loss)
I0626 01:36:52.777706 17260 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0626 01:36:59.126837 17260 solver.cpp:218] Iteration 37900 (15.7789 iter/s, 6.33757s/100 iters), loss = 0.0041726
I0626 01:36:59.126837 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:36:59.126837 17260 solver.cpp:237]     Train net output #1: loss = 0.00417248 (* 1 = 0.00417248 loss)
I0626 01:36:59.126837 17260 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0626 01:37:04.986160 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:37:05.337923 17260 solver.cpp:330] Iteration 38000, Testing net (#0)
I0626 01:37:05.337923 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:37:07.724798  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:37:07.794801 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9186
I0626 01:37:07.794801 17260 solver.cpp:397]     Test net output #1: loss = 0.290413 (* 1 = 0.290413 loss)
I0626 01:37:07.854821 17260 solver.cpp:218] Iteration 38000 (11.4505 iter/s, 8.73326s/100 iters), loss = 0.00612503
I0626 01:37:07.854821 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:37:07.854821 17260 solver.cpp:237]     Train net output #1: loss = 0.00612491 (* 1 = 0.00612491 loss)
I0626 01:37:07.854821 17260 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I0626 01:37:13.943295 17260 solver.cpp:218] Iteration 38100 (16.443 iter/s, 6.0816s/100 iters), loss = 0.0034865
I0626 01:37:13.943295 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:37:13.943295 17260 solver.cpp:237]     Train net output #1: loss = 0.00348637 (* 1 = 0.00348637 loss)
I0626 01:37:13.943295 17260 sgd_solver.cpp:105] Iteration 38100, lr = 0.001
I0626 01:37:20.478082 17260 solver.cpp:218] Iteration 38200 (15.3132 iter/s, 6.53032s/100 iters), loss = 0.0157233
I0626 01:37:20.481585 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:37:20.481585 17260 solver.cpp:237]     Train net output #1: loss = 0.0157232 (* 1 = 0.0157232 loss)
I0626 01:37:20.481585 17260 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I0626 01:37:27.217880 17260 solver.cpp:218] Iteration 38300 (14.8466 iter/s, 6.73554s/100 iters), loss = 0.0185801
I0626 01:37:27.217880 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:37:27.217880 17260 solver.cpp:237]     Train net output #1: loss = 0.01858 (* 1 = 0.01858 loss)
I0626 01:37:27.217880 17260 sgd_solver.cpp:105] Iteration 38300, lr = 0.001
I0626 01:37:33.311928 17260 solver.cpp:218] Iteration 38400 (16.4105 iter/s, 6.09368s/100 iters), loss = 0.048538
I0626 01:37:33.312428 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:37:33.312428 17260 solver.cpp:237]     Train net output #1: loss = 0.0485379 (* 1 = 0.0485379 loss)
I0626 01:37:33.312428 17260 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I0626 01:37:38.847705 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:37:39.189448 17260 solver.cpp:218] Iteration 38500 (17.127 iter/s, 5.83873s/100 iters), loss = 0.00935146
I0626 01:37:39.189894 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:37:39.189949 17260 solver.cpp:237]     Train net output #1: loss = 0.00935134 (* 1 = 0.00935134 loss)
I0626 01:37:39.189949 17260 sgd_solver.cpp:105] Iteration 38500, lr = 0.001
I0626 01:37:45.565521 17260 solver.cpp:218] Iteration 38600 (15.7259 iter/s, 6.35893s/100 iters), loss = 0.00661627
I0626 01:37:45.566022 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:37:45.566022 17260 solver.cpp:237]     Train net output #1: loss = 0.00661615 (* 1 = 0.00661615 loss)
I0626 01:37:45.566022 17260 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I0626 01:37:51.744114 17260 solver.cpp:218] Iteration 38700 (16.1777 iter/s, 6.18136s/100 iters), loss = 0.0148234
I0626 01:37:51.744114 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:37:51.744114 17260 solver.cpp:237]     Train net output #1: loss = 0.0148233 (* 1 = 0.0148233 loss)
I0626 01:37:51.744114 17260 sgd_solver.cpp:105] Iteration 38700, lr = 0.001
I0626 01:37:57.826032 17260 solver.cpp:218] Iteration 38800 (16.4521 iter/s, 6.07825s/100 iters), loss = 0.022275
I0626 01:37:57.826032 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:37:57.826032 17260 solver.cpp:237]     Train net output #1: loss = 0.0222749 (* 1 = 0.0222749 loss)
I0626 01:37:57.826032 17260 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I0626 01:38:03.691938 17260 solver.cpp:218] Iteration 38900 (17.0519 iter/s, 5.86445s/100 iters), loss = 0.00377812
I0626 01:38:03.692440 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:03.692440 17260 solver.cpp:237]     Train net output #1: loss = 0.003778 (* 1 = 0.003778 loss)
I0626 01:38:03.692440 17260 sgd_solver.cpp:105] Iteration 38900, lr = 0.001
I0626 01:38:09.408732 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:38:09.636895 17260 solver.cpp:330] Iteration 39000, Testing net (#0)
I0626 01:38:09.636895 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:38:11.988234  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:38:12.114822 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9187
I0626 01:38:12.115324 17260 solver.cpp:397]     Test net output #1: loss = 0.290686 (* 1 = 0.290686 loss)
I0626 01:38:12.205386 17260 solver.cpp:218] Iteration 39000 (11.8139 iter/s, 8.46461s/100 iters), loss = 0.00474352
I0626 01:38:12.205386 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:12.205386 17260 solver.cpp:237]     Train net output #1: loss = 0.0047434 (* 1 = 0.0047434 loss)
I0626 01:38:12.205386 17260 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I0626 01:38:18.323441 17260 solver.cpp:218] Iteration 39100 (16.3481 iter/s, 6.11692s/100 iters), loss = 0.00457487
I0626 01:38:18.323441 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:18.323441 17260 solver.cpp:237]     Train net output #1: loss = 0.00457475 (* 1 = 0.00457475 loss)
I0626 01:38:18.323441 17260 sgd_solver.cpp:105] Iteration 39100, lr = 0.001
I0626 01:38:24.471812 17260 solver.cpp:218] Iteration 39200 (16.3211 iter/s, 6.12704s/100 iters), loss = 0.00701404
I0626 01:38:24.471812 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:24.471812 17260 solver.cpp:237]     Train net output #1: loss = 0.00701392 (* 1 = 0.00701392 loss)
I0626 01:38:24.471812 17260 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I0626 01:38:30.752545 17260 solver.cpp:218] Iteration 39300 (15.9329 iter/s, 6.27634s/100 iters), loss = 0.00777649
I0626 01:38:30.752545 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:30.752545 17260 solver.cpp:237]     Train net output #1: loss = 0.00777637 (* 1 = 0.00777637 loss)
I0626 01:38:30.752804 17260 sgd_solver.cpp:105] Iteration 39300, lr = 0.001
I0626 01:38:37.337407 17260 solver.cpp:218] Iteration 39400 (15.1814 iter/s, 6.587s/100 iters), loss = 0.00592761
I0626 01:38:37.337407 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:37.337407 17260 solver.cpp:237]     Train net output #1: loss = 0.00592749 (* 1 = 0.00592749 loss)
I0626 01:38:37.337407 17260 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I0626 01:38:43.189505 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:38:43.470202 17260 solver.cpp:218] Iteration 39500 (16.3192 iter/s, 6.12777s/100 iters), loss = 0.00810811
I0626 01:38:43.470202 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:43.470202 17260 solver.cpp:237]     Train net output #1: loss = 0.00810799 (* 1 = 0.00810799 loss)
I0626 01:38:43.470202 17260 sgd_solver.cpp:105] Iteration 39500, lr = 0.001
I0626 01:38:49.673797 17260 solver.cpp:218] Iteration 39600 (16.2259 iter/s, 6.16298s/100 iters), loss = 0.00961038
I0626 01:38:49.673797 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:49.673797 17260 solver.cpp:237]     Train net output #1: loss = 0.00961027 (* 1 = 0.00961027 loss)
I0626 01:38:49.673797 17260 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I0626 01:38:56.090679 17260 solver.cpp:218] Iteration 39700 (15.5841 iter/s, 6.41678s/100 iters), loss = 0.00418132
I0626 01:38:56.091181 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:38:56.091181 17260 solver.cpp:237]     Train net output #1: loss = 0.00418121 (* 1 = 0.00418121 loss)
I0626 01:38:56.091181 17260 sgd_solver.cpp:105] Iteration 39700, lr = 0.001
I0626 01:39:02.223688 17260 solver.cpp:218] Iteration 39800 (16.3078 iter/s, 6.13204s/100 iters), loss = 0.00496802
I0626 01:39:02.223688 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:02.223688 17260 solver.cpp:237]     Train net output #1: loss = 0.00496791 (* 1 = 0.00496791 loss)
I0626 01:39:02.223688 17260 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I0626 01:39:08.572823 17260 solver.cpp:218] Iteration 39900 (15.8954 iter/s, 6.29114s/100 iters), loss = 0.0115625
I0626 01:39:08.572823 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:08.572823 17260 solver.cpp:237]     Train net output #1: loss = 0.0115623 (* 1 = 0.0115623 loss)
I0626 01:39:08.572823 17260 sgd_solver.cpp:105] Iteration 39900, lr = 0.001
I0626 01:39:14.653230 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:39:14.820850 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_40000.caffemodel
I0626 01:39:14.899906 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_40000.solverstate
I0626 01:39:14.954444 17260 solver.cpp:330] Iteration 40000, Testing net (#0)
I0626 01:39:14.954444 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:39:17.474257  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:39:17.498565 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9198
I0626 01:39:17.498565 17260 solver.cpp:397]     Test net output #1: loss = 0.2906 (* 1 = 0.2906 loss)
I0626 01:39:17.581619 17260 solver.cpp:218] Iteration 40000 (11.1481 iter/s, 8.9701s/100 iters), loss = 0.00809945
I0626 01:39:17.581851 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:17.581851 17260 solver.cpp:237]     Train net output #1: loss = 0.00809933 (* 1 = 0.00809933 loss)
I0626 01:39:17.581851 17260 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I0626 01:39:23.285827 17260 solver.cpp:218] Iteration 40100 (17.5335 iter/s, 5.70337s/100 iters), loss = 0.00544584
I0626 01:39:23.285827 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:23.285827 17260 solver.cpp:237]     Train net output #1: loss = 0.00544573 (* 1 = 0.00544573 loss)
I0626 01:39:23.285827 17260 sgd_solver.cpp:105] Iteration 40100, lr = 0.001
I0626 01:39:29.038556 17260 solver.cpp:218] Iteration 40200 (17.5168 iter/s, 5.70879s/100 iters), loss = 0.0101101
I0626 01:39:29.038556 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:29.038556 17260 solver.cpp:237]     Train net output #1: loss = 0.01011 (* 1 = 0.01011 loss)
I0626 01:39:29.038556 17260 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I0626 01:39:35.407855 17260 solver.cpp:218] Iteration 40300 (15.7575 iter/s, 6.34618s/100 iters), loss = 0.0145928
I0626 01:39:35.407855 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:35.408355 17260 solver.cpp:237]     Train net output #1: loss = 0.0145927 (* 1 = 0.0145927 loss)
I0626 01:39:35.408355 17260 sgd_solver.cpp:105] Iteration 40300, lr = 0.001
I0626 01:39:41.610919 17260 solver.cpp:218] Iteration 40400 (16.124 iter/s, 6.20194s/100 iters), loss = 0.00271505
I0626 01:39:41.610919 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:41.610919 17260 solver.cpp:237]     Train net output #1: loss = 0.00271492 (* 1 = 0.00271492 loss)
I0626 01:39:41.610919 17260 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I0626 01:39:47.398285 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:39:47.618441 17260 solver.cpp:218] Iteration 40500 (16.6466 iter/s, 6.00725s/100 iters), loss = 0.00794738
I0626 01:39:47.618942 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:47.618942 17260 solver.cpp:237]     Train net output #1: loss = 0.00794726 (* 1 = 0.00794726 loss)
I0626 01:39:47.618942 17260 sgd_solver.cpp:105] Iteration 40500, lr = 0.001
I0626 01:39:53.669342 17260 solver.cpp:218] Iteration 40600 (16.529 iter/s, 6.04998s/100 iters), loss = 0.0071997
I0626 01:39:53.669342 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:39:53.669342 17260 solver.cpp:237]     Train net output #1: loss = 0.00719958 (* 1 = 0.00719958 loss)
I0626 01:39:53.669342 17260 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I0626 01:39:59.621634 17260 solver.cpp:218] Iteration 40700 (16.8012 iter/s, 5.95196s/100 iters), loss = 0.0170938
I0626 01:39:59.622135 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:39:59.622135 17260 solver.cpp:237]     Train net output #1: loss = 0.0170936 (* 1 = 0.0170936 loss)
I0626 01:39:59.622135 17260 sgd_solver.cpp:105] Iteration 40700, lr = 0.001
I0626 01:40:06.374502 17260 solver.cpp:218] Iteration 40800 (14.8159 iter/s, 6.74952s/100 iters), loss = 0.0113917
I0626 01:40:06.374502 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:06.374502 17260 solver.cpp:237]     Train net output #1: loss = 0.0113916 (* 1 = 0.0113916 loss)
I0626 01:40:06.374502 17260 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I0626 01:40:12.201032 17260 solver.cpp:218] Iteration 40900 (17.1645 iter/s, 5.82597s/100 iters), loss = 0.0038696
I0626 01:40:12.201032 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:12.201032 17260 solver.cpp:237]     Train net output #1: loss = 0.00386947 (* 1 = 0.00386947 loss)
I0626 01:40:12.201530 17260 sgd_solver.cpp:105] Iteration 40900, lr = 0.001
I0626 01:40:18.242249 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:40:18.470654 17260 solver.cpp:330] Iteration 41000, Testing net (#0)
I0626 01:40:18.470654 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:40:20.351686  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:40:20.439749 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9199
I0626 01:40:20.439749 17260 solver.cpp:397]     Test net output #1: loss = 0.292256 (* 1 = 0.292256 loss)
I0626 01:40:20.488283 17260 solver.cpp:218] Iteration 41000 (12.084 iter/s, 8.27539s/100 iters), loss = 0.0074705
I0626 01:40:20.488283 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:20.488283 17260 solver.cpp:237]     Train net output #1: loss = 0.00747036 (* 1 = 0.00747036 loss)
I0626 01:40:20.488283 17260 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I0626 01:40:26.484330 17260 solver.cpp:218] Iteration 41100 (16.7587 iter/s, 5.96706s/100 iters), loss = 0.0106381
I0626 01:40:26.484330 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:40:26.484330 17260 solver.cpp:237]     Train net output #1: loss = 0.010638 (* 1 = 0.010638 loss)
I0626 01:40:26.484832 17260 sgd_solver.cpp:105] Iteration 41100, lr = 0.001
I0626 01:40:33.115545 17260 solver.cpp:218] Iteration 41200 (15.082 iter/s, 6.63042s/100 iters), loss = 0.00556728
I0626 01:40:33.115545 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:33.115545 17260 solver.cpp:237]     Train net output #1: loss = 0.00556714 (* 1 = 0.00556714 loss)
I0626 01:40:33.115545 17260 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I0626 01:40:39.371250 17260 solver.cpp:218] Iteration 41300 (16.0191 iter/s, 6.24255s/100 iters), loss = 0.00481343
I0626 01:40:39.371752 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:39.371752 17260 solver.cpp:237]     Train net output #1: loss = 0.00481329 (* 1 = 0.00481329 loss)
I0626 01:40:39.371752 17260 sgd_solver.cpp:105] Iteration 41300, lr = 0.001
I0626 01:40:45.859262 17260 solver.cpp:218] Iteration 41400 (15.4179 iter/s, 6.48596s/100 iters), loss = 0.00389741
I0626 01:40:45.859262 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:45.859262 17260 solver.cpp:237]     Train net output #1: loss = 0.00389726 (* 1 = 0.00389726 loss)
I0626 01:40:45.859763 17260 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I0626 01:40:51.464690 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:40:51.672338 17260 solver.cpp:218] Iteration 41500 (17.227 iter/s, 5.80485s/100 iters), loss = 0.0123787
I0626 01:40:51.672338 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:51.672338 17260 solver.cpp:237]     Train net output #1: loss = 0.0123785 (* 1 = 0.0123785 loss)
I0626 01:40:51.672338 17260 sgd_solver.cpp:105] Iteration 41500, lr = 0.001
I0626 01:40:57.683411 17260 solver.cpp:218] Iteration 41600 (16.637 iter/s, 6.0107s/100 iters), loss = 0.00764188
I0626 01:40:57.683411 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:40:57.683411 17260 solver.cpp:237]     Train net output #1: loss = 0.00764173 (* 1 = 0.00764173 loss)
I0626 01:40:57.683912 17260 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I0626 01:41:03.354702 17260 solver.cpp:218] Iteration 41700 (17.6352 iter/s, 5.67049s/100 iters), loss = 0.00388433
I0626 01:41:03.354702 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:03.354702 17260 solver.cpp:237]     Train net output #1: loss = 0.00388418 (* 1 = 0.00388418 loss)
I0626 01:41:03.354702 17260 sgd_solver.cpp:105] Iteration 41700, lr = 0.001
I0626 01:41:10.345417 17260 solver.cpp:218] Iteration 41800 (14.3529 iter/s, 6.96722s/100 iters), loss = 0.0105893
I0626 01:41:10.345417 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:10.345417 17260 solver.cpp:237]     Train net output #1: loss = 0.0105892 (* 1 = 0.0105892 loss)
I0626 01:41:10.345417 17260 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I0626 01:41:16.749644 17260 solver.cpp:218] Iteration 41900 (15.7061 iter/s, 6.36695s/100 iters), loss = 0.00421959
I0626 01:41:16.749644 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:16.749644 17260 solver.cpp:237]     Train net output #1: loss = 0.00421943 (* 1 = 0.00421943 loss)
I0626 01:41:16.749644 17260 sgd_solver.cpp:105] Iteration 41900, lr = 0.001
I0626 01:41:22.779008 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:41:23.010332 17260 solver.cpp:330] Iteration 42000, Testing net (#0)
I0626 01:41:23.010332 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:41:25.266937  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:41:25.316972 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9208
I0626 01:41:25.316972 17260 solver.cpp:397]     Test net output #1: loss = 0.291587 (* 1 = 0.291587 loss)
I0626 01:41:25.391525 17260 solver.cpp:218] Iteration 42000 (11.6102 iter/s, 8.61309s/100 iters), loss = 0.00542696
I0626 01:41:25.391525 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:25.391525 17260 solver.cpp:237]     Train net output #1: loss = 0.0054268 (* 1 = 0.0054268 loss)
I0626 01:41:25.391525 17260 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I0626 01:41:31.415058 17260 solver.cpp:218] Iteration 42100 (16.6148 iter/s, 6.01874s/100 iters), loss = 0.00519913
I0626 01:41:31.415058 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:31.415058 17260 solver.cpp:237]     Train net output #1: loss = 0.00519897 (* 1 = 0.00519897 loss)
I0626 01:41:31.415058 17260 sgd_solver.cpp:105] Iteration 42100, lr = 0.001
I0626 01:41:37.420778 17260 solver.cpp:218] Iteration 42200 (16.876 iter/s, 5.92558s/100 iters), loss = 0.00924666
I0626 01:41:37.420778 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:37.420778 17260 solver.cpp:237]     Train net output #1: loss = 0.0092465 (* 1 = 0.0092465 loss)
I0626 01:41:37.420778 17260 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I0626 01:41:43.647840 17260 solver.cpp:218] Iteration 42300 (16.0611 iter/s, 6.22623s/100 iters), loss = 0.00585811
I0626 01:41:43.647840 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:43.647840 17260 solver.cpp:237]     Train net output #1: loss = 0.00585796 (* 1 = 0.00585796 loss)
I0626 01:41:43.647840 17260 sgd_solver.cpp:105] Iteration 42300, lr = 0.001
I0626 01:41:50.223682 17260 solver.cpp:218] Iteration 42400 (15.2278 iter/s, 6.56693s/100 iters), loss = 0.00645701
I0626 01:41:50.224184 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:50.224184 17260 solver.cpp:237]     Train net output #1: loss = 0.00645686 (* 1 = 0.00645686 loss)
I0626 01:41:50.224684 17260 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I0626 01:41:56.262758 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:41:56.561481 17260 solver.cpp:218] Iteration 42500 (15.8218 iter/s, 6.32038s/100 iters), loss = 0.00381326
I0626 01:41:56.561481 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:41:56.561980 17260 solver.cpp:237]     Train net output #1: loss = 0.00381311 (* 1 = 0.00381311 loss)
I0626 01:41:56.561980 17260 sgd_solver.cpp:105] Iteration 42500, lr = 0.001
I0626 01:42:02.290411 17260 solver.cpp:218] Iteration 42600 (17.4597 iter/s, 5.72747s/100 iters), loss = 0.00767702
I0626 01:42:02.290912 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:02.290912 17260 solver.cpp:237]     Train net output #1: loss = 0.00767687 (* 1 = 0.00767687 loss)
I0626 01:42:02.290912 17260 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I0626 01:42:08.726361 17260 solver.cpp:218] Iteration 42700 (15.5951 iter/s, 6.41229s/100 iters), loss = 0.0106285
I0626 01:42:08.726861 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:08.726861 17260 solver.cpp:237]     Train net output #1: loss = 0.0106284 (* 1 = 0.0106284 loss)
I0626 01:42:08.726861 17260 sgd_solver.cpp:105] Iteration 42700, lr = 0.001
I0626 01:42:15.147768 17260 solver.cpp:218] Iteration 42800 (15.5745 iter/s, 6.42077s/100 iters), loss = 0.00528681
I0626 01:42:15.148268 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:15.148268 17260 solver.cpp:237]     Train net output #1: loss = 0.00528665 (* 1 = 0.00528665 loss)
I0626 01:42:15.148268 17260 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I0626 01:42:21.465445 17260 solver.cpp:218] Iteration 42900 (15.8305 iter/s, 6.31692s/100 iters), loss = 0.00272986
I0626 01:42:21.465445 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:21.465445 17260 solver.cpp:237]     Train net output #1: loss = 0.0027297 (* 1 = 0.0027297 loss)
I0626 01:42:21.465945 17260 sgd_solver.cpp:105] Iteration 42900, lr = 0.001
I0626 01:42:26.949208 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:42:27.117398 17260 solver.cpp:330] Iteration 43000, Testing net (#0)
I0626 01:42:27.117398 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:42:28.997252  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:42:29.009260 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9196
I0626 01:42:29.009260 17260 solver.cpp:397]     Test net output #1: loss = 0.293485 (* 1 = 0.293485 loss)
I0626 01:42:29.061297 17260 solver.cpp:218] Iteration 43000 (13.17 iter/s, 7.59304s/100 iters), loss = 0.00516269
I0626 01:42:29.061297 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:29.061297 17260 solver.cpp:237]     Train net output #1: loss = 0.00516253 (* 1 = 0.00516253 loss)
I0626 01:42:29.061297 17260 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I0626 01:42:35.443110 17260 solver.cpp:218] Iteration 43100 (15.6708 iter/s, 6.38131s/100 iters), loss = 0.00814031
I0626 01:42:35.443110 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:35.443110 17260 solver.cpp:237]     Train net output #1: loss = 0.00814015 (* 1 = 0.00814015 loss)
I0626 01:42:35.443110 17260 sgd_solver.cpp:105] Iteration 43100, lr = 0.001
I0626 01:42:39.960783 17260 solver.cpp:218] Iteration 43200 (22.1389 iter/s, 4.51694s/100 iters), loss = 0.0128723
I0626 01:42:39.960783 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:39.960783 17260 solver.cpp:237]     Train net output #1: loss = 0.0128721 (* 1 = 0.0128721 loss)
I0626 01:42:39.960783 17260 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I0626 01:42:44.388031 17260 solver.cpp:218] Iteration 43300 (22.5904 iter/s, 4.42666s/100 iters), loss = 0.013226
I0626 01:42:44.388031 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:44.388031 17260 solver.cpp:237]     Train net output #1: loss = 0.0132258 (* 1 = 0.0132258 loss)
I0626 01:42:44.388031 17260 sgd_solver.cpp:105] Iteration 43300, lr = 0.001
I0626 01:42:49.036641 17260 solver.cpp:218] Iteration 43400 (21.5383 iter/s, 4.64288s/100 iters), loss = 0.00316305
I0626 01:42:49.036641 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:49.036641 17260 solver.cpp:237]     Train net output #1: loss = 0.00316289 (* 1 = 0.00316289 loss)
I0626 01:42:49.036641 17260 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I0626 01:42:53.252777 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:42:53.455421 17260 solver.cpp:218] Iteration 43500 (22.6476 iter/s, 4.41547s/100 iters), loss = 0.00389804
I0626 01:42:53.455421 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:53.455421 17260 solver.cpp:237]     Train net output #1: loss = 0.00389788 (* 1 = 0.00389788 loss)
I0626 01:42:53.455421 17260 sgd_solver.cpp:105] Iteration 43500, lr = 0.001
I0626 01:42:57.745978 17260 solver.cpp:218] Iteration 43600 (23.2939 iter/s, 4.29296s/100 iters), loss = 0.00636583
I0626 01:42:57.745978 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:42:57.745978 17260 solver.cpp:237]     Train net output #1: loss = 0.00636568 (* 1 = 0.00636568 loss)
I0626 01:42:57.745978 17260 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I0626 01:43:02.133640 17260 solver.cpp:218] Iteration 43700 (22.8107 iter/s, 4.38391s/100 iters), loss = 0.00776076
I0626 01:43:02.133640 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:02.133640 17260 solver.cpp:237]     Train net output #1: loss = 0.0077606 (* 1 = 0.0077606 loss)
I0626 01:43:02.133640 17260 sgd_solver.cpp:105] Iteration 43700, lr = 0.001
I0626 01:43:06.493091 17260 solver.cpp:218] Iteration 43800 (22.9709 iter/s, 4.35333s/100 iters), loss = 0.00722217
I0626 01:43:06.493091 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:06.493091 17260 solver.cpp:237]     Train net output #1: loss = 0.00722201 (* 1 = 0.00722201 loss)
I0626 01:43:06.493091 17260 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I0626 01:43:10.869339 17260 solver.cpp:218] Iteration 43900 (22.8526 iter/s, 4.37587s/100 iters), loss = 0.0144375
I0626 01:43:10.869339 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:43:10.869339 17260 solver.cpp:237]     Train net output #1: loss = 0.0144373 (* 1 = 0.0144373 loss)
I0626 01:43:10.869339 17260 sgd_solver.cpp:105] Iteration 43900, lr = 0.001
I0626 01:43:15.090474 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:43:15.268100 17260 solver.cpp:330] Iteration 44000, Testing net (#0)
I0626 01:43:15.268100 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:43:16.666596  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:43:16.708626 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9192
I0626 01:43:16.708626 17260 solver.cpp:397]     Test net output #1: loss = 0.293216 (* 1 = 0.293216 loss)
I0626 01:43:16.758160 17260 solver.cpp:218] Iteration 44000 (16.9834 iter/s, 5.88812s/100 iters), loss = 0.00493139
I0626 01:43:16.758160 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:16.758160 17260 solver.cpp:237]     Train net output #1: loss = 0.00493123 (* 1 = 0.00493123 loss)
I0626 01:43:16.758160 17260 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I0626 01:43:21.141131 17260 solver.cpp:218] Iteration 44100 (22.8192 iter/s, 4.38228s/100 iters), loss = 0.00280626
I0626 01:43:21.141131 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:21.141131 17260 solver.cpp:237]     Train net output #1: loss = 0.0028061 (* 1 = 0.0028061 loss)
I0626 01:43:21.141131 17260 sgd_solver.cpp:105] Iteration 44100, lr = 0.001
I0626 01:43:25.608412 17260 solver.cpp:218] Iteration 44200 (22.3878 iter/s, 4.46672s/100 iters), loss = 0.00612399
I0626 01:43:25.608412 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:25.608412 17260 solver.cpp:237]     Train net output #1: loss = 0.00612382 (* 1 = 0.00612382 loss)
I0626 01:43:25.608412 17260 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I0626 01:43:29.892109 17260 solver.cpp:218] Iteration 44300 (23.3479 iter/s, 4.28304s/100 iters), loss = 0.0059831
I0626 01:43:29.892109 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:29.892109 17260 solver.cpp:237]     Train net output #1: loss = 0.00598294 (* 1 = 0.00598294 loss)
I0626 01:43:29.892109 17260 sgd_solver.cpp:105] Iteration 44300, lr = 0.001
I0626 01:43:34.193939 17260 solver.cpp:218] Iteration 44400 (23.2521 iter/s, 4.30069s/100 iters), loss = 0.00869555
I0626 01:43:34.193939 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:34.193939 17260 solver.cpp:237]     Train net output #1: loss = 0.00869538 (* 1 = 0.00869538 loss)
I0626 01:43:34.193939 17260 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I0626 01:43:38.328701 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:43:38.547857 17260 solver.cpp:218] Iteration 44500 (22.9774 iter/s, 4.3521s/100 iters), loss = 0.0037979
I0626 01:43:38.547857 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:38.547857 17260 solver.cpp:237]     Train net output #1: loss = 0.00379774 (* 1 = 0.00379774 loss)
I0626 01:43:38.547857 17260 sgd_solver.cpp:105] Iteration 44500, lr = 0.001
I0626 01:43:42.860401 17260 solver.cpp:218] Iteration 44600 (23.1923 iter/s, 4.31177s/100 iters), loss = 0.00373197
I0626 01:43:42.860401 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:42.860901 17260 solver.cpp:237]     Train net output #1: loss = 0.00373181 (* 1 = 0.00373181 loss)
I0626 01:43:42.860901 17260 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I0626 01:43:47.464687 17260 solver.cpp:218] Iteration 44700 (21.723 iter/s, 4.60341s/100 iters), loss = 0.00304694
I0626 01:43:47.464687 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:47.464687 17260 solver.cpp:237]     Train net output #1: loss = 0.00304679 (* 1 = 0.00304679 loss)
I0626 01:43:47.464687 17260 sgd_solver.cpp:105] Iteration 44700, lr = 0.001
I0626 01:43:51.902997 17260 solver.cpp:218] Iteration 44800 (22.5328 iter/s, 4.43798s/100 iters), loss = 0.00730906
I0626 01:43:51.902997 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:51.902997 17260 solver.cpp:237]     Train net output #1: loss = 0.0073089 (* 1 = 0.0073089 loss)
I0626 01:43:51.902997 17260 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I0626 01:43:56.335371 17260 solver.cpp:218] Iteration 44900 (22.5639 iter/s, 4.43186s/100 iters), loss = 0.00256441
I0626 01:43:56.335872 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:43:56.335872 17260 solver.cpp:237]     Train net output #1: loss = 0.00256426 (* 1 = 0.00256426 loss)
I0626 01:43:56.335872 17260 sgd_solver.cpp:105] Iteration 44900, lr = 0.001
I0626 01:44:00.427115 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:44:00.594987 17260 solver.cpp:330] Iteration 45000, Testing net (#0)
I0626 01:44:00.594987 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:44:01.993672  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:44:02.005681 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9195
I0626 01:44:02.005681 17260 solver.cpp:397]     Test net output #1: loss = 0.292527 (* 1 = 0.292527 loss)
I0626 01:44:02.049211 17260 solver.cpp:218] Iteration 45000 (17.5043 iter/s, 5.7129s/100 iters), loss = 0.00423083
I0626 01:44:02.049211 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:02.049211 17260 solver.cpp:237]     Train net output #1: loss = 0.00423067 (* 1 = 0.00423067 loss)
I0626 01:44:02.049211 17260 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I0626 01:44:06.430784 17260 solver.cpp:218] Iteration 45100 (22.8149 iter/s, 4.38309s/100 iters), loss = 0.00365939
I0626 01:44:06.430784 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:06.430784 17260 solver.cpp:237]     Train net output #1: loss = 0.00365924 (* 1 = 0.00365924 loss)
I0626 01:44:06.430784 17260 sgd_solver.cpp:105] Iteration 45100, lr = 0.001
I0626 01:44:10.851709 17260 solver.cpp:218] Iteration 45200 (22.5902 iter/s, 4.42671s/100 iters), loss = 0.00396534
I0626 01:44:10.851709 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:10.851709 17260 solver.cpp:237]     Train net output #1: loss = 0.00396519 (* 1 = 0.00396519 loss)
I0626 01:44:10.851709 17260 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I0626 01:44:15.373219 17260 solver.cpp:218] Iteration 45300 (22.1583 iter/s, 4.51297s/100 iters), loss = 0.0060886
I0626 01:44:15.373219 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:15.373219 17260 solver.cpp:237]     Train net output #1: loss = 0.00608844 (* 1 = 0.00608844 loss)
I0626 01:44:15.373219 17260 sgd_solver.cpp:105] Iteration 45300, lr = 0.001
I0626 01:44:19.738175 17260 solver.cpp:218] Iteration 45400 (22.9239 iter/s, 4.36226s/100 iters), loss = 0.00325035
I0626 01:44:19.738175 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:19.738175 17260 solver.cpp:237]     Train net output #1: loss = 0.0032502 (* 1 = 0.0032502 loss)
I0626 01:44:19.738175 17260 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I0626 01:44:24.118403 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:44:24.339059 17260 solver.cpp:218] Iteration 45500 (21.7375 iter/s, 4.60034s/100 iters), loss = 0.00264107
I0626 01:44:24.339560 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:24.339560 17260 solver.cpp:237]     Train net output #1: loss = 0.00264091 (* 1 = 0.00264091 loss)
I0626 01:44:24.339560 17260 sgd_solver.cpp:105] Iteration 45500, lr = 0.001
I0626 01:44:28.802127 17260 solver.cpp:218] Iteration 45600 (22.4179 iter/s, 4.46072s/100 iters), loss = 0.00935819
I0626 01:44:28.802127 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:28.802127 17260 solver.cpp:237]     Train net output #1: loss = 0.00935803 (* 1 = 0.00935803 loss)
I0626 01:44:28.802127 17260 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I0626 01:44:33.258239 17260 solver.cpp:218] Iteration 45700 (22.4456 iter/s, 4.45522s/100 iters), loss = 0.00295963
I0626 01:44:33.258239 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:33.258239 17260 solver.cpp:237]     Train net output #1: loss = 0.00295948 (* 1 = 0.00295948 loss)
I0626 01:44:33.258239 17260 sgd_solver.cpp:105] Iteration 45700, lr = 0.001
I0626 01:44:37.811036 17260 solver.cpp:218] Iteration 45800 (21.9553 iter/s, 4.5547s/100 iters), loss = 0.00315766
I0626 01:44:37.811036 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:37.811036 17260 solver.cpp:237]     Train net output #1: loss = 0.0031575 (* 1 = 0.0031575 loss)
I0626 01:44:37.811036 17260 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I0626 01:44:42.696115 17260 solver.cpp:218] Iteration 45900 (20.5237 iter/s, 4.87242s/100 iters), loss = 0.0031076
I0626 01:44:42.696115 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:42.696115 17260 solver.cpp:237]     Train net output #1: loss = 0.00310744 (* 1 = 0.00310744 loss)
I0626 01:44:42.696115 17260 sgd_solver.cpp:105] Iteration 45900, lr = 0.001
I0626 01:44:47.225469 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:44:47.397637 17260 solver.cpp:330] Iteration 46000, Testing net (#0)
I0626 01:44:47.397637 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:44:48.959426  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:44:48.979944 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9204
I0626 01:44:48.979944 17260 solver.cpp:397]     Test net output #1: loss = 0.292396 (* 1 = 0.292396 loss)
I0626 01:44:49.033987 17260 solver.cpp:218] Iteration 46000 (15.8048 iter/s, 6.32721s/100 iters), loss = 0.00376628
I0626 01:44:49.033987 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:49.033987 17260 solver.cpp:237]     Train net output #1: loss = 0.00376612 (* 1 = 0.00376612 loss)
I0626 01:44:49.033987 17260 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I0626 01:44:53.519080 17260 solver.cpp:218] Iteration 46100 (22.3578 iter/s, 4.47271s/100 iters), loss = 0.00643092
I0626 01:44:53.519080 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:53.519080 17260 solver.cpp:237]     Train net output #1: loss = 0.00643076 (* 1 = 0.00643076 loss)
I0626 01:44:53.519080 17260 sgd_solver.cpp:105] Iteration 46100, lr = 0.001
I0626 01:44:58.069721 17260 solver.cpp:218] Iteration 46200 (22.0053 iter/s, 4.54437s/100 iters), loss = 0.00525955
I0626 01:44:58.069721 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:44:58.069721 17260 solver.cpp:237]     Train net output #1: loss = 0.00525939 (* 1 = 0.00525939 loss)
I0626 01:44:58.069721 17260 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I0626 01:45:02.576864 17260 solver.cpp:218] Iteration 46300 (22.1899 iter/s, 4.50655s/100 iters), loss = 0.00749182
I0626 01:45:02.577364 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:02.577364 17260 solver.cpp:237]     Train net output #1: loss = 0.00749167 (* 1 = 0.00749167 loss)
I0626 01:45:02.577364 17260 sgd_solver.cpp:105] Iteration 46300, lr = 0.001
I0626 01:45:07.000859 17260 solver.cpp:218] Iteration 46400 (22.6076 iter/s, 4.4233s/100 iters), loss = 0.0071218
I0626 01:45:07.000859 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:07.000859 17260 solver.cpp:237]     Train net output #1: loss = 0.00712165 (* 1 = 0.00712165 loss)
I0626 01:45:07.001360 17260 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I0626 01:45:11.349378 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:45:11.547031 17260 solver.cpp:218] Iteration 46500 (21.9992 iter/s, 4.54562s/100 iters), loss = 0.00681727
I0626 01:45:11.547531 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:11.547531 17260 solver.cpp:237]     Train net output #1: loss = 0.00681712 (* 1 = 0.00681712 loss)
I0626 01:45:11.547531 17260 sgd_solver.cpp:105] Iteration 46500, lr = 0.001
I0626 01:45:16.063992 17260 solver.cpp:218] Iteration 46600 (22.1437 iter/s, 4.51596s/100 iters), loss = 0.00361347
I0626 01:45:16.063992 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:16.063992 17260 solver.cpp:237]     Train net output #1: loss = 0.00361332 (* 1 = 0.00361332 loss)
I0626 01:45:16.063992 17260 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I0626 01:45:20.524272 17260 solver.cpp:218] Iteration 46700 (22.5116 iter/s, 4.44216s/100 iters), loss = 0.00737491
I0626 01:45:20.524272 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:20.524272 17260 solver.cpp:237]     Train net output #1: loss = 0.00737475 (* 1 = 0.00737475 loss)
I0626 01:45:20.524272 17260 sgd_solver.cpp:105] Iteration 46700, lr = 0.001
I0626 01:45:24.957465 17260 solver.cpp:218] Iteration 46800 (22.56 iter/s, 4.43263s/100 iters), loss = 0.00476159
I0626 01:45:24.957465 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:24.957465 17260 solver.cpp:237]     Train net output #1: loss = 0.00476144 (* 1 = 0.00476144 loss)
I0626 01:45:24.957465 17260 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I0626 01:45:29.488765 17260 solver.cpp:218] Iteration 46900 (22.0803 iter/s, 4.52892s/100 iters), loss = 0.00687105
I0626 01:45:29.488765 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:29.488765 17260 solver.cpp:237]     Train net output #1: loss = 0.00687089 (* 1 = 0.00687089 loss)
I0626 01:45:29.488765 17260 sgd_solver.cpp:105] Iteration 46900, lr = 0.001
I0626 01:45:33.657797 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:45:33.839937 17260 solver.cpp:330] Iteration 47000, Testing net (#0)
I0626 01:45:33.839937 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:45:35.315997  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:45:35.353525 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9203
I0626 01:45:35.353525 17260 solver.cpp:397]     Test net output #1: loss = 0.292026 (* 1 = 0.292026 loss)
I0626 01:45:35.391052 17260 solver.cpp:218] Iteration 47000 (16.9439 iter/s, 5.90183s/100 iters), loss = 0.00284504
I0626 01:45:35.391052 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:35.391052 17260 solver.cpp:237]     Train net output #1: loss = 0.00284489 (* 1 = 0.00284489 loss)
I0626 01:45:35.391052 17260 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I0626 01:45:39.838295 17260 solver.cpp:218] Iteration 47100 (22.4889 iter/s, 4.44664s/100 iters), loss = 0.0183424
I0626 01:45:39.838295 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:39.838295 17260 solver.cpp:237]     Train net output #1: loss = 0.0183422 (* 1 = 0.0183422 loss)
I0626 01:45:39.838295 17260 sgd_solver.cpp:105] Iteration 47100, lr = 0.001
I0626 01:45:44.333569 17260 solver.cpp:218] Iteration 47200 (22.3157 iter/s, 4.48116s/100 iters), loss = 0.00909046
I0626 01:45:44.333569 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:44.333569 17260 solver.cpp:237]     Train net output #1: loss = 0.00909031 (* 1 = 0.00909031 loss)
I0626 01:45:44.333569 17260 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I0626 01:45:48.845809 17260 solver.cpp:218] Iteration 47300 (22.1653 iter/s, 4.51155s/100 iters), loss = 0.00360918
I0626 01:45:48.845809 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:48.845809 17260 solver.cpp:237]     Train net output #1: loss = 0.00360903 (* 1 = 0.00360903 loss)
I0626 01:45:48.845809 17260 sgd_solver.cpp:105] Iteration 47300, lr = 0.001
I0626 01:45:53.291419 17260 solver.cpp:218] Iteration 47400 (22.4995 iter/s, 4.44455s/100 iters), loss = 0.00532733
I0626 01:45:53.291419 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:53.291419 17260 solver.cpp:237]     Train net output #1: loss = 0.00532718 (* 1 = 0.00532718 loss)
I0626 01:45:53.291419 17260 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I0626 01:45:57.600287 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:45:57.797427 17260 solver.cpp:218] Iteration 47500 (22.1945 iter/s, 4.50563s/100 iters), loss = 0.00413392
I0626 01:45:57.797427 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:45:57.797427 17260 solver.cpp:237]     Train net output #1: loss = 0.00413377 (* 1 = 0.00413377 loss)
I0626 01:45:57.797427 17260 sgd_solver.cpp:105] Iteration 47500, lr = 0.001
I0626 01:46:02.316313 17260 solver.cpp:218] Iteration 47600 (22.1917 iter/s, 4.50618s/100 iters), loss = 0.0138103
I0626 01:46:02.316313 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:02.316313 17260 solver.cpp:237]     Train net output #1: loss = 0.0138101 (* 1 = 0.0138101 loss)
I0626 01:46:02.316313 17260 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I0626 01:46:06.756098 17260 solver.cpp:218] Iteration 47700 (22.5261 iter/s, 4.4393s/100 iters), loss = 0.0183463
I0626 01:46:06.756598 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:46:06.756598 17260 solver.cpp:237]     Train net output #1: loss = 0.0183461 (* 1 = 0.0183461 loss)
I0626 01:46:06.756598 17260 sgd_solver.cpp:105] Iteration 47700, lr = 0.001
I0626 01:46:11.217874 17260 solver.cpp:218] Iteration 47800 (22.4162 iter/s, 4.46107s/100 iters), loss = 0.00275853
I0626 01:46:11.218374 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:11.218374 17260 solver.cpp:237]     Train net output #1: loss = 0.00275838 (* 1 = 0.00275838 loss)
I0626 01:46:11.218374 17260 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I0626 01:46:15.779019 17260 solver.cpp:218] Iteration 47900 (21.9498 iter/s, 4.55584s/100 iters), loss = 0.00537575
I0626 01:46:15.779019 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:15.779019 17260 solver.cpp:237]     Train net output #1: loss = 0.0053756 (* 1 = 0.0053756 loss)
I0626 01:46:15.779019 17260 sgd_solver.cpp:105] Iteration 47900, lr = 0.001
I0626 01:46:20.119429 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:46:20.289551 17260 solver.cpp:330] Iteration 48000, Testing net (#0)
I0626 01:46:20.290051 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:46:21.587993  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:46:21.621016 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9213
I0626 01:46:21.621016 17260 solver.cpp:397]     Test net output #1: loss = 0.293469 (* 1 = 0.293469 loss)
I0626 01:46:21.669550 17260 solver.cpp:218] Iteration 48000 (16.9778 iter/s, 5.89004s/100 iters), loss = 0.0019437
I0626 01:46:21.669550 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:21.669550 17260 solver.cpp:237]     Train net output #1: loss = 0.00194356 (* 1 = 0.00194356 loss)
I0626 01:46:21.669550 17260 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0626 01:46:21.669550 17260 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0626 01:46:26.029188 17260 solver.cpp:218] Iteration 48100 (22.9407 iter/s, 4.35907s/100 iters), loss = 0.0123759
I0626 01:46:26.029188 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:26.029690 17260 solver.cpp:237]     Train net output #1: loss = 0.0123758 (* 1 = 0.0123758 loss)
I0626 01:46:26.029690 17260 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0626 01:46:30.338994 17260 solver.cpp:218] Iteration 48200 (23.2093 iter/s, 4.30862s/100 iters), loss = 0.00603531
I0626 01:46:30.338994 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:30.342996 17260 solver.cpp:237]     Train net output #1: loss = 0.00603517 (* 1 = 0.00603517 loss)
I0626 01:46:30.342996 17260 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0626 01:46:34.682442 17260 solver.cpp:218] Iteration 48300 (23.0655 iter/s, 4.33548s/100 iters), loss = 0.00816037
I0626 01:46:34.683442 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:34.683442 17260 solver.cpp:237]     Train net output #1: loss = 0.00816022 (* 1 = 0.00816022 loss)
I0626 01:46:34.683442 17260 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0626 01:46:39.035506 17260 solver.cpp:218] Iteration 48400 (22.9793 iter/s, 4.35175s/100 iters), loss = 0.00147301
I0626 01:46:39.036006 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:39.036006 17260 solver.cpp:237]     Train net output #1: loss = 0.00147287 (* 1 = 0.00147287 loss)
I0626 01:46:39.036006 17260 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0626 01:46:43.233903 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:46:43.424538 17260 solver.cpp:218] Iteration 48500 (22.7866 iter/s, 4.38855s/100 iters), loss = 0.00403052
I0626 01:46:43.425038 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:43.425038 17260 solver.cpp:237]     Train net output #1: loss = 0.00403038 (* 1 = 0.00403038 loss)
I0626 01:46:43.425038 17260 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0626 01:46:47.852210 17260 solver.cpp:218] Iteration 48600 (22.5869 iter/s, 4.42735s/100 iters), loss = 0.00485435
I0626 01:46:47.852210 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:47.852210 17260 solver.cpp:237]     Train net output #1: loss = 0.00485421 (* 1 = 0.00485421 loss)
I0626 01:46:47.852210 17260 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0626 01:46:52.393602 17260 solver.cpp:218] Iteration 48700 (22.021 iter/s, 4.54113s/100 iters), loss = 0.0151936
I0626 01:46:52.394603 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:46:52.394603 17260 solver.cpp:237]     Train net output #1: loss = 0.0151934 (* 1 = 0.0151934 loss)
I0626 01:46:52.394603 17260 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0626 01:46:56.703470 17260 solver.cpp:218] Iteration 48800 (23.2699 iter/s, 4.2974s/100 iters), loss = 0.00342361
I0626 01:46:56.703470 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:46:56.703470 17260 solver.cpp:237]     Train net output #1: loss = 0.00342347 (* 1 = 0.00342347 loss)
I0626 01:46:56.703470 17260 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0626 01:47:01.032449 17260 solver.cpp:218] Iteration 48900 (23.1039 iter/s, 4.32827s/100 iters), loss = 0.00357599
I0626 01:47:01.032449 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:01.032449 17260 solver.cpp:237]     Train net output #1: loss = 0.00357585 (* 1 = 0.00357585 loss)
I0626 01:47:01.032449 17260 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0626 01:47:05.289791 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:47:05.473423 17260 solver.cpp:330] Iteration 49000, Testing net (#0)
I0626 01:47:05.473423 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:47:06.861927  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:47:06.895951 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9218
I0626 01:47:06.895951 17260 solver.cpp:397]     Test net output #1: loss = 0.292645 (* 1 = 0.292645 loss)
I0626 01:47:06.951491 17260 solver.cpp:218] Iteration 49000 (16.8959 iter/s, 5.91861s/100 iters), loss = 0.00306128
I0626 01:47:06.951491 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:06.951491 17260 solver.cpp:237]     Train net output #1: loss = 0.00306113 (* 1 = 0.00306113 loss)
I0626 01:47:06.951491 17260 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0626 01:47:11.261191 17260 solver.cpp:218] Iteration 49100 (23.2382 iter/s, 4.30327s/100 iters), loss = 0.00676938
I0626 01:47:11.261191 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:11.261191 17260 solver.cpp:237]     Train net output #1: loss = 0.00676923 (* 1 = 0.00676923 loss)
I0626 01:47:11.261191 17260 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0626 01:47:15.731847 17260 solver.cpp:218] Iteration 49200 (22.3711 iter/s, 4.47005s/100 iters), loss = 0.00569032
I0626 01:47:15.731847 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:15.731847 17260 solver.cpp:237]     Train net output #1: loss = 0.00569017 (* 1 = 0.00569017 loss)
I0626 01:47:15.731847 17260 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0626 01:47:20.180366 17260 solver.cpp:218] Iteration 49300 (22.4827 iter/s, 4.44786s/100 iters), loss = 0.00227081
I0626 01:47:20.180366 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:20.180366 17260 solver.cpp:237]     Train net output #1: loss = 0.00227066 (* 1 = 0.00227066 loss)
I0626 01:47:20.180366 17260 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0626 01:47:24.504673 17260 solver.cpp:218] Iteration 49400 (23.1241 iter/s, 4.32449s/100 iters), loss = 0.00242543
I0626 01:47:24.504673 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:24.505674 17260 solver.cpp:237]     Train net output #1: loss = 0.00242528 (* 1 = 0.00242528 loss)
I0626 01:47:24.505674 17260 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0626 01:47:28.512591 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:47:28.721745 17260 solver.cpp:218] Iteration 49500 (23.7191 iter/s, 4.21601s/100 iters), loss = 0.00513258
I0626 01:47:28.721745 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:28.721745 17260 solver.cpp:237]     Train net output #1: loss = 0.00513243 (* 1 = 0.00513243 loss)
I0626 01:47:28.721745 17260 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0626 01:47:33.092455 17260 solver.cpp:218] Iteration 49600 (22.8839 iter/s, 4.36988s/100 iters), loss = 0.00475398
I0626 01:47:33.092455 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:33.092455 17260 solver.cpp:237]     Train net output #1: loss = 0.00475383 (* 1 = 0.00475383 loss)
I0626 01:47:33.092455 17260 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0626 01:47:37.499006 17260 solver.cpp:218] Iteration 49700 (22.6967 iter/s, 4.40592s/100 iters), loss = 0.00419235
I0626 01:47:37.499006 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:37.499006 17260 solver.cpp:237]     Train net output #1: loss = 0.0041922 (* 1 = 0.0041922 loss)
I0626 01:47:37.499006 17260 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0626 01:47:41.792201 17260 solver.cpp:218] Iteration 49800 (23.2946 iter/s, 4.29284s/100 iters), loss = 0.00640378
I0626 01:47:41.792201 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:41.792201 17260 solver.cpp:237]     Train net output #1: loss = 0.00640363 (* 1 = 0.00640363 loss)
I0626 01:47:41.792201 17260 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0626 01:47:46.155002 17260 solver.cpp:218] Iteration 49900 (22.9276 iter/s, 4.36155s/100 iters), loss = 0.00506075
I0626 01:47:46.155002 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:46.155002 17260 solver.cpp:237]     Train net output #1: loss = 0.0050606 (* 1 = 0.0050606 loss)
I0626 01:47:46.155002 17260 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0626 01:47:50.221101 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:47:50.381222 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_50000.caffemodel
I0626 01:47:50.453274 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_50000.solverstate
I0626 01:47:50.497805 17260 solver.cpp:330] Iteration 50000, Testing net (#0)
I0626 01:47:50.497805 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:47:52.005427  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:47:52.036949 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9218
I0626 01:47:52.037451 17260 solver.cpp:397]     Test net output #1: loss = 0.291935 (* 1 = 0.291935 loss)
I0626 01:47:52.097492 17260 solver.cpp:218] Iteration 50000 (16.8301 iter/s, 5.94174s/100 iters), loss = 0.00543911
I0626 01:47:52.097492 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:52.097492 17260 solver.cpp:237]     Train net output #1: loss = 0.00543896 (* 1 = 0.00543896 loss)
I0626 01:47:52.097492 17260 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0626 01:47:56.448479 17260 solver.cpp:218] Iteration 50100 (22.9861 iter/s, 4.35045s/100 iters), loss = 0.00240426
I0626 01:47:56.448479 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:47:56.448479 17260 solver.cpp:237]     Train net output #1: loss = 0.0024041 (* 1 = 0.0024041 loss)
I0626 01:47:56.448479 17260 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0626 01:48:00.882378 17260 solver.cpp:218] Iteration 50200 (22.5561 iter/s, 4.4334s/100 iters), loss = 0.00317661
I0626 01:48:00.882378 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:00.882378 17260 solver.cpp:237]     Train net output #1: loss = 0.00317645 (* 1 = 0.00317645 loss)
I0626 01:48:00.882378 17260 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0626 01:48:05.269384 17260 solver.cpp:218] Iteration 50300 (22.7978 iter/s, 4.3864s/100 iters), loss = 0.00237022
I0626 01:48:05.269384 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:05.269384 17260 solver.cpp:237]     Train net output #1: loss = 0.00237006 (* 1 = 0.00237006 loss)
I0626 01:48:05.269384 17260 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0626 01:48:09.694094 17260 solver.cpp:218] Iteration 50400 (22.6021 iter/s, 4.42436s/100 iters), loss = 0.002763
I0626 01:48:09.694094 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:09.694094 17260 solver.cpp:237]     Train net output #1: loss = 0.00276285 (* 1 = 0.00276285 loss)
I0626 01:48:09.694094 17260 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0626 01:48:13.741292 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:48:13.966452 17260 solver.cpp:218] Iteration 50500 (23.4104 iter/s, 4.27161s/100 iters), loss = 0.00389588
I0626 01:48:13.966452 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:13.966452 17260 solver.cpp:237]     Train net output #1: loss = 0.00389572 (* 1 = 0.00389572 loss)
I0626 01:48:13.966452 17260 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0626 01:48:18.526049 17260 solver.cpp:218] Iteration 50600 (21.9345 iter/s, 4.55902s/100 iters), loss = 0.00289733
I0626 01:48:18.526049 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:18.526049 17260 solver.cpp:237]     Train net output #1: loss = 0.00289718 (* 1 = 0.00289718 loss)
I0626 01:48:18.526049 17260 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0626 01:48:22.829286 17260 solver.cpp:218] Iteration 50700 (23.2412 iter/s, 4.30271s/100 iters), loss = 0.00383687
I0626 01:48:22.829286 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:22.829286 17260 solver.cpp:237]     Train net output #1: loss = 0.00383671 (* 1 = 0.00383671 loss)
I0626 01:48:22.829286 17260 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0626 01:48:27.262230 17260 solver.cpp:218] Iteration 50800 (22.5596 iter/s, 4.43271s/100 iters), loss = 0.00258441
I0626 01:48:27.262230 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:27.262230 17260 solver.cpp:237]     Train net output #1: loss = 0.00258425 (* 1 = 0.00258425 loss)
I0626 01:48:27.262230 17260 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0626 01:48:31.620363 17260 solver.cpp:218] Iteration 50900 (22.9503 iter/s, 4.35724s/100 iters), loss = 0.0114201
I0626 01:48:31.620363 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:48:31.620363 17260 solver.cpp:237]     Train net output #1: loss = 0.0114199 (* 1 = 0.0114199 loss)
I0626 01:48:31.620363 17260 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0626 01:48:35.784909 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:48:35.955531 17260 solver.cpp:330] Iteration 51000, Testing net (#0)
I0626 01:48:35.955531 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:48:37.440093  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:48:37.452602 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9214
I0626 01:48:37.452602 17260 solver.cpp:397]     Test net output #1: loss = 0.291906 (* 1 = 0.291906 loss)
I0626 01:48:37.491130 17260 solver.cpp:218] Iteration 51000 (17.0366 iter/s, 5.86971s/100 iters), loss = 0.003239
I0626 01:48:37.491130 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:37.491130 17260 solver.cpp:237]     Train net output #1: loss = 0.00323884 (* 1 = 0.00323884 loss)
I0626 01:48:37.491130 17260 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0626 01:48:41.856267 17260 solver.cpp:218] Iteration 51100 (22.9112 iter/s, 4.36468s/100 iters), loss = 0.00741782
I0626 01:48:41.856768 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:41.856768 17260 solver.cpp:237]     Train net output #1: loss = 0.00741766 (* 1 = 0.00741766 loss)
I0626 01:48:41.856768 17260 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0626 01:48:46.204028 17260 solver.cpp:218] Iteration 51200 (23.0068 iter/s, 4.34654s/100 iters), loss = 0.00595444
I0626 01:48:46.204028 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:46.204028 17260 solver.cpp:237]     Train net output #1: loss = 0.00595427 (* 1 = 0.00595427 loss)
I0626 01:48:46.204028 17260 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0626 01:48:50.671761 17260 solver.cpp:218] Iteration 51300 (22.4041 iter/s, 4.46347s/100 iters), loss = 0.00313073
I0626 01:48:50.671761 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:50.671761 17260 solver.cpp:237]     Train net output #1: loss = 0.00313057 (* 1 = 0.00313057 loss)
I0626 01:48:50.671761 17260 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0626 01:48:55.008556 17260 solver.cpp:218] Iteration 51400 (23.0607 iter/s, 4.33638s/100 iters), loss = 0.00195097
I0626 01:48:55.009057 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:55.009057 17260 solver.cpp:237]     Train net output #1: loss = 0.00195081 (* 1 = 0.00195081 loss)
I0626 01:48:55.009057 17260 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0626 01:48:59.115267 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:48:59.339330 17260 solver.cpp:218] Iteration 51500 (23.0941 iter/s, 4.33012s/100 iters), loss = 0.00226357
I0626 01:48:59.339330 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:48:59.339330 17260 solver.cpp:237]     Train net output #1: loss = 0.00226341 (* 1 = 0.00226341 loss)
I0626 01:48:59.339330 17260 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0626 01:49:03.629938 17260 solver.cpp:218] Iteration 51600 (23.3099 iter/s, 4.29003s/100 iters), loss = 0.00681968
I0626 01:49:03.629938 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:03.629938 17260 solver.cpp:237]     Train net output #1: loss = 0.00681952 (* 1 = 0.00681952 loss)
I0626 01:49:03.629938 17260 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0626 01:49:07.986884 17260 solver.cpp:218] Iteration 51700 (22.9567 iter/s, 4.35604s/100 iters), loss = 0.00388135
I0626 01:49:07.986884 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:07.986884 17260 solver.cpp:237]     Train net output #1: loss = 0.00388119 (* 1 = 0.00388119 loss)
I0626 01:49:07.986884 17260 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0626 01:49:12.428638 17260 solver.cpp:218] Iteration 51800 (22.515 iter/s, 4.44149s/100 iters), loss = 0.0037479
I0626 01:49:12.429138 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:12.429138 17260 solver.cpp:237]     Train net output #1: loss = 0.00374774 (* 1 = 0.00374774 loss)
I0626 01:49:12.429138 17260 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0626 01:49:16.934774 17260 solver.cpp:218] Iteration 51900 (22.1963 iter/s, 4.50526s/100 iters), loss = 0.00809765
I0626 01:49:16.935274 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:16.935274 17260 solver.cpp:237]     Train net output #1: loss = 0.00809748 (* 1 = 0.00809748 loss)
I0626 01:49:16.935274 17260 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0626 01:49:21.246523 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:49:21.408138 17260 solver.cpp:330] Iteration 52000, Testing net (#0)
I0626 01:49:21.408639 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:49:22.869179  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:49:22.908207 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9213
I0626 01:49:22.908207 17260 solver.cpp:397]     Test net output #1: loss = 0.291941 (* 1 = 0.291941 loss)
I0626 01:49:22.965746 17260 solver.cpp:218] Iteration 52000 (16.5839 iter/s, 6.02996s/100 iters), loss = 0.00336784
I0626 01:49:22.965746 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:22.965746 17260 solver.cpp:237]     Train net output #1: loss = 0.00336768 (* 1 = 0.00336768 loss)
I0626 01:49:22.965746 17260 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0626 01:49:27.432440 17260 solver.cpp:218] Iteration 52100 (22.3893 iter/s, 4.46642s/100 iters), loss = 0.00231058
I0626 01:49:27.432440 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:27.432440 17260 solver.cpp:237]     Train net output #1: loss = 0.00231042 (* 1 = 0.00231042 loss)
I0626 01:49:27.432440 17260 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0626 01:49:31.778167 17260 solver.cpp:218] Iteration 52200 (23.0136 iter/s, 4.34526s/100 iters), loss = 0.024578
I0626 01:49:31.778167 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:49:31.778668 17260 solver.cpp:237]     Train net output #1: loss = 0.0245778 (* 1 = 0.0245778 loss)
I0626 01:49:31.778668 17260 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0626 01:49:36.150494 17260 solver.cpp:218] Iteration 52300 (22.8755 iter/s, 4.37149s/100 iters), loss = 0.00624132
I0626 01:49:36.150494 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:36.150494 17260 solver.cpp:237]     Train net output #1: loss = 0.00624116 (* 1 = 0.00624116 loss)
I0626 01:49:36.150494 17260 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0626 01:49:40.502197 17260 solver.cpp:218] Iteration 52400 (22.9829 iter/s, 4.35105s/100 iters), loss = 0.00362133
I0626 01:49:40.502197 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:40.502197 17260 solver.cpp:237]     Train net output #1: loss = 0.00362116 (* 1 = 0.00362116 loss)
I0626 01:49:40.502197 17260 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0626 01:49:44.675747 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:49:44.881901 17260 solver.cpp:218] Iteration 52500 (22.8338 iter/s, 4.37948s/100 iters), loss = 0.00327226
I0626 01:49:44.882400 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:44.882400 17260 solver.cpp:237]     Train net output #1: loss = 0.0032721 (* 1 = 0.0032721 loss)
I0626 01:49:44.882400 17260 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0626 01:49:49.360865 17260 solver.cpp:218] Iteration 52600 (22.3309 iter/s, 4.4781s/100 iters), loss = 0.00361446
I0626 01:49:49.360865 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:49.360865 17260 solver.cpp:237]     Train net output #1: loss = 0.0036143 (* 1 = 0.0036143 loss)
I0626 01:49:49.360865 17260 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0626 01:49:53.764724 17260 solver.cpp:218] Iteration 52700 (22.7571 iter/s, 4.39422s/100 iters), loss = 0.0139064
I0626 01:49:53.764724 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:53.764724 17260 solver.cpp:237]     Train net output #1: loss = 0.0139063 (* 1 = 0.0139063 loss)
I0626 01:49:53.764724 17260 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0626 01:49:58.197283 17260 solver.cpp:218] Iteration 52800 (22.5631 iter/s, 4.43201s/100 iters), loss = 0.00328788
I0626 01:49:58.197783 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:49:58.197783 17260 solver.cpp:237]     Train net output #1: loss = 0.00328772 (* 1 = 0.00328772 loss)
I0626 01:49:58.197783 17260 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0626 01:50:02.745609 17260 solver.cpp:218] Iteration 52900 (21.9899 iter/s, 4.54754s/100 iters), loss = 0.00157615
I0626 01:50:02.745609 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:02.745609 17260 solver.cpp:237]     Train net output #1: loss = 0.00157599 (* 1 = 0.00157599 loss)
I0626 01:50:02.745609 17260 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0626 01:50:06.871595 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:50:07.060745 17260 solver.cpp:330] Iteration 53000, Testing net (#0)
I0626 01:50:07.060745 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:50:08.461151  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:50:08.491174 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9208
I0626 01:50:08.491174 17260 solver.cpp:397]     Test net output #1: loss = 0.291394 (* 1 = 0.291394 loss)
I0626 01:50:08.542716 17260 solver.cpp:218] Iteration 53000 (17.2906 iter/s, 5.78348s/100 iters), loss = 0.00226302
I0626 01:50:08.542716 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:08.542716 17260 solver.cpp:237]     Train net output #1: loss = 0.00226286 (* 1 = 0.00226286 loss)
I0626 01:50:08.542716 17260 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0626 01:50:12.873858 17260 solver.cpp:218] Iteration 53100 (23.1084 iter/s, 4.32743s/100 iters), loss = 0.00728605
I0626 01:50:12.873858 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:12.873858 17260 solver.cpp:237]     Train net output #1: loss = 0.00728589 (* 1 = 0.00728589 loss)
I0626 01:50:12.873858 17260 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0626 01:50:17.247606 17260 solver.cpp:218] Iteration 53200 (22.8659 iter/s, 4.37333s/100 iters), loss = 0.00501342
I0626 01:50:17.248607 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:17.248607 17260 solver.cpp:237]     Train net output #1: loss = 0.00501325 (* 1 = 0.00501325 loss)
I0626 01:50:17.248607 17260 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0626 01:50:21.606839 17260 solver.cpp:218] Iteration 53300 (22.9521 iter/s, 4.35689s/100 iters), loss = 0.00472949
I0626 01:50:21.606839 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:21.606839 17260 solver.cpp:237]     Train net output #1: loss = 0.00472932 (* 1 = 0.00472932 loss)
I0626 01:50:21.607339 17260 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0626 01:50:25.966032 17260 solver.cpp:218] Iteration 53400 (22.9454 iter/s, 4.35817s/100 iters), loss = 0.00247438
I0626 01:50:25.966032 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:25.966032 17260 solver.cpp:237]     Train net output #1: loss = 0.00247422 (* 1 = 0.00247422 loss)
I0626 01:50:25.966032 17260 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0626 01:50:30.374459 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:50:30.576123 17260 solver.cpp:218] Iteration 53500 (21.6927 iter/s, 4.60984s/100 iters), loss = 0.00473117
I0626 01:50:30.576123 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:30.576123 17260 solver.cpp:237]     Train net output #1: loss = 0.00473101 (* 1 = 0.00473101 loss)
I0626 01:50:30.576123 17260 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0626 01:50:34.819319 17260 solver.cpp:218] Iteration 53600 (23.5723 iter/s, 4.24227s/100 iters), loss = 0.00300772
I0626 01:50:34.819820 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:34.819820 17260 solver.cpp:237]     Train net output #1: loss = 0.00300756 (* 1 = 0.00300756 loss)
I0626 01:50:34.819820 17260 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0626 01:50:39.342384 17260 solver.cpp:218] Iteration 53700 (22.1134 iter/s, 4.52214s/100 iters), loss = 0.00786246
I0626 01:50:39.342384 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:39.342384 17260 solver.cpp:237]     Train net output #1: loss = 0.0078623 (* 1 = 0.0078623 loss)
I0626 01:50:39.342384 17260 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0626 01:50:43.727809 17260 solver.cpp:218] Iteration 53800 (22.806 iter/s, 4.3848s/100 iters), loss = 0.00202707
I0626 01:50:43.727809 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:43.727809 17260 solver.cpp:237]     Train net output #1: loss = 0.0020269 (* 1 = 0.0020269 loss)
I0626 01:50:43.727809 17260 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0626 01:50:48.187235 17260 solver.cpp:218] Iteration 53900 (22.4283 iter/s, 4.45865s/100 iters), loss = 0.00197275
I0626 01:50:48.187235 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:48.187235 17260 solver.cpp:237]     Train net output #1: loss = 0.00197259 (* 1 = 0.00197259 loss)
I0626 01:50:48.187235 17260 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0626 01:50:52.389778 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:50:52.544389 17260 solver.cpp:330] Iteration 54000, Testing net (#0)
I0626 01:50:52.544389 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:50:54.051981  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:50:54.095016 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9213
I0626 01:50:54.095016 17260 solver.cpp:397]     Test net output #1: loss = 0.291668 (* 1 = 0.291668 loss)
I0626 01:50:54.136046 17260 solver.cpp:218] Iteration 54000 (16.8136 iter/s, 5.94758s/100 iters), loss = 0.00269927
I0626 01:50:54.136046 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:54.136046 17260 solver.cpp:237]     Train net output #1: loss = 0.00269911 (* 1 = 0.00269911 loss)
I0626 01:50:54.136046 17260 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 3
I0626 01:50:54.136046 17260 sgd_solver.cpp:105] Iteration 54000, lr = 1e-05
I0626 01:50:58.559808 17260 solver.cpp:218] Iteration 54100 (22.6106 iter/s, 4.4227s/100 iters), loss = 0.00349347
I0626 01:50:58.560307 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:50:58.560307 17260 solver.cpp:237]     Train net output #1: loss = 0.00349331 (* 1 = 0.00349331 loss)
I0626 01:50:58.560307 17260 sgd_solver.cpp:105] Iteration 54100, lr = 1e-05
I0626 01:51:03.013840 17260 solver.cpp:218] Iteration 54200 (22.4544 iter/s, 4.45348s/100 iters), loss = 0.00612152
I0626 01:51:03.014340 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:03.014340 17260 solver.cpp:237]     Train net output #1: loss = 0.00612136 (* 1 = 0.00612136 loss)
I0626 01:51:03.014340 17260 sgd_solver.cpp:105] Iteration 54200, lr = 1e-05
I0626 01:51:07.329560 17260 solver.cpp:218] Iteration 54300 (23.1762 iter/s, 4.31478s/100 iters), loss = 0.00509021
I0626 01:51:07.329560 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:07.329560 17260 solver.cpp:237]     Train net output #1: loss = 0.00509005 (* 1 = 0.00509005 loss)
I0626 01:51:07.329560 17260 sgd_solver.cpp:105] Iteration 54300, lr = 1e-05
I0626 01:51:11.710299 17260 solver.cpp:218] Iteration 54400 (22.8296 iter/s, 4.38028s/100 iters), loss = 0.00316937
I0626 01:51:11.710299 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:11.710299 17260 solver.cpp:237]     Train net output #1: loss = 0.00316921 (* 1 = 0.00316921 loss)
I0626 01:51:11.710299 17260 sgd_solver.cpp:105] Iteration 54400, lr = 1e-05
I0626 01:51:15.898304 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:51:16.106966 17260 solver.cpp:218] Iteration 54500 (22.7488 iter/s, 4.39583s/100 iters), loss = 0.0038127
I0626 01:51:16.106966 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:16.106966 17260 solver.cpp:237]     Train net output #1: loss = 0.00381254 (* 1 = 0.00381254 loss)
I0626 01:51:16.106966 17260 sgd_solver.cpp:105] Iteration 54500, lr = 1e-05
I0626 01:51:20.423419 17260 solver.cpp:218] Iteration 54600 (23.17 iter/s, 4.31593s/100 iters), loss = 0.00831243
I0626 01:51:20.423419 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:20.423419 17260 solver.cpp:237]     Train net output #1: loss = 0.00831227 (* 1 = 0.00831227 loss)
I0626 01:51:20.423419 17260 sgd_solver.cpp:105] Iteration 54600, lr = 1e-05
I0626 01:51:24.736446 17260 solver.cpp:218] Iteration 54700 (23.2125 iter/s, 4.30802s/100 iters), loss = 0.012149
I0626 01:51:24.736446 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:24.736446 17260 solver.cpp:237]     Train net output #1: loss = 0.0121488 (* 1 = 0.0121488 loss)
I0626 01:51:24.736446 17260 sgd_solver.cpp:105] Iteration 54700, lr = 1e-05
I0626 01:51:29.164708 17260 solver.cpp:218] Iteration 54800 (22.5848 iter/s, 4.42775s/100 iters), loss = 0.00300083
I0626 01:51:29.164708 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:29.164708 17260 solver.cpp:237]     Train net output #1: loss = 0.00300067 (* 1 = 0.00300067 loss)
I0626 01:51:29.164708 17260 sgd_solver.cpp:105] Iteration 54800, lr = 1e-05
I0626 01:51:33.490381 17260 solver.cpp:218] Iteration 54900 (23.2017 iter/s, 4.31004s/100 iters), loss = 0.0142453
I0626 01:51:33.490381 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:51:33.490881 17260 solver.cpp:237]     Train net output #1: loss = 0.0142452 (* 1 = 0.0142452 loss)
I0626 01:51:33.490881 17260 sgd_solver.cpp:105] Iteration 54900, lr = 1e-05
I0626 01:51:37.656224 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:51:37.841855 17260 solver.cpp:330] Iteration 55000, Testing net (#0)
I0626 01:51:37.841855 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:51:39.208462  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:51:39.254667 17260 solver.cpp:397]     Test net output #0: accuracy = 0.921
I0626 01:51:39.254667 17260 solver.cpp:397]     Test net output #1: loss = 0.291753 (* 1 = 0.291753 loss)
I0626 01:51:39.292696 17260 solver.cpp:218] Iteration 55000 (17.2362 iter/s, 5.80175s/100 iters), loss = 0.00443567
I0626 01:51:39.292696 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:39.292696 17260 solver.cpp:237]     Train net output #1: loss = 0.00443552 (* 1 = 0.00443552 loss)
I0626 01:51:39.292696 17260 sgd_solver.cpp:105] Iteration 55000, lr = 1e-05
I0626 01:51:43.895553 17260 solver.cpp:218] Iteration 55100 (21.7318 iter/s, 4.60156s/100 iters), loss = 0.00707207
I0626 01:51:43.895553 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:43.895553 17260 solver.cpp:237]     Train net output #1: loss = 0.00707191 (* 1 = 0.00707191 loss)
I0626 01:51:43.895553 17260 sgd_solver.cpp:105] Iteration 55100, lr = 1e-05
I0626 01:51:48.379885 17260 solver.cpp:218] Iteration 55200 (22.3022 iter/s, 4.48386s/100 iters), loss = 0.00188552
I0626 01:51:48.379885 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:48.379885 17260 solver.cpp:237]     Train net output #1: loss = 0.00188536 (* 1 = 0.00188536 loss)
I0626 01:51:48.379885 17260 sgd_solver.cpp:105] Iteration 55200, lr = 1e-05
I0626 01:51:52.861243 17260 solver.cpp:218] Iteration 55300 (22.3165 iter/s, 4.481s/100 iters), loss = 0.00530822
I0626 01:51:52.861243 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:52.861243 17260 solver.cpp:237]     Train net output #1: loss = 0.00530806 (* 1 = 0.00530806 loss)
I0626 01:51:52.861243 17260 sgd_solver.cpp:105] Iteration 55300, lr = 1e-05
I0626 01:51:57.189395 17260 solver.cpp:218] Iteration 55400 (23.2169 iter/s, 4.30721s/100 iters), loss = 0.00276021
I0626 01:51:57.189395 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:51:57.189395 17260 solver.cpp:237]     Train net output #1: loss = 0.00276005 (* 1 = 0.00276005 loss)
I0626 01:51:57.189395 17260 sgd_solver.cpp:105] Iteration 55400, lr = 1e-05
I0626 01:52:01.540731 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:52:01.744876 17260 solver.cpp:218] Iteration 55500 (21.9544 iter/s, 4.55489s/100 iters), loss = 0.0058312
I0626 01:52:01.744876 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:01.744876 17260 solver.cpp:237]     Train net output #1: loss = 0.00583103 (* 1 = 0.00583103 loss)
I0626 01:52:01.744876 17260 sgd_solver.cpp:105] Iteration 55500, lr = 1e-05
I0626 01:52:06.170444 17260 solver.cpp:218] Iteration 55600 (22.5969 iter/s, 4.42538s/100 iters), loss = 0.00865902
I0626 01:52:06.170944 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:06.170944 17260 solver.cpp:237]     Train net output #1: loss = 0.00865885 (* 1 = 0.00865885 loss)
I0626 01:52:06.170944 17260 sgd_solver.cpp:105] Iteration 55600, lr = 1e-05
I0626 01:52:10.476552 17260 solver.cpp:218] Iteration 55700 (23.2503 iter/s, 4.30103s/100 iters), loss = 0.00524121
I0626 01:52:10.476552 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:10.477052 17260 solver.cpp:237]     Train net output #1: loss = 0.00524105 (* 1 = 0.00524105 loss)
I0626 01:52:10.477052 17260 sgd_solver.cpp:105] Iteration 55700, lr = 1e-05
I0626 01:52:14.990016 17260 solver.cpp:218] Iteration 55800 (22.1602 iter/s, 4.51259s/100 iters), loss = 0.00582596
I0626 01:52:14.990016 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:14.990016 17260 solver.cpp:237]     Train net output #1: loss = 0.0058258 (* 1 = 0.0058258 loss)
I0626 01:52:14.990016 17260 sgd_solver.cpp:105] Iteration 55800, lr = 1e-05
I0626 01:52:19.523924 17260 solver.cpp:218] Iteration 55900 (22.0579 iter/s, 4.53353s/100 iters), loss = 0.00216873
I0626 01:52:19.523924 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:19.523924 17260 solver.cpp:237]     Train net output #1: loss = 0.00216857 (* 1 = 0.00216857 loss)
I0626 01:52:19.523924 17260 sgd_solver.cpp:105] Iteration 55900, lr = 1e-05
I0626 01:52:23.705003 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:52:23.878628 17260 solver.cpp:330] Iteration 56000, Testing net (#0)
I0626 01:52:23.878628 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:52:25.300643  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:52:25.341172 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9207
I0626 01:52:25.341672 17260 solver.cpp:397]     Test net output #1: loss = 0.291686 (* 1 = 0.291686 loss)
I0626 01:52:25.380199 17260 solver.cpp:218] Iteration 56000 (17.0778 iter/s, 5.85556s/100 iters), loss = 0.00265393
I0626 01:52:25.380199 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:25.380199 17260 solver.cpp:237]     Train net output #1: loss = 0.00265376 (* 1 = 0.00265376 loss)
I0626 01:52:25.380199 17260 sgd_solver.cpp:105] Iteration 56000, lr = 1e-05
I0626 01:52:29.680271 17260 solver.cpp:218] Iteration 56100 (23.2577 iter/s, 4.29965s/100 iters), loss = 0.0152342
I0626 01:52:29.680271 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:52:29.680771 17260 solver.cpp:237]     Train net output #1: loss = 0.0152341 (* 1 = 0.0152341 loss)
I0626 01:52:29.680771 17260 sgd_solver.cpp:105] Iteration 56100, lr = 1e-05
I0626 01:52:34.044562 17260 solver.cpp:218] Iteration 56200 (22.9177 iter/s, 4.36343s/100 iters), loss = 0.00367733
I0626 01:52:34.044562 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:34.044562 17260 solver.cpp:237]     Train net output #1: loss = 0.00367717 (* 1 = 0.00367717 loss)
I0626 01:52:34.044562 17260 sgd_solver.cpp:105] Iteration 56200, lr = 1e-05
I0626 01:52:38.460855 17260 solver.cpp:218] Iteration 56300 (22.6451 iter/s, 4.41596s/100 iters), loss = 0.00445412
I0626 01:52:38.461355 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:38.461355 17260 solver.cpp:237]     Train net output #1: loss = 0.00445396 (* 1 = 0.00445396 loss)
I0626 01:52:38.461355 17260 sgd_solver.cpp:105] Iteration 56300, lr = 1e-05
I0626 01:52:42.803095 17260 solver.cpp:218] Iteration 56400 (23.0346 iter/s, 4.3413s/100 iters), loss = 0.00158999
I0626 01:52:42.803095 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:42.803095 17260 solver.cpp:237]     Train net output #1: loss = 0.00158983 (* 1 = 0.00158983 loss)
I0626 01:52:42.803095 17260 sgd_solver.cpp:105] Iteration 56400, lr = 1e-05
I0626 01:52:46.928565 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:52:47.146728 17260 solver.cpp:218] Iteration 56500 (23.0707 iter/s, 4.33451s/100 iters), loss = 0.0150684
I0626 01:52:47.146728 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:52:47.146728 17260 solver.cpp:237]     Train net output #1: loss = 0.0150682 (* 1 = 0.0150682 loss)
I0626 01:52:47.146728 17260 sgd_solver.cpp:105] Iteration 56500, lr = 1e-05
I0626 01:52:51.497344 17260 solver.cpp:218] Iteration 56600 (22.9899 iter/s, 4.34974s/100 iters), loss = 0.00205454
I0626 01:52:51.497344 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:51.497344 17260 solver.cpp:237]     Train net output #1: loss = 0.00205438 (* 1 = 0.00205438 loss)
I0626 01:52:51.497344 17260 sgd_solver.cpp:105] Iteration 56600, lr = 1e-05
I0626 01:52:55.732755 17260 solver.cpp:218] Iteration 56700 (23.6129 iter/s, 4.23498s/100 iters), loss = 0.00504938
I0626 01:52:55.732755 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:52:55.732755 17260 solver.cpp:237]     Train net output #1: loss = 0.00504921 (* 1 = 0.00504921 loss)
I0626 01:52:55.732755 17260 sgd_solver.cpp:105] Iteration 56700, lr = 1e-05
I0626 01:53:00.096560 17260 solver.cpp:218] Iteration 56800 (22.9197 iter/s, 4.36306s/100 iters), loss = 0.0109353
I0626 01:53:00.096560 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:00.097060 17260 solver.cpp:237]     Train net output #1: loss = 0.0109351 (* 1 = 0.0109351 loss)
I0626 01:53:00.097060 17260 sgd_solver.cpp:105] Iteration 56800, lr = 1e-05
I0626 01:53:04.501032 17260 solver.cpp:218] Iteration 56900 (22.7127 iter/s, 4.40281s/100 iters), loss = 0.00374305
I0626 01:53:04.501533 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:04.501533 17260 solver.cpp:237]     Train net output #1: loss = 0.00374288 (* 1 = 0.00374288 loss)
I0626 01:53:04.501533 17260 sgd_solver.cpp:105] Iteration 56900, lr = 1e-05
I0626 01:53:08.699072 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:53:08.840673 17260 solver.cpp:330] Iteration 57000, Testing net (#0)
I0626 01:53:08.840673 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:53:10.169117  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:53:10.231662 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9211
I0626 01:53:10.231662 17260 solver.cpp:397]     Test net output #1: loss = 0.291901 (* 1 = 0.291901 loss)
I0626 01:53:10.269189 17260 solver.cpp:218] Iteration 57000 (17.3396 iter/s, 5.76714s/100 iters), loss = 0.00434303
I0626 01:53:10.269189 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:10.269189 17260 solver.cpp:237]     Train net output #1: loss = 0.00434286 (* 1 = 0.00434286 loss)
I0626 01:53:10.269189 17260 sgd_solver.cpp:105] Iteration 57000, lr = 1e-05
I0626 01:53:14.681430 17260 solver.cpp:218] Iteration 57100 (22.6662 iter/s, 4.41185s/100 iters), loss = 0.00341635
I0626 01:53:14.681430 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:14.681430 17260 solver.cpp:237]     Train net output #1: loss = 0.00341618 (* 1 = 0.00341618 loss)
I0626 01:53:14.681430 17260 sgd_solver.cpp:105] Iteration 57100, lr = 1e-05
I0626 01:53:19.194810 17260 solver.cpp:218] Iteration 57200 (22.1586 iter/s, 4.51292s/100 iters), loss = 0.00409255
I0626 01:53:19.195312 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:19.195312 17260 solver.cpp:237]     Train net output #1: loss = 0.00409238 (* 1 = 0.00409238 loss)
I0626 01:53:19.195312 17260 sgd_solver.cpp:105] Iteration 57200, lr = 1e-05
I0626 01:53:23.571717 17260 solver.cpp:218] Iteration 57300 (22.85 iter/s, 4.37636s/100 iters), loss = 0.00784961
I0626 01:53:23.571717 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:23.571717 17260 solver.cpp:237]     Train net output #1: loss = 0.00784945 (* 1 = 0.00784945 loss)
I0626 01:53:23.571717 17260 sgd_solver.cpp:105] Iteration 57300, lr = 1e-05
I0626 01:53:28.098548 17260 solver.cpp:218] Iteration 57400 (22.1591 iter/s, 4.51281s/100 iters), loss = 0.00350945
I0626 01:53:28.098548 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:28.098548 17260 solver.cpp:237]     Train net output #1: loss = 0.00350928 (* 1 = 0.00350928 loss)
I0626 01:53:28.098548 17260 sgd_solver.cpp:105] Iteration 57400, lr = 1e-05
I0626 01:53:32.283558 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:53:32.440170 17260 solver.cpp:218] Iteration 57500 (23.0593 iter/s, 4.33664s/100 iters), loss = 0.00457116
I0626 01:53:32.440170 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:32.440170 17260 solver.cpp:237]     Train net output #1: loss = 0.00457099 (* 1 = 0.00457099 loss)
I0626 01:53:32.440170 17260 sgd_solver.cpp:105] Iteration 57500, lr = 1e-05
I0626 01:53:36.810358 17260 solver.cpp:218] Iteration 57600 (22.8846 iter/s, 4.36975s/100 iters), loss = 0.00395952
I0626 01:53:36.810358 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:36.810358 17260 solver.cpp:237]     Train net output #1: loss = 0.00395935 (* 1 = 0.00395935 loss)
I0626 01:53:36.810358 17260 sgd_solver.cpp:105] Iteration 57600, lr = 1e-05
I0626 01:53:41.287920 17260 solver.cpp:218] Iteration 57700 (22.3375 iter/s, 4.47677s/100 iters), loss = 0.00355809
I0626 01:53:41.287920 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:41.288421 17260 solver.cpp:237]     Train net output #1: loss = 0.00355792 (* 1 = 0.00355792 loss)
I0626 01:53:41.288421 17260 sgd_solver.cpp:105] Iteration 57700, lr = 1e-05
I0626 01:53:45.796720 17260 solver.cpp:218] Iteration 57800 (22.1851 iter/s, 4.50754s/100 iters), loss = 0.00404096
I0626 01:53:45.796720 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:45.796720 17260 solver.cpp:237]     Train net output #1: loss = 0.00404079 (* 1 = 0.00404079 loss)
I0626 01:53:45.796720 17260 sgd_solver.cpp:105] Iteration 57800, lr = 1e-05
I0626 01:53:50.266993 17260 solver.cpp:218] Iteration 57900 (22.3724 iter/s, 4.46978s/100 iters), loss = 0.00389095
I0626 01:53:50.266993 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:50.266993 17260 solver.cpp:237]     Train net output #1: loss = 0.00389078 (* 1 = 0.00389078 loss)
I0626 01:53:50.266993 17260 sgd_solver.cpp:105] Iteration 57900, lr = 1e-05
I0626 01:53:54.485520 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:53:54.684161 17260 solver.cpp:330] Iteration 58000, Testing net (#0)
I0626 01:53:54.684662 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:53:56.091295  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:53:56.106303 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9208
I0626 01:53:56.106303 17260 solver.cpp:397]     Test net output #1: loss = 0.292055 (* 1 = 0.292055 loss)
I0626 01:53:56.160845 17260 solver.cpp:218] Iteration 58000 (16.9684 iter/s, 5.89331s/100 iters), loss = 0.00661966
I0626 01:53:56.160845 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:53:56.160845 17260 solver.cpp:237]     Train net output #1: loss = 0.0066195 (* 1 = 0.0066195 loss)
I0626 01:53:56.160845 17260 sgd_solver.cpp:105] Iteration 58000, lr = 1e-05
I0626 01:54:02.767204 17260 solver.cpp:218] Iteration 58100 (15.1382 iter/s, 6.60581s/100 iters), loss = 0.00811107
I0626 01:54:02.767704 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:02.767704 17260 solver.cpp:237]     Train net output #1: loss = 0.00811091 (* 1 = 0.00811091 loss)
I0626 01:54:02.767704 17260 sgd_solver.cpp:105] Iteration 58100, lr = 1e-05
I0626 01:54:07.670464 17260 solver.cpp:218] Iteration 58200 (20.3985 iter/s, 4.90233s/100 iters), loss = 0.0068768
I0626 01:54:07.670464 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:07.670965 17260 solver.cpp:237]     Train net output #1: loss = 0.00687664 (* 1 = 0.00687664 loss)
I0626 01:54:07.670965 17260 sgd_solver.cpp:105] Iteration 58200, lr = 1e-05
I0626 01:54:12.218796 17260 solver.cpp:218] Iteration 58300 (21.9906 iter/s, 4.54739s/100 iters), loss = 0.00223571
I0626 01:54:12.218796 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:12.218796 17260 solver.cpp:237]     Train net output #1: loss = 0.00223555 (* 1 = 0.00223555 loss)
I0626 01:54:12.218796 17260 sgd_solver.cpp:105] Iteration 58300, lr = 1e-05
I0626 01:54:16.708470 17260 solver.cpp:218] Iteration 58400 (22.2749 iter/s, 4.48935s/100 iters), loss = 0.00217357
I0626 01:54:16.708470 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:16.708971 17260 solver.cpp:237]     Train net output #1: loss = 0.00217341 (* 1 = 0.00217341 loss)
I0626 01:54:16.708971 17260 sgd_solver.cpp:105] Iteration 58400, lr = 1e-05
I0626 01:54:20.970460 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:54:21.216135 17260 solver.cpp:218] Iteration 58500 (22.1873 iter/s, 4.50709s/100 iters), loss = 0.0046156
I0626 01:54:21.216635 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:21.216635 17260 solver.cpp:237]     Train net output #1: loss = 0.00461545 (* 1 = 0.00461545 loss)
I0626 01:54:21.216635 17260 sgd_solver.cpp:105] Iteration 58500, lr = 1e-05
I0626 01:54:25.657115 17260 solver.cpp:218] Iteration 58600 (22.5225 iter/s, 4.44001s/100 iters), loss = 0.00208364
I0626 01:54:25.657614 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:25.657614 17260 solver.cpp:237]     Train net output #1: loss = 0.00208349 (* 1 = 0.00208349 loss)
I0626 01:54:25.657614 17260 sgd_solver.cpp:105] Iteration 58600, lr = 1e-05
I0626 01:54:30.177474 17260 solver.cpp:218] Iteration 58700 (22.127 iter/s, 4.51937s/100 iters), loss = 0.00342046
I0626 01:54:30.177474 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:30.177474 17260 solver.cpp:237]     Train net output #1: loss = 0.0034203 (* 1 = 0.0034203 loss)
I0626 01:54:30.177474 17260 sgd_solver.cpp:105] Iteration 58700, lr = 1e-05
I0626 01:54:34.520486 17260 solver.cpp:218] Iteration 58800 (23.0317 iter/s, 4.34185s/100 iters), loss = 0.00312469
I0626 01:54:34.520486 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:34.520486 17260 solver.cpp:237]     Train net output #1: loss = 0.00312453 (* 1 = 0.00312453 loss)
I0626 01:54:34.520486 17260 sgd_solver.cpp:105] Iteration 58800, lr = 1e-05
I0626 01:54:38.916610 17260 solver.cpp:218] Iteration 58900 (22.7594 iter/s, 4.39379s/100 iters), loss = 0.00921027
I0626 01:54:38.916610 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:38.916610 17260 solver.cpp:237]     Train net output #1: loss = 0.00921011 (* 1 = 0.00921011 loss)
I0626 01:54:38.916610 17260 sgd_solver.cpp:105] Iteration 58900, lr = 1e-05
I0626 01:54:43.117688 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:54:43.277305 17260 solver.cpp:330] Iteration 59000, Testing net (#0)
I0626 01:54:43.277305 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:54:44.770617  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:54:44.815649 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9212
I0626 01:54:44.815649 17260 solver.cpp:397]     Test net output #1: loss = 0.291521 (* 1 = 0.291521 loss)
I0626 01:54:44.855178 17260 solver.cpp:218] Iteration 59000 (16.8406 iter/s, 5.93803s/100 iters), loss = 0.00672981
I0626 01:54:44.855178 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:44.855178 17260 solver.cpp:237]     Train net output #1: loss = 0.00672964 (* 1 = 0.00672964 loss)
I0626 01:54:44.855178 17260 sgd_solver.cpp:105] Iteration 59000, lr = 1e-05
I0626 01:54:49.142084 17260 solver.cpp:218] Iteration 59100 (23.3264 iter/s, 4.28698s/100 iters), loss = 0.00326488
I0626 01:54:49.143085 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:49.143085 17260 solver.cpp:237]     Train net output #1: loss = 0.00326471 (* 1 = 0.00326471 loss)
I0626 01:54:49.143085 17260 sgd_solver.cpp:105] Iteration 59100, lr = 1e-05
I0626 01:54:53.488737 17260 solver.cpp:218] Iteration 59200 (23.0838 iter/s, 4.33204s/100 iters), loss = 0.0065199
I0626 01:54:53.489738 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:53.489738 17260 solver.cpp:237]     Train net output #1: loss = 0.00651973 (* 1 = 0.00651973 loss)
I0626 01:54:53.489738 17260 sgd_solver.cpp:105] Iteration 59200, lr = 1e-05
I0626 01:54:57.933300 17260 solver.cpp:218] Iteration 59300 (22.5021 iter/s, 4.44403s/100 iters), loss = 0.00375187
I0626 01:54:57.934300 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:54:57.934300 17260 solver.cpp:237]     Train net output #1: loss = 0.00375171 (* 1 = 0.00375171 loss)
I0626 01:54:57.934300 17260 sgd_solver.cpp:105] Iteration 59300, lr = 1e-05
I0626 01:55:02.384500 17260 solver.cpp:218] Iteration 59400 (22.4742 iter/s, 4.44955s/100 iters), loss = 0.00820042
I0626 01:55:02.384500 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:02.384500 17260 solver.cpp:237]     Train net output #1: loss = 0.00820026 (* 1 = 0.00820026 loss)
I0626 01:55:02.384500 17260 sgd_solver.cpp:105] Iteration 59400, lr = 1e-05
I0626 01:55:06.559576 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:55:06.757216 17260 solver.cpp:218] Iteration 59500 (22.8711 iter/s, 4.37233s/100 iters), loss = 0.0053777
I0626 01:55:06.757216 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:06.757216 17260 solver.cpp:237]     Train net output #1: loss = 0.00537753 (* 1 = 0.00537753 loss)
I0626 01:55:06.757216 17260 sgd_solver.cpp:105] Iteration 59500, lr = 1e-05
I0626 01:55:11.137205 17260 solver.cpp:218] Iteration 59600 (22.8331 iter/s, 4.37961s/100 iters), loss = 0.00745185
I0626 01:55:11.137205 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:11.137205 17260 solver.cpp:237]     Train net output #1: loss = 0.00745169 (* 1 = 0.00745169 loss)
I0626 01:55:11.137205 17260 sgd_solver.cpp:105] Iteration 59600, lr = 1e-05
I0626 01:55:15.544090 17260 solver.cpp:218] Iteration 59700 (22.7411 iter/s, 4.39732s/100 iters), loss = 0.00369071
I0626 01:55:15.544589 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:15.544589 17260 solver.cpp:237]     Train net output #1: loss = 0.00369054 (* 1 = 0.00369054 loss)
I0626 01:55:15.544589 17260 sgd_solver.cpp:105] Iteration 59700, lr = 1e-05
I0626 01:55:19.967877 17260 solver.cpp:218] Iteration 59800 (22.6092 iter/s, 4.42297s/100 iters), loss = 0.00586237
I0626 01:55:19.967877 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:19.967877 17260 solver.cpp:237]     Train net output #1: loss = 0.0058622 (* 1 = 0.0058622 loss)
I0626 01:55:19.967877 17260 sgd_solver.cpp:105] Iteration 59800, lr = 1e-05
I0626 01:55:24.397696 17260 solver.cpp:218] Iteration 59900 (22.5794 iter/s, 4.42881s/100 iters), loss = 0.00390398
I0626 01:55:24.397696 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:24.397696 17260 solver.cpp:237]     Train net output #1: loss = 0.00390382 (* 1 = 0.00390382 loss)
I0626 01:55:24.397696 17260 sgd_solver.cpp:105] Iteration 59900, lr = 1e-05
I0626 01:55:28.590488 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:55:28.762610 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_60000.caffemodel
I0626 01:55:28.828657 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_60000.solverstate
I0626 01:55:28.852175 17260 solver.cpp:330] Iteration 60000, Testing net (#0)
I0626 01:55:28.852175 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:55:30.345289  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:55:30.375313 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9212
I0626 01:55:30.375313 17260 solver.cpp:397]     Test net output #1: loss = 0.291486 (* 1 = 0.291486 loss)
I0626 01:55:30.417843 17260 solver.cpp:218] Iteration 60000 (16.6111 iter/s, 6.02008s/100 iters), loss = 0.00385996
I0626 01:55:30.417843 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:30.417843 17260 solver.cpp:237]     Train net output #1: loss = 0.00385979 (* 1 = 0.00385979 loss)
I0626 01:55:30.417843 17260 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0626 01:55:34.797598 17260 solver.cpp:218] Iteration 60100 (22.8368 iter/s, 4.3789s/100 iters), loss = 0.00437863
I0626 01:55:34.798099 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:34.798099 17260 solver.cpp:237]     Train net output #1: loss = 0.00437847 (* 1 = 0.00437847 loss)
I0626 01:55:34.798099 17260 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0626 01:55:39.245978 17260 solver.cpp:218] Iteration 60200 (22.4846 iter/s, 4.44748s/100 iters), loss = 0.00789929
I0626 01:55:39.245978 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:39.245978 17260 solver.cpp:237]     Train net output #1: loss = 0.00789913 (* 1 = 0.00789913 loss)
I0626 01:55:39.245978 17260 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0626 01:55:43.574677 17260 solver.cpp:218] Iteration 60300 (23.1029 iter/s, 4.32846s/100 iters), loss = 0.00303503
I0626 01:55:43.574677 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:43.574677 17260 solver.cpp:237]     Train net output #1: loss = 0.00303487 (* 1 = 0.00303487 loss)
I0626 01:55:43.575178 17260 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0626 01:55:47.911501 17260 solver.cpp:218] Iteration 60400 (23.0612 iter/s, 4.3363s/100 iters), loss = 0.00259448
I0626 01:55:47.912003 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:47.912003 17260 solver.cpp:237]     Train net output #1: loss = 0.00259432 (* 1 = 0.00259432 loss)
I0626 01:55:47.912003 17260 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0626 01:55:52.092628 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:55:52.294780 17260 solver.cpp:218] Iteration 60500 (22.8358 iter/s, 4.37908s/100 iters), loss = 0.00282322
I0626 01:55:52.295279 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:52.295279 17260 solver.cpp:237]     Train net output #1: loss = 0.00282306 (* 1 = 0.00282306 loss)
I0626 01:55:52.295279 17260 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0626 01:55:56.707792 17260 solver.cpp:218] Iteration 60600 (22.7584 iter/s, 4.39398s/100 iters), loss = 0.00459267
I0626 01:55:56.708793 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:55:56.708793 17260 solver.cpp:237]     Train net output #1: loss = 0.00459251 (* 1 = 0.00459251 loss)
I0626 01:55:56.708793 17260 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0626 01:56:01.074501 17260 solver.cpp:218] Iteration 60700 (22.9088 iter/s, 4.36514s/100 iters), loss = 0.0217254
I0626 01:56:01.074501 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:56:01.074501 17260 solver.cpp:237]     Train net output #1: loss = 0.0217252 (* 1 = 0.0217252 loss)
I0626 01:56:01.074501 17260 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0626 01:56:05.415050 17260 solver.cpp:218] Iteration 60800 (23.0417 iter/s, 4.33995s/100 iters), loss = 0.00280744
I0626 01:56:05.415050 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:05.415050 17260 solver.cpp:237]     Train net output #1: loss = 0.00280729 (* 1 = 0.00280729 loss)
I0626 01:56:05.415050 17260 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0626 01:56:09.685631 17260 solver.cpp:218] Iteration 60900 (23.4171 iter/s, 4.27038s/100 iters), loss = 0.00241561
I0626 01:56:09.686132 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:09.686132 17260 solver.cpp:237]     Train net output #1: loss = 0.00241545 (* 1 = 0.00241545 loss)
I0626 01:56:09.686132 17260 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0626 01:56:13.877513 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:56:14.055143 17260 solver.cpp:330] Iteration 61000, Testing net (#0)
I0626 01:56:14.055143 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:56:15.538358  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:56:15.578887 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9212
I0626 01:56:15.578887 17260 solver.cpp:397]     Test net output #1: loss = 0.291588 (* 1 = 0.291588 loss)
I0626 01:56:15.623420 17260 solver.cpp:218] Iteration 61000 (16.8443 iter/s, 5.93672s/100 iters), loss = 0.00343809
I0626 01:56:15.623420 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:15.623420 17260 solver.cpp:237]     Train net output #1: loss = 0.00343793 (* 1 = 0.00343793 loss)
I0626 01:56:15.623420 17260 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0626 01:56:20.102973 17260 solver.cpp:218] Iteration 61100 (22.3336 iter/s, 4.47756s/100 iters), loss = 0.00249942
I0626 01:56:20.102973 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:20.102973 17260 solver.cpp:237]     Train net output #1: loss = 0.00249927 (* 1 = 0.00249927 loss)
I0626 01:56:20.102973 17260 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0626 01:56:24.840159 17260 solver.cpp:218] Iteration 61200 (21.1194 iter/s, 4.73498s/100 iters), loss = 0.0048548
I0626 01:56:24.840159 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:24.840159 17260 solver.cpp:237]     Train net output #1: loss = 0.00485465 (* 1 = 0.00485465 loss)
I0626 01:56:24.840159 17260 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0626 01:56:29.261348 17260 solver.cpp:218] Iteration 61300 (22.6212 iter/s, 4.42063s/100 iters), loss = 0.00389772
I0626 01:56:29.261348 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:29.261348 17260 solver.cpp:237]     Train net output #1: loss = 0.00389756 (* 1 = 0.00389756 loss)
I0626 01:56:29.261348 17260 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0626 01:56:33.777884 17260 solver.cpp:218] Iteration 61400 (22.1575 iter/s, 4.51315s/100 iters), loss = 0.00438505
I0626 01:56:33.777884 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:33.777884 17260 solver.cpp:237]     Train net output #1: loss = 0.0043849 (* 1 = 0.0043849 loss)
I0626 01:56:33.777884 17260 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0626 01:56:38.230147 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:56:38.451813 17260 solver.cpp:218] Iteration 61500 (21.4417 iter/s, 4.6638s/100 iters), loss = 0.00320074
I0626 01:56:38.451813 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:38.451813 17260 solver.cpp:237]     Train net output #1: loss = 0.00320059 (* 1 = 0.00320059 loss)
I0626 01:56:38.451813 17260 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0626 01:56:42.955121 17260 solver.cpp:218] Iteration 61600 (22.209 iter/s, 4.50268s/100 iters), loss = 0.00741881
I0626 01:56:42.955121 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:42.955121 17260 solver.cpp:237]     Train net output #1: loss = 0.00741866 (* 1 = 0.00741866 loss)
I0626 01:56:42.955121 17260 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0626 01:56:47.505434 17260 solver.cpp:218] Iteration 61700 (21.9841 iter/s, 4.54874s/100 iters), loss = 0.0260587
I0626 01:56:47.505434 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:56:47.505434 17260 solver.cpp:237]     Train net output #1: loss = 0.0260585 (* 1 = 0.0260585 loss)
I0626 01:56:47.505434 17260 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0626 01:56:52.009708 17260 solver.cpp:218] Iteration 61800 (22.2058 iter/s, 4.50333s/100 iters), loss = 0.00605773
I0626 01:56:52.009708 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:52.009708 17260 solver.cpp:237]     Train net output #1: loss = 0.00605758 (* 1 = 0.00605758 loss)
I0626 01:56:52.009708 17260 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0626 01:56:56.432510 17260 solver.cpp:218] Iteration 61900 (22.6141 iter/s, 4.42202s/100 iters), loss = 0.00453721
I0626 01:56:56.432510 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:56:56.432510 17260 solver.cpp:237]     Train net output #1: loss = 0.00453707 (* 1 = 0.00453707 loss)
I0626 01:56:56.432510 17260 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0626 01:57:00.667898 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:57:00.838021 17260 solver.cpp:330] Iteration 62000, Testing net (#0)
I0626 01:57:00.838021 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:57:02.395628  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:57:02.430654 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9212
I0626 01:57:02.431154 17260 solver.cpp:397]     Test net output #1: loss = 0.291798 (* 1 = 0.291798 loss)
I0626 01:57:02.470181 17260 solver.cpp:218] Iteration 62000 (16.5648 iter/s, 6.03688s/100 iters), loss = 0.00728951
I0626 01:57:02.470181 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:02.470181 17260 solver.cpp:237]     Train net output #1: loss = 0.00728936 (* 1 = 0.00728936 loss)
I0626 01:57:02.470181 17260 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0626 01:57:08.155249 17260 solver.cpp:218] Iteration 62100 (17.5914 iter/s, 5.68459s/100 iters), loss = 0.00445067
I0626 01:57:08.155750 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:08.155750 17260 solver.cpp:237]     Train net output #1: loss = 0.00445052 (* 1 = 0.00445052 loss)
I0626 01:57:08.155750 17260 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0626 01:57:14.509771 17260 solver.cpp:218] Iteration 62200 (15.766 iter/s, 6.34276s/100 iters), loss = 0.00539041
I0626 01:57:14.510272 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:14.510272 17260 solver.cpp:237]     Train net output #1: loss = 0.00539026 (* 1 = 0.00539026 loss)
I0626 01:57:14.510272 17260 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0626 01:57:21.272821 17260 solver.cpp:218] Iteration 62300 (14.8356 iter/s, 6.74053s/100 iters), loss = 0.00422379
I0626 01:57:21.272821 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:21.272821 17260 solver.cpp:237]     Train net output #1: loss = 0.00422364 (* 1 = 0.00422364 loss)
I0626 01:57:21.272821 17260 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0626 01:57:27.433712 17260 solver.cpp:218] Iteration 62400 (16.2884 iter/s, 6.13932s/100 iters), loss = 0.00281085
I0626 01:57:27.433712 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:27.433712 17260 solver.cpp:237]     Train net output #1: loss = 0.0028107 (* 1 = 0.0028107 loss)
I0626 01:57:27.433712 17260 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0626 01:57:32.218212 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:57:32.421356 17260 solver.cpp:218] Iteration 62500 (20.0519 iter/s, 4.98706s/100 iters), loss = 0.00471418
I0626 01:57:32.421356 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:32.421356 17260 solver.cpp:237]     Train net output #1: loss = 0.00471404 (* 1 = 0.00471404 loss)
I0626 01:57:32.421356 17260 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0626 01:57:36.839563 17260 solver.cpp:218] Iteration 62600 (22.6372 iter/s, 4.41752s/100 iters), loss = 0.00363993
I0626 01:57:36.839563 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:36.839563 17260 solver.cpp:237]     Train net output #1: loss = 0.00363978 (* 1 = 0.00363978 loss)
I0626 01:57:36.839563 17260 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0626 01:57:41.265867 17260 solver.cpp:218] Iteration 62700 (22.5934 iter/s, 4.42606s/100 iters), loss = 0.00842418
I0626 01:57:41.265867 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:41.265867 17260 solver.cpp:237]     Train net output #1: loss = 0.00842403 (* 1 = 0.00842403 loss)
I0626 01:57:41.265867 17260 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0626 01:57:45.632642 17260 solver.cpp:218] Iteration 62800 (22.9123 iter/s, 4.36448s/100 iters), loss = 0.00845505
I0626 01:57:45.632642 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:45.632642 17260 solver.cpp:237]     Train net output #1: loss = 0.0084549 (* 1 = 0.0084549 loss)
I0626 01:57:45.632642 17260 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0626 01:57:49.937121 17260 solver.cpp:218] Iteration 62900 (23.2657 iter/s, 4.29818s/100 iters), loss = 0.00190859
I0626 01:57:49.937121 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:49.937121 17260 solver.cpp:237]     Train net output #1: loss = 0.00190844 (* 1 = 0.00190844 loss)
I0626 01:57:49.937121 17260 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0626 01:57:54.200564 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:57:54.365181 17260 solver.cpp:330] Iteration 63000, Testing net (#0)
I0626 01:57:54.365181 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:57:55.775223  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:57:55.796738 17260 solver.cpp:397]     Test net output #0: accuracy = 0.921
I0626 01:57:55.797238 17260 solver.cpp:397]     Test net output #1: loss = 0.291493 (* 1 = 0.291493 loss)
I0626 01:57:55.840299 17260 solver.cpp:218] Iteration 63000 (16.9419 iter/s, 5.90253s/100 iters), loss = 0.00417346
I0626 01:57:55.840299 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:57:55.840299 17260 solver.cpp:237]     Train net output #1: loss = 0.00417331 (* 1 = 0.00417331 loss)
I0626 01:57:55.840299 17260 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0626 01:58:00.257092 17260 solver.cpp:218] Iteration 63100 (22.6465 iter/s, 4.4157s/100 iters), loss = 0.00311014
I0626 01:58:00.257092 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:00.257092 17260 solver.cpp:237]     Train net output #1: loss = 0.00310999 (* 1 = 0.00310999 loss)
I0626 01:58:00.257092 17260 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0626 01:58:04.652911 17260 solver.cpp:218] Iteration 63200 (22.7535 iter/s, 4.39493s/100 iters), loss = 0.014751
I0626 01:58:04.652911 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:58:04.652911 17260 solver.cpp:237]     Train net output #1: loss = 0.0147509 (* 1 = 0.0147509 loss)
I0626 01:58:04.652911 17260 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0626 01:58:09.108480 17260 solver.cpp:218] Iteration 63300 (22.4451 iter/s, 4.45532s/100 iters), loss = 0.00204191
I0626 01:58:09.108480 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:09.108480 17260 solver.cpp:237]     Train net output #1: loss = 0.00204176 (* 1 = 0.00204176 loss)
I0626 01:58:09.108480 17260 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0626 01:58:13.676090 17260 solver.cpp:218] Iteration 63400 (21.951 iter/s, 4.55561s/100 iters), loss = 0.00567607
I0626 01:58:13.676090 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:13.676090 17260 solver.cpp:237]     Train net output #1: loss = 0.00567592 (* 1 = 0.00567592 loss)
I0626 01:58:13.676090 17260 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0626 01:58:18.118633 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:58:18.329823 17260 solver.cpp:218] Iteration 63500 (21.5082 iter/s, 4.64939s/100 iters), loss = 0.00183057
I0626 01:58:18.329823 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:18.329823 17260 solver.cpp:237]     Train net output #1: loss = 0.00183042 (* 1 = 0.00183042 loss)
I0626 01:58:18.329823 17260 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0626 01:58:22.834223 17260 solver.cpp:218] Iteration 63600 (22.2168 iter/s, 4.50111s/100 iters), loss = 0.00472279
I0626 01:58:22.834223 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:22.834223 17260 solver.cpp:237]     Train net output #1: loss = 0.00472264 (* 1 = 0.00472264 loss)
I0626 01:58:22.834223 17260 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0626 01:58:27.220722 17260 solver.cpp:218] Iteration 63700 (22.8396 iter/s, 4.37835s/100 iters), loss = 0.0064867
I0626 01:58:27.220722 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:27.220722 17260 solver.cpp:237]     Train net output #1: loss = 0.00648655 (* 1 = 0.00648655 loss)
I0626 01:58:27.220722 17260 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0626 01:58:31.650257 17260 solver.cpp:218] Iteration 63800 (22.5783 iter/s, 4.42903s/100 iters), loss = 0.00331124
I0626 01:58:31.650257 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:31.650257 17260 solver.cpp:237]     Train net output #1: loss = 0.00331109 (* 1 = 0.00331109 loss)
I0626 01:58:31.650257 17260 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0626 01:58:36.027868 17260 solver.cpp:218] Iteration 63900 (22.9031 iter/s, 4.36622s/100 iters), loss = 0.00279269
I0626 01:58:36.027868 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:36.027868 17260 solver.cpp:237]     Train net output #1: loss = 0.00279254 (* 1 = 0.00279254 loss)
I0626 01:58:36.027868 17260 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0626 01:58:40.248639 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:58:40.430271 17260 solver.cpp:330] Iteration 64000, Testing net (#0)
I0626 01:58:40.430771 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:58:41.826994  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:58:41.872526 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9211
I0626 01:58:41.872526 17260 solver.cpp:397]     Test net output #1: loss = 0.291737 (* 1 = 0.291737 loss)
I0626 01:58:41.910053 17260 solver.cpp:218] Iteration 64000 (17.0017 iter/s, 5.88175s/100 iters), loss = 0.00164099
I0626 01:58:41.910554 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:41.910554 17260 solver.cpp:237]     Train net output #1: loss = 0.00164084 (* 1 = 0.00164084 loss)
I0626 01:58:41.910554 17260 sgd_solver.cpp:105] Iteration 64000, lr = 1e-05
I0626 01:58:46.298101 17260 solver.cpp:218] Iteration 64100 (22.7935 iter/s, 4.38721s/100 iters), loss = 0.00485004
I0626 01:58:46.299101 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:46.299101 17260 solver.cpp:237]     Train net output #1: loss = 0.00484989 (* 1 = 0.00484989 loss)
I0626 01:58:46.299101 17260 sgd_solver.cpp:105] Iteration 64100, lr = 1e-05
I0626 01:58:50.681727 17260 solver.cpp:218] Iteration 64200 (22.8185 iter/s, 4.38241s/100 iters), loss = 0.00549619
I0626 01:58:50.682229 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:50.682229 17260 solver.cpp:237]     Train net output #1: loss = 0.00549604 (* 1 = 0.00549604 loss)
I0626 01:58:50.682229 17260 sgd_solver.cpp:105] Iteration 64200, lr = 1e-05
I0626 01:58:55.227391 17260 solver.cpp:218] Iteration 64300 (22.0063 iter/s, 4.54415s/100 iters), loss = 0.005006
I0626 01:58:55.227391 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:55.227391 17260 solver.cpp:237]     Train net output #1: loss = 0.00500585 (* 1 = 0.00500585 loss)
I0626 01:58:55.227891 17260 sgd_solver.cpp:105] Iteration 64300, lr = 1e-05
I0626 01:58:59.713618 17260 solver.cpp:218] Iteration 64400 (22.2938 iter/s, 4.48556s/100 iters), loss = 0.00314853
I0626 01:58:59.713618 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:58:59.713618 17260 solver.cpp:237]     Train net output #1: loss = 0.00314838 (* 1 = 0.00314838 loss)
I0626 01:58:59.713618 17260 sgd_solver.cpp:105] Iteration 64400, lr = 1e-05
I0626 01:59:03.852257 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:59:04.061405 17260 solver.cpp:218] Iteration 64500 (23.0099 iter/s, 4.34595s/100 iters), loss = 0.00291962
I0626 01:59:04.061405 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:04.061405 17260 solver.cpp:237]     Train net output #1: loss = 0.00291947 (* 1 = 0.00291947 loss)
I0626 01:59:04.061405 17260 sgd_solver.cpp:105] Iteration 64500, lr = 1e-05
I0626 01:59:08.492733 17260 solver.cpp:218] Iteration 64600 (22.5772 iter/s, 4.42926s/100 iters), loss = 0.0106896
I0626 01:59:08.492733 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:08.492733 17260 solver.cpp:237]     Train net output #1: loss = 0.0106894 (* 1 = 0.0106894 loss)
I0626 01:59:08.492733 17260 sgd_solver.cpp:105] Iteration 64600, lr = 1e-05
I0626 01:59:12.800621 17260 solver.cpp:218] Iteration 64700 (23.2174 iter/s, 4.30712s/100 iters), loss = 0.0055338
I0626 01:59:12.800621 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:12.800621 17260 solver.cpp:237]     Train net output #1: loss = 0.00553364 (* 1 = 0.00553364 loss)
I0626 01:59:12.800621 17260 sgd_solver.cpp:105] Iteration 64700, lr = 1e-05
I0626 01:59:17.151775 17260 solver.cpp:218] Iteration 64800 (23.0109 iter/s, 4.34576s/100 iters), loss = 0.00213066
I0626 01:59:17.151775 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:17.151775 17260 solver.cpp:237]     Train net output #1: loss = 0.00213051 (* 1 = 0.00213051 loss)
I0626 01:59:17.151775 17260 sgd_solver.cpp:105] Iteration 64800, lr = 1e-05
I0626 01:59:21.477072 17260 solver.cpp:218] Iteration 64900 (23.1517 iter/s, 4.31934s/100 iters), loss = 0.00285113
I0626 01:59:21.477072 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:21.477072 17260 solver.cpp:237]     Train net output #1: loss = 0.00285098 (* 1 = 0.00285098 loss)
I0626 01:59:21.477072 17260 sgd_solver.cpp:105] Iteration 64900, lr = 1e-05
I0626 01:59:25.708581 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:59:25.876700 17260 solver.cpp:330] Iteration 65000, Testing net (#0)
I0626 01:59:25.876700 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 01:59:27.300642  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:59:27.331663 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9211
I0626 01:59:27.331663 17260 solver.cpp:397]     Test net output #1: loss = 0.291342 (* 1 = 0.291342 loss)
I0626 01:59:27.374694 17260 solver.cpp:218] Iteration 65000 (16.9626 iter/s, 5.89531s/100 iters), loss = 0.00619561
I0626 01:59:27.375195 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:27.375195 17260 solver.cpp:237]     Train net output #1: loss = 0.00619546 (* 1 = 0.00619546 loss)
I0626 01:59:27.375195 17260 sgd_solver.cpp:105] Iteration 65000, lr = 1e-05
I0626 01:59:32.861568 17260 solver.cpp:218] Iteration 65100 (18.2284 iter/s, 5.48593s/100 iters), loss = 0.00653784
I0626 01:59:32.861568 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:32.861568 17260 solver.cpp:237]     Train net output #1: loss = 0.00653769 (* 1 = 0.00653769 loss)
I0626 01:59:32.861568 17260 sgd_solver.cpp:105] Iteration 65100, lr = 1e-05
I0626 01:59:37.200028 17260 solver.cpp:218] Iteration 65200 (23.0529 iter/s, 4.33786s/100 iters), loss = 0.00660907
I0626 01:59:37.200028 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:37.200028 17260 solver.cpp:237]     Train net output #1: loss = 0.00660892 (* 1 = 0.00660892 loss)
I0626 01:59:37.200028 17260 sgd_solver.cpp:105] Iteration 65200, lr = 1e-05
I0626 01:59:41.767809 17260 solver.cpp:218] Iteration 65300 (21.9586 iter/s, 4.55402s/100 iters), loss = 0.00267824
I0626 01:59:41.767809 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:41.767809 17260 solver.cpp:237]     Train net output #1: loss = 0.00267809 (* 1 = 0.00267809 loss)
I0626 01:59:41.767809 17260 sgd_solver.cpp:105] Iteration 65300, lr = 1e-05
I0626 01:59:46.353111 17260 solver.cpp:218] Iteration 65400 (21.8461 iter/s, 4.57748s/100 iters), loss = 0.00432008
I0626 01:59:46.353611 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:46.353611 17260 solver.cpp:237]     Train net output #1: loss = 0.00431993 (* 1 = 0.00431993 loss)
I0626 01:59:46.353611 17260 sgd_solver.cpp:105] Iteration 65400, lr = 1e-05
I0626 01:59:50.719285 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 01:59:50.923931 17260 solver.cpp:218] Iteration 65500 (21.908 iter/s, 4.56454s/100 iters), loss = 0.00412065
I0626 01:59:50.924432 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:50.924432 17260 solver.cpp:237]     Train net output #1: loss = 0.0041205 (* 1 = 0.0041205 loss)
I0626 01:59:50.924432 17260 sgd_solver.cpp:105] Iteration 65500, lr = 1e-05
I0626 01:59:55.476908 17260 solver.cpp:218] Iteration 65600 (21.9677 iter/s, 4.55214s/100 iters), loss = 0.00448364
I0626 01:59:55.477409 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 01:59:55.477409 17260 solver.cpp:237]     Train net output #1: loss = 0.00448349 (* 1 = 0.00448349 loss)
I0626 01:59:55.477409 17260 sgd_solver.cpp:105] Iteration 65600, lr = 1e-05
I0626 01:59:59.896587 17260 solver.cpp:218] Iteration 65700 (22.6312 iter/s, 4.41867s/100 iters), loss = 0.0127726
I0626 01:59:59.896587 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 01:59:59.896587 17260 solver.cpp:237]     Train net output #1: loss = 0.0127725 (* 1 = 0.0127725 loss)
I0626 01:59:59.896587 17260 sgd_solver.cpp:105] Iteration 65700, lr = 1e-05
I0626 02:00:04.549965 17260 solver.cpp:218] Iteration 65800 (21.4922 iter/s, 4.65285s/100 iters), loss = 0.00146072
I0626 02:00:04.550465 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:04.550465 17260 solver.cpp:237]     Train net output #1: loss = 0.00146058 (* 1 = 0.00146058 loss)
I0626 02:00:04.550465 17260 sgd_solver.cpp:105] Iteration 65800, lr = 1e-05
I0626 02:00:08.971174 17260 solver.cpp:218] Iteration 65900 (22.6228 iter/s, 4.42033s/100 iters), loss = 0.00294819
I0626 02:00:08.971174 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:08.971174 17260 solver.cpp:237]     Train net output #1: loss = 0.00294804 (* 1 = 0.00294804 loss)
I0626 02:00:08.971174 17260 sgd_solver.cpp:105] Iteration 65900, lr = 1e-05
I0626 02:00:13.199154 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:00:13.376781 17260 solver.cpp:330] Iteration 66000, Testing net (#0)
I0626 02:00:13.377281 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:00:14.836819  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:00:14.857836 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9212
I0626 02:00:14.858335 17260 solver.cpp:397]     Test net output #1: loss = 0.291668 (* 1 = 0.291668 loss)
I0626 02:00:14.912873 17260 solver.cpp:218] Iteration 66000 (16.8631 iter/s, 5.93012s/100 iters), loss = 0.00230145
I0626 02:00:14.912873 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:14.912873 17260 solver.cpp:237]     Train net output #1: loss = 0.0023013 (* 1 = 0.0023013 loss)
I0626 02:00:14.912873 17260 sgd_solver.cpp:105] Iteration 66000, lr = 1e-05
I0626 02:00:19.519418 17260 solver.cpp:218] Iteration 66100 (21.7159 iter/s, 4.60491s/100 iters), loss = 0.005502
I0626 02:00:19.519418 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:19.519418 17260 solver.cpp:237]     Train net output #1: loss = 0.00550185 (* 1 = 0.00550185 loss)
I0626 02:00:19.519418 17260 sgd_solver.cpp:105] Iteration 66100, lr = 1e-05
I0626 02:00:23.941489 17260 solver.cpp:218] Iteration 66200 (22.6155 iter/s, 4.42175s/100 iters), loss = 0.00333565
I0626 02:00:23.941489 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:23.941489 17260 solver.cpp:237]     Train net output #1: loss = 0.0033355 (* 1 = 0.0033355 loss)
I0626 02:00:23.941489 17260 sgd_solver.cpp:105] Iteration 66200, lr = 1e-05
I0626 02:00:28.454268 17260 solver.cpp:218] Iteration 66300 (22.1627 iter/s, 4.51209s/100 iters), loss = 0.00503882
I0626 02:00:28.454268 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:28.454268 17260 solver.cpp:237]     Train net output #1: loss = 0.00503867 (* 1 = 0.00503867 loss)
I0626 02:00:28.454268 17260 sgd_solver.cpp:105] Iteration 66300, lr = 1e-05
I0626 02:00:32.859086 17260 solver.cpp:218] Iteration 66400 (22.7245 iter/s, 4.40053s/100 iters), loss = 0.00195797
I0626 02:00:32.859086 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:32.859086 17260 solver.cpp:237]     Train net output #1: loss = 0.00195782 (* 1 = 0.00195782 loss)
I0626 02:00:32.859086 17260 sgd_solver.cpp:105] Iteration 66400, lr = 1e-05
I0626 02:00:36.986037 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:00:37.214704 17260 solver.cpp:218] Iteration 66500 (22.9625 iter/s, 4.35493s/100 iters), loss = 0.00633004
I0626 02:00:37.214704 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:37.214704 17260 solver.cpp:237]     Train net output #1: loss = 0.00632989 (* 1 = 0.00632989 loss)
I0626 02:00:37.214704 17260 sgd_solver.cpp:105] Iteration 66500, lr = 1e-05
I0626 02:00:41.483981 17260 solver.cpp:218] Iteration 66600 (23.4247 iter/s, 4.26899s/100 iters), loss = 0.00329493
I0626 02:00:41.483981 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:41.483981 17260 solver.cpp:237]     Train net output #1: loss = 0.00329478 (* 1 = 0.00329478 loss)
I0626 02:00:41.483981 17260 sgd_solver.cpp:105] Iteration 66600, lr = 1e-05
I0626 02:00:45.940450 17260 solver.cpp:218] Iteration 66700 (22.4432 iter/s, 4.4557s/100 iters), loss = 0.011782
I0626 02:00:45.940450 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:00:45.940450 17260 solver.cpp:237]     Train net output #1: loss = 0.0117818 (* 1 = 0.0117818 loss)
I0626 02:00:45.940450 17260 sgd_solver.cpp:105] Iteration 66700, lr = 1e-05
I0626 02:00:50.312121 17260 solver.cpp:218] Iteration 66800 (22.8764 iter/s, 4.37132s/100 iters), loss = 0.00531884
I0626 02:00:50.312121 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:50.312121 17260 solver.cpp:237]     Train net output #1: loss = 0.00531869 (* 1 = 0.00531869 loss)
I0626 02:00:50.312121 17260 sgd_solver.cpp:105] Iteration 66800, lr = 1e-05
I0626 02:00:55.588461 17260 solver.cpp:218] Iteration 66900 (18.9834 iter/s, 5.26775s/100 iters), loss = 0.00317485
I0626 02:00:55.588961 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:00:55.588961 17260 solver.cpp:237]     Train net output #1: loss = 0.00317469 (* 1 = 0.00317469 loss)
I0626 02:00:55.588961 17260 sgd_solver.cpp:105] Iteration 66900, lr = 1e-05
I0626 02:01:01.809211 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:01:02.066893 17260 solver.cpp:330] Iteration 67000, Testing net (#0)
I0626 02:01:02.066893 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:01:04.082978  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:01:04.115502 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9214
I0626 02:01:04.115502 17260 solver.cpp:397]     Test net output #1: loss = 0.291336 (* 1 = 0.291336 loss)
I0626 02:01:04.153028 17260 solver.cpp:218] Iteration 67000 (11.6774 iter/s, 8.56355s/100 iters), loss = 0.00151414
I0626 02:01:04.153028 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:04.153028 17260 solver.cpp:237]     Train net output #1: loss = 0.00151398 (* 1 = 0.00151398 loss)
I0626 02:01:04.153028 17260 sgd_solver.cpp:105] Iteration 67000, lr = 1e-05
I0626 02:01:10.385718 17260 solver.cpp:218] Iteration 67100 (16.1965 iter/s, 6.17418s/100 iters), loss = 0.00323641
I0626 02:01:10.385718 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:10.386219 17260 solver.cpp:237]     Train net output #1: loss = 0.00323626 (* 1 = 0.00323626 loss)
I0626 02:01:10.386219 17260 sgd_solver.cpp:105] Iteration 67100, lr = 1e-05
I0626 02:01:16.573669 17260 solver.cpp:218] Iteration 67200 (16.1631 iter/s, 6.18693s/100 iters), loss = 0.0141317
I0626 02:01:16.573669 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:01:16.573669 17260 solver.cpp:237]     Train net output #1: loss = 0.0141315 (* 1 = 0.0141315 loss)
I0626 02:01:16.573669 17260 sgd_solver.cpp:105] Iteration 67200, lr = 1e-05
I0626 02:01:22.962827 17260 solver.cpp:218] Iteration 67300 (15.7742 iter/s, 6.33948s/100 iters), loss = 0.00326398
I0626 02:01:22.962827 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:22.962827 17260 solver.cpp:237]     Train net output #1: loss = 0.00326383 (* 1 = 0.00326383 loss)
I0626 02:01:22.962827 17260 sgd_solver.cpp:105] Iteration 67300, lr = 1e-05
I0626 02:01:28.877135 17260 solver.cpp:218] Iteration 67400 (16.9095 iter/s, 5.91383s/100 iters), loss = 0.00154003
I0626 02:01:28.877135 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:28.877135 17260 solver.cpp:237]     Train net output #1: loss = 0.00153988 (* 1 = 0.00153988 loss)
I0626 02:01:28.877135 17260 sgd_solver.cpp:105] Iteration 67400, lr = 1e-05
I0626 02:01:34.586277 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:01:34.818442 17260 solver.cpp:218] Iteration 67500 (16.839 iter/s, 5.9386s/100 iters), loss = 0.00379092
I0626 02:01:34.818943 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:34.818943 17260 solver.cpp:237]     Train net output #1: loss = 0.00379077 (* 1 = 0.00379077 loss)
I0626 02:01:34.818943 17260 sgd_solver.cpp:105] Iteration 67500, lr = 1e-05
I0626 02:01:41.548604 17260 solver.cpp:218] Iteration 67600 (14.8606 iter/s, 6.72918s/100 iters), loss = 0.00323798
I0626 02:01:41.559111 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:41.559111 17260 solver.cpp:237]     Train net output #1: loss = 0.00323783 (* 1 = 0.00323783 loss)
I0626 02:01:41.559111 17260 sgd_solver.cpp:105] Iteration 67600, lr = 1e-05
I0626 02:01:47.789700 17260 solver.cpp:218] Iteration 67700 (16.0866 iter/s, 6.21635s/100 iters), loss = 0.00178327
I0626 02:01:47.789700 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:47.789700 17260 solver.cpp:237]     Train net output #1: loss = 0.00178312 (* 1 = 0.00178312 loss)
I0626 02:01:47.789700 17260 sgd_solver.cpp:105] Iteration 67700, lr = 1e-05
I0626 02:01:53.870707 17260 solver.cpp:218] Iteration 67800 (16.5461 iter/s, 6.04373s/100 iters), loss = 0.00400335
I0626 02:01:53.870707 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:53.870707 17260 solver.cpp:237]     Train net output #1: loss = 0.0040032 (* 1 = 0.0040032 loss)
I0626 02:01:53.870707 17260 sgd_solver.cpp:105] Iteration 67800, lr = 1e-05
I0626 02:01:59.940479 17260 solver.cpp:218] Iteration 67900 (16.4807 iter/s, 6.06772s/100 iters), loss = 0.0033477
I0626 02:01:59.940479 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:01:59.940479 17260 solver.cpp:237]     Train net output #1: loss = 0.00334755 (* 1 = 0.00334755 loss)
I0626 02:01:59.940479 17260 sgd_solver.cpp:105] Iteration 67900, lr = 1e-05
I0626 02:02:05.761394 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:02:06.026082 17260 solver.cpp:330] Iteration 68000, Testing net (#0)
I0626 02:02:06.026082 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:02:08.311254  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:02:08.349781 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9212
I0626 02:02:08.349781 17260 solver.cpp:397]     Test net output #1: loss = 0.291343 (* 1 = 0.291343 loss)
I0626 02:02:08.430338 17260 solver.cpp:218] Iteration 68000 (11.7794 iter/s, 8.48936s/100 iters), loss = 0.00121231
I0626 02:02:08.430338 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:08.430338 17260 solver.cpp:237]     Train net output #1: loss = 0.00121216 (* 1 = 0.00121216 loss)
I0626 02:02:08.430338 17260 sgd_solver.cpp:105] Iteration 68000, lr = 1e-05
I0626 02:02:14.362849 17260 solver.cpp:218] Iteration 68100 (16.8578 iter/s, 5.93196s/100 iters), loss = 0.00818582
I0626 02:02:14.362849 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:14.363349 17260 solver.cpp:237]     Train net output #1: loss = 0.00818567 (* 1 = 0.00818567 loss)
I0626 02:02:14.363349 17260 sgd_solver.cpp:105] Iteration 68100, lr = 1e-05
I0626 02:02:21.592939 17260 solver.cpp:218] Iteration 68200 (13.8326 iter/s, 7.22929s/100 iters), loss = 0.00720338
I0626 02:02:21.593439 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:21.593439 17260 solver.cpp:237]     Train net output #1: loss = 0.00720323 (* 1 = 0.00720323 loss)
I0626 02:02:21.593439 17260 sgd_solver.cpp:105] Iteration 68200, lr = 1e-05
I0626 02:02:27.674321 17260 solver.cpp:218] Iteration 68300 (16.4464 iter/s, 6.08035s/100 iters), loss = 0.0117111
I0626 02:02:27.674321 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:27.674321 17260 solver.cpp:237]     Train net output #1: loss = 0.011711 (* 1 = 0.011711 loss)
I0626 02:02:27.674321 17260 sgd_solver.cpp:105] Iteration 68300, lr = 1e-05
I0626 02:02:33.884840 17260 solver.cpp:218] Iteration 68400 (16.1032 iter/s, 6.20994s/100 iters), loss = 0.00230778
I0626 02:02:33.885340 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:33.885340 17260 solver.cpp:237]     Train net output #1: loss = 0.00230763 (* 1 = 0.00230763 loss)
I0626 02:02:33.885340 17260 sgd_solver.cpp:105] Iteration 68400, lr = 1e-05
I0626 02:02:39.692728 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:02:39.994963 17260 solver.cpp:218] Iteration 68500 (16.3693 iter/s, 6.10901s/100 iters), loss = 0.00140435
I0626 02:02:39.994963 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:39.994963 17260 solver.cpp:237]     Train net output #1: loss = 0.0014042 (* 1 = 0.0014042 loss)
I0626 02:02:39.994963 17260 sgd_solver.cpp:105] Iteration 68500, lr = 1e-05
I0626 02:02:46.499260 17260 solver.cpp:218] Iteration 68600 (15.3749 iter/s, 6.50412s/100 iters), loss = 0.00276465
I0626 02:02:46.499761 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:46.499761 17260 solver.cpp:237]     Train net output #1: loss = 0.0027645 (* 1 = 0.0027645 loss)
I0626 02:02:46.499761 17260 sgd_solver.cpp:105] Iteration 68600, lr = 1e-05
I0626 02:02:53.148046 17260 solver.cpp:218] Iteration 68700 (15.0853 iter/s, 6.62898s/100 iters), loss = 0.00700751
I0626 02:02:53.148046 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:53.148046 17260 solver.cpp:237]     Train net output #1: loss = 0.00700736 (* 1 = 0.00700736 loss)
I0626 02:02:53.148046 17260 sgd_solver.cpp:105] Iteration 68700, lr = 1e-05
I0626 02:02:59.866915 17260 solver.cpp:218] Iteration 68800 (14.9792 iter/s, 6.67594s/100 iters), loss = 0.00231348
I0626 02:02:59.866915 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:02:59.866915 17260 solver.cpp:237]     Train net output #1: loss = 0.00231332 (* 1 = 0.00231332 loss)
I0626 02:02:59.866915 17260 sgd_solver.cpp:105] Iteration 68800, lr = 1e-05
I0626 02:03:06.637814 17260 solver.cpp:218] Iteration 68900 (14.7702 iter/s, 6.7704s/100 iters), loss = 0.00271557
I0626 02:03:06.637814 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:06.637814 17260 solver.cpp:237]     Train net output #1: loss = 0.00271541 (* 1 = 0.00271541 loss)
I0626 02:03:06.637814 17260 sgd_solver.cpp:105] Iteration 68900, lr = 1e-05
I0626 02:03:12.353926 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:03:12.503032 17260 solver.cpp:330] Iteration 69000, Testing net (#0)
I0626 02:03:12.503032 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:03:14.319923  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:03:14.376965 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9216
I0626 02:03:14.376965 17260 solver.cpp:397]     Test net output #1: loss = 0.291505 (* 1 = 0.291505 loss)
I0626 02:03:14.451016 17260 solver.cpp:218] Iteration 69000 (12.7999 iter/s, 7.81255s/100 iters), loss = 0.00265329
I0626 02:03:14.451016 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:14.451016 17260 solver.cpp:237]     Train net output #1: loss = 0.00265313 (* 1 = 0.00265313 loss)
I0626 02:03:14.451016 17260 sgd_solver.cpp:105] Iteration 69000, lr = 1e-05
I0626 02:03:20.544888 17260 solver.cpp:218] Iteration 69100 (16.4107 iter/s, 6.0936s/100 iters), loss = 0.00517855
I0626 02:03:20.545389 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:20.545389 17260 solver.cpp:237]     Train net output #1: loss = 0.00517839 (* 1 = 0.00517839 loss)
I0626 02:03:20.545389 17260 sgd_solver.cpp:105] Iteration 69100, lr = 1e-05
I0626 02:03:26.680856 17260 solver.cpp:218] Iteration 69200 (16.3 iter/s, 6.13498s/100 iters), loss = 0.0115562
I0626 02:03:26.680856 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:26.680856 17260 solver.cpp:237]     Train net output #1: loss = 0.011556 (* 1 = 0.011556 loss)
I0626 02:03:26.680856 17260 sgd_solver.cpp:105] Iteration 69200, lr = 1e-05
I0626 02:03:32.690189 17260 solver.cpp:218] Iteration 69300 (16.6421 iter/s, 6.00885s/100 iters), loss = 0.00531136
I0626 02:03:32.690189 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:32.690189 17260 solver.cpp:237]     Train net output #1: loss = 0.00531121 (* 1 = 0.00531121 loss)
I0626 02:03:32.690189 17260 sgd_solver.cpp:105] Iteration 69300, lr = 1e-05
I0626 02:03:38.693070 17260 solver.cpp:218] Iteration 69400 (16.6604 iter/s, 6.00224s/100 iters), loss = 0.00322555
I0626 02:03:38.693070 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:38.693070 17260 solver.cpp:237]     Train net output #1: loss = 0.0032254 (* 1 = 0.0032254 loss)
I0626 02:03:38.693070 17260 sgd_solver.cpp:105] Iteration 69400, lr = 1e-05
I0626 02:03:44.718438 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:03:45.176764 17260 solver.cpp:218] Iteration 69500 (15.4238 iter/s, 6.48348s/100 iters), loss = 0.008913
I0626 02:03:45.176764 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:45.176764 17260 solver.cpp:237]     Train net output #1: loss = 0.00891284 (* 1 = 0.00891284 loss)
I0626 02:03:45.176764 17260 sgd_solver.cpp:105] Iteration 69500, lr = 1e-05
I0626 02:03:51.827771 17260 solver.cpp:218] Iteration 69600 (15.0373 iter/s, 6.65014s/100 iters), loss = 0.00586409
I0626 02:03:51.827771 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:51.827771 17260 solver.cpp:237]     Train net output #1: loss = 0.00586393 (* 1 = 0.00586393 loss)
I0626 02:03:51.827771 17260 sgd_solver.cpp:105] Iteration 69600, lr = 1e-05
I0626 02:03:57.647461 17260 solver.cpp:218] Iteration 69700 (17.1992 iter/s, 5.81421s/100 iters), loss = 0.00449919
I0626 02:03:57.647461 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:03:57.647461 17260 solver.cpp:237]     Train net output #1: loss = 0.00449903 (* 1 = 0.00449903 loss)
I0626 02:03:57.647461 17260 sgd_solver.cpp:105] Iteration 69700, lr = 1e-05
I0626 02:04:04.119308 17260 solver.cpp:218] Iteration 69800 (15.5138 iter/s, 6.44589s/100 iters), loss = 0.00456878
I0626 02:04:04.119308 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:04.119308 17260 solver.cpp:237]     Train net output #1: loss = 0.00456862 (* 1 = 0.00456862 loss)
I0626 02:04:04.119308 17260 sgd_solver.cpp:105] Iteration 69800, lr = 1e-05
I0626 02:04:10.045768 17260 solver.cpp:218] Iteration 69900 (16.8751 iter/s, 5.92589s/100 iters), loss = 0.00343768
I0626 02:04:10.045768 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:10.045768 17260 solver.cpp:237]     Train net output #1: loss = 0.00343753 (* 1 = 0.00343753 loss)
I0626 02:04:10.045768 17260 sgd_solver.cpp:105] Iteration 69900, lr = 1e-05
I0626 02:04:15.844089 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:04:16.170821 17260 solver.cpp:447] Snapshotting to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_70000.caffemodel
I0626 02:04:16.295410 17260 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/Shallow_wide_1M_6L_iter_70000.solverstate
I0626 02:04:16.309921 17260 solver.cpp:330] Iteration 70000, Testing net (#0)
I0626 02:04:16.309921 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:04:18.765209  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:04:18.857794 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9213
I0626 02:04:18.857794 17260 solver.cpp:397]     Test net output #1: loss = 0.29127 (* 1 = 0.29127 loss)
I0626 02:04:18.895819 17260 solver.cpp:218] Iteration 70000 (11.3 iter/s, 8.84958s/100 iters), loss = 0.00324351
I0626 02:04:18.895819 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:18.895819 17260 solver.cpp:237]     Train net output #1: loss = 0.00324335 (* 1 = 0.00324335 loss)
I0626 02:04:18.895819 17260 sgd_solver.cpp:105] Iteration 70000, lr = 1e-05
I0626 02:04:24.986335 17260 solver.cpp:218] Iteration 70100 (16.4878 iter/s, 6.06511s/100 iters), loss = 0.00328388
I0626 02:04:24.986335 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:24.986335 17260 solver.cpp:237]     Train net output #1: loss = 0.00328372 (* 1 = 0.00328372 loss)
I0626 02:04:24.986335 17260 sgd_solver.cpp:105] Iteration 70100, lr = 1e-05
I0626 02:04:31.196537 17260 solver.cpp:218] Iteration 70200 (16.1047 iter/s, 6.20936s/100 iters), loss = 0.010468
I0626 02:04:31.196537 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:31.196537 17260 solver.cpp:237]     Train net output #1: loss = 0.0104679 (* 1 = 0.0104679 loss)
I0626 02:04:31.196537 17260 sgd_solver.cpp:105] Iteration 70200, lr = 1e-05
I0626 02:04:38.091044 17260 solver.cpp:218] Iteration 70300 (14.7645 iter/s, 6.77299s/100 iters), loss = 0.00272031
I0626 02:04:38.091544 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:38.091544 17260 solver.cpp:237]     Train net output #1: loss = 0.00272015 (* 1 = 0.00272015 loss)
I0626 02:04:38.091544 17260 sgd_solver.cpp:105] Iteration 70300, lr = 1e-05
I0626 02:04:44.827389 17260 solver.cpp:218] Iteration 70400 (14.8468 iter/s, 6.73547s/100 iters), loss = 0.00424855
I0626 02:04:44.827389 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:44.827389 17260 solver.cpp:237]     Train net output #1: loss = 0.00424839 (* 1 = 0.00424839 loss)
I0626 02:04:44.827389 17260 sgd_solver.cpp:105] Iteration 70400, lr = 1e-05
I0626 02:04:50.794445 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:04:51.015136 17260 solver.cpp:218] Iteration 70500 (16.1631 iter/s, 6.18694s/100 iters), loss = 0.00483014
I0626 02:04:51.015136 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:51.015136 17260 solver.cpp:237]     Train net output #1: loss = 0.00482998 (* 1 = 0.00482998 loss)
I0626 02:04:51.015136 17260 sgd_solver.cpp:105] Iteration 70500, lr = 1e-05
I0626 02:04:57.201078 17260 solver.cpp:218] Iteration 70600 (16.2049 iter/s, 6.17098s/100 iters), loss = 0.00548652
I0626 02:04:57.201078 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:04:57.201078 17260 solver.cpp:237]     Train net output #1: loss = 0.00548636 (* 1 = 0.00548636 loss)
I0626 02:04:57.201078 17260 sgd_solver.cpp:105] Iteration 70600, lr = 1e-05
I0626 02:05:03.317980 17260 solver.cpp:218] Iteration 70700 (16.3491 iter/s, 6.11653s/100 iters), loss = 0.00405923
I0626 02:05:03.317980 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:03.317980 17260 solver.cpp:237]     Train net output #1: loss = 0.00405907 (* 1 = 0.00405907 loss)
I0626 02:05:03.317980 17260 sgd_solver.cpp:105] Iteration 70700, lr = 1e-05
I0626 02:05:09.487128 17260 solver.cpp:218] Iteration 70800 (16.2182 iter/s, 6.16591s/100 iters), loss = 0.0018414
I0626 02:05:09.487128 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:09.487128 17260 solver.cpp:237]     Train net output #1: loss = 0.00184123 (* 1 = 0.00184123 loss)
I0626 02:05:09.487128 17260 sgd_solver.cpp:105] Iteration 70800, lr = 1e-05
I0626 02:05:15.773916 17260 solver.cpp:218] Iteration 70900 (15.933 iter/s, 6.27627s/100 iters), loss = 0.00451055
I0626 02:05:15.773916 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:15.773916 17260 solver.cpp:237]     Train net output #1: loss = 0.00451039 (* 1 = 0.00451039 loss)
I0626 02:05:15.773916 17260 sgd_solver.cpp:105] Iteration 70900, lr = 1e-05
I0626 02:05:21.505106 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:05:21.726764 17260 solver.cpp:330] Iteration 71000, Testing net (#0)
I0626 02:05:21.727264 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:05:24.277078  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:05:24.395164 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9214
I0626 02:05:24.395164 17260 solver.cpp:397]     Test net output #1: loss = 0.291297 (* 1 = 0.291297 loss)
I0626 02:05:24.506242 17260 solver.cpp:218] Iteration 71000 (11.543 iter/s, 8.66325s/100 iters), loss = 0.00210001
I0626 02:05:24.506742 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:24.506742 17260 solver.cpp:237]     Train net output #1: loss = 0.00209984 (* 1 = 0.00209984 loss)
I0626 02:05:24.506742 17260 sgd_solver.cpp:105] Iteration 71000, lr = 1e-05
I0626 02:05:30.404851 17260 solver.cpp:218] Iteration 71100 (16.9561 iter/s, 5.89759s/100 iters), loss = 0.00975074
I0626 02:05:30.404851 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:30.404851 17260 solver.cpp:237]     Train net output #1: loss = 0.00975058 (* 1 = 0.00975058 loss)
I0626 02:05:30.404851 17260 sgd_solver.cpp:105] Iteration 71100, lr = 1e-05
I0626 02:05:36.669883 17260 solver.cpp:218] Iteration 71200 (16.0415 iter/s, 6.23385s/100 iters), loss = 0.0256204
I0626 02:05:36.669883 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:05:36.670383 17260 solver.cpp:237]     Train net output #1: loss = 0.0256202 (* 1 = 0.0256202 loss)
I0626 02:05:36.670383 17260 sgd_solver.cpp:105] Iteration 71200, lr = 1e-05
I0626 02:05:42.765519 17260 solver.cpp:218] Iteration 71300 (16.45 iter/s, 6.07901s/100 iters), loss = 0.00474538
I0626 02:05:42.766520 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:42.767020 17260 solver.cpp:237]     Train net output #1: loss = 0.00474521 (* 1 = 0.00474521 loss)
I0626 02:05:42.767020 17260 sgd_solver.cpp:105] Iteration 71300, lr = 1e-05
I0626 02:05:48.478771 17260 solver.cpp:218] Iteration 71400 (17.5127 iter/s, 5.71015s/100 iters), loss = 0.00170371
I0626 02:05:48.478771 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:48.479272 17260 solver.cpp:237]     Train net output #1: loss = 0.00170354 (* 1 = 0.00170354 loss)
I0626 02:05:48.479272 17260 sgd_solver.cpp:105] Iteration 71400, lr = 1e-05
I0626 02:05:54.698803 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:05:55.034543 17260 solver.cpp:218] Iteration 71500 (15.2554 iter/s, 6.55506s/100 iters), loss = 0.00130344
I0626 02:05:55.034543 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:05:55.034543 17260 solver.cpp:237]     Train net output #1: loss = 0.00130328 (* 1 = 0.00130328 loss)
I0626 02:05:55.034543 17260 sgd_solver.cpp:105] Iteration 71500, lr = 1e-05
I0626 02:06:01.602346 17260 solver.cpp:218] Iteration 71600 (15.2296 iter/s, 6.56614s/100 iters), loss = 0.00603073
I0626 02:06:01.602346 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:01.602346 17260 solver.cpp:237]     Train net output #1: loss = 0.00603056 (* 1 = 0.00603056 loss)
I0626 02:06:01.602346 17260 sgd_solver.cpp:105] Iteration 71600, lr = 1e-05
I0626 02:06:07.732753 17260 solver.cpp:218] Iteration 71700 (16.3137 iter/s, 6.12982s/100 iters), loss = 0.00405136
I0626 02:06:07.732753 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:07.732753 17260 solver.cpp:237]     Train net output #1: loss = 0.00405119 (* 1 = 0.00405119 loss)
I0626 02:06:07.732753 17260 sgd_solver.cpp:105] Iteration 71700, lr = 1e-05
I0626 02:06:14.575639 17260 solver.cpp:218] Iteration 71800 (14.6148 iter/s, 6.84238s/100 iters), loss = 0.00347298
I0626 02:06:14.575639 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:14.576140 17260 solver.cpp:237]     Train net output #1: loss = 0.00347281 (* 1 = 0.00347281 loss)
I0626 02:06:14.576140 17260 sgd_solver.cpp:105] Iteration 71800, lr = 1e-05
I0626 02:06:20.722339 17260 solver.cpp:218] Iteration 71900 (16.3873 iter/s, 6.10228s/100 iters), loss = 0.00957594
I0626 02:06:20.722339 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:20.722339 17260 solver.cpp:237]     Train net output #1: loss = 0.00957577 (* 1 = 0.00957577 loss)
I0626 02:06:20.722339 17260 sgd_solver.cpp:105] Iteration 71900, lr = 1e-05
I0626 02:06:26.949378 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:06:27.255594 17260 solver.cpp:330] Iteration 72000, Testing net (#0)
I0626 02:06:27.255594 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:06:29.326568  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:06:29.345082 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9214
I0626 02:06:29.345082 17260 solver.cpp:397]     Test net output #1: loss = 0.291586 (* 1 = 0.291586 loss)
I0626 02:06:29.446153 17260 solver.cpp:218] Iteration 72000 (11.4637 iter/s, 8.72322s/100 iters), loss = 0.0081789
I0626 02:06:29.446153 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:06:29.446153 17260 solver.cpp:237]     Train net output #1: loss = 0.00817874 (* 1 = 0.00817874 loss)
I0626 02:06:29.446153 17260 sgd_solver.cpp:105] Iteration 72000, lr = 1e-05
I0626 02:06:36.038223 17260 solver.cpp:218] Iteration 72100 (15.1717 iter/s, 6.59122s/100 iters), loss = 0.00349463
I0626 02:06:36.038223 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:36.038223 17260 solver.cpp:237]     Train net output #1: loss = 0.00349447 (* 1 = 0.00349447 loss)
I0626 02:06:36.038223 17260 sgd_solver.cpp:105] Iteration 72100, lr = 1e-05
I0626 02:06:41.851866 17260 solver.cpp:218] Iteration 72200 (17.2019 iter/s, 5.81332s/100 iters), loss = 0.00690552
I0626 02:06:41.851866 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:41.852367 17260 solver.cpp:237]     Train net output #1: loss = 0.00690536 (* 1 = 0.00690536 loss)
I0626 02:06:41.852367 17260 sgd_solver.cpp:105] Iteration 72200, lr = 1e-05
I0626 02:06:48.142205 17260 solver.cpp:218] Iteration 72300 (16.0639 iter/s, 6.22513s/100 iters), loss = 0.00313945
I0626 02:06:48.142205 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:48.142205 17260 solver.cpp:237]     Train net output #1: loss = 0.00313929 (* 1 = 0.00313929 loss)
I0626 02:06:48.142205 17260 sgd_solver.cpp:105] Iteration 72300, lr = 1e-05
I0626 02:06:54.602438 17260 solver.cpp:218] Iteration 72400 (15.5017 iter/s, 6.45089s/100 iters), loss = 0.00822269
I0626 02:06:54.602438 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:06:54.602438 17260 solver.cpp:237]     Train net output #1: loss = 0.00822253 (* 1 = 0.00822253 loss)
I0626 02:06:54.602438 17260 sgd_solver.cpp:105] Iteration 72400, lr = 1e-05
I0626 02:07:00.801484 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:07:01.018137 17260 solver.cpp:218] Iteration 72500 (15.5892 iter/s, 6.4147s/100 iters), loss = 0.00547259
I0626 02:07:01.018137 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:01.018137 17260 solver.cpp:237]     Train net output #1: loss = 0.00547243 (* 1 = 0.00547243 loss)
I0626 02:07:01.018137 17260 sgd_solver.cpp:105] Iteration 72500, lr = 1e-05
I0626 02:07:07.096560 17260 solver.cpp:218] Iteration 72600 (16.4522 iter/s, 6.07821s/100 iters), loss = 0.00196849
I0626 02:07:07.097060 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:07.097060 17260 solver.cpp:237]     Train net output #1: loss = 0.00196833 (* 1 = 0.00196833 loss)
I0626 02:07:07.097060 17260 sgd_solver.cpp:105] Iteration 72600, lr = 1e-05
I0626 02:07:13.132978 17260 solver.cpp:218] Iteration 72700 (16.5731 iter/s, 6.03388s/100 iters), loss = 0.00709005
I0626 02:07:13.133479 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:13.133479 17260 solver.cpp:237]     Train net output #1: loss = 0.00708988 (* 1 = 0.00708988 loss)
I0626 02:07:13.133479 17260 sgd_solver.cpp:105] Iteration 72700, lr = 1e-05
I0626 02:07:19.272413 17260 solver.cpp:218] Iteration 72800 (16.2924 iter/s, 6.13785s/100 iters), loss = 0.00173378
I0626 02:07:19.272413 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:19.272413 17260 solver.cpp:237]     Train net output #1: loss = 0.00173362 (* 1 = 0.00173362 loss)
I0626 02:07:19.272413 17260 sgd_solver.cpp:105] Iteration 72800, lr = 1e-05
I0626 02:07:25.243688 17260 solver.cpp:218] Iteration 72900 (16.7487 iter/s, 5.9706s/100 iters), loss = 0.00113017
I0626 02:07:25.243688 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:25.243688 17260 solver.cpp:237]     Train net output #1: loss = 0.00113001 (* 1 = 0.00113001 loss)
I0626 02:07:25.243688 17260 sgd_solver.cpp:105] Iteration 72900, lr = 1e-05
I0626 02:07:31.173243 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:07:31.354373 17260 solver.cpp:330] Iteration 73000, Testing net (#0)
I0626 02:07:31.354373 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:07:33.607985  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:07:33.737576 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9211
I0626 02:07:33.737576 17260 solver.cpp:397]     Test net output #1: loss = 0.291852 (* 1 = 0.291852 loss)
I0626 02:07:33.811130 17260 solver.cpp:218] Iteration 73000 (11.6938 iter/s, 8.55158s/100 iters), loss = 0.00355965
I0626 02:07:33.811130 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:33.811130 17260 solver.cpp:237]     Train net output #1: loss = 0.00355948 (* 1 = 0.00355948 loss)
I0626 02:07:33.811130 17260 sgd_solver.cpp:105] Iteration 73000, lr = 1e-05
I0626 02:07:40.166281 17260 solver.cpp:218] Iteration 73100 (15.8321 iter/s, 6.31629s/100 iters), loss = 0.00578181
I0626 02:07:40.166281 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:40.166281 17260 solver.cpp:237]     Train net output #1: loss = 0.00578165 (* 1 = 0.00578165 loss)
I0626 02:07:40.166281 17260 sgd_solver.cpp:105] Iteration 73100, lr = 1e-05
I0626 02:07:46.175191 17260 solver.cpp:218] Iteration 73200 (16.6861 iter/s, 5.99301s/100 iters), loss = 0.0116554
I0626 02:07:46.175191 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:07:46.175191 17260 solver.cpp:237]     Train net output #1: loss = 0.0116552 (* 1 = 0.0116552 loss)
I0626 02:07:46.175191 17260 sgd_solver.cpp:105] Iteration 73200, lr = 1e-05
I0626 02:07:52.386164 17260 solver.cpp:218] Iteration 73300 (16.1308 iter/s, 6.19934s/100 iters), loss = 0.00461063
I0626 02:07:52.386164 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:52.386164 17260 solver.cpp:237]     Train net output #1: loss = 0.00461047 (* 1 = 0.00461047 loss)
I0626 02:07:52.386164 17260 sgd_solver.cpp:105] Iteration 73300, lr = 1e-05
I0626 02:07:58.761492 17260 solver.cpp:218] Iteration 73400 (15.716 iter/s, 6.36296s/100 iters), loss = 0.00788354
I0626 02:07:58.761993 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:07:58.761993 17260 solver.cpp:237]     Train net output #1: loss = 0.00788338 (* 1 = 0.00788338 loss)
I0626 02:07:58.761993 17260 sgd_solver.cpp:105] Iteration 73400, lr = 1e-05
I0626 02:08:04.807427 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:08:05.104138 17260 solver.cpp:218] Iteration 73500 (15.7681 iter/s, 6.34192s/100 iters), loss = 0.00505808
I0626 02:08:05.104640 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:05.104640 17260 solver.cpp:237]     Train net output #1: loss = 0.00505792 (* 1 = 0.00505792 loss)
I0626 02:08:05.104640 17260 sgd_solver.cpp:105] Iteration 73500, lr = 1e-05
I0626 02:08:11.407088 17260 solver.cpp:218] Iteration 73600 (15.8676 iter/s, 6.30214s/100 iters), loss = 0.00286289
I0626 02:08:11.407589 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:11.407589 17260 solver.cpp:237]     Train net output #1: loss = 0.00286273 (* 1 = 0.00286273 loss)
I0626 02:08:11.407589 17260 sgd_solver.cpp:105] Iteration 73600, lr = 1e-05
I0626 02:08:17.643034 17260 solver.cpp:218] Iteration 73700 (16.0383 iter/s, 6.23508s/100 iters), loss = 0.00543708
I0626 02:08:17.643534 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:17.643534 17260 solver.cpp:237]     Train net output #1: loss = 0.00543691 (* 1 = 0.00543691 loss)
I0626 02:08:17.643534 17260 sgd_solver.cpp:105] Iteration 73700, lr = 1e-05
I0626 02:08:24.166833 17260 solver.cpp:218] Iteration 73800 (15.3641 iter/s, 6.5087s/100 iters), loss = 0.00382191
I0626 02:08:24.166833 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:24.166833 17260 solver.cpp:237]     Train net output #1: loss = 0.00382174 (* 1 = 0.00382174 loss)
I0626 02:08:24.166833 17260 sgd_solver.cpp:105] Iteration 73800, lr = 1e-05
I0626 02:08:30.030081 17260 solver.cpp:218] Iteration 73900 (17.0565 iter/s, 5.86286s/100 iters), loss = 0.0033512
I0626 02:08:30.030581 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:30.030581 17260 solver.cpp:237]     Train net output #1: loss = 0.00335104 (* 1 = 0.00335104 loss)
I0626 02:08:30.030581 17260 sgd_solver.cpp:105] Iteration 73900, lr = 1e-05
I0626 02:08:35.730254 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:08:35.901376 17260 solver.cpp:330] Iteration 74000, Testing net (#0)
I0626 02:08:35.901376 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:08:37.872805  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:08:37.999397 17260 solver.cpp:397]     Test net output #0: accuracy = 0.921
I0626 02:08:37.999397 17260 solver.cpp:397]     Test net output #1: loss = 0.29167 (* 1 = 0.29167 loss)
I0626 02:08:38.059939 17260 solver.cpp:218] Iteration 74000 (12.4551 iter/s, 8.02884s/100 iters), loss = 0.0089536
I0626 02:08:38.059939 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:38.060439 17260 solver.cpp:237]     Train net output #1: loss = 0.00895344 (* 1 = 0.00895344 loss)
I0626 02:08:38.060439 17260 sgd_solver.cpp:46] MultiStep Status: Iteration 74000, step = 4
I0626 02:08:38.060439 17260 sgd_solver.cpp:105] Iteration 74000, lr = 1e-06
I0626 02:08:44.247124 17260 solver.cpp:218] Iteration 74100 (16.1647 iter/s, 6.18632s/100 iters), loss = 0.002456
I0626 02:08:44.247124 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:44.247124 17260 solver.cpp:237]     Train net output #1: loss = 0.00245584 (* 1 = 0.00245584 loss)
I0626 02:08:44.247624 17260 sgd_solver.cpp:105] Iteration 74100, lr = 1e-06
I0626 02:08:50.977005 17260 solver.cpp:218] Iteration 74200 (14.9197 iter/s, 6.70254s/100 iters), loss = 0.0194008
I0626 02:08:50.977005 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:08:50.977005 17260 solver.cpp:237]     Train net output #1: loss = 0.0194006 (* 1 = 0.0194006 loss)
I0626 02:08:50.977005 17260 sgd_solver.cpp:105] Iteration 74200, lr = 1e-06
I0626 02:08:57.041399 17260 solver.cpp:218] Iteration 74300 (16.4908 iter/s, 6.06398s/100 iters), loss = 0.00323756
I0626 02:08:57.041899 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:08:57.041899 17260 solver.cpp:237]     Train net output #1: loss = 0.0032374 (* 1 = 0.0032374 loss)
I0626 02:08:57.041899 17260 sgd_solver.cpp:105] Iteration 74300, lr = 1e-06
I0626 02:09:02.964855 17260 solver.cpp:218] Iteration 74400 (16.8853 iter/s, 5.9223s/100 iters), loss = 0.00352897
I0626 02:09:02.965857 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:02.965857 17260 solver.cpp:237]     Train net output #1: loss = 0.00352881 (* 1 = 0.00352881 loss)
I0626 02:09:02.965857 17260 sgd_solver.cpp:105] Iteration 74400, lr = 1e-06
I0626 02:09:08.849787 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:09:09.092960 17260 solver.cpp:218] Iteration 74500 (16.3366 iter/s, 6.12121s/100 iters), loss = 0.00793762
I0626 02:09:09.092960 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:09.092960 17260 solver.cpp:237]     Train net output #1: loss = 0.00793745 (* 1 = 0.00793745 loss)
I0626 02:09:09.092960 17260 sgd_solver.cpp:105] Iteration 74500, lr = 1e-06
I0626 02:09:14.481375 17260 solver.cpp:218] Iteration 74600 (18.5593 iter/s, 5.38814s/100 iters), loss = 0.00468241
I0626 02:09:14.481876 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:14.481876 17260 solver.cpp:237]     Train net output #1: loss = 0.00468225 (* 1 = 0.00468225 loss)
I0626 02:09:14.481876 17260 sgd_solver.cpp:105] Iteration 74600, lr = 1e-06
I0626 02:09:18.903726 17260 solver.cpp:218] Iteration 74700 (22.6384 iter/s, 4.41728s/100 iters), loss = 0.00391775
I0626 02:09:18.903726 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:18.903726 17260 solver.cpp:237]     Train net output #1: loss = 0.00391759 (* 1 = 0.00391759 loss)
I0626 02:09:18.903726 17260 sgd_solver.cpp:105] Iteration 74700, lr = 1e-06
I0626 02:09:23.364919 17260 solver.cpp:218] Iteration 74800 (22.4183 iter/s, 4.46064s/100 iters), loss = 0.00296666
I0626 02:09:23.364919 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:23.364919 17260 solver.cpp:237]     Train net output #1: loss = 0.0029665 (* 1 = 0.0029665 loss)
I0626 02:09:23.364919 17260 sgd_solver.cpp:105] Iteration 74800, lr = 1e-06
I0626 02:09:27.717031 17260 solver.cpp:218] Iteration 74900 (22.979 iter/s, 4.35179s/100 iters), loss = 0.0074058
I0626 02:09:27.717031 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:27.717031 17260 solver.cpp:237]     Train net output #1: loss = 0.00740564 (* 1 = 0.00740564 loss)
I0626 02:09:27.717532 17260 sgd_solver.cpp:105] Iteration 74900, lr = 1e-06
I0626 02:09:31.844507 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:09:32.008625 17260 solver.cpp:330] Iteration 75000, Testing net (#0)
I0626 02:09:32.008625 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:09:33.486191  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:09:33.507707 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9211
I0626 02:09:33.507707 17260 solver.cpp:397]     Test net output #1: loss = 0.291777 (* 1 = 0.291777 loss)
I0626 02:09:33.572752 17260 solver.cpp:218] Iteration 75000 (17.1422 iter/s, 5.83357s/100 iters), loss = 0.00282706
I0626 02:09:33.573252 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:33.573252 17260 solver.cpp:237]     Train net output #1: loss = 0.0028269 (* 1 = 0.0028269 loss)
I0626 02:09:33.573252 17260 sgd_solver.cpp:105] Iteration 75000, lr = 1e-06
I0626 02:09:37.969435 17260 solver.cpp:218] Iteration 75100 (22.7481 iter/s, 4.39598s/100 iters), loss = 0.00597141
I0626 02:09:37.969435 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:37.969435 17260 solver.cpp:237]     Train net output #1: loss = 0.00597125 (* 1 = 0.00597125 loss)
I0626 02:09:37.969435 17260 sgd_solver.cpp:105] Iteration 75100, lr = 1e-06
I0626 02:09:42.347175 17260 solver.cpp:218] Iteration 75200 (22.8726 iter/s, 4.37205s/100 iters), loss = 0.00636818
I0626 02:09:42.347175 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:42.347175 17260 solver.cpp:237]     Train net output #1: loss = 0.00636802 (* 1 = 0.00636802 loss)
I0626 02:09:42.347175 17260 sgd_solver.cpp:105] Iteration 75200, lr = 1e-06
I0626 02:09:46.759896 17260 solver.cpp:218] Iteration 75300 (22.665 iter/s, 4.41209s/100 iters), loss = 0.0157145
I0626 02:09:46.759896 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.99
I0626 02:09:46.759896 17260 solver.cpp:237]     Train net output #1: loss = 0.0157144 (* 1 = 0.0157144 loss)
I0626 02:09:46.759896 17260 sgd_solver.cpp:105] Iteration 75300, lr = 1e-06
I0626 02:09:51.188122 17260 solver.cpp:218] Iteration 75400 (22.6471 iter/s, 4.41559s/100 iters), loss = 0.00620087
I0626 02:09:51.188122 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:51.188624 17260 solver.cpp:237]     Train net output #1: loss = 0.00620071 (* 1 = 0.00620071 loss)
I0626 02:09:51.188624 17260 sgd_solver.cpp:105] Iteration 75400, lr = 1e-06
I0626 02:09:55.467734 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:09:55.672000 17260 solver.cpp:218] Iteration 75500 (22.3462 iter/s, 4.47504s/100 iters), loss = 0.00327154
I0626 02:09:55.672000 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:09:55.672000 17260 solver.cpp:237]     Train net output #1: loss = 0.00327138 (* 1 = 0.00327138 loss)
I0626 02:09:55.672000 17260 sgd_solver.cpp:105] Iteration 75500, lr = 1e-06
I0626 02:10:00.004186 17260 solver.cpp:218] Iteration 75600 (23.0874 iter/s, 4.33138s/100 iters), loss = 0.0151521
I0626 02:10:00.004186 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:00.004186 17260 solver.cpp:237]     Train net output #1: loss = 0.015152 (* 1 = 0.015152 loss)
I0626 02:10:00.004186 17260 sgd_solver.cpp:105] Iteration 75600, lr = 1e-06
I0626 02:10:04.487956 17260 solver.cpp:218] Iteration 75700 (22.305 iter/s, 4.4833s/100 iters), loss = 0.00653592
I0626 02:10:04.488456 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:04.488456 17260 solver.cpp:237]     Train net output #1: loss = 0.00653576 (* 1 = 0.00653576 loss)
I0626 02:10:04.488456 17260 sgd_solver.cpp:105] Iteration 75700, lr = 1e-06
I0626 02:10:08.819717 17260 solver.cpp:218] Iteration 75800 (23.0886 iter/s, 4.33114s/100 iters), loss = 0.00251066
I0626 02:10:08.819717 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:08.819717 17260 solver.cpp:237]     Train net output #1: loss = 0.00251049 (* 1 = 0.00251049 loss)
I0626 02:10:08.819717 17260 sgd_solver.cpp:105] Iteration 75800, lr = 1e-06
I0626 02:10:13.410939 17260 solver.cpp:218] Iteration 75900 (21.7849 iter/s, 4.59034s/100 iters), loss = 0.00206178
I0626 02:10:13.416443 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:13.416443 17260 solver.cpp:237]     Train net output #1: loss = 0.00206161 (* 1 = 0.00206161 loss)
I0626 02:10:13.416443 17260 sgd_solver.cpp:105] Iteration 75900, lr = 1e-06
I0626 02:10:17.684288 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:10:17.874423 17260 solver.cpp:330] Iteration 76000, Testing net (#0)
I0626 02:10:17.874423 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:10:19.301132  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:10:19.355170 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9215
I0626 02:10:19.355170 17260 solver.cpp:397]     Test net output #1: loss = 0.291473 (* 1 = 0.291473 loss)
I0626 02:10:19.396199 17260 solver.cpp:218] Iteration 76000 (16.7247 iter/s, 5.97918s/100 iters), loss = 0.00198069
I0626 02:10:19.396199 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:19.396699 17260 solver.cpp:237]     Train net output #1: loss = 0.00198052 (* 1 = 0.00198052 loss)
I0626 02:10:19.396699 17260 sgd_solver.cpp:105] Iteration 76000, lr = 1e-06
I0626 02:10:23.720185 17260 solver.cpp:218] Iteration 76100 (23.1315 iter/s, 4.3231s/100 iters), loss = 0.00494327
I0626 02:10:23.720185 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:23.720185 17260 solver.cpp:237]     Train net output #1: loss = 0.00494311 (* 1 = 0.00494311 loss)
I0626 02:10:23.720185 17260 sgd_solver.cpp:105] Iteration 76100, lr = 1e-06
I0626 02:10:28.101027 17260 solver.cpp:218] Iteration 76200 (22.8297 iter/s, 4.38026s/100 iters), loss = 0.0257403
I0626 02:10:28.101027 17260 solver.cpp:237]     Train net output #0: accuracy_training = 0.98
I0626 02:10:28.101027 17260 solver.cpp:237]     Train net output #1: loss = 0.0257401 (* 1 = 0.0257401 loss)
I0626 02:10:28.101027 17260 sgd_solver.cpp:105] Iteration 76200, lr = 1e-06
I0626 02:10:32.496743 17260 solver.cpp:218] Iteration 76300 (22.7528 iter/s, 4.39507s/100 iters), loss = 0.00410222
I0626 02:10:32.496743 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:32.496743 17260 solver.cpp:237]     Train net output #1: loss = 0.00410205 (* 1 = 0.00410205 loss)
I0626 02:10:32.496743 17260 sgd_solver.cpp:105] Iteration 76300, lr = 1e-06
I0626 02:10:36.830252 17260 solver.cpp:218] Iteration 76400 (23.0762 iter/s, 4.33347s/100 iters), loss = 0.00257797
I0626 02:10:36.830252 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:36.830252 17260 solver.cpp:237]     Train net output #1: loss = 0.0025778 (* 1 = 0.0025778 loss)
I0626 02:10:36.830252 17260 sgd_solver.cpp:105] Iteration 76400, lr = 1e-06
I0626 02:10:41.007150 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:10:41.228808 17260 solver.cpp:218] Iteration 76500 (22.7405 iter/s, 4.39744s/100 iters), loss = 0.00709885
I0626 02:10:41.228808 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:41.228808 17260 solver.cpp:237]     Train net output #1: loss = 0.00709868 (* 1 = 0.00709868 loss)
I0626 02:10:41.228808 17260 sgd_solver.cpp:105] Iteration 76500, lr = 1e-06
I0626 02:10:45.674171 17260 solver.cpp:218] Iteration 76600 (22.4983 iter/s, 4.44479s/100 iters), loss = 0.0052229
I0626 02:10:45.674171 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:45.674171 17260 solver.cpp:237]     Train net output #1: loss = 0.00522273 (* 1 = 0.00522273 loss)
I0626 02:10:45.674671 17260 sgd_solver.cpp:105] Iteration 76600, lr = 1e-06
I0626 02:10:50.030508 17260 solver.cpp:218] Iteration 76700 (22.9856 iter/s, 4.35055s/100 iters), loss = 0.010811
I0626 02:10:50.030508 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:50.030508 17260 solver.cpp:237]     Train net output #1: loss = 0.0108108 (* 1 = 0.0108108 loss)
I0626 02:10:50.030508 17260 sgd_solver.cpp:105] Iteration 76700, lr = 1e-06
I0626 02:10:54.432771 17260 solver.cpp:218] Iteration 76800 (22.7174 iter/s, 4.40191s/100 iters), loss = 0.00300569
I0626 02:10:54.432771 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:54.432771 17260 solver.cpp:237]     Train net output #1: loss = 0.00300553 (* 1 = 0.00300553 loss)
I0626 02:10:54.432771 17260 sgd_solver.cpp:105] Iteration 76800, lr = 1e-06
I0626 02:10:58.825440 17260 solver.cpp:218] Iteration 76900 (22.768 iter/s, 4.39213s/100 iters), loss = 0.00130003
I0626 02:10:58.825440 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:10:58.825440 17260 solver.cpp:237]     Train net output #1: loss = 0.00129987 (* 1 = 0.00129987 loss)
I0626 02:10:58.825440 17260 sgd_solver.cpp:105] Iteration 76900, lr = 1e-06
I0626 02:11:03.036597 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:11:03.214727 17260 solver.cpp:330] Iteration 77000, Testing net (#0)
I0626 02:11:03.214727 17260 net.cpp:676] Ignoring source layer accuracy_training
I0626 02:11:04.512848  9280 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:11:04.555879 17260 solver.cpp:397]     Test net output #0: accuracy = 0.9214
I0626 02:11:04.555879 17260 solver.cpp:397]     Test net output #1: loss = 0.291682 (* 1 = 0.291682 loss)
I0626 02:11:04.609421 17260 solver.cpp:218] Iteration 77000 (17.3374 iter/s, 5.76786s/100 iters), loss = 0.00742162
I0626 02:11:04.609421 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:11:04.609421 17260 solver.cpp:237]     Train net output #1: loss = 0.00742146 (* 1 = 0.00742146 loss)
I0626 02:11:04.609421 17260 sgd_solver.cpp:105] Iteration 77000, lr = 1e-06
I0626 02:11:09.039202 17260 solver.cpp:218] Iteration 77100 (22.5785 iter/s, 4.429s/100 iters), loss = 0.0053855
I0626 02:11:09.039202 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:11:09.039202 17260 solver.cpp:237]     Train net output #1: loss = 0.00538534 (* 1 = 0.00538534 loss)
I0626 02:11:09.039202 17260 sgd_solver.cpp:105] Iteration 77100, lr = 1e-06
I0626 02:11:13.277266 17260 solver.cpp:218] Iteration 77200 (23.598 iter/s, 4.23765s/100 iters), loss = 0.00505512
I0626 02:11:13.277266 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:11:13.277266 17260 solver.cpp:237]     Train net output #1: loss = 0.00505495 (* 1 = 0.00505495 loss)
I0626 02:11:13.277266 17260 sgd_solver.cpp:105] Iteration 77200, lr = 1e-06
I0626 02:11:19.454779 17260 solver.cpp:218] Iteration 77300 (16.2202 iter/s, 6.16516s/100 iters), loss = 0.00364522
I0626 02:11:19.455279 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:11:19.455279 17260 solver.cpp:237]     Train net output #1: loss = 0.00364506 (* 1 = 0.00364506 loss)
I0626 02:11:19.455279 17260 sgd_solver.cpp:105] Iteration 77300, lr = 1e-06
I0626 02:11:23.806447 17260 solver.cpp:218] Iteration 77400 (22.9841 iter/s, 4.35083s/100 iters), loss = 0.00422351
I0626 02:11:23.806447 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:11:23.806447 17260 solver.cpp:237]     Train net output #1: loss = 0.00422335 (* 1 = 0.00422335 loss)
I0626 02:11:23.806447 17260 sgd_solver.cpp:105] Iteration 77400, lr = 1e-06
I0626 02:11:27.999588 14952 data_layer.cpp:73] Restarting data prefetching from start.
I0626 02:11:28.226249 17260 solver.cpp:218] Iteration 77500 (22.6282 iter/s, 4.41927s/100 iters), loss = 0.00748583
I0626 02:11:28.226249 17260 solver.cpp:237]     Train net output #0: accuracy_training = 1
I0626 02:11:28.226249 17260 